Id,Title,CreationDate,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
27054162,"what are REST,RESTFul, SOA and microservices in simple terms?",2014-11-21 04:31:46,<rest><soa><microservices>,2,19619,3,11.0,23,"<p>I thought I knew what REST/""RESTFul"", restfulservices, webservices, SOA and microservices were but I came across so many different definitions that I reached the conclusion that those terms are overused, misused , or simply badly defined.</p>&#xA;&#xA;<p>I hope to have a clear understanding of what the aforementioned terms represent, their concrete definition , their commonality and differences, advantages vs disadvantages, and most importantly the bottom line - the most important things to remember in order to use those terms appropriately. </p>&#xA;"
27007353,How does data denormalization work with the Microservice Pattern?,2014-11-19 01:25:07,<database><denormalization><microservices>,4,6219,4,21.0,62,"<p>I just read an article on <a href=""http://java.dzone.com/articles/microservices-and-paas-part-2"">Microservices and PaaS Architecture</a>. In that article, about a third of the way down, the author states (under <strong>Denormalize like Crazy</strong>):</p>&#xA;&#xA;<blockquote>&#xA;  <p>Refactor database schemas, and de-normalize everything, to allow complete separation and partitioning of data. That is, do not use underlying tables that serve multiple microservices. There should be no sharing of underlying tables that span multiple microservices, and no sharing of data. Instead, if several services need access to the same data, it should be shared via a service API (such as a published REST or a message service interface).</p>&#xA;</blockquote>&#xA;&#xA;<p>While this <em>sounds</em> great in theory, in practicality it has some serious hurdles to overcome. The biggest of which is that, often, databases are tightly coupled and every table has <em>some</em> foreign key relationship with at least one other table. Because of this it could be impossible to partition a database into <em>n</em> sub-databases controlled by <em>n</em> microservices.</p>&#xA;&#xA;<p>So I ask: <strong>Given a database that consists entirely of related tables, how does one denormalize this into smaller fragments (groups of tables) so that the fragments can be controlled by separate microservices?</strong></p>&#xA;&#xA;<p>For instance, given the following (rather small, but exemplar) database:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;user_id&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;product_id&#xA;order_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p>Don't spend too much time critiquing my design, I did this on the fly. The point is that, to me, it makes logical sense to split this database into 3 microservices:</p>&#xA;&#xA;<ol>&#xA;<li><code>UserService</code> - for CRUDding users in the system; should ultimately manage the <code>[users]</code> table; and</li>&#xA;<li><code>ProductService</code> - for CRUDding products in the system; should ultimately manage the <code>[products]</code> table; and</li>&#xA;<li><code>OrderService</code> - for CRUDding orders in the system; should ultimately manage the <code>[orders]</code> and <code>[products_x_orders]</code> tables</li>&#xA;</ol>&#xA;&#xA;<p>However all of these tables have foreign key relationships with each other. If we denormalize them and treat them as monoliths, they lose all their semantic meaning:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p><strong>Now there's no way to know who ordered what, in which quantity, or when.</strong></p>&#xA;&#xA;<p>So is this article typical academic hullabaloo, or is there a real world practicality to this denormalization approach, and if so, what does it look like (bonus points for using my example in the answer)?</p>&#xA;"
26866479,Architecture of a microservice based web app,2014-11-11 13:53:31,<web-applications><soa><microservices>,4,6863,0,6.0,25,"<p>I am confused about the point at which a web application diverges into microservices - is it at url level or models level?&#xA;As an example, Suppose I have a monolithic app that serves 3 pages. Say each page serves a separate usecase and i want to back eack of them with their own microservices. Now, which of these is the correct way of implementing a microservice based architecture:</p>&#xA;&#xA;<ul>&#xA;<li>I create three different apps(microservices), each containing the (route, controller, models, templates) for one of the pages. And then based on which ever page is requested, I route the request to that particular app. This means that the whole page from database to HTML is served by a separate app. Basically, different pages in the same website are being completely served by different apps on the backend.</li>&#xA;<li>The 3 microservices do not handle the UI stuff but only the data for their usecases(models, controller, no templates) and expose it over a REST api. I have one public facing app. This app queries the three different apps(microservices) only for the data and then builds the html pages to be returned to browser. All the pages in a web app in this case are being served by a single app which internally makes use of three different microservices.</li>&#xA;</ul>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/b62O1.png"" alt=""enter image description here""></p>&#xA;"
22513893,Microservices and SOA using messaging,2014-03-19 17:39:26,<architecture><messaging><soa><microservices>,5,5075,0,8.0,21,"<p>I've been very interested in trying out microservices/SOA as an architecture and am having a hard time conceptualizing how the integration between services would actually be done.</p>&#xA;&#xA;<p>I like the idea of using messaging to decouple the clients from the services, but don't understand how a system could utilize it exclusively. The typical async operations and pub/sub stuff obviously makes sense - scenarios like creating a new order, broadcasting data for reporting, etc. What I don't understand is whether people typically try to use messaging for common request/reply scenarios - for example, a user hits their ""profile"" page and part of the data that needs to get rendered on the page is from a user service.</p>&#xA;&#xA;<p>I know common messaging implementations provide REST-like reply/request functionality but is that often used for simple data requests? It seems more likely that microservices would both expose REST endpoints and also register with a message broker for different types of communication it will participate in, but all these presentations I watch of SOA and microservice architecture seem to suggest they only use one or the other..</p>&#xA;&#xA;<p>Thanks for any elaboration/experiences!</p>&#xA;"
25600580,Sharing code and schema between microservices,2014-09-01 07:13:19,<architecture><microservices>,4,8717,1,9.0,40,"<p>If you go for a <strong>microservices architecture</strong> in your organization, they can share configuration via <a href=""http://zookeeper.apache.org/"">zookeeper</a> or its equivalent. However, how should the various services share a common db schema? common constants? and common utilities?</p>&#xA;&#xA;<p>One way would be to place all the microservices in the same code repository, but that would contradict the decoupling that comes with microservices...</p>&#xA;&#xA;<p>Another way would be to have each microservice be completely independent, however that would cause code duplication and data duplication in the separate databases each microservice would have to hold.</p>&#xA;&#xA;<p>Yet another way would be to implement functional microservices with no context\state, but that's usually not realistic and would push the architecture to having a central hub that maintains the context\state and a lot of traffic from\to it.</p>&#xA;&#xA;<p><strong>What would be a scalable, efficient practical and hopefully beautiful way to share code and schema between microservices?</strong> </p>&#xA;"
25595492,Single Sign-On in Microservice Architecture,2014-08-31 19:26:54,<security><cloud><single-sign-on><microservices><paas>,2,13805,3,22.0,37,<p>I'm trying to design a green-field project that will have several services (serving data) and web-applications (serving HTML). I've read about microservices and they look like good fit.</p>&#xA;&#xA;<p>The problem I still have is how to implement SSO. I want the user to authenticate once and have access to all the different services and applications.</p>&#xA;&#xA;<p>I can think of several approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p>Add Identity service and application. Any service that has protected resources will talk to the Identity service to make sure the credentials it has are valid. If they are not it will redirect the user for authentication.</p></li>&#xA;<li><p>Use a web-standard such as OpenID and have each service handle it own identities. This means the user will have to authorize individually each service/application but after that it will be SSO.</p></li>&#xA;</ol>&#xA;&#xA;<p>I'll be happy to hear other ideas. If a specific PaaS (such as Heroku) has a proprietary solution that would also be acceptable.</p>&#xA;
26331854,Micro services and .NET,2014-10-13 01:45:35,<.net><microservices>,5,43797,1,7.0,25,"<p>How to build micro service oriented application in .NET world? Are there any platforms where we can write micro service oriented apps in .NET world? How to envision architecture that includes Micro services, Event store and some of NoSQL databases?&#xA;Thanks.</p>&#xA;"
28942614,Should I use forever/pm2 within a (Docker) container?,2015-03-09 13:00:16,<node.js><docker><coreos><microservices>,2,10713,0,13.0,37,"<p>I am refactoring a couple of node.js services. All of them used to start with <code>forever</code> on virtual servers, if the process crashed they just relaunch.</p>&#xA;&#xA;<p>Now, moving to containerised and state-less application structures, I think the process should exit and the container should be restarted on a failure.</p>&#xA;&#xA;<p>Is that correct? Are there benefits or disadvantages?</p>&#xA;"
30027545,Vert.x 3 and Microservices,2015-05-04 10:10:47,<architecture><vert.x><microservices>,3,2637,0,4.0,20,"<p>Microservices are gaining traction as an software architecture style that will better support continuous delivery, provide a model for rapid deployment and separation of concerns.</p>&#xA;&#xA;<p>Vert.x 3 and Vert.x-Apex provide an interesting model for building a microservices. As one of the examples shows, a simple verticle can expose an HTTP service, so a REST service is available. The verticle binds its own tcp port.</p>&#xA;&#xA;<p>When scaling up to multiple micro-services to support a full application you end up with a number of choices. Any thoughts on what style could eventually support continuous delivery, and minimizing downtime on upgrades?</p>&#xA;&#xA;<h2>Options</h2>&#xA;&#xA;<ol>&#xA;<li>Run multiple verticles could be a solution, all containing there own routing, so http handling is contained in the verticle. A request/response can be handled completely by the verticle. This could mean that every verticle runs on it's own tcp port. </li>&#xA;<li>Using a router you can expose all paths on a single port, and handle them accordingly. Data will be handled by the verticle that contains the router, possible passing it on to other verticles. This then starts to look like a more monolithic approach.</li>&#xA;<li>Run separate instances of vert.x containing the service (possible cluster them). This could make it easier use continuous delivery, because the whole thing is self-contained.</li>&#xA;<li>Other possible options?</li>&#xA;</ol>&#xA;&#xA;<h2>Deployment</h2>&#xA;&#xA;<p>On the deployment side rapid deployment of new services would be desirable, without bringing the whole application down. </p>&#xA;&#xA;<ul>&#xA;<li>Option 3. could provide a way for this, but can also cause overhead, especially when there is a DB verticle running in every verticle. </li>&#xA;<li>Option 1. could be easier, but what about reloading the new and updated verticles.</li>&#xA;</ul>&#xA;&#xA;<p>Separate micro-services offer an interesting way of development, but offers some challenges in orchestration and deployment.</p>&#xA;&#xA;<p>Any thoughts?</p>&#xA;"
28767707,How to deal with shared state in a micro-service architecture?,2015-02-27 14:44:20,<deployment><architecture><integration-testing><microservices><test-environments>,3,4043,8,13.0,17,"<p>In our company we are transitioning from a huge monolithic application to a micro-service architecture. The main technical drivers for this decision were the need to be able to scale services independently and the scalability of development - we've got ten scrum teams working in different projects (or 'micro-services').</p>&#xA;&#xA;<p>The transition process is being smooth and we've already started to benefit from the advantages of this new technical and organizational structures. Now, on the other hand, <strong>there is a main point of pain that we are struggling with: how to manage the 'state' of the dependencies between these micro-services</strong>. </p>&#xA;&#xA;<p>Let's put an example: one of the micro-services deals with users and registrations. This service (let's call it X) is responsible for maintaining identity information and thus is the main provider for user 'ids'. The rest of the micro-services have a strong dependency on this one. For example, there are some services responsible for user profile information (A), user permissions (B), user groups (C), etc. that rely on those user ids and thus there is a need for maintaining some data sync between these services (i.e. service A should not have info for a userId not registered in service X). We currently maintain this sync by notifying changes of state (new registrations, for example) using RabbitMQ. </p>&#xA;&#xA;<p>As you can imagine, there are <em>many</em> Xs: many 'main' services and many more complicated dependencies between them.</p>&#xA;&#xA;<p>The main issue comes when managing the different dev/testing environments. Every team (and thus, every service) needs to go through several environments in order to put some code live: continuous integration, team integration, acceptance test and live environments. </p>&#xA;&#xA;<p>Obviously we need all services working in all these environments to check that the system is working as a whole. Now, this means that in order to test dependent services (A, B, C, ...) we must not only rely on service X, but also on its state. <strong>Thus, we need somehow to maintain system integrity and store a global &amp; coherent state</strong>.</p>&#xA;&#xA;<p>Our current approach for this is getting snapshots of all DBs from the live environment, making some transformations to shrink and protect data privacy and propagating it to all environments before testing in a particular environment. This is obviously a tremendous overhead, both organizationally and in computational resources: we have ten continuous integration environments, ten integration environments and one acceptance test environment that all need to be 'refreshed' with this shared data from live and the latest version of the code frequently. </p>&#xA;&#xA;<p>We are struggling to find a better way to ease this pain. Currently we are evaluating two options: </p>&#xA;&#xA;<ol>&#xA;<li>using docker-like containers for all these services </li>&#xA;<li>having two versions of each service (one intended for development of that service and one another as a sandbox to be used by the rest of the teams in their development &amp; integration testing)</li>&#xA;</ol>&#xA;&#xA;<p><strong>None of these solutions ease the pain of shared data between services</strong>. We'd like to know how some other companies/developers are addressing this problem, as we think this must be common in a micro services architecture. </p>&#xA;&#xA;<p>How are you guys doing it? Do you also have this problem? Any recommendation?</p>&#xA;&#xA;<p>Sorry for the long explanation and thanks a lot!</p>&#xA;"
27865238,Parent pom and microservices,2015-01-09 16:45:49,<java><maven><microservices>,3,5502,2,4.0,14,"<ul>&#xA;<li>We have several projects that are microservices, every project is independent (running on separate spring boot server, exposing rest services, using separate DB schema...)</li>&#xA;<li>We use maven to manage the dependencies.</li>&#xA;</ul>&#xA;&#xA;<p>Is it a good idea to have a parent pom declaring each microservices as modules? And so helping to manage the common dependencies (like the lib servlet-api witch is used in every project, to remove it of all of them and declare it in only the parent pom)</p>&#xA;"
33399988,Microservices: datasource per instance or per microservice?,2015-10-28 19:31:53,<database><design><architecture><microservices>,5,2501,1,4.0,12,"<p>Building microservice architecture I faced the problem of data sharing between instances of the same microservice.</p>&#xA;&#xA;<p>I have microservice, that massively uses it's datasource - every request to service cause database request (usually insert). This service will be used very heavily and I plan to hide multiple instances behind Load Balancer. And here rises a question: shall these instances use ONE database (will the database be a bottleneck?) or MULTIPLE (datasource per instance) have?</p>&#xA;"
33465577,How to manage secrets in a Microservice / Container / Cloud environment?,2015-11-01 18:21:40,<git><docker><microservices><secret-key>,1,2735,4,8.0,16,"<p>Microservices and Cloud is a thing. Everyone is talking and writing about. Personally i am thinking a lot about this topics: How this can be used to benefit from? What are possible challenges? How can this speedup the daily development? And how to manage all things?&#xA;One question that bothers me since a few days is ""How to manage secrets in a Microservice / Cloud environment?"".</p>&#xA;&#xA;<p>Imagine a company with 150 software engineers and various teams with various products. Every team is creating a software and every service needs various amounts of secrets (API-Keys, Passwords, SSH-Keys, whatever).&#xA;The ""old fashion"" way was to create a few configuration files in a ini / yaml / txt format and read it from. 12Factor apps say: Do it per env vars.</p>&#xA;&#xA;<p>Env vars can be set per machine and the config files can be placed there as well.&#xA;This works if you got a hand full of machines and the deployment is done by a few system admins.&#xA;One of the general rules say: ""Don`t store secrets in a Git repo."".</p>&#xA;&#xA;<p>Now the new world comes in.&#xA;Ever team is responsible for the application they produce itself.&#xA;They should be deployed and run by the team.&#xA;So our company is moving to a container and self-service way (e.g. Mesos and Marathon or Kubernetes).</p>&#xA;&#xA;<p>Of course, Dockerfiles can set env vars as well. And yes, you can ADD your config file into the Docker container during build.&#xA;But with this everyone can access the secrets (e.g. from other teams). And no one knows who uses this secrets and do something dangerous.</p>&#xA;&#xA;<p>You want to versionize your Dockerfiles as well. And applications you want to run on Marathon should be versionized (Git or whatever) as well (and applied by REST API). So where to store and manage all the secrets for this containers / apps?&#xA;Because with scheduler frameworks like Swarm and Machine (for Docker), Mesos and Marathon (usable for Docker as well) or Kubernetes you don`t know where your app will be running. This will be scheduled over several machines.&#xA;And most of this tools have no authentification (by default, of course this can be added by a Nginx proxy or something).</p>&#xA;&#xA;<p>One idea to manage secrets is using a tool like <a href=""https://vaultproject.io/"">Vault</a>. But i never saw ""native"" support in an app. The same applies for <a href=""https://github.com/StackExchange/blackbox"">Blackbox</a>. And i don`t know how configuration management can solve this. I know that Chef supports encrypted databags, but afaik it is not possible to use Chef to setup/build Docker containers.</p>&#xA;&#xA;<p>How do you manage secrets in a multi team env with several engineers in a Microservice / Container / Cloud environment?</p>&#xA;"
30422184,Where does Elixir/erlang fit into the microservices approach?,2015-05-24 09:54:33,<architecture><erlang><docker><elixir><microservices>,1,8742,7,26.0,88,"<p>Lately I've been doing some experiments with docker compose in order to deploy multiple collaborating microservices. I can see the many benefits that microservices provide, and now that there is a good toolset for managing them, I think that it's not extremely hard to jump into the microservices wagon.</p>&#xA;&#xA;<p>But, I have been experimenting with Elixir too, and I am quite fond of the benefits that provides by itself. Given that it encourages packing your code into multiple decoupled applications, and supports hot code upgrades, how would you mix docker with elixir (or erlang, for that matter)?</p>&#xA;&#xA;<p>For example, if I want to use docker because it provides dev-prod parity, how does elixir fit in that? Given that docker containers are immutable, I lose the ability to do hot-code upgrades, right? What about blue/green deployments or canary releases?</p>&#xA;&#xA;<p>I mean, I could just write microservices with Elixir and use them as if they were written in any other language, polyglotism is one of the benefits of microservices anyway, but then I'm not getting the full benefits of using the OTP platform, I guess that pure collaborative erlang applications are way more optimal that using intermediate queues to communicate between microservices written in different (or not) languages.</p>&#xA;"
31842622,Microservices: How to integrate the UI?,2015-08-05 20:54:01,<microservices>,1,3595,3,3.0,13,"<p>today I started reading about Microservice architectures - and it seems to be very interesting!&#xA;But I have one doubt I need some exlanation on:&#xA;Assume I want to create a blog and would build 4 microservices for that: User/login Service, Article Service, Comments Service and Reporting/analytics Service(not a realistic example, I know...).&#xA;The Reporting/Analytics service is purely backend - no issue here for my understanding.&#xA;But the three others involve some UI part - and as to my understanding this UI part should also be part of the microservice itself, right?&#xA;How would the UI integration work? Would I then have a 5th ""front door"" service that collects the user requests, forwards them to the other services which then answer with HTML/CSS and the front door service would then compose the individual responses into what is returned to the user?</p>&#xA;&#xA;<p>Any change you have an example/use case for such a scenario?</p>&#xA;&#xA;<p>Thanks and regards!</p>&#xA;"
31786040,Spring Cloud: Canary Deployments with Zuul,2015-08-03 11:27:35,<spring-cloud><microservices><netflix-eureka><netflix-zuul><canary-deployment>,1,2173,0,8.0,15,"<p>I am getting started with Spring Cloud using Eureka and Zuul and had some questions around structuring blue/green and Canary deployments. So far, I have the basics worked out and have Eureka, Zuul, and a config server working as expected. What I am trying to accomplish is set up a service that has two versions, say 1.0 and a 1.1. For a subset of specific users, I want to route them to the 1.1 version and everyone else should go to the 1.0 version. </p>&#xA;&#xA;<p>The Zuul filter API is a little light on documentation and I'm struggling a bit to grok some of the concepts, so I thought I'd ask a few questions here. I have also have some basic filters running, which don't do a whole lot a the moment other than getting the identity of the principal and the service they are requesting. Where I am hitting a wall is understanding how to expose two different versions of the same service to Eureka and Zuul. A few things I'm curious about:</p>&#xA;&#xA;<ul>&#xA;<li>Between documentation, posts, and other stack overflow, the term ""service"" and ""cluster"" seem to be used interchangeably. Is this correct?</li>&#xA;<li>With that said if I have a service named <code>/simpleservice</code> do I expose two different serviceIDs (i.e. <code>simpleservice</code> and <code>simpleservice-1.1</code> )? And If I do that, when one of the targeted users requests <code>/simpleservice</code>, I'm having Zuul send them to <code>/simpleservice-1.1</code></li>&#xA;<li>Or, do you add another node to the existing service ID and add additional metadata to each node so that Zuul and distinguish versions 1.0 and 1.1?</li>&#xA;<li>Is the correct answer ""all of the above?"" :)</li>&#xA;</ul>&#xA;"
31342583,How to manage/balance semi persistent jobs over service instances,2015-07-10 13:54:10,<php><load-balancing><apache-zookeeper><microservices>,3,261,0,4.0,17,"<p>I see a common pattern for services that we try to develop and I wonder if there are tools / libraries out there that would help here. While the default jobs as discussed in microservice literature is from the REQUEST -> RESPONSE nature, our jobs are more or less assignments of semi permanent tasks.</p>&#xA;&#xA;<p>Examples of such tasks</p>&#xA;&#xA;<ul>&#xA;<li>Listen on the message queue for data from source X and Y, correlate the data that comes in and store it in Z.</li>&#xA;<li>Keep an in-memory buffer that calculates a running average of the past 15 mins of data everytime a new data entry comes in.</li>&#xA;</ul>&#xA;&#xA;<p>Currently our services are written in PHP. Due to the perceived overhead of PHP processes and connections to the message queue we'd like a single service process to handle multiple of those jobs simultanously.</p>&#xA;&#xA;<p>A chart that hopefully illustrated the setup that we have in our head:&#xA;<img src=""https://i.stack.imgur.com/HHDls.png"" alt=""services_setup""></p>&#xA;&#xA;<ul>&#xA;<li>Service Workers are currently deamonized PHP scripts</li>&#xA;<li>For the Service Registry we are looking at Zookeeper</li>&#xA;</ul>&#xA;&#xA;<p>While Zookeeper (and Curator) do loadbalancing, I did not find anything around distributing permanent jobs (that are updatable, removable, and must be reassigned when a worker dies)</p>&#xA;&#xA;<p>Proposed responsibilities of a Job Manager</p>&#xA;&#xA;<ul>&#xA;<li>Knows about jobs</li>&#xA;<li>Knows about services that can do these jobs</li>&#xA;<li>Can assign jobs to services</li>&#xA;<li>Can send job updates to services</li>&#xA;<li>Can reassign jobs if a worker dies</li>&#xA;</ul>&#xA;&#xA;<p>Are there any libraries / tools that can tackle such problems, and can thus function as the Job Manager? Or is this all one big anti pattern and should we do it some other way?</p>&#xA;"
31313170,How to route in between microservices using Spring Cloud & Netflix OSS,2015-07-09 09:17:06,<spring-cloud><microservices><netflix-eureka><netflix-zuul><blue-green-deployment>,1,2730,2,16.0,17,"<p>During our development of microservices using Spring Cloud, we started out using Zuul as a proxy for any connection from the outside to microservices, and for any microservice needing to contact another microservice.</p>&#xA;&#xA;<p>After some time we made the conclusion that Zuul was designed to be an edge service (only proxying traffic from the outside to the microservices), and shouldn't be used for intermicroservices communication. Especially the way Spring Cloud recommends the use of eureka to make a direct (potentially load balanced) connection to another service made us go against having Zuul in between everything.</p>&#xA;&#xA;<p>Of course everything works nicely as expected (as it always does with Spring Cloud), but we are clueless on how to perform a certain use case with this setup.</p>&#xA;&#xA;<p>When deploying a new version of a microservice, we'd like to have a <a href=""http://martinfowler.com/bliki/BlueGreenDeployment.html"" rel=""noreferrer"">blue/green deployment</a> with the old and the new version.&#xA;However, having no Zuul in between the microservices, the communication between two separate services will continue to go to the old version until it is removed from eureka.</p>&#xA;&#xA;<p>We are thinking of how we can achieve this. In the picture below I have drawn what I think might be an option.</p>&#xA;&#xA;<p>In the first part of the picture, Zuul calls eureka to get the registry to create the routes. Also service 1 is calling eureka to get the registry to route to service 2. Since service 2 is in the eureka registry, the routing is done successfully.</p>&#xA;&#xA;<p>In the second part of the picture, an update of service 2 (service 2.1) is deployed. It registers with eureka as well, which makes service 1 now route to both service 2 and service 2.1. This is not wanted with the blue/green deployment.</p>&#xA;&#xA;<p>In the third part a potential solution to this issue is showcased with another instance of eureka being deployed just for this purpose. This instance isn't peer aware and won't sync with the first eureka instance. As opposed to the first instance, this one's only purpose is to facilitate the blue/green deployment. Service 2.1 registers with the second eureka instance, and service 1 his configuration is changed to fetch its registry not from the first but from the second eureka instance.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/V9lpR.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>The main question we are facing is whether this is a viable solution. Having the flexibility of Zuul to route is a big plus which we don't have in this scenario. Should we move back to routing every service-to-service call through Zuul or is there another solution (maybe ribbon configuration of some sort) more appropriate? Or is the second eureka instance the best solution for this type of deployments?</p>&#xA;&#xA;<p>Any feedback would be greatly appreciated.</p>&#xA;&#xA;<p>Kind regards,&#xA;Andreas</p>&#xA;"
48984610,Micro services vs web services,2018-02-26 08:54:35,<java><xml><apache><web-services><microservices>,1,280,1,0.0,-3,"<p>What is the exactly difference between Micro services vs web services.</p>&#xA;&#xA;<p>My requirement is need to link up web services(SOAP,REST) service to micro services.</p>&#xA;&#xA;<p>Can i consider micro services also web services. </p>&#xA;"
48906817,2PC vs Sagas (distributed transactions),2018-02-21 13:10:40,<transactions><cloud><microservices><distributed-computing><saga>,1,361,1,2.0,15,"<p>I'm developing my insight about distributed systems, and how to maintain data consistency across such systems, where business transactions covers multiple services, bounded contexts and network boundaries.</p>&#xA;&#xA;<p>Here are two approaches which I know are used to implement distributed transactions:</p>&#xA;&#xA;<ul>&#xA;<li>2-phase commit (2PC)</li>&#xA;<li>Sagas</li>&#xA;</ul>&#xA;&#xA;<p>2PC is a protocol for applications to <em>transparently</em> utilize global ACID transactions by the support of the platform. Being embedded in the platform, it is transparent to the business logic and the application code as far as I know.</p>&#xA;&#xA;<p>Sagas, on the other hand, are series of local transactions, where each local transaction mutates and persist the entities along with some flag indicating the phase of the global transaction and commits the change. In the other words, state of the transaction is part of the domain model. Rollback is the matter of committing a series of ""inverted"" transactions. Events emitted by the services triggers these local transactions in either case.</p>&#xA;&#xA;<p>Now, when and why would one use sagas over 2PC and vice versa? What are the use cases and pros/cons of both? Especially, the brittleness of sagas makes me nervous, as the inverted distributed transaction could fail as well.</p>&#xA;"
26616962,Microservices: What are smart endpoints and dumb pipes?,2014-10-28 19:33:01,<architecture><soa><messaging><distributed><microservices>,6,13620,0,7.0,15,"<p>I have read an article ""<a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""noreferrer"">Microservices</a>"" by Martin Fowler and find it difficult to understand <strong>smart endpoint</strong>s and <strong>dumb pipes</strong>. Please explain these terms, examples are welcome.</p>&#xA;"
29591967,"Microservice architecture, what is a service in this case",2015-04-12 16:52:49,<java><web-services><rest><microservices>,6,4110,1,3.0,9,"<p>I'm reading some documentation about the micro-services architecture (through  <a href=""http://microservices.io/patterns/microservices.html"" rel=""noreferrer"">this link for example</a>) and I was wondering what is exactly a service in this case.</p>&#xA;&#xA;<p>In IT, everything could be called a service:&#xA;- a SPRING REST application launched through the java command like:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java -jar build/libs/gs-rest-service-0.1.0.jar</p>&#xA;</blockquote>&#xA;&#xA;<ul>&#xA;<li>It could also be a classes corresponding to the business layer in a DDD </li>&#xA;<li>It could be simply something related to the domain studied, like providing something to somebody</li>&#xA;<li>and many others... (android background running services etc...)</li>&#xA;</ul>&#xA;&#xA;<p>But in microservices, what does it mean? And what kind of technologies / tools are used to create a ""service running by himself"" in the Java EE stack for example? It's only related to webservices?</p>&#xA;"
29460485,Microservices Architecture: Cross Service data sharing,2015-04-05 18:03:50,<web-services><architecture><microservices>,3,7356,2,17.0,22,"<p>Consider the following micro services for an online store project:<br>&#xA;Users Service keeps account data about the store's users (including first name, last name, email address, etc')</p>&#xA;&#xA;<p>Purchase Service keeps track of details about user's purchases.</p>&#xA;&#xA;<p>Each service provides a UI for viewing and managing it's relevant entities.&#xA;The Purchase Service index page lists purchases. Each purchase item should have the following fields:<br>&#xA;id, full name of purchasing user, purchased item title and price.<br>&#xA;Furthermore, as part of the index page, I'd like to have a search box to let the store manager search purchases by purchasing user name.</p>&#xA;&#xA;<p>It is not clear to me how to get back data which the Purchase Service does not hold - for example: a user's full name.&#xA;The problem gets worse when trying to do more complicated things like search purchases by purchasing user name.</p>&#xA;&#xA;<p>I figured that I can obviously solve this by syncing users between the two services by broadcasting some sort of event on user creation (and saving only the relevant user properties on the Purchase Service end). That's far from ideal in my perspective. How do you deal with this when you have millions of users? would you create millions of records in each service which consumes users data?</p>&#xA;&#xA;<p>Another obvious option is exposing an API at the Users Service end which brings back user details based on given ids. That means that every page load in the Purchase Service, I'll have to make a call to the Users Service in order to get the right user names. Not ideal, but I can live with it.</p>&#xA;&#xA;<p>What about implementing a purchase search based on user name? Well I can always expose another API endpoint at the Users Service end which receives the query term, perform a text search over user names in the Users Service, and then return all user details which match the criteria. At the Purchase Service, map the relevant ids back to the right names and show them in the page. This approach is not ideal either.</p>&#xA;&#xA;<p>Am I missing something? Is there another approach for implementing the above? Maybe the fact that I'm facing this issue is sort of a code smell? would love to hear other solutions.</p>&#xA;"
29117570,Orchestrating microservices,2015-03-18 08:52:57,<http><orchestration><hypermedia><microservices>,7,41902,0,115.0,132,"<p>What is the standard pattern of orchestrating microservices?</p>&#xA;&#xA;<p>If a microservice only knows about its own domain, but there is a flow of data that requires that multiple services interact in some manner, what's the way to go about it?</p>&#xA;&#xA;<p>Let's say we have something like this:</p>&#xA;&#xA;<ul>&#xA;<li>Invoicing</li>&#xA;<li>Shipment</li>&#xA;</ul>&#xA;&#xA;<p>And for the sake of the argument, let's say that once an an order has been shipped, the invoice should be created. </p>&#xA;&#xA;<p>Somewhere, someone presses a button in a GUI, ""I'm done, let's do this!""&#xA;In a classic monolith service architecture, I'd say that there is either an ESB handling this, or the Shipment service has knowledge of the invoice service and just calls that.</p>&#xA;&#xA;<p>But what is the way people deal with this in this brave new world of microservices?</p>&#xA;&#xA;<p>I do get that this could be considered highly opinion-based. but there is a concrete side to it, as microservices are not supposed to do the above.&#xA;So there has to be a ""what should it by definition do instead"", which is not opinion-based.</p>&#xA;&#xA;<p>Shoot.</p>&#xA;"
28500066,How to deploy SpringBoot Maven application with Jenkins ?,2015-02-13 12:51:45,<maven><tomcat><jenkins><spring-boot><microservices>,4,19550,5,5.0,16,"<p>I have a Spring Boot application which runs on embedded Tomcat servlet container <code>mvn spring-boot:run</code> . And I donâ€™t want to deploy the project as separate war to standalone Tomcat. </p>&#xA;&#xA;<p>Whenever I push code to BitBucket/Github, a hook runs and triggers Jenkins job (runs on Amazon EC2) to deploy the application. </p>&#xA;&#xA;<p>The Jenkins job has a post build action: <code>mvn spring-boot:run</code>, the problem is that the job hangs when post build action finished. </p>&#xA;&#xA;<p>There should be another way to do this. Any help would be appreciated.</p>&#xA;"
30296587,Using Amazon SQS with multiple consumers,2015-05-18 06:40:40,<amazon-web-services><amazon-sqs><microservices><event-based-programming>,1,10770,0,5.0,17,"<p>I have a service-based application that uses Amazon SQS with multiple queues and multiple consumers. I am doing this so that I can implement an event-based architecture and decouple all the services, where the different services react to changes in state of other systems. For example:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Registration Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'registration-new' when a new user registers.</li>&#xA;</ul></li>&#xA;<li><strong>User Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'user-updated' when user is updated.</li>&#xA;</ul></li>&#xA;<li><strong>Search Service</strong>: &#xA;<ul>&#xA;<li>Reads from queue 'registration-new' and indexes user in search.</li>&#xA;<li>Reads from queue 'user-updated' and updates user in search.</li>&#xA;</ul></li>&#xA;<li><strong>Metrics Service</strong>:&#xA;<ul>&#xA;<li>Reads from 'registration-new' queue and sends to Mixpanel.</li>&#xA;<li>Reads from queue 'user-updated' and sends to Mixpanel.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I'm having a number of issues:</p>&#xA;&#xA;<ul>&#xA;<li>A message can be received multiple times when doing polling. I can design a lot of the systems to be idempotent, but for some services (such as the metrics service) that would be much more difficult.</li>&#xA;<li>A message needs to be manually deleted from the queue in SQS. I have thought of implementing a ""message-handling-service"" that handles the deletion of messages when all the services have received them (each service would emit a 'message-acknowledged' event after handling a message).</li>&#xA;</ul>&#xA;&#xA;<p>I guess my question is this: what patterns should I use to ensure that I can have multiple consumers for a single queue in SQS, while ensuring that the messages also get delivered and deleted reliably. Thank you for your help.</p>&#xA;"
30286443,Microservices: How to store source code of many microservices?,2015-05-17 11:30:44,<git><microservices>,3,6232,0,8.0,29,"<p>Currently, I have <strong>20 microservices</strong> for one project. And every microservice stored in separate GIT reposotiry. &#xA;Subsequently, the number of services will increase <strong>to 200 (or more)</strong>.</p>&#xA;&#xA;<p>Every service has unit tests and integration tests. Every service has build in TeamCity (Continuous integration server). </p>&#xA;&#xA;<p>Question: How to store source code of 200 microservices for one project? In one repository or in separate repositories? </p>&#xA;"
30213456,Transactions across REST microservices?,2015-05-13 11:27:25,<rest><architecture><transactions><microservices>,10,43100,6,79.0,120,"<p>Let's say we have a User, Wallet REST microservices and an API gateway that glues things together. When Bob registers on our website, our API gateway needs to create a user through the User microservice and a wallet through the Wallet microservice. </p>&#xA;&#xA;<p>Now here are a few scenarios where things could go wrong:</p>&#xA;&#xA;<ul>&#xA;<li><p>User Bob creation fails: that's OK, we just return an error message to the Bob. We're using SQL transactions so no one ever saw Bob in the system. Everything's good :)</p></li>&#xA;<li><p>User Bob is created but before our Wallet can be created, our API gateway hard crashes. We now have a User with no wallet (inconsistent data).</p></li>&#xA;<li><p>User Bob is created and as we are creating the Wallet, the HTTP connection drops. The wallet creation might have succeeded or it might have not.</p></li>&#xA;</ul>&#xA;&#xA;<p>What solutions are available to prevent this kind of data inconsistency from happening? Are there patterns that allow transactions to span multiple REST requests? I've read the Wikipedia page on <a href=""http://en.wikipedia.org/wiki/Two-phase_commit_protocol"">Two-phase commit</a> which seems to touch on this issue but I'm not sure how to apply it in practice. This <a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"">Atomic Distributed Transactions: a RESTful design</a> paper also seems interesting although I haven't read it yet.</p>&#xA;&#xA;<p>Alternatively, I know REST might just not be suited for this use case. Would perhaps the correct way to handle this situation to drop REST entirely and use a different communication protocol like a message queue system? Or should I enforce consistency in my application code (for example, by having a background job that detects inconsistencies and fixes them or by having a ""state"" attribute on my User model with ""creating"", ""created"" values, etc.)?</p>&#xA;"
33726653,Service Fabric Reliable Services Pipeline design,2015-11-16 00:03:44,<c#><azure><pipeline><microservices><azure-service-fabric>,1,2574,0,10.0,14,"<p>I need to implement pipeline if Service Fabric's Reliable Services, and I need some guidelines about what of these approaches is preferable from the viewpoint of reliability simplicity and simple good design:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pWFql.png""><img src=""https://i.stack.imgur.com/pWFql.png"" alt=""enter image description here""></a></p>&#xA;"
51942114,Why we need to write business logic in separate service layer instead of writing in controller itself?,2018-08-21 05:28:49,<spring><spring-mvc><spring-boot><microservices>,2,46,3,0.0,-5,<p>Whats the use of creating different layer i.e. Service layer for business logic implementation instead of implementing that business logic in Controller itself</p>&#xA;
36896418,Why would I choose a Windows Service over a Web API service?,2016-04-27 17:07:15,<c#><web-services><asp.net-web-api><microservices>,1,586,1,0.0,-4,"<p>For me, Windows Services are inconvenient and cumbersome enough to question their validity in all apps that aren't ""Watch this folder for a change, react to this change.""</p>&#xA;&#xA;<p>I understand that this oversimplification is ignorant, why would one choose a windows service over the Web API.</p>&#xA;"
35065875,How to bring a gRPC defined API to the web browser,2016-01-28 15:44:56,<javascript><node.js><protocol-buffers><microservices><grpc>,7,21905,0,25.0,49,"<p>We want to build a Javascript/HTML gui for our gRPC-microservices. Since gRPC is not supported on the browser side, we thought of using web-sockets to connect to a node.js server, which calls the target service via grpc. &#xA;We struggle to find an elegant solution to do this. Especially, since we use gRPC streams to push events between our micro-services.&#xA;It seems that we need a second RPC system, just to communicate between the front end and the node.js server. This seems to be a lot of overhead and additional code that must be maintained.</p>&#xA;&#xA;<p>Does anyone have experience doing something like this or has an idea how this could be solved?</p>&#xA;"
35113957,Running multiple projects using docker which each runs with docker-compose,2016-01-31 12:42:12,<docker><development-environment><docker-compose><microservices>,3,6126,0,5.0,12,"<p>We are using microservices approach to build our product. We are using some projects which each uses docker-compose to run. The problem is that in development environment, if we want to change codes in multiple projects and test developed codes, we must run projects separately and link them together manually.</p>&#xA;&#xA;<p>Now we want to create a development kit which clones projects and runs them together and handles links. Can docker-compose handle multiple docker-compose file? If not is there any sufficient tool to do that for us? Or is there any recommended approach for our goal?</p>&#xA;&#xA;<p>EDIT: For example we have two projects: PROJECT_A and PROJECT_B. Each one has its own docker-compose.yml and each one needs postgresql to run. We have docker-compose.yml in PROJECT_A like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_a:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>And we have docker-compose.yml in PROJECT_B like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_b:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>Each project can run separately and works fine. But if we want to change the api between PROJECT_A and PROJECT_B we need to run both projects and link them together to test our code. Now we want to write a development kit project which can run both projects and link them if needed. What is the best approach to do this?</p>&#xA;"
35040975,Microservices architecture and breaking away from monolithic application,2016-01-27 15:09:26,<architecture><domain-driven-design><nservicebus><microservices>,1,247,2,0.0,-3,"<p>I am about to start process of breaking up our legacy application (build on top of EpiServer CMS). We would like to break it up into smaller, more manageable components (microservices). I'm leaning towards NServiceBus and some type of domain model. What are some tools that could help me?. Where would I start? Is there anything that can help me with identifying different abstraction points?</p>&#xA;&#xA;<p>I understand this is somewhat broad topic. However It's something I've been put in charge of and any feedback would be great. </p>&#xA;"
33041733,Microservices vs Monolithic Architecture,2015-10-09 15:11:34,<microservices>,3,26144,2,37.0,60,"<p>I did some reading about microservices, and I'm little bit intrigued.Seems like it is interesting concept. But I wonder, what are advantages and disadvantages using microservices over monolithic architecture, and vice versa.</p>&#xA;&#xA;<p>When microservices suitable better, and where better to go with monolithic architecture.</p>&#xA;"
34640611,How do I use an API Gateway in conjunction with microservices and JWTs?,2016-01-06 18:54:39,<api><security><jwt><microservices><kong>,1,2748,0,7.0,16,"<p>Afternoon y'all,</p>&#xA;&#xA;<p>Just looking for someone to double check my work. Is the below an effective way to secure microservices?</p>&#xA;&#xA;<h2>Premise</h2>&#xA;&#xA;<p>Breaking up our monolithic application and monolithic Partner API into microservices oriented around specific business functions. They'll most likely be small expressjs applications running in a docker container, on elastic beanstalk, who knows. They'll live somewhere :)</p>&#xA;&#xA;<p>I'm looking into either standing up <a href=""https://getkong.org"">Kong</a> as my API Gateway or using AWS API Gateway to encapsulate the details of my microservices. Also, it just feels good. </p>&#xA;&#xA;<p>The <a href=""https://getkong.org/plugins/jwt/"">JWT plugin</a> for Kong will verify the signature of the JWT and then pass the <code>customer_id</code> along in the header to the microservice. I should also mention that we have 3rd party developers that will be partaking in the integration fun as well. Here's a basic sketch of what I see happening:</p>&#xA;&#xA;<h2>Implementation</h2>&#xA;&#xA;<ol>&#xA;<li>Generate ""consumers"" for each platform and 3rd party developer we have. (Web app, mobile app, and the current integration partners we have. Note: I'm not looking to create consumers for every user that logs in. While certainly more secure, this adds a lot of work. Also, if you figure out how to get the secret out of my API Gateway I clearly have other issues)</li>&#xA;<li>Let Kong verify the request for me. Kind of like a bouncer at the door, there's no authorization, just authentication. </li>&#xA;<li>I don't need to know that the token is valid once it gets to the microservice, I can just use some middleware to decode it and use custom logic to decide if this user <em>really</em> should be doing whatever is they're trying to do. </li>&#xA;</ol>&#xA;&#xA;<h2>Extra Stuff</h2>&#xA;&#xA;<ul>&#xA;<li><p>There's a nice access control plugin for Kong. Our application and mobile app would run with ""God"" privileges, but I could definitely lock down the developers to specific routes and methods. </p></li>&#xA;<li><p>Revoking 3rd party access will be easy, revoking end users access won't be so simple unless I'm willing to invalidate all JWTs at once by generating a new secret. Perhaps I can limit token time to 10 minutes or so and make our applications check if they're expired, get a new token, and then get on with the original request. This way I can ""flag"" them in the database or something and not let the JWT be generated. </p></li>&#xA;<li><p>SSL used everywhere, JWT is stored in an SSL only cookie in the web browser and there's no sensitive information stored in any of the claims. </p></li>&#xA;</ul>&#xA;&#xA;<p>Thanks guys. </p>&#xA;"
35381163,Best practice to organize authorization in microservice architecture?,2016-02-13 14:34:27,<authentication><architecture><authorization><microservices>,1,3241,8,3.0,9,"<p>For example, I have 3 services:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Seller</li>&#xA;<li>Buyer</li>&#xA;</ul>&#xA;&#xA;<p>Each of them got their own databases, models, services... etc</p>&#xA;&#xA;<p>Authentication service knows about users, user-groups, roles, permissions and creates token.</p>&#xA;&#xA;<p>Where should I store sellers/buyers entities? On Authentication service, or on Seller/Buyer services?</p>&#xA;&#xA;<p>How should Seller/Buyer services interact to create new seller/buyer entity?</p>&#xA;&#xA;<p>How should Seller/Buyer services check permissions?</p>&#xA;&#xA;<p>Seller and Buyer entities have some common fields: name, password, email..., but also each of them have their own additional fields.</p>&#xA;&#xA;<p>Seller and Buyer interact with each other.</p>&#xA;"
41640621,Data Sharing between micro services,2017-01-13 17:52:49,<design-patterns><architecture><microservices><aws-api-gateway><data-sharing>,4,6060,9,11.0,24,"<p><strong>Current Architecture:</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qlrIu.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qlrIu.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Problem:</strong></p>&#xA;&#xA;<p>We have a two-step flow between frontend and backend layers.  </p>&#xA;&#xA;<ul>&#xA;<li>First step:&#xA;The frontend validates an input <strong>I1</strong> from the user on microservice 1 (MS1)</li>&#xA;<li>Second step:&#xA;The frontend submits <strong>I1</strong> and more information to the microservice 2</li>&#xA;</ul>&#xA;&#xA;<p>The micro service 2 (MS2) needs to validates the integrity of <strong>I1</strong> as it is coming from the frontend. How to do avoid a new query to MS1? What's the best approach?</p>&#xA;&#xA;<p><strong>Flows that I'm trying to optimize removing the steps 1.3 and 2.3</strong></p>&#xA;&#xA;<p>Flow 1:</p>&#xA;&#xA;<ul>&#xA;<li>1.1 The User X requests data (MS2_Data) from MS2</li>&#xA;<li>1.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>1.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>1.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p>Flow 2:</p>&#xA;&#xA;<ul>&#xA;<li>2.1 The User X already has data (MS2_Data) stored on local/session storage</li>&#xA;<li>2.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>2.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>2.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Approach</strong></p>&#xA;&#xA;<p>One possible approach is to use a B2B HTTP request between MS2 and MS1 but we would be duplicating the validation in the first step.&#xA;Another approach will be duplicating data from MS1 to MS2. however this is prohibitive due to the amount of data and it's volatility nature. Duplication does not seem to be a viable option.</p>&#xA;&#xA;<p>A more suitable solution is my opinion will the frontend to have the responsibility to fetch all the information required by the micro service 1 on the micro service 2 and delivered it to the micro service 2. This will avoid all this B2B HTTP requests.</p>&#xA;&#xA;<p><strong>The problem is how the micro service 1 can trust the information sent by the frontend. Perhaps using <a href=""https://jwt.io/introduction/"" rel=""noreferrer"">JWT</a> to somehow sign the data from the micro service 1 and the micro service 2 will be able to verify the message.</strong></p>&#xA;&#xA;<p><strong>Note</strong>&#xA;Every time the micro service 2 needs information from the micro service 1 a B2B http request is performed. (The HTTP request use <a href=""https://en.wikipedia.org/wiki/HTTP_ETag"" rel=""noreferrer"">ETAG</a> and <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control"" rel=""noreferrer"">Cache Control: max-age</a>). How to avoid this? </p>&#xA;&#xA;<p><strong>Architecture Goal</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FR7E7.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FR7E7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The micro service 1 needs the data from the micro service 2 on demand to be able to persist MS1_Data and MS2_Data on MS1 database, so the ASYNC approach using a broker does not apply here.</strong></p>&#xA;&#xA;<p>My question is if exists a design pattern, best practice or a framework to enable this kind of thrust communication. </p>&#xA;&#xA;<p>The downside of the current architecture is the number of B2B HTTP requests that are performed between each micro services. Even if I use a cache-control mechanism the response time of each micro service will be affected. The response time of each micro services is critical. The goal here is to archive a better performance and some how use the frontend as a gateway to distribute data across several micro services but using a <strong>thrust communication</strong>. </p>&#xA;&#xA;<p>MS2_Data is just an Entity SID like product SID or vendor SID that the MS1 must use to maintain data integrity. </p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qSYQY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qSYQY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The idea is to use the gateway as an api gateway request processing that will cache some HTTP response from MS1 and MS2 and use them as a response to MS2 SDK and MS1 SDK. This way no communication (SYNC OR ASYNC) is made directly between MS1 and MS2 and data duplication is also avoided.</p>&#xA;&#xA;<p>Of course the above solution is just for shared UUID/GUID across micro services. For full data, an event bus is used to distribute events and data across micro services in an asynchronous way (Event sourcing pattern). </p>&#xA;&#xA;<p>Inspiration: <a href=""https://aws.amazon.com/api-gateway/"" rel=""noreferrer"">https://aws.amazon.com/api-gateway/</a> and <a href=""https://getkong.org/"" rel=""noreferrer"">https://getkong.org/</a></p>&#xA;&#xA;<p><strong>Related questions and documentation:</strong></p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://stackoverflow.com/questions/41445442/how-to-sync-the-database-with-the-microservices-and-the-new-one/41475346"">How to sync the database with the microservices (and the new one)?</a></li>&#xA;<li><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""noreferrer"">https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/30213456/transactions-across-rest-microservices"">Transactions across REST microservices?</a></li>&#xA;<li><a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></li>&#xA;<li><a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"" rel=""noreferrer"">http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf</a></li>&#xA;<li><a href=""https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/"" rel=""noreferrer"">https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/</a></li>&#xA;</ul>&#xA;"
36407520,Spring Cloud/Boot vs Wildfly Swarm,2016-04-04 16:02:13,<java><spring-boot><microservices><wildfly-9><wildfly-swarm>,1,5675,4,4.0,12,"<p>I have doing some analysis of modern Container less Java Stack on net, two Major promising things i came about was:</p>&#xA;&#xA;<ol>&#xA;<li>Spring Boot/Cloud (Packed in Tomcat or Jetty,...)</li>&#xA;<li>Wildfly Swarm (Moduler Wildfly 9 Server with minimum possible components)</li>&#xA;</ol>&#xA;&#xA;<p>Yes both have their own features but i have not been able to find out a good comparison of both as both thing are in my point of view better then each other but still i have to decide what good for implementing,</p>&#xA;&#xA;<ol>&#xA;<li>Good for Developer health</li>&#xA;<li>Complex Enterprise logic</li>&#xA;<li>Scalability</li>&#xA;<li>Hot deployments</li>&#xA;<li>Microservice Approach</li>&#xA;<li>Enterprise Integration Patterns</li>&#xA;<li>Continuous Delivery Pipeline.</li>&#xA;</ol>&#xA;&#xA;<p>Thanks for your thoughts</p>&#xA;&#xA;<p>Zaheer  </p>&#xA;"
33125508,Service discovery vs load balancing,2015-10-14 12:36:39,<web-services><amazon-web-services><cloud><distributed-computing><microservices>,3,5816,1,3.0,21,"<p>I am trying to understand in which scenario I should pick a service registry over a load balancer.</p>&#xA;&#xA;<p>From my understanding both solutions are covering the same functionality.</p>&#xA;&#xA;<p>For instance if we consider <strong>consul.io</strong> as a feature list we have:</p>&#xA;&#xA;<ul>&#xA;<li>Service Discovery</li>&#xA;<li>Health Checking</li>&#xA;<li>Key/Value Store</li>&#xA;<li>Multi Datacenter</li>&#xA;</ul>&#xA;&#xA;<p>Where a load balancer like <strong>Amazon ELB</strong> for instance has:</p>&#xA;&#xA;<ul>&#xA;<li>configurable to accept traffic only from your load balancer</li>&#xA;<li>accept traffic using the following protocols: HTTP, HTTPS (secure HTTP), TCP, and SSL (secure TCP)</li>&#xA;<li>distribute requests to EC2 instances in multiple Availability Zones</li>&#xA;<li>The number of connections scales with the number of concurrent requests that the load balancer receives</li>&#xA;<li>configure the health checks that Elastic Load Balancing uses to monitor the health of the EC2 instances registered with the load balancer so that it can send requests only to the healthy instances</li>&#xA;<li>You can use end-to-end traffic encryption on those networks that use secure (HTTPS/SSL) connections</li>&#xA;<li>[EC2-VPC] You can create an Internet-facing load balancer, which takes requests from clients over the Internet and routes them to your EC2 instances, or an internal-facing load balancer, which takes requests from clients in your VPC and routes them to EC2 instances in your private subnets. Load balancers in EC2-Classic are always Internet-facing.</li>&#xA;<li>[EC2-Classic] Load balancers for EC2-Classic support both IPv4 and IPv6 addresses. Load balancers for a VPC do not support IPv6 addresses.</li>&#xA;<li>You can monitor your load balancer using CloudWatch metrics, access logs, and AWS CloudTrail.</li>&#xA;<li>You can associate your Internet-facing load balancer with your domain name. </li>&#xA;<li>etc.</li>&#xA;</ul>&#xA;&#xA;<p>So in this scenario I am failing to understand why I would pick something like <code>consul.io</code> or <code>netflix eureka</code> over <code>Amazon ELB</code> for service discovery.</p>&#xA;&#xA;<p>I have a hunch that this might be due to implementing <strong>client side service discovery</strong> vs <strong>server side service discovery</strong>, but I am not quite sure.</p>&#xA;"
33202053,Product Versioning Microservices,2015-10-18 19:08:57,<architecture><docker><domain-driven-design><soa><microservices>,2,6086,2,6.0,15,"<p>I go into microservices architecture based on docker and I have 3 microservices, which together create one product for example ""CRM system"".</p>&#xA;&#xA;<p>Now I want my client to be able to upgrade his product, whenever he wants to. &#xA;I have 3 different versions of my microservices, which one should client see? &#xA;I guess product version should be independent of microservices, because copying one of the microservices version would make me go into more trouble than having no version at all. </p>&#xA;&#xA;<p>So is there any pattern, idea to handle such situation? </p>&#xA;&#xA;<p>The only thing that comes to my mind is to have another repository which will be versioned whenever one of the microservices will produce production ready package. However, I now have a version, which none of my Product Owners (PO) would ever know about.</p>&#xA;"
29669180,"Microservice, service registry, API gateway and data sharing",2015-04-16 08:22:16,<java><web-services><rest><microservices>,1,3736,1,9.0,14,"<p>I m actually reading tones of articles concerning microservices architecture, but, it seems that they are dealing the things the easiest way possible, without going deeper in explanations.</p>&#xA;&#xA;<p>To explain you my questions, I will show you my actual little architecture :</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/0hqf5.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>So, here's what I want to use. Before making anything technically, I need more theorical informations.</p>&#xA;&#xA;<p><strong>Description of my domain</strong></p>&#xA;&#xA;<p>I have some mobile and browser based customers, able to connect themselves on an application, getting their user informations and able to consult billing informations about what they bought. </p>&#xA;&#xA;<p>On a monolithic application, I would use this architecture :&#xA;- Presentation layer with Mobile / Angular-Ember&#xA;- Business layer with a REST API with NGINX in front of that&#xA;- DAL with a standard MySQL database&#xA;- Scalability would be applied only on X-axis</p>&#xA;&#xA;<p>I want to use a microservice architecture in this case, because it's ""domain scalable"" and really flexible (and to learn a bit more about it of course).</p>&#xA;&#xA;<p>On the schema, in each service, there is the only HTTP URL exposed by the API concerned.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<p><strong>a/</strong> In the (1) flux, ""mobile"" send an http request on <a href=""http://myDomain.or/auth"" rel=""noreferrer"">http://myDomain.or/auth</a>.</p>&#xA;&#xA;<p>In my mind, the APIGateway is able to ask a standard Service Registry (Eureka, ZooKeeper, or something else) is able to find if a AuthSrv is accessible and can retrieve his network adress. Then the ApiGateway can request the AuthSrv and respond to the server</p>&#xA;&#xA;<p>Is that a good way to make it work ? Isn't there a latency problem when dealing with X machines to access a data ?</p>&#xA;&#xA;<p><strong>b/</strong> The flux (2) consults the service registry. How can the service registry understand that every requests on /auth, even on children url like /auth/other (if it was exposed) are related to this service on this address ip:port ?</p>&#xA;&#xA;<p><strong>c/</strong> The flux (3) is showing that the service registry has an available AuthSrv. The (3 bis) show the other : no AuthSrv is available. In a little application, we can admit that we lose sometime of disponibility, but in a big system, where hundred of services are linked, how can we handle service defficience ?</p>&#xA;&#xA;<p><strong>d/</strong> In an other post, I was asking how to store a billing information because it's related to a user, from another service, and another database.</p>&#xA;&#xA;<p>In a standard architecture I would have : </p>&#xA;&#xA;<pre><code>{&#xA;   billingInformations:{...},&#xA;   billingUser:ObjectId(""userId"")&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In a microservice architecture, somebody recommended to use :</p>&#xA;&#xA;<pre><code>{&#xA;    billingInformations:{...},&#xA;    billingUser:""/user/12365"" // URL corresponding the the user Ressource in the other service&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Is this the best way to handle ""service data sharing"" and not couple the services ?</p>&#xA;&#xA;<p><strong>e/</strong> When should I prefer using AMQP protocol instead of HTTP protocol in this specific case ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
29761872,Microservices and database joins,2015-04-21 02:34:10,<database><integration><microservices>,5,10558,2,18.0,55,"<p>For people that are splitting up monolithic applications into microservices how are you handling the connundrum of breaking apart the database.  Typical applications that I've worked on do a lot of database integration for performance and simplicity reasons.</p>&#xA;&#xA;<p>If you have two tables that are logically distinct (bounded contexts if you will) but you often do aggregate processing on a large volumes of that data then in the monolith you're more than likely to eschew object orientation and are instead using your database's standard JOIN feature to process the data on the database prior to return the aggregated view back to your app tier.</p>&#xA;&#xA;<p>How do you justify splitting up such data into microservices where presumably you will be required to 'join' the data through an API rather than at the database.</p>&#xA;&#xA;<p>I've read Sam Newman's Microservices book and in the chapter on splitting the Monolith he gives an example of ""Breaking Foreign Key Relationships"" where he acknowledges that doing a join across an API is going to be slower - but he goes on to say if your application is fast enough anyway, does it matter that it is slower than before?</p>&#xA;&#xA;<p>This seems a bit glib?  What are people's experiences?  What techniques did you use to make the API joins perform acceptably?</p>&#xA;"
29644916,Microservice Authentication strategy,2015-04-15 08:10:33,<authentication><architecture><microservices>,4,35930,7,47.0,92,"<p>I'm having a hard time choosing a decent/secure authentication strategy for a microservice architecture. The only SO post I found on the topic is this one: <a href=""https://stackoverflow.com/questions/25595492/single-sign-on-in-micro-service-architecture"">Single Sign-On in Microservice Architecture</a></p>&#xA;&#xA;<p>My idea here is to have in each service (eg. authentication, messaging, notification, profile etc.) a unique reference to each user (quite logically then his <code>user_id</code>) and the possibility to get the current user's <code>id</code> if logged in.</p>&#xA;&#xA;<p>From my researches, I see there are two possible strategies:</p>&#xA;&#xA;<h3>1. Shared architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/po7Qr.png"" alt=""Shared architecture""></p>&#xA;&#xA;<p>In this strategy, the authentication app is one service among other. But each service must be able to make the conversion <code>session_id</code> => <code>user_id</code> so it must be dead simple. That's why I thought of Redis, that would store the key:value <code>session_id:user_id</code>.</p>&#xA;&#xA;<h3>2. Firewall architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/NHGjh.png"" alt=""Firewall architecture""></p>&#xA;&#xA;<p>In this strategy, session storage doesn't really matter, as it is only handled by the authenticating app. Then the <code>user_id</code> can be forwarded to other services. I thought of Rails + Devise (+ Redis or mem-cached, or cookie storage, etc.) but there are tons of possibilities. The only thing that matter is that Service X will never need to authenticate the user.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How do those two solutions compare in terms of:</p>&#xA;&#xA;<ul>&#xA;<li>security</li>&#xA;<li>robustness</li>&#xA;<li>scalability</li>&#xA;<li>ease of use</li>&#xA;</ul>&#xA;&#xA;<p>Or maybe you would suggest another solution I haven't mentioned in here?</p>&#xA;&#xA;<p>I like the solution #1 better but haven't found much default implementation that would secure me in the fact that I'm going in the right direction.</p>&#xA;&#xA;<p>I hope my question doesn't get closed. I don't really know where else to ask it.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
44241320,Deploy Service Fabric app on Windows 10,2017-05-29 11:23:01,<microservices><azure-service-fabric><service-fabric-stateful>,1,97,0,0.0,-4,<p>Is it possible to run a release/production version of Service Fabric application on a Windows 10 machine?</p>&#xA;
44579396,In microservices should i use pub/sub instead RPC to get more loosely couple architecture?,2017-06-16 01:24:56,<architecture><rpc><publish-subscribe><microservices>,2,1806,0,2.0,9,"<p>I current using a RPC call to another microservice via TCP and getting the response, but I think I can do it in this way:</p>&#xA;&#xA;<p>whithout make a RPC call, can I use a pub/sub to send to one service, publishing some channel like <em>request_user</em> and subscribed to a channel like  <em>object_user_response</em>, and then the other service that is subscribed to this <em>request_user</em>, publish <em>object_user_response</em>.</p>&#xA;&#xA;<p>Like that:</p>&#xA;&#xA;<pre><code>Service A &lt;-- (sub)object_user_response &lt;------  Redis&#xA;Service A --&gt; (pub)request_user -------------&gt;   Redis&#xA;&#xA;Service B &lt;-- (sub)request_user &lt;--------------- Redis&#xA;Service B --&gt; (pub) object_user_response ------&gt; Redis&#xA;</code></pre>&#xA;&#xA;<p>On receive a object_user_response, the service A checks if the id of user is the same that the function have requested. </p>&#xA;&#xA;<p>Should I use RPC or Pub/sub for that?&#xA;What is the most correct way to send data to a microservice and get response from there in terms of loosely coupled architecture, is using a RPC call or using two pub/sub, on for the request and another for the response?  </p>&#xA;"
44458709,My micro-service does not start and throws an error,2017-06-09 13:09:51,<spring-boot><spring-cloud><microservices>,2,320,0,0.0,-3,<p>I use springcloud+springboot+hibernate:</p>&#xA;&#xA;<pre><code>Caused by: java.lang.VerifyError: class io.netty.channel.nio.NioEventLoop overrides final method pendingTasks.()I&#xA;    at java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.8.0_111]&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763) ~[na:1.8.0_111]&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.8.0_111]&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) ~[na:1.8.0_111]&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73) ~[na:1.8.0_111]&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368) ~[na:1.8.0_111]&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362) ~[na:1.8.0_111]&#xA;    at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_111]&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361) ~[na:1.8.0_111]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_111]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_111]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_111]&#xA;    at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:94) ~[netty-transport-4.0.37.Final.jar:4.0.37.Final]&#xA;    at io.netty.util.concurrent.MultithreadEventExecutorGroup.&lt;init&gt;(MultithreadEventExecutorGroup.java:64) ~[netty-common-4.0.27.Final.jar:4.0.27.Final]&#xA;    at io.netty.channel.MultithreadEventLoopGroup.&lt;init&gt;(MultithreadEventLoopGroup.java:49) ~[netty-transport-4.0.37.Final.jar:4.0.37.Final]&#xA;    at io.netty.channel.nio.NioEventLoopGroup.&lt;init&gt;(NioEventLoopGroup.java:68) ~[netty-transport-4.0.37.Final.jar:4.0.37.Final]&#xA;    at io.netty.channel.nio.NioEventLoopGroup.&lt;init&gt;(NioEventLoopGroup.java:63) ~[netty-transport-4.0.37.Final.jar:4.0.37.Final]&#xA;    at io.netty.channel.nio.NioEventLoopGroup.&lt;init&gt;(NioEventLoopGroup.java:54) ~[netty-transport-4.0.37.Final.jar:4.0.37.Final]&#xA;    at com.datastax.driver.core.NettyUtil.newEventLoopGroupInstance(NettyUtil.java:139) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.NettyOptions.eventLoopGroup(NettyOptions.java:99) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Connection$Factory.&lt;init&gt;(Connection.java:769) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1410) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Cluster.init(Cluster.java:159) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Cluster.connectAsync(Cluster.java:330) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Cluster.connectAsync(Cluster.java:305) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at com.datastax.driver.core.Cluster.connect(Cluster.java:247) ~[cassandra-driver-core-3.1.4.jar:na]&#xA;    at org.springframework.cassandra.config.CassandraCqlSessionFactoryBean.connect(CassandraCqlSessionFactoryBean.java:100) ~[spring-cql-1.5.1.RELEASE.jar:na]&#xA;    at org.springframework.cassandra.config.CassandraCqlSessionFactoryBean.afterPropertiesSet(CassandraCqlSessionFactoryBean.java:94) ~[spring-cql-1.5.1.RELEASE.jar:na]&#xA;    at org.springframework.data.cassandra.config.CassandraSessionFactoryBean.afterPropertiesSet(CassandraSessionFactoryBean.java:103) ~[spring-data-cassandra-1.5.1.RELEASE.jar:na]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1687) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1624) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE]&#xA;    ... 73 common frames omitted&#xA;</code></pre>&#xA;
44503237,Microservices - Security Implementation,2017-06-12 15:28:51,<java><spring-boot><microservices><api-gateway>,2,141,0,1.0,-3,<p>Is it better to handle security at a microservice level or at api-gateway level in microservice deployments? Are there scenarios where one would be more apt than the other?</p>&#xA;
51726515,Which one is synchronous or asynchronous communication ? And Why?,2018-08-07 12:12:18,<web-services><asynchronous><web><microservices><synchronous>,2,34,0,0.0,-4,<p>I am confuse about both communication for the given scenario.I feel that every single list item can be synchronous communication. </p>&#xA;&#xA;<ul>&#xA;<li><p>Order service calling the shipping service to proceed for shipment.</p>&#xA;&#xA;<ul>&#xA;<li>User buying items from User Interface(UI) Service resulting in&#xA;invocation of Order Service.</li>&#xA;<li>User Interface(UI) service calling catalog service to get information&#xA;about all of the items that it needs to render.</li>&#xA;</ul></li>&#xA;</ul>&#xA;
42096392,Is it possible to combine different language in one application?,2017-02-07 17:38:09,<java><php><node.js><microservices>,1,46,5,0.0,-3,"<p>first of all, i dont want to make things a bit ambiguous.</p>&#xA;&#xA;<p>is it possible to to use different language such node.js, php for developing a Web service?</p>&#xA;&#xA;<p>for instance the node.js will be responsible for user authentication and PHP and responsible messaging .&#xA;mainly the idea of the app will be in Microservice architecture.&#xA;The Node.js will have the authentication service&#xA;and the PHP will have the messaging service.&#xA;is that a good idea&#xA;because i am learning microservices architecure and i got the user authentication and i was thinking of use PHP to complete the rest of my project.&#xA;Obviously they will have a different DB.&#xA;thanks in advance</p>&#xA;"
36701111,Communication between two microservices,2016-04-18 17:58:51,<java><spring><spring-boot><jhipster><microservices>,4,13403,5,9.0,29,"<p>I am creating a project with microservices architecture. And I created two microservices.</p>&#xA;&#xA;<p>One of them is for product entity, the other is for bill entity. They have their own endpoints and they are connected together with the gateway (i am using jhipster microservices architecture). </p>&#xA;&#xA;<p>The bill-ms should access to list of products. I'm wondering how I can communicate between those two ms. I have three approaches in my mind:</p>&#xA;&#xA;<ol>&#xA;<li><p>Send a request from bill-ms to queue - like rabbitMQ, to get these products with these ids from product-ms (I don't know what is bottleneck of this)</p></li>&#xA;<li><p>Send a request to gateway for product service and get the product from there (I'm worried about the latency because of the data size between them and in this way I'm not touching the database directly so I always depend on the gateway)</p></li>&#xA;<li><p>I can duplicate the repositories, services and entities in bill-ms (it's an ugly way, and I think it breaks the rule of ms-architecture and the maintenance is very difficult)</p></li>&#xA;</ol>&#xA;&#xA;<p>If you have any other approaches, I appreciate you to share it with me.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<ol>&#xA;<li>Now I know what the bottleneck is: say that there are 3 instance of bill-ms and how does rabbitMQ decide which instance to respond? or how should I say to ribbon ""<strong>give me the free instance of bill-ms to subscribe to the request from rabbitMQ</strong>"" for load balancing.</li>&#xA;</ol>&#xA;"
42648060,Unauthorized in spring boot admin,2017-03-07 12:15:20,<spring><spring-boot><microservices><netflix-eureka><spring-boot-admin>,2,11214,0,3.0,11,"<p>I wanted to control the microservices that are running in the Eureka server. I used spring-boot-admin for this, but I am getting the error on accessing the information about the Trace,Log etc...</p>&#xA;&#xA;<p>The error I am getting is </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: {""timestamp"":1489052472862,""status"":401,""error"":""Unauthorized"",""message"":""Full authentication is required to access this resource."",""path"":""/metrics""}</p>&#xA;</blockquote>&#xA;&#xA;<p>My dependencies are</p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>and none of the below properties worked</p>&#xA;&#xA;<pre><code>endpoints.info.id=information&#xA;endpoints.info.sensitive=false&#xA;endpoints.info.enabled=true&#xA;information.app.name=Actuator Example&#xA;information.app.description=Actuator Example&#xA;information.app.version=1.0.0&#xA;</code></pre>&#xA;&#xA;<p>and the same thing is happening with all the end points like mappings, env and all accept health</p>&#xA;"
51017164,Go local packages and modules,2018-06-25 06:04:20,<go><import><package><microservices>,2,77,0,0.0,-3,"<p>I have just started learning GO development, read a lot of articles and documentation, however haven't found a concrete answer. </p>&#xA;&#xA;<p>There are some questions </p>&#xA;&#xA;<ol>&#xA;<li>How to use local packages? Using <code>./../</code> doesn't work, I can put all my source code under <code>vendror/src</code> directory, but it makes my project structure  to look not like I want</li>&#xA;<li>Should I always upload somewhere in remote repository my packages? Is it possible to keep them local. Event if I develop a microservice, a microservice itself is a monolith application. And I don't want my microservice to have a single file. I want to split logic between several files.</li>&#xA;<li>Is it fine to keep all files in a single file? </li>&#xA;</ol>&#xA;&#xA;<p>I know that this question has been already asked several times, however I haven't found any complete answer.</p>&#xA;&#xA;<p>I would be grateful for any help. Thanks</p>&#xA;"
50986816,How to handle HTTP requests in a Microservice / Event Driven Architecture?,2018-06-22 11:20:06,<node.js><rest><websocket><apache-kafka><microservices>,6,455,1,8.0,16,"<p><strong>Background:</strong></p>&#xA;&#xA;<p>I am building an application and the proposed architecture is Event/Message Driven on a microservice architecture. </p>&#xA;&#xA;<p>The monolithic way of doing thing is that I've a <code>User/HTTP request</code> and that actions some commands that have a direct <code>synchronous response</code>. Thus, to respond to the same User/HTTP request is 'hassle free'.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rP5nf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rP5nf.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The problem:</strong></p>&#xA;&#xA;<p>The user sends an <code>HTTP request</code> to the <strong>UI Service</strong> (there are multiple UI Services) that fires some events to a queue (Kafka/RabbitMQ/any). a N of services picks up that Event/Message do some magic along the way and <strong>then at some point that same UI Service should pick that up a response and give that back to the user that originated HTTP request.</strong> Request processing is <code>ASYNC</code> but the <code>User/HTTP REQUEST-&gt;RESPONSE</code> is <code>SYNC</code> as per your typical HTTP interaction.</p>&#xA;&#xA;<p><strong>Question:</strong>&#xA;How do I send a response to the same UI Service that originated the action (The service thats interacting with the user over HTTP) in this Agnostic/Event driven world?</p>&#xA;&#xA;<p><strong>My research so far</strong> &#xA;I've been looking around and it seems that some people are solving that problem using WebSockets.</p>&#xA;&#xA;<p>But the layer of complexity is that there needs to be some table that maps <code>(RequestId-&gt;Websocket(Client-Server))</code> which is used to â€˜discoverâ€™ which node in the gateway has the websocket connection for some particular response. But even if I understand the problem and complexity I'm stuck that I can't find any articles that would give me info on how to solve this problem at the implementation layer. <strong>AND</strong> this still is not a viable option because of 3rd party integrations such as payments providers(WorldPay) that expect <code>REQUEST-&gt;RESPONSE</code> - specially on the 3DS validation.</p>&#xA;&#xA;<p>So I am somehow reluctant to think that WebSockets is an option. But even if WebSockets are ok for Webfacing apps, for API that connects to external systems is not a great architecture.</p>&#xA;&#xA;<p>** ** ** <strong>Update:</strong> ** ** ** </p>&#xA;&#xA;<p>Even if long polling is an possible solution for a WebService API with a <code>202 Accepted</code> a <code>Location header</code> and a <code>retry-after header</code> it wouldn't be performant for a high concurrency &amp; high ability website. &#xA;Imagine a huge number of people trying to get the transaction status update on EVERY request they make and you have to invalidate CDN cache (go and play with that problem now! ha).</p>&#xA;&#xA;<p>But most important and relatable to my case I've 3rd party APIs such as payment systems where the 3DS systems have automatic redirects that are handled by the payment provider system and they expect a typical <code>REQUEST/RESPONSE flow</code>, thus this model would not work for me nor the sockets model would work. </p>&#xA;&#xA;<p>Because of this use-case the <code>HTTP REQUEST/RESPONSE</code> should be handled in the typical fashion where i have a dumb client that expect that the complexity of the precessing is handled in back-end.</p>&#xA;&#xA;<p><strong>So i am looking for a solution where externally I have a typical <code>Request-&gt;Response</code>(SYNC) and the complexity of the status(ASYNCrony of the system) is handled internally</strong> </p>&#xA;&#xA;<p>An example of the long polling, but this model wouldn't work for 3rd party API such as payments provider on <code>3DS Redirects</code> that are not within my control.</p>&#xA;&#xA;<pre><code> POST /user&#xA;    Payload {userdata}&#xA;    RETURNs: &#xA;        HTTP/1.1 202 Accepted&#xA;        Content-Type: application/json; charset=utf-8&#xA;        Date: Mon, 27 Nov 2018 17:25:55 GMT&#xA;        Location: https://mydomain/user/transaction/status/:transaction_id&#xA;        Retry-After: 10&#xA;&#xA;GET &#xA;   https://mydomain/user/transaction/status/:transaction_id&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rznNC.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rznNC.png"" alt=""enter image description here""></a></p>&#xA;"
38071714,GraphQL and Microservice Architecture,2016-06-28 09:04:42,<architecture><microservices><graphql>,5,14892,0,48.0,86,"<p>I'm trying to understand where GraphQL is most suitable to use within a Microservice architecture. </p>&#xA;&#xA;<p>There is some debate about having only 1 GraphQL schema that works as API Gateway proxying the request to the targeted microservices and coercing their response. Microservices still would use REST / Thrift protocol for communication thought.</p>&#xA;&#xA;<p>Another approach is instead to have multiple GraphQL schemas one per microservice. Having a smaller API Gateway server that route the request to the targeted microservice with all the information of the request + the GraphQL query.</p>&#xA;&#xA;<p><strong>1st Approach</strong></p>&#xA;&#xA;<p>Having 1 GraphQL Schema as an API Gateway will have a downside where every time you change your microservice contract input/output, we have to change the GraphQL Schema accordingly on the API Gateway Side.</p>&#xA;&#xA;<p><strong>2nd Approach</strong></p>&#xA;&#xA;<p>If using Multiple GraphQL Schema per microservices, make sense in a way because GraphQL enforces a schema definition, and the consumer will need to respect input/output given from the microservice.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>Where do you find GraphQL the right fit for designing microservice architecture? </p></li>&#xA;<li><p>How would you design an API Gateway with a possible GraphQL implementation?</p></li>&#xA;</ul>&#xA;"
37180375,Using Zuul as an authentication gateway,2016-05-12 07:42:05,<spring-boot><spring-cloud><microservices><gateway><netflix-zuul>,3,14024,3,14.0,18,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I want to implement the design presented in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""noreferrer"">article</a>.</p>&#xA;&#xA;<p>It can be summarised by the diagram below:&#xA;<a href=""https://i.stack.imgur.com/viaL4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viaL4.png"" alt=""Security Architecture""></a></p>&#xA;&#xA;<ol>&#xA;<li>The client first authenticate with the IDP (OpenID Connect/OAuth2)</li>&#xA;<li>The IDP returns an access token (opaque token with no user info)</li>&#xA;<li>The client makes a call through the API gateway use the access token in the Authorization header</li>&#xA;<li>The API gateway makes a request to the IDP with the Access Token</li>&#xA;<li>The IDP verifies that the Access Token is valid and returns user information in JSON format</li>&#xA;<li>The API Gateway store the user information in a JWT and sign it with a private key. The JWT is then passed to the downstream service which verifies the JWT using the public key</li>&#xA;<li>If a service must call another service to fulfil the request it passes the JWT along which serves as authentication and authorisation for the request</li>&#xA;</ol>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have most of that done using:</p>&#xA;&#xA;<ul>&#xA;<li>Spring cloud as a global framework</li>&#xA;<li>Spring boot to launch individual services</li>&#xA;<li>Netflix Zuul as the API gateway</li>&#xA;</ul>&#xA;&#xA;<p>I have also written a Zuul PRE filter that checks for an Access Token, contacts the IDP and create a JWT. The JWT is then added to the header for the request forwarded to the downstream service.</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>Now my question is quite specific to Zuul and its filters. If authentication fails in the API gateway for any reason, how can I can stop the routing and respond directly with a 401 without continuing the filter chain and forwarding the call?</p>&#xA;&#xA;<p>At the moment if authentication fails the filter won't add the JWT to the header and the 401 will come from the downstream service. I was hoping my gateway could prevent this unnecessary call.</p>&#xA;&#xA;<p>I tried to see how I could use <code>com.netflix.zuul.context.RequestContext</code>to do this but the documentation is quite poor and I couldn't find a way. </p>&#xA;"
44195150,How can we keep an java application running forever,2017-05-26 06:37:24,<java><web-services><microservices>,2,72,4,0.0,-4,"<p>I want to write an java application, which should be running forever. &#xA;Webservice is a way to do so, but i don't want to run it as webservice. &#xA;I just want to run some threads inside application running forever, I don't want to process any webRequest as such.</p>&#xA;&#xA;<p>Can you please tell what are other ways to do so ?</p>&#xA;"
38633023,What are the disadvantages of Spring Boot for Java web applications?,2016-07-28 09:57:24,<java><spring><spring-boot><microservices>,1,8337,2,1.0,19,"<p>[This needs to be voted to be reopened to answer.]</p>&#xA;&#xA;<p>Spring boot is tipped as being the default go to when making a new spring application as it makes set up easier and automatically wires in common dependencies. </p>&#xA;&#xA;<p>I am yet in industry to see spring-boot used in the manner advertised.</p>&#xA;&#xA;<p>Factually and concisely, what are the disadvantages that are faced by developers on adoption of Spring boot as the de facto Spring go to?</p>&#xA;&#xA;<p>The advantages of Spring Boot <a href=""https://stackoverflow.com/questions/28831479/advantage-of-spring-boot"">question</a> shows advantages of which I agree there are many, but believe there should be a rounder view. </p>&#xA;&#xA;<p>An example non opinion based point would be:</p>&#xA;&#xA;<ul>&#xA;<li><p>Spring boot may unnecessarily increase the deployment binary size with unused dependencies.</p></li>&#xA;<li><p>Not being able to customize logging easily as shown <a href=""https://stackoverflow.com/questions/29609996/spring-boot-loggingapplicationlistener-interfering-with-application-server-logg"">here</a>.</p></li>&#xA;</ul>&#xA;"
43950808,Data Consistency Across Microservices,2017-05-13 08:13:05,<design-patterns><akka><microservices><data-consistency>,5,3656,0,9.0,12,"<p>While each microservice generally will have its own data - certain entities are required to be consistent across multiple services. </p>&#xA;&#xA;<p>For such data consistency requirement in a highly distributed landscape such as microservices architecture, what are the choices for design? Of course, I do not want shared database architecture, where a single DB manages the state across all the services. That violates isolation and shared-nothing principles. </p>&#xA;&#xA;<p>I do understand that, a microservice can publish an event when an entity is created, updated or deleted. All other microservices which are interested in this event can accordingly update the linked entities in their respective databases. </p>&#xA;&#xA;<p>This is workable, however it leads to a lot of careful and coordinated programming effort across the services.</p>&#xA;&#xA;<p>Can Akka or any other framework solve this use case? How?</p>&#xA;&#xA;<p><strong>EDIT1:</strong><br/>&#xA;Adding the below diagram for clarity. &#xA;<br/>Basically, I am trying to understand, if there are available frameworks today that can solve this data consistency problem. </p>&#xA;&#xA;<p>For the queue I can use any AMQP software such as RabbitMQ or Qpid etc. &#xA;For the data consistency framework, I am not sure if presently Akka or any other software can help. Or is this scenario so uncommon, and such an anti-pattern that no framework should be ever needed?<br>&#xA;<a href=""https://i.stack.imgur.com/9hIo9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9hIo9.png"" alt=""enter image description here""></a></p>&#xA;"
34903605,Microservices: what are pros and cons?,2016-01-20 15:08:36,<architecture><microservices>,2,9224,0,7.0,20,<p>What are pros and cons of using microservices in comparison with alternative architectures?&#xA;Is there a rule of thumb when microservices should be used?</p>&#xA;
31044380,Microservices authentication,2015-06-25 07:53:17,<rest><microservices>,4,3308,0,4.0,9,"<p><strong>Context</strong></p>&#xA;&#xA;<p>I have multiple services like :</p>&#xA;&#xA;<ul>&#xA;<li>User (LDAP or active directory etc...)</li>&#xA;<li>Billing</li>&#xA;<li>Planning</li>&#xA;<li>etc...</li>&#xA;<li>Authentication</li>&#xA;</ul>&#xA;&#xA;<p>I need to connect on my microservices Using OAuth2.0, for beginning, using the standard login / password (I use my own data, and not gettint a third leg server)</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>According to these pictures :</p>&#xA;&#xA;<p><em>Step 1</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/csUn0.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p><em>Step 2</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/xmohK.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p>How can I handle access_token control or authorization control, in my other services than authmicroservice ?</p>&#xA;"
31031865,How do you manage per-environment data in Docker-based microservices?,2015-06-24 16:20:31,<deployment><configuration><architecture><docker><microservices>,1,6770,1,17.0,21,"<p>In a microservice architecture, I'm having a hard time grasping how one can manage environment-specific config (e.g. IP address and credentials for database or message broker).</p>&#xA;&#xA;<p>Let's say you have three microservices (""A"", ""B"", and ""C""), each owned and maintained by a different team.  Each team is going to need a team integration environment... where they work with the latest snapshot of their microservice, along with stable versions of all dependency microservices.  Of course, you'll also need QA/staging/production environments as well.  A simplified view of the big picture would look like this:</p>&#xA;&#xA;<p><strong>""Microservice A"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice B"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice C"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (<strong>SNAPSHOT</strong>)</li>&#xA;</ul>&#xA;&#xA;<p><strong>QA / Staging / Production</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice B (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice C (STABLE, RELEASE, etc)</li>&#xA;</ul>&#xA;&#xA;<p>That's a lot of deployments, but that problem can be solved by a continuous integration server and perhaps something like Chef/Puppet/etc.  The <strong><em>really</em></strong> hard part is that each microservice would need some environment data particular to each place in which it's deployed.  </p>&#xA;&#xA;<p>For example, in the ""A"" Team Environment, ""A"" needs one address and set of credentials to interact with ""B"".  However, over in the ""B"" Team Environment, <em>that</em> deployment of ""A"" needs a different address and credentials to interact with <em>that</em> deployment of ""B"".</p>&#xA;&#xA;<p>Also, as you get closer to production, environmental config info like this probably needs security restrictions (i.e. only certain people are able to modify or even view it).</p>&#xA;&#xA;<p>So, with a microservice architecture, how to you maintain environment-specific config info and make it available to the apps?  A few approaches come to mind, although they all seem problematic:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Have the build server bake them into the application at build-time</strong> - I suppose you could create a repo of per-environment properties files or scripts, and have the build process for each microservice reach out and pull in the appropriate script (you could also have a separate, limited-access repo for the production stuff).  You would need a <em>ton</em> of scripts, though.  Basically a separate one for every microservice in every place that microservice can be deployed.</li>&#xA;<li><strong>Bake them into base Docker images for each environment</strong> - If the build server is putting your microservice applications into Docker containers as the last step of the build process, then you could create custom base images for each environment.  The base image would contain a shell script that sets all of the environment variables you need.  Your Dockerfile would be set to invoke this script prior to starting your application.  This has similar challenges to the previous bullet-point, in that now you're managing a ton of Docker images.</li>&#xA;<li><strong>Pull in the environment info at runtime from some sort of registry</strong> - Lastly, you could store your per-environment config inside something like Apache ZooKeeper (or even just a plain ol' database), and have your application code pull it in at runtime when it starts up.  Each microservice application would need a way of telling which environment it's in (e.g. a startup parameter), so that it knows which set of variable to grab from the registry.  The advantage of this approach is that now you can use the <em>exact</em> same build artifact (i.e. application or Docker container) all the way from the team environment up to production.  On the other hand, you would now have another runtime dependency, and you'd still have to manage all of that data in your registry anyway.</li>&#xA;</ul>&#xA;&#xA;<p>How do people commonly address this issue in a microservice architecture?  It seems like this would be a common thing to hear about.</p>&#xA;"
31104540,DB consistency with microservices,2015-06-28 20:42:03,<database><soa><microservices>,4,4038,1,10.0,29,"<p>What is the best way to achieve DB consistency in microservice-based systems?</p>&#xA;&#xA;<p>At the <a href=""https://www.youtube.com/watch?v=wgdBVIX9ifA"" rel=""noreferrer"">GOTO in Berlin</a>, Martin Fowler was talking about microservices and one ""rule"" he mentioned was to keep ""per-service"" databases, which means that services cannot directly connect to a DB ""owned"" by another service.</p>&#xA;&#xA;<p>This is super-nice and elegant but in practice it becomes a bit tricky. Suppose that you have a few services:</p>&#xA;&#xA;<ul>&#xA;<li>a frontend</li>&#xA;<li>an order-management service</li>&#xA;<li>a loyalty-program service</li>&#xA;</ul>&#xA;&#xA;<p>Now, a customer make a purchase on your frontend, which will call the order management service, which will save everything in the DB -- no problem. At this point, there will also be a call to the loyalty-program service so that it credits / debits points from your account.</p>&#xA;&#xA;<p>Now, when everything is on the same DB / DB server it all becomes easy since you can run everything in one transaction: if the loyalty program service fails to write to the DB we can roll the whole thing back.</p>&#xA;&#xA;<p>When we do DB operations throughout multiple services this isn't possible, as we don't rely on one connection / take advantage of running a single transaction.&#xA;What are the best patterns to keep things consistent and live a happy life?</p>&#xA;&#xA;<p>I'm quite eager to hear your suggestions!..and thanks in advance!</p>&#xA;"
41731704,Use docker-compose with multiple repositories,2017-01-19 00:16:29,<docker><docker-compose><microservices>,1,3197,0,1.0,11,"<p>I'm currently struggling with the deployment of my services and I wanted to ask, what's the proper way when you have to deal with multiple repositories. The repositories are independent, but to run in production, everything needs to be launched.</p>&#xA;&#xA;<p>My Setup:</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Backend:&#xA;&#xA;<ul>&#xA;<li>Backend Project Rails</li>&#xA;<li>docker-compose: backend(expose 3000), db and redis</li>&#xA;</ul></li>&#xA;<li>Git Repository Frontend&#xA;&#xA;<ul>&#xA;<li>Express.js server</li>&#xA;<li>docker-compose: (expose 4200)</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>Both can be run independently and test can be executed by CI</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Nginx for Production&#xA;&#xA;<ul>&#xA;<li>Needs to connect to the other two services (same docker network)</li>&#xA;<li>forwards requests to the right service</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I have already tried to include the two services as submodules into the Nginx repository and use the docker-compose of the nginx repo, but I'm not really happy with it.  </p>&#xA;"
41795612,How to deploy microservices on Heroku,2017-01-22 20:09:47,<heroku><architecture><jhipster><microservices>,1,3183,1,4.0,11,"<p>I have read a lot about microservices, and would like to build my app with that approach. What I know so far is that I nead some services like:</p>&#xA;&#xA;<ul>&#xA;<li><strong>load balancer</strong> - to deal with every request, and push it forward to another services</li>&#xA;<li><strong>authorization service</strong> - to authorize my users</li>&#xA;<li><strong>database</strong> - for my microservices. I would like to use one instance of DB with different schemas for every service.</li>&#xA;<li><strong>service A</strong> - for functionality A</li>&#xA;<li><p><strong>service B</strong> - for functionality B</p></li>&#xA;<li><p>etc. etc. etc.</p></li>&#xA;</ul>&#xA;&#xA;<p>I found out, that Heroku is interesting place to deploy applications. My problem is that I completely don't understand they ideology. What I have done so far, is creation/registration of few ""apps"":</p>&#xA;&#xA;<ul>&#xA;<li>my-app-auth</li>&#xA;<li>my-app-load-balancer</li>&#xA;<li>etc. etc.</li>&#xA;</ul>&#xA;&#xA;<p>I see, that Heroku gives me some public hostname for every of that app, and this is where my concerns starts. Should I deploy my internal services with public hostnames? I don't think so. And here my question comes:</p>&#xA;&#xA;<p>Can anyone provide me some guidelines, how to deal with microservices on Heroku? How should i deploy them? How should I define my load balancer, and hook internal services to it? What is JHipster? Do I need it? How can I use it? Should I use Heroku tools (for example CLI) or can I stay with my gitlab repo? I can't find any point of grasp on the Internet, about that.</p>&#xA;"
35756663,API gateway vs. reverse proxy,2016-03-02 19:44:32,<nginx><reverse-proxy><microservices><aws-api-gateway><tyk>,2,17931,0,23.0,47,"<p>In order to deal with the microservice architecture, it's often used alongside a Reverse Proxy (such as nginx or apache httpd) and for cross cutting concerns implementation  <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">API gateway pattern is used</a>. Sometimes Reverse proxy does the work of API gateway. <br>&#xA;It will be good to see clear differences between these two approaches.&#xA;It looks like the potential benefit of API gateway usage is invoking multiple microservices and aggregating the results. All other <a href=""https://auth0.com/blog/2015/09/13/an-introduction-to-microservices-part-2-API-gateway/"" rel=""noreferrer"">responsibilities</a> of API gateway can be implemented using Reverse Proxy.Such as:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication (It can be done using nginx LUA scripts);</li>&#xA;<li>Transport security. It itself Reverse Proxy task;</li>&#xA;<li>Load balancing</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>So based on this there are several questions:</p>&#xA;&#xA;<ol>&#xA;<li>Does it make sense to use API gateway and Reverse proxy simultaniously (as example request->Api gateway-> reverse proxy(nginx)-> concrete mictoservice)? In what cases ?</li>&#xA;<li>What the other differences that can be implemented using API gateway and can't be implemented by Reverse proxy and vice versa ?</li>&#xA;</ol>&#xA;"
51541318,How do I resolve the authors names of books in microservice world?,2018-07-26 14:30:41,<node.js><amazon-web-services><aws-lambda><microservices>,4,165,1,1.0,11,"<p>So I'm starting a journey down the road of microservices. I've spent some hours online trying immerse myself into this topic. </p>&#xA;&#xA;<p>One concept I'm not quite grasping yet is the idea of <strong>not using SQL joins</strong> and therefore having a small independent database for authors and the same for books.</p>&#xA;&#xA;<p>So I understand the following SQL:</p>&#xA;&#xA;<pre><code>BooksTable - id, name, authorid&#xA;AuthorsTable - id, name&#xA;&#xA;select book.name, author.name from book &#xA;join author on book.authorId = author.id&#xA;</code></pre>&#xA;&#xA;<p>In Node.js world</p>&#xA;&#xA;<p><strong>index.js</strong></p>&#xA;&#xA;<pre><code>app.get('/api/books' bookDomain.get());&#xA;</code></pre>&#xA;&#xA;<p><strong>bookDomain.js</strong></p>&#xA;&#xA;<pre><code>exports.get = () =&gt; {&#xA;  const books = bookService.get();&#xA;&#xA;  const authors = authorService.get();&#xA;&#xA;  /*&#xA;    This is where I'm lost: how do you achieve the simple SQL &#xA;    above? I'm assuming in the domain is where this information is &#xA;    ""joined""? am I correct?&#xA;  */&#xA;};&#xA;</code></pre>&#xA;&#xA;<p><strong>Services</strong></p>&#xA;&#xA;<pre><code>Database1&#xA;**bookService.js**&#xA;database context&#xA;&#xA;Database2&#xA;**authorService.js**&#xA;database context&#xA;</code></pre>&#xA;&#xA;<p><strong>expected data</strong> (something like it, basically i'm saying JSON should be the return type)</p>&#xA;&#xA;<pre><code>[{&#xA;  book {&#xA;    ""name"": ""Book 1"",&#xA;    ""author"": ""Author Name 1""&#xA;  }&#xA;},&#xA;{&#xA;  book {&#xA;    ""name"": ""Book 2"",&#xA;    ""author"": ""Author Name 2""&#xA;  }&#xA;}]&#xA;</code></pre>&#xA;"
42487685,How to inject module from different app in Node.js,2017-02-27 14:02:36,<javascript><node.js><express><amd><microservices>,4,434,3,4.0,9,"<p>I've two node apps/services that are running together, &#xA;1. main app&#xA;2. second app</p>&#xA;&#xA;<p>The main app is responsible to show all the data from diffrent apps at the end. Now I put some code of the second app in the main app and now its working, but I want it to be decoupled. I mean that the code of the secnod app will not be in the main app (by somehow to inject it on runtime )</p>&#xA;&#xA;<p>like the second service is registered to the main app in inject the code of it.&#xA;the code of it is just two modules ,is it possible to do it in nodejs ?</p>&#xA;&#xA;<pre><code>const Socket = require('socket.io-client');&#xA;const client = require(""./config.json"");&#xA;&#xA;module.exports =  (serviceRegistry, wsSocket) =&gt;{&#xA;    var ws = null;&#xA;    var consumer = () =&gt; {&#xA;        var registration = serviceRegistry.get(""tweets"");&#xA;        console.log(""Service: "" + registration);&#xA;        //Check if service is online&#xA;        if (registration === null) {&#xA;            if (ws != null) {&#xA;                ws.close();&#xA;                ws = null;&#xA;                console.log(""Closed websocket"");&#xA;            }&#xA;            return&#xA;        }&#xA;        var clientName = `ws://localhost:${registration.port}/`&#xA;        if (client.hosted) {&#xA;            clientName = `ws://${client.client}/`;&#xA;        }&#xA;        //Create a websocket to communicate with the client&#xA;        if (ws == null) {&#xA;            console.log(""Created"");&#xA;            ws = Socket(clientName, {&#xA;                reconnect: false&#xA;            });&#xA;            ws.on('connect', () =&gt; {&#xA;                console.log(""second service is connected"");&#xA;            });&#xA;            ws.on('tweet', function (data) {&#xA;                wsSocket.emit('tweet', data);&#xA;            });&#xA;            ws.on('disconnect', () =&gt; {&#xA;                console.log(""Disconnected from blog-twitter"")&#xA;            });&#xA;            ws.on('error', (err) =&gt; {&#xA;                console.log(""Error connecting socket: "" + err);&#xA;            });&#xA;        }&#xA;    }&#xA;    //Check service availability&#xA;    setInterval(consumer, 20 * 1000);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In the main module I put this code and I want to decouple it by inject it somehow on runtime ? example will be very helpful ... </p>&#xA;"
49561411,How to create a new microservice spring?,2018-03-29 16:54:28,<spring><spring-boot><microservices>,1,33,2,0.0,-3,<p>I'm using Intellij IDE Ultimate and I create a Project with spring inicializer. The problem is... now I need create more microservices (Spring Boot) but idk how to do this in IDE. I the end I need 3 microservices. Have a terminal command to create a new microservice inside my project? Or a way in the IDE to do this.</p>&#xA;
44870461,Microservices: how to handle foreign key relationships,2017-07-02 11:45:53,<database><microservices>,2,6194,0,11.0,26,"<p>Microservices architecture suggest that each service should handle it's own data. Hence any service (Service A) dependent on data owned by other service (service B) should access such data not by making direct DB calls but through the api provided by the second service (service B).</p>&#xA;&#xA;<p><strong>So what does microservices best practices suggest on checking foreign key constrains.</strong> </p>&#xA;&#xA;<p>Example: I am developing a delivery feature (microservice 1) for products and certain products are deliverable to only certain locations as mentioned in the products table accessible to only products micro service (mircoservice 2).</p>&#xA;&#xA;<p>How do I make sure that microservice 1 (i.e delivery feature) does not take an order to a unserviced location. I have this question because delivery feature can not directly access products database, so there is no constraints applicable at DB level when a delivery order is place in to delivery data base (no check is possible to see if a foreign key match exists in products database or table).</p>&#xA;"
48639206,How to start single Spring Boot Microservice on Multiple Ports in STS/eclipse?,2018-02-06 09:09:11,<spring><spring-boot><microservices>,1,344,3,1.0,-6,<p>How  to start single Spring Boot Microservice on Multiple Ports in STS/eclipse ?</p>&#xA;
37915326,How to keep DB in sync when using microservices architecture?,2016-06-20 05:47:00,<architecture><microservices>,3,3503,0,3.0,9,"<p>Im about to learn how microservices architecture work. So far i unserstood that each microservice need its own database, which make sense. </p>&#xA;&#xA;<p>So lets say we have a customer microservice which is responsible for creating a customer and returning a list of customers. The service will ofcource have it own customer DB. </p>&#xA;&#xA;<p>Lets say we have very high load on this ervice, so we chooce to scale out 20x. </p>&#xA;&#xA;<p>SÃ¥ we have 20 microservices and each have its own DB, and all the services is behind a load balancer. </p>&#xA;&#xA;<p>Now a client wants to create a customer, load balancer sends client request to service 9/20, and the customer is created. </p>&#xA;&#xA;<p>On the next request the same client wants to be sure that customer is created and want to view the list of the customers, on the request LB sends him to service 11/20. </p>&#xA;&#xA;<p>Now how do i make sure that service 9/20 synced the newly created customer to the db of service 11/20?</p>&#xA;&#xA;<p>In MSSQL there are functionality to keep DB in sync by before alowing the initial commit, to save the data in all the other databases first, but this approach will give problems in the long run, because the more services there are the longer time it will take to make a commit?</p>&#xA;"
37897058,"How to properly setup documentation for Restful services in a micro-service architecture (HAL, ALPS)",2016-06-18 12:39:04,<java><spring><spring-data><spring-data-rest><microservices>,2,391,1,0.0,9,"<p>I have been reading a lot about how to setup Microservices properly and I have been getting hung up with some of the more recent concepts including: HAL, ALPS, and the HAL Browser.  I have historically documented things leveraging Swagger UI, however, I am coming to understand that URL centric isn't the proper way and I should be organizing documentation around resources and links which is what the newer technologies are for.  I have quite a few knowledge gaps around these newer concepts, so I wanted to get a proper understanding of how these technologies work together so as I learn about each I can fit them into the puzzle.</p>&#xA;&#xA;<p>My current understanding is:</p>&#xA;&#xA;<p><b>HAL</b> - Is an additional format on top of JSON that will let you navigate through your API via links.</p>&#xA;&#xA;<p><b>ALPS</b> - It is an additional format on top of JSON that can let me provide English based descriptions to help describe my resources</p>&#xA;&#xA;<p><b>HAL Browser</b> - Swagger UI replacement for Resource and Link centric documentation.  Works with both HAL and ALPS together?</p>&#xA;&#xA;<p>Would my current understanding of these technologies be accurate or lacking in some areas?  Also implementation wise I am not fully understanding how the ALPS and HAL are interacting together.  I was aware of a hal+json format and a alps+json format, but I haven't seen a hal+alps+json format.</p>&#xA;&#xA;<p>The last area I would like to clear up is how I should be exposing these resources.  Typically I always had a focus on very lean json messages is sending the hal+json format around the expected or should I be hosting those endpoints at another URL specifically for documentation similar to swagger / HAL browser?</p>&#xA;"
40900818,Querying / Pagination Across Microservices,2016-12-01 00:48:57,<web-services><rest><integration><soa><microservices>,1,836,3,0.0,11,"<p>Our shop has recently started taking on an SOA approach to application development.  We are seeing some great benefits with the separation of concerns, reusability, and other benefits of SOA/microservices.</p>&#xA;&#xA;<p>However, one <strong>big</strong> item we're stuck on is aggregating, filtering, and paginating results across services.  Let me describe the issue with a scenario.</p>&#xA;&#xA;<p>Say we have 3 services:</p>&#xA;&#xA;<ol>&#xA;<li><strong>PersonService</strong> - Stores information on people (names, addresses, etc)</li>&#xA;<li><strong>ItemService</strong> - Stores information on items that are purchasable.</li>&#xA;<li><strong>PaymentService</strong> - Stores information regarding payments that people have made for different items.</li>&#xA;</ol>&#xA;&#xA;<p>Now, say we want to build a reporting/admin tool that can display / report on multiple services in aggregate.  For instance, we want to display a paginated list of Payments, along with the Person and Item that each payment was for.  This is pretty straightforward:  Grab the list of payments, then query PersonService and ItemService for the respective Person and Item records.</p>&#xA;&#xA;<p>However, the issue comes into play when we want to then filter down that data:  For instance, displaying a paginated list of payments made by people with the first name 'Bob', who have purchased the item 'Car'. This makes things much more complicated, because we need to filter results from 3 different services without knowing how many results each service is going to return.  </p>&#xA;&#xA;<p>From a performance perspective, querying all of the services over and over again to narrow down the results would be costly, so I've been researching better solutions.  However, I cannot find concrete solutions to this problem (or at least a ""best practice"").  In a monolithic application, we'd simply use SQL joins across the different tables.  I'm having a ton of trouble figuring out how/if something similar is possible across services.</p>&#xA;&#xA;<p>My question to the community is:  What would your approach be?  Things I've considered:</p>&#xA;&#xA;<ol>&#xA;<li>Using some sort of search index (<strong>Elasticsearch</strong>, <strong>Solr</strong>) that contains all data for all services (updated via events pushed out by services), and then querying the search index for results.</li>&#xA;<li>Attempting to understand how projects like <strong>GraphQL</strong> and <strong>Neo4j</strong> may assist us with these issues.</li>&#xA;</ol>&#xA;"
50111276,What are my technical requirements?,2018-05-01 04:15:34,<amazon-web-services><windows-services><microservices><windows-server-2012-r2>,1,115,0,0.0,-4,"<p>My goal is to build an application that can dynamically monitor my Stock Portfolio (Stock Options actually).  So, I am building my business logic in a TDD approach using C# on .NET core.  I haven't much thought about the interface because the following is true:</p>&#xA;&#xA;<p>1) My broker is ETrade so I will have to authenticate and use their api for my position information</p>&#xA;&#xA;<p>2) I need this application to run from 9:30 AM - 4:00 PM EST Monday - Friday</p>&#xA;&#xA;<p>As I am nearing completion of my 1st MVP business logic, I am now starting to think about where I will delpoy the final solution and hence I am seeking the community for feedback.</p>&#xA;&#xA;<p>I have heard, but not worked much with Microservices (AWS, Azure, etc.) so I'm not sure if that is the direction I want to look.  (Also, I have a tight timeline and don't want to have to learn too much to get this thing deployed - but I am open to any solution).  Excluding Microservices and the Cloud I have considered the following:</p>&#xA;&#xA;<h2>a) ""I could run the program from a Console application""?</h2>&#xA;&#xA;<p><strong>(answer)</strong> I would have to either:</p>&#xA;&#xA;<p>(a) get a dedicated server to do or </p>&#xA;&#xA;<p>(b) try to ensure that I can leave a laptop running at home or something, blah, blah</p>&#xA;&#xA;<p><strong>(conclusion)</strong> Both are plausible decisions.</p>&#xA;&#xA;<h2>b) ""I could run the program as a Windows Service""</h2>&#xA;&#xA;<p><strong>(answer)</strong> I would have to either </p>&#xA;&#xA;<p>(a) (same as above)</p>&#xA;&#xA;<p>(b) (same as above)</p>&#xA;&#xA;<p><strong>(conclusion)</strong> Both are plausible decisions.</p>&#xA;&#xA;<h2>c) ""I could run the program as a Web Site""</h2>&#xA;&#xA;<p><strong>(answer)</strong> I would have to either </p>&#xA;&#xA;<p>(a) (same as above)</p>&#xA;&#xA;<p>(b) (same as above)</p>&#xA;&#xA;<p><strong>(conclusion)</strong> Both are plausible decisions.</p>&#xA;&#xA;<h2>c) ""I could investigate The Cloud (Microservices)""</h2>&#xA;&#xA;<p><strong>(answer)</strong> ???&#xA;<strong>(conclusion)</strong> </p>&#xA;&#xA;<p>So, in closing, basically, given the requirements of up-time between those hours and I would like to be able to access the app from any internet browser.  I have logic that needs to ping various endpoints pretty much every minute during market hours.  So I am not sure how I would handle this using a Web Application because if (by chance) the browser is closed, the Web Application stops running and thus would defeat my needs!  Does the cloud help here?  Maybe I should just use a Windows Service and make my logs accessible on the web.  Or I deploy the TraderBot in a Windows Service and also build a Web Application to receive real-time intel from the TraderBot Windows Service / Logs /  and-or DB?  Not sure, but I appreciate any knee-jerk responses you all have!</p>&#xA;"
51829581,What is the purpose of using Spring cloud? What is the difference between AWS and Springcloud?,2018-08-13 19:47:24,<amazon-web-services><microservices><spring-cloud>,2,34,0,0.0,-3,<p>Why we need Spring cloud? What is the difference between AWS and Spring Cloud?</p>&#xA;
37749087,"How to restore state in an event based, message driven microservice architecture on failure scenario",2016-06-10 13:06:04,<messaging><reactive-programming><microservices><event-based-programming>,3,1771,0,7.0,12,"<p>In the context of a microservice architecture, a message driven, asynchronous, event based design seems to be gaining popularity (see <a href=""http://blog.christianposta.com/microservices/why-microservices-should-be-event-driven-autonomy-vs-authority/"" rel=""noreferrer"">here</a> and <a href=""https://www.nginx.com/blog/event-driven-data-management-microservices/"" rel=""noreferrer"">here</a> for some examples, as well as the <a href=""http://www.reactivemanifesto.org/#message-driven"" rel=""noreferrer"">Reactive Manifesto - Message Driven trait</a>) as opposed to a synchronous (possibly REST based) mechanism.</p>&#xA;&#xA;<p>Taking that context and imagining an overly simplified ordering system, as depicted below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Xtttg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Xtttg.png"" alt=""ordering system""></a></p>&#xA;&#xA;<p>and the following message flow:</p>&#xA;&#xA;<ul>&#xA;<li>Order is placed from some source (web/mobile etc.)</li>&#xA;<li>Order service accepts order and publishes a <code>CreateOrderEvent</code></li>&#xA;<li>The InventoryService reacts on the <code>CreateOrderEvent</code>, does some inventory stuff and publishes a <code>InventoryUpdatedEvent</code> when it's done</li>&#xA;<li>The Invoice service then reacts to the <code>InventoryUpdatedEvent</code>, sends an invoice and publishes a <code>EmailInvoiceEvent</code></li>&#xA;</ul>&#xA;&#xA;<p>All services are up and we happily process orders... Everyone is happy.&#xA;Then, the Inventory service goes down for some reason </p>&#xA;&#xA;<p>Assuming that the events on the event bus are flowing in a ""non blocking"" manor. I.e. the messages are being published to a central topic and do not pile up on a queue if no service is reading from it (what I'm trying to convey is an event bus where, if the event is published on the bus, it would flow ""straight through"" and not queue up - ignore what messaging platform/technology is used at this point). That would mean that if the Inventory service were down for 5 minutes, the <code>CreateOrderEvent</code>'s passing through the event bus during that time are now ""gone"" or not seen by the Inventory service because in our overly simplified system, no other system is interested in those events.</p>&#xA;&#xA;<p>My question then is: How does the Inventory service (and the system as a whole) restore state in a way that no orders are missed/not processed?</p>&#xA;"
47793065,Angular and Micro-Frontends,2017-12-13 12:29:00,<javascript><html><angular><microservices>,6,3468,5,14.0,36,"<p>I am doing some research on how to split a huge single-page-monolith into a micro-frontend architecture.</p>&#xA;&#xA;<h1>The idea:</h1>&#xA;&#xA;<ul>&#xA;<li>the page consists of several components which would be running autonomously</li>&#xA;<li>each component is managed by one dev-team</li>&#xA;<li>each team can change, update and deploy their components without breaking components of other teams</li>&#xA;<li>each team chooses its own toolstack</li>&#xA;</ul>&#xA;&#xA;<h1>The reason</h1>&#xA;&#xA;<p>To efficiently develop large applications you need to have many people working on it. However the number of developers per app/team does not scale well. Parallel development of multiple independent apps by independent teams however can be scaled arbitrarily</p>&#xA;&#xA;<p>With this in mind it is imperative that teams can choose their own toolstack and especially perform independent version-upgrades of third party-libraries (like angular, react, jquery). If this was not the case a framework-update would need to be compatible with every single component before you could deploy it to production.</p>&#xA;&#xA;<h1>Does this work with Angular?</h1>&#xA;&#xA;<p>While independent version-upgrades are necessary, it would be reasonable to restrict the teams to a few supported frameworks (Angular, React, Vue, Polymer...) and for now I try to build a demo purely consisting of Angular-Apps.</p>&#xA;&#xA;<p>However even though Angular 5 is supposedly a platform-framework which supports huge multi-module apps, it seems to be almost impossible to have several independent angular-apps running in the same browser window.</p>&#xA;&#xA;<p>I managed to bootstrap several Angular-Apps (different versions, each hosted on its own server) on a single webapp by utilizing HTML-Imports. However there are several <code>global</code> dependencies which need to be shared between apps</p>&#xA;&#xA;<ul>&#xA;<li>zone.js can only be started once</li>&#xA;<li>routing requires url-changes</li>&#xA;<li>Browser-stuff like cookies, sessionstorage, etc...</li>&#xA;</ul>&#xA;&#xA;<p>There are several articles in the net on how to bootstrap multiple angular-modules but they all refer to multiple modules in the same core-app, which in turn means they all are running on the same framework-version and an update means you have to rebuild and deploy the whole monolith.</p>&#xA;&#xA;<p><strong>Is there any solution other than ""<code>iframes</code>"" to get multiple Angular (5) Apps running on the same Page?</strong></p>&#xA;"
45208766,Microservices Why Use RabbitMQ?,2017-07-20 07:57:56,<rabbitmq><microservices>,2,5165,1,3.0,9,<p>I haven't found an existing post asking this but apologize if I missed it. </p>&#xA;&#xA;<p>I'm trying to get my head round microservices and have come across articles where RabbitMQ is used. I'm confused why RabbitMQ is needed. Is the intention that the services will use a web api to communicate with the outside world and RabbitMQ to communicate with each other?</p>&#xA;
40448015,Microservices Architecture in NodeJS,2016-11-06 09:54:11,<node.js><microservices>,2,3310,3,8.0,12,"<p>I was working on a side project and i deiced to redesign my Skelton project to be as Microservices, so far i didn't find any opensource project that follow this pattern. After a lot of reading and searching i conclude to this design but i still have some questions and thought.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N265s.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N265s.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Here are my questions and thoughts:</p>&#xA;&#xA;<ul>&#xA;<li>How to make the API gateway smart enough to load balnce the request if i have 2 node from the same microservice?</li>&#xA;<li>if one of the microservice is down how the discovery should know?</li>&#xA;<li>is there any similar implementation? is my design is right?</li>&#xA;<li>should i use Eureka or similar things?</li>&#xA;</ul>&#xA;"
41036545,How to pass through properties in JSON messages with Jackson and MongoDB?,2016-12-08 09:58:46,<java><json><spring><jackson><microservices>,7,731,7,0.0,9,"<p>We have a microservice which gets some JSON data from the queue, processes it a little bit and sends the result of processing further on - again via queue. In the microservice we don't work with <code>JSONObject</code> an likes directly, we map JSON onto Java classes using Jackson.</p>&#xA;&#xA;<p>When processing, the microservice is only interested in a some properties of the incoming message, not all of them. Imagine it just receives</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And sends:</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    ""multiplicationResult"": 15,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>How can I tunnell or pass-through other properties of the message which I'm not interested in this service without explicitly mapping them in my classes?</strong></p>&#xA;&#xA;<p>For the purposes of this microservice it would be enough to have a structure like:</p>&#xA;&#xA;<pre><code>public class Task {&#xA;   public double operand1;&#xA;   public double operand2;&#xA;   public double multiplicationResult;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However if I don't map all of the <em>other properties</em>, they will be lost.</p>&#xA;&#xA;<p>If I do map them then I'll have to update the model of this microservice every time the structure of the message changes which takes effort and is error-prone.</p>&#xA;"
46031939,How to manage read requests in an event sourced application,2017-09-04 07:07:54,<domain-driven-design><microservices><cqrs><event-sourcing><event-store>,2,109,2,2.0,9,"<p>I was asked to do some exploration in event sourcing. my objective is to create a tiny API layer that satisfies all the traditional CRUD operation. I am now using a package called 'sourced' and trying to play around with it (Using Nodejs).</p>&#xA;&#xA;<p>However, I came to realize that the event sourcing is not quite useful when it is used alone. usually, it is coupled with CQRS.</p>&#xA;&#xA;<p>My understanding of the CQRS is, when the UI sends a write command to the server. the app does some validation towards the data. and saves it in the event store(I am using mongoDB), for example: here is what my event store should look like:</p>&#xA;&#xA;<pre><code>{method:""createAccount"",name:""user1"", account:1}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""withdraw"",name:""user1"",account1,amount:250}&#xA;</code></pre>&#xA;&#xA;<p>It contains all the audit information rather than the eventual status.&#xA;however, I am confused how can I handle the read operation. what if I want to read the balance of an account. what exactly will happen?&#xA;here are my questions:</p>&#xA;&#xA;<ol>&#xA;<li>If we can not query the event store(database) directly for reading operation, then where should we query? should it be a cache in memory?</li>&#xA;<li>If we query the memory. is the eventual status already there or I have to do a replay (or left-fold) operation to calculate the result. for example, the balance of the account 1 is 50.</li>&#xA;<li>I found some bloggers talked about 'subscribe' or 'broadcast'. what are they and broadcast to who?</li>&#xA;</ol>&#xA;&#xA;<p>I will be really appreciated for any suggestion and please corret me if my understanding is wrong.</p>&#xA;"
45869766,How to get docker toolbox to work with .net core 2.0 project,2017-08-24 19:46:40,<c#><docker><asp.net-core><visual-studio-2017><microservices>,2,4412,3,14.0,20,"<p>I'm getting an error trying to use the Docker functionality with my .NET core 2.0 project. I've been getting an error message saying </p>&#xA;&#xA;<blockquote>&#xA;  <p>Visual Studio Container Tools requires Docker to be running before&#xA;  building, debugging or running a containerized project. For more info,&#xA;  please see: <a href=""http://aka.ms/DockerToolsTroubleshooting"" rel=""noreferrer"">http://aka.ms/DockerToolsTroubleshooting</a></p>&#xA;</blockquote>&#xA;&#xA;<p>I followed the link, and upon realizing I have Windows 10 Home x64, and had to install Docker Toolbox, instead of Docker For Windows. Now it installed this executable called </p>&#xA;&#xA;<blockquote>&#xA;  <p>Docker Quickstart Terminal</p>&#xA;</blockquote>&#xA;&#xA;<p>Is this the way one is supposed to start up that docker services? I have tried running this executable, and it seems to be working. My containers are running, but the error for Visual Studio Container Tools still persists. </p>&#xA;&#xA;<p>What am I missing? Is having a version of windows higher than Home required in order to use the Docker Container Support within Visual Studio 2017?</p>&#xA;&#xA;<p>UPDATE:</p>&#xA;&#xA;<p>I tried to follow Quetzcoatl's suggestion, and I am still getting the same error within visual studio about those tools. Here is what I ran in the Docker Quick Start Terminal. I tried building the project after Visual Studio successfully opened the project, and was still getting the aforementioned error regarding the container tools.</p>&#xA;&#xA;<p>My devenv.exe file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\devenv.exe</p>&#xA;</blockquote>&#xA;&#xA;<p>and my solution file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>D:\Development\Visual Studio\Musify2\Musify2\Musify2.sln</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/epqfT.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/epqfT.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>UPDATE 2:</strong></p>&#xA;&#xA;<p>I ran some of the suggested commands to try in the docker quickstart terminal and here were the results of those commands quetz<a href=""https://i.stack.imgur.com/nowpc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/nowpc.png"" alt=""enter image description here""></a></p>&#xA;"
45682321,"Microservice architecture, does it really encourage copy / paste?",2017-08-14 20:10:35,<architecture><microservices>,1,136,1,0.0,-4,"<p>I'm working in middle size organisation. From about a year we started refactor our old solution creating microservices. For backend part Go was chosen, for front we have Node.js</p>&#xA;&#xA;<p>Now imagine that we have some html form where user puts some data. After it front end part makes own validation and call one of three different endpoints (three different microservices). </p>&#xA;&#xA;<p>This validated by front end data then is validated by three micro services separately. The same rules are copy/pasted. And there are a lot of other examples like this.</p>&#xA;&#xA;<p>I proposed to create some validator service that will perform validation in one place and I got the answer something like 'in microservices architecture we cannot create strong dependencies' </p>&#xA;&#xA;<p>My question is if 'strong dependencies' are really so bad that we need to do stupid copy/paste and moreover create a unit tests for copy/pasted code (we copy/paste them too and change the names). If 'strong dependencies' are so bad could you give some examples why.  </p>&#xA;"
45625886,REST vs gRPC: when should I choose one over the other?,2017-08-11 02:09:34,<rest><kubernetes><microservices><docker-swarm><grpc>,3,3474,1,3.0,14,"<p>I see more and more software organizations using gRPC in their service-oriented architectures, but people are also still using REST. In what use cases does it make sense to use gRPC, and when does it make sense to use REST for inter-service communication?</p>&#xA;&#xA;<p>Interestingly, I've come across open source projects that use both REST and gRPC. For instance, Kubernetes and Docker Swarm all employ gRPC to some extent for cluster coordination, but also expose REST APIs for interfacing with master/leader nodes. Why not use gRPC up and down?</p>&#xA;"
26800452,Proxy_pass nginx not found,2014-11-07 11:41:14,<node.js><nginx><routes><reverse-proxy><microservices>,2,470,1,0.0,0,"<p>So, I was developing my server following the micro services arch in node. Therefore, I'm using nginx to redirect correctly the routes with each service. And was going pretty well since I added ghost on a subdirectory.</p>&#xA;&#xA;<p>Now, Ghost is working perfectly but all the others routes are broken. The nginx answer is not found.</p>&#xA;&#xA;<p>My nginx server congiguration:</p>&#xA;&#xA;<pre><code>server {&#xA;  listen 0.0.0.0:80;&#xA;&#xA;  location / {&#xA;    root /var/www/html;&#xA;  }&#xA;&#xA;  location ^~ /blog {&#xA;    proxy_set_header X-Real-IP $remote_addr;&#xA;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#xA;    proxy_set_header Host $http_host;&#xA;    proxy_set_header X-NginX-Proxy true;&#xA;    proxy_pass http://127.0.0.1:2368;&#xA;    proxy_redirect off;&#xA;  }&#xA;&#xA;  location /tool/Â {&#xA;    proxy_pass http://127.0.0.1:8100/;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Also I test the micro services with, ie:</p>&#xA;&#xA;<pre><code>telnet localhost 8100&#xA;</code></pre>&#xA;&#xA;<p>Result it's ok.</p>&#xA;&#xA;<p>I'm not even close to know what's happening, any help would be great. Thanks in advance.</p>&#xA;&#xA;<p><strong>EDIT</strong>: Also I notice that if I start a micro service on root, ie, the next routes try to follow the service instead of the nginx routing.</p>&#xA;"
50527363,HttpClientErrorException with spring microservices in java,2018-05-25 10:42:29,<java><microservices>,1,18,0,0.0,0,"<p>I am trying to create 2 microservices. 1st calls 2nd (add method should only check content of review and set approved flag) for approving but I am still receiving an exception <code>org.springframework.web.client.HttpClientErrorException: 405 null</code>. </p>&#xA;&#xA;<p>Here you are my REST from 1st microservice</p>&#xA;&#xA;<pre><code>  @RequestMapping(value = ""/addreview"", method = RequestMethod.PUT, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;    public ResponseEntity&lt;?&gt; createReviewForMovie(@RequestBody Review review) {&#xA;&#xA;        ResponseEntity&lt;Boolean&gt; response = new RestTemplate().getForEntity(""http://localhost:9100/add"", &#xA;                Boolean.class, review);&#xA;&#xA;        Boolean resultReview = response.getBody();&#xA;&#xA;        return new ResponseEntity&lt;Boolean&gt;(resultReview, HttpStatus.OK);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>And the second one:</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/add"", method = RequestMethod.PUT, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;public ResponseEntity&lt;?&gt; add(@RequestBody Review review){&#xA;    if(review.getReviewContent().length()&lt;10){&#xA;        review.setApproved(false);&#xA;        return new ResponseEntity&lt;Boolean&gt;(review.isApproved(), HttpStatus.OK);&#xA;    }&#xA;    review.setApproved(true);&#xA;    return new ResponseEntity&lt;Boolean&gt;(review.isApproved(), HttpStatus.OK);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What am I doing wrong? How to call 2nd microservice from 1st?</p>&#xA;"
50598938,How to connect to another docker service from one docker service in a docker swarm cluster?,2018-05-30 07:38:54,<api><docker><service><microservices><docker-swarm>,1,18,0,0.0,0,"<p>In the docker swarm cluster, launched two services:</p>&#xA;&#xA;<ul>&#xA;<li>sv_web</li>&#xA;<li>sv_api</li>&#xA;</ul>&#xA;&#xA;<p>The stack deploy file of web is:</p>&#xA;&#xA;<pre><code>version: ""3""&#xA;services:&#xA;  web:&#xA;    image: XXX/sv_web:latest&#xA;    ports:&#xA;      - ""80:80""&#xA;    networks:&#xA;      - webnet&#xA;networks:&#xA;  webnet:&#xA;</code></pre>&#xA;&#xA;<p>Deploy:</p>&#xA;&#xA;<pre><code>docker stack deploy -c ~/docker-compose-web.yml sv&#xA;</code></pre>&#xA;&#xA;<p>The stack deploy file of api is:</p>&#xA;&#xA;<pre><code>version: ""3""&#xA;services:&#xA;  web:&#xA;    image: XXX/sv_api:latest&#xA;    ports:&#xA;      - ""81:81""&#xA;    networks:&#xA;      - webnet&#xA;networks:&#xA;  webnet:&#xA;</code></pre>&#xA;&#xA;<p>Deploy:</p>&#xA;&#xA;<pre><code>docker stack deploy -c ~/docker-compose-api.yml sv&#xA;</code></pre>&#xA;&#xA;<p>Now want to connect <code>sv_api</code> service inside the <code>sv_web</code> application. Tried to write:</p>&#xA;&#xA;<pre><code>api_server = ""sv_api:81""&#xA;</code></pre>&#xA;&#xA;<p>But can't connect the <code>sv_api</code> service after deploying it. If use the real IP of the host in the cluster, it can be found: <code>[HOST]:81</code>.</p>&#xA;&#xA;<p>So how to connect to the API service from web service in this way?</p>&#xA;"
50584687,Does pact support application/JavaScript content-type?,2018-05-29 12:41:19,<spring><testing><integration-testing><microservices><pact>,1,23,0,0.0,0,"<p>The third party service that my microservice interacts with returns the response with the content-type application/JavaScript;charset=UTF-8. Therefore, pact json has response body as string &amp; matching rules have an empty body.</p>&#xA;&#xA;<p>Using the following pact dependencies:</p>&#xA;&#xA;<pre><code>testIntegrationCompile('au.com.dius:pact-jvm-consumer-junit_2.12:3.5.11')&#xA;   testIntegrationCompile('au.com.dius:pact-jvm-provider-junit_2.12:3.5.11')&#xA;   testIntegrationCompile('au.com.dius:pact-jvm-provider-spring_2.12:3.5.11')&#xA;   testIntegrationCompile('au.com.dius:pact-jvm-consumer-java8_2.12:3.5.11')&#xA;</code></pre>&#xA;"
50583823,AWS ECS run instance for each microservice,2018-05-29 11:57:29,<docker><docker-compose><microservices><amazon-ecs>,1,36,0,0.0,0,"<p>I suppose, it's a stupid question but I have no idea where to find the answer. I've checked so many resources but I still didn't get it.</p>&#xA;&#xA;<p>I have docker-compose.yml file. Is it possible to use AWS ECS cluster to run a new instance (t2.micro, for example) for each service (eurekaserver, configserver, zuulserver, database)? I saw only examples with one big instance.</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;&#xA;  eurekaserver:&#xA;   image: maxb/tracker-eurekasvr:tracker-eurekasvr&#xA;   ports:&#xA;       - ""8761:8761""&#xA;&#xA;  configserver:&#xA;    image: maxb/tracker-confsvr:tracker-confsvr&#xA;    ports:&#xA;       - ""8888:8888""&#xA;    environment:&#xA;       EUREKASERVER_URI: ""http://eurekaserver:8761/eureka/""&#xA;       EUREKASERVER_PORT: ""8761""&#xA;       ENCRYPT_KEY:       ""IMSYMMETRIC""&#xA;&#xA;  zuulserver:&#xA;    image: maxb/tracker-zuulsvr:tracker-zuulsvr&#xA;    ports:&#xA;      - ""5555:5555""&#xA;    environment:&#xA;      PROFILE: ""default""&#xA;      SERVER_PORT: ""5555""&#xA;      CONFIGSERVER_URI: ""http://configserver:8888""&#xA;      EUREKASERVER_URI: ""http://eurekaserver:8761/eureka/""&#xA;      DATABASESERVER_PORT: ""27017""&#xA;      EUREKASERVER_PORT:   ""8761""&#xA;      CONFIGSERVER_PORT:   ""8888""&#xA;&#xA;  database:&#xA;    image: mongo&#xA;    container_name: tracker-mongo&#xA;    volumes:&#xA;      - $HOME/tracker-data:/data/db&#xA;      - $HOME/tracker-datacd:/data/bkp&#xA;    restart: always&#xA;</code></pre>&#xA;&#xA;<p>AWS ECS has Tasks Definitions but I'm not sure if it can help</p>&#xA;"
50663047,Microservices and Rest services deployed as jar file?,2018-06-03 03:35:19,<java><rest><war><microservices>,3,66,0,0.0,0,"<p>Let's take the simple example, where I have multiplication service as part of single monolithic MathService(deployed as war).</p>&#xA;&#xA;<p>Now I need to deploy multiplication service as separate service(rest service) which MathService can call. The concept of dividing the single monolithic&#xA;in to small maintainable service is microservice.</p>&#xA;&#xA;<p>But I am not sure is it mandatory to deploy Multiplication service as war file? Can it be still deployed as jar file on the web server?</p>&#xA;&#xA;<p>My understanding is that it should be war file as rest calls(HTTP call) needs to be handled by the servlet. Including servlet means it has to be war file.&#xA;Is that correct?</p>&#xA;"
50531553,Spring boot applications high availability,2018-05-25 14:31:13,<spring-boot><microservices><high-availability>,1,70,0,0.0,0,"<p>We have a microservice which is developed using spring boot. couple of the functionalities it implements is </p>&#xA;&#xA;<p>1) A scheduler that triggers, at a specified time,  a file download using webhdfs and process it and once the data is processed, it will send an email to users with the data process summary.&#xA;2) Read messages from kafka and once the data is read, send an email to users.</p>&#xA;&#xA;<p>We are now planning to make this application high available either in Active-Active or Active-passive set up. The problem we are facing now is if both the instances of the application are running then both of them will try to download the file/read the data from kafka, process it and send emails.  How can this be avoided? I mean to ensure that only one instance triggers the download and process it ? </p>&#xA;&#xA;<p>Please let me know if there is known solution for this kind of scenarios as this seems to be a common scenario in most of the projects? Is master-slave/leader election approach a correct solution? </p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50628676,"Explications about EventSourcing, Microservice, CQRS",2018-05-31 16:17:22,<events><apache-kafka><microservices><apache-zookeeper><event-sourcing>,1,104,0,1.0,0,"<p>I am currently building an app, and i would like to use microservices as pattern and GraphQl for communication. I am thinking about using kafka / rabbitmq + authZ + auth0 + apollo + prisma. And all of this running on docker.&#xA;I found many ressources on event sourcing, the advantage/disavantage, and I am stuck on how it work in the real world. As far, this is how i will do it:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/llH9o.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/llH9o.png"" alt=""Microservice CQRS""></a></p>&#xA;&#xA;<ul>&#xA;<li>Apollo engine to monitor request / responses..</li>&#xA;<li>Auth0 for authentification management</li>&#xA;<li>AuthZ for authorization</li>&#xA;<li>A graphql gateway. Sadly I did not find a reliable solution, I guess i have to do it my self using apollo + graphql-tool to merge schema.</li>&#xA;</ul>&#xA;&#xA;<p>And ideally: </p>&#xA;&#xA;<ul>&#xA;<li>Prisma for the read side of bill's MS</li>&#xA;<li>nodejs for the write side of bill's MS </li>&#xA;</ul>&#xA;&#xA;<p>Now if I understand correctly, using apache kafka + zookeeper :</p>&#xA;&#xA;<ul>&#xA;<li>Kafka as the message broker</li>&#xA;<li>Zookeeper as an eventstore.</li>&#xA;</ul>&#xA;&#xA;<p>If I am right, can I assume: </p>&#xA;&#xA;<ul>&#xA;<li><p>There would be 2 ways to validate if the request is valid:</p>&#xA;&#xA;<ul>&#xA;<li>Write's side only get events (from event store, AKA zookeeper) to validate if the requested mutation is possible.</li>&#xA;<li>Write's side get a snapshot from a traditional database to validate the requested mutation.</li>&#xA;</ul>&#xA;&#xA;<p>Then it publish an event to kafka (I assume kafka update zookeeper automatically), and then the message can be used by the read's side to update a private snapshot of the entity. Of course, this message can also be used by others MS.&#xA;I do not know apache kafka + zookeeper very well, in the past i only used messaging service as rabbitmq. They seems similars in the shape but very different in the usage.</p></li>&#xA;<li>The main difference between event sourcing and basic messaging is the usage of the event-store instead of a entity's snapshot? In this case, can we assume that not all MS need an event's store tactic (i mean, validating via the event store and not via a ""private"" database)? If yes, does anyone can explain when you need event's store and when not? </li>&#xA;</ul>&#xA;"
50647694,Why using Eureka?,2018-06-01 16:33:00,<kubernetes><microservices><spring-cloud><netflix-eureka>,2,138,0,3.0,0,"<p>I was setting up microservices based on <a href=""https://github.com/Netflix/eureka"" rel=""nofollow noreferrer"">Netflix Eureka</a> and experimenting on top of <a href=""https://cloud.spring.io/spring-cloud-netflix/"" rel=""nofollow noreferrer"">spring-cloud</a> and after weeks of research and development the question rose! </p>&#xA;&#xA;<p>Why do I need the Eureka and spring-cloud?</p>&#xA;&#xA;<p>Why not developing your independent containers and deploy them on <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> as pods and maintain everything from there?</p>&#xA;&#xA;<p>You can support load balancing, service registery, monitoring, containerization, etc. from <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> too.</p>&#xA;&#xA;<p>Here are some points that I can think of:</p>&#xA;&#xA;<ul>&#xA;<li>developer friendly</li>&#xA;<li>lower server costs for the complete stack</li>&#xA;<li>less OPS dependent</li>&#xA;<li>more resources on developer communities and tutorials</li>&#xA;<li>gradual learning curve</li>&#xA;</ul>&#xA;"
50688223,Update/Add as separate service and Get as separate service,2018-06-04 20:22:49,<microservices>,1,32,1,0.0,0,"<p>We started to migrate our existing project into microservice architecture. After going through a lot of videos/lectures, we came to a conclusion that a service should do one task and only one task and should be great at it. The services should be designed around <code>Noun</code> and <code>Verb</code>.</p>&#xA;&#xA;<p>We have an entity which has basically CRUD operations. Now the add, update and delete are least used operations but GET requests at too high compared to those operations. Typically, update/add/delete are done by admin guys.</p>&#xA;&#xA;<p>What we thought of is breaking the CRUD entity into  two services</p>&#xA;&#xA;<ul>&#xA;<li>EntityCUDService (create/update/delete)</li>&#xA;<li>EntityLookupService (get)</li>&#xA;</ul>&#xA;&#xA;<p>Now both these services point to the same collection in mongo or say some SQL.&#xA;Now if <code>EntityCUDService</code> has done some changes to collection/table then <code>EntityLookupService</code> fails.</p>&#xA;&#xA;<p>We heard of maintaining semantic versioning, that sounds okay but We also heard microservices should not share model/data source. So what would be the optimal solution to handle this where we have tons of gets but tens of updates/adds of same entity</p>&#xA;&#xA;<p>Any help is greatly appreciated.</p>&#xA;"
50697247,Kubernetes (Minikube): link between client and server,2018-06-05 09:56:32,<kubernetes><microservices><minikube>,2,56,1,0.0,0,"<p>I'm running a simple spring microservice project with Minikube. I have two projects: lucky-word-client (on port 8080) and lucky-word-server (on port 8888). But I can't communicate client with server. Infact if lucky-word-client communicates with lucky-word-server, the result is the word ""Evviva"", else the word is ""Default"". When I run on terminal: <code>minikube service lucky-client</code> the output is Default, instead of Evviva.</p>&#xA;&#xA;<p>This is the file Dockerfile of lucky-word-server:</p>&#xA;&#xA;<pre><code>FROM frolvlad/alpine-oraclejdk8 &#xA;&#xA;ADD build/libs/common-config-server-0.0.1-SNAPSHOT.jar common-config-server.jar&#xA;&#xA;EXPOSE 8888&#xA;&#xA;ENTRYPOINT [""/usr/bin/java"", ""-Xmx128m"", ""-Xms128m""]&#xA;&#xA;CMD [""-jar"", ""common-config-server.jar""]&#xA;</code></pre>&#xA;&#xA;<p>This is the file Dockerfile of lucky-word-client:</p>&#xA;&#xA;<pre><code>FROM frolvlad/alpine-oraclejdk8 &#xA;&#xA;ADD build/libs/lucky-word-client-0.0.1-SNAPSHOT.jar lucky-word-client.jar&#xA;&#xA;EXPOSE 8080&#xA;&#xA;ENTRYPOINT [""/usr/bin/java"", ""-Xmx128m"", ""-Xms128m""]&#xA;&#xA;CMD [""-jar"", ""-Dspring.profiles.active=italian"", ""lucky-word-client.jar""]&#xA;</code></pre>&#xA;&#xA;<p>This is deployment of lucky-word-server:</p>&#xA;&#xA;<pre><code>apiVersion: apps/v1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: lucky-server&#xA;spec:&#xA;  selector:&#xA;      matchLabels:&#xA;        app: lucky-server&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: lucky-server&#xA;    spec:&#xA;      containers:&#xA;        - name: lucky-server&#xA;          image: lucky-server-img&#xA;          imagePullPolicy: Never&#xA;          ports:&#xA;            - containerPort: 8888&#xA;</code></pre>&#xA;&#xA;<p>This is the service of lucky-word-server:</p>&#xA;&#xA;<pre><code>kind: Service&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: lucky-server&#xA;spec:&#xA;  selector:&#xA;    app: lucky-server&#xA;  ports:&#xA;  - protocol: TCP&#xA;    port: 8888&#xA;  type: NodePort&#xA;</code></pre>&#xA;&#xA;<p>This is the deployment of lucky-word-client:</p>&#xA;&#xA;<pre><code>apiVersion: apps/v1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: lucky-client&#xA;spec:&#xA;  selector:&#xA;      matchLabels:&#xA;        app: lucky-client&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: lucky-client&#xA;    spec:&#xA;      containers:&#xA;        - name: lucky-client&#xA;          image: lucky-client-img&#xA;          imagePullPolicy: Never&#xA;          ports:&#xA;            - containerPort: 8080&#xA;</code></pre>&#xA;&#xA;<p>This is the service of lucky-word-client:</p>&#xA;&#xA;<pre><code>kind: Service&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: lucky-client&#xA;spec:&#xA;  selector:&#xA;    app: lucky-client&#xA;  ports:&#xA;  - protocol: TCP&#xA;    port: 8080&#xA;  type: NodePort&#xA;</code></pre>&#xA;"
50707566,Kubernetes (Minikube): environment variable,2018-06-05 19:25:54,<docker><kubernetes><microservices>,1,96,1,0.0,0,"<p>I'm running a simple spring microservice project with Minikube. I have two projects: lucky-word-client (on port 8080) and lucky-word-server (on port 8888). lucky-word-client has to communicate with lucky-word-server. I want to inject the static Nodeport of lucky-word-server (<a href=""http://192"" rel=""nofollow noreferrer"">http://192</a>.<strong>*.</strong>.100:32002) as an environment variable in my Kuberenetes deployment script of lucky-word-client. How I could do?</p>&#xA;&#xA;<p>This is deployment of lucky-word-server:</p>&#xA;&#xA;<pre><code>apiVersion: apps/v1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: lucky-server&#xA;spec:&#xA;  selector:&#xA;      matchLabels:&#xA;        app: lucky-server&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: lucky-server&#xA;    spec:&#xA;      containers:&#xA;        - name: lucky-server&#xA;          image: lucky-server-img&#xA;          imagePullPolicy: Never&#xA;          ports:&#xA;            - containerPort: 8888&#xA;</code></pre>&#xA;&#xA;<p>This is the service of lucky-word-server:</p>&#xA;&#xA;<pre><code>kind: Service&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: lucky-server&#xA;spec:&#xA;  selector:&#xA;    app: lucky-server&#xA;  ports:&#xA;  - protocol: TCP&#xA;    targetPort: 8888&#xA;    port: 80&#xA;    nodePort: 32002&#xA;  type: NodePort&#xA;</code></pre>&#xA;&#xA;<p>This is the deployment of lucky-word-client:</p>&#xA;&#xA;<pre><code>apiVersion: apps/v1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: lucky-client&#xA;spec:&#xA;  selector:&#xA;      matchLabels:&#xA;        app: lucky-client&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: lucky-client&#xA;    spec:&#xA;      containers:&#xA;        - name: lucky-client&#xA;          image: lucky-client-img&#xA;          imagePullPolicy: Never&#xA;          ports:&#xA;            - containerPort: 8080&#xA;</code></pre>&#xA;&#xA;<p>This is the service of lucky-word-client:</p>&#xA;&#xA;<pre><code>kind: Service&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: lucky-client&#xA;spec:&#xA;  selector:&#xA;    app: lucky-client&#xA;  ports:&#xA;  - protocol: TCP&#xA;    targetPort: 8080&#xA;    port: 80&#xA;  type: NodePort&#xA;</code></pre>&#xA;"
50562495,How to handle microservice Interaction when one of the microservice is down,2018-05-28 08:52:46,<spring-boot><microservices>,2,132,1,0.0,0,"<p>I am new to microservice architecture. Currently I am using spring boot for my microservices, in case one of the microservice is down how should fail over mechanism work ?</p>&#xA;&#xA;<p>For Ex. if we have 3 microservices M1,M2,M3 . M1 is interacting with M2 and M2 is interacting with M3 . In case M2 microservice cluster is down how should we handle this situation?</p>&#xA;"
50673143,How to log info logs to one file & error logs to another file,2018-06-04 03:41:09,<java><spring-boot><log4j><microservices>,1,149,1,0.0,0,<p>I want to print Info &amp; Debug logs to success.log file &amp; Error logs to error.log file in log4j by Java programmatic level(In config class). I tried many but couldn't get. Can anyone please help.</p>&#xA;
50506101,Spring Boot - how to communicate between microservices?,2018-05-24 09:45:18,<spring-boot><microservices>,2,721,1,0.0,0,"<p>I'm currently working on a Spring Boot microservices project. I have created services and each service is running separately. With this, I need some services to communicate with other services. How can i achieve that?</p>&#xA;&#xA;<p>I saw some blogs about this which use Netflix, Eureka cloud servers to achieve this. Is there any way I can achieve this in my local environment without using cloud servers?</p>&#xA;"
50627087,"If my users are stored in another database, should I duplicate them in my service that uses SQL database?",2018-05-31 14:48:42,<mysql><sql><postgresql><microservices>,2,39,5,0.0,0,"<p>If my users are stored in some other database, but I am building posts in my SQL database, should I create another table <code>users</code>?</p>&#xA;&#xA;<p>If I did, I would be duplicating all of my users and would have to make sure this stays in sync with the other database, but on the other hand, my posts tables could save space by referring to fk instead of full id string each time.</p>&#xA;&#xA;<p>What is the recommendation? Create another table <code>users</code> or just pass in the user ids to query? </p>&#xA;"
28997963,"How to send eMails the Immutable Microservices (Container, Docker) Way",2015-03-11 21:42:42,<immutability><microservices>,1,361,0,0.0,0,"<p>Naturally, with all this microservices and immutability hype, real life questions like this arise:</p>&#xA;&#xA;<p>How to send eMails from a containerized application which is immutable and supposed to support multiple providers ranging from plain SMTP to transactional mail proviers like Sendgrid, MailJet, Mandrill, Mailgun and the like?</p>&#xA;&#xA;<p>In software systems built on past architecture principles, this problem has often been solved through a plugin mechanism which allows to override the default SMTP provider; Wordpress is one example.&#xA;This is, however, considered bad design as it breaks the immutability of the application.</p>&#xA;"
28664781,"Monitoring cluster of micro services (web,queue,db,ha proxy)",2015-02-22 23:38:28,<nginx><architecture><health-monitoring><microservices>,1,300,0,0.0,0,"<p>I am designing an architecture where all micro services are clustered.&#xA;For instance: 5 web server, 1 clustered db, 1 clustered queue system, 8 clustered workers (like send email,send sms,...) that consume from the queue (tasks are pushed by the web server)</p>&#xA;&#xA;<p>I am wondering about the best practice in order to detect that each 'cluster of micro service' is healthy, and how to 'fail fast' the whole service in such case one of the micro service is unavailable.</p>&#xA;&#xA;<p>All the service is sitting behind an nginx for ha proxy - should it be nginx that monitors everything and fails? How can I check the health of all the micro services?</p>&#xA;"
28828573,How do I create a delegating Angular multi host site?,2015-03-03 09:47:08,<angularjs><rest><proxy><delegation><microservices>,1,66,0,0.0,0,"<p>I work in an environment where we develop a solution using several (a lot of) servers. They microservice style is the role model.</p>&#xA;&#xA;<p>To be able to upgrade systems they must be switchable/replaceable (including the user interface) in runtime.&#xA;The principal solution that have been decided upon is that </p>&#xA;&#xA;<ol>&#xA;<li>a Portal/Proxy is the only visible system for the end user</li>&#xA;<li>The proxy is ""aware"" af the supporting servers</li>&#xA;<li>The proxy has some basic user interface with for instance menues. Might be in collaboration with the subsystems (several entries in the menu etc.)</li>&#xA;<li>A user requests a page with some dynamic content</li>&#xA;<li>The portal relays/proxy the query of ""content"" part of the page to the subsystem.</li>&#xA;<li>Any REST-calls needed by the client is also proxied through the main server.</li>&#xA;</ol>&#xA;&#xA;<p>The REST calls are of course very simple but I am too n00b in Angular to really understand how to make the ""mix.&#xA;Point number 5 is of course the tough part. IF the subserver would have been visible an iframe (eeek!) could have been used but not in this case.</p>&#xA;&#xA;<p>I need some sort of ""delegation"" within a page, anything done before? How DOES the microservice flagships handle the User Interface?</p>&#xA;"
27752201,How would a platform or core code design look like in a microservices architecture?,2015-01-03 05:58:52,<architecture><domain-driven-design><software-design><microservices>,1,105,0,0.0,0,"<p>In a monolithic architecture, you would have a core/platform code on top of which a bunch of services or business domains would be built. Some examples being, db abstraction, external service abstraction etc. </p>&#xA;&#xA;<p>In case of micro services, would the platform code be written as a module, which would be imported as a dependent module in each of the micro services or, does this violate the construct of the architecture because of tight coupling between the module and the common (core/platform) code and thereby going back to the issues related multiple deployments, code bugs, vendor lock ins etc?</p>&#xA;"
33431076,Environment variables inheritance with microservices (Laravel & Lumen),2015-10-30 07:52:01,<php><laravel><inheritance><environment-variables><microservices>,1,399,6,0.0,0,"<p>Recently I ran into a problem while deploying a <strong>Lumen</strong> microservice next to a <strong>Laravel</strong> app. On the same machine I have a Laravel app and a Lumen app both with different <code>.env</code> file and the default environment variables (<code>APP_ENV</code>, <code>DB_HOST</code>, <code>DB_DATABASE</code>, etc).</p>&#xA;&#xA;<p>My <strong>Laravel</strong> app needs to make a request the the <strong>Lumen</strong> app to get some data. That's when the problem occures. When the <strong>Lumen</strong> app receives the request it also inherits the <strong>Laravel</strong>'s environment variables, making it impossible to do it's job (to connect to the database or other services that have the environment variables set in the <code>.env</code> file because all the variables are inherited from the parent request).</p>&#xA;&#xA;<p>Has anyone encountered this problem before? Am I using the microservices architecture the right way?</p>&#xA;&#xA;<p><strong>Update</strong> with code.</p>&#xA;&#xA;<p><em>Laravel app - UsersController.php</em> </p>&#xA;&#xA;<pre><code>/**&#xA; * Makes a request to the Core API and fills properties with the response data&#xA; *&#xA; * @param $method&#xA; * @param $uri&#xA; * @param array|null $data&#xA; */&#xA;public function request($method, $uri, array $data = null)&#xA;{&#xA;    $this-&gt;api = new Client(['base_uri' =&gt; 'http://127.0.0.1/']);&#xA;&#xA;    if (property_exists($this, 'uriPrefix')) $uri = $this-&gt;uriPrefix . $uri;&#xA;    $requestOptions = [&#xA;        'http_errors'   =&gt; false,&#xA;        'headers' =&gt; ['Accept' =&gt; 'application/json']&#xA;    ];&#xA;    if (session('api_cookie')) $requestOptions['headers']['Cookie'] = implode(';', session('api_cookie'));&#xA;    if ($data) {&#xA;        if ($method == 'GET') $requestOptions['query'] = $data;&#xA;        else if (($method == 'POST') || ($method == 'PUT')) $requestOptions['form_params'] = $data;&#xA;    }&#xA;&#xA;    $response = $this-&gt;api-&gt;request($method, $uri, $requestOptions);&#xA;&#xA;    session(['api_cookie' =&gt; $response-&gt;getHeader('Set-Cookie')]);&#xA;&#xA;    $this-&gt;responseCode = $response-&gt;getStatusCode();&#xA;    $this-&gt;responseReasonPhrase = $response-&gt;getReasonPhrase();&#xA;    $this-&gt;responseData = $response-&gt;getBody();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I make this request the <strong>Lumen</strong> app can't connect to the database because it inherits the <code>DB_</code> environment variables from the parent <strong>Laravel</strong> app.</p>&#xA;"
31962345,How to secure an API used only from front-end (Ajax call),2015-08-12 10:17:40,<javascript><api><authentication><token><microservices>,1,543,0,0.0,0,"<p>Well, I created an API to manage for our websites some attachments uploads and store into Amazon S3 buckets</p>&#xA;&#xA;<p>The scenario : Once visitor / user in the form and wants to submit it with attachment, once the file is selected then button clicked an Ajax request fire to the micro service API so it can store the file into S3 do some processing then return the direct link or identifier.</p>&#xA;&#xA;<p>The question is : how can we authenticate the user using for example a short live token or something like that without being hijacked, mis-usage of the token..</p>&#xA;&#xA;<p>In Javascript everything is visible to the visitor, and we try to not integrate any heavy process in the backend</p>&#xA;"
32106454,Intercepting and overriding microservice,2015-08-19 22:09:07,<override><microservices>,1,32,0,0.0,0,"<p>Imagine that you build your app from various HTTP microservices. However, there is one that you want to change the behavior - you dont want it to work as it works by default, but you want to change its behavior. In OO world, you would simply extend the class. In microservices you do... what?</p>&#xA;&#xA;<p>Example: Imaginge you have the api:</p>&#xA;&#xA;<pre><code>/data&#xA;</code></pre>&#xA;&#xA;<p>that return various information from the some datastore. But you want to add parameter 'userId' to every request (if not set by user), so all data should be related to user. In other words, we want to override it with:</p>&#xA;&#xA;<pre><code>/data?userId=123&#xA;</code></pre>&#xA;&#xA;<p>Is there an example of microservices (like with some tool that helps you building APIs, like we have nowdays in Java, Scala...) where you can override on service and change the behavior? Note that I am <strong>not</strong> overriding the <em>code</em>, since the code is not available; i want to override the <em>microservice</em> api.</p>&#xA;"
32167881,How to setup Nginx to proxy to two service on one machine?,2015-08-23 14:44:38,<python><ruby><nginx><reverse-proxy><microservices>,1,398,0,0.0,0,"<p>I have written two micros services with python and ruby. The python one serves some api requests.  and the ruby one serves the other api requests.</p>&#xA;&#xA;<p>the python one listens port 80 and can handle /users /feeds requests&#xA;the ruby one listens port 4567 and can handle /orders /products requests.</p>&#xA;&#xA;<p>the following is my config file .but it does not work with nginx .</p>&#xA;&#xA;<pre><code>upstream midgard_api_cluster&#xA; {&#xA;     server unix:/tmp/midgard_api.sock;&#xA;  }&#xA;&#xA;upstream tradeapi {&#xA;    server    127.0.0.1:4567;&#xA; }&#xA;&#xA;server {&#xA;   listen        80;&#xA;server_name my.domain.name;&#xA;client_max_body_size 20M;&#xA;&#xA;set $x_remote_addr $http_x_real_ip;&#xA;if ($x_remote_addr = """") {&#xA;    set $x_remote_addr $remote_addr;&#xA;}&#xA;&#xA;access_log     /var/log/nginx/midgard/access_log ;&#xA;error_log     /var/log/nginx/midgard/error_log ;&#xA;charset utf-8;&#xA;location /static/ {&#xA;        root /opt/www/templates/;&#xA;        expires 30d;&#xA;    }&#xA;&#xA;location / {&#xA;        error_page      502 503 504 /500.html;&#xA;        uwsgi_pass      midgard_api_cluster;&#xA;        include     uwsgi_params;&#xA;&#xA;        # proxy_redirect      default;&#xA;        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;&#xA;        proxy_set_header    X-Real-IP $x_remote_addr;&#xA;        proxy_set_header    Host $http_host;&#xA;        proxy_set_header    Range $http_range;&#xA;&#xA;        proxy_connect_timeout 10;&#xA;        proxy_send_timeout 10;&#xA;        proxy_read_timeout 11;&#xA;    }&#xA;&#xA;    location /products {&#xA;    proxy_set_header X-Real-IP $remote_addr;&#xA;    proxy_set_header Host $host;&#xA;    proxy_set_header X-NginX-Proxy true;&#xA;    proxy_pass http://tradeapi;&#xA;    proxy_redirect off;&#xA;}&#xA;&#xA;location /orders {&#xA;    proxy_set_header X-Real-IP $remote_addr;&#xA;    proxy_set_header Host $host;&#xA;    proxy_set_header X-NginX-Proxy true;&#xA;    proxy_pass http://tradeapi;&#xA;&#xA;    proxy_redirect off;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>Now , when i use </p>&#xA;&#xA;<pre><code> curl http://my.domain.name/products &#xA;</code></pre>&#xA;&#xA;<p>It got a 404 error and the request was directed to the python service .</p>&#xA;&#xA;<p>and </p>&#xA;&#xA;<pre><code>curl http://my.domain.name:3000/products &#xA;</code></pre>&#xA;&#xA;<p>can get the right response .</p>&#xA;&#xA;<p>How can i setup the nginx configuration file and route the request to the ruby service ?</p>&#xA;"
32071088,What are containers e.g Docker,2015-08-18 11:25:11,<design-patterns><microservices>,1,147,0,0.0,0,"<p>Lately, I've been reading about microservices because I keep hearing about them. But while reading on microservices some articles make  mention of container's and all the resources I've read on container's seems not to help me understand <strong>what they're</strong>, <strong>how they relate to microservices</strong>, and <strong>what problem does it solve</strong>.</p>&#xA;&#xA;<p>Also, is there any book that can be recommended on microservices?</p>&#xA;"
49817769,Polymorphic Microservices,2018-04-13 13:05:50,<rest><architecture><microservices>,1,72,0,0.0,0,"<p>I'm going to describe a very trivial example and of course in reality it is much more complicated.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/z4w4P.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/z4w4P.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In this picture I have an API gateway that some application will call to ask to get a list of animals.  I have an ""Animals"" microservice that will handle the incoming request and then delegate the request to other microservices for each animal; I'm equating this to polymorphism.</p>&#xA;&#xA;<p>When I first launch my application I only have ""Dogs"" and ""Cats"" available.  At some point in the future I now have the ability to add ""Rabbits"" to my list of animals.</p>&#xA;&#xA;<p>Questions:</p>&#xA;&#xA;<ol>&#xA;<li>Does this architecture have a named pattern I can search for and&#xA;learn about? </li>&#xA;<li>What is a clean way to add in the ""Rabbits""&#xA;microservice and have the Client app get a complete list of animals?</li>&#xA;<li>How should the ""Animals"" microservice communicate with ""Dogs"",&#xA;""Cats"", and ""Rabbits""?  HTTP or message bus?</li>&#xA;</ol>&#xA;"
49818943,Cumulocity microservice deployment: access is denied,2018-04-13 14:08:15,<java><microservices><cumulocity>,1,93,0,0.0,0,"<h2>My goal (background info)</h2>&#xA;&#xA;<p>I want to develop a java microservice on cumulocity. It should be able to do the following:<br>&#xA;I would send ""112233"" to the microservice as follows:&#xA;<a href=""https://myTenant.cumulocity.com/service/my-application-name/decode?data=112233"" rel=""nofollow noreferrer"">https://myTenant.cumulocity.com/service/my-application-name/decode?data=112233</a><br>&#xA;The microservice should then split the data into ""11"" for the first measurement and ""22"" for the second measurement etc. These measurements would be POSTed to cumulocity.</p>&#xA;&#xA;<h2>My problem</h2>&#xA;&#xA;<p>I am now stuck on getting the <a href=""https://www.cumulocity.com/guides/java/java-microservice/"" rel=""nofollow noreferrer"">Hello, microservice tutorial</a> to work. I can't deploy the microservice (zip file) to cumulocity. &#xA;<code>""error"":""security/Forbidden"",""info"":""https://www.cumulocity.com/guides/reference-guide/#error_reporting"",""message"":""Access is denied""}</code> (I am an admin user.)  </p>&#xA;&#xA;<p>I also tried to upload the zip file via the website, this created a <code>HOSTED</code> application instead of a <code>MICROSERVICE</code>. Uploading my zip via a POST request to a <code>HOSTED</code> application actually works (which I obviously don't need).  </p>&#xA;&#xA;<p>I suspect that I get the ""access denied"" error cause cumulocity thinks that I upload a <code>HOSTED</code> application to a <code>MICROSERVICE</code>.  </p>&#xA;&#xA;<h2>What I've done so far</h2>&#xA;&#xA;<h3>Code side</h3>&#xA;&#xA;<p>I downloaded the <a href=""https://bitbucket.org/m2m/cumulocity-examples/src/4a67ea4ab039/hello-world-microservice/?at=develop"" rel=""nofollow noreferrer"">hello-world-microservice example</a> from the cumulocity bitbucket development branch. (This code is not available on the default branch).<br>&#xA;I changed the cumulocity versions to <code>9.3.0</code>, only this version seems to exist.  </p>&#xA;&#xA;<p><strong>The HelloWorldMain.java is unedited</strong>  </p>&#xA;&#xA;<p>This is my <strong>cumulocity.json</strong> manifest file: (the roles make no difference)  </p>&#xA;&#xA;<pre><code>{  &#xA; ""apiVersion"":""1"",&#xA; ""type"":""MICROSERVICE"",&#xA; ""version"":""@project.version@"",&#xA; ""availability"":""PRIVATE"",&#xA; ""provider"":{  &#xA;     ""name"":""Cumulocity GmbH""&#xA; },&#xA; ""isolation"":""MULTI_TENANT"",&#xA; ""requiredRoles"":[  &#xA;     ""ROLE_APPLICATION_MANAGEMENT_ADMIN"",&#xA;     ""ROLE_MEASUREMENT_ADMIN"",&#xA;     ""ROLE_INVENTORY_ADMIN""&#xA; ],&#xA; ""roles"":[  &#xA;     ""ROLE_APPLICATION_MANAGEMENT_ADMIN"",&#xA;     ""ROLE_MEASUREMENT_ADMIN"",&#xA;     ""ROLE_INVENTORY_ADMIN""&#xA; ],&#xA; ""livenessProbe"":{  &#xA;     ""httpGet"":{  &#xA;         ""path"":""/health"",&#xA;         ""port"":80&#xA;     },&#xA;     ""initialDelaySeconds"":15,&#xA;     ""periodSeconds"":10&#xA; },&#xA; ""readinessProbe"":{  &#xA;     ""httpGet"":{  &#xA;         ""path"":""/health"",&#xA;         ""port"":80&#xA;     }&#xA; }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This is my <strong>application.properties</strong> file </p>&#xA;&#xA;<pre><code>application.name=my-application-name&#xA;server.port=80&#xA;C8Y.baseURL=https://myTenant.cumulocity.com&#xA;C8Y.bootstrap.tenant=myTenant&#xA;C8Y.bootstrap.user=servicebootstrap_my-application-name&#xA;C8Y.bootstrap.password={SECRET_BOOTSTRAP_PASSW}&#xA;C8Y.user={MY_USERNAME}&#xA;C8Y.password={SECRET_PASSW}&#xA;C8Y.bootstrap.register=true&#xA;C8Y.microservice.isolation=MULTI_TENANT&#xA;C8Y.bootstrap.initialDelay=10000&#xA;</code></pre>&#xA;&#xA;<h3>Cumulocity side</h3>&#xA;&#xA;<p>I successfully <strong>created</strong> a microservice application,<br>&#xA;GET <a href=""https://myTenant.cumulocity.com/application/applications/5886"" rel=""nofollow noreferrer"">https://myTenant.cumulocity.com/application/applications/5886</a> returns:  </p>&#xA;&#xA;<pre><code>{  &#xA; ""availability"":""PRIVATE"",&#xA; ""id"":""5886"",&#xA; ""key"":""my-application-key"",&#xA; ""manifest"":{  &#xA;     ""imports"":[  &#xA;     ],&#xA;     ""noAppSwitcher"":true&#xA; },&#xA; ""name"":""my-application-name"",&#xA; ""owner"":{  &#xA;     ""self"":""https://myTenant.cumulocity.com/tenant/tenants/myTenant"",&#xA;     ""tenant"":{  &#xA;         ""id"":""myTenant""&#xA;     }&#xA; },&#xA; ""requiredRoles"":[  &#xA;     ""ROLE_APPLICATION_MANAGEMENT_ADMIN"",&#xA;     ""ROLE_MEASUREMENT_ADMIN"",&#xA;     ""ROLE_INVENTORY_ADMIN""&#xA; ],&#xA; ""roles"":[  &#xA;     ""ROLE_APPLICATION_MANAGEMENT_ADMIN"",&#xA;     ""ROLE_MEASUREMENT_ADMIN"",&#xA;     ""ROLE_INVENTORY_ADMIN""&#xA; ],&#xA; ""self"":""https://myTenant.cumulocity.com/application/applications/5886"",&#xA; ""type"":""MICROSERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I also successfully <strong>subscribed</strong> to this application.  </p>&#xA;&#xA;<p>When I try to upload the zip file to cumulocity, I get this error:&#xA;<code>""error"":""security/Forbidden"",""info"":""https://www.cumulocity.com/guides/reference-guide/#error_reporting"",""message"":""Access is denied""}</code><br>&#xA;(Uploading to a <code>HOSTED</code> type application works fine, but I don't want that.)  </p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>note</strong>: I also tried to use the <a href=""https://www.cumulocity.com/guides/reference/microservice-package/"" rel=""nofollow noreferrer"">microservice deploy script</a>, this gave the same result as doing everything manually.</p>&#xA;</blockquote>&#xA;&#xA;<h3>Trying to run it locally</h3>&#xA;&#xA;<p>Since I couldn't get it to work on the cumulocity platform, I tried to run it locally via docker. I ran it with this command:<br>&#xA;<code>docker run -e ""C8Y_MICROSERVICE_ISOLATION=MULTI_TENANT"" 10aa0b73ddb3</code>  </p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>note</strong>: I had to add the ""C8Y_MICROSERVICE_ISOLATION=MULTI_TENANT"" <a href=""https://www.cumulocity.com/guides/reference/microservice-runtime/"" rel=""nofollow noreferrer"">environment variable</a>. if I didn't add this, I'd get credential/permission issues. This seems weird to me, since all other info is read from the <strong>application.properties</strong> file except for this one.</p>&#xA;</blockquote>&#xA;&#xA;<p>I have no errors when running this image on a local docker.  </p>&#xA;&#xA;<p>According to the <a href=""https://www.cumulocity.com/guides/java/java-microservice/"" rel=""nofollow noreferrer"">Hello, microservice tutorial</a>, I should be able to request   <code>curl -H ""Authorization: {AUTHORIZATION}"" https://myTenant.cumulocity.com/service/my-application-name/hello?who=me</code><br>&#xA;This returns:<br>&#xA;<code>{""error"":""microservice/Not Found"",""info"":""https://www.cumulocity.com/guides/reference-guide/#error_reporting"",""message"":""Microservice my-application-name not found.""}</code></p>&#xA;&#xA;<h2>Back to the questions</h2>&#xA;&#xA;<p>Has anyone else had difficulties with setting up a microservice on cumulocity?<br>&#xA;Is there something I'm totally overseeing?</p>&#xA;"
49683432,"How use apache kafka in vertx, both on the server side, as well as the client?",2018-04-06 00:21:19,<java><apache-kafka><microservices><vert.x>,1,113,0,0.0,0,"<p>I recently asked what was the best way to communicate my microservices in vertx, I did it in a way which was with a web client with the same library that provides vertx (it was very simple), however I have been reading that use apache kafka is better, but I do not know how to use it, I read the official documentation of kafka, but I could only create a producer and a consumer, I really do not know what to do with them, how can I from a microservice send a method to another miscroservice through kafka? Excuse my ignorance with the subject</p>&#xA;"
49793326,How to deploy microservices web application on Kubernetes?,2018-04-12 09:47:00,<web-applications><kubernetes><microservices><kubernetes-ingress>,1,136,0,1.0,0,"<p>I want to create a web application using Angular and microservices backend serving some REST api. Then I would like to deploy everything on Kubernetes. </p>&#xA;&#xA;<p>Lets say application will serve some drinks (Coffea and Tea). For the simplification lets assume that app is fully stateless and I want to 2 have microservices.</p>&#xA;&#xA;<p>Without Kubernetes I would do this in such a way:</p>&#xA;&#xA;<ol>&#xA;<li><p>Coffea service - rest API for /api/coffea endpoint</p></li>&#xA;<li><p>Tea service - rest API for /api/tea endpoint</p></li>&#xA;<li><p>Nginx - static contents with Angular app (HTML/CSS/JS/images etc.) and the gateway (proxy for /api/coffea and /api/tea endpoints)</p></li>&#xA;</ol>&#xA;&#xA;<p>Now the question is how to reflect this in Kubernetes? Would it be enough just to deploy everything in a several replicas, then expose Coffea and Tea services as a NodePort and finally expose Nginx as a LoadBalancer? Is this a right approach? Should I use Ingress instead of making my own nginx proxy? If yes, then how to serve static contents using Ingress Controller? </p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
49880941,Microservices in Docker Container,2018-04-17 14:36:09,<java><docker><kubernetes><microservices><spring-cloud>,2,174,0,0.0,0,"<p>I am using Spring Cloud for Creating Microservice Architecture.</p>&#xA;&#xA;<p>I was using the below feature from the Spring Cloud</p>&#xA;&#xA;<ul>&#xA;<li>Zuul â€“  API gateway service that provides dynamic routing, monitoring, resiliency, security, and more - </li>&#xA;<li>Ribbon â€“ Client side load balancer</li>&#xA;<li>Feign â€“ Declarative REST client</li>&#xA;<li>Eureka â€“ Service registration and discovery</li>&#xA;<li>Sleuth â€“ Distributed tracing via logs</li>&#xA;<li>Zipkin â€“ Distributed tracing system with request visualization.</li>&#xA;<li>Hystrix - Circuit Breaker, Fault Tolerance, Hystrix Dashboard for all API </li>&#xA;</ul>&#xA;&#xA;<p>Now Lets say if I have 100 microservices, then we need 100 servers to maintain each microservices. So I thought of using Kubernetes to solve this issue by  deploying each microservices in a separate docker container, so now since Kubernetes takes care of microserivice health check, autoscaling, load-balancing so do I need to again use Ribbon, Eureka and Zuul. </p>&#xA;&#xA;<p>Can anyone please help me on this</p>&#xA;"
49771449,How to get clients actual address in java,2018-04-11 09:30:31,<microservices><clientip>,1,13,1,0.0,0,<p>We have an application which runs on multiple microservice systems.Lets consider a scenario where client requests something from microservice1 and microservice1 invokes an API on microservice2. In this scenario I want to get clients_ip_address in microservice2. Is there a provision where I can get client_ip_address from request_header ?&#xA;Thanks&#xA;Srumith.</p>&#xA;
49709956,Can multiple Meteor Microservices be run in one galaxy container?,2018-04-07 17:19:01,<meteor><hosting><microservices>,1,43,1,0.0,0,<p>I'm developing microservices using Meteor and was wondering if there was a way to host multiple instances in one galaxy container?</p>&#xA;
49848942,Accessing a oauth2 secured service via WSO2 API Manager,2018-04-16 02:41:05,<spring-security><wso2><microservices>,1,32,2,0.0,0,"<p>I have a project in which there are several microservices which are secured using spring oauth2.I have published these services on WSO2 API Manager and disabled the oauth2 feature of WSO2 as my services are already secured using spring oauth2.Now when I access my services published on WSO2, using token of spring oauth2 i get in response either status code 0 ""no response"" or status code 403 unauthorized.What could be the issue here.</p>&#xA;"
49809651,AMQP (RabbitMQ) and passing data in work-flow situations to other consumers,2018-04-13 05:05:33,<rabbitmq><microservices><amqp>,1,44,2,0.0,0,"<p>I'm working with RabbitMQ 3.7, and I'm finding that my microservice architecture is starting to feel tangled and coupled.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/4TOde.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4TOde.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I'm finding that I'm <em>publishing messages from within my consumer's <code>received</code> event to other queues</em>. <strong>This feels wrong.</strong> But I'm not sure what the alternative is, since I benefit from the efficiency in passing the data from the consumer directly to the next queue/task.</p>&#xA;&#xA;<p><em>Note that the above is just an example, and the service I'm running are similar, and fairly work-flow dependent (although they can be ran independently!)</em></p>&#xA;&#xA;<p>Questions:</p>&#xA;&#xA;<ol>&#xA;<li><p>How is data normally passed from process to process (or consumer to publisher) in situations where the micro-services are fairly dependent on each other. Not that they can't be ran individually, but that they work best in a work-flow scenario?</p></li>&#xA;<li><p>If the solution involves <em>not</em> publishing new messages from within the <code>received</code> event of a consumer, then what is the proper way to get the data to that microservice/process?</p></li>&#xA;</ol>&#xA;"
49849813,Node js microservice,2018-04-16 04:49:43,<node.js><spring><microservices>,1,53,3,0.0,0,<p>Can anyone please tell how to consume a node js based microservice from spring based web application?can restful API be the best choice to be used by the application to message the microservices based on nodejs ?</p>&#xA;
49823345,What is the best way to host a MicroService .net core web api in Docker?,2018-04-13 18:41:49,<docker><asp.net-core><microservices>,1,384,3,0.0,0,<p>I have several micro services that I would like to dockerized them. Is it better to build them in a self-hosted console application or build asp.net web application?</p>&#xA;&#xA;<p>Which one is faster?</p>&#xA;&#xA;<p>My MicroServices are only simple Web Api.</p>&#xA;
49777963,How to best handle shared services using docker-compose for local development in microservice architecture?,2018-04-11 14:38:16,<docker><docker-compose><microservices>,1,110,4,0.0,0,"<p>Trying to set up an effective pattern that allows communication between all of my services and allows for local development on multiple services simultaneously. I am currently setting up local development for my application using docker compose. The basic idea of my <code>docker-compose.yml</code> looks something like this. </p>&#xA;&#xA;<pre><code>version: '3'&#xA;services:&#xA;  web: &#xA;    &lt;web_config&gt;&#xA;  worker:&#xA;    &lt;worker_config&gt;&#xA;  service-a:&#xA;</code></pre>&#xA;&#xA;<p>I'm questioning how to handle <code>service-a</code>. </p>&#xA;&#xA;<p><code>service-a</code> is required by any local applications I am running. So if I am running this application and another at the same time, they will both need to communicate with <code>service-a</code>. </p>&#xA;&#xA;<p>Should <code>service-a</code> be running in its own compose instance? If so, are <code>networks</code> the best way for all my apps to communicate with <code>service-a</code>? From my understanding, this used to be the job of <code>links</code>, but <code>networks</code> are now preferred. I have already tried running with <code>network_mode</code> host, but am running into issues, as I am using Docker for Mac. </p>&#xA;&#xA;<p>I've seen a lot of opinions and solutions out there, but I'm honestly unsure which of these approaches is best. Some of the solutions I've seen include:</p>&#xA;&#xA;<ul>&#xA;<li>creating a shared <code>network</code> for all my services and run them separately in their own docker composes</li>&#xA;<li>using <code>network_mode: 'host'</code> and run everything on my host (Sadly I couldn't get this working)</li>&#xA;<li>running a separate compose of all my shared services that all other services depend on</li>&#xA;</ul>&#xA;&#xA;<p>Let me know if you've run into this and have any advice to share, thanks!</p>&#xA;"
31801057,Microservices & Business Process Monitoring,2015-08-04 05:04:43,<activiti><bpmn><microservices>,2,515,0,0.0,0,"<p>If we move to a micro services architecture, how can we handle business process management? We are thinking of moving away from our monolith to a micro service based application. One of the challenges we face is monitoring the status of user tasks &amp; jeopardy management. How can we do this if we use micro services?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
31912285,Setting up artifactory for microservices,2015-08-10 05:39:57,<java><gradle><artifactory><microservices>,1,101,0,0.0,0,"<p>So I am currently building  multiple micro-services in Java using gradle. Lets say for example, I have 4 micro-services A, B, C and D. C is dependent on A and B &amp; D in dependent on A, B and C. Only C and D get released. </p>&#xA;&#xA;<p><strong>Today:</strong></p>&#xA;&#xA;<p>To build C, I clone A, B and C then I checkout out master branch in all 3 of them, cd to C, call ""gradle buildâ€, which builds A, B and C and then fetch the C.war in Jenkins. </p>&#xA;&#xA;<p><strong>Artifactory setup concerns:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Lets say I build A and B after every commit and push the jars to  artifactory. Now, when there is a change in C it picks up the latest of A and B from artifactory and builds C. I then push C.war to artifactory. </li>&#xA;<li>Lets say there is a change in B related to D, and now I have to build D. First, B gets rebuilt and pushed to artifactory. C, which is dependent on A and B, doesnâ€™t get rebuild. D takes A, B and C from artifactory and builds D.war and gets pushed to artifactory.</li>&#xA;<li>Is this OKAY i.e. C being built with  v1 (version 1) of A and B &amp; D gets built with v1 of A, v2 of B and v1 of C ?? </li>&#xA;<li>If not, then what is the standard practice of using artifactory for micro-services ? </li>&#xA;<li>How to manage micro-services across multiple branches ? </li>&#xA;<li>How to manage released versions from dev versions ? </li>&#xA;</ul>&#xA;&#xA;<p>Please let me know how to approach. </p>&#xA;&#xA;<p>Thanks...</p>&#xA;"
31412249,Gateway API vs Frontend Service,2015-07-14 16:26:16,<ajax><microservices>,1,338,0,0.0,0,"<p>I'm struggling in what would be a better approach for a project I'm working on.&#xA;I'm working on a micro-service based SaaS where I have several services for some functionality, each one with its own REST APIs.&#xA;My dilemma right now is whether to:</p>&#xA;&#xA;<ol>&#xA;<li>Include my frontend UI in a gateway service that will provide both UI and business logic that will proxy requests to other services.</li>&#xA;<li>Have a service that will only allow the user access to the UI while all content will be retrieved via AJAX directly with the different services.</li>&#xA;</ol>&#xA;&#xA;<p>Thoughts?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
31468806,Identity management with multiple spring boot micro services,2015-07-17 05:17:05,<spring><spring-boot><single-sign-on><microservices><identity-management>,2,918,1,0.0,0,"<p>I have multiple spring boot applications for difference purposes. &#xA;For example, mobile clients send their GPS coordinates to one spring boot micro service and at the same time, these mobile client access another spring boot micro service to do their CRUD operations. </p>&#xA;&#xA;<p>I'm facing with a problem of authenticating clients. I don't want do the authentication at all the services. Rather I would like to do this by using another identity management server (ex: Kerberos)  which produce a SSO token for all these micro services.</p>&#xA;&#xA;<p>OR a proxy which authenticates all the incoming requests and delegates them to relevant micro service.</p>&#xA;&#xA;<p>I searched couple of hours and I couldn't find any solid information on securing micro services even in general.</p>&#xA;&#xA;<ol>&#xA;<li>The design or architecture I'm taking is correct? </li>&#xA;<li>What is the best approach for this kind of a situation?</li>&#xA;<li>How can I implement this identity server/proxy who does the authentication?</li>&#xA;<li>Any technology, known identity mgmt servers which can easily integrate with Spring, known design patterns are there?</li>&#xA;</ol>&#xA;&#xA;<p>One question more,&#xA;It is OK to implement same authentication layer at each of these services?&#xA;(Because I think it is bad and I may wrong with that)</p>&#xA;&#xA;<p>I would like to stick with Spring.</p>&#xA;&#xA;<p>Highly appreciate if someone can direct me to a correct path.</p>&#xA;"
48966893,The Registration process in microservices architecture,2018-02-24 19:46:08,<microservices>,1,41,0,0.0,0,"<p>Chris Richardson mentioned in his <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow noreferrer"">article</a> ""3rd-party-registration"":</p>&#xA;&#xA;<p><em>""The 3rd party registrar might only have <strong>superficial knowledge</strong> of the state of the service instance, e.g. RUNNING or NOT RUNNING and so might not know whether it can handle requests.""</em></p>&#xA;&#xA;<p>But what this really means? What <strong>information</strong> does a microservice send to the registrar when it starts? Why is the registrar not able to know information about the service and its location?</p>&#xA;"
48840474,Spring batch executing stor proc conditionally,2018-02-17 10:45:43,<java><sql><spring><spring-batch><microservices>,1,53,0,0.0,0,"<p>In my Spring Batch Application, I am reading, processing and then trying to write with a ItemWriter to the database using <code>stored procedure</code>:</p>&#xA;&#xA;<p>Below is what my CSV file looks like lets say which I want to read, process and write:</p>&#xA;&#xA;<pre><code>Cob Date;Customer Code;Identifer1;Identifier2;Price&#xA;20180123;ABC LTD;BFSTACK;1231.CZ;102.00&#xA;</code></pre>&#xA;&#xA;<p>My <code>ItemWriter</code>:</p>&#xA;&#xA;<pre><code>@Slf4j&#xA;public class MyDBWriter implements ItemWriter&lt;Entity&gt; {&#xA;&#xA;    private final EntityDAO scpDao;&#xA;&#xA;    public MyWriter(EntityDAO scpDao) {&#xA;        this.scpDao = scpDao;&#xA;    }&#xA;&#xA;    @Override&#xA;    public void write(List&lt;? extends Entity&gt; items) {&#xA;        items.forEach(scpDao::insertData);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My DAO implementation:</p>&#xA;&#xA;<pre><code>@Repository&#xA;public class EntityDAOImpl implements EntityDAO {&#xA;&#xA;    @Autowired&#xA;    private JdbcTemplate jdbcTemplate;&#xA;&#xA;    private SimpleJdbcCall simpleJdbcCall = null;&#xA;&#xA;&#xA;    @PostConstruct&#xA;    private void prepareStoredProcedure() { &#xA;        simpleJdbcCall = new SimpleJdbcCall(jdbcTemplate).withProcedureName(""loadPrice"");&#xA;        //declare params&#xA;    }&#xA;&#xA;    @Override&#xA;    public void insertData(Entity scp) {&#xA;&#xA;        Map&lt;String, Object&gt; inParams = new HashMap&lt;&gt;();&#xA;&#xA;        inParams.put(""Identifier1"", scp.getIdentifier1());&#xA;        inParams.put(""Identifier2"", scp.getIdentifier1());&#xA;        inParams.put(""ClosingPrice"", scp.getClosingPrice());&#xA;        inParams.put(""DownloadDate"", scp.getDownloadDate());&#xA;&#xA;        simpleJdbcCall.execute(inParams);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My Stored procedure used to update is as follows:</p>&#xA;&#xA;<pre><code>ALTER PROCEDURE [dbo].[loadPrice]&#xA;@Identifier1 VARCHAR(50),&#xA;@Identifier1  VARCHAR(50),&#xA;@ClosingPrice decimal(28,4),&#xA;@DownloadDate datetime&#xA;&#xA;AS&#xA; SET NOCOUNT ON;&#xA;&#xA;UPDATE p&#xA;SET ClosingPrice = @ClosingPrice,&#xA;from Prices p&#xA;join Instrument s on s.SecurityID = p.SecurityID&#xA;WHERE convert(date, @DownloadDate) = convert(date, DownloadDate)&#xA;    and s.Identifier1 = @Identifier1&#xA;&#xA;&#xA;if @@ROWCOUNT = 0&#xA;    INSERT INTO dbo.Prices&#xA;    (&#xA;        sec.SecurityID&#xA;        , ClosingPrice&#xA;        , DownloadDate&#xA;    )&#xA;    select sec.SecurityID&#xA;        , @ClosingPrice&#xA;        , LEFT(CONVERT(VARCHAR, @DownloadDate, 112), 8)&#xA;    from dbo.Instrument sec&#xA;    WHERE sec.Identifier1 = @Identifier1&#xA;</code></pre>&#xA;&#xA;<p>Give I have this setup, one of my requirement is that if I am unable to update/insert to the database using <code>@Identifier1</code> i.e. there is no <code>SecurityID</code> which matched with <code>Identifier1</code>, I need to THEN update/insert &#xA;using the <code>Identifier2</code>. Second level match if you like. </p>&#xA;&#xA;<p>How can I do this in my DAO <code>insertData()</code>? It is business logic and prefer in java code instead of stored proc but I am keen to look at your examples how this can be achieved. </p>&#xA;&#xA;<p>How can I return a result of a row being updated/inserted and take decision as to whether or not to update/insert with second identifier? </p>&#xA;"
48850386,Containarize spring booot microservices,2018-02-18 09:55:54,<docker><spring-boot><docker-compose><containers><microservices>,1,85,0,0.0,0,"<p>For a project i'm trying to put my microservices inside a container. &#xA;Right now I can succesfully put a jar file inside a docker container and run it.&#xA;I know how docker images and containers work. But Im very new on microservices, a friend of me asked to put his spring boot microservices in a docker environment. Right now this is my plan.&#xA;Put every microservice inside 1 container , manage them with docker compose so that you can run and config them at the same time. And maybe later put some high availibility in it with docker compose scale or try something out with Docker swarm. </p>&#xA;&#xA;<p>My question now is how do you put one service inside a container. Do you create a jar /war file from a service put that inside a container with the expose port you are working with inside your service ?</p>&#xA;&#xA;<p>For my testjar file (a simple hello world i found online) i used this dockerfile</p>&#xA;&#xA;<pre><code>FROM openjdk:8&#xA;ADD /jarfiles/test.jar test.jar&#xA;EXPOSE 8080&#xA;ENTRYPOINT [""java"", ""-jar"" , ""test.jar""]&#xA;</code></pre>&#xA;"
48962157,register postgres with eureka with out docker image,2018-02-24 11:08:44,<database><postgresql><spring-boot><microservices><eureka>,2,102,0,0.0,0,"<p>How to register a database server like a ""PostgreSQL"" or any other sql database with eureka server and use it in spring boot micro service?</p>&#xA;"
48983199,Mock the dependent microservices for testing the performance of another microservice,2018-02-26 07:13:55,<spring-boot><performance-testing><microservices><jhipster-registry>,1,125,0,0.0,0,<p>I am working on setting up the environment for testing the performance of a microservice A.This microservice A has dependency to another micro service B.Both the microservices are registered in JHipster Registry and Rippon client is used for communicating between microservices(A &amp; B).How do I mock the dependent micro service so that I don't need to hit that real microservice B?</p>&#xA;
48949396,SaaS implementation with Micro-services,2018-02-23 13:53:03,<microservices>,1,138,0,0.0,0,"<p>I'm trying to build a web-based SaaS solution in ASP.NET Core 2.0, with the help of micro-services architecture, token based authentication and service will be hosted on Docker. Each client has its own users, product and other details with multiple databases with shared schema. Each micro-service has its own database (Schema-per-service).</p>&#xA;&#xA;<p>I hit a roadblock where I need to locate logged in userâ€™s database credentials (connection string), so that database connection will be passed dynamically to respective micro-service to fetch data from respective client database? </p>&#xA;"
49000291,Separating Microservices - Excel Generation,2018-02-27 02:43:33,<java><excel><design><responsive-design><microservices>,2,144,0,0.0,0,"<p>In our application , in one of  our microservice we will query the DB , get the result ( 100k rows ) and generate Excel using Apache POI.In couple of other services they also does the same process ( get DB rows and generate excel) . Here Excel generation process is common , IS this right design to separate this excel generation process as separate micorservice and use in all other services ?&#xA;The challenge is passing the data ( 100k rows ) between microservices over HTTP .&#xA;How can we achieve it ? </p>&#xA;"
48912603,Use Kafka to increase resilience of a new service,2018-02-21 18:03:27,<apache-kafka><microservices><cqrs>,1,150,0,0.0,0,"<p>I am working in a project that starts creating independent deployable services. The service we are creating should be resilient with an 24/7 uptime.</p>&#xA;&#xA;<p>Some devs already created a concept regarding what technologies to use. To make sure that the service is always available Kafka should be used. For example there should be a simple application/serverless function that adds something to an collection of items. The thin layer should create a Kafka message that will be processed by the real application later on.</p>&#xA;&#xA;<p>In the beginning this approach sound odd to me. Kafka is something to communicate between systems. But is it good to split applications even more to increase resilience for a bounded context? I guess not I thought. Because by using modern technologies the application can be very resilient. Therefore we can just create one application instead of adding a lot more complexity.</p>&#xA;&#xA;<p>Later I understood that this approach is a CQRS like approach. By creating an application that receives the writes it will be completely separated from the reads. In this case Kafka will be used as an event system. It should maybe not delete old messages but however, I want to understand if this is a good way to go and if I am getting the things right.</p>&#xA;&#xA;<p>What do you think about the requirements and the usage of Kafka to get a highly available and resilient application?</p>&#xA;"
48980066,Storing the session token in AWS Lambda function?,2018-02-26 00:51:40,<amazon-web-services><lambda><microservices>,1,179,0,0.0,0,<p>I have a AWS Lambda function which need to talk to an external REST API. The external API needs a session token with every request.</p>&#xA;&#xA;<p>I generate session token using client id and secret and then i use the session token with further requests to the external REST API. </p>&#xA;&#xA;<p>I am currently storing the session token in mongodb (to persist data during lambda restarts) and retrieving it every time i need it. I think this is not the best way. what is the best / recommended way ?</p>&#xA;
49013500,OAuth 2.0 Flows for Microservice Architectures,2018-02-27 16:31:08,<oauth-2.0><authorization><microservices><auth0>,3,248,0,0.0,0,"<p>I'm trying to understand how to best apply the OAuth 2.0 grant types to a microservice architecture I am working on. Here's the situatation...</p>&#xA;&#xA;<p>I have a Single-Page Application/Mobile App acting as a client running in a web browser (browser acting as the user agent) or mobile phone. I use the <strong>Implicit Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.2"" rel=""nofollow noreferrer"">RFC 6749, section 4.1</a> to authenticate a user and acquire an access token that the app uses to access some externally exposed API.</p>&#xA;&#xA;<p>The architecture I am dealing with is a collection of microservices that call on one another. For example, consider an externally exposed API <code>serviceA</code> and internal APIs <code>serviceB</code> and <code>serviceC</code>. Let's say <code>serviceA</code> depends on <code>serviceB</code> which subsequently depends on <code>serviceC</code> (<code>A</code> --> <code>B</code> --> <code>C</code>). </p>&#xA;&#xA;<p>My question is, what is the typical authorization flow for this situation? Is it standard to use Implicit Grant for the SPA to acquire an access token and then use the <strong>Client Credentials Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.4"" rel=""nofollow noreferrer"">RFC 6749, section 4.4</a> to acquire an access token for the machine to machine interaction between <code>serviceB</code> and <code>serviceC</code>?</p>&#xA;"
49021899,How to handle Facade in feature by package structure,2018-02-28 04:17:41,<spring><spring-boot><design-patterns><microservices>,1,25,1,0.0,0,<p>How can I structure my project if I have a facade?</p>&#xA;&#xA;<p>The controller will call the facade to call the class in another package and the self package?</p>&#xA;&#xA;<p>Like:</p>&#xA;&#xA;<pre><code>feature/&#xA;â”œâ”€â”€ order/&#xA;â”‚   â”œâ”€â”€ OrderController &lt;== here calls Facade&#xA;â”‚   â”œâ”€â”€ OrderService&#xA;â””â”€â”€ facade/&#xA;â”‚   â”œâ”€â”€ CheckoutFacade &lt;== here calls orderService(go to facade and back to self package) and personService &#xA;â””â”€â”€ person/&#xA;    â””â”€â”€ PersonService&#xA;</code></pre>&#xA;&#xA;<p>Should I create a controller package separately of feature?</p>&#xA;
48925813,Object Building across Micro services,2018-02-22 11:03:48,<java><oop><domain-driven-design><microservices><soa>,2,50,1,1.0,0,"<p>We have three micro services MSA, MSB and MSC. The micro service MSA creates a partial object O1 and sends to MSB only through a dedicated message topic. After receiving the partial object O1 from MSA, MSB populates few more attributes in O1 and shares in the common message bus from which MSC consumes the object O1.</p>&#xA;&#xA;<p>Question is that, is this a good approach where the object building is shared across multiple micro services?</p>&#xA;"
48835919,Service Fabric - How to reserve or protect my hardcoded Port,2018-02-16 22:46:00,<microservices><azure-service-fabric><service-fabric><service-fabric-on-premises>,1,59,1,0.0,0,"<p><strong>Landscape:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>We have an Application with two micro services.  </p>&#xA;&#xA;<p>Micro Service A is used to expose the application outside the cluster (our web server)</p>&#xA;&#xA;<p>Micro Service B is our business functionality.</p></li>&#xA;<li><p>We have an F5 in front of Micro Service A to handle the load balancing over the hard coded Ports(onPrem).   </p></li>&#xA;<li>Inside Micro Service A we are hard coding specific ports for the http endpoint in the manifest.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Problem:</strong>&#xA;We witness it is possible that sometimes Micro Service B (Business functionality) will steal the port that Micro Service A is hard coded to use.  Then it will never start the service correctly.</p>&#xA;&#xA;<p>We also see that SF seems to use the available ports sequentially.  So If we hard coded Micro Service A to use port 001 and the Micro Service B to be random.  When A got restarted sometimes B would grab 001.</p>&#xA;&#xA;<p><strong>Possible Solutions:</strong></p>&#xA;&#xA;<ol>&#xA;<li>We could hard code all Micro Services - Don't like it.</li>&#xA;<li>We could reserve the higher range for these hard coded ports.  For example if Service Fabric uses 1000 ports we can keep 501-1000 for Service A and let Service B grab 001-499.  This only delays the issues until you have more than 500 instances. - Not a big fan of this either.</li>&#xA;<li>Hard code the port to be a port that is outside of the range of the cluster?  For example if we used 20001-20500 as the ApplicationEndpointsÂ range when setting up the cluster, if we hard code MicroService A to user 21000 it seems to work?  I""m not sure what unintended consequences that could create? </li>&#xA;</ol>&#xA;&#xA;<p>Please give me a great option 4 :)</p>&#xA;&#xA;<p>Thanks, </p>&#xA;&#xA;<p>Greg</p>&#xA;"
48934158,Spring boot/cloud microservices on AWS,2018-02-22 17:53:57,<amazon-web-services><spring-boot><microservices><netflix>,2,325,1,0.0,0,"<p>I have created a Spring cloud microservices based application with netflix APIs (Eureka, config, zuul etc). can some one explain me how to deploy that on AWS? I am very new to AWS. I have to deploy development instance of my application.</p>&#xA;&#xA;<p>Do I need to integrate docker before that or I can go ahead without docker as well.   </p>&#xA;"
49019203,Coordinating dependent microservices in java,2018-02-27 22:47:03,<java><design><microservices><orchestration>,2,78,1,0.0,0,"<p>I have to coordinate 5 separate microservices e.g. A,B,C,D,E</p>&#xA;&#xA;<p>I need to create a coordinator which might monitor a queue for new jobs for A. If A completes ok then a rest request should be sent to B then if everything is ok (happy path) then C is called all the way down to E.</p>&#xA;&#xA;<p>However B,C etc might fail for one reason or another e.g. end point is down or credentials are insufficient causing the flow to fail at a particular stage. I'd like to be able to create something that could check the status of failed job and rerun again e.g. lets try B again, ok now it works the flow would then continue.</p>&#xA;&#xA;<p>Any tips or advice for patterns / frameworks to do this. I'd like something fairly simple and not over complex.</p>&#xA;&#xA;<p>I've already looked briefly at Netflix Conductor / Camunda but ideally I'd like something a bit less complex.</p>&#xA;&#xA;<p>Thanks&#xA;W</p>&#xA;"
48971368,"Microservices, complete case study example",2018-02-25 07:47:32,<transactions><microservices><distributed-computing><soa>,1,178,1,0.0,0,"<p>I have read a lot of theory about microservices, pros and cons of the approach, architectural guidelines and most common pitfalls. I have read <a href=""https://rads.stackoverflow.com/amzn/click/1491950358"" rel=""nofollow noreferrer"">Building Microservices</a> by Sam Newman, which gives a good theoretical overview of the subject, and have read a lot of blog posts and studied patterns and principles.</p>&#xA;&#xA;<p>However, there is a lot to digest and I'm missing a concrete example how to put everything together in practice. Getting the realization of it's potency. I don't think building such a system myself would be a good idea to learn at this point, as the entitlement for the architecture originates from the real need. Forcing it could make more harm than good (over-engineering), and such is not a good way to learn.</p>&#xA;&#xA;<p>So, is there some detailed case study of designing and implementing Microservices architecture with concrete pattern implementations?</p>&#xA;"
48949794,How does Lagom Framework implement ES and CQRS (Scala)?,2018-02-23 14:13:16,<scala><microservices><cqrs><lagom>,1,122,2,0.0,0,"<p>I'm fairly new to Lagom and trying to build my web project, I have already downloaded the sample projects given in the website (specifically Chirper &amp; Auction),  but I've been stuck in ES and CQRS since a week, can someone share some knowledge, that you had, while working on it or even a sample project demonstrating it would really help. I have understood the lagom and microservice structure, but do not understand how ES and CQRS is implemented in it, like the Commands,Event Processors and the state. &#xA;I'm sorry for being a little vague on the question I'm asking, but any developers who have worked in it, if could share some light, on how they started. Books, references and sample projects are highly welcomed.</p>&#xA;&#xA;<p>p.s I have already gone through maybe 70% of the documentation in their official page, but a need a little more clarity.&#xA;Thank you in advance.</p>&#xA;"
48863771,Failure while calling a microservice via ribbon enabled client(Without eureka service discovery),2018-02-19 10:11:34,<java><microservices><netflix-ribbon>,2,141,2,0.0,0,"<p>I am trying to call a 'microservice'(microservice-producer) via ribbon enabled the client(ribbon-client) but it is giving me an error.</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: No instances available for employee-microservice</p>&#xA;</blockquote>&#xA;&#xA;<p>I am following the official spring.io link for the client side load balancing(<a href=""https://spring.io/guides/gs/client-side-load-balancing/"" rel=""nofollow noreferrer"">https://spring.io/guides/gs/client-side-load-balancing/</a>) and I am also following all the specification given at this link. &#xA;You can see the code at my GitHub address :&#xA; (<a href=""https://github.com/vickygupta0017/microservice-ribbon"" rel=""nofollow noreferrer"">https://github.com/vickygupta0017/microservice-ribbon</a>).</p>&#xA;&#xA;<p>I am not sure what I am missing or doing wrong, could someone please help me out?</p>&#xA;"
48956086,Patterns to segregate Models and DbContext on ASP.NET Core microservices,2018-02-23 20:55:05,<design-patterns><asp.net-core><.net-core><microservices><ef-core-2.0>,1,79,3,0.0,0,"<p>I'm trying to make my services to deploy individually without depending on each other.</p>&#xA;&#xA;<p>All services will be using the same SQL database using EF Core (same DbContext).</p>&#xA;&#xA;<p>I'm using a separate project (MyServices.Data) that has all my models and the DbContext, but I'm really dependent on this and if there is any change on this Data project, all services needs to be redeployed.</p>&#xA;&#xA;<p>Is there any pattern/approach to this situation so I can have my project not dependant on it?</p>&#xA;"
30583466,"What is the best way to implement a fast, scalable statistics aggregation architecture?",2015-06-01 21:18:27,<design-patterns><architecture><distributed><microservices>,2,153,0,0.0,0,"<p><strong>The problem:</strong></p>&#xA;&#xA;<p>When displaying user statistics in our e-commerce website (e.g: sales/shopping analytics, etcâ€¦) we use a fan-in approach:  certain flows in the system trigger an event to a rabbit worker, which aggregates statistics per user in MongoDB, so that most of the calculations are done upon insert and retrieving statistics for display is trivial and very lightweight.</p>&#xA;&#xA;<p>When an event isnâ€™t received in the worker, the counters start to â€˜drift awayâ€™ from the true MySQL count.</p>&#xA;&#xA;<p>counters may drift due to:</p>&#xA;&#xA;<ul>&#xA;<li>Service outages</li>&#xA;<li>Bugs</li>&#xA;<li>Multiple-workers synchronisations (2 workers can update the same document, so updates must be atomic, like mongoâ€™s â€˜incâ€™)</li>&#xA;</ul>&#xA;&#xA;<p>As the number of users/orders/messages/etc keeps growing, doing MySQL counts and joins to calculate these stats on-the-fly becomes less and less scalable. So we canâ€™t do that.&#xA;Thatâ€™s why we chose the fan-in approach to begin with.</p>&#xA;&#xA;<p>What is the best solution to overcome these ""drifts away"" in a robust and scalable way?</p>&#xA;"
30613574,Data sharing with microservices,2015-06-03 07:31:09,<microservices>,1,416,1,0.0,0,"<p>I am implementing an event-driven microservice architecture. Imagine the following scenario:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Chat service</strong>: Ability to see conversations and send messages. Conversations can have multiple participants.</li>&#xA;<li><strong>Registration-login service</strong>: Deals with the registration of new users, and login.</li>&#xA;<li><strong>User service</strong>: Getting/updating user profiles.</li>&#xA;</ul>&#xA;&#xA;<p>The registration-login service emits the following event with the newly created user object:&#xA;<code>registration-new</code>&#xA;<code>login-success</code>&#xA;<code>logout-success</code></p>&#xA;&#xA;<p>The chat service then listens on <code>registration-new</code> and stores some fields of user in its own redis cache. It also listens on <code>login-success</code> and stores the token, and on <code>logout-success</code> to delete the token.</p>&#xA;&#xA;<p>The user service has the following event: <code>user-updated</code>. When this is fired, a listener in the chat service updates the data corresponding to the user id in redis. Like the chat service, the user service also listens on <code>login-success</code> and <code>logout-success</code> and does the same thing as what the chat service does.</p>&#xA;&#xA;<p>My question is the following: is this a good way to do this? It feels a bit counterintuitive to be sharing data everywhere. I need some advice on this. Thank you!</p>&#xA;"
30991404,Spray microservice assembly deduplicate,2015-06-22 23:13:55,<scala><sbt><akka><spray><microservices>,1,171,0,0.0,0,"<p>I'm using this template to develop a microservice:</p>&#xA;&#xA;<p><a href=""http://www.typesafe.com/activator/template/activator-service-container-tutorial"" rel=""nofollow"">http://www.typesafe.com/activator/template/activator-service-container-tutorial</a></p>&#xA;&#xA;<p>My sbt file is like this:</p>&#xA;&#xA;<pre><code>import sbt._&#xA;import Keys._&#xA;&#xA;name := ""activator-service-container-tutorial""&#xA;&#xA;version := ""1.0.1""&#xA;&#xA;scalaVersion := ""2.11.6""&#xA;crossScalaVersions := Seq(""2.10.5"", ""2.11.6"")&#xA;&#xA;resolvers += ""Scalaz Bintray Repo"" at ""https://dl.bintray.com/scalaz/releases""&#xA;&#xA;libraryDependencies ++= {&#xA;&#xA;    val containerVersion    = ""1.0.1""&#xA;  val configVersion     = ""1.2.1""&#xA;  val akkaVersion           = ""2.3.9""&#xA;  val liftVersion               = ""2.6.2""&#xA;  val sprayVersion          = ""1.3.3""&#xA;&#xA;  Seq(&#xA;    ""com.github.vonnagy""    %%  ""service-container"" % containerVersion,&#xA;    ""com.github.vonnagy""    %%  ""service-container-metrics-reporting"" % containerVersion,&#xA;    ""com.typesafe""        %   ""config""                   % configVersion,&#xA;    ""com.typesafe.akka""     %%  ""akka-actor""                 % akkaVersion exclude (""org.scala-lang"" , ""scala-library""),&#xA;    ""com.typesafe.akka""     %%  ""akka-slf4j""                 % akkaVersion exclude (""org.slf4j"", ""slf4j-api"") exclude (""org.scala-lang"" , ""scala-library""),&#xA;    ""ch.qos.logback""            %   ""logback-classic""        % ""1.1.3"",&#xA;    ""io.spray""                      %%  ""spray-can""                  % sprayVersion,&#xA;    ""io.spray""                      %%  ""spray-routing""          % sprayVersion,&#xA;    ""net.liftweb""               %%  ""lift-json""                  % liftVersion,&#xA;&#xA;    ""com.typesafe.akka""     %%  ""akka-testkit""           % akkaVersion   % ""test"",&#xA;    ""io.spray""            %%  ""spray-testkit""      % sprayVersion  % ""test"",&#xA;    ""junit""               %   ""junit""              % ""4.12""        % ""test"",&#xA;    ""org.scalaz.stream""   %%  ""scalaz-stream""      % ""0.7a""        % ""test"",&#xA;    ""org.specs2""          %%  ""specs2-core""        % ""3.5""         % ""test"",&#xA;    ""org.specs2""          %%  ""specs2-mock""        % ""3.5""         % ""test"",&#xA;    ""com.twitter""         %% ""finagle-http""        % ""6.25.0"",&#xA;    ""com.twitter""         %% ""bijection-util""      % ""0.7.2""&#xA;  )&#xA;}&#xA;&#xA;scalacOptions ++= Seq(&#xA;  ""-unchecked"",&#xA;  ""-deprecation"",&#xA;  ""-Xlint"",&#xA;  ""-Ywarn-dead-code"",&#xA;  ""-language:_"",&#xA;  ""-target:jvm-1.7"",&#xA;  ""-encoding"", ""UTF-8""&#xA;)&#xA;&#xA;crossPaths := false&#xA;&#xA;parallelExecution in Test := false&#xA;&#xA;&#xA;assemblyJarName in assembly := ""santo.jar""&#xA;mainClass in assembly := Some(""Service"")&#xA;</code></pre>&#xA;&#xA;<p>The project compiles fine!&#xA;But when I run assembly, the terminal show me this:</p>&#xA;&#xA;<pre><code>[error] (*:assembly) deduplicate: different file contents found in the following:&#xA;[error] /path/.ivy2/cache/io.dropwizard.metrics/metrics-core/bundles/metrics-core-3.1.1.jar:com/codahale/metrics/ConsoleReporter$1.class&#xA;[error] /path/.ivy2/cache/com.codahale.metrics/metrics-core/bundles/metrics-core-3.0.1.jar:com/codahale/metrics/ConsoleReporter$1.class&#xA;</code></pre>&#xA;&#xA;<p>What options do I have to fix it?&#xA;Thanks</p>&#xA;"
30910817,Keep microservices data consistent,2015-06-18 08:57:44,<rabbitmq><zeromq><masstransit><microservices>,1,394,1,1.0,0,"<p>Our current project is based on a microservices architecture. So far so good, but we started to approach a way to keep all of them in a consistent state in terms of data.</p>&#xA;&#xA;<p>Basically we split them according to our main entities in the solution. Those entities can work independently quite well but there's still some dependencies between them, which involves update a set of microservices when an entity from another microservice is modified.</p>&#xA;&#xA;<p>We tried to tackle this challenge through different routes. &#xA;At first, we considered rabbitmq to be a good solution for this problem: a microservice sends a message with the change information to an exchange that fan outs it to the consuming microservices queues. Something like this:</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/jMwO8.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>It seems a good solution, but we are a little bit worried about the data consistency if an error arises in any of the consumers: we would need to implement a strategy for reverting back those changes across all the consuming microservices. Also were considering a brokerless technology such as ZeroMq that could do the same trick without having the broker bottleneck.</p>&#xA;&#xA;<p>We also thought of masstransit routing slip pattern implementation as a possible solution, so we could compensate all these errors in an easy way, but we are not that fond of having a sequential set of activities consuming these changes. We rather have the same approach we got on rabbitmq, where consumers are working in a more parallel way.</p>&#xA;&#xA;<p>So right now we are in kinda of an impasse and we were wondering what other developers have chosen as a solution for this problem.&#xA;We don't discard other technologies if those get to solve this issue.</p>&#xA;"
30800908,Dropwizard Jersey Client Sample,2015-06-12 10:32:45,<jersey><dropwizard><microservices>,2,1941,3,0.0,0,"<p>Dropwizard <strong><a href=""http://www.dropwizard.io/manual/client.html"" rel=""nofollow"">official documentation</a></strong> jersey Client isn't testable, someone have a dropwizard jersey client sample?</p>&#xA;"
29148547,Spring Security OAuth2 AuthorizationServer,2015-03-19 15:22:41,<spring-security><spring-security-oauth2><microservices>,1,854,0,0.0,0,"<p>I'm playing around with spring-security-oauth2. I try to build some microservices with an authentication backend. </p>&#xA;&#xA;<p>I set up an simple spring boot project with the following dependencies</p>&#xA;&#xA;<pre><code>    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.2.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>and one Configuration Class</p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class SecurityConfiguration {&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""clientDetailsServiceBean"")&#xA;    private ClientDetailsService clientDetailsService;&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""userDetailsServiceBean"")&#xA;    private UserDetailsService userDetailsService;&#xA;&#xA;    @Configuration&#xA;    @EnableWebSecurity&#xA;    @EnableGlobalMethodSecurity(jsr250Enabled = true, securedEnabled = true, prePostEnabled = true)&#xA;    public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {&#xA;&#xA;        @Override&#xA;        @Bean(name = ""authenticationManagerBean"")&#xA;        public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;            return super.authenticationManagerBean();&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;            auth.userDetailsService(userDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(HttpSecurity http) throws Exception {&#xA;            http.authorizeRequests().anyRequest().permitAll().and().userDetailsService(userDetailsService).formLogin().and().httpBasic();&#xA;        }&#xA;    }&#xA;&#xA;    @Configuration&#xA;    @EnableAuthorizationServer&#xA;    public class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;        @Autowired&#xA;        @Qualifier(""authenticationManagerBean"")&#xA;        private AuthenticationManager authenticationManager;&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;            endpoints.authenticationManager(authenticationManager).tokenStore(tokenStore());&#xA;        }&#xA;&#xA;        @Bean&#xA;        public ApprovalStore approvalStore() throws Exception {&#xA;            TokenApprovalStore store = new TokenApprovalStore();&#xA;            store.setTokenStore(tokenStore());&#xA;            return store;&#xA;        }&#xA;&#xA;        @Bean&#xA;        public TokenStore tokenStore() {&#xA;            return new InMemoryTokenStore();&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;            clients.withClientDetails(clientDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {&#xA;            security.checkTokenAccess(""permitAll()"");&#xA;            security.allowFormAuthenticationForClients();&#xA;        }&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>My Implementation of Client- and UserDetailsService are very simple and always returns an object</p>&#xA;&#xA;<pre><code>@Service(""clientDetailsServiceBean"")&#xA;public class ClientDetailsServiceBean implements ClientDetailsService {&#xA;&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(ClientDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public ClientDetails loadClientByClientId(String clientId) throws ClientRegistrationException {&#xA;        LOGGER.info(""Load client {}"", clientId); &#xA;        BaseClientDetails details = new BaseClientDetails();&#xA;        details.setClientId(clientId);&#xA;        details.setAuthorizedGrantTypes(Arrays.asList(""password"", ""refresh_token"", ""client_credentials""));&#xA;        details.setScope(Arrays.asList(""trust""));&#xA;        details.setAutoApproveScopes(Arrays.asList(""trust""));&#xA;        details.setAuthorities(Arrays.asList(new SimpleGrantedAuthority(""client_role2"")));&#xA;        details.setResourceIds(Arrays.asList(""clients""));&#xA;        details.setClientSecret(""secret"");&#xA;&#xA;        return details;&#xA;    }&#xA;&#xA;}&#xA;@Service(""userDetailsServiceBean"")&#xA;public class UserDetailsServiceBean implements UserDetailsService {&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(UserDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {&#xA;        LOGGER.info(""Load user {}"", username);&#xA;        return new User(username, ""password"", Arrays.asList(new SimpleGrantedAuthority(""ROLE_USER"")) );&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But, when i try to receive an accessToken via</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Full authentication is required to access this resource"" and when i try</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret --user web_client:secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Bad credentials"". From my point of view both should work, but it seems like my configuration is missing. </p>&#xA;&#xA;<p>There are other things with OAuth that unclear to me:&#xA;I try to build an spring-mvc application with spring-security and a custom login form. It's possible to handle token request and refresh cycles by spring security without redirect to the authentication app?</p>&#xA;&#xA;<p>In case of event driven application, it's possible to ensure the token is valid? In case of failure, the user clicks on button and an event is written but the processing of this will be hours later. How can i process the event with the user credentials?</p>&#xA;"
28581644,Protect Kafka against flood,2015-02-18 10:45:27,<security><apache-kafka><microservices>,3,174,0,0.0,0,"<p>I use Kafka in production. Many services send and read messages into it.</p>&#xA;&#xA;<p>All work fine but I had a bug in one service.&#xA;For a weird reason this one sends millions messages by second to Kafka.</p>&#xA;&#xA;<p>Due to this bug, my Kafka crashes.</p>&#xA;&#xA;<p>It's not a Kafka bug but how can I protect it against potential flood ?</p>&#xA;"
28565187,add a custom service for Meteor.loginWith<ExternalService>,2015-02-17 15:38:47,<meteor><microservices>,1,441,0,0.0,0,"<p>In my application architecture, I have a separate login service (REST API) which handles all user login/account related functionalities like creating user, authentication etc.&#xA;Right now on valid login I'm setting the appropriate session variables but these seems to be a bad approach. &#xA;Is there any way to create a custom service for</p>&#xA;&#xA;<pre><code>Meteor.loginWith&lt;ExternalService&gt;&#xA;</code></pre>&#xA;"
41335071,Central logging service with Microservices and Springboot how I can use this service as a central logging service,2016-12-26 18:39:58,<rest><logging><spring-boot><microservices>,1,165,0,0.0,0,<p>I have developed the RestFull webservice with SpringBoot in Microservice Architecture Envirnment and I want to use that logging service as a central logging service if anybody have idea please let me know.</p>&#xA;&#xA;<p>Here how I can append the logs of the service where I want to consume logging service what will be in the request and response</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;
41247817,Consul set up without docker for production use,2016-12-20 17:14:24,<microservices><consul>,2,452,0,0.0,0,"<p>I am doing a POC on Consul for supporting service discovery and multiple microservice versions. Consul clients and server cluster(3 servers) are set up on Linux VMs. I followed the documentation at <a href=""https://www.consul.io/intro/index.html"" rel=""nofollow noreferrer"" title=""consul website"">Consul</a> and the set up is successful. </p>&#xA;&#xA;<p>Here is my doubt. My set up is completely on VMs. I've added a service definition using HTTP API. The same service is running on two nodes. &#xA;The services are correctly registered:</p>&#xA;&#xA;<pre><code>curl http://localhost:8600/v1/catalog/service/my-service&#xA;</code></pre>&#xA;&#xA;<p>gives me the two node details.</p>&#xA;&#xA;<p>When I do a DNS query:</p>&#xA;&#xA;<pre><code>dig @127.0.0.1 -p 8600 my-service.service.consul&#xA;</code></pre>&#xA;&#xA;<p>I am able to see the expected results with the node which hosts the service. But I cannot ping the service since the service name is not resolved.</p>&#xA;&#xA;<pre><code>ping -c4 my-service or ping -c4 my-service.service.consul&#xA;</code></pre>&#xA;&#xA;<p>ping: unknown host.</p>&#xA;&#xA;<p>If I enter a mapping for <code>my-service</code> in /etc/hosts file, I can ping this, only from the same VM. I won't be able to ping this from another VM on the same LAN or WAN.&#xA;The default port for DNS is 53. Consul DNS interface listens to 8600. I cannot use Docker for DNS forwarding. Is it possible I missed something here? Can consul DNS query work without Docker/dnsmasq or iptables updates?&#xA;To be clear, here is what I would like to have as the end result:</p>&#xA;&#xA;<pre><code>ping my-service&#xA;</code></pre>&#xA;&#xA;<p>This needs to ping the nodes I have configured, in a round robin fashion.</p>&#xA;&#xA;<p>Please bear with me if this question is basic, and I've gone through each of the consul related questions in SO.</p>&#xA;&#xA;<p>Also gone through <a href=""https://blog.nimbusscale.com/2015/12/28/leveraging-consuls-dns-interface/%20%22%22"" rel=""nofollow noreferrer"">this</a> and <a href=""http://blog.scottlowe.org/2015/02/06/quick-intro-to-consul/%20%22%22"" rel=""nofollow noreferrer"">this</a> and these too says I need to do extra set up.</p>&#xA;"
49216360,How to run a 'watch' script along with a 'start' script in my node.js project,2018-03-11 03:31:27,<node.js><ecmascript-6><microservices>,2,33,0,0.0,0,"<p>I'm writing an app that is composed of microservices (I use <a href=""https://github.com/zeit/micro"" rel=""nofollow noreferrer"">micro</a>). </p>&#xA;&#xA;<p>I really like <code>es6</code>, so I use <code>Babel</code> to make the development process easier. The problem that I have is that I need a script that would compile my <code>es6</code> code and restarted the 'server'; I don't know how to achieve this.</p>&#xA;&#xA;<p>Right now I have the following script in my <code>package.json</code>:</p>&#xA;&#xA;<pre><code>  ""scripts"": {&#xA;    ""start"": ""yarn run build &amp;&amp; micro"",&#xA;    ""build"": ""./node_modules/.bin/babel src --out-dir lib""&#xA;  },&#xA;</code></pre>&#xA;&#xA;<p>When I run <code>yarn start</code> my <code>es6</code> code compiles successfully and <code>micro</code> starts the server. However, if I make changes to my code, I'll have to manually stop the server and run <code>yarn start</code> again.</p>&#xA;&#xA;<p>I've tried to change my build script</p>&#xA;&#xA;<pre><code>    ""build"": ""./node_modules/.bin/babel src --watch --out-dir lib""&#xA;</code></pre>&#xA;&#xA;<p>But in this case the <code>micro</code> command does not get executed as the <code>build</code> script just watches for changes and blocks anything else from execution. My goal is to have a script that would watch for changes and restart the server if a change occurred (compiling the code beforehand) like in <code>Meteor</code>. </p>&#xA;"
49062631,MicroServices - Async Communication via AMQP with multiple receivers scenario,2018-03-02 04:02:35,<asynchronous><microservices><amqp><servicebus>,2,35,0,0.0,0,"<p>Using Micro Services approach, I have Service A with 3 instances (A1, A2, A3) that can communicate with Service B which has (B1, B2, B3) instances via AMQP Message based Async communication. Example, by Azure Service Bus queues.</p>&#xA;&#xA;<p>Part of Service A's action implementation, I have 5 Steps to be taken care and 2nd step of the 5 is to reach out to Service B to get some info and proceed further.</p>&#xA;&#xA;<p>When I have a multi receiver approach, how does A2 instance of Service A can handle response from Service B, while actual request was made by A1 instance. </p>&#xA;&#xA;<p>I would like to know how these kind of scenarios handled in multi sender + multi receiver approach in micro services.</p>&#xA;"
49198200,Serving permitted documents in microservices environment,2018-03-09 16:32:58,<node.js><architecture><microservices>,1,36,0,0.0,0,"<p>Lets assume the following scenario :</p>&#xA;&#xA;<ul>&#xA;<li><p>There is an undefined number of micro-services written in node.js on top of the database</p></li>&#xA;<li><p>There is a Front-end application consuming those services using token based authentication and expanded Actor pattern for permissions</p></li>&#xA;<li><p>Certain requests are required to return documents</p></li>&#xA;<li><p>Those documents may only be served to users with permissions for specific document (permissions are app based, not OS based)</p></li>&#xA;<li><p>Microservice endpoint fetches document info from DB which would contain a path to the document on file server, that path would be resolved by service consumer application which would then serve the actual document.</p></li>&#xA;</ul>&#xA;&#xA;<p>With these things in mind, i'm trying to figure out safest and fastest way  (performance wise) to enable my system with abilities to download and upload documents.</p>&#xA;&#xA;<p>This approach still uses the built in permission system to obtain document physical path (not the doc it self) but trust needs to exist between consumer server and File server to obtain the actual document.&#xA;<strong>File server is in no way exposed to internet.</strong></p>&#xA;&#xA;<p>EDIT: &#xA;If as per @JPs suggestion i decided to go with document storage exposed to internet, i'm affraid that in case of front-end being compromised attacker would be able to get any document he wants.</p>&#xA;&#xA;<p>I'm unsure if thats the way to go especially if there is a way to avoid any kind of trust and be as explicit as possible, but i'm hoping someone will be able to suggest better way or the right way of achieving this.</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
49226141,Microservices architecture event collaboration pattern,2018-03-11 23:17:23,<microservices><event-sourcing><event-collaboration>,1,74,0,0.0,0,"<p>Martin Fowler's description of the Event Collaboration pattern (<a href=""https://martinfowler.com/eaaDev/EventCollaboration.html"" rel=""nofollow noreferrer"">https://martinfowler.com/eaaDev/EventCollaboration.html</a>) appears to imply that requisite external data (data from other services) that is needed for a service to function should be replicated and maintained within the service.</p>&#xA;&#xA;<p>This seems to imply that we should not resort issuing explicit queries.&#xA;For example:</p>&#xA;&#xA;<p>Say you have a communications service that is responsible for sending emails to clients and is dependent order information (that lives in the order service) to send an order confirmation email.</p>&#xA;&#xA;<p>With Event Collaboration, the communications service will have some internal representation of all orders that it will have built up by consuming relevant order creation/modification events.</p>&#xA;&#xA;<p>In this example a query to retrieve order details will not be necessary to generate the confirmation email.</p>&#xA;&#xA;<p>Are there any instances in which we would use explicit query messages rather than data replication when adopting the Event Collaboration pattern?</p>&#xA;"
49081095,Should single micro-service listen to single azure bus topic/queue?,2018-03-03 05:43:35,<azure><microservices><azure-service-fabric><azureservicebus>,2,140,0,1.0,0,"<p>We have a Azure service fabric micro-service which listen to multiple azure service bus topics(Topic A, Topic B).</p>&#xA;&#xA;<p>Topic A has more then 10 times message traffic then topic B. and to handle the scale-ability of service we will create the multiple instance of service.</p>&#xA;&#xA;<ol>&#xA;<li>My first question is, In most of the services instance will not get the message in Topic B, As Topic B has less traffic, So will it be waste of resources ?</li>&#xA;</ol>&#xA;&#xA;<p>2 Is it better to create different micro-services for Topic A and Topic B listeners, and create 10x instance of micro-service which listen to topic A and x instance of topic B listener service ?</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>Is create a message listener in azure service bus, keep on pulling message every time ? means continuously looking/ checking for message, message is there or not.</li>&#xA;</ol>&#xA;&#xA;<p>Thanks Guys for your supports. </p>&#xA;"
49100994,"DDD : one aggregate root , multiple persistent datasources",2018-03-04 22:07:24,<domain-driven-design><persistence><microservices><ddd-repositories><aggregateroot>,1,188,0,0.0,0,"<p>In the Guide/eBook: <a href=""https://aka.ms/microservicesebook"" rel=""nofollow noreferrer"">.NET Microservices: Architecture for Containerized .NET Applications</a> (related to the <a href=""https://github.com/dotnet-architecture/eShopOnContainers"" rel=""nofollow noreferrer"">eShopOnContainers</a>) in the chapter ""Designing the infrastructure persistence layer"" (page 213) is explained in general how an aggregate root can perform CUD operations against a persistent data source.</p>&#xA;&#xA;<p>Two important starting points are mentioned :</p>&#xA;&#xA;<ol>&#xA;<li>An aggregate is ignorant of methods of persistency and infrastructure following the Persistence Ignorance and the Infrastructure Ignorance principles (page 218). An aggregate is determined by the business and not by the infrastructure.</li>&#xA;<li>One should only define one repository per aggregate root to maintain transactional consistency between the objects within the aggregate (page 213)</li>&#xA;</ol>&#xA;&#xA;<p>Unfortunately, in all further examples that are mentioned the aggregate root and all underlying objects that fall under it are within one and the same persistent data source.</p>&#xA;&#xA;<p>The pattern then is as follows:</p>&#xA;&#xA;<ol>&#xA;<li>A repository is created containing that aggregate </li>&#xA;<li>In this repository a Unit of Work is injected during creation. This Unit of Work contains methods such as SaveChangesAsync, SaveEntitiesAsync, Update&#xA;and so on. </li>&#xA;<li>In a command, the Unit of Work manages the transactions to&#xA;this one data source such as a database or similar.</li>&#xA;</ol>&#xA;&#xA;<p>I want to expand this pattern that the aggregate can write its data over 2 or more physical data sources depending on the underlying object type.</p>&#xA;&#xA;<p>Starting from starting point 1, it is perfectly justified to have a root aggregate and its underlying object to be updated to different data sources depending on the type of underlying object. Examples mentioned are : a Database and an XML file, a database and a NOSQL 'database',a database and a service,  a database and an IoT device. Because an aggregate must be ignorant to methods of persistence and infrastructure, to my opinion there is no need to argue about the design of the aggregate. I think nowhere in the book it is written that a aggregate root should persist within one data source.</p>&#xA;&#xA;<p>At the same time, starting point 2 also seems perfectly justified. Because the complete set of objects within the aggregate root is edited, and the successful persistence of the entire package is coordinated from one repository and (preferably) from one Unit of Work.</p>&#xA;&#xA;<p>The question is: &#xA;How deals Domain Driven Design if within the aggregate - depending on the type of the underlying object - it is hydrated over different data sources?&#xA;Should I use one custom Unit of Work and make the decision where to write to within this UoW ? </p>&#xA;&#xA;<p>I'm aware of the next <a href=""https://stackoverflow.com/questions/3629500/unit-of-work-with-multiple-data-sources"">question</a> , but having studied the <a href=""http://dddpds.codeplex.com/"" rel=""nofollow noreferrer"">code</a> I think it only deals with inheritance of repositories that deal with different data sources, but still serving one data source at the time and that is not what I'm after. </p>&#xA;"
49113488,Distributed Database Design style for micro service-oriented architecture,2018-03-05 15:09:55,<spring-boot><microservices><distributed-database>,3,246,0,1.0,0,"<p>I am trying to convert one monolithic application into micro service oriented architecture style. Back end I am using spring , spring boot frameworks for development. Front-end I am using angular 2. And also using postgreSQL as database. &#xA;        Here my confusion is that , when I am designing my databases as distributed, according to functionalities it may contain  5 databases. Means I am designing according to vertical partition. Then I am thinking to implement inter-microservice communication services to achieve the entire functionality. </p>&#xA;&#xA;<p>The other way I am thinking that to horizontally partition the current structure. So my domain is based on some educational university. So half of university go under one DB and remaining will go under another DB. And deploy services according to Two region(two for two set of university). </p>&#xA;&#xA;<p>Currently I am decided to continue with the last mentioned approach. I am new to these types of tasks, since it referring some architecture task. Also I am beginner to this microservice and distributed database world. So Can anyone help me to confirm that my approach will give solution to my issue? Can I continue with my second approach - Horizontal partitioning of databases according to domain object? </p>&#xA;"
49226015,How to isolate services in choreography service composition,2018-03-11 22:58:24,<architecture><microservices><distributed-computing><service-composition>,1,55,1,2.0,0,"<p>I always encourage to design each service without knowing other services exists (isolated). </p>&#xA;&#xA;<p>Few days ago, i was reading about the cons and pros of choreography over orchestration in micro service architecture, i came across this topic that, &#xA;Lets say we have a system which consist of 3 services: ordering, payment, shipment. if i use a orchestrator, the orchestrator knows when and how to call each service. in fact its duty is to know how and when call what service, but in choreography, i have no idea when payment service does not know the ordering service exists how its gonna subscribe to its event (for sure at least ordering system needs to have payment models)?</p>&#xA;&#xA;<p>i become more confuse when i start to think that, if we have a method in ordering service which returns the ordering information followed by payment data and shipping data. how its going to return payment and shipping data?</p>&#xA;"
49158331,How to update library version on multiple microservice pom.xml files,2018-03-07 17:51:33,<maven><spring-boot><pom.xml><microservices><auto-update>,1,76,1,0.0,0,<p>So lets say you have a common library repo. A release changes library latest version from 1.1 to 1.2.&#xA;Now any microservices that use this library need to have their pom.xml files updated manually.&#xA;Appreciate any suggestions on how to get around this.</p>&#xA;
49060040,What's the decision of using SQL vs. NoSQL?,2018-03-01 22:56:29,<sql><nosql><amazon-dynamodb><microservices>,1,87,1,1.0,0,"<p>Let's say, a system already uses the relational database as its primary db. The system is a monolithic service and the team wants to decompose it to several micro-services. Meanwhile, some new database tables needs to be added. For these new tables, is it a good idea to use NoSQL system (DynamoDB) over the relational database? These new tables have no much interactions with the existing tables, however, I didn't see much of necessity of using DynamoDB for all the new tables, because:</p>&#xA;&#xA;<ol>&#xA;<li><p>Need to interact with additional service (DynamoDB). This includes setting up accounts and manage DynamoDB tables;</p></li>&#xA;<li><p>Using the relational database for new tables won't block the decomposition to micro-services.</p></li>&#xA;</ol>&#xA;&#xA;<p>What's the current trend in industry? Do we use NoSQL for all tables if applicable? And for the situation above, what's the proper consideration here? </p>&#xA;"
49080999,how to handle duplicated data in a micro service architecture,2018-03-03 05:28:51,<microservices>,1,99,1,0.0,0,"<p>I am working on a jobs site where I am thinking of breaking out the jobs matching section into a micro service - everything else is a monolith. </p>&#xA;&#xA;<p>But when thinking about how the microservice should have its own separate database, that would mean having the microservice have a separate copy of all the jobs, given the monolith would still handle all job crud functionality.</p>&#xA;&#xA;<p>Am I thinking about this the right way and is it normal to have multiple copies of the same data spread out across different microservices?</p>&#xA;&#xA;<p>The idea of having different databases with the same data scares me a bit, since that creates the potential for things to get out of sync.</p>&#xA;"
49198914,Spring boot applications with realtime communication,2018-03-09 17:17:10,<spring-boot><real-time><microservices>,1,175,1,0.0,0,"<p>I have a core application and a provider application. </p>&#xA;&#xA;<p>The provider application is added dynamically. It needs to register itself to the core. Originally I assumed the providers will have a public IP and would register there IP to the core and the core would call them when it needs some service. (Or connect to a VPN and the IP would be accessible)</p>&#xA;&#xA;<p>This approach became hard to manage and there was overhead when checking the status of the provider.</p>&#xA;&#xA;<p>I thought of some alternatives and don't know which one to use</p>&#xA;&#xA;<ol>&#xA;<li>Websockets. The providers would subscribe to some topics. I haven't figured out how to publish to a single one yet, but I'm thinking the providers will register their uuid when subscribing and we publish to just one uuid which only one provider will subscribe to. </li>&#xA;<li>Use Apache MQ or Kafka or something similar.  </li>&#xA;<li>Implement a TCP communication (Spring integration might help, but I'm not sure )</li>&#xA;</ol>&#xA;&#xA;<p>Those are the ideas I have and I'm not sure on how to structure them for best performance and cleaner code.</p>&#xA;&#xA;<p>What other option do I have? </p>&#xA;&#xA;<h2>Edit</h2>&#xA;&#xA;<p>@cool suggested that I use a discovery server and it makes more sense. The providers themselves contain a list of devices. Does it make sense to publish them separately? They all would have the same IP but device Id will be associated with the metadata (perhaps the id would be part of the url). </p>&#xA;"
49165457,Deploy Serverless (Faas) locally instead of using Cloud Providers,2018-03-08 04:30:35,<containers><microservices><serverless>,1,15,2,0.0,0,<p>Is local deploy Serverless architecture a good idea to optimize system performance (event driven) and reduce server operational cost instead of using Cloud Provider like AWS?</p>&#xA;
49187093,How to get data from JWT if didn't have users table in laravel?,2018-03-09 05:23:15,<laravel><jwt><microservices>,1,76,2,0.0,0,"<p>I try to implement microservice arhitecture.Because I new in it,can maybe someone can tell me:&#xA;- can I use JWT for communication to services,when someone login into one service.Is that secure way or there is something better?&#xA;- how do I parse JWT and get user id or some other data from it to have it in other service which didn't have users table?Like is it expiried,user id...</p>&#xA;&#xA;<p>Thank you a loot if someone can help me to send me a direction for it.</p>&#xA;"
49175047,C# how to aggregate results from multiple HTTP requests?,2018-03-08 14:05:47,<c#><system.reactive><microservices><mediatr>,1,91,2,0.0,0,"<p>I am designing an application written in C# and AspNetCore that requires making multiple HTTP requests to microservices and aggregating the results before returning to the controller. </p>&#xA;&#xA;<p>I have looked into MediatR pipelines but seems limited and unfit for this particular scenario. </p>&#xA;&#xA;<p>I imagine there being something useful within the realm of map and reduce but struggling to find a framework my developers can get going with quickly.</p>&#xA;&#xA;<p>We want to ensure aggregation is terminated should one or more requests fail. </p>&#xA;&#xA;<p>I created a proof of concept using worker threads e.g.</p>&#xA;&#xA;<pre><code>var results = await Task.WhenAll(task1, task2);&#xA;</code></pre>&#xA;&#xA;<p>But this does not provide a framework like MediatR developers can easily adopt and unit test.</p>&#xA;&#xA;<p>I suppose the same can be said had my proof of concept been written using Rx extensions and Observable.zip. I am nonetheless rather curious and hoping to find examples of using Observable.zip in C# similar to what has been demonstrated in this Netflix blog post</p>&#xA;&#xA;<p><a href=""https://medium.com/netflix-techblog/reactive-programming-in-the-netflix-api-with-rxjava-7811c3a1496a"" rel=""nofollow noreferrer"">Reactive Programming in the Netflix API with RxJava</a></p>&#xA;"
49242181,Dependency injection in ASP.NET Core 2 issue,2018-03-12 18:29:35,<c#><asp.net-core><rabbitmq><microservices>,1,221,2,1.0,0,"<p><strong>Update</strong></p>&#xA;&#xA;<p>I changed the startup to :</p>&#xA;&#xA;<pre><code>using System;&#xA;using System.Collections.Generic;&#xA;using System.Linq;&#xA;using System.Threading.Tasks;&#xA;using Actio.Api.Handlers;&#xA;using Actio.Api.Repositories;&#xA;using Actio.Common.Auth;&#xA;using Actio.Common.Events;&#xA;using Actio.Common.Mongo;&#xA;using Actio.Common.RabbitMq;&#xA;using Microsoft.AspNetCore.Builder;&#xA;using Microsoft.AspNetCore.Hosting;&#xA;using Microsoft.Extensions.Configuration;&#xA;using Microsoft.Extensions.DependencyInjection;&#xA;using Microsoft.Extensions.Logging;&#xA;using Microsoft.Extensions.Options;&#xA;&#xA;namespace Actio.Api&#xA;{&#xA;    public class Startup&#xA;    {&#xA;        public Startup(IConfiguration configuration)&#xA;        {&#xA;            Configuration = configuration;&#xA;        }&#xA;&#xA;        public IConfiguration Configuration { get; }&#xA;&#xA;        // This method gets called by the runtime. Use this method to add services to the container.&#xA;        public void ConfigureServices(IServiceCollection services)&#xA;        {&#xA;            services.AddMvc();&#xA;            services.AddJwt(Configuration);&#xA;            services.AddRabbitMq(Configuration);&#xA;            services.AddMongoDB(Configuration);&#xA;            services.AddScoped&lt;IEventHandler&lt;ActivityCreated&gt;, ActivityCreatedHandler&gt;();&#xA;            services.AddScoped&lt;IActivityRepository, ActivityRepository&gt;();&#xA;&#xA;        }&#xA;&#xA;        // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.&#xA;        public void Configure(IApplicationBuilder app, IHostingEnvironment env)&#xA;        {&#xA;            if (env.IsDevelopment())&#xA;            {&#xA;                app.UseDeveloperExceptionPage();&#xA;            }&#xA;            // app.ApplicationServices.GetService&lt;IDatabaseInitializer&gt;().InitializeAsync();&#xA;&#xA;            using (var serviceScope = app.ApplicationServices.CreateScope())&#xA;            {&#xA;                serviceScope.ServiceProvider.GetService&lt;IDatabaseInitializer&gt;().InitializeAsync();&#xA;            }&#xA;            app.UseAuthentication();&#xA;            app.UseMvc();&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But now I am having Error in <strong>SubscribeToEvent</strong>:&#xA;Cannot resolve scoped service </p>&#xA;&#xA;<pre><code>'Actio.Common.Events.IEventHandler`1[Actio.Common.Events.ActivityCreated]' from root provider.' &#xA;</code></pre>&#xA;&#xA;<p>in my ServiceHost.cs.</p>&#xA;&#xA;<p><strong>ServiceHost.cs</strong></p>&#xA;&#xA;<pre><code>using System;&#xA;using Actio.Common.Commands;&#xA;using Actio.Common.Events;&#xA;using Actio.Common.RabbitMq;&#xA;using Microsoft.AspNetCore;&#xA;using Microsoft.AspNetCore.Hosting;&#xA;using Microsoft.Extensions.Configuration;&#xA;using RawRabbit;&#xA;&#xA;namespace Actio.Common.Services&#xA;{&#xA;    public class ServiceHost : IServiceHost&#xA;    {&#xA;        private readonly IWebHost _webHost;&#xA;&#xA;        public ServiceHost(IWebHost webHost)&#xA;        {&#xA;            _webHost = webHost;&#xA;        }&#xA;&#xA;        public void Run() =&gt; _webHost.Run();&#xA;&#xA;        public static HostBuilder Create&lt;TStartup&gt;(string[] args) where TStartup : class&#xA;        {&#xA;            Console.Title = typeof(TStartup).Namespace;&#xA;            var config = new ConfigurationBuilder()&#xA;                .AddEnvironmentVariables()&#xA;                .AddCommandLine(args)&#xA;                .Build();&#xA;            var webHostBuilder = WebHost.CreateDefaultBuilder(args)&#xA;                .UseConfiguration(config)&#xA;                .UseStartup&lt;TStartup&gt;();&#xA;&#xA;            return new HostBuilder(webHostBuilder.Build());&#xA;        }&#xA;&#xA;        public abstract class BuilderBase &#xA;        {&#xA;            public abstract ServiceHost Build();&#xA;        }&#xA;&#xA;        public class HostBuilder : BuilderBase&#xA;        {&#xA;            private readonly IWebHost _webHost;&#xA;            private IBusClient _bus;&#xA;&#xA;            public HostBuilder(IWebHost webHost)&#xA;            {&#xA;                _webHost = webHost;&#xA;            }&#xA;&#xA;            public BusBuilder UseRabbitMq()&#xA;            {&#xA;                _bus = (IBusClient)_webHost.Services.GetService(typeof(IBusClient));&#xA;&#xA;                return new BusBuilder(_webHost, _bus);&#xA;            }&#xA;&#xA;            public override ServiceHost Build()&#xA;            {&#xA;                return new ServiceHost(_webHost);&#xA;            }&#xA;        }&#xA;&#xA;        public class BusBuilder : BuilderBase&#xA;        {&#xA;            private readonly IWebHost _webHost;&#xA;            private IBusClient _bus; &#xA;&#xA;            public BusBuilder(IWebHost webHost, IBusClient bus)&#xA;            {&#xA;                _webHost = webHost;&#xA;                _bus = bus;&#xA;            }&#xA;&#xA;            public BusBuilder SubscribeToCommand&lt;TCommand&gt;() where TCommand : ICommand&#xA;            {&#xA;                var handler = (ICommandHandler&lt;TCommand&gt;)_webHost.Services&#xA;                    .GetService(typeof(ICommandHandler&lt;TCommand&gt;));&#xA;                _bus.WithCommandHandlerAsync(handler);&#xA;&#xA;                return this;&#xA;            }&#xA;&#xA;            public BusBuilder SubscribeToEvent&lt;TEvent&gt;() where TEvent : IEvent&#xA;            {&#xA;                var handler = (IEventHandler&lt;TEvent&gt;)_webHost.Services&#xA;                    .GetService(typeof(IEventHandler&lt;TEvent&gt;));&#xA;                _bus.WithEventHandlerAsync(handler);&#xA;&#xA;                return this;&#xA;            }&#xA;&#xA;            public override ServiceHost Build()&#xA;            {&#xA;                return new ServiceHost(_webHost);&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<h1>------------------------------------------------------------------------------</h1>&#xA;&#xA;<p>I recently started learning Microservices with RabbitMQ. After much struggle I got a code sample but I am unable to run it as it is giving error <code>:""System.InvalidOperationException: 'Cannot resolve scoped service 'Actio.Common.Mongo.IDatabaseInitializer' from root provider.'""</code></p>&#xA;&#xA;<p>I wish to understand this code so that I can have better understanding of Microservices.</p>&#xA;&#xA;<p><strong>Code-Startup.cs</strong></p>&#xA;&#xA;<pre><code>using System;&#xA;using System.Collections.Generic;&#xA;using System.Linq;&#xA;using System.Threading.Tasks;&#xA;using Actio.Api.Handlers;&#xA;using Actio.Api.Repositories;&#xA;using Actio.Common.Auth;&#xA;using Actio.Common.Events;&#xA;using Actio.Common.Mongo;&#xA;using Actio.Common.RabbitMq;&#xA;using Microsoft.AspNetCore.Builder;&#xA;using Microsoft.AspNetCore.Hosting;&#xA;using Microsoft.Extensions.Configuration;&#xA;using Microsoft.Extensions.DependencyInjection;&#xA;using Microsoft.Extensions.Logging;&#xA;using Microsoft.Extensions.Options;&#xA;&#xA;namespace Actio.Api&#xA;{&#xA;    public class Startup&#xA;    {&#xA;        public Startup(IConfiguration configuration)&#xA;        {&#xA;            Configuration = configuration;&#xA;        }&#xA;&#xA;        public IConfiguration Configuration { get; }&#xA;&#xA;        // This method gets called by the runtime. Use this method to add services to the container.&#xA;        public void ConfigureServices(IServiceCollection services)&#xA;        {&#xA;            services.AddMvc();&#xA;            services.AddJwt(Configuration);&#xA;            services.AddRabbitMq(Configuration);&#xA;            services.AddMongoDB(Configuration);&#xA;            services.AddScoped&lt;IEventHandler&lt;ActivityCreated&gt;, ActivityCreatedHandler&gt;();&#xA;            services.AddScoped&lt;IActivityRepository, ActivityRepository&gt;();&#xA;        }&#xA;&#xA;        // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.&#xA;        public void Configure(IApplicationBuilder app, IHostingEnvironment env)&#xA;        {&#xA;            if (env.IsDevelopment())&#xA;            {&#xA;                app.UseDeveloperExceptionPage();&#xA;            }&#xA;          //Giving Error in below line&#xA;&#xA;&#xA;app.ApplicationServices.GetService&lt;IDatabaseInitializer&gt;().InitializeAsync();&#xA;                app.UseAuthentication();&#xA;                app.UseMvc();&#xA;            }&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Can someone please help so that I can debug and l have better understanding.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
30273152,Logical Layer to connect multiple .Net Services,2015-05-16 07:49:15,<web-services><design><architecture><microservices>,1,60,0,0.0,0,"<p>I am not sure if this is the appropriate place for this, but I have come up with a ""conceptual"" modular design architecture that separates the logic out into individual services to allow an almost plug and play type scenario whereby there are no dependencies between the services. Think a list of features and only enabling the ones that you want.</p>&#xA;&#xA;<p>To facilitate this I realise that I will need some type of middleware that will connect these all together and control the flow of data. However I am not sure of the specifics around what would be appropriate to achieve this. </p>&#xA;&#xA;<p>I plan on implementing the services using .NET soap based services, so is this a case of using something like Tibco? </p>&#xA;&#xA;<p>Any suggestions around what would be most appropriate or even where to start looking would be great.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/KVxoj.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p>If the above description didn't make sense hopefully this image is a bit clearer in describing the relationship between the services.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
33659658,Service Fabric Reliable Services: proccessing parallel request with CPU-bound methods,2015-11-11 20:56:00,<c#><azure><microservices><azure-service-fabric>,2,1663,0,0.0,0,"<p>Azure <strong>Service Fabric</strong>'s Reliable Actors turn-based concurrency is described in official documentation.As If I get it right, <strong>Reliable Services</strong>, can serve multiple requests simultaneously.&#xA;Lets say I have a Reliable Service with single CPU-bounded method.&#xA;Method is async as expected, so Service can handle multiple requests.&#xA;My local cluster is hosted on 2-core machine, when I call Service from 2 different console-app clients, CPU 100% utilized as expected. So there is no reason to handle more than 2 request simultaneously. How can I limit this?&#xA;And if I move to real cluster, I don't know anything about machine Service hosted on, what should I do then?</p>&#xA;&#xA;<pre><code>public async Task&lt;bool&gt; CpuBoundAsync(int value)&#xA;&#xA;    {&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK IN PROGRESS"");&#xA;        int z;&#xA;        await Task.Run(() =&gt;&#xA;        {&#xA;            for (int i = 0; i &lt; int.MaxValue; i++)&#xA;            {&#xA;                z++;&#xA;                z--;&#xA;            }&#xA;        });&#xA;&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK COMPLETED"");&#xA;        return true;&#xA;    }&#xA;</code></pre>&#xA;"
33669733,Microservices and message consumption in mixed sync/async interaction,2015-11-12 10:49:47,<java><design><architecture><message-queue><microservices>,1,197,0,1.0,0,"<p>I'm developing a Document Management Systems (DMS) using Microservices architecture. While most services interact with each other through direct synchronous calls (Netflix Ribbon + Hystrix), there is Messaging Systems (Apache Kafka) in the middle for asynchronous document processing.</p>&#xA;&#xA;<p>My <code>DocumentService</code>, that processes documents (with using other services also) and provides public API is pretty ""fat"" and I can't decide is it worth to make <code>DocumentService</code> consume Documents or create another microservices, that will delegate Documents to <code>DocumentService</code> for further processing?</p>&#xA;&#xA;<p>Here are diagrams of these variants:&#xA;<a href=""https://i.stack.imgur.com/Gwkel.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gwkel.jpg"" alt=""Without pre-processing microservice""></a>&#xA;<code>Without pre-processing microservice</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/A1dZC.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A1dZC.jpg"" alt=""With document consuming service""></a>&#xA;<code>With document consuming service</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p>From the one hand, I do not want to create too many microservices, because it's harder to control instances, but I don't want to make microservices too fat also.</p>&#xA;&#xA;<p>P.S. Each microservices may has multiple instances.</p>&#xA;"
33706599,Where to store configuration retrieved from etcd in nodejs,2015-11-14 08:34:03,<node.js><soa><microservices><etcd>,1,245,3,0.0,0,"<p>I'm getting config from http call. </p>&#xA;&#xA;<p>Where I can store that config, Serialize to <strong>filesystem or attach to GLOBAL</strong> or any other</p>&#xA;&#xA;<p>I'm implementing service discovery with nodejs. <a href=""http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/"" rel=""nofollow"">http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/</a></p>&#xA;&#xA;<p>I'm getting the service registry. I want to store it for using application wide.</p>&#xA;"
51974383,@pact and @pactVerfication have to be in same class,2018-08-22 20:09:08,<testing><microservices><pact>,1,9,0,0.0,0,"<p>I am looking to invoke the @pactverification test from consumer code instead of creating a dummy HttpClient and verifying the same. Does the @pact and @pactVerfication have to be in same class? Can we seperate the contracts with actual tests? If yes, how does the @pactverification test know which contract to look for ?Please let me know if I am missing anything</p>&#xA;"
52057408,Contract Testing for AWS Lambdas,2018-08-28 12:02:13,<aws-lambda><microservices><pact><aws-sam>,2,11,0,0.0,0,"<p>Is there any way to do Contract testing for the AWS lambdas.&#xA;Pact is being used for normal APIs, But I am trying to implement Contract Testing on AWS SAM. Is there any tool for this or Pact can be used with any modifications?</p>&#xA;"
52093232,Spring Cloud Multiproject or Single Projects,2018-08-30 09:11:06,<microservices><spring-cloud><continuous-delivery>,1,11,0,0.0,0,<p>Does anyone have experience with running Spring Cloud Micro Services in production? </p>&#xA;&#xA;<p>I have about 10 micro services within one big Maven multi-project. This means that all the source code is under a single repo. The advantages are that it is easy to check out and manage the project in my IDE.</p>&#xA;&#xA;<p>My concern is with CI as it means that the build server will need to figure out which services changed and deploy them respectively. Alternatively all the micro services will be deployed every time a change is committed.</p>&#xA;&#xA;<p>I'm eyeing exploding the project into a source repo per micro service (my gut feel is that this is the correct approach). This way only the affected service is deployed.</p>&#xA;&#xA;<p>My goal is to run every micro service as a container on Kubernetes.</p>&#xA;&#xA;<p>Do you have any advise / tips / concerns that you can raise that might be an unwelcome surprise down the line? </p>&#xA;
52001694,How to stop logging access log to stdout with Quart Python,2018-08-24 09:43:00,<python><logging><stdout><microservices><quart>,1,17,0,0.0,0,<p>I have microservice written in Quart python. I would like to stop logging on to stdout. So far I have tried app.logger.disabled = True and Flask alike &#xA;import logging&#xA;log = logging.getLogger('werkzeug')&#xA;log.setLevel(logging.ERROR)</p>&#xA;&#xA;<p>Havent achieved goals yet. </p>&#xA;
52126065,Redundant classes in Microservice architecture,2018-09-01 07:46:59,<microservices>,1,17,0,0.0,0,"<p>I just moved to a new project, and it is a legacy code, having 15 microservices.</p>&#xA;&#xA;<p>Problem is each service has 3-4 common classes, e.g. <code>User.java</code>, <code>Supplier.java</code>, <code>Settings.java</code>. Whenever we need do any change in any of those classes in any of the microservices then we have to do that change in rest of other 14 apis as well, which is so tiring.</p>&#xA;&#xA;<p>Is there any workaround for this problem?</p>&#xA;"
52105225,"In a microservice architecture, when use webservice as data provider vs direct db",2018-08-30 20:55:03,<architecture><microservices><soa>,3,21,0,0.0,0,"<p>We are developing a system which is spread in about 7 microservices.</p>&#xA;&#xA;<p>One of them (a-service) it's a CRUD that allows a mobile client to get some data required to operate. Turns out that another microservice needs the same data to perform some checks before processing a request.</p>&#xA;&#xA;<p>We don't implement one-database-per-microservice, instead we have a sharded MongoDB for all applications (not my fault, my company set it).</p>&#xA;&#xA;<p>Should I in this b-service that also needs the data exposed by a-service consume that service or should I connect directly to the database and retrieve it?</p>&#xA;&#xA;<p>My current considerations:</p>&#xA;&#xA;<ul>&#xA;<li>Putting load on the micro-service and the db vs loading only the database.</li>&#xA;<li>Possible encapsulation of data if it's served by the micro-service for future changes.</li>&#xA;</ul>&#xA;&#xA;<p>Maybe someone can give me some 'best practices' in the matter? Thanks!</p>&#xA;"
51991404,Caused by: org.apache.maven.plugin.MojoExecutionException: .git directory is not found! Please specify a valid [dotGitDirectory] in your pom.xml,2018-08-23 17:36:53,<spring><spring-boot><microservices>,1,22,0,1.0,0,"<p>I am referring code from the link: <a href=""https://github.com/sivaprasadreddy/spring-boot-microservices-series"" rel=""nofollow noreferrer"">https://github.com/sivaprasadreddy/spring-boot-microservices-series</a>. When I simply build the code, I get the below error.</p>&#xA;&#xA;<p>Could you please update on any pointers?</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal pl.project13.maven:git-commit-id-plugin:2.2.3:revision (default) on project config-server: .git directory is not found! Please specify a valid [dotGitDirectory] in your pom.xml -&gt; [Help 1]&#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal pl.project13.maven:git-commit-id-plugin:2.2.3:revision (default) on project config-server: .git directory is not found! Please specify a valid [dotGitDirectory] in your pom.xml&#xA;    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)&#xA;    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)&#xA;    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)&#xA;    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)&#xA;    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)&#xA;    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)&#xA;    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)&#xA;    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)&#xA;    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)&#xA;    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)&#xA;    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954)&#xA;    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288)&#xA;    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke (Method.java:498)&#xA;    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)&#xA;    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)&#xA;    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)&#xA;    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)&#xA;Caused by: org.apache.maven.plugin.MojoExecutionException: .git directory is not found! Please specify a valid [dotGitDirectory] in your pom.xml&#xA;</code></pre>&#xA;&#xA;<p><strong>List from the derectories?</strong></p>&#xA;&#xA;<pre><code>$ ls -ltra&#xA;total 56&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 users-microservice/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 recommendation-microservice/&#xA;-rw-r--r-- 1 e081155 1049089  2538 Nov 11  2016 README.md&#xA;-rw-r--r-- 1 e081155 1049089  4180 Nov 11  2016 pom.xml&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 movies-ui/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 movie-microservice/&#xA;-rw-r--r-- 1 e081155 1049089 11358 Nov 11  2016 LICENSE&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 hystrix-dashboard/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 docker/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 discovery-microservice/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 consul-microservice/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 config-microservice/&#xA;drwxr-xr-x 1 e081155 1049089     0 Nov 11  2016 api-gateway-microservice/&#xA;drwxr-xr-x 1 e081155 1049089     0 Aug 24 01:13 ../&#xA;drwxr-xr-x 1 e081155 1049089     0 Aug 24 01:15 ./&#xA;</code></pre>&#xA;"
52058409,Grouping together micro services internal error codes?,2018-08-28 12:51:31,<api><error-handling><refactoring><microservices>,1,25,0,0.0,0,<p>Is it a good practice to put all internal error codes and exception class into a common module? or what problems you guys have encounter by doing so...</p>&#xA;&#xA;<p>I am thinking of grouping all these error codes together for re-usability and consistency instead of each micro services having their own error codes.</p>&#xA;
51962515,Why containerPort and hostPort need to be same in DCOS?,2018-08-22 08:14:03,<azure><microservices><mesos><marathon><dcos>,1,26,0,0.0,0,"<p>I have a web application with the below application definition and DCOS setup up and running on azure cloud with marathon-lb deployed. When I add below as a service.</p>&#xA;&#xA;<pre><code>{&#xA;  ""id"": ""web"",&#xA;  ""container"": {&#xA;    ""type"": ""DOCKER"",&#xA;    ""docker"": {&#xA;      ""image"": ""myimage"",&#xA;      ""network"": ""BRIDGE"",&#xA;      ""portMappings"": [&#xA;        { ""hostPort"": 5000, ""containerPort"": 5000, ""servicePort"": 0 }&#xA;      ],&#xA;      ""forcePullImage"":true&#xA;    }&#xA;  },&#xA;  ""instances"": 1,&#xA;  ""cpus"": 0.1,&#xA;  ""mem"": 614,&#xA;  ""labels"":{&#xA;    ""HAPROXY_GROUP"":""external"",&#xA;    ""HAPROXY_0_VHOST"":""localhost"",&#xA;    ""HAPROXY_0_MODE"":""http""&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am able to access my application through browser only when I keep containerPort and hostPort same.</p>&#xA;&#xA;<p>If I change the hostPort to 0 , I am not able to access the app.&#xA;And I need hostPort as 0 so that I can scale the app and It will allocate the free hostPort to the application.&#xA;What is wrong here pls guide?</p>&#xA;"
52081388,Securing communication between backend microservices using JWT,2018-08-29 15:41:19,<oauth><oauth-2.0><openid><microservices><openid-connect>,2,28,0,0.0,0,<p>let's say we have a lot of microservices in backend. There is gateway API service that authorize user to execute some action done in UI. Than that's microservice (MicroBackend1) calls next microservice(MicroBackend2) and next one calls next one. What JWT should be passed to authorize between MicroBackend1 and MicroBackend2? Which approach i the right one:</p>&#xA;&#xA;<ol>&#xA;<li><p>JWT from UI user is passed only to first MicroBackend1. Than it passed his own JWT to MicroBackend2. Context  knows context of user that executed action in UI is not available in MicroBackend2.</p></li>&#xA;<li><p>MicroBackend1 does the ActAs token request to STS and then passes new JWT to MicroBackend2. This means user context is known to MicroBackend2.</p></li>&#xA;<li><p>MicroBackend1 directly passes JWT that he got from UI to MicroBackend2 therefore it has user context.</p></li>&#xA;</ol>&#xA;&#xA;<p>What are the pros and cons of such solutions? Which one you have tried and which one should we choose?</p>&#xA;
52098061,is it possible to use OSGI with spring boot microservices? Please tell me in detail,2018-08-30 13:14:50,<spring-boot><osgi><microservices><sdn><opendaylight>,1,46,0,0.0,0,"<p>I want to use ODL framework for SDN development, in that internally OSGI framework is used to (karaf). Apart from that i want to use spring boot and spring cloud to achieve cloud services also. It is possible to use these all framework as a single unit. and how we can achieve this please tell.</p>&#xA;"
51986244,Spring Cloud Microservices - Eureka Server Security,2018-08-23 12:49:57,<spring><security><microservices><discovery><eureka>,1,54,0,0.0,0,"<p>Since Eureka uses http/https protocols to interact with its registrants (clients), you could easily trick the eureka server by pretending to be one of its clients posting false/erroneous data to it telling that a service is down which eventually result in removal of those services from registry. This is a very likely scenario in a large system with many users.&#xA;What are the alternative security/authentication schemes to prevent such attack?</p>&#xA;"
51980596,How to Map specific fields of an object to another object?,2018-08-23 07:37:30,<java><spring><spring-boot><microservices>,4,62,0,0.0,0,"<p>I have a situation where I have an object(obj1) which I have to map to another object(obj2) but in this Mapping some of obj2's fields are already having some values while other fields are null, so I have to pick only those fields which are null in obj2 and then send data from obj1 to those fields. I am not sure if ModelMapper will be useful in this case. </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
52125150,last item in the cart,2018-09-01 05:30:07,<java><microservices><shopping-cart>,2,26,1,0.0,0,"<p>I am learning microservices and trying to design an e-commerce website. I can't figure out how big shopping sites take care of the last item in the cart problem. </p>&#xA;&#xA;<p>For example, I selected an item from Amazon which had just a single item available in stock. I logged in from two different accounts and placed the item in cart. I even reached the payment page from both the account and the site didn't restrict me anywhere saying that the item is not available. I am not sure after the payment page when payment from both the account is in progress, how Amazon handles it. </p>&#xA;&#xA;<p>Few solutions which come to my mind are like:</p>&#xA;&#xA;<ol>&#xA;<li>Accept payment from both the accounts and later cancel transaction for one of them which paid later than the first. This will not be a good practice though as it will result in bas customer experience.</li>&#xA;<li>Keep few items in reserve and use them in case of overbooking.</li>&#xA;<li>I forget what Amazon is doing and implement quantity checks in Order service from Item service via REST calls, at every stage of the order. But these checks sometimes can fail when a lot of people are ordering the same item. for e.g. in flash sales</li>&#xA;</ol>&#xA;&#xA;<p>Please share if you guys have worked on similar problem and solved it even with few limitations. If I need to put any in more details, let me know.</p>&#xA;"
51999232,Rest End point not showing any json data when using POSTMAN application,2018-08-24 07:11:48,<spring-boot><postman><microservices>,2,29,1,0.0,0,"<p>I am trying to implement sample spring boot project and trying to retrieve result using POSTMAN application. But when using POSTMAN , I am not able to see that response for a GET request. But I can see by using browser properly. POSTMAN returning ""Expected ':' instead of 't'"" as result. But I can see result properly by using browser.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GwlgX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GwlgX.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>And my controller code is like the following,</strong></p>&#xA;&#xA;<pre><code>@GetMapping(""/check"")&#xA;    public List&lt;Users&gt; check() {&#xA;        return  (List&lt;Users&gt;) userObj.findAll();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Can anyone help me to find out why I am not able to see result using POSTMAN application please?</p>&#xA;"
52076009,How one Jhipster application microservices call in another application..?,2018-08-29 11:09:11,<spring-boot><microservices><jhipster>,1,29,1,1.0,0,"<p>I have 1 UAA, 1 gateway and 2 microservices application. How can i call first application rest api to another application.</p>&#xA;"
52008034,Sharing a graph database between Microservices,2018-08-24 15:59:00,<neo4j><microservices><graph-databases><amazon-neptune>,1,34,1,1.0,0,"<p>Is there any way to share a neo4j / aws Neptune graph database between microservices while restricting the access to the specific parts of the graph database to only a specific microservice ? By doing so, will there be any performance impact ?</p>&#xA;"
52057828,How to Create a MicroService in .Net Core / Visual Studio,2018-08-28 12:23:28,<asp.net-core><.net-core><microservices>,3,38,1,0.0,0,"<blockquote>&#xA;  <p>This buzzword is making me pull my hair... I have been asked to create&#xA;  a <strong>microservice</strong> using <strong>.net core</strong>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Googled a lot, different definitions and samples, but still, I don't know what makes a vs project a microservice / how can I create a microservice in VS. For example, I have asked to create a microservice where a user will input two latitude and longitude values and they will get the distance between them.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Cool, I can do this as a web project in no time. But here I need this as a microservice where the rest of the projects in our firm can use it.&#xA;What really makes a VS project into a Microservice or can I convert a project into a micro service? Microservice experts are welcome ...!!! I looking for that step by process in which a microservice is created in .net core. </p>&#xA;"
51950785,Where to place kubernetes and dockerfiles,2018-08-21 14:19:53,<docker><kubernetes><microservices><devops>,2,72,1,0.0,0,"<p>We have several options how to correctly manage kubernetes delcaration files and dockerfiles. Services development may be considered as fully separate without any cross service communications for now.</p>&#xA;&#xA;<ol>&#xA;<li>Setup separate repository which will contain all k8s and docker delcarations and  build/deploy scripts. </li>&#xA;<li>Setup separate repository for k8s declarations and leave docker files in the repositories of appropriate services.</li>&#xA;<li>All k8s declarations and docker files placed near services code (same repo with code)</li>&#xA;</ol>&#xA;&#xA;<p>Which approach is better and provides more flexibility? We are having 2 services and soon the counter of services with complex inner network configurations will increase to 8 and 3rd option not looking good at all.</p>&#xA;&#xA;<p>2nd option is better, but I'm not quite sure if k8s separate repo is a good option. While local docker image might also create some difficulties for local development, as it not fully required for developer teams to interact with other services and spin up all services.</p>&#xA;&#xA;<p>1st option looks good as it provides full responsibility dedication and solves devops only task, but in the future may lead to problems when team would need to spin up whole k8s cluster. But, even in this case, this repo might be pulled and executed in respect to minikube.</p>&#xA;&#xA;<p>But neither of those options looking really good for me. Am I missing something?</p>&#xA;"
52062284,Why is the username commonly used for user identification with OAuth2?,2018-08-28 16:14:45,<authentication><oauth><microservices>,1,16,2,0.0,0,"<p>I want to set up a resource server and an external authentication server with oauth2, both servers with their own databases to avoid coupling.</p>&#xA;&#xA;<p>Apart from verifying that the user is authenticated, I need to know which user is authenticated. If resource and authentication server share the same database, this is rather simple. But since this is not the case here I've been wondering how I could do that. The obvious choice, for me, would be to somehow obtain the user ID. However, Spring, for example, only returns the username when calling /oauth/check_token, also in all JWT examples that I've  seen the username is included in the payload but not the ID.</p>&#xA;&#xA;<p>But why does everyone seem to prefer the username over an ID, when usernames have so many drawbacks (they might change, they might not be unique, ...)?</p>&#xA;&#xA;<p>And what would be the correct solution to get the ID? Maybe token introspection or part of a JWT token?</p>&#xA;"
52104915,Governance methodology for micro services explosion,2018-08-30 20:28:17,<amazon-web-services><architecture><aws-lambda><microservices>,2,23,2,0.0,0,"<p>Microservices are the trend now and most of them are developed on cloud. I have a situation where we are decomposing most of <strong>monolithic services</strong> into <strong>domain level microservices</strong>. Each problem domain having just a handful of services.</p>&#xA;&#xA;<p>In Amazon cloud each individual services would further realize down as multiple lambda functions. As there would <strong>100s of functions</strong> each doing specific kind of activities, deployed by <strong>individual pipeline jobs each</strong>. </p>&#xA;&#xA;<p>The volume of functions can potentially increase to the <strong>order of 1000s</strong> in very near future. This in comparison to 40 monolithic apps we have today. <strong>Is there any way to group, visualize, account usage metrics, cost etc?</strong></p>&#xA;&#xA;<p>The situation would be similar or complex than the xml hell we saw with earlier version spring framework.</p>&#xA;"
52099128,can we have single application.properties file for multiple microservices in spring-boot framework?,2018-08-30 14:09:53,<spring-boot><openshift><microservices>,1,25,2,0.0,0,<p>Is it feasible to have only one application.properties for microservices built in spring-boot and deployed on openshift?</p>&#xA;
52011129,Access database that is outside the docker environment,2018-08-24 20:11:30,<java><docker><docker-compose><microservices>,1,26,2,0.0,0,"<p>I created a microservice environment, more precisely 5 services, where they are connected to each other and access the same database (PostgreSQL). After development, I started to create the docker images for the services. All images have been created, however, I can not put postgreSQL in the docker environment, since it is already running on the machine in localhost, and other applications depend on it, so I can not migrate to the docker environment. I would like to know if it is possible for my applications to access the database that is outside the environment?</p>&#xA;&#xA;<p>Below, my docker-compose</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;    server:&#xA;        image: microservices/server:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        expose:&#xA;          - ""8080""&#xA;        ports:&#xA;          - ""8080:8080""&#xA;        networks:&#xA;          - microservices&#xA;    security-server:&#xA;        image: microservices/security-server:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        depends_on:&#xA;          - server&#xA;        expose:&#xA;          - ""8081""&#xA;        ports:&#xA;          - ""8081:8081""&#xA;        networks:&#xA;          - microservices&#xA;        restart: ""always""&#xA;    api-gateway:&#xA;        image: microservices/api-gateway:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        depends_on:&#xA;          - server&#xA;          - security-server          &#xA;        expose:&#xA;          - ""9999""&#xA;        ports:&#xA;          - ""9999:9999""&#xA;        networks:&#xA;          - microservices&#xA;        restart: ""always""         &#xA;    imovel:&#xA;        image: microservices/imovel:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        depends_on:&#xA;          - server&#xA;          - security-server&#xA;          - api-gateway        &#xA;        expose:&#xA;          - ""8082""&#xA;        ports:&#xA;          - ""8082:8082""&#xA;        networks:&#xA;          - microservices          &#xA;        restart: ""always"" &#xA;    imovel2:&#xA;        image: microservices/imovel:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        depends_on:&#xA;          - server&#xA;          - security-server&#xA;          - api-gateway         &#xA;        expose:&#xA;          - ""9098""&#xA;        ports:&#xA;          - ""9098:9098""&#xA;        networks:&#xA;          - microservices          &#xA;        restart: ""always""           &#xA;    cliente:&#xA;        image: microservices/cliente:latest&#xA;        mem_limit: 1073741824 # RAM 1GB&#xA;        environment:&#xA;          - SPRING_PROFILES_ACTIVE=docker&#xA;        depends_on:&#xA;          - server&#xA;          - security-server&#xA;          - api-gateway          &#xA;        expose:&#xA;          - ""8083""&#xA;        ports:&#xA;          - ""8083:8083""&#xA;        networks:&#xA;          - microservices&#xA;        restart: ""always""            &#xA;networks:&#xA;  microservices:&#xA;    driver: bridge    &#xA;</code></pre>&#xA;&#xA;<p>In the <a href=""https://stackoverflow.com/questions/31249112/allow-docker-container-to-connect-to-a-local-host-postgres-database"">link</a> quoted, his problem was that postgres wasn't accepting connections from outside. My problem is more of the beginning, where should I start configuring the connection?</p>&#xA;"
52097737,Problem with creating consul cluster using ansible,2018-08-30 12:59:13,<ansible><vagrant><microservices><vagrantfile><consul>,1,40,2,0.0,0,"<p>I'm trying to create a Consul cluster using Ansible and i'm using this example <a href=""https://github.com/brianshumate/ansible-consul"" rel=""nofollow noreferrer"">https://github.com/brianshumate/ansible-consul</a> .i'm using the vagrant file to up 3 Ubuntu machines</p>&#xA;&#xA;<p>the problem is that the task <code>Install unzip package</code> seem to always fail,and it gives this error message: </p>&#xA;&#xA;<pre><code>fatal: [consul1.consul -&gt; localhost]: FAILED! =&gt; {""changed"": false, ""msg"": ""Could not detect which package manager to use. Try gathering facts or setting the \""use\"" option.""}&#xA;</code></pre>&#xA;&#xA;<p>Ansible seem unable to recognize the package manager,even though <code>ansible localhost -m setup | grep mgr</code> shows that the variable <code>ansible_pkg_mgr</code> has the value <code>apt</code></p>&#xA;&#xA;<p>i'm not sure what could be the source of the problem.i tried upping 3 debian machines and i still have the same problem.</p>&#xA;&#xA;<p>UPDATE:&#xA;here's the task file for consul</p>&#xA;&#xA;<pre><code>---&#xA;# File: install.yml - package installation tasks for Consul&#xA;&#xA;- name: Install OS packages&#xA;  package:&#xA;    name: ""{{ item }}""&#xA;    state: present&#xA;  with_items: ""{{ consul_os_packages }}""&#xA;  tags: installation&#xA;&#xA;- name: Read package checksum file&#xA;  local_action:&#xA;    module: stat&#xA;    path: ""{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS""&#xA;  become: no&#xA;  run_once: true&#xA;  register: consul_checksum&#xA;  tags: installation&#xA;&#xA;- name: Download package checksum file&#xA;  local_action:&#xA;    module: get_url&#xA;    url: ""{{ consul_checksum_file_url }}""&#xA;    dest: ""{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS""&#xA;  become: no&#xA;  run_once: true&#xA;  tags: installation&#xA;  when: not consul_checksum.stat.exists | bool&#xA;&#xA;- name: Read package checksum&#xA;  local_action:&#xA;    module: shell&#xA;      grep ""{{ consul_pkg }}"" ""{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS"" | awk '{print $1}'&#xA;  become: no&#xA;  run_once: true&#xA;  register: consul_sha256&#xA;  tags: installation&#xA;&#xA;- name: Check Consul package file&#xA;  local_action:&#xA;    module: stat&#xA;    path: ""{{ role_path }}/files/{{ consul_pkg }}""&#xA;  become: no&#xA;  run_once: true&#xA;  register: consul_package&#xA;  tags: installation&#xA;&#xA;- name: Download Consul package&#xA;  local_action:&#xA;    module: get_url&#xA;    url: ""{{ consul_zip_url }}""&#xA;    dest: ""{{ role_path }}/files/{{ consul_pkg }}""&#xA;    checksum: ""sha256:{{ consul_sha256.stdout }}""&#xA;    timeout: ""42""&#xA;  become: no&#xA;  run_once: true&#xA;  tags: installation&#xA;  when: not consul_package.stat.exists | bool&#xA;&#xA;- name: Update alpine package manager (apk)&#xA;  local_action:&#xA;    module: apk&#xA;    update_cache: yes&#xA;  run_once: true&#xA;  when: lookup('file','/etc/alpine-release')&#xA;&#xA;- name: Install unzip package&#xA;  local_action:&#xA;    module: package&#xA;    name: unzip&#xA;    state: present&#xA;  run_once: true&#xA;  when:&#xA;    - consul_install_dependencies | bool&#xA;&#xA;- name: Unarchive Consul package&#xA;  local_action:&#xA;    module: unarchive&#xA;    src: ""{{ role_path }}/files/{{ consul_pkg }}""&#xA;    dest: ""{{ role_path }}/files/""&#xA;    creates: ""{{ role_path }}/files/consul""&#xA;  become: no&#xA;  run_once: true&#xA;  tags: installation&#xA;&#xA;- name: Install Consul&#xA;  copy:&#xA;    src: ""{{ role_path }}/files/consul""&#xA;    dest: ""{{ consul_bin_path }}/consul""&#xA;    owner: ""{{ consul_user }}""&#xA;    group: ""{{ consul_group }}""&#xA;    mode: 0755&#xA;  tags: installation&#xA;&#xA;- name: Daemon reload systemd in case the binaries upgraded&#xA;  command: systemctl daemon-reload&#xA;  become: yes&#xA;  notify: restart consul&#xA;  when:&#xA;    - ansible_service_mgr == ""systemd""&#xA;    - consul_install_upgrade&#xA;&#xA;- name: Cleanup&#xA;  local_action: file path=""{{ item }}"" state=""absent""&#xA;  become: no&#xA;  with_fileglob: ""{{ role_path }}/files/consul""&#xA;  run_once: true&#xA;  tags: installation&#xA;</code></pre>&#xA;"
51996128,Is anaemic model or transaction script good enough for micro service?,2018-08-24 01:00:59,<domain-driven-design><microservices>,2,43,2,0.0,0,"<p>While we always talking about anaemic model being anti-pattern, I'm thinking whether it's just good enough for microservice.</p>&#xA;&#xA;<p>As many has mentioned, anaemic model(or transaction script as Martin Fowler call it), is actually good with small applications. Though with monolithic architecture it's understandable we must use more sophisticated structure to handle complexity.</p>&#xA;&#xA;<p>However, with microservice, it's unlikely we pack too much logic in one single service. Instead a service usually only contains related logic in one single domain, which is usually easy to understand and work upon. In this case, is it totally fine to use transaction script model inside microservice?</p>&#xA;"
52041354,microservice: How to do validations from other microservice,2018-08-27 14:18:08,<validation><microservices>,1,22,3,1.0,0,<p>If there are 2 micro services and if you want a validation to be performed against other micro service. What would be the best scenario to handle these cases?</p>&#xA;
52098392,Consuming RESTful services orchestrated by Kubernetes,2018-08-30 13:33:31,<rest><kubernetes><microservices>,1,26,3,0.0,0,"<p>How do you consume a service that is being orchestrated by Kubernetes?&#xA;What does the calling statement look like.&#xA;When consuming a normal RESTful web service, you might use RestTemplate (for Java) and specify the URL.&#xA;How does this differ when Kubernetes creates and destroys occurrences of the service?</p>&#xA;"
51982133,Message-completion results from a consumer back to a producer,2018-08-23 09:08:45,<redis><aws-lambda><microservices><message-queue><amazon-sqs>,1,36,4,0.0,0,"<p>We are building an application with a microservice architecture.  </p>&#xA;&#xA;<p>The microservice architecture will follow a message-oriented pattern, with AWS SQS.</p>&#xA;&#xA;<p>We would like to return completion results from the consumer service back to the producer service.</p>&#xA;&#xA;<p>This is the algorithm we are considering:</p>&#xA;&#xA;<ol>&#xA;<li>Producer creates a message with a unique id</li>&#xA;<li>Producer subscribes to a Redis channel that is named with the message id</li>&#xA;<li>Producer places the message onto the SQS queue</li>&#xA;<li>Consumer removes the message from the SQS queue and performs an operation</li>&#xA;<li>Consumer publishes the results of the operation to the Redis channel that is named with the message id</li>&#xA;<li>Producer recieves the completion results and resumes execution</li>&#xA;</ol>&#xA;&#xA;<p>Is this a reasonable way to pass message-completion results from a consumer back to a producer?</p>&#xA;"
36858626,Designing System using Message Queues and Coordinating Services,2016-04-26 07:52:25,<design><apache-kafka><apache-zookeeper><microservices><distributed-system>,1,93,0,0.0,0,"<p>I am new with Designing system and have some doubts on Message Queues and coordinating services(zookeeper).</p>&#xA;&#xA;<p>It will be great if someone can clarify these concepts:-</p>&#xA;&#xA;<p>My understanding of MQ in the system that I am designing:-</p>&#xA;&#xA;<p>I will have producer service which will create the message and add to MQ. The consumer will consume this message and do the appropriate action. Once the consumer ACK's the message process completion; MQ will move the offset to next one. I do not want my messages to be missed so I have to be sure that the messages were consumed successfully. Also I am trying to have this system consume messages exactly once(trying as close as possible).</p>&#xA;&#xA;<p>Now I have following questions based on this understanding:-</p>&#xA;&#xA;<p>1)If I want my producer and consumer to be running more than one instance (for High availability) in the same DC then do I need to have both producer and consumer as separate Zookeeper services? Can all my different services(in a microservices world) need separate zookeeper server/instance or a same instance can solve this problem?</p>&#xA;&#xA;<p>2) When the messages are consumed by Consumer it will ACK the MQ after consuming it(completing the processing and taking action whatsoever required.). I am trying to understand how this will be faster for a system which will have thousands of requests every second. If we read more messages or do not wait for ACK till processing then in case of consumer Failure these messages will be missed as they were never processed successfully. I understand that having more consumers will make it work in parallel but am not clear how this concept works. Can someone explain me what will be the right way to consume and configure the interaction between components so that its optimized as well as persistent, high available, reliable and as closed to exactly once model. </p>&#xA;&#xA;<p>EDIT: I am planning to use Java, Zookeeper,Kafka, Cassandra in the system.</p>&#xA;"
36988921,What is a good event store/stream middleware for service-oriented/ microservice-architectures,2016-05-02 18:14:06,<events><soa><microservices><event-driven><event-stream>,2,196,4,0.0,0,"<p>I am building a microservice-architecture and I am looking for a good way to stream events.</p>&#xA;&#xA;<p>Currently I have a service that publishes an event that three other services need to react to in a certain way, however the reaction to this event shall happen only once. </p>&#xA;&#xA;<p>At the moment I am using RabbitMQ and my service publishes three messages in seperate queues, and each subscribing service listens to one queue. So, only one service instance can actually take the message and react to it. </p>&#xA;&#xA;<p>However, I do not like this approach, because if I want to add a new subscriber I have to add a new queue for the publishing service.</p>&#xA;&#xA;<p>I am basically looking for some kind of middleware on an event stream, that lets multiple services listen to one event, but makes sure that only one instance of each service actually reacts to the event.</p>&#xA;&#xA;<p>I haven't found anything yet, so I would appreciate suggestions.</p>&#xA;"
36920620,fastest mechanism to return large data from a micro-service,2016-04-28 16:38:11,<json><rest><http><redis><microservices>,1,323,6,1.0,0,"<p>I am new to the micro-service world.</p>&#xA;&#xA;<p>My micro-service has to return a large data (ballpark of 10-20 Mb).&#xA;The returned data contains <strong>large 2D arrays</strong> (""images"") and <strong>small structured data</strong> that can easily be represented with Json.</p>&#xA;&#xA;<p>Important: Both client and server are <strong>on the same machine</strong>.</p>&#xA;&#xA;<p>I have few options to return the data: </p>&#xA;&#xA;<ol>&#xA;<li>Encode the data to bytes array and send in the <strong>post</strong> body.</li>&#xA;<li>Encode only the ""images"" to binary and <strong>""multi-part"" post</strong> json + binary image1 + ... + binary imageN.</li>&#xA;<li>Write the data to a <strong>server resources</strong> (memory?)&#xA;and send the urls to client. The client will fetch the data with&#xA;few <strong>GET</strong> commands.</li>&#xA;<li>Write the data to <strong>Redis DB</strong> and send the client the&#xA;Redis address and data keys. The client will fetch the data with few&#xA;Redis readings.</li>&#xA;</ol>&#xA;&#xA;<p>What is <strong>fastest</strong> and the industry <strong>best known method</strong> to send back the results?</p>&#xA;"
35179495,Spring Boot Microservices Deployment,2016-02-03 14:16:51,<spring-boot><microservices>,3,542,0,0.0,0,"<p>Has anyone deployed multiple instances of the same microservice? If so, how are you managing such deployments?</p>&#xA;"
33078422,Service registry and api gateway knowledge of services,2015-10-12 10:05:00,<web-services><api><rest><gateway><microservices>,1,432,0,0.0,0,"<p>I m actually studying microservices architecture and there are some points that I dont understand.</p>&#xA;&#xA;<p>In fact, I know that when a user sends a request, the request (admitting in that case /users) is handled by an API gateway.</p>&#xA;&#xA;<p><strong>This API gateway knows that when an url like /users/* is called, it should discover the user service informations from a service registry (in this case ZooKeeper).</strong></p>&#xA;&#xA;<p><em>-> This means that the API gateway should known that on each different pattern, it has to get the concerned service. Is that right every time ?</em></p>&#xA;&#xA;<p><strong>The API gateway then knows how to redirect the request /users to to correct service (through the service registry) and then make the good request to the good endpoint (imagining that the microservice doesn't have an endpoint like /users, but /utilisateurs. The gateway has to know that</strong></p>&#xA;&#xA;<p><em>-> Does it imply that the API gateway has the knowledge of every microservice API endpoint ? Or does it exist a better (automated) manner to make it work ?</em> </p>&#xA;"
33033834,how do I migrate a Java interface to a microservice?,2015-10-09 08:47:54,<java><rest><microservices>,3,764,0,0.0,0,"<p>I am looking at microservices, and the possibility of migrating some of our code to this architecture.  I understand the general concept but am struggling to see how it would work for our example.</p>&#xA;&#xA;<p>Supposing I have an interface called <code>RatingEngine</code> and an implementation called <code>RatingEngineImpl</code>, both running inside my monolithic application.  The principle is simple - The <code>RatingEngineImpl</code> could run in a different machine, and be accessed by the monolithic application via (say) a REST API, serializing the DTOs with json over http.  We even have an interface to help with this decoupling.</p>&#xA;&#xA;<p>But how do I actually go about this?  As far as I can see, I need to create a new implementation of the interface for the rump monolith (ie now the client), which takes calls to the interface methods, converts them into a REST call, and sends them over the network to the new 'rating engine service'.  Then I also need to implement a new http server, with an endpoint for each interface method, which then deserializes the DTOs (method parameters) and routes the call to our original <code>RatingEngineImpl</code>, which sits inside the server.  Then it serializes the response and sends it back to the client.  </p>&#xA;&#xA;<p>So that seems like an awful lot of plumbing code.  It also adds maintenance overhead, since if you tweak a method in the interface you need to make changes in two more places.</p>&#xA;&#xA;<p>Am I missing something?  Is there some clever way we can automate this boilerplate code construction?</p>&#xA;"
34730542,Eureka on docker container : unknown host exception,2016-01-11 20:32:33,<java><docker><spring-boot><microservices><netflix-eureka>,1,2648,0,0.0,0,"<p>I'm trying to start eureka server via spring boot on docker container and getting the following exception ""unknownhostexception"".&#xA;Now in the eureka config.properties file I've used hostname as localhost however the exception is showing that it somehow uses the hostname of the container rather than using the hostname which I've defined in eureka properties file. Moreover even if it uses container defined host name it is resolving fine on container to the right ip and has entry in /etc/hosts.</p>&#xA;&#xA;<p>Note : </p>&#xA;&#xA;<ol>&#xA;<li>This is reproducible only if I use oracle java 7/8, however works fine with openjdk 7. Any clues what might be the problem here.&#xA;&#xA;<ol start=""2"">&#xA;<li>have tried using 127.0.0.1 inplace of localhost in eureka properties without any success.</li>&#xA;</ol></li>&#xA;</ol>&#xA;&#xA;<p>eureka config file content:</p>&#xA;&#xA;<pre><code># Configure this Discovery Server&#xA;eureka:&#xA;  instance:&#xA;    hostname: localhost&#xA;  client:  # Not a client, don't register with yourself&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;server:&#xA;  port: 1111   # HTTP (Tomcat) port&#xA;</code></pre>&#xA;&#xA;<p>Exception stack trace:</p>&#xA;&#xA;<pre><code>2016-01-11 20:04:54 INFO  RegistrationServer:47 - Starting RegistrationServer v0.0.1-SNAPSHOT with PID 1 (/Jars/registration-service-0.0.1-SNAPSHOT.jar started by root in /)&#xA;2016-01-11 20:04:54 INFO  AnnotationConfigApplicationContext:510 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@70ab4338: startup date [Mon Jan 11 20:04:54 GMT 2016]; root of context hierarchy&#xA;2016-01-11 20:04:55 INFO  AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2016-01-11 20:04:55 INFO  Version:27 - HV000001: Hibernate Validator 5.1.3.Final&#xA;2016-01-11 20:04:55 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'encrypt.CONFIGURATION_PROPERTIES' of type [class org.springframework.cloud.bootstrap.encrypt.KeyProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:04:55 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'encryptionBootstrapConfiguration' of type [class org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$$EnhancerBySpringCGLIB$$58540477] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:04:56 INFO  RegistrationServer:56 - Started RegistrationServer in 2.695 seconds (JVM running for 7.037)&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA;[32m :: Spring Boot :: [39m      [2m (v1.2.4.RELEASE)[0;39m&#xA;&#xA;2016-01-11 20:04:57 INFO  AnnotationConfigEmbeddedWebApplicationContext:510 - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@68eefca4: startup date [Mon Jan 11 20:04:57 GMT 2016]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@70ab4338&#xA;2016-01-11 20:05:00 WARN  PathMatchingResourcePatternResolver:652 - Skipping [/tmp/spring-boot-libs/06f98804e83cf4a94380b46591b976b1d17c36b8-eureka-client-1.1.147.jar] because it does not denote a directory&#xA;2016-01-11 20:05:01 WARN  PathMatchingResourcePatternResolver:652 - Skipping [/tmp/spring-boot-libs/b8da6470c5c08e33f9ae3737f338b4b81696fa98-eureka-core-1.1.147.jar] because it does not denote a directory&#xA;2016-01-11 20:05:04 INFO  DefaultListableBeanFactory:822 - Overriding bean definition for bean 'beanNameViewResolver': replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter.class]]&#xA;2016-01-11 20:05:05 INFO  DefaultListableBeanFactory:822 - Overriding bean definition for bean 'infoEndpoint': replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration; factoryMethodName=infoEndpoint; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/actuate/autoconfigure/EndpointAutoConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.cloud.autoconfigure.RefreshAutoConfiguration$InfoEndpointRebinderConfiguration; factoryMethodName=infoEndpoint; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/cloud/autoconfigure/RefreshAutoConfiguration$InfoEndpointRebinderConfiguration.class]]&#xA;2016-01-11 20:05:06 INFO  GenericScope:230 - BeanFactory id=0e0ed65b-ca3b-3a06-a0e2-4597f85dabe8&#xA;2016-01-11 20:05:06 INFO  AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2016-01-11 20:05:07 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$9787da3e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:05:07 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'transactionAttributeSource' of type [class org.springframework.transaction.annotation.AnnotationTransactionAttributeSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:05:07 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'transactionInterceptor' of type [class org.springframework.transaction.interceptor.TransactionInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:05:07 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'org.springframework.transaction.config.internalTransactionAdvisor' of type [class org.springframework.transaction.interceptor.BeanFactoryTransactionAttributeSourceAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:05:07 INFO  PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'org.springframework.cloud.autoconfigure.RefreshAutoConfiguration$ConfigurationPropertiesRebinderConfiguration' of type [class org.springframework.cloud.autoconfigure.RefreshAutoConfiguration$ConfigurationPropertiesRebinderConfiguration$$EnhancerBySpringCGLIB$$888ac754] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-01-11 20:05:09 INFO  TomcatEmbeddedServletContainer:79 - Tomcat initialized with port(s): 1111 (http)&#xA;2016-01-11 20:05:10 INFO  StandardService:180 - Starting service Tomcat&#xA;2016-01-11 20:05:10 INFO  StandardEngine:180 - Starting Servlet Engine: Apache Tomcat/8.0.23&#xA;2016-01-11 20:05:11 INFO  [/]:180 - Initializing Spring embedded WebApplicationContext&#xA;2016-01-11 20:05:11 INFO  ContextLoader:268 - Root WebApplicationContext: initialization completed in 14097 ms&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:286 - Mapping filter: 'metricFilter' to: [/*]&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:286 - Mapping filter: 'characterEncodingFilter' to: [/*]&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:286 - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:286 - Mapping filter: 'webRequestTraceFilter' to: [/*]&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:299 - Mapping filter: 'servletContainer' to urls: [/eureka/*]&#xA;2016-01-11 20:05:17 INFO  FilterRegistrationBean:286 - Mapping filter: 'applicationContextIdFilter' to: [/*]&#xA;2016-01-11 20:05:17 INFO  ServletRegistrationBean:188 - Mapping servlet: 'dispatcherServlet' to [/]&#xA;2016-01-11 20:05:17 INFO  WebApplicationImpl:785 - Initiating Jersey application, version 'Jersey: 1.13 06/29/2012 05:14 PM'&#xA;2016-01-11 20:05:28 ERROR EurekaInstanceConfigBean:122 - Cannot get host info&#xA;java.net.UnknownHostException: ef769e37c05f: ef769e37c05f: Name or service not known&#xA;    at java.net.InetAddress.getLocalHost(InetAddress.java:1475)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean.initHostInfo(EurekaInstanceConfigBean.java:118)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean.&lt;init&gt;(EurekaInstanceConfigBean.java:50)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration.eurekaInstanceConfigBean(EurekaClientAutoConfiguration.java:81)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$$EnhancerBySpringCGLIB$$2debd82d.CGLIB$eurekaInstanceConfigBean$3(&lt;generated&gt;)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$$EnhancerBySpringCGLIB$$2debd82d$$FastClassBySpringCGLIB$$a2b83124.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:309)&#xA;    at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$$EnhancerBySpringCGLIB$$2debd82d.eurekaInstanceConfigBean(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:606)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1119)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1014)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1120)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1044)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:942)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:533)&#xA;    at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:331)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1210)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755)&#xA;    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)&#xA;    at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118)&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:957)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:946)&#xA;    at com.cisco.microservice.registration.RegistrationServer.main(RegistrationServer.java:31)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:606)&#xA;    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:53)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: java.net.UnknownHostException: ef769e37c05f: Name or service not known&#xA;    at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)&#xA;    at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901)&#xA;    at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1295)&#xA;    at java.net.InetAddress.getLocalHost(InetAddress.java:1471)&#xA;    ... 50 more&#xA;2016-01-11 20:05:28 WARN  URLConfigurationSource:120 - No URLs will be polled as dynamic configuration sources.&#xA;2016-01-11 20:05:28 INFO  URLConfigurationSource:121 - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.&#xA;2016-01-11 20:05:28 INFO  DynamicPropertyFactory:281 - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@69f889&#xA;2016-01-11 20:05:29 INFO  RequestMappingHandlerAdapter:517 - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@68eefca4: startup date [Mon Jan 11 20:04:57 GMT 2016]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@70ab4338&#xA;2016-01-11 20:05:29 INFO  RequestMappingHandlerMapping:217 - Mapped ""{[//lastn],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.String org.springframework.cloud.netflix.eureka.server.EurekaController.lastn(javax.servlet.http.HttpServletRequest,java.util.Map&lt;java.lang.String, java.lang.Object&gt;)&#xA;2016-01-11 20:05:29 INFO  RequestMappingHandlerMapping:217 - Mapped ""{[/],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.String org.springframework.cloud.netflix.eureka.server.EurekaController.status(javax.servlet.http.HttpServletRequest,java.util.Map&lt;java.lang.String, java.lang.Object&gt;)&#xA;2016-01-11 20:05:29 INFO  RequestMappingHandlerMapping:217 - Mapped ""{[/error],methods=[],params=[],headers=[],consumes=[],produces=[text/html],custom=[]}"" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest)&#xA;2016-01-11 20:05:29 INFO  RequestMappingHandlerMapping:217 - Mapped ""{[/error],methods=[],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)&#xA;2016-01-11 20:05:29 INFO  SimpleUrlHandlerMapping:314 - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;2016-01-11 20:05:29 INFO  SimpleUrlHandlerMapping:314 - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;2016-01-11 20:05:29 INFO  SimpleUrlHandlerMapping:314 - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/metrics/{name:.*}],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/metrics],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/trace],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/health],methods=[],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/configprops],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/refresh],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/pause],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/autoconfig],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/info],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/mappings],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/env],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map&lt;java.lang.String, java.lang.String&gt;)&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/env/reset],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.util.Map&lt;java.lang.String, java.lang.Object&gt; org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/restart],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/archaius],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/dump],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/env/{name:.*}],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/env],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/beans],methods=[GET],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&#xA;2016-01-11 20:05:32 INFO  EndpointHandlerMapping:217 - Mapped ""{[/resume],methods=[POST],params=[],headers=[],consumes=[],produces=[],custom=[]}"" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()&#xA;2016-01-11 20:05:32 INFO  SpringTemplateLoader:61 - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@68eefca4: startup date [Mon Jan 11 20:04:57 GMT 2016]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@70ab4338] and template loader path [classpath:/templates/]&#xA;2016-01-11 20:05:32 INFO  FreeMarkerConfigurer:127 - ClassTemplateLoader for Spring macros added to FreeMarker configuration&#xA;2016-01-11 20:05:33 WARN  URLConfigurationSource:120 - No URLs will be polled as dynamic configuration sources.&#xA;2016-01-11 20:05:33 INFO  URLConfigurationSource:121 - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:431 - Registering beans for JMX exposure on startup&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:912 - Bean with name 'refreshEndpoint' has been autodetected for JMX exposure&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:912 - Bean with name 'restartEndpoint' has been autodetected for JMX exposure&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:912 - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:912 - Bean with name 'refreshScope' has been autodetected for JMX exposure&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:912 - Bean with name 'environmentManager' has been autodetected for JMX exposure&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:674 - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:674 - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:674 - Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:674 - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=68eefca4,type=ConfigurationPropertiesRebinder]&#xA;2016-01-11 20:05:33 INFO  AnnotationMBeanExporter:674 - Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.bootstrap.config:name=refreshEndpoint,type=RefreshEndpoint]&#xA;2016-01-11 20:05:33 INFO  EndpointMBeanExporter:431 - Registering beans for JMX exposure on startup&#xA;2016-01-11 20:05:33 INFO  DefaultLifecycleProcessor:341 - Starting beans in phase 0&#xA;2016-01-11 20:05:33 INFO  EurekaConfigBasedInstanceInfoProvider:80 - Setting initial instance status as: STARTING&#xA;^C^C2016-01-11 20:05:35 INFO  AnnotationConfigApplicationContext:862 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@70ab4338: startup date [Mon Jan 11 20:04:54 GMT 2016]; root of context hierarchy&#xA;^C^C&#xA;</code></pre>&#xA;"
35315679,Should iOS client retry on server (microservice) failure?,2016-02-10 12:44:59,<ios><mobile><client-server><microservices><conceptual>,1,49,0,0.0,0,"<p>I'm building a project consisting of an iOS app that communicates with microservices via HTTP for many reasons: authenticating users, saving data, retrieving data, and more. </p>&#xA;&#xA;<p>If the <strong>client fails</strong>, the app crashes. This will be reported and fixed if possible for the following release.</p>&#xA;&#xA;<p><em>Here's my question:</em> </p>&#xA;&#xA;<ol>&#xA;<li><p>If the <strong>server fails</strong>, it returns an error HTTP code (4XX, 5XX, etc). How should the iOS app react? Should it accept failure and notify the user? Should it re-try? How many times? </p></li>&#xA;<li><p>If the <strong>database fails</strong>, the server returns an error message via JSON. Again, how should the iOS app react?</p></li>&#xA;</ol>&#xA;&#xA;<p><em>Does the answer depend on the technologies used?</em></p>&#xA;"
35329128,Transferring from a monolithic application to a micro service one - approach,2016-02-11 01:16:09,<amazon-web-services><microservices>,1,76,0,0.0,0,"<p>We currently have a monolithic web application built with Scala (scalatra for the Rest APIs) for the backend and AngularJS for the front end. The application is deployed at AWS. We are going to build a new component, which we would like to build it as an independent microservice. And this component will have its own data repository which may not be the same type of DB. It will also be built with Scala as well, but Akka for the Rest APIs. The current application is built with DB module, domain module, and web service API module and front end/client module.</p>&#xA;&#xA;<p>What is a good approach of a smooth journey? We possibly need to set up a micro service architecture first, such as an API gateway service along with others.   </p>&#xA;"
35267071,How microservices are managed using Mantl?,2016-02-08 10:14:12,<docker><microservices>,1,397,0,1.0,0,"<p>Recently I came across <a href=""http://microservices-infrastructure.readthedocs.org/en/latest/getting_started/index.html"" rel=""nofollow"">Mantl</a> ( microservices infrastructure management project by Cisco). Its an opensource one and they have  pushed it on <a href=""https://github.com/CiscoCloud/microservices-infrastructure#deploying-on-multiple-servers"" rel=""nofollow"">github</a>. I didn't understood their basic working. Does anyone have any idea about that ? </p>&#xA;"
35286730,How to execute efficient communication for multiple (micro)services?,2016-02-09 08:01:49,<php><rest><restful-architecture><microservices>,1,574,1,1.0,0,"<p><strong>Case:</strong> Software build with many microservices and internal services.</p>&#xA;&#xA;<p><strong>The doubt</strong> is how to manage performance issues (network latency, size of resource) getting multiple resources from many microservices at once.</p>&#xA;&#xA;<p>I Just can not imagine making 20 HTTP requests to access all necessary resources.</p>&#xA;"
34109946,Delivery tier example in Forrester 4-tier model of mobile web apps,2015-12-05 19:37:27,<model-view-controller><mobile><nginx><architecture><microservices>,1,425,0,0.0,0,"<p>Forrester report suggests a new 4-tier architecture to mobile apps: Client, Delivery, Aggregation, and Services.</p>&#xA;&#xA;<p>Several articles describe the model:</p>&#xA;&#xA;<ul>&#xA;<li><a href=""http://blogs.forrester.com/ted_schadler/13-11-20-mobile_needs_a_four_tier_engagement_platform"" rel=""nofollow"">http://blogs.forrester.com/ted_schadler/13-11-20-mobile_needs_a_four_tier_engagement_platform</a></li>&#xA;<li><a href=""https://www.nginx.com/blog/time-to-move-to-a-four-tier-application-architecture/"" rel=""nofollow"">https://www.nginx.com/blog/time-to-move-to-a-four-tier-application-architecture/</a></li>&#xA;<li><a href=""https://strongloop.com/strongblog/node-js-api-tier-enterprise/"" rel=""nofollow"">https://strongloop.com/strongblog/node-js-api-tier-enterprise/</a></li>&#xA;</ul>&#xA;&#xA;<p>I seem to understand a typical implementation of the Client, Aggregation, and Services tiers, but I am still struggling to understand how the Delivery tier might be typically implemented.</p>&#xA;&#xA;<p>My understanding of the model so far: </p>&#xA;&#xA;<ul>&#xA;<li>Client: runs on the Client device or as JS in the browser</li>&#xA;<li>Delivery: Unclear. Probably a combination of a Load Balancer with Apache HTTP Server/Nginx. <strong>Is this correct?</strong></li>&#xA;<li>Aggregation: my app residing in a tomcat/netty. Communicates with other services/microservices on behalf of the client, typically over REST.</li>&#xA;<li>Services: other internal or external apps </li>&#xA;</ul>&#xA;&#xA;<p>Is the above description correct? <br/>&#xA;<strong>I need simple examples of how the Delivery tier is typically implemented, preferably in the Java stack.</strong> <br/>&#xA;Please don't include CDNs in your answer - I am interested in examples that don't use them.</p>&#xA;"
34077752,Service Fabric: packaging code error: missing required references,2015-12-03 22:50:52,<azure><reference><package><microservices><azure-service-fabric>,2,442,0,0.0,0,"<p>After updating SF I've got an issue that prevents using of SF totally, I'll try to put a problem in words without code.</p>&#xA;&#xA;<p>Service fabric application <code>AppName.SF</code> consists of an <code>AppName.SF.StatefulActor</code> and <code>AppName.SF.StatefulService</code>. Both reference to class library called <code>AppName.Core</code>.</p>&#xA;&#xA;<p><strong>Case 1:</strong> <code>StatefulActor</code> not references <code>StatefulService</code> - package performs OK:</p>&#xA;&#xA;<p><code>AppName.SF\pkg\Debug\AppName.SF.StatefulActor\Code has</code> <code>AppName.Core.dll</code></p>&#xA;&#xA;<p><code>AppName.SF\pkg\Debug\AppName.SF.StatefulService\Code</code> has <code>AppName.Core.dll</code></p>&#xA;&#xA;<p>each package Code folder has <code>AppName.Core.dll</code>. Deployment performs successfully.</p>&#xA;&#xA;<p><strong>Case 2:</strong> <code>StatefulActor</code> references <code>StatefulService</code> - package performs BAD:</p>&#xA;&#xA;<p><code>AppName.SF\pkg\Debug\AppName.SF.StatefulActor\Code</code> has <code>AppName.Core.dll</code></p>&#xA;&#xA;<p><code>AppName.SF\pkg\Debug\AppName.SF.StatefulService\Code</code> has <strong>no(!)</strong> <code>AppName.Core.dll</code></p>&#xA;&#xA;<p>So I get a missing reference error if I try to deploy application in cluster. Issue appeared after SF updated to 1.4.87-preview.</p>&#xA;"
34163944,Zuul Autodiscovery issues,2015-12-08 19:04:35,<microservices><netflix-eureka><netflix-zuul>,1,453,0,1.0,0,"<p>We are in the process of standing up a new microservices architecture with Zuul at the front-end and a bunch of tomcat enabled microservices at the backend. Each service as it starts up, will register itself with Eureka and any client that wants to call those service will do so through Zuul. We've got this all wired in and everything is working fine. </p>&#xA;&#xA;<p>However, I have a couple questions as to how we can make this architecture much more dynamic.</p>&#xA;&#xA;<ol>&#xA;<li>One thing that we assumed was there out of the box with Ribbon/Eureka, but have yet to find a solution for is that as we add more services to the backend, that somehow (via Archiaus and update to Zuul's eureka-client.properties file) Zuul's Ribbon client would update itself with the new service details (e.g. vipaddress, load balancing algorithm, etc). So far, the only thing that works is to update the properties file and restart Zuul (ughhh).</li>&#xA;</ol>&#xA;&#xA;<p>For example, let's say today we have 2 microservices at the backend, therefore, Zuul's eureka/ribbon client configuration would include the below:</p>&#xA;&#xA;<p>ribbon.client.niws.clientlist=service1|service2&#xA;zuul.ribbon.namespace=zuul.client</p>&#xA;&#xA;<p>service1.zuul.client.DeploymentContextBasedVipAddresses=myService1&#xA;service1.zuul.client.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>&#xA;&#xA;<p>service2.zuul.client.DeploymentContextBasedVipAddresses=myService2&#xA;service2.zuul.client.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>&#xA;&#xA;<p>Now tomorrow, let's assume we need to add service3. What we have observed is that if we add those details to the same configuration (see below), they only become available to Zuul after a restart. Is there some other configuration parameter we are missing that would allow us to dynamically introduce the new service details or do we have to roll our own Eureka/Ribbon client to do this? </p>&#xA;&#xA;<p>ribbon.client.niws.clientlist=service1|service2|service3&#xA;zuul.ribbon.namespace=zuul.client</p>&#xA;&#xA;<p>service1.zuul.client.DeploymentContextBasedVipAddresses=myService1&#xA;service1.zuul.client.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>&#xA;&#xA;<p>service2.zuul.client.DeploymentContextBasedVipAddresses=myService2&#xA;service2.zuul.client.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>&#xA;&#xA;<p>service3.zuul.client.DeploymentContextBasedVipAddresses=myService3&#xA;service3.zuul.client.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>My other question is related and that is do we really need to add a client configuration (in eureka-client.properties) for every service that Zuul could possibly route to?  At some point, we may have 100's of services running and trying to maintain all the related client configurations in Zuul seems a bit clumsy. Is there a way to globally configure Zuul to load all services into its client list from Eureka (or based on some service metadata in Eureka) and dynamically update this list as new services register themselves with Eureka?</li>&#xA;</ol>&#xA;&#xA;<p>Thanks!</p>&#xA;"
34230517,Play akka microservice as multi project,2015-12-11 18:48:31,<playframework><sbt><akka><microservices><multi-project>,1,203,0,0.0,0,"<p>I am learning about microservices. For demonstration purposes I want to combine a frontend: <code>play</code> with some backend services: <code>Akka</code>. SBT<code>s</code>multi-project` compilation should be well suited for this. However I face some problems:</p>&#xA;&#xA;<ul>&#xA;<li>The main class cannot be found - even if I navigate into the correct sub-module. </li>&#xA;<li>The dependencies are not resolved, even though they seem to be defined correctly.</li>&#xA;</ul>&#xA;&#xA;<p>To follow along:&#xA;<a href=""https://github.com/dataplayground/microservice"" rel=""nofollow"">https://github.com/dataplayground/microservice</a></p>&#xA;"
35926145,Micro service conceptual clarification and good practices,2016-03-10 20:03:42,<microservices>,1,74,2,0.0,0,"<p>One of the tenets of micro services is that they are developed and deployed independently and some even says that micro services must use different tables to be truly decoupled and independent.</p>&#xA;&#xA;<p>So, when we talk about business exposed using micro services it is not entirely true.  If you have a normalized database and a table for user, another for user address because one user may have one or more addresses (residential, comercial...) and another table for telephones for the same reason the micro service os client would use more than one table.&#xA;1 - In that case we can still classify it as micro service? (maybe my understanding of micro service could be incorrect or incomplete)&#xA;2 - If I can not classify it as micro service, than how to correctly develop a micro service for it?&#xA;3 - If the assumption that each micro service must use one table only to decouple than most cases of micro services could be resumed to CRUD exposition?</p>&#xA;"
36116835,Recommended patterns to consume an asynchronous microservice from a client?,2016-03-20 17:12:48,<asynchronous><microservices>,1,129,2,0.0,0,"<p>so our use case is to have a microservice which is very expensive (takes time to run). this service is consumed by any client.</p>&#xA;&#xA;<p>i've read about some patterns for best practices for consuming, for example:</p>&#xA;&#xA;<ol>&#xA;<li>use WebSockets - which will make the server able to send the result back to the client.</li>&#xA;<li>Constant polling (i don't like it much)</li>&#xA;<li>Leases - it's some kind of polling - the client will acquire a lease for X minutes, and will renew it every few minutes until a response comes - but if the response comes back, the client will still have to wait for it (although the result is ready already) - this will make cleanup easier (clients which abandoned the requests)</li>&#xA;</ol>&#xA;&#xA;<p>i'd love to hear about your best practices in this event-driven microservices architecture</p>&#xA;&#xA;<p>thanks!</p>&#xA;"
35914674,Cascading microservices using Meteor,2016-03-10 11:06:08,<meteor><package><cluster-computing><microservices>,1,169,11,1.0,0,"<p>I've been looking into scaling Meteor, and had an idea by using the <a href=""https://www.google.co.uk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi3z66g-7XLAhWDRhQKHS_qBwsQFggkMAA&amp;url=https%3A%2F%2Fgithub.com%2Fmeteorhacks%2Fcluster&amp;usg=AFQjCNEy9N5lo-9TmjFYvjgmCCO93mAwmg"" rel=""nofollow"">Meteor Cluster package</a>;</p>&#xA;&#xA;<ul>&#xA;<li>Create a super-service*, which the user connects to, containing general core packages to be used by every micro-service (api, app, salesSite, etc. would make use of its package),</li>&#xA;<li>The super-service then routes to the appropriate micro-service (e.g., the app), providing it with the functionality of its own packages.</li>&#xA;</ul>&#xA;&#xA;<p>(* - as in super- and sub-, not that it's awesome... I mean it is but...)</p>&#xA;&#xA;<p>The idea being that I can cascade each service as a superset of the super-service. This would also allow me to cleverly inherit functionality for other services in a cascading service style. E.g.,</p>&#xA;&#xA;<p>unauthedApp > guestApp > userApp > modApp > adminApp, </p>&#xA;&#xA;<p>for the application, where the functionality of the previous service are inherited to the preceding service (e.g., the further right along that chain, the more extra functionality is added and inherited).</p>&#xA;&#xA;<p>Is this possible?</p>&#xA;&#xA;<p>EDIT: If possible, is there a provided example of how to implement such a pattern using micro-services?</p>&#xA;&#xA;<p><strong>[[[[[ BIG EDIT #2: ]]]]]</strong></p>&#xA;&#xA;<p>Think I'm trying to make a solution fit the problem, so let me re-explain so this question can be answered based on the issue rather than the solution I'm trying to implement.</p>&#xA;&#xA;<p>Basically, I want to ""inherit"" (for lack of a better word) the packages depended on needed functionality, so that no code is unnecessarily sent through the wire. </p>&#xA;&#xA;<p>So starting with the core packages, which has libraries I want all of my services to have, I then want to further ""add"" the functionality as needed. Then I want to add page packages if serving a page-based service (instead of, say, the API service, which doesn't render pages), then the appropriate role-based page packages, etc., until the most specific packages are added.</p>&#xA;&#xA;<p>My thought was that I could make the services chain in such a way that I could traverse through from the most generic to most specific service, and that would finally end with a composition of packages from multiple services. So, for e.g., the guestApp, that might be the core packages + generic page packages + generic app packages + unauthApp packages + guestApp packages, so no unneccessary packages are added.</p>&#xA;&#xA;<p>Also with this imaginary pattern I'm describing, I don't need to add all my core packages to each microservice - I can deal with them all within the core package right at the top of the package traversal I've discussed above and not have to worry about forgetting to add the packages to the ""inherited"" packages.</p>&#xA;&#xA;<p>Hope my reasoning here makes sense, and I hope you guys know of a best practice for doing this. Thank you!</p>&#xA;"
32778803,"Four webapps, one have to expose an HTTP authentication to the others",2015-09-25 09:16:40,<design><architecture><http-authentication><microservices>,1,42,0,0.0,0,"<p>I'm in this situation: I have to build four webapps, A, B, C, D, one of them, let's say A, have to expose an HTTP authentication API to the others.&#xA;Does this can called a microservice architecture?&#xA;A, B, C, D are all webapp. Every of them has a database. A contains users and groups. B, C, D have to authenticate on A and save entities related to A.&#xA;Which options I have to implement this? Oauth? Any suggested resources to read/study? </p>&#xA;"
32750861,Using search in grails 3.x web-micro rest call does not work,2015-09-23 23:03:17,<grails><microservices>,1,80,3,0.0,0,"<p>I'm using the web-micro profile from Grails 3.x to write microservices.  I need to be able to search on one of the fields.  I believe in previous versions of grails, you could add the fields to the query string. </p>&#xA;&#xA;<p><a href=""http://localhost:3141/zipcode?zip=55509"" rel=""nofollow"">http://localhost:3141/zipcode?zip=55509</a> would return just the zipcode object(s) that had that value for zip.</p>&#xA;&#xA;<p>This does not seem to work in Grails 3.x web-micro.</p>&#xA;&#xA;<pre><code>@Entity &#xA;@Resource(uri=""/zipcode"") &#xA;class ZipCode { &#xA;    static belongsTo = [kingdomGroup : KingdomGroup] &#xA;    String zip &#xA;&#xA;    static constraints = { &#xA;    }&#xA;&#xA;    String toString() { zip } &#xA;}&#xA;</code></pre>&#xA;"
34402406,Spring microservices: response with info from other microservices,2015-12-21 18:49:57,<java><spring><microservices><netflix-eureka>,2,60,0,0.0,0,<p>Let's say we have two services AccountService and OrderService. Both are registered with Eureka. Now a third service can get info from Eureka about these two services and make calls however what I need is when a get order call is executed it should internally call account service to get the account info to be filled in the order bean and then respond. Please note that the databases for each service is different and account id is stored in order table as well for referece.&#xA;Now how should the Order service be built such that at run time it can fetch accounts and build order objects with that info.&#xA;Now in a monolithic design where all entities are in single RDBMS it would have been very easy to manage nested objects with hibernate however not sure how to handle it in microservices where the idea is to decouple them completely.</p>&#xA;&#xA;<pre><code>class Account(){&#xA;String name;&#xA;Long acct_id;&#xA;}&#xA;class Order(){&#xA;Account acct;&#xA;int order_id;&#xA;....&#xA;}&#xA;</code></pre>&#xA;
34376576,Best architecture to share large files among microservices,2015-12-19 23:42:44,<nfs><microservices><data-sharing>,1,1629,0,0.0,0,"<p>I am about to start re-designing an old monolithic software with a microservices-oriented architecture (educational purposes). To give a bit of context, the old software runs on a powerful server that performs the following operations:</p>&#xA;&#xA;<ol>&#xA;<li>Receives batch data (binary file) from a producer.</li>&#xA;<li>Accumulates batch data from each producer.</li>&#xA;<li>Periodically, execute a batch operation over each producer's accumulated data, and store the result (another binary file).</li>&#xA;</ol>&#xA;&#xA;<p>Now, I want to create a separated microservice for this batch operation.  I would like to have this microservice executed in dozens of machines in paralell, so that I can process a big amount of producers.</p>&#xA;&#xA;<p>Each microservice instance will receive a binary file with each producer's data and output another binary file. The problem is that these files can be big (e.g. each producer may produce 20Mb of accumulated data). I came across several ways of dealing with this but I am not convinced by any of them:</p>&#xA;&#xA;<ol>&#xA;<li>Send the binary data among microservices using HTTP calls. I did not try it but it does not seem reasonable.</li>&#xA;<li>Store all the data in a central data repository from where each microservice can download it. Maybe I could use some sort of NFS, but I am not sure if that's a good option. Also, doesn't this go against the microservices philosophy?</li>&#xA;<li>Have a copy of all the data near each microservice. I am afraid I'll eventually run into consistency problems.</li>&#xA;</ol>&#xA;&#xA;<p>What do you believe is the best option (if any)? Thanks!</p>&#xA;"
34341322,Spring cloud proxy service-to-service calls,2015-12-17 18:03:18,<spring><spring-boot><spring-cloud><microservices>,2,119,0,0.0,0,"<p>Currently I have a frontend service that makes calls to a notification service. The frontend service does not depend on the response from the notification service. I want the frontend service to make a call to the notification, but not wait for a response from the notification service. Could do this within the frontend service itself? Do I have to use some messaging service that can 'proxy' the calls between the two services?</p>&#xA;"
34424706,How to access meteor collection through the database,2015-12-22 21:28:48,<meteor><microservices>,3,154,1,0.0,0,"<p>I want to have my application's admin code hosted on a completely different app that shares the same database. However, that means that my collections are defined, at least in the code, in the global namespace of my main application and not my admin application. How can I access my collections, that are in the database, without having the global variables defined in a file shared between the meteor server/client? For reference, I am using this article as the idea to set up my admin tools this way. <a href=""http://joshowens.me/building-an-admin-app-as-a-microservice-with-meteor-js/"" rel=""nofollow"">admin article</a></p>&#xA;"
34502682,make a post request with in node.js application,2015-12-29 00:16:16,<node.js><microservices>,2,469,0,0.0,0,"<p>I've a node.js service with /api/authenticate endpoint. I can call this service successfully from POSTMAN with 'username' and 'password' as input (body parameters). How do I call the same services from another node.js server? </p>&#xA;&#xA;<p>With postman I get,</p>&#xA;&#xA;<pre><code>body: {name: 'xxxxxx', password: 'xxxxxx' }&#xA;headers: { 'content-type': 'application/x-www-form-urlencoded',&#xA;  host: 'xx.xx.xx.xx:xxxx',&#xA;  connection: 'close',&#xA;  'content-length': '0' }&#xA;</code></pre>&#xA;&#xA;<h1>    POST /api/authenticate 200 1.336 ms - 72</h1>&#xA;&#xA;<p>Following is another nodejs application ... which makes a successful request call but doesn't have any body parameters (username and password) when it reaches to the authentication server api.</p>&#xA;&#xA;<pre><code>var my_http = require('http');&#xA;&#xA;app.get('/makeacall', function(req, res) {&#xA;  var output = '';&#xA;  var options = {&#xA;    body: { name: 'xxxxxx', password: 'xxxxxx' },&#xA;    method: 'POST',&#xA;    host: 'xx.xx.xx.xx',&#xA;    port: 'xxxx',&#xA;    path: '/api/authenticate',&#xA;    headers: {&#xA;      'Content-Type': 'application/x-www-form-urlencoded'&#xA;    }&#xA;  };&#xA;&#xA;console.log('before request');&#xA;&#xA;var req = my_http.request(options, function(response) {&#xA;  console.log('response is: ' + response);&#xA;  console.log('Response status code: ' + response.statusCode); &#xA;  response.on('data', function(chunk) {&#xA;   console.log('Data ..');&#xA;   output += chunk;&#xA;  });&#xA;  response.on('end', function(chunk) {&#xA;   console.log('Whole Data ..' + output);&#xA;  });&#xA;&#xA;});&#xA;req.on('error', function(err) {&#xA;  console.log('Error: ' + err);&#xA;});&#xA;req.end();&#xA;console.log('444');&#xA;res.send({ message: 'View record message'});&#xA;</code></pre>&#xA;&#xA;<p>});</p>&#xA;&#xA;<p>From this nodejs application I get empty body on the server.</p>&#xA;&#xA;<pre><code>body: {}&#xA;headers: { 'content-type': 'application/x-www-form-urlencoded',&#xA;  host: 'xx.xx.xx.xx:xxxx',&#xA;  connection: 'close',&#xA;  'content-length': '0' }&#xA;POST /api/authenticate 200 1.336 ms - 72&#xA;</code></pre>&#xA;&#xA;<p>What am I missing? Any help is appreciated.</p>&#xA;"
39405067,org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization,2016-09-09 06:23:48,<java><spring-boot><microservices>,1,14900,0,2.0,0,"<p>I'm developing <strong>spring boot microservices</strong> example from the link: <a href=""https://dzone.com/articles/spring-boot-creating"" rel=""nofollow"">https://dzone.com/articles/spring-boot-creating</a>. In this project I simply updated the parent dependency to its latest version and other code files are unchanged. I faced the following error when I click <strong><a href=""http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4"" rel=""nofollow"">http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4</a></strong></p>&#xA;&#xA;<pre><code>2016-09-09 11:46:20.888 ERROR 14152 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : StandardWrapper.Throwable&#xA;&#xA;org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization.&#xA;[[FATAL] A resource model has ambiguous (sub-)resource method for HTTP method GET and input mime-types as defined by""@Consumes"" and ""@Produces"" annotations at Java methods public java.util.List br.com.alexandreesl.handson.rest.ProductRest.getProducts() and public java.util.List br.com.alexandreesl.handson.rest.CustomerRest.getCustomers() at matching regular expression /. These two methods produces and consumes exactly the same mime-types and therefore their invocation as a resource methods will always fail.; source='org.glassfish.jersey.server.model.RuntimeResource@14c14bf']&#xA;    at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:555) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.access$500(ApplicationHandler.java:184) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:350) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:315) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:297) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.processWithException(Errors.java:255) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.&lt;init&gt;(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.WebComponent.&lt;init&gt;(WebComponent.java:392) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:177) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:369) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at javax.servlet.GenericServlet.init(GenericServlet.java:158) ~[tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1194) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.allocate(StandardWrapper.java:806) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:133) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:522) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:1110) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:785) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1425) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_102]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_102]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_102]&#xA;</code></pre>&#xA;&#xA;<p>the updated <strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;junit&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;junit&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Application.java</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;public class Application {&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(Application.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ApplicationConfig.java</strong></p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class ApplicationConfig {&#xA;    @Named&#xA;    static class JerseyConfig extends ResourceConfig {&#xA;        public JerseyConfig() {&#xA;            this.packages(""br.com.alexandreesl.handson.rest"");&#xA;        }&#xA;    }&#xA;&#xA;    @Bean&#xA;    public RestTemplate restTemplate() {&#xA;        RestTemplate restTemplate = new RestTemplate();&#xA;        return restTemplate;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Order.java</strong></p>&#xA;&#xA;<pre><code>public class Order {&#xA;    private long id;&#xA;    private long amount;&#xA;    private Date dateOrder;&#xA;    private Customer customer;&#xA;    private Product product;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>OrderRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class OrderRest {&#xA;    private long id = 1;&#xA;&#xA;    @Inject&#xA;    private RestTemplate restTemplate;&#xA;&#xA;    @GET&#xA;    @Path(""order"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Order submitOrder(@QueryParam(""idCustomer"") long idCustomer,&#xA;            @QueryParam(""idProduct"") long idProduct,&#xA;            @QueryParam(""amount"") long amount) {&#xA;&#xA;        Customer customer = restTemplate.getForObject(""http://localhost:8080/customer?id={id}"", Customer.class, idCustomer);&#xA;        Product product = restTemplate.getForObject(""http://localhost:8080/product?id={id}"", Product.class,idProduct);&#xA;&#xA;        Order order = new Order();&#xA;        order.setCustomer(customer);&#xA;        order.setProduct(product);&#xA;        order.setId(id);&#xA;        order.setAmount(amount);&#xA;        order.setDateOrder(new Date());&#xA;        id++;&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Customer.java</strong></p>&#xA;&#xA;<pre><code>public class Customer {&#xA;    private long id;&#xA;    private String name;&#xA;    private String email;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>CustomerRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class CustomerRest {&#xA;    private static List&lt;Customer&gt; customers = new ArrayList&lt;Customer&gt;();&#xA;&#xA;    static {&#xA;        Customer customer1 = new Customer();&#xA;        customer1.setId(1);&#xA;        customer1.setNome(""Customer 1"");&#xA;        customer1.setEmail(""customer1@gmail.com"");&#xA;&#xA;        Customer customer2 = new Customer();&#xA;        customer2.setId(2);&#xA;        customer2.setNome(""Customer 2"");&#xA;        customer2.setEmail(""Customer2@gmail.com"");&#xA;&#xA;        Customer customer3 = new Customer();&#xA;        customer3.setId(3);&#xA;        customer3.setNome(""Customer 3"");&#xA;        customer3.setEmail(""Customer3@gmail.com"");&#xA;&#xA;        Customer customer4 = new Customer();&#xA;        customer4.setId(4);&#xA;        customer4.setNome(""Customer 4"");&#xA;        customer4.setEmail(""Customer4@gmail.com"");&#xA;&#xA;        Customer customer5 = new Customer();&#xA;        customer5.setId(5);&#xA;        customer5.setNome(""Customer 5"");&#xA;        customer5.setEmail(""Customer5@gmail.com"");&#xA;&#xA;        customers.add(customer1);&#xA;        customers.add(customer2);&#xA;        customers.add(customer3);&#xA;        customers.add(customer4);&#xA;        customers.add(customer5);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Customer&gt; getCustomers() {&#xA;        return customers;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""customer"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Customer getCustomer(@QueryParam(""id"") long id) {&#xA;        Customer cli = null;&#xA;        for (Customer c : customers) {&#xA;            if (c.getId() == id)&#xA;                cli = c;&#xA;        }&#xA;        return cli;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Product.java</strong></p>&#xA;&#xA;<pre><code>public class Product {&#xA;    private long id;&#xA;    private String sku;&#xA;    private String description;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ProductRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class ProductRest {&#xA;    private static List&lt;Product&gt; products = new ArrayList&lt;Product&gt;();&#xA;&#xA;    static {&#xA;        Product product1 = new Product();&#xA;        product1.setId(1);&#xA;        product1.setSku(""abcd1"");&#xA;        product1.setDescription(""Product1"");&#xA;        Product product2 = new Product();&#xA;        product2.setId(2);&#xA;        product2.setSku(""abcd2"");&#xA;        product2.setDescription(""Product2"");&#xA;        Product product3 = new Product();&#xA;        product3.setId(3);&#xA;        product3.setSku(""abcd3"");&#xA;        product3.setDescription(""Product3"");&#xA;        Product product4 = new Product();&#xA;        product4.setId(4);&#xA;        product4.setSku(""abcd4"");&#xA;        product4.setDescription(""Product4"");&#xA;        products.add(product1);&#xA;        products.add(product2);&#xA;        products.add(product3);&#xA;        products.add(product4);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Product&gt; getProducts() {&#xA;        return products;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""product"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Product getProduct(@QueryParam(""id"") long id) {&#xA;        Product prod = null;&#xA;        for (Product p : products) {&#xA;            if (p.getId() == id)&#xA;                prod = p;&#xA;        }&#xA;        return prod;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please guide on this issue.</p>&#xA;"
39555686,.NET REST API with Vert.x,2016-09-18 08:38:11,<java><c#><rest><microservices><vert.x>,1,327,0,1.0,0,"<p>I have a .NET REST API application that read some data from active directory. </p>&#xA;&#xA;<p>I want to build a microservices based environment and decide to use <a href=""http://vertx.io/"" rel=""nofollow"">http://vertx.io/</a> that is written in java. Vert.x support different language except for .NET application.  </p>&#xA;&#xA;<p>My question is, how can I deploy a .NET REST API application to Vert.x that I can communicate with other Vert.x based services. As far I understood, Microservices environment provide you to programming in different languages.  </p>&#xA;"
39425569,Spring Boot Java8 Microservice Simple Message Subscription service,2016-09-10 11:27:38,<spring-boot><java-8><jms><microservices>,2,659,0,0.0,0,<p>I am new to Microservice and JMS likes to know how can I</p>&#xA;&#xA;<ul>&#xA;<li>create a subscription      </li>&#xA;<li>read the subscription </li>&#xA;</ul>&#xA;&#xA;<p>Using Spring Boot and JMS </p>&#xA;
39622142,resilient microservices design pattern,2016-09-21 16:42:31,<reactive-programming><microservices><resiliency>,2,154,0,2.0,0,"<p>in reactive programming Resilience is achieved by replication, containment, isolation and delegation.</p>&#xA;&#xA;<p>two of the famous design patterns are Bulkheads with supervisor and circuit breaks. are these only for reaching isolation and containment?</p>&#xA;&#xA;<p>what are the most famous design patterns for microservices and specially the ones give resiliency?  </p>&#xA;"
39414913,Optimising a microservice to be queried with other domain data,2016-09-09 15:22:09,<cqrs><microservices>,1,170,0,0.0,0,"<p>Consider I have these somewhat simplistic services</p>&#xA;&#xA;<ol>&#xA;<li>User-Service</li>&#xA;<li>DiscussionGroup-Service</li>&#xA;</ol>&#xA;&#xA;<p>A DiscussionGroup have users as members.</p>&#xA;&#xA;<p>All of these services have their own DBs.</p>&#xA;&#xA;<p>The UI now wants to list all users (name, profile-picture, etc) for a specific DiscussionGroup.&#xA;There could be 1000's of users per group so the result should be paginatable.</p>&#xA;&#xA;<p>In the monolithic approach, I would have done a DB-join in the UserDAO with the DiscussionGroupMember-table. But this can't be done anymore since the DB's are separated. </p>&#xA;&#xA;<p>What would be the best strategy to solve this in a performing way? Should I consider adding a 3rd service just for this query?</p>&#xA;"
39617171,How should a synchronous public api be integrated with message-based services?,2016-09-21 12:54:44,<asynchronous><spring-cloud><synchronous><microservices><messagebroker>,1,175,0,0.0,0,"<p>I've been reading about microservices, and have found a lot of interesting advice in Jonas BonÃ©r's Reactive Microservices Architecture (available to download free <a href=""https://info.lightbend.com/COLL-20XX-Reactive-Microservices-Architecture-RES-LP.html"" rel=""nofollow"">here</a>). He emphasises the need for asynchronous communication between miroservices, but says that APIs for external clients sometimes need to be synchronous (often REST).</p>&#xA;&#xA;<p>I've been trying to think how asynchronous response messages sent back from microservices should best be routed back to the waiting client. To me the most obvious way would be to record something like a request id in all messages sent when processing the request, and then copy this id into response messages sent by the services. The public API would block when processing the request, collecting all expected response messages which have the matching id, before finally sending the response to the client.</p>&#xA;&#xA;<p>Am I on the right lines here? Are there better approaches? Do any frameworks take the work of doing this routing away from the developer (I'm looking at Spring Cloud Streams etc, but others would be interesting too)?</p>&#xA;"
39395503,Performance testing a service using ICAP,2016-09-08 15:57:56,<java><performance-testing><microservices><icap>,1,187,0,0.0,0,<p>I am trying to performance test a service that uses ICAP as its protocol. Is there any specific tool / library that can come in handy? Any Java suggestions?</p>&#xA;&#xA;<p>Suggestions would be much appreciated.</p>&#xA;
39485766,How to push the result of an asynchronous REST call to the client using REST and Kafka,2016-09-14 08:25:47,<java><rest><apache-kafka><microservices>,1,220,0,0.0,0,<p>I want to deploy a scalable set of microservices. Every service should communicate via REST to each other. Also I need to request third-party services which will be slow and unstable. &#xA;So I came up with the idea to make it event-driven and use apache kafka.</p>&#xA;&#xA;<p>Something like:</p>&#xA;&#xA;<p>WebClient_X--request--->LoadBalancer--forward-->A-Service_1--request--->ThirdPartyService</p>&#xA;&#xA;<p>A_Service_1 needs to poll the ThirdPartyService for the results and writes them into kafka.</p>&#xA;&#xA;<p>A_Service_1--->Kafka</p>&#xA;&#xA;<p>Now what?</p>&#xA;&#xA;<p>How is it possible to send the results stored in the kafka topic back to the requesting WebClient_X. &#xA;Remember:&#xA;- A-Service is deployed N-times behind the LB.&#xA;- the A-Service_1 instance returned a Response.created(uuid) to the WebClient</p>&#xA;&#xA;<p>On solution would be to make the WebClient consume the kafka topic. But this seems to be a stupid idea.</p>&#xA;
39589556,Debug eureka-client side http requests,2016-09-20 08:47:07,<java><microservices><netflix-eureka>,1,493,0,0.0,0,"<p>I am trying to register my monolithic application to eureka server (first migration step into microservices world). The client &amp; server versions that I use is 1.5.3. The registration request fails, due to bad request error.</p>&#xA;&#xA;<p>My java code that creates the eureka client is:</p>&#xA;&#xA;<pre><code>private EurekaClient createEurekaClient(){&#xA;    EurekaInstanceConfig instanceConfig = new MyDataCenterInstanceConfig(MY_NAMESPACE);&#xA;    InstanceInfo instanceInfo = new EurekaConfigBasedInstanceInfoProvider(instanceConfig).get();&#xA;    ApplicationInfoManager applicationInfoManager = new ApplicationInfoManager(instanceConfig, instanceInfo);&#xA;    return new DiscoveryClient(applicationInfoManager, new DefaultEurekaClientConfig());&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>eureka-client.properties:</p>&#xA;&#xA;<pre><code>my-namespace.vipAddress=eureka&#xA;my-namespace.instance.preferIpAddress=true&#xA;eureka.region=default&#xA;my-namespace.name=MY-APP&#xA;my-namespace.port=8080&#xA;my-namespace.shouldUseDns=false&#xA;eureka.serviceUrl.default=http://localhost:9999/eureka/v2/&#xA;</code></pre>&#xA;&#xA;<p>The logs output:</p>&#xA;&#xA;<pre><code>2016-09-20 10:35:54,325 DEBUG [DiscoveryClient-HeartbeatExecutor-0] (AbstractJerseyEurekaHttpClient.java:60) - Jersey HTTP POST http://localhost:9999/eureka/v2//apps/MY-APP with instance 7010; statusCode=400&#xA;2016-09-20 10:35:54,326 DEBUG [DiscoveryClient-HeartbeatExecutor-0] (ThreadSafeClientConnManager.java:282) - Released connection is not reusable.&#xA;2016-09-20 10:35:54,326 DEBUG [DiscoveryClient-HeartbeatExecutor-0] (ConnPoolByRoute.java:429) - Releasing connection [{}-&gt;http://localhost:9999][null]&#xA;2016-09-20 10:35:54,326 DEBUG [DiscoveryClient-HeartbeatExecutor-0] (ConnPoolByRoute.java:676) - Notifying no-one, there are no waiting threads&#xA;2016-09-20 10:35:54,326 DEBUG [DiscoveryClient-HeartbeatExecutor-0] (RedirectingEurekaHttpClient.java:121) - Pinning to endpoint null&#xA;2016-09-20 10:35:54,326 WARN  [DiscoveryClient-HeartbeatExecutor-0] (RetryableEurekaHttpClient.java:127) - Request execution failure with status code 400; retrying on another server if available&#xA;</code></pre>&#xA;&#xA;<p>The server returns a 400 error code which means bad request, so am looking for a way to print the full registration request to the log file.</p>&#xA;"
39416301,Microservices - API Gateway Layer,2016-09-09 16:48:40,<spring-boot><cloudfoundry><microservices><pivotal-cloud-foundry>,1,1395,1,0.0,0,"<p>I have read few details of use of api gateway in microservices architecture. I have read that it basically helps with security , transformation , throttling etc. Is orchestration also one of it responsibilities? When I read about microservices , I saw that it should have dumb pipes and smart endpoints and services must be choreographed and not orchestrated. So my assumption is that orchestration is not a responsibility  of api gateway.</p>&#xA;"
32248896,Archiving microservice: How to organize business functions,2015-08-27 12:04:40,<architecture><soa><microservices>,2,126,0,0.0,0,"<p>I am creating a microservice which will be responsible for handling archiving and unarchiving of zip and tar files.</p>&#xA;&#xA;<p>I know that microservice should be focused on one business function (BF). But when I think of business function, should I mean archiving and unarchiving (1 BF), archiving, and separate unarchiving (2 BFs) or zipping, taring, unzipping, untaring (4 BFs)?</p>&#xA;&#xA;<p>Is there any reason to prefer one of those options over the rest?  </p>&#xA;"
32398245,Node.js + RabbitMQ + Socket.io,2015-09-04 12:35:57,<javascript><node.js><socket.io><rabbitmq><microservices>,1,728,3,1.0,0,"<p>We're in a project with a few microservices.<br>&#xA;We've got a microservice (A) that get's and saves data and publishes a message to RabbitMQ, stating new data has come in (with the CouchDB _id), so that another microservice(b) can process it.</p>&#xA;&#xA;<p>The problem lies in a third service where we've got a frontend that needs to be updated in 'real-time'.<br>&#xA;We're using Socket.io for the client updates, but the node.js instance get's the updates from A as well.</p>&#xA;&#xA;<p>The later is as followed:  </p>&#xA;&#xA;<pre><code>- RabbitMQ message comes in&#xA;- Order is being retrieved from A (HTTP Request)&#xA;- Data is processed (remapping for user interface, bla bla bla)&#xA;- Data is sent through Socket.io to the client.&#xA;</code></pre>&#xA;&#xA;<p>My problem is, how do I do this cleanly in node?</p>&#xA;&#xA;<p>I want to split the files (ofcourse), make each their own module and create a handler which 'knows' RabbitMQ and Socket.io, so it can process the data and send a message back up the queue when the client has done something with the data that needs to be processed and the other way around.</p>&#xA;&#xA;<p>If more info is needed, please tell me.</p>&#xA;"
32364506,Monolithic (vs) Micro-services ==> Threads (vs) Process,2015-09-02 22:58:59,<multithreading><process><docker><microservices>,1,1584,4,0.0,0,"<p>I have a monolithic application with single process having 5 threads. Each thread accomplishes certain specific task. Thinking to move this application to microservices using dockers. If I look at the architecture, each worker thread would become a docker process. So, in some way Monolithic vs Microservices becomes more like Thread vs Process discussion in my case. </p>&#xA;&#xA;<p>The original thinking of having the monolithic was to have threads for performance and share the same memory. Now with microservices arch, I am pushed to a process model that may not suit from performance point of view.</p>&#xA;&#xA;<p>I am kind of stuck on how to approach this problem.</p>&#xA;"
39848800,Can I Enrol One Micro services at 2 Different eureka,2016-10-04 09:31:04,<spring-boot><microservices><netflix-eureka>,1,29,0,0.0,0,"<p>I don't know whether it is possible or not. I want to know whether I can enroll one microservice at two different eureka server at once.</p>&#xA;&#xA;<p>I have one MS let say API-GATEWAY:&#xA;I want to enrol it on two different eureka registry server running on 8761 and 8762.</p>&#xA;&#xA;<p>for that I write:</p>&#xA;&#xA;<pre><code>eureka:&#xA;  client:&#xA;    serviceUrl: &#xA;      defaultZone: http://localhost:8761/eureka/ , http://localhost:8762/eureka/&#xA;    registry-fetch-interval-seconds: 1000&#xA;  instance:&#xA;    hostname: api-gateway&#xA;    prefer-ip-address: true&#xA;    lease-renewal-interval-in-seconds: 5000000&#xA;    lease-expiration-duration-in-seconds: 5000000 &#xA;</code></pre>&#xA;&#xA;<p>First up all tell me is it possible or not?&#xA;If yes, what property should I use to achieve the objectives?</p>&#xA;"
39686804,Designing multiservice architecture with public services and Consul.io,2016-09-25 12:28:38,<rest><web><architecture><microservices><consul>,1,67,0,0.0,0,"<p>I have a design question about a microservice setup with service discovery using Consul.io (might be applicable to other service discovery tools).</p>&#xA;&#xA;<p>(All services and web-nodes will be built using the .NET framework)</p>&#xA;&#xA;<p>We're building a solution with 2 or more front-end nodes and a series of services at the backend. One of these services will be providing a product search to the front-end websites. We're thinking of using Consul.io for providing redundency for these services. The front-end will be using AngularJS to show the products using a REST endpoint to query. My question is what would be the better setup for this:</p>&#xA;&#xA;<ul>&#xA;<li>each web node hosts its own product service which relays to an internal product service using a Consul.io lookup (health check etc)</li>&#xA;<li>the frontend client connect directly to the product service.</li>&#xA;</ul>&#xA;&#xA;<p>In the second case I'm wondering how the client would connect to the backend service and how discovery works. Also, I'm wondering which of those two would be the better design choice. It seems to me that using the first option would bring overhead by doing two HTTP calls.</p>&#xA;&#xA;<p>I'm looking forward to your thoughts.</p>&#xA;"
39741506,What does setClusterHost mean in vertx?,2016-09-28 08:04:26,<java><microservices><vert.x>,1,141,0,0.0,0,"<p>I am trying to learn vertx and downloaded a sample from github.   </p>&#xA;&#xA;<p>Consider following code snippet:  </p>&#xA;&#xA;<pre><code>VertxOptions options = new VertxOptions().setClustered(true).setClusterHost(""localhost"");&#xA;</code></pre>&#xA;&#xA;<p>How can I imagine how the localhost will be clustered?</p>&#xA;"
39658735,Best security practise for passing resource ID in URI,2016-09-23 10:38:38,<spring><rest><security><uri><microservices>,1,170,2,0.0,0,<p>I am currently working on developing Rest API for Bank. In Rest API principle URI are uniquely identify. That mean we have to pass the resource ID in request URL&#xA;eg:</p>&#xA;&#xA;<ul>&#xA;<li>GET /customer/  </li>&#xA;<li>PUT /customer/   </li>&#xA;<li>DELETE /customer/</li>&#xA;</ul>&#xA;&#xA;<p>But problem is in my bank passing id's in URI prohibited due to security reason. (URI can read any one)</p>&#xA;&#xA;<p>Could someone let me know is there any industry level best practise for overcome this security issue without violating Rest Resource naming principle?</p>&#xA;
39721025,microservices for very small enterprise,2016-09-27 09:28:42,<api><web-applications><architecture><microservices>,2,699,2,0.0,0,"<p>Presently i'm working as web developper in a small company and i'm in charge to create a new web software to manage our business.&#xA;We cannot hire new developpers yet and we must deliver a first version as soon as posible.&#xA;In this context, i'm thinking about microservices architecture and i don't know if we should spend some time and resources to start our project with this kind of architecture.&#xA;Somebody has some experience about this subject?</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
39690572,"microservices spring cloud, security, oauth2, Netflix OSS @EnableOAuth2Resource not exist in spring security 1.1",2016-09-25 18:51:51,<spring><spring-mvc><spring-security><microservices>,1,491,2,0.0,0,"<p>I use this tutorial <a href=""http://callistaenterprise.se/blogg/teknik/2015/04/27/building-microservices-part-3-secure-APIs-with-OAuth/"" rel=""nofollow"">http://callistaenterprise.se/blogg/teknik/2015/04/27/building-microservices-part-3-secure-APIs-with-OAuth</a>/  to create organized webservices project based on Netflix OSS by using the following technologies spring cloud, boot, security, oauth2.</p>&#xA;&#xA;<p>I'm using spring security 1.1 and I see annotation @EnableOAuth2Resource not exist in the spring security 1.1 what I should do?</p>&#xA;&#xA;<p>Maven Dependencies</p>&#xA;&#xA;<pre><code>&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;&lt;groupId&gt;auctionblox&lt;/groupId&gt;&#xA;&lt;artifactId&gt;auth-microservice&lt;/artifactId&gt;&#xA;&lt;version&gt;1.0&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-cloud-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;Brixton.RELEASE&lt;/version&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;!-- Stand-alone RESTFul application for testing only --&gt;&#xA;    &lt;start-class&gt;io.pivotal.microservices.services.Main&lt;/start-class&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Setup Spring Boot --&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;!--&lt;dependency&gt;--&gt;&#xA;        &lt;!--&amp;lt;!&amp;ndash; Setup Spring MVC &amp; REST, use Embedded Tomcat &amp;ndash;&amp;gt;--&gt;&#xA;        &lt;!--&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;--&gt;&#xA;        &lt;!--&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;--&gt;&#xA;    &lt;!--&lt;/dependency&gt;--&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Setup Spring Data common components --&gt;&#xA;        &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-data-commons&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Testing starter --&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Setup Spring Data JPA Repository support --&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&#xA;        &lt;exclusions&gt;&#xA;            &lt;exclusion&gt;&#xA;                &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&#xA;            &lt;/exclusion&gt;&#xA;        &lt;/exclusions&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.10.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Eureka service registration --&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- Spring Cloud starter --&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;!-- In-memory database for testing/demos --&gt;&#xA;        &lt;groupId&gt;org.hsqldb&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;hsqldb&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;mysql&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&#xA;        &lt;version&gt;5.1.39&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;executions&gt;&#xA;                &lt;execution&gt;&#xA;                    &lt;goals&gt;&#xA;                        &lt;goal&gt;repackage&lt;/goal&gt;&#xA;                    &lt;/goals&gt;&#xA;                &lt;/execution&gt;&#xA;            &lt;/executions&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;"
40092551,Couldn't resolve host 'cdk-builds.usersys.redhat.com',2016-10-17 17:43:03,<vagrant><openshift><redhat><microservices><fabric8>,2,81,0,0.0,0,"<p>While installing vagrant i'm getting following error....&#xA;I'm following <a href=""https://fabric8.io/guide/getStarted/cdk.html"" rel=""nofollow"">https://fabric8.io/guide/getStarted/cdk.html</a> for installation.</p>&#xA;&#xA;<pre><code>pwd&#xA;&#xA;/Users/apple/openshift-vagrant/cdk-v2&#xA;&#xA;vagrant up&#xA;&#xA;Bringing machine 'cdk' up with 'virtualbox' provider...&#xA;==&gt; cdk: Box 'cdk_v2' could not be found. Attempting to find and install...&#xA;    cdk: Box Provider: virtualbox&#xA;    cdk: Box Version: &gt;= 0&#xA;==&gt; cdk: Box file was not detected as metadata. Adding it directly...&#xA;==&gt; cdk: Adding box 'cdk_v2' (v0) for provider: virtualbox&#xA;    cdk: Downloading: http://cdk-builds.usersys.redhat.com/builds/nightly/27-May-2016/rhel-7-cdk-vagrant-scratch-7.2.27052016-1.x86_64.vagrant-virtualbox.box&#xA;An error occurred while downloading the remote file. The error&#xA;message, if any, is reproduced below. Please fix this error and try&#xA;again.&#xA;&#xA;Couldn't resolve host 'cdk-builds.usersys.redhat.com'&#xA;</code></pre>&#xA;&#xA;<p>any idea ?</p>&#xA;"
40231507,I am not able to configure Docker VM for Lightbend ConductR. Sandbox init is throwing FileNotFoundError,2016-10-25 04:43:13,<docker><sandbox><microservices><lagom>,1,111,0,0.0,0,"<p>I am trying out Lighbend's ConductR and currently stuck with setting up the sandbox. I followed the instructions given on their <a href=""https://www.lightbend.com/product/conductr/developer"" rel=""nofollow"">site</a> but I am facing following error at the step ""Configure Docker VM"" - when I try to do sandbox init:</p>&#xA;&#xA;<pre><code>shishir@shishir-VirtualBox:~/Lightbend$ sudo sandbox init&#xA;Warning: Docker has an insufficient no. of CPUs 1 - please increase to a minimum of 4 CPUs&#xA;Error: Encountered unexpected error.&#xA;Error: Reason: FileNotFoundError [Errno 2] No such file or directory: 'docker-machine'&#xA;Error: Further information of the error can be found in the error log file: /home/shishir/.conductr/errors.log&#xA;Traceback (most recent call last):&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/main_handler.py"", line 8, in run&#xA;    result = callback()&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/sandbox.py"", line 6, in main_method&#xA;    sandbox_main.run()&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/sandbox_main.py"", line 158, in run&#xA;    args.func(args)&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/sandbox_init.py"", line 32, in init&#xA;    if is_docker_machine_installed():&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/sandbox_init.py"", line 104, in is_docker_machine_installed&#xA;    terminal.docker_machine_help()&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/terminal.py"", line 71, in docker_machine_help&#xA;    return subprocess.check_output(cmd, universal_newlines=True).strip()&#xA;  File ""/usr/lib/python3.5/subprocess.py"", line 626, in check_output&#xA;    **kwargs).stdout&#xA;  File ""/usr/lib/python3.5/subprocess.py"", line 693, in run&#xA;    with Popen(*popenargs, **kwargs) as process:&#xA;  File ""/usr/lib/python3.5/subprocess.py"", line 947, in __init__&#xA;    restore_signals, start_new_session)&#xA;  File ""/usr/lib/python3.5/subprocess.py"", line 1551, in _execute_child&#xA;    raise child_exception_type(errno_num, err_msg)&#xA;FileNotFoundError: [Errno 2] No such file or directory: 'docker-machine'&#xA;&#xA;During handling of the above exception, another exception occurred:&#xA;&#xA;Traceback (most recent call last):&#xA;  File ""/usr/local/bin/sandbox"", line 9, in &lt;module&gt;&#xA;    load_entry_point('conductr-cli==0.39', 'console_scripts', 'sandbox')()&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/sandbox.py"", line 10, in run&#xA;    main_handler.run(main_method)&#xA;  File ""/usr/local/lib/python3.5/dist-packages/conductr_cli/main_handler.py"", line 31, in run&#xA;    handler = logging.handlers.RotatingFileHandler(DEFAULT_ERROR_LOG_FILE, maxBytes=3000000, backupCount=1)&#xA;  File ""/usr/lib/python3.5/logging/handlers.py"", line 150, in __init__&#xA;    BaseRotatingHandler.__init__(self, filename, mode, encoding, delay)&#xA;  File ""/usr/lib/python3.5/logging/handlers.py"", line 57, in __init__&#xA;    logging.FileHandler.__init__(self, filename, mode, encoding, delay)&#xA;  File ""/usr/lib/python3.5/logging/__init__.py"", line 1008, in __init__&#xA;    StreamHandler.__init__(self, self._open())&#xA;  File ""/usr/lib/python3.5/logging/__init__.py"", line 1037, in _open&#xA;    return open(self.baseFilename, self.mode, encoding=self.encoding)&#xA;FileNotFoundError: [Errno 2] No such file or directory: '/home/shishir/.conductr/errors.log'&#xA;</code></pre>&#xA;&#xA;<p>I am trying to run it on Ubuntu Virtual Box. Here is the uname output:</p>&#xA;&#xA;<pre><code>shishir@shishir-VirtualBox:~$ uname -a&#xA;Linux shishir-VirtualBox 4.4.0-45-generic #66-Ubuntu SMP Wed Oct 19 14:12:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux&#xA;</code></pre>&#xA;&#xA;<p>I have installed Docker and Python3 as per the instructions.</p>&#xA;&#xA;<p>I am not sure whats causing the issue but seems like there is something missing in the guide. Any help in solving this issue would be appreciated.</p>&#xA;"
40216362,Microservices and Messaging: Message Content,2016-10-24 10:39:10,<java><spring><rabbitmq><microservices>,3,112,0,0.0,0,"<p>I'm building an application that consists out of several microservices. One of the microservices, which is called Hera, manages users. Another microservice manages authorization and authentication. This microservice is called Zeus and is an implementation of Spring OAuth 2.0. </p>&#xA;&#xA;<p>When a user is created, updated or deleted in Hera, I'd like to replicate certain information to Zeus via RabbitMQ. This information includes the username, the user type (an enum) and a flag to indicate whether the user is enabled. </p>&#xA;&#xA;<p>I've already set up RabbitMQ and everything is working properly. The only thing I'm not certain about is the message body content. How should this information be packaged in the message? For instance, should I create a maven project containing the POJO with the required properties which will be marshalled and send via RabbitMQ and add dependency to this project in both Hera and Zeus? Or should I just add this information as a list of plain properties? </p>&#xA;&#xA;<p>I could not find any best practices or guidelines on this subject, so I'm asking you.</p>&#xA;&#xA;<p>Thank you in advance!</p>&#xA;"
40304324,how to configure service discovery in bluemix for microsrvices (written in java),2016-10-28 11:41:17,<java><ibm-cloud><microservices><service-discovery>,1,130,0,0.0,0,"<p>I have 5 microsrvices:</p>&#xA;&#xA;<ol>&#xA;<li>acmeair-mainapp (main service)  </li>&#xA;<li>acmeair-as  </li>&#xA;<li>acmeair-bs  </li>&#xA;<li>acmeair-cs </li>&#xA;<li>acmeair-fs</li>&#xA;</ol>&#xA;&#xA;<p>Which application should I include in SD or how can these applications be configured? </p>&#xA;&#xA;<p>I have followed the Bluemix documentation but things are not transparent with how to follow the steps. The Bluemix docs says to add some code to register a new service and it gives sample code for nodeJS, Python, and cURL, yet my application is written in java. Please help me proceed.</p>&#xA;"
40296029,npm inodes issues in docker / kubernetes environment,2016-10-28 00:02:56,<node.js><npm><kubernetes><microservices><inode>,1,145,0,0.0,0,"<p>we have a kubernetes cluster environment which at any given time has around 10~20 pods/containers running on a single node. Each node has around 200k ish <code>inodes</code> available. However our micro service (nodejs/npm) app can each eats up around 20k+ inodes, and times that by say 10 pods/containers on a node that basically eats up all the available inodes on a server (node). </p>&#xA;&#xA;<p>The question is if there is way to deal with this issue in the <code>node_modules</code> to minimize the number of files it contains or use some kind of bundler for the node_modules ??</p>&#xA;"
40238733,Using Consul to monitoring 3rd party services,2016-10-25 11:28:13,<spring><apache-zookeeper><microservices><consul>,1,149,0,1.0,0,"<p>As a organisation, we have 100+ services running at the same time, to keep the company functioning (namely software applications to assists the HR, Finance, Purchasing, Estate, Services, payroll, etc....)</p>&#xA;&#xA;<p>our main focus is to look after the integrations between those services, so they can functioning as a single unit, rather than a list of isolated applications </p>&#xA;&#xA;<p>LDAP, Oracle Database, SOAP webservices, tomcat based webApps are our critical services, we are currently looking at a service monitoring and discovery tool to manage those services</p>&#xA;&#xA;<p>my questions is with our in house webApps or webservices, through the consul java API its fairly easy to register with the Consul server, and implement a health check mechanism. I found its difficult to register and monitoring other services such as LDAP, database or 3rd party SOAP services</p>&#xA;&#xA;<p>anyone can share some examples or point me to the right directions please. </p>&#xA;"
40170212,how to add content-length to response headers when i use spring cloud to build my micro service,2016-10-21 06:56:58,<spring-boot><spring-cloud><microservices><netflix-zuul>,1,965,0,0.0,0,"<p>I have used spring cloud to build a multiple microservice,and i use a API-Gateway implemented using Spring Cloud Netfix's Zuul Server to route the requests to our micro services ,the gateway config like this:</p>&#xA;&#xA;<p>application.yml:</p>&#xA;&#xA;<pre><code>server:&#xA;port: 8021&#xA;&#xA;ribbon:&#xA;ConnectTimeout: 3000&#xA;ReadTimeout: 60000&#xA;&#xA;zuul:&#xA;ignoredServices: ""*""&#xA;add-proxy-headers: true&#xA;#prefix: /v1&#xA;&#xA;routes:&#xA;m_test:&#xA;path: /api/testService/**&#xA;sensitiveHeaders: ""*""&#xA;url: http://127.0.0.1:4008/testService/  &#xA;&#xA;eureka:&#xA;instance:&#xA;hostname: gateway&#xA;client:&#xA; registerWithEureka: true&#xA; fetchRegistry: true&#xA;serviceUrl:&#xA;  defaultZone: http://127.0.0.1:8761/eureka/&#xA;</code></pre>&#xA;&#xA;<p>CorsFilter.java:</p>&#xA;&#xA;<pre><code>@Component&#xA;@Order(Ordered.HIGHEST_PRECEDENCE)&#xA;public class CorsFilter implements Filter {&#xA;public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {&#xA;&#xA;    HttpServletResponse response = (HttpServletResponse) res;&#xA;    HttpServletRequest request = (HttpServletRequest) req;&#xA;    response.setHeader(""Access-Control-Allow-Origin"", ""*"");&#xA;    response.setHeader(""Access-Control-Allow-Methods"", ""POST, PUT, GET, OPTIONS, DELETE"");&#xA;    response.setHeader(""Access-Control-Allow-Headers"", ""Origin, X-Requested-With, Content-Type, Accept, Authorization,Content-length"");&#xA;    response.setHeader(""Access-Control-Max-Age"", ""1800"");&#xA;    Map&lt;String, String&gt; map = getHeadersInfo(request);&#xA;&#xA;    if (request.getMethod().equalsIgnoreCase(""OPTIONS"")) {&#xA;        response.setStatus(HttpServletResponse.SC_OK);&#xA;    } else {&#xA;        chain.doFilter(request, response);&#xA;    }&#xA;}&#xA;&#xA;public void init(FilterConfig filterConfig) {&#xA;}&#xA;&#xA;public void destroy() {&#xA;}&#xA;&#xA;private Map&lt;String, String&gt; getHeadersInfo(HttpServletRequest request) {&#xA;    Map&lt;String, String&gt; map = new HashMap&lt;&gt;();&#xA;    Enumeration headerNames = request.getHeaderNames();&#xA;    while (headerNames.hasMoreElements()) {&#xA;        String key = (String) headerNames.nextElement();&#xA;        String value = request.getHeader(key);&#xA;        map.put(key, value);&#xA;    }&#xA;&#xA;    return map;&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>GatewaySystemApplication.java:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableZuulProxy&#xA;@EnableEurekaClient&#xA;public class GatewaySystemApplication {&#xA;&#xA;public static void main(String[] args) throws Exception {&#xA;    //SpringApplication.run(GatewaySystemApplication.class, args);&#xA;    new SpringApplicationBuilder(GatewaySystemApplication.class).web(true).run(args);&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The browser response headers are like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jeFDo.png"" rel=""nofollow noreferrer"">passing through gateway layer response headers</a></p>&#xA;&#xA;<p>and the response header of my request miss the content-length,&#xA;but it has the content-length when i directly invoke backend service.<a href=""https://i.stack.imgur.com/2IYfM.png"" rel=""nofollow noreferrer"">directly response headers</a></p>&#xA;"
40132631,SocketTimeoutException : null while opening New Spring Starter Project,2016-10-19 13:21:23,<spring><web-services><spring-boot><microservices><eclipse-jee>,1,1497,0,0.0,0,"<p>SocketTimeoutException : null while opening New Spring Starter Project</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/uWW5K.png"" alt=""enter image description here""></p>&#xA;&#xA;<pre><code>JAVA_HOME=C:\Program Files (x86)\Java\jdk1.7.0_40&#xA;Path=%JAVA_HOME%\bin;C:\..&#xA;</code></pre>&#xA;"
40208887,"When utilizing a microservices architecture, will the underlying read/write database become a bottleneck?",2016-10-23 23:36:41,<sql><amazon-web-services><scalability><microservices>,3,348,1,0.0,0,"<p>As I described in the question, if I were to implement a microservices architecture, would the centralized read/write database become a bottleneck?</p>&#xA;&#xA;<p>To expand with an example, let's say I have three microservices: <code>users</code>, <code>teams</code>, and <code>team_members</code>. Each has its own microservice, but they all rely on each other in the database, so exclusive, parallel databases wouldn't be appropriate. Since microservices is meant to distribute the work to several different servers, doesn't the central database ultimately defeat the purpose of these microservices, as they all end up calling to the same server?</p>&#xA;"
40233978,Handling UI in microservices,2016-10-25 07:34:14,<microservices>,2,223,1,0.0,0,"<p>I am in the process of learning about microservices and there's one thing that I can't seem to figure out and I can't find any resources that give me a direct answer to this. The question is:</p>&#xA;&#xA;<p>Do microservices involve only business logic and database interactions&#xA;or do they involve UI components like JS, CSS, HTML as well ?</p>&#xA;"
40108015,Microservice's High availability concern on cloud,2016-10-18 12:15:58,<cloud><microservices>,1,230,3,0.0,0,"<p>I was reading about Microservices and everything makes sense to me but I have one little doubt.</p>&#xA;&#xA;<p>On cloud, every component has a availability SLA (lets assume 99.9%). So, if we have a single component to do a job, our application SLA would be the same (approx.). But if we create multiple components to do one job, our application's SLA would be reduced because all the components can go down at different time. In microservices, one service can communicate to other services to complete a task. Now, any of the participant service can be down at different time, So our application availability will be lesser compared to monolithic service?</p>&#xA;"
35589008,Advice on how to monitor (micro)services?,2016-02-23 21:54:58,<service><spring-boot><monitoring><microservices><spring-boot-actuator>,1,851,2,0.0,0,"<p>We are transitioning from building applications on monolith application servers, to more microservices oriented applications on Spring Boot. We will publish health information with SB Actuator through HTTP or JMX.</p>&#xA;&#xA;<p>What are the options/best practices to monitor services, that will be around 30-50 in total? Thanks for your input!</p>&#xA;"
35600997,ejabberd in a microservice network,2016-02-24 11:31:54,<xmpp><ejabberd><microservices><mongoose-im>,2,287,6,0.0,0,<p>I'm willing to use ejabberd / mongooseIm in a microservice network. XMPP should be our chat protocol aside from a REST API network. I want to send messages incoming at the xmpp server downstream to worker services. Has anybody done this or could lead me into the right direction? </p>&#xA;&#xA;<p>My first thoughts are using RabbitMQ for sending the new incoming messages to the workers.</p>&#xA;
41492081,Kubernetes container cluster conventions,2017-01-05 18:25:05,<containers><kubernetes><google-cloud-platform><microservices>,1,47,0,1.0,0,"<p>I have been trying out kubernetes on GCP to build microservices for a while and it has been amazing so far. </p>&#xA;&#xA;<p>Although i am a bit confused on what would probably be the best approach, should i</p>&#xA;&#xA;<ol>&#xA;<li>create (<code>gcloud container clusters create ""[cluster-name]"" ...</code>) one container-cluster per service?</li>&#xA;<li>create one container-cluster for multiple services? or</li>&#xA;<li>do both of those above depending on my situation?</li>&#xA;</ol>&#xA;&#xA;<p>all of the examples i have managed to find has only covered #2, but my hunch is kind of telling me that i should do #1, and my hunch is also kind of telling me that i have probably missed some basic understanding around containers, i have been trying to find answers without any luck, i guess i just can't figure out the right search keyword, i am hoping that i could find some answer here.</p>&#xA;"
41566244,Can containers share a framework?,2017-01-10 10:09:26,<.net><iis><docker><containers><microservices>,1,373,0,0.0,0,"<p>I'm aware that Docker containers can share a data volume but is it possible for them to share frameworks? For instance, if i have two .NET services running on IIS can I just share the framework between them? </p>&#xA;"
41556946,Securing WSO2 microservices with JWT using WSO2 Identity Server,2017-01-09 21:06:57,<wso2><jwt><wso2is><microservices><msf4j>,1,188,0,0.0,0,"<p>I found this:</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/40255523/wso2-identity-server-jwt-access-token"">WSO2 Identity Server JWT Access token</a></p>&#xA;&#xA;<p>but it doesn't seem to be answered. </p>&#xA;&#xA;<p>What I want to do is this:</p>&#xA;&#xA;<p>1 - call some URL on the WSO2 Identity Server to authenticate, sending a username and password, and have it send me back a Json Web Token (JWT). It's possible this will have to be 2 calls, one to authenticate and one to retrieve the JWT but I'd really really like to avoid that. </p>&#xA;&#xA;<p>2 - pass the JWT along to WSO2 microservices via the Authorization: Bearer header</p>&#xA;&#xA;<p>3 - have the microservices automatically validate the JWT and get the user information so I can build a security context. I expect this will need to call back to the WSO2 Identity Server for every call.</p>&#xA;&#xA;<p>Is there a step by step guide to getting this working? Everything I see involves redirecting the user to log in at the WSO2 identity server or generating a JWT which is app client specific, not user specific. This should be front and center for the MSF4J documentation. </p>&#xA;"
42969532,How to make sure there will be a fixed DB server across multiple deployments in Cloud Foundry?,2017-03-23 07:18:56,<cloudfoundry><microservices><pivotal-cloud-foundry>,1,25,0,0.0,0,"<p>I am a newbie with CF microservices and I am trying to deploy a service multiple times. As far as I understood, each time I deploy into a space the application is getting a different database server and schema. Is there a way to tell the Cloud Foundry to use only a fixed DB server all the times across multiple deployments in one environment?</p>&#xA;"
42846703,Spring Cloud with multiple UI services as one,2017-03-16 23:38:12,<spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,87,0,0.0,0,"<p>Is it possible to use spring cloud for creating a integration between multiple web ui applications as one using a common service that can integrate all URLs in menus to presented as one application?</p>&#xA;&#xA;<p>In addition, based on previous description, how can is it possible distribute this application in multiples servers and reference them using eureka and securing it with zuul services?</p>&#xA;"
42934172,how to get api gateway address in order to call it from angular container in docker compose,2017-03-21 17:24:54,<angularjs><docker><docker-compose><microservices><gateway>,2,416,0,0.0,0,"<p>i have a  docker compose file in which there are several containers among which there are an api gateway and another one with an angularjs application (the website of this stack). The api gateway is concerned to call correct apis of several containers presents in the compose file. But i need to call the api gateway from the website (angular container) and &#xA;i would like to know what is the best practices for get the address of the api gateway container in order to call it from angular container (or from browser anyway..).&#xA;For the moment i working in local, so i specify&#xA;localhost:PortOfApiGateway/apis/...</p>&#xA;&#xA;<p>and everything work fine,  but obviously if try  to connect from another host it not works...</p>&#xA;&#xA;<p>Any suggestion?</p>&#xA;"
43018613,What is Spring Boot config to use Cloud Foundry Service Registry (Netflix Eureka) Service?,2017-03-25 16:02:36,<spring-boot><cloudfoundry><microservices><netflix-eureka>,1,435,0,0.0,0,"<p>I am able to setup my own Eureka server locally and register my services to that without any issue, but when I create a Eureka server using Pivotal Cloud Foundry's ""Service Registry"" service my applications are not showing up under ""Registered Apps"". </p>&#xA;&#xA;<p>I've done the following:</p>&#xA;&#xA;<ol>&#xA;<li>Created Service Registry via Cloud Foundry Marketplace.</li>&#xA;<li>Bound my application to the service.</li>&#xA;<li>Successfully registered my application with the service.</li>&#xA;</ol>&#xA;&#xA;<p>Logs:</p>&#xA;&#xA;<pre><code>2017-03-25T11:32:26.994-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:26.994 INFO 13 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]&#xA;2017-03-25T11:32:27.426-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:27.424 INFO 13 --- [ main] o.s.c.support.DefaultLifecycleProcessor : Starting beans in phase 0&#xA;2017-03-25T11:32:27.444-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:27.443 INFO 13 --- [ main] o.s.c.n.eureka.InstanceInfoFactory : Setting initial instance status as: STARTING&#xA;2017-03-25T11:32:27.758-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:27.755 INFO 13 --- [ main] c.n.d.provider.DiscoveryJerseyProvider : Using JSON encoding codec LegacyJacksonJson&#xA;2017-03-25T11:32:27.758-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:27.758 INFO 13 --- [ main] c.n.d.provider.DiscoveryJerseyProvider : Using JSON decoding codec LegacyJacksonJson&#xA;2017-03-25T11:32:28.114-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.113 INFO 13 --- [ main] c.n.d.provider.DiscoveryJerseyProvider : Using XML decoding codec XStreamXml&#xA;2017-03-25T11:32:28.114-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.113 INFO 13 --- [ main] c.n.d.provider.DiscoveryJerseyProvider : Using XML encoding codec XStreamXml&#xA;2017-03-25T11:32:28.682-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.678 INFO 13 --- [ main] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration&#xA;2017-03-25T11:32:28.745-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Disable delta property : false&#xA;2017-03-25T11:32:28.745-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Single vip registry refresh property : null&#xA;2017-03-25T11:32:28.745-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Force full registry fetch : false&#xA;2017-03-25T11:32:28.746-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Application is null : false&#xA;2017-03-25T11:32:28.746-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Registered Applications size is zero : true&#xA;2017-03-25T11:32:28.747-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.745 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Application version is -1: true&#xA;2017-03-25T11:32:28.761-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:28.747 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Getting all instance registry info from the eureka server&#xA;2017-03-25T11:32:29.156-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.155 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : The response status is 200&#xA;2017-03-25T11:32:29.160-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.160 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Starting heartbeat executor: renew interval is: 30&#xA;2017-03-25T11:32:29.165-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.164 INFO 13 --- [ main] c.n.discovery.InstanceInfoReplicator : InstanceInfoReplicator onDemand update allowed rate per min is 4&#xA;2017-03-25T11:32:29.170-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.169 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Discovery Client initialized at timestamp 1490455949169 with initial instances count: 23&#xA;2017-03-25T11:32:29.227-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.227 INFO 13 --- [ main] c.n.e.EurekaDiscoveryClientConfiguration : Registering application gym-service with eureka with status UP&#xA;2017-03-25T11:32:29.230-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.229 INFO 13 --- [ main] com.netflix.discovery.DiscoveryClient : Saw local status change event StatusChangeEvent [timestamp=1490455949229, current=UP, previous=STARTING]&#xA;2017-03-25T11:32:29.236-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.236 INFO 13 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_GYM-SERVICE/3a2f6286-096c-4a2a-782a-03bab8f020a9: registering service...&#xA;2017-03-25T11:32:29.349-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.348 INFO 13 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_GYM-SERVICE/3a2f6286-096c-4a2a-782a-03bab8f020a9 - registration status: 204&#xA;2017-03-25T11:32:29.570-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.569 INFO 13 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)&#xA;2017-03-25T11:32:29.575-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.574 INFO 13 --- [ main] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 8080&#xA;2017-03-25T11:32:29.582-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:32:29.582 INFO 13 --- [ main] com.campbellonsoftware.orka.GymServer : Started GymServer in 22.159 seconds (JVM running for 24.923)&#xA;2017-03-25T11:32:31.135-04:00 [CELL/0] [OUT] Container became healthy&#xA;2017-03-25T11:37:28.751-04:00 [APP/PROC/WEB/0] [OUT] 2017-03-25 15:37:28.751 INFO 13 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration&#xA;</code></pre>&#xA;&#xA;<p>manage-gym.yml file:</p>&#xA;&#xA;<pre><code># Spring properties&#xA;spring:&#xA;  application:&#xA;     name: gym-service  # Service registers under this name&#xA;  freemarker:&#xA;    enabled: false           # Ignore Eureka dashboard FreeMarker templates&#xA;  thymeleaf:&#xA;    cache: false             # Allow Thymeleaf templates to be reloaded at runtime&#xA;    prefix: classpath:/manage-gym/templates/    # Trailing / mandatory&#xA;                             # Template location for this application only&#xA;&#xA;# Map the error path to error template (for Thymeleaf)&#xA;error:&#xA;  path: /error&#xA;&#xA;# HTTP Server&#xA;server: &#xA;  port: 2222   # HTTP (Tomcat) port&#xA;&#xA;# Discovery Server Access&#xA;#  1. DEV ONLY: Reduce the lease renewal interval to speed up registration&#xA;#  2. Define URL of registration server (defaultZone)&#xA;eureka:&#xA;  client:&#xA;    serviceUrl:&#xA;      defaultZone: ${vcap.services.${PREFIX:}eureka.credentials.uri:http://user:${eureka.password:}@${PREFIX:}eureka.${application.domain:cfapps.io}}/eureka/&#xA;  instance:&#xA;    hostname: ${vcap.application.uris[0]}&#xA;    leaseRenewalIntervalInSeconds: 30   # DO NOT DO THIS IN PRODUCTION&#xA;</code></pre>&#xA;&#xA;<p>Main Class:</p>&#xA;&#xA;<pre><code>package com.campbellonsoftware.orka;&#xA;&#xA;import java.util.logging.Logger;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;&#xA;&#xA;@SpringBootApplication&#xA;@EnableAutoConfiguration&#xA;@EnableDiscoveryClient&#xA;public class GymServer {&#xA;&#xA;&#xA;    protected Logger logger = Logger.getLogger(GymServer.class.getName());&#xA;&#xA;    public static void main(String[] args) {&#xA;        System.setProperty(""spring.config.name"", ""manage-gym"");&#xA;        SpringApplication.run(GymServer.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Service Registry:&#xA;<a href=""https://i.stack.imgur.com/EttTC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EttTC.png"" alt=""Service Registry config""></a></p>&#xA;"
43018514,"AWS Lambda + Spring, how to load application.yml",2017-03-25 15:55:04,<java><spring><amazon-web-services><aws-lambda><microservices>,1,695,0,1.0,0,"<p>I have problem with customizing API gateway domain, for my restful app deployed on AWS lambda. Customized domain, works this way, that depending on basePath it chooses different APIs which finally touches Lambda. For example:</p>&#xA;&#xA;<p><code>api.mycustomdomain.com/view/ping</code> -> goes to application <code>view</code> with path <code>/view/ping</code>&#xA;<code>api.mycustomdomain.com/admin/ping</code> -> goes to application <code>admin</code> with path <code>/admin/ping</code></p>&#xA;&#xA;<p>I am using this example as boilerplate: <a href=""https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store</a></p>&#xA;&#xA;<p>What I would like to achieve is handler which depending on <code>Host</code> header strips prefix from request path.</p>&#xA;&#xA;<p>I have prepared following application.yml file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: ""/view""&#xA;  productionHost: ""api.mycustomdomain.com""&#xA;</code></pre>&#xA;&#xA;<p>The problem/question is. How can I now load those into my Lambda function? Here is my naive try:</p>&#xA;&#xA;<pre><code>public class LambdaHandler implements RequestHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; {&#xA;    SpringLambdaContainerHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; handler;&#xA;    boolean isinitialized = false;&#xA;&#xA;    @Value(""${server.contextPath}"")&#xA;    private String prefix;&#xA;&#xA;    @Value(""${server.productionHost}"")&#xA;    private String productionHost;&#xA;&#xA;    public AwsProxyResponse handleRequest(AwsProxyRequest awsProxyRequest, Context context) {&#xA;        if(awsProxyRequest.getHeaders().get(""Host"").equals(productionHost))&#xA;            awsProxyRequest.setPath(awsProxyRequest.getPath().substring(prefix.length()));&#xA;&#xA;        if (!isinitialized) {&#xA;            isinitialized = true;&#xA;            try {&#xA;                handler = SpringLambdaContainerHandler.getAwsProxyHandler(PingPongApp.class);&#xA;            } catch (ContainerInitializationException e) {&#xA;                e.printStackTrace();&#xA;                return null;&#xA;            }&#xA;        }&#xA;        return handler.proxy(awsProxyRequest, context);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Obviously this doesn't work, LambdaHandler is working out of Spring context.</p>&#xA;&#xA;<p>Any ideas how can I deal with that?</p>&#xA;"
42928059,Request per second and performance limit of Spring rest backend,2017-03-21 13:06:03,<spring><performance><rest><microservices>,2,3308,0,0.0,0,"<p>I would like to develop a Spring REST backend application with tomcat.&#xA;I expect 1000-5000 active users. The users will create requests from clients(Android, web, Ios) to backend. Most of requests will create a simple db select.</p>&#xA;&#xA;<ul>&#xA;<li>How to calculate the limit of requests per second?</li>&#xA;<li>How to estimate the performance limits?</li>&#xA;<li>Should I use Microservice architecure or monolithic?</li>&#xA;</ul>&#xA;&#xA;<p>Thanks</p>&#xA;"
42958561,Creating NodeJS microservices that are invokable from Android app,2017-03-22 17:19:27,<java><android><node.js><microservices>,2,237,0,0.0,0,"<p>For my final year project at uni I've decided to research into micro-services, specifically ones that can be invoked by an Android app. </p>&#xA;&#xA;<p>I want to create a micro-service that queries an API that grabs any new data or changes to existing objects that has been stored. In regards to data storage, I want to try and see if it's possible to either cache the data server-side then feed it to the client-side? Or store that data in a local DB and then read from that to display on the client? </p>&#xA;&#xA;<p>The app itself will be written in Java and the micro-services running/written in a Node environment. </p>&#xA;&#xA;<p>I've done a bit of reading and a lot of people are saying to use RESTful or an API Gateway of sorts. </p>&#xA;&#xA;<p>Any feedback would be greatly appreciated!</p>&#xA;&#xA;<p>Cheers</p>&#xA;"
43056426,Microservices - using strict types to enforce the API?,2017-03-27 21:01:45,<json><haskell><service><types><microservices>,1,76,1,0.0,0,"<p>I am writing two separate services. The output of the first service feeds into the second. Should I use a shared library so the type checker can make sure the interfaces match?</p>&#xA;&#xA;<p>The ""products"" service takes an <code>Application</code> and produces <code>Products</code>. </p>&#xA;&#xA;<p>The ""scores"" service takes <code>Application</code> and <code>Products</code> and produces a <code>Score</code>. It uses less than half of the information available. </p>&#xA;&#xA;<p>Should I have the interface for ""scores"" exactly match the output of ""products"", even though it doesn't use all the information? Both will be used by the same client, and it would be convenient for it not to have to do any transformation. I can use a shared library containing only types and json serialization code that can enforce this. The build system can depend on old versions of the shared lib, so as long as I keep it forward compatible, I shouldn't need to update ""scores"" when fields are added to the output of ""products"". </p>&#xA;&#xA;<p>Or should I have ""scores"" reinvent its own concept of the interface, with only the fields it needs? The field names might not match, making it more difficult for the client to connect them. The advantage is the interfaces are completely de-coupled.</p>&#xA;"
43055993,Sizing up Microservices using bonded context from DDD,2017-03-27 20:35:21,<domain-driven-design><microservices><bounded-contexts>,1,171,1,0.0,0,<p>Ive heard allot about sizing up Microservices using bounded context from DDD. Any ideas what this actually means?</p>&#xA;&#xA;<p>thanks&#xA;goaths</p>&#xA;
43032883,How could authentication work across microservices?,2017-03-26 18:31:33,<javascript><node.js><authentication><jwt><microservices>,3,111,3,0.0,0,"<p>I have two separate Node.js services.</p>&#xA;&#xA;<p>Service <code>A</code> is responsible for authenticating users.  If a user successfully logs in, the user is redirected to Service <code>B</code> (hosted on a <strong>subdomain</strong> of the domain Service <code>A</code> is hosted on).</p>&#xA;&#xA;<p>I am using <a href=""https://jwt.io/"" rel=""nofollow noreferrer"">JWT</a> for authentication.</p>&#xA;&#xA;<p><strong>Question:</strong> How can Service <code>B</code> be aware if a user is or is not authenticated?</p>&#xA;&#xA;<p>I imagine one way that Service <code>B</code> could be aware if they are or aren't authenticated is by asking Service <code>A</code> to check the JWT on each  Request to Service <code>B</code>. But how is Service <code>A</code> supposed to send the JWT to the client when the client is going to be redirected to a new origin?</p>&#xA;&#xA;<p>Is it safe to do something like:</p>&#xA;&#xA;<pre><code>window.location.href = 'https://b.example.com?jwt=tokenhere'&#xA;</code></pre>&#xA;&#xA;<p>I don't believe storing the JWT on <code>localStorage</code> since it does not allow cross origin access.</p>&#xA;"
51312350,Microservices seggregation,2018-07-12 18:33:44,<microservices>,2,22,0,0.0,0,"<p>I am a little bit confused. In my company we have lots of different integrations, at the moment we have them within the same application. If we decide to go to micro service architecture, should every integration be separate service or they should all be in one? </p>&#xA;&#xA;<p>Situation with integrations is that they are payment integrations, we communicate go payment providers and async responses from them, so we have to open couple of urls for each integration to receive answers from payment gateways. So they are not related to each other. </p>&#xA;"
51150957,How to apply a microservices architecture to a financial products consulting website? is it practical?,2018-07-03 09:23:55,<architecture><microservices>,1,29,0,0.0,0,"<p>I'm working on a website which displays financial products, their related documents and performance charts...</p>&#xA;&#xA;<p>It is actually a complex monolithic application which has a lot of code and functionality.</p>&#xA;&#xA;<p>Is it practical to divide this application into a microservices architecture?</p>&#xA;&#xA;<p>knowing that users do not login on the website, there is no business transactions, they simply search, consult and see products and related information on the website</p>&#xA;"
51284332,Using Spring's Sleuth for MDC when working with other microservices frameworks,2018-07-11 11:27:54,<spring-boot><microservices><spring-cloud-sleuth><mdc>,1,39,0,0.0,0,"<p>The Spring's <a href=""https://cloud.spring.io/spring-cloud-sleuth/"" rel=""nofollow noreferrer"">Sleuth</a> seems like a good solution for <a href=""https://logback.qos.ch/manual/mdc.html"" rel=""nofollow noreferrer"">MDC (Mapped Diagnostic Context)</a> when working with only Spring Boot microservices.</p>&#xA;&#xA;<p>But we are wondering if it can useful when every microservice is built with a different framework (<a href=""https://www.dropwizard.io/1.3.5/docs/"" rel=""nofollow noreferrer"">dropwizard</a>, <a href=""http://sparkjava.com/"" rel=""nofollow noreferrer"">java spark</a>, ...), or even different language (Node.js...)? </p>&#xA;&#xA;<p>Or the only way to use it, is when all the microservices in the system are built with Spring Boot?</p>&#xA;&#xA;<p>Obviously, non-springboot apps will not be able to support this Sleuth's MDC functionality, and the chain of ""traceId"" will be lost.</p>&#xA;&#xA;<p>So it seems like the way to work around this, is to keep on passing some ""traceId"" parameter in all the HTTP calls between the different services. </p>&#xA;&#xA;<p>For example: <code>http://userservice/getuser?id=5&amp;traceId=abc-321</code>&#xA;and &#xA;<code>http://billingservice/getbill?id=5&amp;traceId=abc-321</code></p>&#xA;&#xA;<p>And then, each microservice has to ""reinvent the wheel"" in order to handle the MDC issue.</p>&#xA;&#xA;<p>Is this correct, or are we missing something?</p>&#xA;"
51314434,ASP.NET Core Microservices,2018-07-12 21:04:28,<docker><asp.net-core><microservices><docker-container>,1,45,0,0.0,0,"<p>I am creating microservices using docker and asp.net core 2. I have created 2 microservices and a web api. I am trying to call the microservice endpoint from the web api using HttpClient. Below is the web api controller code</p>&#xA;&#xA;<pre><code>    [HttpGet]&#xA;    public async Task&lt;IEnumerable&lt;string&gt;&gt; GetAsync()&#xA;    {&#xA;&#xA;        var client = new HttpClient();&#xA;        var data = await client.GetAsync(""http://localhost:8081/api/values"");&#xA;&#xA;        return new string[] { ""apigateway-value1"", ""apigateway-value2"" };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>This is my docker-compose.yml file where the microservice I am trying to call is specified.</p>&#xA;&#xA;<pre><code>microserviceone:&#xA;&#xA;image: ${DOCKER_REGISTRY}microserviceone&#xA;build:&#xA;  context: .&#xA;  dockerfile: MicroserviceOne/Dockerfile&#xA;ports: &#xA;- ""8082:80""&#xA;</code></pre>&#xA;&#xA;<p>This the microservice Dockerfile</p>&#xA;&#xA;<pre><code>FROM microsoft/aspnetcore:2.0 AS base    &#xA;WORKDIR /app    &#xA;EXPOSE 80&#xA;&#xA;FROM microsoft/aspnetcore-build:2.0 AS build    &#xA;WORKDIR /src    &#xA;COPY MicroserviceOne/MicroserviceOne.csproj MicroserviceOne/    &#xA;RUN dotnet restore MicroserviceOne/MicroserviceOne.csproj    &#xA;COPY . .    &#xA;WORKDIR /src/MicroserviceOne    &#xA;RUN dotnet build MicroserviceOne.csproj -c Release -o /app&#xA;&#xA;FROM build AS publish    &#xA;RUN dotnet publish MicroserviceOne.csproj -c Release -o /app    &#xA;&#xA;FROM base AS final    &#xA;WORKDIR /app    &#xA;COPY --from=publish /app .    &#xA;ENTRYPOINT [""dotnet"", ""MicroserviceOne.dll""]&#xA;</code></pre>&#xA;&#xA;<p>The problem is I am getting an error ""System.Net.Http.CurlException: Couldn't connect to server"". From the command prompt if I try to access the same endpoint using the command    </p>&#xA;&#xA;<pre><code>    curl -X GET -H Content-Type: application/json  http://localhost:808/api/values    &#xA;</code></pre>&#xA;&#xA;<p>I am getting the data. I really don't know what is happening.</p>&#xA;"
51285225,User and Account management in a distributed system,2018-07-11 12:14:38,<microservices><soa>,1,48,0,0.0,0,"<p>we have a big distributed and multitenant system with all sorts of accounts :&#xA; - admin and backoffice users account&#xA; - customer account&#xA; - cashier  account (tenant : there is one or many more cashier for each client tenant)</p>&#xA;&#xA;<p>All this account are sharing more or less the same lifecycle (account created, grant on some ressources, deny account, password reminder...) &#xA;But they are not used in all applications of the system : some account would be used on specific or just two application for example.&#xA; Furthermore our system should have the possibility to have a bridge with a CMS for the customer management, or the backoffice users account could be authorized one day against a ldap...</p>&#xA;&#xA;<p>So the question : we are searching for the best way to model our right and authorization service(s).&#xA;One idea is to create one service in order to manage all types of accounts of any kind : that is a SOA way to modularize our system&#xA;And one idea is to create different services : perhaps much more a micro-service oriented way of thinking...</p>&#xA;&#xA;<p>What are your opinion ? I am searching some advices and feedback on this two different approach or perhaps an alternative that we habve not thought about...</p>&#xA;"
51138147,jhipster gateway and microservice,2018-07-02 14:10:58,<microservices><jhipster><gateway>,1,51,0,0.0,0,<p>I need to run my gateway and microservice in local without docker. Is this possible?</p>&#xA;&#xA;<p>I created two projects: gateway and microservice. How can I run in local without docker?</p>&#xA;
51282283,Multi-Tenant Authentication with AWS Cognito,2018-07-11 09:46:40,<amazon-web-services><authentication><microservices><multi-tenant><aws-cognito>,1,78,0,1.0,0,"<p>My current project is in AWS, using Cognito and microservices with Lambda. We have designed the microservices using DDD and are in the process of implementing basic functionality.</p>&#xA;&#xA;<p>However, there is a business need for users of the API to be able to be categorised into the client company that they work for, and only be able to access data for that client company as well as any role-based authentication we will have.</p>&#xA;&#xA;<p>This isn't a full multi-tenant solution as every user will be working with the same website, but their account will have been associated with a particular client. </p>&#xA;&#xA;<p>Everything I have read about doing something like this in AWS suggests using one user role or pool per client and associating users with it when they are created, however we do not want to do this, as the clients typically consist of 2-3 users and there are many clients. This would quickly become unmaintainable in terms of number of user pools.</p>&#xA;&#xA;<p>I tried to think of ways around this issue using ""conventional"" means, such as adding a domain service into the architecture which was solely designed to add client data to each request by a particular user by calling into the user microservice, but this seems overly complex. I also considered changing the architecture to include basic user and role information in each microservice, but that seems messy.</p>&#xA;&#xA;<p>My question is are there any officially supported ways to add data into an AWS Cognito profile programmatically, and in such a way that this could be changed through a front-end website by a client admin after the account has been created? Even if it's just a clientId field in the token.</p>&#xA;&#xA;<p>If not, then what would anybody who has experienced a similar issue recommend as an alternative to the user pools suggestion.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>I have also been investigating several ways to do this using attributes on Cognito profiles, as mentioned <a href=""https://aws.amazon.com/blogs/apn/managing-saas-identity-through-custom-attributes-and-amazon-cognito/"" rel=""nofollow noreferrer"">here</a>. It seems like this is the way to do more or less what I'm trying to achieve, but I'd still like to hear about alternatives or advice.</p>&#xA;"
51173039,How do I call API from service bus,2018-07-04 11:52:21,<asp.net-mvc><microservices><publish-subscribe><azureservicebus><servicebus>,2,87,0,0.0,0,"<p>I am trying to learn to Build Microservices based app where Microservices would be communicating via some service bus. In my case, I am using Azure Service bus.</p>&#xA;&#xA;<p>With referring to below link an initial system is set up. Messages are reaching to the queue.</p>&#xA;&#xA;<p><a href=""https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dotnet-multi-tier-app-using-service-bus-queues"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dotnet-multi-tier-app-using-service-bus-queues</a></p>&#xA;&#xA;<p>But as next step or mimicking real app, I have OrderAPI to handle the orders.</p>&#xA;&#xA;<p>This is how my WorkerRole class looks like</p>&#xA;&#xA;<pre><code>namespace OrderProcessingRole&#xA;{&#xA; public class WorkerRole : RoleEntryPoint&#xA; {&#xA;    // The name of your queue&#xA;    const string QueueName = ""ProcessingQueue"";&#xA;&#xA;    // QueueClient is thread-safe. Recommended that you cache &#xA;    // rather than recreating it on every request&#xA;    QueueClient Client;&#xA;    ManualResetEvent CompletedEvent = new ManualResetEvent(false);&#xA;&#xA;    public override void Run()&#xA;    {&#xA;        Trace.WriteLine(""Starting processing of messages"");&#xA;&#xA;        // Initiates the message pump and callback is invoked for each message that is received, calling close on the client will stop the pump.&#xA;        Client.OnMessage((receivedMessage) =&gt;&#xA;            {&#xA;                try&#xA;                {&#xA;                    // Process the message&#xA;                    Trace.WriteLine(""Processing Service Bus message: "" + receivedMessage.SequenceNumber.ToString());&#xA;                }&#xA;                catch&#xA;                {&#xA;                    // Handle any message processing specific exceptions here&#xA;                }&#xA;            });&#xA;&#xA;        CompletedEvent.WaitOne();&#xA;     }&#xA;&#xA;     public override bool OnStart()&#xA;     {&#xA;        // Set the maximum number of concurrent connections &#xA;        ServicePointManager.DefaultConnectionLimit = 12;&#xA;&#xA;        // Create the queue if it does not exist already&#xA;        string connectionString = CloudConfigurationManager.GetSetting(""Microsoft.ServiceBus.ConnectionString"");&#xA;        var namespaceManager = NamespaceManager.CreateFromConnectionString(connectionString);&#xA;        if (!namespaceManager.QueueExists(QueueName))&#xA;        {&#xA;            namespaceManager.CreateQueue(QueueName);&#xA;        }&#xA;&#xA;        // Initialize the connection to Service Bus Queue&#xA;        Client = QueueClient.CreateFromConnectionString(connectionString, QueueName);&#xA;        return base.OnStart();&#xA;    }&#xA;&#xA;    public override void OnStop()&#xA;    {&#xA;        // Close the connection to Service Bus Queue&#xA;        Client.Close();&#xA;        CompletedEvent.Set();&#xA;        base.OnStop();&#xA;    }}}&#xA;</code></pre>&#xA;&#xA;<p>I am not sure, how &amp; where should I call the OrdersAPI when service bus is in place.</p>&#xA;&#xA;<p>I am guessing it would be in </p>&#xA;&#xA;<pre><code>OnStart() -&gt; &#xA;Client.OnMessage((receivedMessage) =&gt;&#xA;            {&#xA;                try&#xA;                {&#xA;                   //Order API call here&#xA;                }&#xA;                catch&#xA;                {&#xA;&#xA;                }&#xA;            });&#xA;</code></pre>&#xA;&#xA;<p>If my guess is right, then how I call my OrderAPI which is hosted on</p>&#xA;&#xA;<pre><code>http://localhost:8090/api/order&#xA;</code></pre>&#xA;&#xA;<p>Thanks.</p>&#xA;"
51191291,Differences between the service Mesh projects Istio and Conduit,2018-07-05 12:26:01,<microservices><istio>,1,118,0,0.0,0,"<p><strong><em>"" 2018: The Year of Service Mesh ""</strong> <br></em></p>&#xA;&#xA;<p>Recently, I did some research on the service Mesh for handling service-to-service communication, and the implementations created in the last two years. But I'm still so confused about the real <strong>differences</strong> between <em>Istio</em> and <em>Conduit</em> that already give the same features.&#xA;<br><br>&#xA;So it is obvious that they are competitors but, based on what, we can choose, as clients, the project that we should take?</p>&#xA;"
51175627,Unserializable value,2018-07-04 14:07:01,<python><serialization><flask><microservices><nameko>,1,51,1,0.0,0,"<p>I'm currently stuck with a serialization problem. The data seems ok in Nameko but not in Flask because an error occurred. I tried to serialise and unserialize, but it didn't work.</p>&#xA;&#xA;<p>Here is an example of data from a MongoDB database : </p>&#xA;&#xA;<pre><code>{u'building': u'urk', u'idcapteur': 8, u'room': u'tyu', u'idpiece': 1, u'uri': u'urk/tyu/luminosity/yota1', u'idMesure': 458945, u'subId': u'yota1', u'datemesure2': datetime.datetime(2017, 6, 16, 12, 48, 19, 179000), u'datemesure': datetime.datetime(2017, 6, 16, 12, 48, 19, 179000), u'device': u'luminosity', u'_id': ObjectId('7825ahy'), u'data': {u'date': u'2017-06-16T14:48:19.179435', u'payload': {u'subID': u'yota1', u'input': 50, u'value_units': u'lux', u'value': 500, u'unitID': u'inside'}, u'uri': u'urk/tyu/luminosity/yota1'}, u'mesurevaleur': [{u'idlibv': 5, u'valeur': 500.0}]}&#xA;</code></pre>&#xA;&#xA;<p>Here is my Nameko program : </p>&#xA;&#xA;<pre><code># -*-coding:utf-8 -*&#xA;&#xA;# neocampus.py&#xA;&#xA;import json&#xA;from database import startMongoDbConnection, getRawDataCollection, mongoDbQuery&#xA;from nameko.rpc import rpc&#xA;#from database.py import startMongoDbConnection, getRawDataCollection, mongoDbQuery&#xA;&#xA;mdbConnection = ''&#xA;mdbCollection = ''&#xA;&#xA;# Send a request to the microservices system. It will call other microservices&#xA;class MsRequest:&#xA;    name=""msRequest""&#xA;&#xA;    # TODO&#xA;    @rpc&#xA;    def msRequest(self, value):&#xA;        # Connect to MongoDB database and collection, if not already done&#xA;        global mdbConnection, mdbCollection, queryResult&#xA;        if mdbConnection == '':&#xA;            mdbConnection = startMongoDbConnection()&#xA;        if mdbCollection == '':&#xA;            mdbCollection = getRawDataCollection(mdbConnection)&#xA;&#xA;        # Check the requested microservice&#xA;        someData = GetData()&#xA;        jsonData = someData.getData(value)&#xA;&#xA;        # It prints the proper data&#xA;        for document in jsonData:&#xA;            print(document)&#xA;&#xA;        print(""FINISHED !!!"")&#xA;&#xA;        # Don't forget : closeMongoDbConnection()&#xA;        return jsonData&#xA;&#xA;# Get data depending on sensor type&#xA;class GetData:&#xA;    name=""getData""&#xA;&#xA;    def getData(self, sensorType):&#xA;        global mdbCollection&#xA;        queryResult = mongoDbQuery(mdbCollection, ""device"", ""$eq"", sensorType)&#xA;        return queryResult&#xA;&#xA;&#xA;# From database.py&#xA;&#xA;&#xA;def mongoDbQuery(someCollection, key, choice, value):&#xA;    # Use MongoDB query dependeing on choices in parameters&#xA;    docs = someCollection.find({key:{choice:value}}).limit(10)&#xA;&#xA;    #for document in docs:&#xA;        #print(document)&#xA;    return docs&#xA;&#xA;# Start a MongoDB connection&#xA;def startMongoDbConnection():&#xA;    connected = connectToMongoDb(""mongodb"")&#xA;    return connected&#xA;&#xA;# Start a MongoDB connection&#xA;def startMongoDbConnection():&#xA;    connected = connectToMongoDb(""mongodb"")&#xA;    return connected&#xA;&#xA;# Choose the first collection available (for raw data)&#xA;def getRawDataCollection(connection):&#xA;    currentCollection = chooseCollection(connection, mongollection)&#xA;    return currentCollection&#xA;</code></pre>&#xA;&#xA;<p>And now, my Flask program : </p>&#xA;&#xA;<pre><code>@app.route('/', methods=['GET', 'POST'])&#xA;def getData():&#xA;    with ClusterRpcProxy(CONFIG) as rpc:&#xA;        myData = rpc.msRequest.msRequest(""luminosity"")&#xA;        #for document in myData:&#xA;            #print myData&#xA;    return flask.jsonify(**myData)&#xA;</code></pre>&#xA;&#xA;<p>Finally, the error output : </p>&#xA;&#xA;<pre><code>ERROR in app: Exception on / [GET]&#xA;Traceback (most recent call last):&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/flask/app.py"", line 2292, in wsgi_app&#xA;    response = self.full_dispatch_request()&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/flask/app.py"", line 1815, in full_dispatch_request&#xA;    rv = self.handle_user_exception(e)&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/flask/app.py"", line 1718, in handle_user_exception&#xA;    reraise(exc_type, exc_value, tb)&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/flask/app.py"", line 1813, in full_dispatch_request&#xA;    rv = self.dispatch_request()&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/flask/app.py"", line 1799, in dispatch_request&#xA;    return self.view_functions[rule.endpoint](**req.view_args)&#xA;  File ""/home/oyo/flask_sandfox/sandfox.py"", line 16, in getData&#xA;    myData = rpc.msRequest.msRequest(""luminosity"")&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/nameko/rpc.py"", line 369, in __call__&#xA;    return reply.result()&#xA;  File ""/home/oyo/.local/lib/python2.7/site-packages/nameko/rpc.py"", line 327, in result&#xA;    raise deserialize(error)&#xA;RemoteError: UnserializableValueError Unserializable value: `&lt;pymongo.cursor.Cursor object at 0x7f3274612e50&gt;`&#xA;</code></pre>&#xA;&#xA;<p>With a print, data is correctly displayed in the terminal. But not in Flask, I get an error 500. I thought that with JSON data and Jsonify (found here, in this site), I could display something. But it's not the cas.</p>&#xA;&#xA;<p>Any help, advice or hint would be gladly appreciated. Thank you.</p>&#xA;"
51292640,How to design a microservice based application with each microservice having their own datasource?,2018-07-11 19:09:48,<java><spring-boot><microservices><rdbms>,2,62,2,0.0,0,<p>I am designing a microservice based application in which there are services that uses information from a MySQL db. There are two services - Booking Service and Payment Service.</p>&#xA;&#xA;<p>Payment Service needs information from Booking Service.</p>&#xA;&#xA;<p>How to design this using MySQL while keeping separate db for both the services? How to enforce the relational constraints between two tables which are on separate databases?</p>&#xA;&#xA;<p>P.S: I am using Spring Boot to design the web services.</p>&#xA;
51224374,Microservice requests,2018-07-07 15:04:26,<microservices>,2,40,3,0.0,0,"<p>I'm trying to start a little microservice application, but I'm a little bit stuck on some technicalities.</p>&#xA;&#xA;<p>I'm trying to build an issue tracker application as an example.</p>&#xA;&#xA;<p>It has 2 database tables, issues and comments. These will also be separate microservices, for the sake of the example.</p>&#xA;&#xA;<p>It has to be a separate API that can be consumed by multiple types of clients e.g. mobile, web etc..</p>&#xA;&#xA;<p>When using a monolitic approach, all the codebase is coupled together, and when making a request to let's say the REST API, I would handle for example the '/issues/19' request&#xA;to fetch the issue with the id '19' and it's corresponding comments by means of the following pseudocode.</p>&#xA;&#xA;<pre><code>on_request_issue(id) # handler for the route '/issues/&lt;id&gt;'&#xA;    issue = IssuesModel.findById(id)&#xA;    issue.comments = CommentsModel.findByIssueId(id)&#xA;    return issue&#xA;</code></pre>&#xA;&#xA;<p>But I'm not sure on how I should approach this with microservices. Let's say that we have microservice-issues and microservice-comments.</p>&#xA;&#xA;<p>I could either let the client send a request to both '/issues/19' and '/comments/byissueid/19'. But that doesn't work nice in my point of view, since if we're having multiple things&#xA;we're sending alot of requests for one page.</p>&#xA;&#xA;<p>I could also make a request to the microservice-issues and in that one also make a request to the microservice-comments, but that looks even worse to me than the above, since from what&#xA;I've read microservices should not be coupled, and this couples them pretty hard.</p>&#xA;&#xA;<p>So then I read about API gateways, that they could/should receive a request and fan out to the other microservices but then I couldn't really figure out how to use an API gateway. Should&#xA;I write code in there for example to catch the '/issues/19' request, then fan out to both the microservice-issues and microservice-commetns, assemble the stuff and return it? &#xA;In that case, I'm feeling I'm doing the work double, won't the API gateway become a new monolith then?</p>&#xA;&#xA;<p>Thank you for your time</p>&#xA;"
51280734,Spring boot application stopping without any error on console,2018-07-11 08:30:13,<maven><spring-boot><amazon-ec2><microservices><aws-regions>,4,149,3,0.0,0,"<p>I have created spring boot application using maven. Where I built a executable jar for application the tried to run it on EC2 instance free tier windows using following command<br>&#xA;java -jar com-spring-boot-apps-0.0.1-SNAPSHOT.jar  --server.port=8181 -Xdebug</p>&#xA;&#xA;<p>Some it application does not run, it exists with following logs on console. </p>&#xA;&#xA;<pre><code>log4j:WARN No appenders could be found for logger (org.springframework.web.context.support.StandardServletEnvironment).&#xA;log4j:WARN Please initialize the log4j system properly.&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v2.0.3.RELEASE)&#xA;&#xA;2018-07-11 13:55:50.762  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]&#xA;2018-07-11 13:55:50.768  INFO 2784 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.31&#xA;2018-07-11 13:55:50.800  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : Loaded APR based Apache Tomcat Native library [1.2.17] using APR version [1.6.3].&#xA;2018-07-11 13:55:50.803  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true].&#xA;2018-07-11 13:55:50.805  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR/OpenSSL configuration: useAprConnector [false], useOpenSSL [true]&#xA;2018-07-11 13:55:52.060  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : OpenSSL successfully initialized [OpenSSL 1.0.2o  27 Mar 2018]&#xA;2018-07-11 13:55:52.402  INFO 2784 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext&#xA;2018-07-11 13:55:52.532  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]&#xA;</code></pre>&#xA;&#xA;<p>Exception :- </p>&#xA;&#xA;<pre><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'regionProvider': Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.aws.core.region.StaticRegionProvider]: Constructor threw exception; nested exception is java.lang.IllegalArgumentException: The region 'ap-south-1a' is not a valid region!&#xA;</code></pre>&#xA;"
51272560,Dockerized Spring Boot microservice freeze without reason,2018-07-10 19:14:13,<java><spring><docker><microservices><freeze>,1,58,4,0.0,0,"<p>I have a microservices based project. Each microservice is a Spring Boot (v.2.0.0-RC2) app. I have also a discovery, config and gateway microservices based on Spring Cloud (Finchley). The whole system is deployed on test machine using Docker Compose. </p>&#xA;&#xA;<p>I realized that one of the microservices freezes after receiving several subsequent requests from frontend app, in a short period of time. After this, it becomes unresponsive for further requests, and I receive read timeout from my gateway. The same occurs when calling this microservice directly, bypassing the gateway.</p>&#xA;&#xA;<p>I have a spring boot admin instance, and I realized the microservice goes offline and online again every 5 minutes. Despite of that, nothing interesting occurs in logs. No memory issues observed.</p>&#xA;&#xA;<p>Next remark: this problem occurs only when I start all system from docker compose in same time. When I restart this single microservice, I can't reproduce it anymore.</p>&#xA;&#xA;<p>And the last:  the whole container of the microservice seems to be freezed. When I do 'docker stop' on it, the terminal hangs up, but after checking the container status in another terminal, the container appears as 'exited'. A very strange thing occured, when I did 'docker attach' on the container. The terminal also hung up and when I exited from it, my problematic microservice started to work properly and accepts incoming request with success.</p>&#xA;&#xA;<p>Can anyone help me with this strange problem ? I have really no more ideas, what can I try to resolve it. </p>&#xA;&#xA;<p>Thanks in advance for any clue.</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>docker-compose.yml</p>&#xA;&#xA;<pre><code>version: '3.4'&#xA;&#xA;services:&#xA;&#xA;  config-service:&#xA;    image: im/config-service&#xA;    container_name: config-service&#xA;    environment:&#xA;     - SPRING_PROFILES_ACTIVE=native&#xA;    volumes:&#xA;     - ~/production-logs:/logs&#xA;&#xA;  discovery-service:&#xA;    image: im/discovery-service&#xA;    container_name: discovery-service&#xA;    environment:&#xA;     - SPRING_PROFILES_ACTIVE=production&#xA;    volumes:&#xA;     - ~/production-logs:/logs&#xA;&#xA;  gateway-service:&#xA;    image: im/gateway-service&#xA;    container_name: gateway-service&#xA;    ports:&#xA;     - ""8080:8080""&#xA;    depends_on:&#xA;     - config-service&#xA;     - discovery-service&#xA;    environment:&#xA;     - SPRING_PROFILES_ACTIVE=production&#xA;    volumes:&#xA;     - ~/production-logs:/logs&#xA;&#xA;  car-service_db:&#xA;    image: postgres:9.5&#xA;    container_name: car-service_db&#xA;    environment:&#xA;     - POSTGRES_DB=car&#xA;     - POSTGRES_USER=user&#xA;     - POSTGRES_PASSWORD=pass&#xA;&#xA;  car-service:&#xA;    image: im/car-service&#xA;    container_name: car-service&#xA;    depends_on:&#xA;     - config-service&#xA;     - discovery-service&#xA;     - car-service_db&#xA;    environment:&#xA;     - SPRING_PROFILES_ACTIVE=production&#xA;     - CAR_SERVICE_DB_URL=jdbc:postgresql://car-service_db:5432/car&#xA;     - CAR_SERVICE_DB_USER=user&#xA;     - CAR_SERVICE_DB_PASSWORD=pass&#xA;    volumes:&#xA;     - ~/production-logs:/logs&#xA;</code></pre>&#xA;&#xA;<p>Dockerfile of car-service</p>&#xA;&#xA;<pre><code>FROM openjdk:8-jdk-alpine&#xA;VOLUME /tmp&#xA;EXPOSE 9005&#xA;ARG JAR_FILE&#xA;ADD ${JAR_FILE} app.jar&#xA;ENV JAVA_OPTS=""-agentlib:jdwp=transport=dt_socket,address=8001,server=y,suspend=n""&#xA;ENTRYPOINT [""sh"", ""-c"", ""java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar""]&#xA;</code></pre>&#xA;&#xA;<p>Command used to start up</p>&#xA;&#xA;<pre><code>docker-compose up&#xA;</code></pre>&#xA;&#xA;<p>Test machine: &#xA;Ubuntu Server 16.04 LTS</p>&#xA;"
51238009,Create endpoint to get multiple records in microservice,2018-07-09 03:52:33,<java><c#><design-patterns><microservices>,3,64,4,0.0,0,"<p>Currently, we have an API endpoint (microservice called supplier service) like this: <code>/suppliers/{supplierNumber}</code>, which will return a single supplier information. </p>&#xA;&#xA;<p>In the UI, there is a screen to display a list of suppliers for different products. It looks something like this:  </p>&#xA;&#xA;<pre><code>product1 -&gt; supplier1&#xA;product2 -&gt; supplier2&#xA;product3 -&gt; supplier3&#xA;</code></pre>&#xA;&#xA;<p>To display suppliers for a list of products, we need a for loop which calls the end point on each iteration.</p>&#xA;&#xA;<p>My concern is that this is inefficient from a performance stand point. Why is it not possible to design an endpoint that takes in a list of supplier numbers and returns a list of supplier information?</p>&#xA;&#xA;<p>Other people have said that it's not microservice design, and I'm not sure why it's not a proper design. Does anyone know the reasoning behind this?</p>&#xA;"
51300620,Strange error with a JHipster app in a microservices architecture and Docker up,2018-07-12 08:22:11,<docker><docker-compose><microservices><jhipster>,2,66,4,0.0,0,"<p>I have generated an app with JHipster 5.0.1 version. The app has 4 components:</p>&#xA;&#xA;<ul>&#xA;<li>UAA app for user accounting and authorizing</li>&#xA;<li>JHipster Registry app</li>&#xA;<li>A gateway app </li>&#xA;<li>A simple microservice</li>&#xA;</ul>&#xA;&#xA;<p>I have followed all the steps in the documentation, including the steps to create docker compose file. But, then when I want to run docker-compose up I get some errors with pull permisions with my custom components.</p>&#xA;&#xA;<p>Here are the logs</p>&#xA;&#xA;<blockquote>&#xA;  <p>compose.cli.verbose_proxy.proxy_callable: docker inspect_image &lt;- ('chipagames')&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""GET /v1.22/images/chipagames/json HTTP/1.1"" 404 60&#xA;  compose.service.pull: Pulling chipagames-app (chipagames:)...&#xA;  compose.cli.verbose_proxy.proxy_callable: docker pull &lt;- ('chipagames', tag='latest', stream=True, platform=None)&#xA;  docker.auth.get_config_header: Looking for auth config&#xA;  docker.auth.resolve_authconfig: Using credentials store ""osxkeychain""&#xA;  docker.auth._resolve_authconfig_credstore: Looking for auth entry for '<a href=""https://index.docker.io/v1/"" rel=""nofollow noreferrer"">https://index.docker.io/v1/</a>'&#xA;  docker.auth.get_config_header: Found auth config&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""POST /v1.22/images/create?tag=latest&amp;fromImage=chipagames HTTP/1.1"" 404 91</p>&#xA;</blockquote>&#xA;&#xA;<p>I have docker service running, I have created a repository in docker hub too, but I don't understand the error.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Here is my docker-compose.yml</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;    appuaa-app:&#xA;        image: appuaa&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATA_MONGODB_URI=mongodb://appuaa-mongodb:27017&#xA;            - SPRING_DATA_MONGODB_DATABASE=appuaa&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=appuaa-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    appuaa-mongodb:&#xA;        image: mongo:3.6.3&#xA;    appuaa-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    chipagames-app:&#xA;        image: chipagames&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://chipagames-postgresql:5432/chipagames&#xA;            - JHIPSTER_SLEEP=30&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;        ports:&#xA;            - 8080:8080&#xA;    chipagames-postgresql:&#xA;        image: postgres:9.6.5&#xA;        environment:&#xA;            - POSTGRES_USER=chipagames&#xA;            - POSTGRES_PASSWORD=&#xA;&#xA;    users-app:&#xA;        image: users&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://users-postgresql:5432/users&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=users-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    users-postgresql:&#xA;        image: postgres:10.4&#xA;        environment:&#xA;            - POSTGRES_USER=users&#xA;            - POSTGRES_PASSWORD=&#xA;    users-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    jhipster-registry:&#xA;        extends:&#xA;            file: jhipster-registry.yml&#xA;            service: jhipster-registry&#xA;&#xA;    jhipster-elasticsearch:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-elasticsearch&#xA;    jhipster-logstash:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-logstash&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-console:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-console&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-import-dashboards:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-import-dashboards&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-zipkin:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-zipkin&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;</code></pre>&#xA;"
36573857,Consistency with partitioned Service Fabric stateful service,2016-04-12 12:51:14,<architecture><microservices><consistency><azure-service-fabric>,4,319,0,0.0,0,"<p>Let's take a simple example. I have a stateful service that manages users. It has a reliable dictionary that maps UserID to some data, including User Name.</p>&#xA;&#xA;<p>In this service's RegisterUser method, we want to check that the user name has not already been used. This is quite straightforward when the service is a singleton, but when it's partitioned we end up with several problems:</p>&#xA;&#xA;<ol>&#xA;<li>We have to ask all partitions if the user already exists. We could possibly introduce another singleton service that maps user name to user id to overcome this problem.</li>&#xA;<li>There's a race condition. Two users could try to register the name user name at the same time. It's possible that both users could succeed.</li>&#xA;</ol>&#xA;&#xA;<p>I'm looking for general advice for possible ways to deal with situations such as this. I can imagine that this sort of problem would occur regularly with partitioned data.</p>&#xA;"
36599435,Servce Fabric Stateful services - Recovering from corruption,2016-04-13 13:09:23,<architecture><microservices><azure-service-fabric><disaster-recovery>,1,84,0,0.0,0,"<p>The scenario is that we have a Service Fabric application in production, using Stateful services. Something bad has happened that has caused the state of the system to become inconsistent. We need to fix the problem that caused the corrupted state, but we need to very quickly fix the state.</p>&#xA;&#xA;<p>There are a couple of issues here about which I would like to hear peoples' views:</p>&#xA;&#xA;<ol>&#xA;<li><p>How do we visualise the data in the services? Should we implement some sort of 'Dump Data' functions so that we can get a handle on what's happened? Even with a debugger it's hard to see the data in the services.</p></li>&#xA;<li><p>Once we've identified what data has been corrupted, we will want to quickly fix it to get our customers running again. We may want to do this before we've figured out the root cause of the problem. I assume we need to deploy a new version of all affected services with some special one-time code in there to fix up the corruption. Any other suggestions?</p></li>&#xA;</ol>&#xA;"
36569703,how to set local path in yaml configuration file in microservice,2016-04-12 09:51:32,<config><microservices><netflix-eureka>,1,1374,0,0.0,0,"<p>Here all the properties file are in github location,so that I am able to read using uri path ,how I will read if It's in my local system.Can anybody please guide ?</p>&#xA;&#xA;<pre><code>server:&#xA;  port: 8888&#xA;&#xA;eureka:&#xA;  instance:&#xA;    hostname: configserver&#xA;  client:&#xA;    registerWithEureka: true&#xA;    fetchRegistry: true&#xA;    serviceUrl:&#xA;      defaultZone: http://discovery:8761/eureka/&#xA;&#xA;spring:&#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: https://github.com/****/******&#xA;</code></pre>&#xA;"
36422243,spring security oauth2 authorization server without any UI,2016-04-05 09:25:47,<spring-security><spring-boot><spring-security-oauth2><microservices>,2,951,0,0.0,0,"<p>I have implemented a spring security oauth2 authorization server as a spring boot microservice.  I'm trying to allow our main (non-java) application to migrate to oauth2 using this new service.  </p>&#xA;&#xA;<p>One thing I can't get around my head is how to set this up so that the authorization server never shows any UI.  In particular, is there any way to have the /oauth/authorize UI hosted on our main application, but still accept proxied authorization approvals?  Or does that UI need to be served directly by the authorization server?</p>&#xA;"
36400599,Spring Boot Issue while starting Jetty Container,2016-04-04 10:50:21,<spring-boot><microservices>,1,526,5,0.0,0,"<p>When I am starting the spring boot application, it is throwing the following exception.</p>&#xA;&#xA;<p>I am not sure if the FAT jar includes servlet container that has anything related to OS related. Here is the exception I am getting while running the application:</p>&#xA;&#xA;<pre><code>    2016-04-04 15:42:55.146  INFO 10432 --- [           main] application&#xA;                   : Destroying Spring FrameworkServlet 'dispatcherServlet'&#xA;2016-04-04 15:42:55.147  INFO 10432 --- [           main] o.e.jetty.server.handl&#xA;er.ContextHandler  : Stopped o.s.b.c.e.j.JettyEmbeddedWebAppContext@1f144a2b{/,f&#xA;ile:/C:/Users/roopa_ranganath/AppData/Local/Temp/jetty-docbase.89466793494324913&#xA;0.8080/,UNAVAILABLE}&#xA;2016-04-04 15:42:55.154 ERROR 10432 --- [           main] o.s.boot.SpringApplica&#xA;tion               : Application startup failed&#xA;&#xA;org.springframework.boot.context.embedded.EmbeddedServletContainerException: Una&#xA;ble to start embedded Jetty servlet container&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:124) ~[spring-boot-1.3.3.RELEA&#xA;SE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:293) ~[sprin&#xA;g-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.finishRefresh(EmbeddedWebApplicationContext.java:141) ~[spring-boot-1.3.3.REL&#xA;EASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refres&#xA;h(AbstractApplicationContext.java:541) ~[spring-context-4.2.5.RELEASE.jar!/:4.2.&#xA;5.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.3.3.RELEASE.j&#xA;ar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.&#xA;java:766) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.createAndRefreshContext(Sp&#xA;ringApplication.java:361) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:307) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1191) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1180) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at com.infosys.finanztools.Application.main(Application.java:13) [Finanz&#xA;ToolsServices-11.2.6-SNAPSHOT.jar!/:11.2.6-SNAPSHOT]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.&#xA;0_66]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.&#xA;0_66]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:&#xA;1.8.0_66]&#xA;        at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_66]&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:54) [FinanzToolsServices-11.2.6-SNAPSHOT.jar!/:11.2.6-SNAPSHOT]&#xA;        at java.lang.Thread.run(Unknown Source) [na:1.8.0_66]&#xA;Caused by: java.net.BindException: Address already in use: bind&#xA;        at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.Net.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.Net.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source) ~[na:1.8.0_66&#xA;]&#xA;        at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:27&#xA;7) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNet&#xA;workConnector.java:80) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java&#xA;:216) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLife&#xA;Cycle.java:68) ~[jetty-util-9.2.15.v20160210.jar!/:9.2.15.v20160210]&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:118) ~[spring-boot-1.3.3.RELEA&#xA;SE.jar!/:1.3.3.RELEASE]&#xA;        ... 16 common frames omitted&#xA;&#xA;2016-04-04 15:42:55.160  INFO 10432 --- [           main] .b.l.ClasspathLoggingA&#xA;pplicationListener : Application failed to start with classpath: [jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/, jar:file:/D:/FinanzToolsServices-11.2.&#xA;6-SNAPSHOT.jar!/lib/commons-io-2.4.jar!/, jar:file:/D:/FinanzToolsServices-11.2.&#xA;6-SNAPSHOT.jar!/lib/spring-boot-starter-web-1.3.3.RELEASE.jar!/, jar:file:/D:/Fi&#xA;nanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-boot-starter-1.3.3.RELEASE.jar&#xA;!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-boot-1.3.3.&#xA;RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-&#xA;boot-autoconfigure-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-&#xA;SNAPSHOT.jar!/lib/spring-boot-starter-logging-1.3.3.RELEASE.jar!/, jar:file:/D:/&#xA;FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/logback-classic-1.1.5.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/logback-core-1.1.5.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jcl-over-slf4j-1.7.16.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jul-to-slf4j-1.7.&#xA;16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/log4j-over-s&#xA;lf4j-1.7.16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/sna&#xA;keyaml-1.16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spr&#xA;ing-boot-starter-tomcat-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11&#xA;.2.6-SNAPSHOT.jar!/lib/tomcat-embed-core-8.0.32.jar!/, jar:file:/D:/FinanzToolsS&#xA;ervices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-el-8.0.32.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-logging-juli-8.0.32.jar!/,&#xA;jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-websocke&#xA;t-8.0.32.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring&#xA;-boot-starter-validation-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-1&#xA;1.2.6-SNAPSHOT.jar!/lib/hibernate-validator-5.2.4.Final.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/validation-api-1.1.0.Final.jar!/, jar:f&#xA;ile:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jboss-logging-3.3.0.Final.j&#xA;ar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/classmate-1.1.0.&#xA;jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/hibernate-core-&#xA;3.6.0.Final.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/ant&#xA;lr-2.7.7.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/common&#xA;s-collections-3.2.2.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/dom4j-1.6.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/li&#xA;b/hibernate-commons-annotations-3.2.0.Final.jar!/, jar:file:/D:/FinanzToolsServi&#xA;ces-11.2.6-SNAPSHOT.jar!/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jta-1.1.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/finacle-11.2.6.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-logging-1.1.1.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-beanutils-1.9.2.jar!/, j&#xA;ar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/log4j-1.2.17.jar!/, jar&#xA;:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/common-11.2.6.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-11.2.6.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-jaxb-11.2.6.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/finacle-jaxb-11.2&#xA;.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-ap&#xA;i-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/calcul&#xA;ations-api-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/l&#xA;ib/calculations-impl-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPS&#xA;HOT.jar!/lib/commons-lang-2.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNA&#xA;PSHOT.jar!/lib/febaData-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SN&#xA;APSHOT.jar!/lib/spring-core-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsService&#xA;s-11.2.6-SNAPSHOT.jar!/lib/spring-web-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzTo&#xA;olsServices-11.2.6-SNAPSHOT.jar!/lib/spring-beans-4.2.5.RELEASE.jar!/, jar:file:&#xA;/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-webmvc-4.2.5.RELEASE.jar&#xA;!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-tx-4.2.5.RE&#xA;LEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-te&#xA;st-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/li&#xA;b/spring-context-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SN&#xA;APSHOT.jar!/lib/spring-expression-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsS&#xA;ervices-11.2.6-SNAPSHOT.jar!/lib/spring-aop-4.2.5.RELEASE.jar!/, jar:file:/D:/Fi&#xA;nanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/aopalliance-1.0.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-oxm-4.2.5.RELEASE.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-orm-4.2.5.RELEASE.j&#xA;ar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-jdbc-4.2.&#xA;5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jmock&#xA;-junit3-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/j&#xA;mock-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/hamc&#xA;rest-core-1.3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/h&#xA;amcrest-library-1.3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/jmock-junit4-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.&#xA;jar!/lib/junit-dep-4.4.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.j&#xA;ar!/lib/jmock-legacy-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSH&#xA;OT.jar!/lib/objenesis-1.0.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/cglib-nodep-2.1_3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAP&#xA;SHOT.jar!/lib/junit-3.8.2.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/hsqldb-1.8.0.7.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/hibernate-ehcache-3.6.0.Final.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/ehcache-2.10.1.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-api-2.2.5.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-xjc-2.2.5.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-impl-2.2.5.jar!/, jar:file:/D:/FinanzToolsService&#xA;s-11.2.6-SNAPSHOT.jar!/lib/ehcache-core-2.5.0.jar!/, jar:file:/D:/FinanzToolsSer&#xA;vices-11.2.6-SNAPSHOT.jar!/lib/hibernate-entitymanager-3.6.0.Final.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/cglib-2.2.jar!/, jar:file:/D&#xA;:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/asm-3.1.jar!/, jar:file:/D:/Finan&#xA;zToolsServices-11.2.6-SNAPSHOT.jar!/lib/javassist-3.12.0.GA.jar!/, jar:file:/D:/&#xA;FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/integration-1.0.0.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/slf4j-log4j12-1.7.7.jar!/, jar:f&#xA;ile:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/slf4j-api-1.7.7.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jstl-1.2.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/mysql-connector-java-5.1.10.jar!&#xA;/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-dbcp-1.4.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-pool-1.6.&#xA;jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-server-9.&#xA;2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/j&#xA;avax.servlet-api-3.1.0.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.j&#xA;ar!/lib/jetty-http-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsServices-11.2&#xA;.6-SNAPSHOT.jar!/lib/jetty-io-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/jetty-webapp-9.2.2.v20140723.jar!/, jar:file:/D:&#xA;/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-xml-9.2.15.v20160210.jar!/,&#xA;jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-servlet-9.2.15.v&#xA;20160210.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-&#xA;ant-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/ant-1.6.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/&#xA;ant-launcher-1.6.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/&#xA;lib/jetty-annotations-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsServices-1&#xA;1.2.6-SNAPSHOT.jar!/lib/javax.annotation-api-1.2.jar!/, jar:file:/D:/FinanzTools&#xA;Services-11.2.6-SNAPSHOT.jar!/lib/asm-5.0.1.jar!/, jar:file:/D:/FinanzToolsServi&#xA;ces-11.2.6-SNAPSHOT.jar!/lib/asm-commons-5.0.1.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/asm-tree-5.0.1.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/jetty-plus-9.2.2.v20140723.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-jndi-9.2.2.v20140723.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-util-9.2.15.v20160&#xA;210.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-secur&#xA;ity-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/apache-jstl-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-&#xA;SNAPSHOT.jar!/lib/taglibs-standard-spec-1.2.1.jar!/, jar:file:/D:/FinanzToolsSer&#xA;vices-11.2.6-SNAPSHOT.jar!/lib/taglibs-standard-impl-1.2.1.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-databind-2.4.0.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-core-2.4.0.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-annotations-2.4.&#xA;0.jar!/]&#xA;Exception in thread ""main"" java.lang.RuntimeException: java.lang.reflect.Invocat&#xA;ionTargetException&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:62)&#xA;        at java.lang.Thread.run(Unknown Source)&#xA;Caused by: java.lang.reflect.InvocationTargetException&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;        at java.lang.reflect.Method.invoke(Unknown Source)&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:54)&#xA;        ... 1 more&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerExc&#xA;eption: Unable to start embedded Jetty servlet container&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:124)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:293)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.finishRefresh(EmbeddedWebApplicationContext.java:141)&#xA;        at org.springframework.context.support.AbstractApplicationContext.refres&#xA;h(AbstractApplicationContext.java:541)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.refresh(EmbeddedWebApplicationContext.java:118)&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.&#xA;java:766)&#xA;        at org.springframework.boot.SpringApplication.createAndRefreshContext(Sp&#xA;ringApplication.java:361)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:307)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1191)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1180)&#xA;        at com.infosys.finanztools.Application.main(Application.java:13)&#xA;        ... 6 more&#xA;Caused by: java.net.BindException: Address already in use: bind&#xA;        at sun.nio.ch.Net.bind0(Native Method)&#xA;        at sun.nio.ch.Net.bind(Unknown Source)&#xA;        at sun.nio.ch.Net.bind(Unknown Source)&#xA;        at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)&#xA;        at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)&#xA;        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:27&#xA;7)&#xA;       at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNet&#xA;workConnector.java:80)&#xA;        at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java&#xA;:216)&#xA;        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLife&#xA;Cycle.java:68)&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:118)&#xA;        ... 16 more&#xA;</code></pre>&#xA;"
33315965,Java Streams batch combinatory call,2015-10-24 08:09:44,<java><java-stream><microservices><project-reactor>,1,68,0,0.0,0,"<p>My question of the day is about combinatory operation when building microservices.</p>&#xA;&#xA;<p>Let us use the fictionnal scenario : I want to build a dashboard. The dashboard is composed of a bunch of people and their infos (history, reviews, purchases, last products searched). </p>&#xA;&#xA;<p>Reading spring-cloud and spring-reactor, I would like a non blocking solution calling multiple microservices : user service, review service, search engine service, .... </p>&#xA;&#xA;<p>My first guess was to do something like </p>&#xA;&#xA;<ul>&#xA;<li>load the users, </li>&#xA;<li>for each one load its reviews then </li>&#xA;<li>load its history then </li>&#xA;<li>combine all the data</li>&#xA;</ul>&#xA;&#xA;<p>In pseudo-code something like <code>loadUsers().flatmap(u -&gt; loadReviews(u))....reduce()</code>. It's really approximative here as you can see.</p>&#xA;&#xA;<p>When loading 1 user, we can estimate that we need 4 more http calls. For 100 users, 400 additional calls etc etc. <strong>The Big-O doesn't seem linear</strong>. </p>&#xA;&#xA;<p>In the worst case where a microservice also delegates data loading from a XYZ microservices then we have got : for 1 user -> N calls including 1 review call -> 1 XYZ call. Sorry I didn't calculate the Big-O (quadratic ?).</p>&#xA;&#xA;<p>To avoid that, we can perhaps load all the users, extract their id, call earch microservcies with a batch of ids. Each microservices can load all the data at once (List of reviews mapped by id perhaps) and the original called will merge all theses lists. (a kind of zip function)</p>&#xA;&#xA;<p><strong>Summary</strong> : I just read <a href=""https://stackoverflow.com/questions/28402376/how-to-compose-observables-to-avoid-the-given-nested-and-dependent-callbacks"">this question about Observables composition</a>. My question is can be summarize with ""Do you use the same strategy when you don't have a unique user at the start of the chain but hundreds of users ?"" (the performance can be a problem no ?)</p>&#xA;"
33179127,What are the most common ways to Architect the verification process of the access tokens between resource and authentication server using OAUTH 2.0?,2015-10-16 20:34:28,<web-applications><oauth><oauth-2.0><google-oauth><microservices>,2,122,0,0.0,0,"<p>What are the most common ways to Architect the verification process of the access tokens between resource server and authentication server using OAUTH 2.0?</p>&#xA;&#xA;<p>I am trying to build a web application broken down into bunch of micro services and each micro service is a resource server. I also have a separate authentication server and I am wondering which of the approaches I tried below is better or if you think you have better idea then it is greatly appreciated or if you think OAUTH is not the right tool for this then please explain.</p>&#xA;&#xA;<p>Here are the ways I tried.</p>&#xA;&#xA;<p>say user (resource owner) goes to my app home page <a href=""http://helloworldhello.com"" rel=""nofollow"">http://helloworldhello.com</a>. This landing page has username and password field so once the user enters these fields I make an ajax call to the authentication server which eventually will give me an access token after the TWO-LEGGED OAUTH FLOW. Now I take the oauth access token and go to the resource server to access the resource. The resource server will now make another http call to the authentication server programmatically to verify the access token once the authentication server says yes then the resource server will serve request towards the completion (This way the resource server is totally isolated with the authentication process)</p>&#xA;&#xA;<p>The other way would be to let the resource server verify the access token by talking to shared database.</p>&#xA;&#xA;<p>which one of these is the more common in the industry? or any other ideas on how to verify the access tokens between authentication server and resource server?</p>&#xA;"
33187526,Header and footer as a service in Dropwizard?,2015-10-17 14:05:51,<web-services><architecture><freemarker><dropwizard><microservices>,2,169,0,0.0,0,"<p>I have a hypothetical web application which is split up into a microservice architecture like (as an example):&#xA;<a href=""https://i.stack.imgur.com/SIEy1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SIEy1.png"" alt=""Distributed application structure""></a></p>&#xA;&#xA;<p>Clients A-C are web applications that serve HTML. Services 1-3 are the backend that handle CRUD and serve JSON. There are other clients (not pictured) that do not access Frontend Service - namely, native clients such as Android and iOS. I'm trying to figure out the best way to serve common frontend content (such as header/footer/css) across all web clients. The best way I can think of doing this is to create a Frontend Service that each web client can access to pull this common information. That way changing the common front end will be reflected in each application immediately without need to update versions, recompile or redeploy.</p>&#xA;&#xA;<p><strong>My question</strong> is what is the best way of doing this? I'm using Dropwizard to serve both the web clients and the services. The web clients serve Dropwizard Views (with freemarker templates) via Jetty. Is there a way to compose Dropwizard Views so that I can request a Header and a Footer view from Frontend Service and wrap these around each view returned from the Clients? Or am I going about this completely wrong? I know that Freemarker supports template inheritance but as far as I can tell this means the header/footer would have to live in each client or be pulled in from a common JAR (which would require updating version numbers and recompiling).</p>&#xA;"
33180090,Spring security Post Requests,2015-10-16 21:50:29,<spring><spring-security><microservices>,1,1204,0,0.0,0,"<p>Im following this guide <code>https://spring.io/guides/gs/securing-web/guide</code> to set up spring security for my microservice</p>&#xA;&#xA;<p>Im just sending basic POST and GET requests. I can do GET requests but when I try for POST requests I get a 403 error.(""Expected CSRF token not found. Has your session expired?"")&#xA;Im trying to set up basic authentication for my microservice</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
33194778,Keyword Search in microservices based architecture,2015-10-18 05:51:39,<search><solr><microservices>,1,1009,0,2.0,0,<p>I need some advice as to how a search needs to be implemented to search keywords within relational databases owned by microservices.&#xA;I have some microservices with their own relational DB. These microservices are likely to be deployed in a docker container.&#xA;What would be the best way to use a search engine like Apache SOLR so that each of the microservices' database can be indexed and we can achieve keyword search</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;
38461294,How to send JSON as a Input parameter from one Microservice to another using RestTemplate in Spring Boot,2016-07-19 14:24:45,<java><spring-boot><resttemplate><microservices>,3,1356,0,1.0,0,"<p>I want to send <code>JSON</code> as an <code>input</code> from Microservice M1 to a Microservice M2.</p>&#xA;&#xA;<p>M1 and M2 both are on different machines.&#xA;I am new to Spring Boot,</p>&#xA;&#xA;<p>I found some <a href=""https://spring.io/guides/tutorials/bookmarks/"" rel=""nofollow"">code</a> but I am unable to get it.&#xA;Please help.</p>&#xA;"
38265103,MSF4J: Serving static content,2016-07-08 11:04:24,<angularjs><web><mustache><microservices><msf4j>,1,132,0,0.0,0,"<p>Can <a href=""https://github.com/wso2/msf4j"" rel=""nofollow"">MSF4J</a> application serve static content without using the Mustache template engine. I have developed a REST service which will be consumed by an already developed angular web app. Now I need to package the same angular app with the micro service so it will render in the browser and will consume the service via ajax calls. </p>&#xA;"
38440876,Stand up select services with docker-compose,2016-07-18 15:41:52,<deployment><docker><microservices><devops><software-distribution>,2,237,1,0.0,0,"<p>I wanted to create a install script which would stand up certain services based on user input. I am using docker for the managing these services. With docker-compose I am able to define multiple services, but by default all the services defined in docker-compose.yml start. Is there any workaround for this ? Also, is this a terrible strategy [but all my services use docker, so is there an alternate way] ?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
38380827,Microservices Maven Project Structure,2016-07-14 17:43:39,<java><spring><maven><microservices>,2,2112,2,0.0,0,"<p>I am working on a project in which we'll deploy a full Spring Boot microservices architecture, along with supporting services like load balancing, service registry, edge server, and centralized monitoring.</p>&#xA;&#xA;<p>I have a single project that will be shared among all core microservices which contains DAOs and all the dependencies for the core microservices. I am hoping to be able to release one ~60Mb jar, and have the other Spring Boot core microservices be very lightweight (&lt;1Mb). At runtime the core microservices will reference the shared jar on their classpath.</p>&#xA;&#xA;<p>The way I've set the project up is to have separate project, with a structure like so:</p>&#xA;&#xA;<pre><code>|shared_project&#xA;|pom.xml&#xA;&#xA;|ms-1&#xA;|pom.xml&#xA;&#xA;|ms-2&#xA;|pom.xml&#xA;</code></pre>&#xA;&#xA;<p>The shared project uses maven-assembly-plugin to create a big jar and copies it to my local .m2 repo. The ms-1 and ms-2 poms use maven-jar-plugin to create their jars and have one dependency, the shared project. </p>&#xA;&#xA;<p>I'm sure this is not the best way to handle this. It's creating issues during unit tests and I have to imagine it'll create issues down the line. I've seen this done using parents in the pom file, nesting the project inside another directory, and other ways. </p>&#xA;&#xA;<p>What I am wondering is what is the best practice regarding keeping your Spring Boot projects' dependencies and shared code centralized and externalized through use of Maven, such that the projects that you are frequently rolling are kept lightweight and decoupled? </p>&#xA;&#xA;<p>Bonus questions: </p>&#xA;&#xA;<ol>&#xA;<li><p>Does the fact that we'll be using Jenkins/TeamCity for CI and automated testing affect the answer?</p></li>&#xA;<li><p>Does having one shared jar on the filesystem which each project references in its classpath during startup pose any challenges? Depending on demand, we may flexibly spin up 10 instances of microservice-1 and only 3 of microservice-2. </p></li>&#xA;</ol>&#xA;&#xA;<p>EDIT: I think this already has a good answer here: &#xA;<a href=""https://stackoverflow.com/questions/27865238/parent-pom-and-microservices"">Parent pom and microservices</a></p>&#xA;"
38389706,Looking for help on how to manage microservices in Golang,2016-07-15 06:56:33,<go><deployment><microservices>,1,436,2,0.0,0,"<p>Currently, I deal with microservices on a daily basis at my 9-5.  Most everything that I touch is written in PHP, and as only a software engineer, SysOps manages everything that has to do with apps running, etc.  I have a little familiarity in how the infrastructure and build pipeline is setup, but I still am not a SysOps or DevOps guy.  </p>&#xA;&#xA;<p>With that said, I love Golang and for a side project, I am creating a fairly large web application with a lot of moving parts.  Writing and designing the code is easy as I have learned a lot from my day job, but deploying and managing Golang web apps (as they are executables) is quite different than updating files for apache to serve.</p>&#xA;&#xA;<p>I have researched a lot on how I would build and deploy my microservice apps, but I keep on thinking of more problems that will need to be solved along the way.  I have tinkered with the idea of using Docker for all of this, but I would rather not have the added complexity of learning that and managing storage for all of the images as that could be large.</p>&#xA;&#xA;<p>Is there a best practice or a good way to manage Golang applications after they have been deployed?  I would need a way to keep track of all the microservice processes to be able to see if they are still up and to be able to stop them when a new build is going to be deployed.</p>&#xA;&#xA;<p>As for the setup, just assume that all the microservices will be run on the server, not in a container or in a VM.  They will all need to be managed, but also able to act upon independently.  Jenkins will be used for building and deploying. I will be using Consul for service discovery and possibly configuration, and most likely health checks on the services.  I'm thinking of having each microservice register itself to consul when started and deregister when stopping.</p>&#xA;&#xA;<p>Again, I am looking for a solution that is hopefully not just ""Docker"".  I also had thoughts into creating a deploy service that manages the services (add and remove), as well as registering them in Consul.  So if I cannot find a better solution, I might go that path.  Any help is appreciated.</p>&#xA;&#xA;<p>** Sorry if my question was confusing, but since a couple people answered on the wrong topic at hand, I will try to clarify.  I don't need any help making the microservices, or even know anything about them.  I brought that point up as to why I need to ask my question.  Basically what I need is just the ability to manage the running go processes of all my microservices so I can do deployments and be able to stop and start processes to update the code.  It is easier when you have to worry about one app, but when you can have up to 10-15 difference microservices they become harder to keep track of.  After my own research, it seems that Supervisord is what I am looking for, but I'm not sure.  That is the direction I am going in with this question.  Thanks.</p>&#xA;"
38297333,Sharing data among Microservicesâ€,2016-07-10 23:27:59,<rest><design-patterns><enterprise><restful-architecture><microservices>,2,774,4,1.0,0,"<p>I'm seeking an answer to a design question that I didn't find an answer to in any literature on this matter. Allow me to explain the use case, my solution to it and, ask for your opinion as a subject matter expert.</p>&#xA;&#xA;<p><strong>Use Case</strong>:&#xA;We've several Microservices that all return some form of content from different business domains. We're using Spring Cloud Netflix, so a gateway service routes traffic to the content services. Some, if not all, of these services require data that is derived from the request, and is immutable. A trivial example is locale, although there are other proprietary information too.</p>&#xA;&#xA;<p><strong>Solution</strong>:&#xA;I'm currently deriving the shared data in the gateway service and persisting as JSON in a NoSQL database with a unique key. Then I'm adding the key as a request header before routing the request. I've a shared library that the content services include at build time, and includes a Spring bean that reads the key from the request header, fetches the stored data using the key and initializes itself. This makes it possible for the content services to access the shared data (by simply injecting the previously mentioned bean) without knowing the underlying mechanism.&#xA;If a content service invokes another one, it's responsible for adding the unique key as a request header.</p>&#xA;&#xA;<p><strong>Debate</strong>:&#xA;The debate I've with my colleagues is that whether using a shared datastore for this purpose is appropriate. I contend that it is bad for a service to leak it's domain specific data to others, but the data in question isn't domain specific, so there's nothing wrong with having a shared database and passing the key around. The alternative would be to pass all the shared data around which I consider redundant.</p>&#xA;&#xA;<p>What is your thought?</p>&#xA;&#xA;<p><strong>Edit</strong>: I see someone voted to close the question. Unless they can point me to a reference that discusses data sharing among Microservices, such policing is a hindrance to meaningful discussion. Not every question is a boolean yes/no answer, some require deeper thoughts.</p>&#xA;"
38352227,What is the name of this 'intermediary' pattern?,2016-07-13 12:48:52,<java><web-services><design-patterns><microservices>,1,99,5,0.0,0,"<p>I've got an intermediary java web service application application (built using Spark Java - but that is incidental) that takes an http parameter - from it generates a URL - calls the URL and then returns the result to the original caller. </p>&#xA;&#xA;<pre><code>Original Client -&gt; My Application -&gt; Http Web Service Producer&#xA;</code></pre>&#xA;&#xA;<p>This is kind of a MicroServices pattern - but I'm looking for a more specific term. I think it is a 'pipeline', 'solicitor' or a 'mediator'. </p>&#xA;&#xA;<p>My question is: <strong>What is the name of this 'intermediary' pattern?</strong></p>&#xA;"
38397672,Multiple database management,2016-07-15 13:44:30,<mongodb><haxe><microservices>,1,174,6,0.0,0,"<p>I'm currently working on a multiplayer game which will be using two databases(MONGODB). One for authentication(login) and one to contain all game-specific data.&#xA;What I've done is to separate the user and game specific data. This way i'll be able to build micro services around the user in the future.</p>&#xA;&#xA;<p>I'm a bit uncertain on how to handle/validate the game-specific database operations tho.&#xA;When i log into my game, i perform a POST request to my rest api, which validates the user and returns some data.</p>&#xA;&#xA;<p>The game itself however, is using a TCP socket connection to handle real-time gameplay and will be saving game-specific data to the database on the authoritative server(all game logic is done on the server) . How would you go about to link the data on the game-specific database to a specific user found in the authentication database?</p>&#xA;"
39866282,How to access User-Provided environment variables in cloud foundry?,2016-10-05 05:48:34,<deployment><environment-variables><cloud><cloudfoundry><microservices>,1,807,0,0.0,0,"<p>I'm aware of setting environment variables in <code>manifest.yml</code> by doing following</p>&#xA;&#xA;<pre><code>--- &#xA;- applications:&#xA;  - name:&#xA;    .&#xA;    .&#xA;    env:&#xA;      MY_ENV_VAR: 'my-var-value'&#xA;</code></pre>&#xA;&#xA;<p>How do I access <code>MY_ENV_VAR</code> in my program (python for example) ?</p>&#xA;&#xA;<p>Additionally, I only want to access this variable in cloud foundry environment. While doing local development, I would like to use some hard-coded value, how do I separate these two scenarios (python example again) ?</p>&#xA;"
39916051,Sharing of a view among microservies,2016-10-07 11:24:30,<spring><jsp><spring-mvc><spring-boot><microservices>,1,107,0,0.0,0,"<p>I'm splitting up a monolith web service into several microservices using spring boot. To reduce duplicated code I extracted shared parts in a maven module that is used in the different microservices.</p>&#xA;&#xA;<p>The monolith application had a healthcheck page that showed various information about the state of the service and some debbuging infos. It is implemented with Spring MVC and jsp.</p>&#xA;&#xA;<p>I'd like to use this view in each of the microservices. Whats the best way to do this without duplicating the view/controller?</p>&#xA;&#xA;<p>I was thinking of adding a web module to the shared maven project that contains the controller, view, spring mvc settings,...&#xA;But I'm not sure if it is good to have two web modules in one microservice.</p>&#xA;"
40044128,Fetch Configuration from Spring Cloud Config over SSL,2016-10-14 13:14:30,<java><ssl><spring-boot><microservices><spring-cloud-config>,2,1658,0,0.0,0,"<p>I am building microservices using Spring Boot where configuration is distributed using Spring Cloud Config. Config application has SSL enabled.</p>&#xA;&#xA;<p>I want my spring boot application to communicate to Config server over https. Problem is that before loading SSL configuration from bootstrap.yml, application initiates a rest call to Config Server to fetch the configuration and fails miserably with error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""https://host:8888/abcd/development,production"": sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; nested exception is javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: &#xA;</code></pre>&#xA;&#xA;<p>I have configured a truststore with CA certificate in bootstrap.yml:</p>&#xA;&#xA;<pre><code># MicroServices Properties&#xA;spring:&#xA;  application:&#xA;     name: abcd&#xA;  profiles:&#xA;    active: development,production&#xA;  cloud:&#xA;    config:&#xA;      uri: https://&lt;host&gt;:8888 &#xA;      fail-fast: true&#xA;      password: abc@123&#xA;      username: user&#xA;server:&#xA;  ssl:&#xA;    trust-store: D:/Certs/caCert/server.p12&#xA;    trust-store-password: keystore&#xA;    key-store-provider: PKCS12&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions what should I do to create successful SSL communication with Config Server?</p>&#xA;"
39990666,Immutable database to huge write volume,2016-10-12 04:43:48,<database><cqrs><microservices><event-sourcing><datomic>,2,129,0,0.0,0,"<p>I'm building a application that need to be created using an immutable database, I know about Datomic, but's not <a href=""http://www.datomic.com/faq.html"" rel=""nofollow"">recommended</a> to huge data volume (my application will have thousands, or more, writes per second).</p>&#xA;&#xA;<p>I already did some search about it and I could't find any similar database that do not have this ""issue"".</p>&#xA;&#xA;<p>My application will use event sourcing and microservices pattern.</p>&#xA;&#xA;<p>Any suggestions about what database should I use?</p>&#xA;"
39941660,Which could be the best way for communication of Micro-services without any HARD-CODE,2016-10-09 08:43:40,<spring-boot><microservices><netflix-eureka>,2,153,0,2.0,0,"<p>I having a bunch of microservices which communicates with each other using <code>RestTemplate</code>. All the communication of microservices is from API gateway.</p>&#xA;&#xA;<p>I am doing as following,</p>&#xA;&#xA;<pre><code>    public List&lt;ServiceInstance&gt; serviceInstancesByApplicationName(String applicationName) {&#xA;            return this.discoveryClient.getInstances(applicationName);&#xA;        }&#xA;&#xA;    //some Other logic &#xA;&#xA;    List&lt;ServiceInstance&gt; apigatewaymsInstanceList = discoveryClient.getInstances(apigatewaymsName);&#xA;            ServiceInstance apigatewaymsInstance = apigatewaymsInstanceList.get(0);&#xA;&#xA;    //and&#xA;&#xA;    restTemplate.exchange(apigatewaymsInstance.getUri().toString() + plmpayloadprocessmsResource, HttpMethod.POST,&#xA;                                entity, String.class);&#xA;</code></pre>&#xA;&#xA;<p>But here it appears like a hard code. Is there some another approach I am missing? What could be the best way ?</p>&#xA;&#xA;<p>Likewise, I am asking is there any method available so that I can pass the name of application and eureka return me its full URI no need to do <code>applicationgetInstaceId(0);</code></p>&#xA;"
39982623,Wildfly Swarm start browser on mvn run,2016-10-11 16:55:50,<maven><microservices><wildfly-swarm>,1,158,0,0.0,0,<p>Is there any possibility to open a browser with a tab to localhost:8080/index.html when running mvn wildfly-swarm:run?</p>&#xA;&#xA;<p>I would appreciate your answer!</p>&#xA;
39876079,JHipster - Doubts in the development using Microservices Architecture,2016-10-05 14:01:25,<docker-compose><jhipster><microservices>,1,189,0,0.0,0,"<p>I'm trying to build a microservice system using JHipster platform, but I am having some problems.</p>&#xA;&#xA;<p>1Âº The Eureka Service Discovery is UNKNOWN in registry screen and I have no idea where I can fix this...</p>&#xA;&#xA;<p>2Âº I am using docker-compose to up all the application and it would be great to use BrowserSync in development, but the application is inside a docker container and the changes I made in the code does not appear on screen even after refresh action is executed (It is necessary build the changes, stop docker-compose and start again).</p>&#xA;&#xA;<p>My doubts are the same as this post on Stackoverflow:</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/38955146/jhipster-application-development-with-docker-and-gulp"">Jhipster application development with Docker and gulp</a></p>&#xA;&#xA;<p>But this solution not worked for me.</p>&#xA;&#xA;<p>I'll be very greatful with your help!</p>&#xA;&#xA;<p>Best regards,</p>&#xA;&#xA;<p>Vinicius Carvalho.</p>&#xA;"
40036030,"""eurekaHealthIndicator"" issue with netflix eureka client",2016-10-14 06:07:19,<spring-cloud><microservices><netflix-eureka><spring-cloud-netflix>,2,331,2,0.0,0,"<p>Trying to write  Eureka Client With Spring Cloud Netflix v1.2.0.Release&#xA; but facing the below mentioned issue. PFB code and configurations.</p>&#xA;&#xA;<p>EurekaClient.java</p>&#xA;&#xA;<pre><code>import org.springframework.boot.autoconfigure.EnableAutoConfiguration;&#xA;import org.springframework.boot.builder.SpringApplicationBuilder;&#xA;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;&#xA;import org.springframework.context.annotation.ComponentScan;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;&#xA;    @Configuration&#xA;    @EnableAutoConfiguration&#xA;    @EnableEurekaClient&#xA;    @RestController&#xA;    @ComponentScan(basePackages={""com.west.eas.netflix.config""})&#xA;    public class EurekaClient {&#xA;&#xA;        @RequestMapping(""/"")&#xA;          public String home() {&#xA;            return ""Hello World"";&#xA;          }&#xA;&#xA;          public static void main(String[] args) {&#xA;              new SpringApplicationBuilder(EurekaClient.class).run(args);&#xA;          }&#xA;&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<pre><code>server:  &#xA;  port: 9000&#xA;&#xA;spring:  &#xA;  application:&#xA;    name: eas-eureka-client&#xA;&#xA;eureka:  &#xA;  client:&#xA;    healthcheck:&#xA;      enabled: true&#xA;    serviceUrl:&#xA;      defaultZone: http://localhost:8761/eureka/&#xA;  instance:&#xA;    preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>bootstrap.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: eu-client&#xA;  cloud:&#xA;    config:&#xA;      uri: http://localhost:8888&#xA;encrypt:&#xA;  failOnError: false&#xA;</code></pre>&#xA;&#xA;<p>Client fails to start with following error</p>&#xA;&#xA;<blockquote>&#xA;  <p>"" Parameter 0 of method eurekaHealthIndicator in&#xA;  org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration$EurekaHealthIndicatorConfiguration&#xA;  required a bean of type 'com.netflix.discovery.EurekaClient' that&#xA;  could not be found.""</p>&#xA;</blockquote>&#xA;&#xA;<p>the below screenshot will have more details on error stack</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/YGbHU.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/YGbHU.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I even tried setting healthcheck enable to false in application.yml but it still wont work. Any Help would be appreciated.</p>&#xA;&#xA;<p>Regards</p>&#xA;"
40082248,Handle message dependency when using evening environment(MessageMQ),2016-10-17 09:00:38,<spring-boot><rabbitmq><message><microservices>,1,28,3,0.0,0,"<p>I am developing a micro service platform using Spring technologies. I am facing some problem when consuming message from Rabbit MQ.</p>&#xA;&#xA;<p>Scenario:</p>&#xA;&#xA;<p>I have two message queue, <strong>student</strong> and <strong>enrollment</strong>. In my one microservice I put the student and enrollment creation request to message queue. </p>&#xA;&#xA;<p>But, since the message queue order not guaranteed, enrollment message comes <strong>before</strong> the students come. &#xA;On that time my relation database fail. </p>&#xA;&#xA;<p>What is the best way to handle this kind of scenario(message ordring) when using message mq in microservice platform? </p>&#xA;"
39932500,Microservices with Spring-Boot and Release Management,2016-10-08 12:43:10,<spring-boot><microservices><spring-boot-maven-plugin>,1,485,5,1.0,0,"<p>Looking for advice in how to do release management of microservices built with Spring Boot. </p>&#xA;&#xA;<p>Most projects I've worked use the release plugin (maven) to create tags as well as to release maven projects (jar, war, rpm). Usually, this relies on the maven parent/child relationship for all sub-projects (jars, wars) during the release process (monolith source code, all living in a single git repository). I'm wondering how do people maintain different boot projects (microservices) and make releases.  </p>&#xA;&#xA;<p>The way I see it, the following are possible strategies:</p>&#xA;&#xA;<ol>&#xA;<li>One Spring Boot project (microservice maven project) per git repository so that releases are managed independently. </li>&#xA;<li>A Multi-Module maven project with each module being a microservice. All submodules (microservices) will have to be released together. The parent pom will have to use a Boot's parent pom. </li>&#xA;<li>Rely on the maven-release-plugin ability to release only certain sub-modules based on a release. This will make each maven sub-module have different versions (potentially).</li>&#xA;</ol>&#xA;&#xA;<p>What has your team found useful? I like Boot's programming model, but I'm hopeful I can use a release strategy that is consistent with Boot model of keeping things simple.</p>&#xA;"
29731394,dependency management on micro services architecture,2015-04-19 14:46:29,<git><dependencies><microservices>,2,836,0,0.0,0,"<p>I build an app based on the micro services architecture, i have now two services with some common code to both.</p>&#xA;&#xA;<p>What is the conventional way to do that? (different projects, modules etc)&#xA;I would also like a refernece on how to handle them in a git repository (for all? for each?)</p>&#xA;"
29821391,Spring @RequestMapping redirect to same path with additional info,2015-04-23 10:57:01,<java><spring><spring-mvc><spring-boot><microservices>,2,861,3,0.0,0,"<p>A somewhat unusual scenario perhaps, but we need to redirect in a Spring MVC controller from:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html&#xA;</code></pre>&#xA;&#xA;<p>to:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html#/some_path/&#xA;</code></pre>&#xA;&#xA;<p>All my attempted solutions to date have resulted in a redirect loop, as Spring performs the redirect but is then repeatedly matching /browser.html in the redirect URL, regardless of the additional info.  What I need to say is 'match /browser.html ONLY if it's the end of the path'.</p>&#xA;&#xA;<p>I have tried <code>setUseSuffixPatternMatch(Boolean.FALSE);</code> on the <code>PathMatchConfigurer</code> to no avail, also tried the following URI template regex pattern in the request mapping itself:</p>&#xA;&#xA;<pre><code>""/js/hal-browser/{file:browser\\.html$}""&#xA;</code></pre>&#xA;&#xA;<p>..but still get a redirect loop. Ideas appreciated - this is Spring 4.1.6 in a SpringBoot 1.2.3 microservice, by way of context.</p>&#xA;&#xA;<p><strong>Update:</strong>&#xA;On further investigation and a better understanding of the URL fragment in use by the HAL browser to determine which path it will make a request to within the microservice itself, I believe the solution may lie not in trying to redirect off <code>browser.html</code>, as Spring will map this to the same controller method on every request regardless of the fragment value, but instead either reverting to the default context path for the application (<code>/</code>), which the HAL browser has set as its default entry point, or finding a way to configure the embedded tomcat container to respond with something sensible (not just a 404) on the default context path even though the app is mapped to /some_path.</p>&#xA;&#xA;<p>As further context, we can redirect no problem at all from a convenience path of <code>/browser</code> (or whatever) into the HAL browser with the correct entry point fragment as the context path of the service - that works fine. The issue is the browser itself has a 'Go to entry point' button which, when pulling it in as a <a href=""https://github.com/Product-Foundry/hal-browser-webjar"" rel=""nofollow"">webjar</a>, is hardcoded to <code>/</code>. The other alternative is to ditch the webjar and just copy in the static files for the browser and update the entry point.</p>&#xA;"
29610354,Discovery pattern for REST API endpoint,2015-04-13 16:27:09,<java><node.js><rest><microservices>,1,674,3,0.0,0,"<p>I m actually studying Microservice architecture pattern and it seems that the API Gateway pattern uses the Discovery pattern, but with REST API endpoints.</p>&#xA;&#xA;<p>Can anybody explain me how it works for example if my API Gateway is NodeJS based and my REST APIs are Java written ?</p>&#xA;&#xA;<p>I dont really know how can I implement this pattern and I dont find any code or schema to help me understand a bit more.</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
44432985,Deploying Service fabric project on azure cluster,2017-06-08 10:19:05,<azure><http><port><microservices><azure-service-fabric>,1,30,0,0.0,0,<p>I have created  a project with 2 microservices and had made then listen on two different ports but when i deploy them on Azure Cluster(remote) Only one microservice work which is at port 19080 </p>&#xA;
44361901,Redelivery of JMS message in microserices,2017-06-05 04:55:51,<microservices><spring-jms>,1,33,0,0.0,0,"<p>I want to know the redelivery of JMS in a microservices.</p>&#xA;&#xA;<p>For example, if I have a microservices system. And I have 2 instances of User service. And have a listener on a destination in user service. It means I have 2 listeners. The listener is like this:</p>&#xA;&#xA;<pre><code>@JmsListener(destination = ""order:new"", containerFactory = ""orderFactory"")&#xA;@Transactional&#xA;public void create(OrderDTO orderDTO) {&#xA;    Order order = new Order(orderDTO);&#xA;    orderRepository.save(order);&#xA;    jmsTemplate.convertAndSend(""order:need_to_pay"", order);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So my question is, how many times a message will be delivered. And if there is some error in this function, and the message will be re-delivered. But I have 2 instances of the service. And on which this message will be delivered?</p>&#xA;"
44394119,monolithic or microservice concept,2017-06-06 15:30:08,<django><microservices>,2,610,0,0.0,0,"<p>I have a very large django project with many features that uses django as backend framework. My project lets users use both a website and a iOS app.</p>&#xA;&#xA;<p>I am researching using a monolithic app (currently using monolithic) vs micro services, I watched this <a href=""https://www.youtube.com/watch?v=OuhCYGLByJg"" rel=""nofollow noreferrer"">video</a> but one part really throws me off. At 1:05, he previews his 'monolithic' app before he changes to micro services, which to me looks like a single project with a bunch of different apps. </p>&#xA;&#xA;<p>1) Are these technically just folders and not apps? These (what i would assume he calls folders) all have a models.py and views.py and most have a admin.py.</p>&#xA;&#xA;<p>2) What makes this a monolithic app? Is it just because he doesn't simply use django-admin startapp in the terminal to create these 'folders'?</p>&#xA;&#xA;<p>3) Or are microservices multiple projects connected and not simply multiple apps in a single project?</p>&#xA;&#xA;<p>My biggest confusion is with the previewed project in the video because before then I thought I had a good grasp on these concepts. I was simply looking to change to microservices, after this part in the video I'm not sure I even know what a monolithic app really is.</p>&#xA;"
44404941,Service fabric more than one communication listener for service remoting,2017-06-07 06:19:34,<azure><microservices><azure-service-fabric>,1,375,0,0.0,0,"<p>I am developing few micro services using Azure Service Fabric. I have some use cases which need the communication between micro services and I read about service remoting <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-communication-remoting"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-communication-remoting</a>. I just wanted to know is it possible to support more than one listeners in a SF application. E.g. I have an existing stateless web api SF application which is having a listener like below</p>&#xA;&#xA;<pre><code>protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;    {&#xA;        return new ServiceInstanceListener[]&#xA;        {&#xA;            new ServiceInstanceListener(serviceContext =&gt; new OwinCommunicationListener(Startup.ConfigureApp, serviceContext, ServiceEventSource.Current, ""ServiceEndpoint""))&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>To the above list, I need to add a ServiceRemotingListener so that I can expose some data from Micro service for others. Is it possible or anything wrong with approach. I have done the Reverse proxy based communication, but bit concerned with the performance(since I am planning to perform a real time read operation from Service 1 to Service 2).</p>&#xA;"
44216244,Best option for running java web service (rest based) (JRE/JDK vs Server JRE),2017-05-27 11:22:27,<java><deployment><microservices>,1,178,0,0.0,0,"<p>I was stumble upon two options while deploying java web service (rest api built using spring-boot and family).</p>&#xA;&#xA;<ol>&#xA;<li>install JRE/JDK and use -server argument for starting up service&#xA;<code>java -server -classpath lib\*.jar -Denv=staging com.acme.pos.application.Application</code></li>&#xA;<li>install server JRE from <a href=""http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.html"" rel=""nofollow noreferrer"">http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.html</a> and use above java command</li>&#xA;</ol>&#xA;&#xA;<p>Can someone please answer this with the best practices perspective?</p>&#xA;"
44435017,How to make two microservices listen on same port in azure service fabric,2017-06-08 11:51:04,<azure><visual-studio-2015><port><microservices><azure-service-fabric>,2,181,0,0.0,0,<p>I have created a project with two microservices and want both of them to listen to same port.&#xA;I have two separate ServiceManifest File in which i have defined same endpoint for both of them but when i deploy it locally or remotely it doesn't work.</p>&#xA;&#xA;<p>When I deploy it locally it shows following Exception:&#xA;Exception thrown: 'System.Reflection.TargetInvocationException' in mscorlib.dll</p>&#xA;
44414323,Testing containerized microservice with external dependency,2017-06-07 13:38:56,<rest><unit-testing><docker><microservices><external-dependencies>,1,48,2,0.0,0,"<p>So I built a REST API microservice which queries a local Elasticsearch instance and translates the results according to an internal protocol. I built it into a Docker image and I would like to run some unit tests on it in build. Being ES connected to a private Docker network, it isn't reachable by the microservice during build, so the tests obviously fail. I was wondering, is there a way around this situation without having to use some complicated testing framework to do dependency injection? How do you test this kind of containers in your work practice?</p>&#xA;"
44343697,Use both WCF service and Web Api in same Service fabric reliable services,2017-06-03 12:00:25,<wcf><azure><asp.net-web-api><microservices><azure-service-fabric>,1,111,2,0.0,0,"<p>I haven't had much luck finding a way of using the WCFCommunicationListener as well as HttpListner(OwinCommunicationListner) inside same Reliable service. I Want to use two different listeners one that provide the Soap functionality that I can achieve using WCFCommunicationListener and other will simple Web Api consumption that what pretty much OwinCommunicationListner provides. I don't want to use the WcfCommunicationListener for my REST functionalities, I want to consume my REST apis as Web Api. </p>&#xA;"
44265295,Caching layer for different microservices,2017-05-30 14:40:03,<caching><design><varnish><microservices><vert.x>,1,447,3,0.0,0,"<p>We have different microservices which makes duplicate calls to internal and external services. We need to cache these calls between services to improve latency. We are thinking of introducing an API gateway whose major aim would be caching the data between services. &#xA;Some other objectives are -</p>&#xA;&#xA;<p>i) Would be calling different micro-services to aggregate their response.</p>&#xA;&#xA;<p>ii) Would also be avoiding multiple calls to external services across micro services.</p>&#xA;&#xA;<p>iii) Would be taking care of cache miss &amp; hit for external API calls.</p>&#xA;&#xA;<p>iv) High throughput, performance and low latency.</p>&#xA;&#xA;<p>We have vert.x based tech stack.&#xA;What would be the best way to implement such a system. I had following questions -</p>&#xA;&#xA;<p>1) Implement it as a library or a service ?</p>&#xA;&#xA;<p>2) Which data store to be used ( we are considering Redis/Hazelcast) ?</p>&#xA;&#xA;<p>3) Can libraries such as Varnish/Squid/Nginx help here ?</p>&#xA;&#xA;<p>4) How to handle cache invalidation ?</p>&#xA;"
38858550,microservices and bounded contexts,2016-08-09 19:04:09,<domain-driven-design><microservices><consistency>,1,345,0,0.0,0,"<p>For the sake of question, let's say i have 2 microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Identity management</li>&#xA;<li>Accounting</li>&#xA;</ul>&#xA;&#xA;<p>I know that each microservice should not be tightly coupled and it should have it's own database.</p>&#xA;&#xA;<p>Let's say that accounting has invoices and each invoice has issuing agent. &#xA;Agent from accounting also exists as User in Identity microservice.</p>&#xA;&#xA;<p>If i understood well, data from identity management (users), should be copied to accounting (agents), and should copy only data which are needed for that bounded context (first and last name), so the invoice can have proper <code>issuingAgentId</code>.</p>&#xA;&#xA;<p>Is this correct way to keep data consistent and shared between contexts?&#xA;Each time when user is created in identity microservice, event ""UserCreated"" will be published and accounting or any other service interested in this event should listen and process it by adding corresponding agent?&#xA;Same goes for updating user information.</p>&#xA;"
38737317,Spring Cloud Stream conflicts with Hystrix,2016-08-03 07:39:20,<java><amqp><microservices><hystrix><spring-cloud-stream>,1,120,0,0.0,0,"<p>I have a <em>RestController</em> with <em>Hystrix</em> and <em>Spring Cloud Stream</em> channels:</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(value = ""/api/products"")&#xA;@EnableBinding(ProductProcessor.class)&#xA;public class ProductUiController {&#xA;&#xA;    /*******&#xA;     * LISTENERS&#xA;     *******/&#xA;    private List&lt;Product&gt; listenAllProducts;&#xA;    private Product listenProduct;&#xA;&#xA;    /*******&#xA;     * CHANNELS&#xA;     *******/&#xA;    @Autowired&#xA;    @Qualifier(ProductProcessor.OUTPUT_DELETE)&#xA;    private MessageChannel channel_delete;&#xA;    @Autowired&#xA;    @Qualifier(ProductProcessor.OUTPUT_CREATE)&#xA;    private MessageChannel channel_create;&#xA;    @Autowired&#xA;    @Qualifier(ProductProcessor.OUTPUT_UPDATE)&#xA;    private MessageChannel channel_update;&#xA;&#xA;    Logger logger = Logger.getLogger(ProductUiController.class);&#xA;&#xA;&#xA;    @Autowired&#xA;    RabbitTemplate rabbitTemplate;&#xA;&#xA;    @Autowired&#xA;    RabbitAdmin rabbitAdmin;&#xA;&#xA;    @Autowired&#xA;    private LoadBalancerClient loadBalancer;&#xA;&#xA;    /**&#xA;     * returns all the products in the database&#xA;     *&#xA;     * @return&#xA;     */&#xA;    @RequestMapping(method = RequestMethod.GET)&#xA;    @HystrixCommand(fallbackMethod = ""getAllProductsFallback"")&#xA;    public List&lt;Product&gt; getAllProducts() {&#xA;        try {&#xA;            ServiceInstance instance = loadBalancer.choose(""product-service"");&#xA;            URI uri = instance.getUri();&#xA;            URL obj = new URL(uri.toString() + ""/products"");&#xA;&#xA;            HttpURLConnection con = (HttpURLConnection) obj.openConnection();&#xA;            con.getResponseCode();&#xA;&#xA;        } catch (MalformedURLException e) {&#xA;            logger.error(e.getMessage());&#xA;        } catch (IOException e) {&#xA;            logger.error(e.getMessage());&#xA;        }&#xA;        return this.listenAllProducts;&#xA;    }&#xA;&#xA;    /**&#xA;     * Returns a specific product from product-service&#xA;     *&#xA;     * @param id&#xA;     * @return&#xA;     */&#xA;    @RequestMapping(value = ""/{id}"", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;    public Product getProduct(@PathVariable(""id"") Long id) {&#xA;        try {&#xA;            ServiceInstance instance = loadBalancer.choose(""product-service"");&#xA;            URI uri = instance.getUri();&#xA;&#xA;            URL obj = new URL(uri.toString() + ""/products/"" + id);&#xA;&#xA;            HttpURLConnection con = (HttpURLConnection) obj.openConnection();&#xA;            con.setRequestMethod(""GET"");&#xA;            con.getResponseCode();&#xA;        } catch (MalformedURLException e) {&#xA;            logger.error(e.getMessage());&#xA;        } catch (IOException e) {&#xA;            logger.error(e.getMessage());&#xA;        }&#xA;        System.out.println(""RETURNED PRODUCT = "" + listenProduct);&#xA;        return listenProduct;&#xA;    }&#xA;&#xA;    @HystrixCommand(fallbackMethod = ""addProductFallback"")&#xA;    @RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE)&#xA;    public Product addProduct(@RequestBody Product product) {&#xA;&#xA;        logger.info(""SENT VIA OUTPUT_CREATE: "" + product);&#xA;        channel_create.send(MessageBuilder.withPayload(product).build());&#xA;&#xA;        return product;&#xA;    }&#xA;&#xA;&#xA;    @HystrixCommand(fallbackMethod = ""removeProductFallback"")&#xA;    @RequestMapping(method = RequestMethod.DELETE)&#xA;    public void removeProduct(@RequestParam(""id"") Long id) {&#xA;&#xA;        logger.info(""SENT VIA OUTPUT_DELETE: "" + id);&#xA;        this.channel_delete.send(MessageBuilder.withPayload(id).build());&#xA;    }&#xA;&#xA;&#xA;    /**************************************/&#xA;    /**********LISTENERS*******************/&#xA;    /**************************************/&#xA;&#xA;    /**&#xA;     * Receiver for all products&#xA;     *&#xA;     * @param products&#xA;     */&#xA;    @StreamListener(ProductProcessor.INPUT_GETALL)&#xA;    public void listenerGetAllProducts(List&lt;Product&gt; products) {&#xA;        logger.info(""RECEIVED FROM INPUT_GETALL: "" + products);&#xA;        listenAllProducts = products;&#xA;    }&#xA;&#xA;    /**&#xA;     * Receiver for product&#xA;     *&#xA;     * @param product&#xA;     */&#xA;    @StreamListener(ProductProcessor.INPUT_GET)&#xA;    public void listenerGetProduct(Product product) {&#xA;        logger.info(""RECEIVED FROM INPUT_GET: "" + product);&#xA;        listenProduct = product;&#xA;    }&#xA;&#xA;&#xA;    /**************************************/&#xA;    /**********FALLBACK METHODS************/&#xA;    /**************************************/&#xA;&#xA;    /**&#xA;     * Fallback method for getAllProducts&#xA;     *&#xA;     * @return&#xA;     */&#xA;    public List&lt;Product&gt; getAllProductsFallback(Throwable e) {&#xA;        logger.info(""getAllProductsFallback"");&#xA;        return listenAllProducts;&#xA;    }&#xA;&#xA;    /**&#xA;     * Fallback method for addProduct&#xA;     *&#xA;     * @param product&#xA;     * @return&#xA;     */&#xA;    Product addProductFallback(Product product) {&#xA;        logger.info(""addProductFallback"");&#xA;        return null;&#xA;    }&#xA;&#xA;    /**&#xA;     * Fallback method for delete&#xA;     *&#xA;     * @param id&#xA;     */&#xA;    void removeProductFallback(Long id) {&#xA;        logger.info(""removeProductFallback"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In the implementation <em>HystrixCommand</em> makes a <em>getDeclaredMethod</em> to <em>ProductUiController</em> to find the fallback methods but <em>@EnableBinding</em> hides class methods from reflection, any clue of a workaround?</p>&#xA;"
38863716,Update in Lagom via REST API,2016-08-10 03:24:42,<microservices><lagom>,1,199,0,1.0,0,"<p>I have went through 2 examples of using Lagom to develop Micro-Service Architecture system, namely the 'chirp' and 'cargotracker', but none of them show how to update to existing entity.</p>&#xA;&#xA;<p>For instance, having following entity with REST URI</p>&#xA;&#xA;<p>Sugguestion{&#xA;   id&#xA;   content&#xA;   viewCount&#xA;   author&#xA;}</p>&#xA;&#xA;<pre><code>api/suggestion      with  Http Post      ----&gt; add a new suggestion&#xA;api/suggestion/:id  with Http Get,       ----&gt;read a suggestion&#xA;api/suggestion/:id  with Http Delete,   ----&gt;remove a suggestion&#xA;</code></pre>&#xA;&#xA;<p>How about update ?</p>&#xA;&#xA;<p>1)api/suggestion/viewCount with Http Put?</p>&#xA;&#xA;<p>2)api/suggestion/:id with Http Put ?</p>&#xA;&#xA;<p>3)api/suggestion/:id with Http Post ?</p>&#xA;&#xA;<p>There are some disadvantages of the above 3 approch</p>&#xA;&#xA;<p>for 1), need to define a seperately data class for each fields, otherwise, update directly on the Suggestion entity would introduce 'mutable changes', which is aginst the principle of Lagom.</p>&#xA;&#xA;<p>for 2)&amp;3), need a deep copy of the old state and update with changed fields, otherwise, introduces 'mutable changes' as well.</p>&#xA;&#xA;<p>Is there any other options ?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
38812779,Database design for microservices,2016-08-07 09:32:08,<database><database-design><cassandra><network-programming><microservices>,1,512,1,0.0,0,<p>I am building a back end for a web application which will be based on microservices architecture. Each microservice will be responsible for managing tasks related to a specific module only and will have its own local database.There can be more than one microservice for one module.For example </p>&#xA;&#xA;<p>A customer module will have its own microservice and the microservice will have local database to persist the customer data.&#xA;A order module will like wise have its own local database to persist order records.</p>&#xA;&#xA;<p>I am thinking of managing data persistance using event driven architecture but I want to know if there is some database which can be useful for this implementation ( Cassandra maybe ? )</p>&#xA;&#xA;<p>I am open to any suggestions :)</p>&#xA;
38872460,How to share a host directory between multiple docker container?,2016-08-10 11:41:31,<node.js><docker><dockerfile><microservices>,3,294,1,0.0,0,"<p>This is my directory structure <a href=""http://i.stack.imgur.com/yaANi.png"" rel=""nofollow"">for docker microservices </a>. What I need to do  is to share certain files from my lib folder which is on my host machine to containers. These are lib files which are required to run the application in both of the containers.This is the content from one of my docker file inside one of the container propinfo-finder</p>&#xA;&#xA;<pre><code>FROM alpine:3.3&#xA;&#xA;RUN apk add --update nodejs&#xA;&#xA;RUN mkdir -p /usr/src/app&#xA;WORKDIR /usr/src/app&#xA;&#xA;COPY . /usr/src/app&#xA;RUN npm install&#xA;&#xA;EXPOSE 3000&#xA;&#xA;WORKDIR /usr/src/app&#xA;CMD node index.js&#xA;</code></pre>&#xA;&#xA;<p>I build the docker images using this command <code>docker build -t nodeapp/premcal .</code> The build process is successful . Then i use this command to map/mount the directory <code>bin</code> to the container to make it run&#xA;from the parent directory where bin folder is located </p>&#xA;&#xA;<p><code>docker run -v $PWD/lib:/usr/src/app -p 3010:3000 -i nodeapp/premcal&#xA;</code>&#xA;after running it I am getting this error </p>&#xA;&#xA;<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">&#xD;&#xA;<div class=""snippet-code"">&#xD;&#xA;<pre class=""snippet-code-html lang-html prettyprint-override""><code>module.js:328&#xD;&#xA;    throw err;&#xD;&#xA;    ^&#xD;&#xA;&#xD;&#xA;Error: Cannot find module '/usr/src/app/index.js'&#xD;&#xA;    at Function.Module._resolveFilename (module.js:326:15)&#xD;&#xA;    at Function.Module._load (module.js:277:25)&#xD;&#xA;    at Function.Module.runMain (module.js:442:10)&#xD;&#xA;    at startup (node.js:136:18)&#xD;&#xA;    at node.js:966:3</code></pre>&#xD;&#xA;</div>&#xD;&#xA;</div>&#xD;&#xA;</p>&#xA;&#xA;<p>The host is a physical Ubuntu machine . </p>&#xA;&#xA;<p>can anybody please tell me how to make this go away . All I have is 2 hrs of experience with node.js and docker environment . &#xA;Thank you .</p>&#xA;"
38739188,Docker Compose not starting,2016-08-03 09:09:06,<docker><docker-compose><dockerfile><microservices>,1,98,1,0.0,0,"<p>My <code>docker-compose.yml</code> file contains</p>&#xA;&#xA;<pre><code>version: '2'&#xA; services:&#xA;   config-server:&#xA;     image: config-server&#xA;   registration-server:&#xA;     image: registration-server&#xA;     ports:&#xA;       - 1111:1111&#xA;</code></pre>&#xA;&#xA;<p>Config server Docker file is </p>&#xA;&#xA;<pre><code>FROM java:8-jre&#xA;MAINTAINER ccc &lt;cccc.@vv.com&gt;&#xA;&#xA;ADD ./target/config-server.jar /app/&#xA;CMD [""java"", ""-Xmx200m"", ""-jar"", ""/app/config-server.jar""]&#xA;&#xA;EXPOSE 1116&#xA;</code></pre>&#xA;&#xA;<p>and my registration server Dockerfile is </p>&#xA;&#xA;<pre><code>FROM java:8-jre&#xA;MAINTAINER ccc &lt;cccs.@gg.com&gt;&#xA;&#xA;ADD ./target/registration-server.jar /app/&#xA;CMD [""java"", ""-Xmx200m"", ""-jar"", ""/app/registration-server.jar""]&#xA;&#xA;EXPOSE 1111&#xA;</code></pre>&#xA;&#xA;<p>While I am starting this Docker Compose it's showing </p>&#xA;&#xA;<pre><code>Creating registration-server&#xA;creating config-server&#xA;</code></pre>&#xA;&#xA;<p>After that it's not showing when I am checking in Docker. However, while typing <code>docker ps -a</code> it shows status <code>exited(0)</code>.</p>&#xA;"
38764797,Get AccessToken from spring cloud zuul API Gateway,2016-08-04 10:26:02,<wso2is><spring-cloud><microservices><oauth2><netflix-zuul>,1,301,4,0.0,0,<p>We are using zuul as API gateway in spring cloud. Now we want to extract access token from zuul for further implementation.Please provide suggestion how we want to implement. Thank you</p>&#xA;
46308297,Is there a reason why dispatch.yaml doesn't seem to route to specified microservices when I locally run my Node.js app which contains microservices?,2017-09-19 19:22:51,<node.js><google-app-engine><microservices><dispatch>,1,64,0,0.0,0,"<p>Eventually, I want to deploy a Node.js app which contains microservices to Google Cloud Platform. I develop locally. However, my dispatch file doesn't seem to route to the associated modules.</p>&#xA;&#xA;<p>My dispatch.yaml file looks like this: </p>&#xA;&#xA;<p><strong>dispatch.yaml</strong></p>&#xA;&#xA;<pre><code>dispatch :&#xA;  - url    : ""*/service-1/*""&#xA;    module : service-1&#xA;&#xA;  - url    : ""*/service-2/*""&#xA;    module : service-2&#xA;</code></pre>&#xA;&#xA;<p>In the same map exists the app file for the main app:</p>&#xA;&#xA;<p><strong>app.js</strong></p>&#xA;&#xA;<pre><code>""use strict""&#xA;&#xA;const express = require('express')&#xA;const app     = express()&#xA;&#xA;app.get('/',     function(req, res){res.status(200).send('Main app: Hello, world!')})&#xA;&#xA;const PORT = process.env.PORT || 8080&#xA;app.listen(PORT, () =&gt; {console.log(`Main app server listening on port ${PORT}`)})&#xA;</code></pre>&#xA;&#xA;<p>Per (micro)service I've created a potentially autonomous application-map.&#xA;Here is the example for the first microservice.</p>&#xA;&#xA;<p><strong>service-1/app.js</strong></p>&#xA;&#xA;<pre><code>""use strict""&#xA;&#xA;const express = require('express')&#xA;const app     = express()&#xA;&#xA;app.get('/service-1/', function(req, res){res.status(200).send('Service 1: Hello, world!')})&#xA;&#xA;const PORT = process.env.PORT || 8080&#xA;app.listen(PORT, () =&gt; {console.log(`service-1 server listening on port ${PORT}`)})&#xA;</code></pre>&#xA;&#xA;<p>When I start the main app's server through the terminal and then go to <code>localhost:8080</code>&#xA;in my browser: it responds as expected. The message 'Main app: Hello, world!' is received.</p>&#xA;&#xA;<p>However, when I type in <code>localhost:8080/service-1</code> in the browser, it doesn't respond as it should.</p>&#xA;&#xA;<p>Does anyone know why? Or does dispatch.yaml only work when actually deployed?</p>&#xA;&#xA;<p>Thank you for your time.</p>&#xA;&#xA;<p>I appreciate help very much.</p>&#xA;"
46434569,How can I make my .NET Core microservice do a recursive health check?,2017-09-26 19:42:53,<asp.net-core><microservices><health-monitoring>,1,586,0,0.0,0,"<p><a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/monitor-app-health"" rel=""nofollow noreferrer"">As described</a> I can do:</p>&#xA;&#xA;<pre><code>checks.AddUrlCheck(Configuration[""OrderingUrl""])&#xA;</code></pre>&#xA;&#xA;<p>to make my health check dependant on the health of other Microservices. However,I do not just want to do an url check. I want to do a full health check on the other Microservice (so it will also check the database dependencies etc of the other Microservice). This could be something like,</p>&#xA;&#xA;<p><code>checks.AddFullMicroserviceIncludingDatabaseAndUrlCheck(Configuration[""OrderingUrl""])</code> (hypothically).</p>&#xA;&#xA;<p>How can I do such a recursive health check in my .NET Core microservice?</p>&#xA;"
46453447,Installing Istio in Kubernetes with automatic sidecar injection: istio-inializer.yaml Validation Failure,2017-09-27 17:01:22,<azure><kubernetes><microservices><kubectl><istio>,1,467,0,1.0,0,"<p>I'm trying to install Istio with automatic sidecar injection into Kubernetes. My environment consists of three masters and two nodes and was built on Azure using the Azure Container Service marketplace product. </p>&#xA;&#xA;<p>Following the documentation located <a href=""https://istio.io/docs/setup/kubernetes/automatic-sidecar-inject.html"" rel=""nofollow noreferrer"">here</a>, I have so far enabled <code>RBAC</code> and <code>DynamicAdmissionControl</code>. I have accomplished this by modifying <code>/etc/kubernetes/istio-inializer.yaml</code> on the Kubernetes Master by adding the <a href=""https://i.imgur.com/6O5que7.png"" rel=""nofollow noreferrer"">following content outlined in red</a> and then restarting the Kubernetes Master using the Unix command, <code>reboot</code>. </p>&#xA;&#xA;<p>The next step in the documentation is to apply the yaml using <code>kubectl</code>. I assume that the documentation intends for the user to clone the Istio repository and <code>cd</code> into it before this step but that is unmentioned. </p>&#xA;&#xA;<pre><code>git clone https://github.com/istio/istio.git&#xA;cd istio&#xA;kubectl apply -f install/kubernetes/istio-initializer.yaml&#xA;</code></pre>&#xA;&#xA;<p>After which the following error occurs: </p>&#xA;&#xA;<pre><code>user@hostname:~/istio$ kubectl apply -f install/kubernetes/istio-initializer.yaml&#xA;&#xA;configmap ""istio-inject"" configured&#xA;serviceaccount ""istio-initializer-service-account"" configured&#xA;error: error validating ""install/kubernetes/istio-initializer.yaml"": error validating data: found invalid field initializers for v1.ObjectMeta; if you choose to ignore these errors, turn validation off with --validate=false&#xA;</code></pre>&#xA;&#xA;<p>If I attempt to execute <code>kubectl apply</code> with the mentioned flag, <code>validate=false</code>, then this error is generated instead:</p>&#xA;&#xA;<pre><code>user@hostname:~/istio$ kubectl apply -f install/kubernetes/istio-initializer.yaml --validate=false&#xA;&#xA;configmap ""istio-inject"" configured&#xA;serviceaccount ""istio-initializer-service-account"" configured&#xA;deployment ""istio-initializer"" configured&#xA;error: unable to recognize ""install/kubernetes/istio-initializer.yaml"": no matches for admissionregistration.k8s.io/, Kind=InitializerConfiguration&#xA;</code></pre>&#xA;&#xA;<p>I'm not sure where to go from here. The problem appears to be related to the <code>admissionregistration.k8s.io/v1alpha1</code> block in the <code>yaml</code> but I'm unsure what specifically is incorrect in this block.</p>&#xA;&#xA;<pre><code>apiVersion: admissionregistration.k8s.io/v1alpha1&#xA;kind: InitializerConfiguration&#xA;metadata:&#xA;  name: istio-sidecar&#xA;initializers:&#xA;  - name: sidecar.initializer.istio.io&#xA;    rules:&#xA;      - apiGroups:&#xA;          - ""*""&#xA;        apiVersions:&#xA;          - ""*""&#xA;        resources:&#xA;          - deployments&#xA;          - statefulsets&#xA;          - jobs&#xA;          - daemonsets&#xA;</code></pre>&#xA;&#xA;<p>Installed version of Kubernetes:</p>&#xA;&#xA;<pre><code>user@hostname:~/istio$ kubectl version&#xA;Client Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.6"", GitCommit:""7fa1c1756d8bc963f1a389f4a6937dc71f08ada2"", GitTreeState:""clean"", BuildDate:""2017-06-16T18:21:54Z"", GoVersion:""go1.7.6"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.6"", GitCommit:""7fa1c1756d8bc963f1a389f4a6937dc71f08ada2"", GitTreeState:""clean"", BuildDate:""2017-06-16T18:21:54Z"", GoVersion:""go1.7.6"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;</code></pre>&#xA;&#xA;<p>I suspect this is a versioning mismatch. As a follow up question, is it possible to deploy a version of kubernetes >= 1.7.4 to Azure using ACS?</p>&#xA;&#xA;<p>I'm fairly new to working with Kubernetes so if anyone could help I would greatly appreciate it. Thank you for your time. </p>&#xA;"
46388219,Nats.io QueueSubscribe behavior on timeout,2017-09-24 08:40:56,<go><microservices><nats.io>,1,124,1,0.0,0,"<p>I'm evaluating NATS for migrating an existing msg based software &#xA;I did not find documentation about msg timeout exception and overload. &#xA;For Example:</p>&#xA;&#xA;<ul>&#xA;<li>After Subscriber has been <em>chosen</em> , Is it aware of timeout settings posted by Publisher ? Is it possible to notify an additional time extension ?</li>&#xA;<li>If the <em>elected</em> subscriber is aware that some DBMS connection is missing and cannot complete It could be possible to bounce the message</li>&#xA;</ul>&#xA;&#xA;<p>NATS server will pickup another subscriber and will re-post the same message ?</p>&#xA;&#xA;<p>Ciao&#xA;Diego   </p>&#xA;"
46343630,Pact.js - willRespondWith an arbitrary ordered array,2017-09-21 12:12:52,<node.js><microservices><pact><pact-node>,1,40,2,0.0,0,"<p>my consumer service asks a provider service for a list of all users, but the provider answers with an arbitrary ordered list (which is fine). The pact execution on consumer side looks fine, but when executing it on the provider site, it says: <code>Expected ""user1"" but got ""user3"" at $.items[0].userName</code> for example.</p>&#xA;&#xA;<p>This is is a snippet of the interaction:</p>&#xA;&#xA;<pre><code>willRespondWith: {&#xA;    status: 200,&#xA;    headers: { ""Content-Type"": ""application/json; charset=utf-8"" },&#xA;    body: {&#xA;        items: [&#xA;            { userName: ""user1"" },&#xA;            { userName: ""user2"" },&#xA;            { userName: ""user3"" },&#xA;        ],&#xA;    },&#xA;},&#xA;</code></pre>&#xA;&#xA;<p>Is there a way to ignore the order of returned items?</p>&#xA;&#xA;<p>Further, my mocha test doesn't seem to have an impact on the comparison. I also tried to order both arrays, but nothing helped. How are both (interaction and mocha test) connected?</p>&#xA;&#xA;<pre><code>it(""Should generate a list of users in the system"", async function () {&#xA;            await userServiceClient.getUsers()&#xA;                .then((users) =&gt; {&#xA;                    expect(users).to.include.members(EXPECTED_USERS_ARRAY);&#xA;                });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>Many thanks in advance!</p>&#xA;"
46329712,Service Fabric Package Activation Error,2017-09-20 18:50:56,<.net><asp.net-core><microservices><azure-service-fabric><service-fabric-stateless>,1,394,2,0.0,0,"<p>Getting the following error</p>&#xA;&#xA;<pre><code>Error event: SourceId='System.Hosting', &#xA;&#xA;Property='CodePackageActivation:Code:EntryPoint'.&#xA;There was an error during CodePackage activation.Service host failed to activate. Error:0x800700c1`&#xA;</code></pre>&#xA;&#xA;<p>If I attempt it on a linux service fabric cluster, the error changes some. So thinking the windows cluster is failing on the entyPoint.sh script as windows doesn't have bash. Linux cluster apparent getting past that and failing somewhere inside of the initialization code, but still can't find where. I added the     </p>&#xA;&#xA;<pre><code> &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048""/&gt;&#xA;</code></pre>&#xA;&#xA;<p>And downloaded all of the logs from the linux box, but not seeing anything from the console in there. </p>&#xA;&#xA;<pre><code>Error event: SourceId='System.Hosting', &#xA;&#xA;Property='CodePackageActivation:Code:EntryPoint'.&#xA;There was an error during CodePackage activation.The service host terminated with exit code:134&#xA;</code></pre>&#xA;&#xA;<p>Startup class looks like </p>&#xA;&#xA;<pre><code>namespace MyApp&#xA;{&#xA;    using System.Collections.Generic;&#xA;    using System.Fabric;&#xA;    using System.IO;&#xA;    using System.Net.Http;&#xA;    using Microsoft.AspNetCore.Hosting;&#xA;    using Microsoft.Extensions.DependencyInjection;&#xA;    using Microsoft.ServiceFabric.Services.Communication.AspNetCore;&#xA;    using Microsoft.ServiceFabric.Services.Communication.Runtime;&#xA;    using Microsoft.ServiceFabric.Services.Runtime;&#xA;/// &lt;summary&gt;&#xA;/// The FabricRuntime creates an instance of this class for each service type instance. &#xA;/// &lt;/summary&gt;&#xA;internal sealed class MyApp : StatelessService&#xA;{&#xA;    public MyApp(StatelessServiceContext context)&#xA;        : base(context)&#xA;    {&#xA;    }&#xA;&#xA;    /// &lt;summary&gt;&#xA;    /// Optional override to create listeners (like tcp, http) for this service instance.&#xA;    /// &lt;/summary&gt;&#xA;    /// &lt;returns&gt;The collection of listeners.&lt;/returns&gt;&#xA;    protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;    {&#xA;        return new ServiceInstanceListener[]&#xA;        {&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new KestrelCommunicationListener(&#xA;                        serviceContext,&#xA;                        ""ServiceEndpoint"",&#xA;                        (url, listener) =&gt;&#xA;                        {&#xA;                            ServiceEventSource.Current.ServiceMessage(serviceContext, $""Starting WebListener on {url}"");&#xA;&#xA;                            return new WebHostBuilder()&#xA;                                .UseKestrel()&#xA;                                .ConfigureServices(&#xA;                                    services =&gt; services&#xA;                                        .AddSingleton&lt;ConfigSettings&gt;(new ConfigSettings(serviceContext))&#xA;                                        .AddSingleton&lt;HttpClient&gt;(new HttpClient())&#xA;                                        .AddSingleton&lt;FabricClient&gt;(new FabricClient())&#xA;                                        .AddSingleton&lt;StatelessServiceContext&gt;(serviceContext))&#xA;                                .UseContentRoot(Directory.GetCurrentDirectory())&#xA;                                .UseServiceFabricIntegration(listener, ServiceFabricIntegrationOptions.None)&#xA;                                .UseStartup&lt;Startup&gt;()&#xA;                                .UseUrls(url)&#xA;                                .Build();&#xA;                        }))&#xA;        };&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Program.cs</p>&#xA;&#xA;<pre><code>namespace MyApp&#xA;{&#xA;    using System;&#xA;    using System.Diagnostics;&#xA;    using System.Threading;&#xA;    using CommandLine;&#xA;    using Microsoft.AspNetCore.Hosting;&#xA;    using Microsoft.ServiceFabric.Services.Runtime;&#xA;&#xA;internal static class Program&#xA;{&#xA;    /// &lt;summary&gt;&#xA;    /// This is the entry point of the service host process.&#xA;    /// &lt;/summary&gt;&#xA;    private static void Main(string[] args)&#xA;    {&#xA;        var parser = new Parser(with =&gt;&#xA;        {&#xA;            with.HelpWriter = Console.Out;&#xA;        });&#xA;&#xA;        var options = new Options();&#xA;        var result = parser.ParseArguments(args, options);&#xA;&#xA;&#xA;        if (options.Host.ToLower() == MyAppConstants.ServiceFabricHost)&#xA;        {&#xA;            try&#xA;            {&#xA;                // The ServiceManifest.XML file defines one or more service type names.&#xA;                // Registering a service maps a service type name to a .NET type.&#xA;                // When Service Fabric creates an instance of this service type,&#xA;                // an instance of the class is created in this host process.&#xA;&#xA;                ServiceRuntime.RegisterServiceAsync(&#xA;                    ""WebServiceType"",&#xA;                    context =&gt; new MyApp(context)).GetAwaiter().GetResult();&#xA;&#xA;                ServiceEventSource.Current.ServiceTypeRegistered(Process.GetCurrentProcess().Id, typeof(SnapNurse).Name);&#xA;&#xA;                // Prevents this host process from terminating so services keeps running. &#xA;                Thread.Sleep(Timeout.Infinite);&#xA;            }&#xA;            catch (Exception e)&#xA;            {&#xA;                ServiceEventSource.Current.ServiceHostInitializationFailed(e.ToString());&#xA;                throw;&#xA;            }&#xA;        }&#xA;        else if (options.Host.ToLower() == MyAppConstants.SelfHost)&#xA;        {&#xA;            using (var host = WebHostBuilderHelper.GetWebHost(new WebHostBuilder(), options.Protocol, options.Port))&#xA;            {&#xA;                host.Run();&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I haven't been able to find specifics on the error, and can't debug anything in a service fabric environment because they won't run. Any help appreciated!</p>&#xA;&#xA;<p>I have run PerfView and found the events related to package activation, but no hints in there to what the actual issue is. Even if nobody knows what the issue is, just some help with techniques to get more information would be great!</p>&#xA;&#xA;<p>Another thing that seems strange is that even if I comment out all of the code in the Main() method, I still get the exact same error. Almost like it is failing before it even gets there on framework dlls or something of the sort, but everything is .netcore2 and I have the runtime installed on the machine with service fabric</p>&#xA;"
44564299,"Linkerd not displaying count of requests, success and failure rates",2017-06-15 09:48:26,<microservices><linkerd>,1,18,0,0.0,0,"<p>I am new to linkerd and trying to proxy all the requests to my microservices via linkerd and with file based service discovery. I was able to do it successfully and the requests successfully got registered with the admin dashboard running on port 9990. </p>&#xA;&#xA;<p>But my problem is the dashboard always shows N/A for the success rate and failure rate. It becomes 100% for just a sec the request is received and again goes back to N/A. But I want to keep track of all my request via linkerd i.e I want linkerd to remember the number of requests and the successrate and failure rate.</p>&#xA;&#xA;<p>Here is the screenshot of my problem</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hRqYM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hRqYM.png"" alt=""enter image description here""></a></p>&#xA;"
44602525,Service discoverability and communication,2017-06-17 08:42:51,<ipc><microservices><netflix>,1,30,0,0.0,0,"<p>I'm creating a microservice architecture.  I'm looking for a way (protocol or other thing) for my services communicate together but with automatic message translation between them.</p>&#xA;&#xA;<p>Example.  I have two kinds of store services, both of them expose their catalogs but with a distinct description format.  I can obviously code an adapter to do the job but the next time, the problem will come back.</p>&#xA;&#xA;<p>Any idea?</p>&#xA;"
44601394,"When desiging an activity based authorization system, how should additional conditional checks be handled?",2017-06-17 06:08:16,<rest><api><security><design><microservices>,1,35,0,0.0,0,"<p>When desiging an activity based authorization system, how should additional conditional checks be handled?</p>&#xA;&#xA;<p>For example, I have the following authority:</p>&#xA;&#xA;<pre><code>VIEW_COMPANY_TRANSACTIONS&#xA;</code></pre>&#xA;&#xA;<p>which allows the user to hit the endpoint </p>&#xA;&#xA;<pre><code>GET /company/{companyName}/transactions&#xA;</code></pre>&#xA;&#xA;<p>However, what if my authority <code>VIEW_COMPANY_TRANSACTIONS</code> has other restrictions based on the activity parameters that in fact make the authority effectively <code>VIEW_COMPANY_TRANSACTIONS(companyName=company_a)</code>. I don't want to encode that information into the authority system, and end up with the following new authority:</p>&#xA;&#xA;<pre><code>VIEW_COMPANY_TRANSACTIONS_FOR_COMPANY_A&#xA;</code></pre>&#xA;&#xA;<p>The above authority seems to mix up the filtering of the views and the authority itself which makes everything somewhat tedious and inflexible.</p>&#xA;&#xA;<p>In another example, I have the following authority:</p>&#xA;&#xA;<pre><code>APPROVE_TRANSACTION&#xA;</code></pre>&#xA;&#xA;<p>which allows the user to hit the endpoint:</p>&#xA;&#xA;<pre><code>POST /company/{companyName}/transactions/{id}/approvals&#xA;</code></pre>&#xA;&#xA;<p>But what if the approval can only be done if the <code>transaction.amount &lt; maxAmount</code> in which case, it's even harder to encode this into a new hardcoded authority.</p>&#xA;&#xA;<p>Note that these authorities may also be included in a JWT token, so they must somewhat <em>transferable</em> as well.</p>&#xA;&#xA;<p>What's the best way to design such a system? Any tips?</p>&#xA;"
44625192,Apache Kafka for inter-microservice communication; at what level to map topics to events?,2017-06-19 08:03:23,<events><logging><apache-kafka><microservices><api-design>,2,307,0,0.0,0,"<p>I'm working with a medium-sized web application, which is separated into several microservices. Currently, the way the services communicate with each other is an unsustainable mess, so I'm looking into other solutions.</p>&#xA;&#xA;<p>One approach that looks very appealing to me is to use a message broker, where each service sends and listens to messages. Apache Kafka has caught my attention and looks like a very promising choice of software for this purpose.</p>&#xA;&#xA;<p>However, I'm not sure how I'd use Kafka's topics, or more specifically, at what level to map the events to topics. I've identified three major levels of granularity, described below.</p>&#xA;&#xA;<p>For demonstration purposes, consider a hypothetical online store consisting of a number of services such as ShoppingCart, Billing and Shipping.</p>&#xA;&#xA;<p><strong>The whole application uses one topic</strong>.</p>&#xA;&#xA;<p>One single topic, e.g. <code>my-app-events</code>, is used to channel all events sent and received by the services. An event might look like: <code>{""from"": ""shopping-cart"", ""name"": ""PRODUCT_ADDED"", ""payload"": {""product_id"": 137}}</code>.</p>&#xA;&#xA;<p><strong>Each microservice uses its own topic</strong>.</p>&#xA;&#xA;<p>Separate topics, such as <code>shopping-cart-events</code>, <code>billing-events</code>, <code>shipping-events</code> etc. are used. Now an event in the <code>shopping-cart-events</code> topic might look like <code>{""name"": ""PRODUCT_ADDED"", ""payload"": {""product_id"": 137}}</code>.</p>&#xA;&#xA;<p><strong>Each event type uses its own topic</strong>.</p>&#xA;&#xA;<p>Here each possible message has its own topic. I suppose it'd make sense to include the producer of the event in the topic name, so that a topic might be called <code>shopping-cart.product-added</code>. In that case, the message contents would simply be the payload, e.g. <code>{""product_id"": 137}</code>.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I hope I made the difference clear between the three approaches. What do you suggest? Have you used Kafka (or any other message broker) successfully in this way? What are the advantages and pitfalls with each of the solutions?</p>&#xA;"
44535853,Security considerations for API Gateway clustering?,2017-06-14 05:06:37,<api><security><microservices><api-gateway>,1,63,0,2.0,0,"<p><a href=""https://i.stack.imgur.com/lWDTz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lWDTz.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>Clients that communicate against a single point of entry via an API Gateway over HTTPS against a RESTful API</li>&#xA;<li>API Gateway: API Keys for tracking and analytics, oAuth for API platform authentication</li>&#xA;<li>User Micro service provides user authentication and authorization, generates JWT that is signed and encrypted (JWS,JWE)</li>&#xA;<li>Other micro services determine permissions based on claims inside JWT</li>&#xA;<li>Micro services communicate internally via PUB/SUB using JWT in the message and other info. Each micro service could be scaled out with multiple instances (cluster with a load balancer).</li>&#xA;</ol>&#xA;&#xA;<p><strong>Question</strong>: <em>Can I cluster the the API Gateway and have the load balancer in front of it.  What do I need to consider with respect to managing authentication?  ie: sharing of API Keys across the API Gateway cluster?</em>  </p>&#xA;&#xA;<p>Extra notes, I'm planning on terminating SSL at the gateway and the use of bcrypt for passwords in the db.</p>&#xA;&#xA;<p>Any feedback would be great, thank you.</p>&#xA;"
44626450,Best practice - Calling APIs & Services in Single page applications,2017-06-19 09:10:14,<architecture><single-page-application><microservices>,1,92,0,0.0,0,<p>I have a single page applications that needs to call a variety of web services and/or APIs. I would like to understand what is a generally agreed approach to making api or service calls from SPA. We currently have two approaches </p>&#xA;&#xA;<ol>&#xA;<li><p>For certain 3rd party APIs- we make direct calls from the single page application without a server side proxy. In order for this to work we have CORS enabled. </p></li>&#xA;<li><p>For other  API calls - we make calls to a proxy (wrapper) which is responsible for redirecting them to the appropriate endpoints. </p></li>&#xA;</ol>&#xA;&#xA;<p>The way we decide which approach to use is - if there is some kind of data manipulation thats needed before calling the 3rd party api - we use the proxy - else we make direct calls from the SPA. Is this a valid approach. Would you have any feedback on if the 1st approach is robust from a security point of view? In the 1st approach we have a http-only cookie that is being used as an access token to make calls to the 3rd party api. Does this make the API we are exposing vulnerable?</p>&#xA;&#xA;<p>thanks in advance</p>&#xA;
44503321,How to access Kubernetes pod in local cluster?,2017-06-12 15:33:03,<kubernetes><microservices><kube-proxy>,2,417,0,0.0,0,"<p>I have set up an experimental <em>local</em> Kubernetes cluster with one master and three slave nodes. I have created a deployment for a custom service that listens on port 10001. The goal is to access an exemplary endpoint <code>/hello</code> with a stable IP/hostname, e.g. <code>http://&lt;master&gt;:10001/hello</code>.</p>&#xA;&#xA;<p>After deploying the deployment, the pods are created fine and are accessible through their cluster IPs.</p>&#xA;&#xA;<p>I understand the solution for cloud providers is to create a load balancer service for the deployment, so that you can just <code>expose</code> a service. However, this is apparently not supported for a local cluster. Setting up <a href=""https://kubernetes.io/docs/concepts/services-networking/ingress/"" rel=""nofollow noreferrer"">Ingress</a> seems overkill for this purpose. Is it not?</p>&#xA;&#xA;<p>It seems more like <code>kube proxy</code> is the way to go. However, when I run <code>kube proxy --port &lt;port&gt;</code> on the master node, I can access <code>http://&lt;master&gt;:&lt;port&gt;/api/...</code>, but not the actual pod.</p>&#xA;&#xA;<p>There are many related questions (e.g. <a href=""https://stackoverflow.com/questions/41663504/how-to-access-services-through-kubernetes-cluster-ip"">How to access services through kubernetes cluster ip?</a>), but no (accepted) answers. The Kubernetes <a href=""https://kubernetes.io/docs/user-guide/kubectl/v1.6/#proxy"" rel=""nofollow noreferrer"">documentation</a> on the <a href=""https://kubernetes.io/docs/admin/kube-proxy/"" rel=""nofollow noreferrer"">topic</a> is rather sparse as well, so I am not even sure about what is the right approach conceptually.</p>&#xA;&#xA;<p>I am hence looking for a straight-forward solution and/or a good tutorial. It seems to be a very typical use case that lacks a clear path though.</p>&#xA;"
44455242,Wether to make a service stateless or stateful in Azure Service Fabric,2017-06-09 10:18:25,<microservices><azure-service-fabric><stateless><stateful>,2,430,0,0.0,0,<p>I have microservice which basically read and update data on an Azure Storage table&#xA;Read and Update function are implemented as REST calls.I am confused whether to make it stateless or stateful</p>&#xA;
44471051,"In a microservice environment, should any producer be able to verify JWT tokens?",2017-06-10 08:06:58,<authentication><authorization><token><jwt><microservices>,1,184,0,1.0,0,"<p>I'm trying to figuring out how to manage authorization in a microservice environment.</p>&#xA;&#xA;<p>This is my hypothetical scenario.</p>&#xA;&#xA;<p>I have a service which provides authentication (using <a href=""https://github.com/plataformatec/devise"" rel=""nofollow noreferrer""><code>devise</code></a> gem)  and authorization via oauth2 (using <a href=""https://github.com/doorkeeper-gem/doorkeeper"" rel=""nofollow noreferrer""><code>doorkeeper</code></a> gem). Once logged in, the service returns a <a href=""https://jwt.io/"" rel=""nofollow noreferrer"">JWT</a> token to the user.</p>&#xA;&#xA;<p>Now let's suppose I have two API servers. The user must provide the JWT token to these API servers in order to access to private resources.</p>&#xA;&#xA;<p>Is it ok to share the JWT secret key I used to sign JWT token with my two API servers so they can decode the token and verify its validity? Or should my API servers forward the JWT token to the authorization service and ask it to verify it?</p>&#xA;&#xA;<p>Pros of sharing JWT secret key with API servers:</p>&#xA;&#xA;<ul>&#xA;<li>no round trip to the authorization service</li>&#xA;</ul>&#xA;&#xA;<p>Cons of sharing JWT secret key with API servers:</p>&#xA;&#xA;<ul>&#xA;<li>if someone breaks in any of my API server, he/she have access to my JWT secret key</li>&#xA;</ul>&#xA;&#xA;<p>I am stuck. I don't even know if there is a third solution I didn't consider :)</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
44651737,How can I replicate user roles from an Authorization Server to downstream microservices?,2017-06-20 11:24:10,<security><spring-security><jwt><microservices><spring-cloud>,1,186,0,0.0,0,"<p>I need to implement an application where I am going to use an Authorization Server generating a JWT token. These token will include the roles a user is granted to then authorize the user access to different resources. There will also be a gateway where this security will be added. </p>&#xA;&#xA;<p>My question is regarding the user roles and the security between internal microservices. </p>&#xA;&#xA;<p>When the user is created, he should be granted a set of roles and he may be granted different ones at a later point or maybe new roles will be added later. All this information should be stored in the Authorization Server. But how is this information replicated to other microservices? If I use a framework like Spring Security to secure my endpoints, where I add the roles needed for the different URLs, do I need to hardcode the user roles into my security configuration in the downstream microservices or is there any other way to find them from the Authorization Server? </p>&#xA;&#xA;<p>The architecture is going to use an API gateway in a public network that then communicates with a service discovery in an internal one to find the different microservices. These also find each other through the service discovery. I use Zuul for routing. In this situation, do I need to also secure the communication within the internal network? I understand that to use Spring Security for authorization I would need to pass the JWT token anyway to get the user roles. But would it be necessary otherwise? Would it be enough to use HTTPS from the client to the gateway and unsafe HTTP within the private network?</p>&#xA;"
44456131,How to work with Cache-Control using WebRequest and WebResponse?,2017-06-09 11:02:40,<c#><.net><asp.net-web-api><microservices>,1,190,0,0.0,0,"<p>Imagine a number of services in a Microservices architecture. Service A requests a response from service B and service B sets the <code>Cache-Control</code> header to <code>public, max-age=78261</code>.</p>&#xA;&#xA;<p>Is there not a .NET way to work with the requested object and a ""Cache"" object of some sort?</p>&#xA;&#xA;<p>One could think that there should/would be a <code>Cache</code> property in the <code>WebResponse</code> or <code>HttpWebResponse</code> class, interfacing the <code>Cache-Control</code> header.</p>&#xA;&#xA;<p><strong>Is it really neccessary to parse the <code>Cache-Control</code> string, find the value and implement support for the header manually?</strong></p>&#xA;"
44571838,Message based communication between microservices,2017-06-15 15:48:43,<java><activemq><publish-subscribe><microservices>,1,214,0,0.0,0,"<p>I would like to build few number of microservices that send and receive message using a message broker: <em>ActiveMQ</em>. Now I am exploring options for message type (i.e. <code>String</code>, <code>byte[]</code>, <em>object</em> type):</p>&#xA;&#xA;<ol>&#xA;<li>publish msg in <strong>XML/JSON</strong> format and once received they are parsed</li>&#xA;<li>publish msg in <strong>XML/JSON</strong> format, using schema to convert them to objects</li>&#xA;<li>Create a Domain object and add to microservices dependency for data exchange</li>&#xA;</ol>&#xA;&#xA;<p>These are the 3 options I have looked at, and I am leaning towards option 1 for below mentioned reasons :</p>&#xA;&#xA;<ol>&#xA;<li>when a new field needs to be added only those microservices that require this field need change.</li>&#xA;<li>Different version of microservices can be deployed without breaking existing communication</li>&#xA;<li>microservices remain decoupled</li>&#xA;</ol>&#xA;&#xA;<p>However this raises the issue of parsing and extracting data which is very error prone. </p>&#xA;&#xA;<p>I would like to know if anyone else has done a similar design and could share their experience and suggest solutions. Also if there is a better way to implement communication between microservices using messaging and queues.</p>&#xA;"
44464660,Ideally how many functions should be there in a fucntion app,2017-06-09 18:35:42,<azure><microservices><azure-functions>,1,94,1,1.0,0,"<p>As per the new template in Visual Studio 2017 prev 2, all function in a function app do share dependencies. Any custom business code/library added will be available to all other functions in a function app. &#xA;There is a problem here that it is will give monolithic design a chance to sneak in. And any change in a function would require entire set of function to be redeployed.</p>&#xA;&#xA;<p>Another design can be to keep the function app as thin as possible (if possible one function per function app in my opinion). This would segregate the code and dependencies of each function, but on the flip side, I would bring a deployment/maintainability nightmare.</p>&#xA;&#xA;<p>Is there any design guideline to be followed which could balance maintainability hassle and help achieving micro service design goal ?</p>&#xA;"
44482448,What is the deployment dependencies of cloud functions vs firebase app in microservice style of development?,2017-06-11 09:48:49,<firebase><microservices><firebase-hosting><polymerfire>,1,109,1,0.0,0,"<ol>&#xA;<li><p>I've a project with polymer 2.0 web app with polymerfire and published to firebase hosting using <code>firebase deploy</code></p></li>&#xA;<li><p>I've another project with a cloud function that acts on database trigger, and deployed it using <code>firebase deploy --only functions:updateOnChange</code></p></li>&#xA;<li><p>I've another project with a cloud function that is an express app with route mappings <code>GET /fns/register</code>, <code>POST /fns/register</code>, and <code>PUT /fns/register/confirm</code>. I've deployed this using <code>firebase deploy --only functions:register</code></p></li>&#xA;</ol>&#xA;&#xA;<p>I've created the rewrite rules to map the routes <code>/fns/**</code> to the register cloud function in my first project (the polymer one) in the firebase.json file. I see this as a current firebase limitation that we can't manage the rewrite rules from multiple projects. </p>&#xA;&#xA;<p>Following is my <code>firebase.json</code> in the 1st project (polymer project):</p>&#xA;&#xA;<pre><code>{&#xA;  ""database"": {&#xA;    ""rules"": ""database.rules.json""&#xA;  },&#xA;  ""hosting"": {&#xA;    ""public"": ""build/default/public"",&#xA;    ""rewrites"": [&#xA;      {&#xA;        ""source"": ""/fns/**"",&#xA;        ""function"": ""fns""&#xA;      },&#xA;      {&#xA;        ""source"": ""**"",&#xA;        ""destination"": ""/index.html""&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now my requests for <code>/fns/register</code> are getting routed to my <code>register</code> cloud function, but the <code>res.sendFile</code> I wrote in the app is not working. it always says </p>&#xA;&#xA;<pre><code>TypeError: path must be absolute or specify root to res.sendFile&#xA;    at ServerResponse.sendFile (/user_code/node_modules/express/lib/response.js:410:11)&#xA;    at app.get (/user_code/index.js:28:13)&#xA;    at Layer.handle [as handle_request] (/user_code/node_modules/express/lib/router/layer.js:95:5)&#xA;    at next (/user_code/node_modules/express/lib/router/route.js:137:13)&#xA;    at Route.dispatch (/user_code/node_modules/express/lib/router/route.js:112:3)&#xA;    at Layer.handle [as handle_request] (/user_code/node_modules/express/lib/router/layer.js:95:5)&#xA;    at /user_code/node_modules/express/lib/router/index.js:281:22&#xA;    at Function.process_params (/user_code/node_modules/express/lib/router/index.js:335:12)&#xA;    at next (/user_code/node_modules/express/lib/router/index.js:275:10)&#xA;    at expressInit (/user_code/node_modules/express/lib/middleware/init.js:40:5)&#xA;</code></pre>&#xA;&#xA;<p>My log statements inside the code are not working and even if I am sending simple <code>res.send(JSON.stringify({ a: 1 }, null, 3));</code> it still throws the same above error. </p>&#xA;&#xA;<p>This means, my code is not getting executed or my libraries are not getting uploaded to my cloud function. I want to understand the deployment scoping/ architecture/ dependencies of the cloud functions vs the app. </p>&#xA;&#xA;<p>In Google IO 2017, the repeated advice was to go and use microsrevice style of development for the apps, and not a single monolith. What I am following here is microservice style of development, but getting no where!</p>&#xA;&#xA;<p>Kindly help me here. </p>&#xA;"
44502869,How to load a zip file in java servlet and expose as URL,2017-06-12 15:11:58,<java><url><servlets><microservices><embedded-jetty>,2,98,5,0.0,0,"<p>My requirement is loading a zip file from file system in java servlet and expose as URL (without extracting the zip file).</p>&#xA;&#xA;<p>For example, a zip file is located in C:\temp\example.zip. Content of this zip file is </p>&#xA;&#xA;<ol>&#xA;<li>example.html and its dependent files</li>&#xA;<li>one.js</li>&#xA;<li>two.js.</li>&#xA;</ol>&#xA;&#xA;<p>How to construct URL like ""<a href=""http://localhost:8080/app/example.zip/example.html"" rel=""nofollow noreferrer"">http://localhost:8080/app/example.zip/example.html</a>""? &#xA;Server could be jetty. Any help is highly appreciated. Thanks.</p>&#xA;&#xA;<p>I can even change the server or can use some other approach also to achieve the above solution. As said earlier, the only constraint is ""should not be extracted"".</p>&#xA;"
44585239,Splitting monolith to microservices database issues,2017-06-16 09:08:05,<database><oracle><join><microservices>,1,227,6,0.0,0,"<p>I am splitting monolith application to microservices and I was able to split it to three microservices, for easier explanation suppose these are:</p>&#xA;&#xA;<ul>&#xA;<li>Users (CRUD)</li>&#xA;<li>Messages (CRUD)</li>&#xA;<li>Other things (CRUD)</li>&#xA;</ul>&#xA;&#xA;<p>All of these are distinct bounded contexts and I'm using database table for microservice. So in DB i have:</p>&#xA;&#xA;<pre><code>USERS table&#xA;id&#xA;surname&#xA;lastname&#xA;...&#xA;&#xA;OTHER_THINGS table&#xA;id&#xA;col1&#xA;col2&#xA;...&#xA;&#xA;MESSAGES table&#xA;id&#xA;title&#xA;created_time&#xA;USER_ID&#xA;OTHER_THING_ID&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>Now my web page needs searching/filtering of messages by all of the specified columns of all of these tables. For example:</p>&#xA;&#xA;<p>Web page user can enter:</p>&#xA;&#xA;<ul>&#xA;<li>surname of USER, </li>&#xA;<li>col2 of OTHER_THINGS </li>&#xA;<li>title of messages </li>&#xA;</ul>&#xA;&#xA;<p>And I should return only filtered rows.</p>&#xA;&#xA;<p>With monolith I have used simple database JOINS, but in this situation I can't find the best option. Can you suggest me possible options and which ones are better?</p>&#xA;"
44484346,bash command to wait until TCP port is opened,2017-06-11 13:24:50,<java><linux><bash><microservices>,1,981,7,0.0,0,"<p>I want my micro services to open in a new command line and run it from there one after the other. below is my bash script</p>&#xA;&#xA;<pre class=""lang-bash prettyprint-override""><code>################ first SERVER #####################&#xA;gnome-terminal -x sh -c 'java -jar server/target/first-server.jar; exec bash'&#xA;&#xA;################ second SERVER #####################&#xA;export service_port=8771&#xA;export host_name=firstdomain&#xA;gnome-terminal -x sh -c 'java -Dservice.port=""${service_port}"" -Dhost.name=""${host_name}"" -jar eureka/target/second-server.jar; exec bash'&#xA;</code></pre>&#xA;&#xA;<p>The problem is it that i want to start my <strong>""second-server.jar""</strong> after successfully started the <strong>""first-server.jar""</strong>. I can detect that by checking if the service is listening to network port. Is there any way to archive this? <strong>sleep</strong> bash command is not a option for me.</p>&#xA;"
31605799,Auth service to insulate webapps from database,2015-07-24 08:35:17,<scala><authentication><oauth-2.0><openid-connect><microservices>,1,85,0,1.0,0,"<p>A company that I'm developing for currently has some internal-use webapps that authenticate using their main database (they store authorization info in different tables).&#xA;I'm working on creating a new webapp, in Scala. I want to completely insulate it from the main database: it should be a true microservice. (Hopefully other things will gradually move more in the microservices direction.)&#xA;The GUI will need to allow the predefined users to log in, with various authorities. So the authentication and authorization information already exists in the main database. Since I don't want to give my webapp direct access to the database, the user info in the main database should only be accessible to it via a service that is external to it.&#xA;(Once that auth service is in place, the existing apps could also be made to use it eventually.)</p>&#xA;&#xA;<p>My question is what I should use for the auth service. Do I want an OAuth2 + OpenID connect service? Perhaps something much simpler? Should I be using something off the shelf?</p>&#xA;&#xA;<p>At the moment SSO is not a requirement, but it may be a nice-to-have in the future.</p>&#xA;"
31608784,Wildfly swarm jax-rs multipart form NotSupportedException,2015-07-24 10:56:42,<wildfly><resteasy><java-ee-7><microservices><wildfly-swarm>,1,382,0,0.0,0,"<p>I have a fairly simple jax-rs application running on wildfly 9. It makes use of resteasy multipart form. It runs 100%. Now I am trying to run the same application with wildfly swarm, but get a </p>&#xA;&#xA;<pre><code>javax.ws.rs.NotSupportedException: Could not find message body reader for type .... multipart/form-data on execute of the resource post operation.&#xA;</code></pre>&#xA;&#xA;<p>This as far as I understand is the resteasy-multipart-provider. In my <code>pom</code> I have the <code>wildfly-swarm-weld-jaxrs</code> fraction. Is this not suppose to take care of the multipart features? If not how do I get it included in the swarm fat jar/package? I have tried including the <code>resteasy-multipart-provider</code> as a compile dependency, but this breaks the swarm application and it refuses to start/boot. Or have I missed something else?</p>&#xA;"
31493493,How to leverage oauth to implement SSO for micro service apps,2015-07-18 17:03:48,<ruby-on-rails><ruby><oauth-2.0><single-sign-on><microservices>,1,194,0,0.0,0,"<p>We want to establish SSO between microservice apps,</p>&#xA;&#xA;<p>Eg: In a e-commerce site if user logins to main app,user should be automatically allowed to access cart app connected to it, which is a micro service.</p>&#xA;&#xA;<p>I searched Oauth spec but I could find any relevant answer specific to my case.&#xA;some of things which differ wrt Oauth are</p>&#xA;&#xA;<ul>&#xA;<li>User need not to authorize resources(cart app) against Identify provider.it should be done seamlessly in backend.</li>&#xA;<li>we don't want to use outside Identify provider like facebook,google,Main app(from eg above) should act as identity provider.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<p>1.Is there a standard way(procedure) defined in oauth to handle these kind of authentication/authorization.?</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>If not what are the most popular alternatives ?</li>&#xA;</ol>&#xA;&#xA;<p>Other info:&#xA;Ours apps are build using Ruby on Rails,if you know any good gems please suggest. </p>&#xA;&#xA;<p>I found couple of questions(<a href=""https://stackoverflow.com/questions/29644916/microservice-authentication-strategy"">1</a>,<a href=""https://stackoverflow.com/questions/25595492/single-sign-on-in-micro-service-architecture"">2</a>) related to this but they much broader. Even google is also not helping,so please don't mark this question as duplicate.</p>&#xA;"
51615385,Spring boot micro services with pre-Authenticated filter using CSRF protection,2018-07-31 14:09:37,<spring-boot><single-sign-on><csrf><microservices><pre-authentication>,1,19,0,0.0,0,<p>I am using SSO and preAuthenticated Filter in my micro services. Micro services are built using spring boot and are stateless in nature. How can I apply CSRF protection across all micro services using spring security. Please let me know if any solution is available to implement CSRF for this scenario. </p>&#xA;
51545971,Nginx Microservices Authentication,2018-07-26 19:07:46,<nginx><microservices>,1,22,0,0.0,0,"<p>What's the best practice to build microservices authentication over Nginx?</p>&#xA;&#xA;<p>At the moment I have the next reverse-proxy service</p>&#xA;&#xA;<pre><code>server {&#xA;    listen 80;&#xA;    listen [::]:80;&#xA;&#xA;    server_name sspay.local;&#xA;&#xA;    location /service/passport/ {&#xA;        proxy_pass http://passport-service:3000/;&#xA;        proxy_redirect off;&#xA;        proxy_set_header Host $host;&#xA;        proxy_set_header X-Real-IP $remote_addr;&#xA;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#xA;        proxy_set_header X-Forwarded-Host $server_name;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For example I want to create ""user-serivce"" which will be giving information about users. And I want it to give information about current user for ordinary user and information about all users for admins.</p>&#xA;&#xA;<p>For this opportunity passport service gives JWT token that contains rights information for user.</p>&#xA;&#xA;<p>So how I can create ""a middleware"" inside nginx which will do requests to ""passport-service"" to check if current JWT token has rights to access specified routes (ex., ""/service/users/{id}"")</p>&#xA;"
51651248,SpringBoot: Eureka server is not discovering OAuth2 secure microservice,2018-08-02 10:25:14,<spring-boot><microservices><eureka>,1,24,0,0.0,0,"<p>I have a Eurea server with config</p>&#xA;&#xA;<pre><code># Eureka configuration&#xA;&#xA;    eureka.instance.hostname: localhost&#xA;    eureka.client.registerWithEureka: false&#xA;    eureka.client.fetchRegistry: false&#xA;    eureka.client.serviceUrl.defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/&#xA;</code></pre>&#xA;&#xA;<p>Also, running two microservices of customer and orders with Eurea Discovery enabled. I want to access Orders microservice in customers microservice, but eureka is not discovering order microservice.</p>&#xA;&#xA;<p>In my both services, security is implemented that way</p>&#xA;&#xA;<pre><code>@Configuration&#xA;@EnableResourceServer&#xA;public class OAuth2ResourceServerConfig extends ResourceServerConfigurerAdapter {&#xA;&#xA;    @Override&#xA;    public void configure(HttpSecurity http) throws Exception {&#xA;        http.cors().and().csrf().disable()&#xA;                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)&#xA;                .and().authorizeRequests().antMatchers(""/api/**"").authenticated()&#xA;                .and().authorizeRequests().antMatchers(""/swagger-ui.html"").permitAll()&#xA;                .and().authorizeRequests().antMatchers(""/**"").authenticated();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please help.&#xA;Thanks.</p>&#xA;"
51579626,Delay feauture of RabbitMQ is not working,2018-07-29 11:02:39,<spring-boot><rabbitmq><microservices><spring-rabbitmq><rabbitmq-exchange>,2,25,0,0.0,0,"<p>I am using RabbitMQ in spring boot for sending messages over  microservices. I need to set up delay option for every message. This case I used MessageProperties file with Message and It likes this.</p>&#xA;&#xA;<pre><code> MessageProperties properties = new MessageProperties();&#xA;    properties.setDelay(15000);&#xA;    properties.setContentType(ContentType.APPLICATION_JSON.getMimeType());&#xA;    properties.setType(""direct"");&#xA;    properties.setHeader(""x-delay"",15000);&#xA;    properties.setHeader(""x-delayed-type"",""direct"");&#xA;    properties.setHeader(""x-delayed-message"",true);&#xA;    Message forSms = MessageBuilder.withBody(SerializationUtils.serialize(updatedAppointment.getId())).andProperties(properties).setCorrelationId(correlationIdForSms.getBytes()).setHeader(""x-delay"", 20000).setHeaderIfAbsent(""x-delay"", 20000).build();&#xA;rabbitTemplate.send(""auto.exch"", ""orderRoutingKey"", forSms);&#xA;and I handle it in this function:&#xA;&#xA;@RabbitListener(bindings = @QueueBinding(&#xA;        value = @Queue(value = ""myQueue"", durable = ""true""),arguments = @Argument(name = ""x-delay"",value = ""15000"",type = ""java.lang.Integer""),&#xA;        exchange = @Exchange(value = ""auto.exch"", delayed =""true"",ignoreDeclarationExceptions = ""true"",arguments = @Argument(name = ""x-delayed-type"",value = ""direct""), type = ExchangeTypes.HEADERS),&#xA;         key = ""orderRoutingKey"")&#xA;)&#xA;&#xA;public void sendMessagePatientPhone(final Message message) throws EntityNotFoundException {&#xA;    Long appointmentId = (Long) SerializationUtils.deserialize(message.getBody());&#xA;    String correlationId = new String(message.getMessageProperties().getCorrelationId());&#xA;&#xA;&#xA;    Appointment appointment = appointmentService.findById(appointmentId);&#xA;    User user = appointment.getPatient().getUser();&#xA;    String msg = ""Teleconference is started after "" + formattedTime(user.getNotificationPeriodForSms());&#xA;    sendSms(user, msg);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I get only empty header and messages are not beaing delayed. Maybe I am using wrong way but I need right solution. My basic aim is that delay every message with specific time </p>&#xA;"
51610138,"Spring config client configuration not updated with ""/actuator/refresh"" endpoint",2018-07-31 09:33:47,<spring-boot><microservices><spring-cloud-config>,1,29,0,0.0,0,"<p>I am using Spring 2.0.3. Database configuration of config client are getting from git repository via config server. </p>&#xA;&#xA;<p>I have changed database configuration and push back into the git.</p>&#xA;&#xA;<p>Then, I have called to ""<a href=""http://client_host/actuator/refresh"" rel=""nofollow noreferrer"">http://client_host/actuator/refresh</a>"" endpoint for load new configuration. </p>&#xA;&#xA;<p>I have already exposed the ""refresh"" endpoint in my application.yml file. &#xA;The results are,&#xA;Config server call to git repository and can manged to save new configuration in  ""/tmp/repos"".</p>&#xA;&#xA;<p>However config client couldn't update database configuration? </p>&#xA;&#xA;<p>Could you please help me to resolve this. </p>&#xA;"
51558885,definition of airflow dag for a use case with variable dependencies,2018-07-27 13:21:39,<microservices><oozie><airflow><luigi><azkaban>,1,33,0,0.0,0,"<p>I would like to use airflow for the following use-case :</p>&#xA;&#xA;<ul>&#xA;<li>Compute a daily report for a given website (~150 websites to handle). Each report will be computed as follows:&#xA;&#xA;<ul>&#xA;<li>A set of tasks that should be run at site level,</li>&#xA;<li>A set of tasks that should be run at page level, each website contanining ~ 10k pages.</li>&#xA;<li>Once both sets of tasks above are performed, a third set of tasks are run to aggregate the results and generate the report.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>Note : each airflow task described here is in fact a simple call to a remote micro-service (grpc call).</p>&#xA;&#xA;<p>The design I have in mind so far :</p>&#xA;&#xA;<ul>&#xA;<li>I initially wanted to perform all processes related to the pages in one task in order to have a simple, well-defined dag with only a few tasks.&#xA;But the treatment that needs to be performed on the page is complex, with external dependencies and queues (only trigger the next task if you receive notifications from external systems, those notifications may arrive several hours later) => I would like to use airflow to handle this process.</li>&#xA;<li>Given the point above, I'm now inclined towards a model whereby all the processes for one website are embeedded in one dag, including the tasks for the pages. Ideally I would like to use a subdag for the tasks related to pages but from what I read so far, this feature is not yet stable.&#xA;Each website will generate a new dag, with a new set of tasks (because the structure of the dag depends on the number of pages).&#xA;The number of tasks per dag will therefore be relatively important (10k).</li>&#xA;</ul>&#xA;&#xA;<p>My questions :</p>&#xA;&#xA;<ul>&#xA;<li>Is airflow an acceptable framework for this use case (i.e did you run similar use cases) or do alternative frameworks such as luigi, oozie ... present clear advantages in that context ?</li>&#xA;<li>Is the approach above (one dag per website, no subdag, include page tasks in the dag) a sound one ? Do you foresee any issue with this ?</li>&#xA;<li>Is the web ui still usable with that number of tasks ? I did a quick test with a few hundreds tasks and I got several timeouts, I'm wondering if it is linked to my configuration or not.</li>&#xA;<li>Is celery the correct backend for this ? I'm wondering if ""LocalExecutor"" would in fact be more appropriate for this use case, given that there is in fact no computation performed directly by the airflow workers (they only call remote services).</li>&#xA;</ul>&#xA;"
51665264,Is it wise to stream file over vertx event bus,2018-08-03 04:17:44,<java><microservices><vert.x>,1,35,0,0.0,0,"<p>We have set of services in a vertx cluster. We serve web front end through a API gateway which is one service within the cluster. Client ask a requirement for download some data as a CSV file. It should be transmitted as bellow.</p>&#xA;&#xA;<p>Service A --(Event bus)---> API gateway ---(Web socket)---> Browser</p>&#xA;&#xA;<p>My question is, is it wise to stream such file over event bus from Service A to API gateway? (File may get as large as 100 MB)</p>&#xA;"
51673608,Microservice architecture with ONE Websocket connection with every browser,2018-08-03 13:20:02,<websocket><architecture><microservices>,1,38,0,0.0,0,"<p>Following the typical microservice REST architecture &#xA;where multiple servers run up and expose different controllers , providing services for each feature individually.</p>&#xA;&#xA;<p>My question is this:</p>&#xA;&#xA;<p>Assuming my business logic = A realtime web application which requires real time computing and real time responsiveness, where multiple clients in the application communicating with each-other.</p>&#xA;&#xA;<p>My options are limited to only using websocket connection between every browser and to have mediator servers connecting between them.</p>&#xA;&#xA;<p>But, the architecture is abit obscured to me, since I'm not interested in a monolith mediator!</p>&#xA;&#xA;<p>If I follow the REST microservice architecture, I'll force every browser to open multiple/alot-of socket connections which isn't my goal</p>&#xA;&#xA;<p>My approach is to consume all socket events through ONE socket connection from each client and in the backend realm, deal with it </p>&#xA;&#xA;<p>My imagination takes me further to imagine an architecture of multiple microservices as the following:</p>&#xA;&#xA;<ol>&#xA;<li>socket handler service</li>&#xA;<li>feature 1 service </li>&#xA;<li>feature 2 service</li>&#xA;</ol>&#xA;&#xA;<p>all connected with internal sockets as if like one big backend mesh</p>&#xA;&#xA;<p>But that would fail since I'm in need for scaling out...&#xA;scaling every feature backend server to support millions of requests per second..</p>&#xA;&#xA;<p>so that will bring me to maintain clusters of each that correlate with eachother? </p>&#xA;&#xA;<p>By reading this , you might possibly understand the reason for this topic&#xA;Need some architectural thoughts.</p>&#xA;&#xA;<p>My pursue for high maintainability and performance want a sophisticated architecture&#xA;but the more I think about it the more I go back to the monolith approach. </p>&#xA;&#xA;<p>Is there any recommended architecture?</p>&#xA;"
51552739,How we can achieve Microservices related functionality with Loopback Framework,2018-07-27 07:18:52,<node.js><microservices><strongloop><loopback>,1,42,0,0.0,0,"<p>I need your help in Loopback Framework.&#xA;Actually, my need is how we can achieve Microservices related functionality with Loopback Framework.</p>&#xA;&#xA;<p>Please share any links/tutorials/knowledge if you have any.&#xA;I have gone through below links,&#xA;<a href=""https://strongloop.com/strongblog/creating-a-multi-tenant-connector-microservice-using-loopback/"" rel=""nofollow noreferrer"">https://strongloop.com/strongblog/creating-a-multi-tenant-connector-microservice-using-loopback/</a></p>&#xA;&#xA;<p>I have downloaded the related demo from below links but doesn't work it.&#xA;<a href=""https://github.com/strongloop/loopback4-example-microservices"" rel=""nofollow noreferrer"">https://github.com/strongloop/loopback4-example-microservices</a>&#xA;<a href=""https://github.com/strongloop/loopback-example-facade"" rel=""nofollow noreferrer"">https://github.com/strongloop/loopback-example-facade</a></p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
51602388,API Gateway Design,2018-07-30 21:14:44,<architecture><microservices><api-gateway>,1,42,0,0.0,0,"<p>Api gateway <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a> seems to be a good pattern to be adopted in Micro Service architecture(Not internal communication between services).</p>&#xA;&#xA;<p>But I have below queries  </p>&#xA;&#xA;<ol>&#xA;<li><p>I am unable to understand how API Gateways should be designed itself. We can't have just one api gateway for all services. For example for Uber we have &#xA;<strong>Trip, Cabs, Driver, User, Pricing</strong> Micro Services, so how many API Gateways should we design.</p></li>&#xA;<li><p>In  <a href=""https://medium.com/netflix-techblog/optimizing-the-netflix-api-5c9ac715cf19"" rel=""nofollow noreferrer"">https://medium.com/netflix-techblog/optimizing-the-netflix-api-5c9ac715cf19</a> what does Dynamic Endpoints means.</p></li>&#xA;</ol>&#xA;&#xA;<p>I was thinking like in Uber case,to display user first page we will need cabs and pricing. So we will expose an API in api-gateway some /home and from here asynchronously we will call Pricing and Cabs api will merge and return the response. Is there any batter way to do this? </p>&#xA;"
51734131,How To Use ElasticSearch as a search Engine for relational structure in a micro-services envirement,2018-08-07 19:30:13,<database><elasticsearch><nosql><microservices><search-engine>,1,52,0,1.0,0,"<p>Iâ€™m working on an application that is using a relational database <code>Mysql</code> for most of the entities and it is constructed in a microservices architecture and each service is using a separate MYSQL database.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/KiqEL.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KiqEL.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Now Iâ€™m trying to implement a search engine for publications using elasticsearch as a middleware funnel to be able to search by all entities that are related to the publication object even from different services with different databases.</p>&#xA;&#xA;<p><strong>What will be the best way to index the publication object?</strong></p>&#xA;&#xA;<ul>&#xA;<li>I have 3 options in mind:&#xA;&#xA;<ul>&#xA;<li>Create a full publication type with multi-nested object types?&#xA;&#xA;<ul>&#xA;<li>problems:</li>&#xA;<li>Duplication of all the entities from different services</li>&#xA;<li>Hard to update for example in case of updating an instruction</li>&#xA;</ul></li>&#xA;<li>Create a different publication type with all fields from other objects then normalize the data when inserting or finding the data.&#xA;&#xA;<ul>&#xA;<li>problems:</li>&#xA;<li>normalizing data on inserting and on finding is costly</li>&#xA;<li>hard to maintain and to update</li>&#xA;</ul></li>&#xA;<li>Insert multiple separated types similar to the relational database then do multiple queries to find the final object, for example, if we want to find a publication by user_name we have to find the user first then use the user_id to find the publications.&#xA;&#xA;<ul>&#xA;<li>problems:</li>&#xA;<li>we have to make more than 1 query to get valid results</li>&#xA;</ul></li>&#xA;<li>Use has_parent, has_child relation but in this case the child is publication and it is having multiple many-to-one relations so multiple parents.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I could be going in the wrong direction please share your feedback if you think I should use a different technology</p>&#xA;"
51557001,Spring Cloud Netflix & Spring Cloud Data Flow microservice arheticture,2018-07-27 11:27:00,<microservices><spring-cloud><spring-cloud-stream><spring-cloud-netflix><spring-cloud-dataflow>,1,69,0,0.0,0,"<p>I'm developing an application that must both handle events coming from other systems and provide a REST API. I want to split the applications into micro services and I'm trying to figure out which approach I should use. I drew attention to the Spring Cloud Netflix and the Spring Cloud Data Flow toolkit, but it's not clear to me whether they can be integrated and how.</p>&#xA;&#xA;<p>As an example, suppose we have the following functionality in the system:&#xA;1. information about users</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>card of orders</li>&#xA;<li>product catalog</li>&#xA;<li>sending various notifications</li>&#xA;<li>obtaining information about the orders from third-party systems</li>&#xA;<li>processing, filtering, and transformation of order events</li>&#xA;<li>processing of various rules based on orders and sending notifications</li>&#xA;<li>sending information about user orders from third-party systems to other users using websockets (with pre-filtering)</li>&#xA;</ol>&#xA;&#xA;<p>Point 1-4 - there I see the classical micro service architecture. Framework - Spring Netflix Stack.&#xA;Point 5-9 - it's best to use an event-driven approach. Toolkit - Spring Data Flow.</p>&#xA;&#xA;<p>The question is how to build communication between these platforms.&#xA;In particular - POPULATE ORDER DETAILS SERVICE must transform the incoming orders and save additional information (in case it needed) in the database. ORDER RULE EXECUTOR SERVICE should obtain information about the current saved rules, execute them and send notifications. WEB SOCKET SERVICE should send orders information only if a particular user has set the filters, and ORDER SAVER SERVICE should store the information about the transformed orders in the database.</p>&#xA;&#xA;<p>1.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eCqZ8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eCqZ8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Communication between the micro-services within the two platforms could be using the API GATEWAY, but in this case, I have the following questions:</p>&#xA;&#xA;<ul>&#xA;<li>Does the Spring Cloud platform allow to work with micro services that way?</li>&#xA;<li>Performance - the number of events is very huge, which can significantly slow down the processing of events. Is it possible to use other approaches, for example, communication not through the API Gateway but through in-memory cache?</li>&#xA;</ul>&#xA;&#xA;<p>2.&#xA;<a href=""https://i.stack.imgur.com/LnMWL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LnMWL.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Since some functionality intersects between these services, I have a question about what is ""microservice"" in the understanding of the Spring Cloud Stream framework. In particular, does it make sense to have separate services? Can the microservice in the Spring Cloud Stream have a REST API, work with the database and simultaneously process the events? Does such a diagram make sense and is it possible to build such a stack at the moment?</p>&#xA;&#xA;<p>The question is which of these approaches is more correct? What did Spring Data Streams mean by ""microservice""?</p>&#xA;"
51603557,Spring microservice jwt authentication,2018-07-30 23:30:50,<spring><jwt><microservices><netflix-zuul><okta>,1,69,0,0.0,0,"<p>I have been trying to build a spring distributed application that works on JWT.&#xA;Github repo -  <a href=""https://github.com/dhananjay12/spring-microservice-demo"" rel=""nofollow noreferrer"">https://github.com/dhananjay12/spring-microservice-demo</a></p>&#xA;&#xA;<p><strong>Service Description</strong></p>&#xA;&#xA;<ul>&#xA;<li>product-service : A simple downstream service having protected routes</li>&#xA;<li>jwt-resoure-server : A jar that when included in downstream services make it a rsourceserver that extract jwt token and set it in security contex.</li>&#xA;<li>eureka-service : Discovery service</li>&#xA;<li>zuul-server : Edge server</li>&#xA;</ul>&#xA;&#xA;<p>Now product-service with jwt-resoure-server , works fine:&#xA;<a href=""https://i.stack.imgur.com/3G7dt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3G7dt.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Setting up zuul and eureka:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/52AZp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/52AZp.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But if I hit from the zuul server I get the following error:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/2MwkA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2MwkA.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I am using okta for authentication. I am not sure, where the error is coming from. Is it zuul not passing the token or some place else.</p>&#xA;&#xA;<p>Any help would be appreciated. Thanks.</p>&#xA;"
51573236,How to properly use express-gateway for authentication of a web app?,2018-07-28 16:31:17,<node.js><express><microservices><api-gateway><express-gateway>,1,86,0,0.0,0,"<p>I am fairly new to the concept of microservices and api gateways in general. I am trying to understand the role that an api gateway plays in a modern web application using many microservices. I have been reading the documentation and tutorials of express-gateway but am a bit confused on how a web application would perform authentication with an api gateway set up like express-gateway.</p>&#xA;&#xA;<p>My web app would have multiple microservices that it would talk to. I thought that putting an API gateway in front of all my microservices would make it so that each microservice would not need to worry about whether a user/request is authenticated or not, because if the microservice was being talked to it meant that the api gateway had verified the request was a valid user. Is my understanding of this correct?</p>&#xA;&#xA;<p>Assuming that my thought of the api gateway serving as a gatekeeper to other microservices is correct, my follow up question is with the specifics of how it is performed.</p>&#xA;&#xA;<p>Does this mean that all user creation and authentication is performed by the api gateway? Meaning that I would have no custom user creation/login microservices? Or would I have a publically reachable through the api gateway custom user creation microservice which upon creation would itself create the user accounts within the api gateway? Is user information now duplicated by my microservice in a database somewhere and the express-gateway's own storage? I guess my general confusion is around does an api gateway take the role of authentication/user creation entirely away from a web app's own microservices, or do you still need both parts?</p>&#xA;&#xA;<p>I thought that my own authentication microservice would first validate a user then work with the api gateway to generate a valid short lived token, but reading about creating user or app accounts for authentication in express-gateway has made me confused on the roles each play.</p>&#xA;"
51740873,integration test in .Net for rest api between two microservices,2018-08-08 07:27:49,<.net><rest><asp.net-web-api2><integration-testing><microservices>,1,29,1,0.0,0,"<p>What is the proper way to perform an integration test between two microservices that communicate between them self in REST API?</p>&#xA;&#xA;<p>Say I want to post data from one microservice to another, how can I mock the sending from one point and receiving it on the other end, and be able to validate that the data is correct.</p>&#xA;&#xA;<p>What is the right way of doing that, in .Net if possible? </p>&#xA;"
51586999,How to refresh a HashMap in Java which is already loaded during startup using @PostConstruct annotation,2018-07-30 04:30:57,<java-8><hashmap><microservices><spring-webflux>,1,40,1,0.0,0,"<p>I'm working on a Java application(micro-services) using Spring 5, JDK 1.8, SpringBoot 2.0. I got a helper class where I'm loading a hashmap using the @PostConstruct like below :-</p>&#xA;&#xA;<p><strong>Helper class:-</strong></p>&#xA;&#xA;<pre><code>private final Map&lt;String, CommonData&gt; empMap = new HashMap&lt;&gt;();&#xA;&#xA;@PostConstruct&#xA;public void init() {&#xA;    loadEmpMap();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>private void loadEmpMap() {</p>&#xA;&#xA;<pre><code>List&lt;EmpMap&gt; employees = empRepo.getEmpInfo();&#xA;employees&#xA;    .forEach(p -&gt; empMap&#xA;        .put(p.getEmpId(),&#xA;            new CommonData(p.getName(), p.getDesignation(), p.getContactNumber())));&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>Now during the application startup, @PostConstruct will be called and HashMap will be loaded with data using <strong>JPA Repository</strong>. This HashMap will be available through out this object to use. Now my requirement is to update (auto-refresh) this HashMap with new set of data (ofcourse entity refresh) whenever there is an update/save operation on entity. For this, I have written an Interface like below to Refresh the entity using the EntityManager :-</p>&#xA;&#xA;<pre><code>import org.springframework.data.jpa.repository.JpaRepository;&#xA;import org.springframework.data.repository.NoRepositoryBean;&#xA;&#xA;import java.io.Serializable;&#xA;&#xA;@NoRepositoryBean&#xA;public interface CustomRepository&lt;T, ID extends Serializable&gt; extends JpaRepository&lt;T, ID&gt; {&#xA;  void refresh(T t);&#xA;&#xA;}&#xA;&#xA;&#xA;public class CustomRepositoryImpl&lt;T, ID extends Serializable&gt;&#xA;    extends SimpleJpaRepository&lt;T, ID&gt; implements CustomRepository&lt;T, ID&gt; {&#xA;&#xA;  private final EntityManager entityManager;&#xA;&#xA;  @Autowired&#xA;  public CustomRepositoryImpl(JpaEntityInformation entityInformation,&#xA;      EntityManager entityManager) {&#xA;    super(entityInformation, entityManager);&#xA;    this.entityManager = entityManager;&#xA;&#xA;  }&#xA;&#xA;  @Override&#xA;  @Transactional&#xA;  public void refresh(T t) {&#xA;    entityManager.refresh(t);&#xA;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And then extending this custom repository to my application respository like below :-</p>&#xA;&#xA;<pre><code>@Repository&#xA;public interface EmpRepo extends CustomRepository&lt;Employee, EmpKey&gt; {&#xA;&#xA;}&#xA;&#xA;&#xA;public final class CommonRepositoryDetails implements EmpRepo {&#xA;&#xA; private EmpRepo empRepo;&#xA;&#xA; constructor(){&#xA;&#xA; }&#xA;&#xA;  XYZMethod(){&#xA;    -------&#xA;    ---- some line of code for save/update operation using Jpa -----&#xA;    -- then trying to refresh the entity as below -----&#xA;&#xA;    empRepo.refresh(value);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm not sure whether this will refresh my hashmap again with latest objects from entity to be used or Im missing something here. Please let me know as I want to refresh my HashMap again. Thanks</p>&#xA;"
51634486,Master Slave configuration for Spring Boot Microservices,2018-08-01 13:24:24,<spring-boot><microservices><master-slave>,1,55,1,0.0,0,"<p>I have a Spring boot application (Micro-service) running on Two nodes and registered with Eureka Naming server. My requirement is as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>An Autosys job will trigger one complex calculation in micro-service which will take about 45 minutes to complete. Result of this calculation will be saved to Gemfire cache and database. I want these two nodes act as Master-Slave where only Master node will take up and execute the request of complex calculation. If master goes down then only slave will become master and will be responsible for execution of complex calculation.</p></li>&#xA;<li><p>Another catch is while complex calculation is running, if adhoc request for the same calculation comes; latest request needs to be rejected saying calculation is already running.</p></li>&#xA;</ol>&#xA;&#xA;<p>I explored the possibility to use Apache <a href=""https://www.ibm.com/developerworks/library/bd-zookeeper/index.html"" rel=""nofollow noreferrer"">ZooKeeper</a> but it doesn't seem to satisfy my requirement of serving the request only using Master node.</p>&#xA;&#xA;<p>Is there any way of achieving this?</p>&#xA;"
51676756,org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name. Couldn't get my springboot application running,2018-08-03 16:29:43,<java><spring><spring-boot><spring-data-jpa><microservices>,1,61,1,0.0,0,"<p>I am new to Microservices and started building one with a simple Get and Post implementations. I am getting an error about bean creation and unsatisfied Dependency Exception. Please find my code attached.&#xA;Any help is appreciated. &#xA;Thanks in advance.</p>&#xA;&#xA;<p><strong>DbServiceApplication.java(under package com.example.dbservice)</strong></p>&#xA;&#xA;<pre><code>package com.example.dbservice;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.data.jpa.repository.config.EnableJpaRepositories;&#xA;&#xA;@EnableJpaRepositories(basePackages = ""com.example.dbservice.repository"")&#xA;@SpringBootApplication&#xA;public class DbServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(DbServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>QuotesRepository.java (under package com.example.dbservice.repository)</strong></p>&#xA;&#xA;<pre><code>package com.example.dbservice.repository;&#xA;&#xA;import com.example.dbservice.model.Quote;&#xA;import org.springframework.data.jpa.repository.JpaRepository;&#xA;import org.springframework.stereotype.Repository;&#xA;import org.springframework.stereotype.Service;&#xA;&#xA;import java.util.List;&#xA;&#xA;@Repository&#xA;public interface QuotesRepositpory extends JpaRepository&lt;Quote, Integer&gt; {&#xA;    List&lt;Quote&gt; findByUserName(String username);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>DbServiceResource (under repository com.example.dbservice.resource)</strong></p>&#xA;&#xA;<pre><code>package com.example.dbservice.resource;&#xA;&#xA;&#xA;import com.example.dbservice.model.Quote;&#xA;import com.example.dbservice.model.Quotes;&#xA;import com.example.dbservice.repository.QuotesRepositpory;&#xA;import org.springframework.web.bind.annotation.*;&#xA;&#xA;import java.util.List;&#xA;import java.util.stream.Collectors;&#xA;&#xA;@RestController&#xA;@RequestMapping(""/rest/db"")&#xA;public class DbServiceResource {&#xA;&#xA;    private QuotesRepositpory quotesRepository;&#xA;&#xA;    public DbServiceResource(QuotesRepositpory quotesRepository) {&#xA;        this.quotesRepository = quotesRepository;&#xA;    }&#xA;&#xA;    @GetMapping(""/{username}"")&#xA;    public List&lt;String&gt; getQuotes(@PathVariable(""username"")&#xA;                                  final String username){&#xA;&#xA;        return quotesRepository.findByUserName(username)&#xA;                .stream()&#xA;                .map(Quote::getQuote)&#xA;                .collect(Collectors.toList());&#xA;&#xA;    }&#xA;&#xA;&#xA;    @PostMapping(""/add"")&#xA;    public List&lt;String&gt; add(@RequestBody final Quotes quotes){&#xA;        return null;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml Dependencies</strong></p>&#xA;&#xA;<pre><code>&lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;mysql&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.hibernate&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;4.1.4.Final&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.hibernate&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt;&#xA;            &lt;version&gt;5.2.3.Final&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Error Stack trace</strong></p>&#xA;&#xA;<pre><code>  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v2.0.4.RELEASE)&#xA;&#xA;2018-08-03 12:02:21.462  INFO 10968 --- [           main] c.t.s.dbservice.DbServiceApplication     : Starting DbServiceApplication on JAGWANIA01 with PID 10968 (C:\Users\jagwania\Desktop\db-service\target\classes started by jagwania in C:\Users\jagwania\Desktop\db-service)&#xA;2018-08-03 12:02:21.469  INFO 10968 --- [           main] c.t.s.dbservice.DbServiceApplication     : No active profile set, falling back to default profiles: default&#xA;2018-08-03 12:02:21.675  INFO 10968 --- [           main] ConfigServletWebServerApplicationContext : Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@5c86a017: startup date [Fri Aug 03 12:02:21 CDT 2018]; root of context hierarchy&#xA;WARNING: An illegal reflective access operation has occurred&#xA;WARNING: Illegal reflective access by org.springframework.cglib.core.ReflectUtils$1 (file:/C:/Users/jagwania/.m2/repository/org/springframework/spring-core/5.0.8.RELEASE/spring-core-5.0.8.RELEASE.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)&#xA;WARNING: Please consider reporting this to the maintainers of org.springframework.cglib.core.ReflectUtils$1&#xA;WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations&#xA;WARNING: All illegal access operations will be denied in a future release&#xA;2018-08-03 12:02:24.991  INFO 10968 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$cc6bebb7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2018-08-03 12:02:25.877  INFO 10968 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8300 (http)&#xA;2018-08-03 12:02:25.936  INFO 10968 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]&#xA;2018-08-03 12:02:25.936  INFO 10968 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.32&#xA;2018-08-03 12:02:25.960  INFO 10968 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jdk-10.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\nodejs\;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\Geth;C:\Program Files\Git\cmd;C:\Program Files\Git\bin;C:\Program Files\Java\jdk-10.0.2\bin;C:\Program Files\apache-maven-3.5.4-bin\apache-maven-3.5.4\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\jagwania\AppData\Roaming\npm;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;.]&#xA;2018-08-03 12:02:26.255  INFO 10968 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext&#xA;2018-08-03 12:02:26.255  INFO 10968 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 4587 ms&#xA;2018-08-03 12:02:26.433  INFO 10968 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Servlet dispatcherServlet mapped to [/]&#xA;2018-08-03 12:02:26.441  INFO 10968 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]&#xA;2018-08-03 12:02:26.441  INFO 10968 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]&#xA;2018-08-03 12:02:26.441  INFO 10968 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]&#xA;2018-08-03 12:02:26.441  INFO 10968 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]&#xA;2018-08-03 12:02:26.802  INFO 10968 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;2018-08-03 12:02:27.352  INFO 10968 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.&#xA;2018-08-03 12:02:27.448  INFO 10968 --- [           main] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;2018-08-03 12:02:27.487  INFO 10968 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [&#xA;    name: default&#xA;    ...]&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;Fri Aug 03 12:02:27 CDT 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.&#xA;2018-08-03 12:02:27.894  INFO 10968 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.2.17.Final}&#xA;2018-08-03 12:02:27.898  INFO 10968 --- [           main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found&#xA;2018-08-03 12:02:27.928  WARN 10968 --- [           main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException&#xA;2018-08-03 12:02:27.928  INFO 10968 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...&#xA;2018-08-03 12:02:27.964  INFO 10968 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.&#xA;2018-08-03 12:02:27.969  INFO 10968 --- [           main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]&#xA;2018-08-03 12:02:27.993  INFO 10968 --- [           main] ConditionEvaluationReportLoggingListener : &#xA;&#xA;Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.&#xA;2018-08-03 12:02:28.005 ERROR 10968 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xA;&#xA;org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1699) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:573) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1089) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:859) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:398) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:330) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.example.dbservice.DbServiceApplication.main(DbServiceApplication.java:12) [classes/:na]&#xA;Caused by: java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException&#xA;    at org.hibernate.boot.spi.XmlMappingBinderAccess.&lt;init&gt;(XmlMappingBinderAccess.java:43) ~[hibernate-core-5.2.17.Final.jar:5.2.17.Final]&#xA;    at org.hibernate.boot.MetadataSources.&lt;init&gt;(MetadataSources.java:87) ~[hibernate-core-5.2.17.Final.jar:5.2.17.Final]&#xA;    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.&lt;init&gt;(EntityManagerFactoryBuilderImpl.java:209) ~[hibernate-core-5.2.17.Final.jar:5.2.17.Final]&#xA;    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.&lt;init&gt;(EntityManagerFactoryBuilderImpl.java:164) ~[hibernate-core-5.2.17.Final.jar:5.2.17.Final]&#xA;    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:51) ~[spring-orm-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1758) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1695) ~[spring-beans-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    ... 16 common frames omitted&#xA;Caused by: java.lang.ClassNotFoundException: javax.xml.bind.JAXBException&#xA;    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) ~[na:na]&#xA;    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:190) ~[na:na]&#xA;    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:499) ~[na:na]&#xA;    ... 27 common frames omitted&#xA;&#xA;&#xA;Process finished with exit code 1&#xA;</code></pre>&#xA;"
51697673,"Microservice design with Kubernetes - API gateway, communication, service discovery and db issues",2018-08-05 19:42:13,<node.js><database><rest><kubernetes><microservices>,1,69,1,2.0,0,"<p>Recently I have been researching about microservices and kubernetes. All the tutorial and article I read online talks about general staff. I have several specific questions about building a microservices app on kubernetes.</p>&#xA;&#xA;<ol>&#xA;<li><strong>API gateway:</strong> Is API gateway a microservice I built for my app that can automatically scale? Or is it already a built-in function of kubernetes? The reason I ask is because a lot of the articles are saying that load-balancing is part of the API gateway which confuse me since in kubernetes, load-balancing is handled by <code>service</code>. Also, is this the same as the API gateway on AWS, why don't people use the AWS API gateway instead?</li>&#xA;<li><strong>Communication within services:</strong> from what I read only, there are <em>Rest/RPC</em> way and <em>Message queue</em> way. But why do people say that the <em>Rest</em> way is for sync operation? Can we build the services and have them communicate with rest api with <code>Nodejs async/await</code> functions? </li>&#xA;<li><strong>Service Discovery:</strong> Is this a problem with kubernetes at all? Does kubernetes automatically figure out this for you?</li>&#xA;<li><strong>Databases:</strong> What is the best practice to deploy a database? Deploy as a microservice on one of the node? Also, some articles say that each service should talk to a different db. So just separate the tables of one db to several dbs?</li>&#xA;</ol>&#xA;"
51682257,Using Swagger to Manage Microservice Architecture Across IIS Express,2018-08-04 03:50:52,<reactjs><visual-studio><swagger><asp.net-core-2.0><microservices>,1,28,2,0.0,0,"<p>I'm coming into an existing application where a single React application exists that calls multiple APIs. The APIs are written in .NET Core and I've been instructed they are typically hosted with IIS Express when debugging locally.</p>&#xA;&#xA;<p>Where I'm running into trouble is understanding how the React application will hit the backend API projects, when the API projects are running on multiple IIS Express instances that don't have static ports.</p>&#xA;&#xA;<p>For instance, I'll hit ""run"" on the React project which launches the React application along with a controller that might be running on localhost:5888. I can easily hit the controller from the React application using <code>window.host + /Controller/</code> which will handle resolving the port for me. However, if I ""run"" another API, from a separate Visual Studio instance, it'll get hosted on a random port, something like localhost:5889. If I try to hit that API with <code>window.host + /SecondAPIMethod/</code> from the React application, it'll come up with a 404 error, because the React app doesn't know what port the IIS express instance with the second API is running on.</p>&#xA;&#xA;<p>I've been told by coworkers that Swagger is the key to managing this, but I'm unsure how.</p>&#xA;"
51670858,Is it better to put multiple files in background job or a single file?,2018-08-03 10:41:30,<php><rest><api><microservices><beanstalkd>,1,34,2,0.0,0,"<p>Few months ago i asked <a href=""https://stackoverflow.com/questions/49625076/obtaining-result-from-async-api"">this</a> about the implementation of my api for processing files it uses PHP, a command line script that is called via PHP and queue. For the queue i am using beanstalkd</p>&#xA;&#xA;<p>The API accepts one file or group of files (up to 5) per request. Processing one file takes 1-3 seconds depending of the size. </p>&#xA;&#xA;<p>My question now is whatever will be better, to put every file of the request to a separate job or all the files in one job? My function for processing that is slow accepts one or multiple files. My guess is that i put the all the files of the request on processing, they will be processed by one worker. But if i put every file into separate background job it will be probably processed by own worker so 4 files 4 workers - that is what i think. Not sure if this is correct.</p>&#xA;&#xA;<p>So if my above conclusion is correct, is it better for a lot of requests to process all files in once or add them separate worker?</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
51733502,Micro Services and Transaction Manager how to handle concurrency Issue,2018-08-07 18:46:11,<java><concurrency><microservices><distributed-transactions><optimistic-locking>,2,40,2,0.0,0,<p>I am working on building a microservice which is using transaction manager implemented based on Java Transaction API(JTA).</p>&#xA;&#xA;<p>My question is does Trasaction maanger have ability to handle concurrency issue in distributed database scenario's .</p>&#xA;&#xA;<p><strong>Scenario:</strong></p>&#xA;&#xA;<p>Assume there are multiple instance of a service running and we get two requests to update balance amount by 10 in an account. Initially an account can have $100 and the first instance gets that and increments it to $10 but has not been commited yet. </p>&#xA;&#xA;<p>At the same time the second instance also retreive's account which is still 100 and increments it by $10 and then commits it updating balance to $110 and then service one updates account again to $110.</p>&#xA;&#xA;<p>By this time you must have figured that balance was supposed to be incremented by $20 and not 10. Do I have to write some kind of Optimistic lock exception mechanism to prevent the above scenario or will Transaction Manager based on JTA specification already ensure such a thing will not happen ?</p>&#xA;
51623293,what are the best approaches (practices) to create stateful microservices?,2018-07-31 23:07:41,<spring><microservices><stateful>,2,60,2,0.0,0,"<p>I need to create a food ordering service, using microservices, scalable , cluster, several steps to order. Need to store user data between steps / requests.</p>&#xA;&#xA;<p>What is an approach to keep state and user data? Store it in DB? Cache? Shared memory?&#xA;Are there any tutorials for the best practice of it?</p>&#xA;&#xA;<p>(I gonna use spring / springboot and modules)</p>&#xA;"
51679363,multi-module Maven project on Dockers,2018-08-03 19:57:38,<java><maven><docker><pom.xml><microservices>,1,43,3,0.0,0,"<p>I have a multi-module maven project where the single modules are all runnable microservice applications containing their own Dockerfile, so in production every module will be a containerized application.</p>&#xA;&#xA;<p>The parent project, which contains the child-modules only contains the parent pom.xml and the docker-compose.yml</p>&#xA;&#xA;<p>I have tried to use the following Dockerfile (on sub-module level):</p>&#xA;&#xA;<pre><code>FROM sgrio/java-oracle&#xA;&#xA;RUN apt-get update&#xA;&#xA;RUN apt-get install -y maven&#xA;&#xA;COPY ../pom.xml /usr/local/service/Oogaday/pom.xml&#xA;&#xA;COPY pom.xml /usr/local/service/Oogaday/OogadayApi/pom.xml&#xA;&#xA;COPY src /usr/local/service/Oogaday/OogadayApi/src&#xA;&#xA;WORKDIR /usr/local/service/Oogaday/OogadayApi/&#xA;&#xA;RUN mvn package -DskipTests&#xA;&#xA;CMD [""java"",""-jar"",""org.oogaday.api-1.0-SNAPSHOT-jar-with-dependencies.jar""]&#xA;</code></pre>&#xA;&#xA;<p>But I am getting a security error because I am  trying to copy the parent pom.xml file (which is not placed in the directory from which I am running the build).</p>&#xA;&#xA;<p>So is there a way to build a maven based sub-module with parent pom?</p>&#xA;"
51566509,In Microservices is it acceptable to have an API returning an Aggregate Root that was replicated?,2018-07-27 22:56:45,<domain-driven-design><microservices><multiple-databases><aggregateroot>,3,72,7,0.0,0,"<p>Imagine we have a microservice M1 with an aggregate root called <code>Player</code> and a microservice M2 with an aggregate root called <code>Classification</code>, now in the M1 we need to do some logic based on some property from <code>Classification</code>, now some steps to do that are:</p>&#xA;&#xA;<ol>&#xA;<li>Replicate the list of possible Classifications to M1 via asynchronous messaging;</li>&#xA;<li>Do what is asked by the business in M1;</li>&#xA;</ol>&#xA;&#xA;<p>Ok, now imagine we have a view to add Players, and in that view is possible to choose the <code>Classification</code> of the new <code>Player</code> from a dropdown list. Now the question:</p>&#xA;&#xA;<p>Should the dropdown list be populated with the Classifications that were replicated into M1 or from M2?</p>&#xA;&#xA;<p>As you can see, by using the data from M1 we would have to expose the <code>Classification</code> from M1 via an API, thus the title of the question.</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>The replications happens through async messaging using events, so I'm not exposing the entire aggregate to M1 just some properties like an Id and the Description of the classification.</p>&#xA;"
42006876,Is communication between to Java processes still within Microservices?,2017-02-02 16:02:48,<java><rest><components><microservices>,1,40,0,0.0,0,"<p>Actually I'm about to realise some microservices architecture.&#xA;Having three different processes running on one Windowns machine I'm about to let them communicate with each other.</p>&#xA;&#xA;<p>Is this in the paradigma of Microservices? Or am I'm pushing this too far?</p>&#xA;&#xA;<p><strong>Context</strong>: A system which lets a frontend webapp execute tools/scripts which lie on a backend machine on a server.</p>&#xA;&#xA;<p><strong>Components</strong>:</p>&#xA;&#xA;<ul>&#xA;<li><strong>REST Interface</strong> (with which the webapp frontend does communicate)</li>&#xA;<li><strong>ToolBoxExecutor</strong> (with which the REST Controller is communicating)</li>&#xA;<li><strong>ToolSyncer</strong> (which is being ""triggered"" by the ToolBoxExectutor to refresh all Git Repositories for the tools)</li>&#xA;</ul>&#xA;&#xA;<p>Those three components do not have a big load of logic - but I still want them NOT to act as Services of the REST Controller - just for the sake of ""microservices"". I want them all to be three independent java applications.</p>&#xA;&#xA;<p><em>Am I on the right track?</em></p>&#xA;"
42060090,How mule api manager manage spring boot based service?,2017-02-06 03:52:07,<spring-boot><mule><microservices>,1,555,0,1.0,0,"<p>I've created a spring boot based service and like to deploy it to existing mule API platform, then I realize there are some challenges I need to face by myself such as, service discovery and policy management. </p>&#xA;&#xA;<p>To be specific, I want to know if there is any way to manage policy for spring boot service from mule API manager? Since there is no agent that mule service has.</p>&#xA;"
42115903,Should a single microservice be both public and internal simultaneously,2017-02-08 14:32:20,<design-patterns><microservices><restful-architecture>,1,68,0,0.0,0,"<p>There are three microservices in place:</p>&#xA;&#xA;<p><strong>Authors</strong> <br>&#xA;which has the ability to SELECT and CRUD entity ""author""</p>&#xA;&#xA;<p><strong>Books</strong> <br>&#xA;which has the ability to SELECT and CRUD entity ""book""</p>&#xA;&#xA;<p><strong>Mobile app host</strong> <br>&#xA;built especially for the mobile client to respond with full data model requested, so that the mobile app would not 'enrich' data on its end. <br></p>&#xA;&#xA;<p>Example: API 'MobileHost.getAllBooksOfGivenAuthor' will respond with both author name and book names, by calling 'Authors.getAuthorData(authorId)' and merging its data with 'Books.getBooksByAuthorIds(authorId)' resulting in a structure like this:</p>&#xA;&#xA;<pre><code>{ &#xA;  ""author"" : {&#xA;    ""name"" : ""Winner"",&#xA;    ""id"" : 1&#xA;  },&#xA;  ""books"" : [&#xA;     {&#xA;       ""name"" : ""Book A"",&#xA;       ""id"" : ""13231231""&#xA;     }&#xA;   ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My <strong>question</strong> is: <br>&#xA;If the mobile client reads data through ""Mobile app host"" should it do ""add author"" through ""Mobile app host"" also, or is it ok to contact the ""Authors"" service directly? Should CRUD be proxied in such a case or not?</p>&#xA;"
42025000,IdentityServer4 first acceptance test,2017-02-03 13:03:22,<tdd><microservices><identityserver4><atdd>,1,80,0,0.0,0,"<p>I am starting a new project to create an authentication api using IdentityServer4 following TDD. Many microservices and websites will be using this to authenticate users. But I could not figure out first 3 acceptance tests for the project. Any help will be highly appreciated.</p>&#xA;&#xA;<p><strong>Note:</strong> I have recently read <a href=""https://www.amazon.co.uk/Growing-Object-Oriented-Software-Addison-Wesley-Signature-ebook/dp/B002TIOYVW"" rel=""nofollow noreferrer"">goos</a> </p>&#xA;"
42079952,Microservices handeling events from redis pubsub,2017-02-07 01:00:07,<java><redis><microservices>,1,192,0,0.0,0,<p>I am trying to create a microservice that listen to a redis pubsub channel and persist some events into a DB.</p>&#xA;&#xA;<p>In my test case i am spinning up 2 instances of my microservice both listening to the same channel.</p>&#xA;&#xA;<p>the thing that i am facing now is that for every events received both instances update the DB at the same time and i wanted to know if there are ways to prevent this action?</p>&#xA;&#xA;<p>like for every events one instance will be elected to perform the update?</p>&#xA;
41942024,Shared entity/table design for microservices,2017-01-30 17:36:53,<java><spring><hibernate><microservices>,2,452,0,0.0,0,"<p>We are in the middle of breaking a big monolithic e-commerce application into microservices. (We plan to use Java, Spring, Hibernate) We have concept of fulfillment items and persistent items in our monolithic application. Our plan is to mostly break up the fulfillment item CRUD operations and persistent item CRUD operations into two separate APIs.  But we have some common entities/tables that both the API's will end up needing. What is the best way to handle this scenario?</p>&#xA;&#xA;<p>Currently one of the options open on table is to have one microservice own the entity/table and have a READ ONLY object reference in other microservice. Are there any drawbacks to this? </p>&#xA;"
42142284,How to query the event repository in a microservice Event Sourcing architecture with Spring Cloud Stream Kafka,2017-02-09 16:45:17,<apache-kafka><spring-cloud><microservices><spring-cloud-stream><spring-kafka>,1,517,2,1.0,0,"<p><strong>CLARIFICATION</strong>: Notice that this question is different form this one: <a href=""https://stackoverflow.com/questions/42140285/how-to-implement-a-microservice-event-driven-architecture-with-spring-cloud-stre"">How to implement a microservice Event Driven architecture with Spring Cloud Stream Kafka and Database per service</a></p>&#xA;&#xA;<p>This one is about using <a href=""http://microservices.io/patterns/data/event-sourcing.html"" rel=""nofollow noreferrer"">Kafka as the only repository (of events)</a>, no DB needed, The other one is about using a <a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">Database (MariaDB) per service + Kafka</a>.  </p>&#xA;&#xA;<p>I would like to implement an Event Sourcing architecture to handle distributed transactions:</p>&#xA;&#xA;<pre><code>OrdersService &lt;------------&gt; | Kafka Event Store | &lt;------------&gt;PaymentsService&#xA;                subscribe/                           subscribe/&#xA;                   find                                 find&#xA;</code></pre>&#xA;&#xA;<p>OrdersService receives an order request and stores the new Order in the broker. </p>&#xA;&#xA;<pre><code>private OrderBusiness orderBusiness;    &#xA;&#xA;@PostMapping&#xA;public Order createOrder(@RequestBody Order order){&#xA;    logger.debug(""createOrder()"");&#xA;    //do whatever&#xA;    //Publish the new Order with state = pending&#xA;    order.setState(PENDING);&#xA;    try{       &#xA;       orderSource.output().send(MessageBuilder.withPayload(order).build());&#xA;    }catch(Exception e){&#xA;        logger.error(""{}"", e);&#xA;    }&#xA;    return order;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This is my main doubt: how can I query a Kafka broker? Imagine I want to search for orders by user/date,state, etc.</p>&#xA;"
42046797,"New to Microservices - refactoring a monolith ""Marketplace"" database",2017-02-04 23:20:58,<oop><microservices>,1,180,3,0.0,0,"<p>I am new to microservices and have been struggling to wrap my brain around it. On the surface they sound like a good idea, but from a practical standpoint, I can't break away from my centralized database background. For an example, I have this real-world Marketplace example that I cannot figure out if microservices would help or hurt. This site was working well until the PO asked for ""Private Products."" Now it is fragile and slow so I need to do a major refactor. A good time to implement microservices. I feel like many systems have this type of coupling, so that deconstructing this example would be very instructive. </p>&#xA;&#xA;<p><strong>Current State</strong> </p>&#xA;&#xA;<p>This is a b2b marketplace where users belong to companies that are buying products from each other. Currently, there exists a monolithic database: User, Company, Catalog, Product, and Order. (This is a simplification, the actual scenario is much more complicated, users have roles, orders have header/detail, products have inventories, etc.)</p>&#xA;&#xA;<ul>&#xA;<li>Users belong to Companies</li>&#xA;<li>Companies have a Catalog of their Products</li>&#xA;<li>Companies have Orders for Products from other Companies </li>&#xA;</ul>&#xA;&#xA;<p>So far so good. I could see breaking the app into microservices on the major entity boundaries. </p>&#xA;&#xA;<p><strong>New Requirement</strong></p>&#xA;&#xA;<p>Unfortunately for my architectural aspirations, the product owner wants more features. In this case: Private Products.</p>&#xA;&#xA;<ul>&#xA;<li>Products are Public or Private</li>&#xA;<li>Companies send time-bound Invitations to Products or Catalogs to Users of other Companies</li>&#xA;</ul>&#xA;&#xA;<p>This seemingly simple request all the suddenly complicated everything.</p>&#xA;&#xA;<p><strong>Use Case - User displays a list of products</strong></p>&#xA;&#xA;<p>For example, listing or searching products was once just a simple case of asking the Products to list/search themselves. It is one of the top run queries on the system. Unfortunately, now what was a simple use case just got messy.</p>&#xA;&#xA;<ul>&#xA;<li>A User should be able to see all public Products (easy)</li>&#xA;<li>A User should be able to see all their own Company's private Products (not horrible)</li>&#xA;<li>A User can see any Product that their Company has Ordered in the past regardless of privacy (Uh oh, now the product needs to know about the User Company's Order history) </li>&#xA;<li>A User can see any private Product for which they have an active Invitation (Uh oh, now the product needs to know about the User's Product or Catalog Invitations which are time dependent)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Initial Monolithic Approach</strong></p>&#xA;&#xA;<p>This can be solved at the database level, but the SQL joins basically ALL of the tables together (and not just master data tables, all the transactions as well.) While it is a lot slower than before, since a DBMS is designed for big joins it seems like the appropriate tool. So I can start working on optimizing the query. However, as I said, for this and other reasons the system is feeling fragile.</p>&#xA;&#xA;<p><strong>Initial Design Thoughts... and ultimately my questions</strong></p>&#xA;&#xA;<p>So considering a Microservices architecture as a potential new direction, I began to think about how to start. Data redundancy seems necessary. Since, if I translate my major entities into services, asking to get a list of products without data redundancy would just have all of the services calling each other and a big slow mess. </p>&#xA;&#xA;<p>Starting with a the idea of carving out ""Product and Catalog"" as its own microservice. Since Catalogs are just collections of Products, they seem to belong together - I'll just call the whole thing the ""Product Service"". This service would have an API for managing both products and catalogs and, most importantly, to search and list them.</p>&#xA;&#xA;<p>As a separate service, to perform a Product search would require a lot of redundant data as it would have to subscribe to any event that affected product privacy, such as:</p>&#xA;&#xA;<ul>&#xA;<li>Listen for Orders and keep at least a summary of the relationship between purchased Products and Purchasing Companies</li>&#xA;<li>Listen to Invitations and maintain a list of <strong>active</strong> User/Product/Time relationships </li>&#xA;<li>Listen to User and Company events to maintain a User to Company relationship</li>&#xA;</ul>&#xA;&#xA;<p>I begin to worry about keeping it all synchronized. </p>&#xA;&#xA;<p>In the end, a Product Service would have a large part of the current schema replicated. So I begin to think, maybe Microservices won't work for this situation. Or am I being melodramatic and the schema will be simpler enough to be more managable and faster so it is worth it?</p>&#xA;&#xA;<p>Overall, am I thinking about this whole approach properly? Is this how microservice based designs are intended to be thought through? If not, can somebody give me a push in a different direction?</p>&#xA;"
42061684,Microservice redundancy issue in our architecture,2017-02-06 06:36:51,<microservices>,1,246,4,0.0,0,"<p>We have 12 microservices deployed in our application server. Problem is, since we have a microservice for each specific function, a lot of libraries are being repeated in each microservice instead of if they are shared in larger monolithic services or app. This causes each .ear file to be large per microservice. with this, out of memory errors start to happen more often.</p>&#xA;&#xA;<p>Is there any way to get around this? or better ways to do this?</p>&#xA;"
36734091,Can we add custom scope in UAAC,2016-04-20 04:51:02,<authentication><microservices>,1,288,0,0.0,0,<p>I am working on CF-UAA. I want to define my application specific custom scope e.g. user.reports. I want this scope to be included in the token.&#xA;The token then validated by a report microservice and it will serve only if the token contains the scope.</p>&#xA;&#xA;<p>My questions are:</p>&#xA;&#xA;<ol>&#xA;<li>Can we define custom scope and add users to it?</li>&#xA;<li>If yes how? and if not what is the best way to achieve this kind of requirement</li>&#xA;</ol>&#xA;
36719045,kafka + storm topology vs microservices,2016-04-19 12:53:41,<java><apache-kafka><apache-storm><microservices>,2,724,1,1.0,0,"<p>what's the benefit of using storm topology when one can use microservices that connect to kafka directly. the microservice approach seems to offer much better solution for:</p>&#xA;&#xA;<ul>&#xA;<li>tools (every possible library, IoC container etc)</li>&#xA;<li>continuous deployment (existing tools and best practices)</li>&#xA;</ul>&#xA;&#xA;<p>while storm topology seems to use plain java with need of static functions. </p>&#xA;&#xA;<p>so what are the benefits of using storm topology instead of microservices?</p>&#xA;"
36775802,Sharing huge data between microservices,2016-04-21 16:42:08,<microservices>,2,2005,1,0.0,0,"<p>I am designing an review analysis platform in microservices architecture. </p>&#xA;&#xA;<p>Application is works like below;</p>&#xA;&#xA;<ul>&#xA;<li>all product reviews retrieved from ecommerce-site-a ( site-a ) as an excel file </li>&#xA;<li>reviews are uploaded to system with excel </li>&#xA;<li>Analysis agent can list all reviews, edit some of them, delete or approve</li>&#xA;<li>Analysis agent can export all reviews for site-a</li>&#xA;<li>Automated regexp based checks are applied for each review on upload and editing. </li>&#xA;</ul>&#xA;&#xA;<p>I have 3 microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Reviews: Responsible for Review Crud operations plus operations similar to approve/reject..</li>&#xA;<li>Validations: Responsible for defining and applying validation rules on review.</li>&#xA;<li>Export/Import: Export service exports huge files given site name (like site-a)</li>&#xA;</ul>&#xA;&#xA;<p><strong>The problem is</strong> at some point, validation service requires to get all reviews for site-a, apply validation rules and generate errors if is there any. I know sharing database schema's and entities breaks micro-services architecture.</p>&#xA;&#xA;<p>One possible solution is</p>&#xA;&#xA;<ul>&#xA;<li>Whenever validation service requires reviews for a site, it requests gateway, gateway redirects request to Reviews service and response taken. </li>&#xA;</ul>&#xA;&#xA;<p>Two <strong>possible drawbacks</strong> of this approach is</p>&#xA;&#xA;<ul>&#xA;<li>validation service <strong>knows</strong> about gateway? Is it brings a dependency?</li>&#xA;<li>in case I have 1b reviews for a site, getting all reviews via rest request may be a problem. ( or not, I can make paginated requests from validation service to gateway..)  </li>&#xA;</ul>&#xA;&#xA;<p>So what is the best practice for sharing huge data between micro-services without </p>&#xA;&#xA;<ul>&#xA;<li>sharing entity</li>&#xA;<li>and dublicating data</li>&#xA;</ul>&#xA;&#xA;<p>I read lot about using messaging queues but I think in my case it is not good to use messaging queue to share gigabytes of data.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>edit 1: Instead of sharing entity, using data stores with rest API can be a solution? Assume I am using mongodb, instead of sharing my entity object between microservices, I can use rest interface of mongo (<a href=""http://restheart.org/"" rel=""nofollow"">http://restheart.org/</a>) and query data whenever possible.  </p>&#xA;"
36760694,Working example of spring watchservicedirectoryscanner,2016-04-21 05:50:13,<java><spring><spring-mvc><spring-boot><microservices>,2,1137,2,0.0,0,"<p>I'm struggling to implement a <code>WatchServiceDirectoryScanner</code>. I want to use the scanner to monitor new file uploads to a directory + sub directories. This will exist as part of a Spring boot MVC microservice. I can do this using Java 7's <code>WatchService</code> but would prefer a spring file integration style, AOP style</p>&#xA;&#xA;<p>I have it registered as a <code>@Bea</code>n in my app config but I'm struggling to figure out how to have it poll and scan a directory and then call... something (a message endpoint?) when a file is detected. Is anyone able to point me in the right direction for even conceptually how this is done. I cannot find an example implementation of this anywhere.</p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner"" rel=""nofollow"">http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner</a></p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-"" rel=""nofollow"">http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-</a></p>&#xA;&#xA;<p>here is my Spring appConfig:</p>&#xA;&#xA;<pre><code>public class appConfig {&#xA;    @Bean&#xA;    public DirectoryScanner scanner() {&#xA;        return new WatchServiceDirectoryScanner(""/uploads/test"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
36694873,Token/stateless auth in Silex application with a Microservice architecture?,2016-04-18 13:05:31,<php><session><authentication><silex><microservices>,1,710,2,0.0,0,"<p>I would like to use Silex as a base framework for couple of services. It would be used by different clients and apis (mobile, web etc.) so I'm generally trying to avoid cookies/session and 'do it' using headers.</p>&#xA;&#xA;<p>Setup/flow of what I'm trying to achieve:</p>&#xA;&#xA;<ol>&#xA;<li><p>user logins in his mobile app/on webpage producing request to authservice.domain.com, gets back new token as a response which is as well registered in token store</p></li>&#xA;<li><p>when user access from web or mobile app products.domain.com the token is read from the headers and checked in store</p></li>&#xA;</ol>&#xA;&#xA;<p>Everything looks beautiful, but somehow I cannot make Silex add headers to requests following the login step, I'm able to add it to response, but not to request (i tried using before/after middleware so 1st auth, then add token in $app->after/before)... btw. im not sure if I understand it right, but if a user press a refresh page button when setting headers this way won't the custom header get lost? if that's the case is it possible to keep token persisted in headers without cookies/sessions after all?</p>&#xA;&#xA;<p>Here's example code I'm running after getting token, it gets sets on response (and i can see it in chrome), but it won't get set on request - I tried as well using with before middleware</p>&#xA;&#xA;<pre><code>    $this-&gt;after(function(Request $request, Response $response) {&#xA;        $response-&gt;headers-&gt;set(""X-token"",""2"");&#xA;        $request-&gt;headers-&gt;set(""X-token"",""2"");&#xA;    });&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions on how I can achieve this? So... stateless auth using  headers over multiple services in plain (Silex : )) php without keeping token in cookies or (api gateway) sessions? </p>&#xA;"
36638486,Unable to run node js seneca microservice,2016-04-15 04:50:05,<node.js><api><microservices>,1,258,5,0.0,0,"<p>I am new in node js. I try to run my first node microservice using seneca framework. But it shows following error</p>&#xA;&#xA;<pre><code>&gt; npm ERR! Linux 4.2.0-16-generic&#xA;&gt; &#xA;&gt; npm ERR! argv ""/usr/local/bin/node"" ""/usr/bin/npm"" ""start""&#xA;&gt; &#xA;&gt; npm ERR! node v5.10.1&#xA;&gt; &#xA;&gt; npm ERR! npm  v3.8.6&#xA;&gt; &#xA;&gt; npm ERR! code ELIFECYCLE&#xA;&gt; &#xA;&gt; npm ERR! myproject@0.0.1 start: `node server.js`&#xA;&gt; &#xA;&gt; npm ERR! Exit status 2&#xA;&gt; &#xA;&gt; npm ERR! &#xA;&gt; &#xA;&gt; npm ERR! Failed at the myproject@0.0.1 start script 'node server.js'.&#xA;&gt; &#xA;&gt; npm ERR! Make sure you have the latest version of node.js and npm &#xA;&gt; installed.&#xA;&gt; &#xA;&gt; npm ERR! If you do, this is most likely a problem with the myproject&#xA;&gt; package,&#xA;&gt; &#xA;&gt; npm ERR! not with npm itself.&#xA;&gt; &#xA;&gt; npm ERR! Tell the author that this fails on your system:&#xA;&gt; &#xA;&gt; npm ERR!     node server.js&#xA;&gt; &#xA;&gt; npm ERR! You can get information on how to open an issue for this&#xA;&gt; project with:&#xA;&gt; &#xA;&gt; npm ERR!     npm bugs myproject&#xA;&gt; &#xA;&gt; npm ERR! Or if that isn't available, you can get their info via:&#xA;&gt; &#xA;&gt; npm ERR!     npm owner ls myproject&#xA;&gt; &#xA;&gt; npm ERR! There is likely additional logging output above.&#xA;&gt; &#xA;&gt; &#xA;&gt; npm ERR! Please include the following file with any support request:&#xA;&gt; &#xA;&gt; npm ERR!     ~/Desktop/micro services/myproject/npm-debug.log&#xA;</code></pre>&#xA;&#xA;<p>i use Seneca.js Yeoman generator to create this project. Please anyone help me.</p>&#xA;&#xA;<p>my project directry looks like the following structure</p>&#xA;&#xA;<pre><code>        test-seneca&#xA;        |&#xA;        |-- client&#xA;        |   |-- css&#xA;        |   |-- js&#xA;        |   |-- partials&#xA;        |   |-- index.html&#xA;        |-- server&#xA;        |   |-- api.js&#xA;        |-- test&#xA;        |   |-- functional&#xA;        |-- bower.json&#xA;        |-- package.json&#xA;        |-- server.js &#xA;</code></pre>&#xA;&#xA;<p>my package.json is</p>&#xA;&#xA;<pre><code>{&#xA;&#xA;  ""name"": ""myproject"",&#xA;&#xA;  ""version"": ""0.0.1"",&#xA;&#xA;  ""scripts"": {&#xA;&#xA;    ""postinstall"": ""./node_modules/.bin/webdriver-manager update --standalone &amp;&amp; ./node_modules/.bin/bower install"",&#xA;&#xA;    ""test"": ""./node_modules/.bin/protractor test/functional/protractor.conf.js""&#xA;&#xA;  },&#xA;&#xA;  ""dependencies"": &#xA;{&#xA;&#xA; ""async"": ""^0.9.0"",&#xA;&#xA;    ""hapi"": ""~8.2.0"",&#xA;&#xA;    ""hapi-seneca"": ""^1.0.3"",&#xA;&#xA;    ""seneca"": ""git://github.com/rjrodger/seneca.git"",&#xA;&#xA;    ""seneca-account"": ""^0.1.8"",&#xA;&#xA;    ""seneca-auth"": ""git://github.com/rjrodger/seneca-auth.git"",&#xA;&#xA;    ""seneca-card"": ""^0.1.3"",&#xA;&#xA;    ""seneca-project"": ""^0.1.4"",&#xA;&#xA;    ""seneca-user"": ""~0.2.10""&#xA;&#xA;  },&#xA;&#xA;  ""devDependencies"": {&#xA;&#xA;    ""protractor"": ""~1.7.0"",&#xA;&#xA;    ""bower"": ""~1.3.12""&#xA;&#xA;  }&#xA;&#xA;}&#xA;</code></pre>&#xA;"
42810364,How to track data in nodejs with microservices,2017-03-15 12:52:26,<node.js><logging><monitoring><microservices><winston>,2,318,0,0.0,0,"<p>I'm dealing with an application using multiple microservices.</p>&#xA;&#xA;<p>The application receieves data and processes it, and I'd like to have a way to monitor everything the received data is going throughout the microservices.</p>&#xA;&#xA;<p>Since the platform is <code>nodejs</code> we're dealing with asynchronous processing, logs wont always be written one after the other, and since the data does not have a×ž ID the logs cannot be filtered in any convenient way.</p>&#xA;&#xA;<p>Is there any way to track the data from the first moment it enters the application till the end, moving between the microservices <strong><em>without</em></strong> having to pass a generate id between all the methods.</p>&#xA;&#xA;<p>Obviously that id will be passed between the microserives but within each one, I'd like to keep the code clean.</p>&#xA;&#xA;<p>I'm using <a href=""https://www.npmjs.com/package/winston"" rel=""nofollow noreferrer""><code>winston</code></a> to log, maybe something could fit there.</p>&#xA;&#xA;<p>Thanks in advance, any suggestion would be highly appreciated.</p>&#xA;"
42741917,SWIM protocol how does a new node get an address of an existing node in a cluster,2017-03-11 23:29:24,<microservices>,1,83,0,0.0,0,"<p>Background:&#xA;  I've been looking into microservices more specifically service discovery,&#xA;one thing thats interested me is the SWIM protocol. But I'm a little confused when it comes to new nodes joining the network.</p>&#xA;&#xA;<p><strong>How does a new node joining the cluster get an address of 1 or more nodes of the existing cluster, without their being a single point of faliure?</strong></p>&#xA;&#xA;<p>If you need any further information or have any questions just let me know.</p>&#xA;"
42769855,How to change express.js microservice application for ecs auto scaling,2017-03-13 17:31:24,<amazon-web-services><express><docker><microservices><amazon-ecs>,1,120,0,0.0,0,"<p>This is my containerized micro-service application and workflow. </p>&#xA;&#xA;<ol>&#xA;<li><a href=""http://travis-ci.com"" rel=""nofollow noreferrer"">Travis</a> pull code from git, build docker image and push to <a href=""https://aws.amazon.com/ecr/"" rel=""nofollow noreferrer"">ECR</a>. </li>&#xA;<li>Updates <a href=""https://aws.amazon.com/ecs/"" rel=""nofollow noreferrer"">ECS</a> task and service with new image tag using <a href=""https://aws.amazon.com/cli/"" rel=""nofollow noreferrer"">aws cli</a> on successful travis build. </li>&#xA;<li>I have one instance per dev and staging cluster. </li>&#xA;<li>I can have more than one instance for prod cluster but no more than 1 instance per dev and staging clusters. </li>&#xA;<li>The solution has about 10 micro services, rabbitmq and mysql. <em>(gateway, api, etc..)</em></li>&#xA;</ol>&#xA;&#xA;<p>Scenario: &#xA;If my webapp or any other container is highly used, I want to scale up that by automatically creating multiple containers in same ec2 instance. (instance has enough ram and memory). </p>&#xA;&#xA;<p>Currently I hardcoded the port for webapp as 3000. How my express.js code should change for the following? </p>&#xA;&#xA;<ol>&#xA;<li>Dynamically binding port for webapp and api. </li>&#xA;<li>Load balance within them.</li>&#xA;<li>Configure autoscalling to make them happen automatically. </li>&#xA;</ol>&#xA;&#xA;<p>Additionally: &#xA;Can this be achieved using Ansible? How? &#xA;I need to scale containers, not clusters or instances. </p>&#xA;"
42674145,Zuul seems to rewrite routes after REST call,2017-03-08 14:34:47,<microservices><netflix-zuul><netflix-eureka>,1,197,0,0.0,0,"<p>I have encountered a strange behaviour with our Zuul-Proxy in our Microservice-Project. My Setup consists of a Discovery-Service (Eureka), an API-Gateway (Zuul) and two Microservices ""A"" &amp; ""B"".&#xA;After starting the setup, the following routes are shown via ""localhost:10000/routes"":</p>&#xA;&#xA;<pre><code>{&#xA;  ""/api-gateway/**"": ""api-gateway"",&#xA;  ""/a-service/**"": ""a-service"",&#xA;  ""/b-service/**"": ""b-service""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My Zuul Config looks like this:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignored-services: ''&#xA;  add-proxy-headers: true&#xA;  sensitiveHeaders: 'Cookie,Set-Cookie'&#xA;</code></pre>&#xA;&#xA;<p>Now I access the services via the gateway and make some REST calls:</p>&#xA;&#xA;<p><a href=""http://localhost:10000/a-service/sayHello"" rel=""nofollow noreferrer"">http://localhost:10000/a-service/sayHello</a> --> OK</p>&#xA;&#xA;<p><a href=""http://localhost:10000/b-service/sayBye"" rel=""nofollow noreferrer"">http://localhost:10000/b-service/sayBye</a> --> OK</p>&#xA;&#xA;<p><a href=""http://localhost:10000/a-service/sayHello"" rel=""nofollow noreferrer"">http://localhost:10000/a-service/sayHello</a> --> ERROR 404</p>&#xA;&#xA;<p>I can see that the last request is mistakenly routed to Service B, even though I am using the ""/a-service/**"" route. How can this happen? Did the second REST call to service B somehow rewrite the routing? </p>&#xA;&#xA;<p>However ""localhost:10000/routes"" is still returning the same as above. This also works with calling the services in opposite order B-A-B -> 404 and mistakenly routed to service A.</p>&#xA;&#xA;<p>You can download a minimal project with the 4 components, which should let you easily replicate this behaviour here:&#xA;<a href=""https://github.com/Netflix/zuul/files/827817/MinimalZuulRouteBugProject.zip"" rel=""nofollow noreferrer"">https://github.com/Netflix/zuul/files/827817/MinimalZuulRouteBugProject.zip</a></p>&#xA;&#xA;<p>Thank you, for any insights regarding this issue.</p>&#xA;"
42642688,Spring Cloud Zuul as API gateway,2017-03-07 07:35:12,<spring><spring-security><microservices><spring-cloud><netflix-zuul>,1,929,2,0.0,0,"<p>I'm new to Spring Cloud and about to kick start a new project in micro-service fashion using Spring Cloud stack i.e. Eureka, Zuul, Ribbon and Hystrix.</p>&#xA;&#xA;<p>The application will have a dumb UI which will interact with back-end services to get job done, the back-end services are rest in nature and will use token based authentication (using JWT) backed by Spring security, so following will be the flow of application </p>&#xA;&#xA;<ol>&#xA;<li><strong>Authentication service</strong>:- Authentication service will take care of authenticating user and validating access token.</li>&#xA;<li><strong>Rest services</strong>: Other services will have their own authorization mechanism, i.e. whether given user (identified from JWT token) has access to requested resource or not.</li>&#xA;</ol>&#xA;&#xA;<p>I've used JWT and Spring security filters to achieve same but not able to map how Zuul will fit into this picture, while going through documentation I encountered ZuulFilters, which can be used to achieve this but using this I need to have my authentication/authorization mechanism at same place i.e. Zuul, but I want my authentication piece at Zuul and have distributed authorization this will save me from configuring every rest resource to role mapping in DB and have that loaded/read at zuul for every request.</p>&#xA;&#xA;<p>I've gone through some blogs/example but most of them talk about SSO stuff, Can someone please enlighten me with a blog post or example, any help is appreciated. </p>&#xA;"
42630302,Cannot access the microservice through the gateway,2017-03-06 16:09:44,<spring><jhipster><microservices><netflix-zuul><api-gateway>,1,453,2,0.0,0,"<p>I am not experienced in spring micro services and zuul configuration so I will need some help.</p>&#xA;&#xA;<p>I have a microservice running on jhipster-registry and I am trying to access the microservice from my application through the gateway. </p>&#xA;&#xA;<p>In my application I have this service in the current routes:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/PnnCh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PnnCh.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>If I am accessing the service when my application is started as a spring boot app everything works fine; but when I deploy my application on tomcat the same request returns 404. </p>&#xA;&#xA;<p>Here is the zuul config : </p>&#xA;&#xA;<pre><code>zuul:&#xA;    routes:&#xA;     assessmentapi: &#xA;        path: /assessmentapi/**&#xA;        serviceId: assessmentapi&#xA;        url:  http://192.168.80.44:8081/assessment-api&#xA;</code></pre>&#xA;&#xA;<p>and http get request </p>&#xA;&#xA;<pre><code>$http.get('/assessmentapi/main/....)&#xA;</code></pre>&#xA;"
42691892,Microservices Per DB table,2017-03-09 09:47:19,<domain-driven-design><microservices>,3,200,2,0.0,0,"<p>I ran into the microservices architecture for e-commerce application where each table has it's own micro service basically with CRUD operations (something like rest client for each table). &#xA;Now I am thinking about combine and model them around business domains, before that I wanted to know does anyone encountered such situation and is it right architecture or not.&#xA;Any suggestions will be very helpful.&#xA;Thanks.</p>&#xA;"
42711116,Service Fabric - DeleteServiceAsync timing out,2017-03-10 05:45:34,<azure><microservices><azure-service-fabric><service-fabric-stateful>,1,62,3,0.0,0,"<p>I am spawning several ASF microservices to run some process. Once the process is done, I am deleting those services using <code>DeleteServiceAsync</code> by using following code. Almost 98% of the time, everything works fine. However, 2% of the time, I run into timeout issue and the microservices stucks in deleting state with Idle Secondary replica. Thanks in advance for any suggestions to resolve this issue.</p>&#xA;&#xA;<pre><code>using (FabricClient fc = new FabricClient())&#xA;{&#xA;    fc.ServiceManager.DeleteServiceAsync(deleteServiceDescription, TimeSpan.FromMinutes(5), cancellationToken);&#xA;}&#xA;</code></pre>&#xA;"
42778151,Integrating with Auth0,2017-03-14 05:10:33,<publish-subscribe><microservices><cqrs><eventual-consistency>,1,38,4,0.0,0,"<p>I'm in the process of implementing a user management Microservice (MS) and wanted to find out whether what I'm doing is ok. Users are created from the UI, which interacts with an API. The API makes an RPC call to the user management MS, and publishes a CreateUserCommand to an InMem-bus. The consumer then handles the command by then creating a user in the DB, but then I need this user also registered within Auth0 - would the way to go about this be to send a different command to a persistent queue, for a subscriber to pick it up and register that user with Auth0 (persistent queue in case can't reach Auth0). Once that completes successfully, I could then publish a UserCreatedEvent? </p>&#xA;&#xA;<p>Any help with this would be much appreciated.</p>&#xA;"
50964458,Zuul proxy server throwing Internal Server Error when request takes more time to process,2018-06-21 08:59:00,<microservices><netflix-zuul><proxy-server>,1,21,0,0.0,0,"<p><a href=""https://i.stack.imgur.com/8xz2G.png"" rel=""nofollow noreferrer"">Zuul Proxy Error</a></p>&#xA;&#xA;<p>I am getting this error when the request takes more time to process in the service.But Zuul returns response of Internal Server Error</p>&#xA;&#xA;<p>Using zuul 2.0.0.RC2 release</p>&#xA;"
51093230,how to split a monorepo accross multiple teams each has access to only a slice of repo?,2018-06-29 01:47:33,<git><github><gitlab><microservices><project-management>,1,39,0,0.0,0,"<p>there are a lot of good advantages in monorepo, we also read that large companies like google and facebook use this tech to keep all source code in single repo.</p>&#xA;&#xA;<p>but question is how do you manage to limit access of a certain team to projects he is working on only in monorepo ?</p>&#xA;&#xA;<p>example we have a microservice infrastructure</p>&#xA;&#xA;<p>service A&#xA;service B&#xA;Api Gateway&#xA;service A here is developer using Team A, and service B is developed by different team (team b) while Api Gateway is common repo in this project.</p>&#xA;&#xA;<p>now how can we limit access of each team to his own service only ?</p>&#xA;&#xA;<p>also since a monorepo can be Gigabytes in size, so we need teams to only clone parts that they care about, not whole project</p>&#xA;&#xA;<p>currently we keep every part in its own repo, and this way we can controll access control for each team, but i was asked to migrate this to monorepo and im not sure how to protect source code and split project in such approach.</p>&#xA;&#xA;<p>thank you</p>&#xA;"
50971334,"Decode JWT and create authenticated User in Laravel microservice, merging with local user data",2018-06-21 14:42:41,<php><laravel><jwt><microservices>,1,49,0,0.0,0,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I have a microservice setup the flow is:</p>&#xA;&#xA;<pre><code>client &gt; api gateway &gt; auth server &gt; api gateway &gt; microservice&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>The client has a 'external' JWT from Laravel passport</li>&#xA;<li>Client sends request to the api gateway with the 'external' JWT</li>&#xA;<li>The api gateway sends a request to the auth server (Laravel passport) with the 'external' JWT</li>&#xA;<li>The auth server verifies the user is still active and returns a new 'internal' JWT to the api gateway containing the users profile, groups etc</li>&#xA;<li>The api gateway forwards the request with this new 'internal' JWT to the microservice </li>&#xA;<li><strong>(all fine up to this point)</strong></li>&#xA;<li>The Microservice verifies the 'internal' JWT using the auth servers public key</li>&#xA;<li>The microservice decodes the 'internal' JWT and creates a user object from the profile contained within</li>&#xA;<li>If the microservice has a local users table (e.g. for microservice specific user data), merge the local data with the JWT data</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Microservice Authentication</strong></p>&#xA;&#xA;<p>I have created a JwtGuard that can decode the JWT and create a user using GenericUser:</p>&#xA;&#xA;<p>auth.php</p>&#xA;&#xA;<pre><code>'guards' =&gt; [&#xA;        'web' =&gt; [&#xA;            'driver' =&gt; 'session',&#xA;            'provider' =&gt; 'users',&#xA;        ],&#xA;&#xA;        'api' =&gt; [&#xA;            'driver' =&gt; 'jwt',&#xA;            'provider' =&gt; 'users',&#xA;        ],&#xA;    ],&#xA;'providers' =&gt; [&#xA;    'users' =&gt; [&#xA;        'driver' =&gt; 'eloquent',&#xA;        'model' =&gt; App\User::class,&#xA;    ],&#xA;],&#xA;</code></pre>&#xA;&#xA;<p>AuthServiceProvider.php</p>&#xA;&#xA;<pre><code>public function boot()&#xA;    {&#xA;        $this-&gt;registerPolicies();&#xA;&#xA;        Auth::extend('jwt', function ($app) {&#xA;            return new JwtGuard($app['request']);&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>JwtGuard.php</p>&#xA;&#xA;<pre><code>&lt;?php&#xA;namespace App\Services\Auth;&#xA;&#xA;use Illuminate\Auth\GenericUser;&#xA;use Illuminate\Auth\GuardHelpers;&#xA;use Illuminate\Contracts\Auth\Authenticatable;&#xA;use Illuminate\Contracts\Auth\Guard;&#xA;&#xA;use \Firebase\JWT\JWT;&#xA;use Illuminate\Http\Request;&#xA;&#xA;class JwtGuard implements Guard {&#xA;&#xA;    use GuardHelpers;&#xA;&#xA;    /**&#xA;     * @var Request&#xA;     */&#xA;    private $request;&#xA;&#xA;    public function __construct(Request $request)&#xA;    {&#xA;        $this-&gt;request = $request;&#xA;    }&#xA;&#xA;    /**&#xA;     * Get the currently authenticated user.&#xA;     *&#xA;     * @return \Illuminate\Contracts\Auth\Authenticatable|null&#xA;     */&#xA;    public function user()&#xA;    {&#xA;        if (!is_null($this-&gt;user)) {&#xA;            return $this-&gt;user;&#xA;        }&#xA;&#xA;        if(!$jwt = $this-&gt;getJwt()) {&#xA;            return null;&#xA;        }&#xA;&#xA;        return $this-&gt;decode($jwt);&#xA;    }&#xA;&#xA;    /**&#xA;     * Validate a user's credentials.&#xA;     *&#xA;     * @param  array $credentials&#xA;     * @return bool&#xA;     */&#xA;    public function validate(array $credentials = [])&#xA;    {&#xA;        if(!$jwt = $this-&gt;getJwt()) {&#xA;            return false;&#xA;        }&#xA;&#xA;        return !is_null($this-&gt;decode($jwt))?true:false;&#xA;    }&#xA;&#xA;    /**&#xA;     * Decode JWT and return user&#xA;     *&#xA;     * @return mixed|null&#xA;     */&#xA;    private function decode($jwt)&#xA;    {&#xA;        $publicKey = file_get_contents(storage_path('oauth-public.key'));&#xA;&#xA;        try {&#xA;            $res = JWT::decode($jwt, $publicKey, array('RS256'));&#xA;            return $this-&gt;user = new GenericUser(json_decode(json_encode($res-&gt;user), true));&#xA;        } catch (\Exception $e) {&#xA;            return null;&#xA;        }&#xA;    }&#xA;&#xA;    private function hasAuthHeader()&#xA;    {&#xA;        return $this-&gt;request-&gt;header('Authorization')?true:false;&#xA;    }&#xA;&#xA;    private function getJwt()&#xA;    {&#xA;        if(!$this-&gt;hasAuthHeader()){&#xA;            return null;&#xA;        }&#xA;&#xA;        preg_match('/Bearer\s((.*)\.(.*)\.(.*))/', $this-&gt;request-&gt;header('Authorization'), $jwt);&#xA;&#xA;        return $jwt[1]?$jwt[1]:null;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>The problem</strong></p>&#xA;&#xA;<p>This works ok(ish), except that:</p>&#xA;&#xA;<ul>&#xA;<li>I can't use authorization policies properly as GenericUser doesn't have the can() method</li>&#xA;<li>There is no easy way to merge with a local user object</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have tried the following to merge the local user data with the JWT profile:</p>&#xA;&#xA;<pre><code>private function decode($jwt)&#xA;    {&#xA;        $publicKey = file_get_contents(storage_path('oauth-public.key'));&#xA;&#xA;        try {&#xA;            $res = JWT::decode($jwt, $publicKey, array('RS256'));&#xA;            $this-&gt;user = new GenericUser(json_decode(json_encode($res-&gt;user), true));&#xA;            $this-&gt;user-&gt;localUser = \App\User::where('user_id', $this-&gt;user-&gt;id)-&gt;first();&#xA;            return $this-&gt;user;&#xA;        } catch (\Exception $e) {&#xA;            return null;&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>but this still leaves GenericUser not having the can() function. </p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Help...please!</strong></p>&#xA;&#xA;<p>I can't help feel there is a better (proper?) way to achieve this using 'User' instead of 'GenericUser' which will allow all the Authentication/Authorization features in Laravel to work properly, and to merge the data easily.</p>&#xA;"
51035215,Running a jar as docker image and using this jar in other java application,2018-06-26 05:03:58,<java><docker><jar><microservices>,1,51,0,0.0,0,"<p>I have a jar that do some business functionality and developed as a standalone component. Now I want to use it as a Microservice hosted as docker image. I was able to create a docker image by following the tutorial as:&#xA;<a href=""https://dzone.com/articles/run-simple-jar-application-in-docker-container-1"" rel=""nofollow noreferrer"">https://dzone.com/articles/run-simple-jar-application-in-docker-container-1</a></p>&#xA;&#xA;<p>Now I have two problems:</p>&#xA;&#xA;<ol>&#xA;<li>How to call the methods of the classes in this Jar in other java applications</li>&#xA;<li>how to do the integration testing?</li>&#xA;</ol>&#xA;&#xA;<p>I am asking this as I need to take a decision if I should convert this JAR to a REST based application or it can be used as a Microservice in its actual (jar) based packaging.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50965591,Spring Cloud Netflix Eureka doesn't find eureka-js instances,2018-06-21 09:54:02,<node.js><spring><microservices><netflix-eureka>,1,71,0,0.0,0,"<p>I have 3 microservices in Spring:</p>&#xA;&#xA;<ul>&#xA;<li>Netflix Eureka</li>&#xA;<li>A Producer</li>&#xA;<li>A Consumer</li>&#xA;</ul>&#xA;&#xA;<p>And another microservice written in NodeJs with Eureka-js-client</p>&#xA;&#xA;<ul>&#xA;<li>node-microservice</li>&#xA;</ul>&#xA;&#xA;<p>Spring Eureka dashboard lists all of them&#xA;<a href=""https://i.stack.imgur.com/jNjE3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jNjE3.png"" alt=""instances""></a></p>&#xA;&#xA;<p>Until now everything looks OK, but the problem is when I try to read my <strong>node-microservice</strong> instance in eureka server. While I successfully find employee-producer instance in this way</p>&#xA;&#xA;<pre><code>List&lt;ServiceInstance&gt; instances=discoveryClient.getInstances(""employee-producer"");&#xA;    ServiceInstance serviceInstance=instances.get(0);&#xA;</code></pre>&#xA;&#xA;<p>I'm not able to find my node-microservice</p>&#xA;&#xA;<pre><code>List&lt;ServiceInstance&gt; instances=discoveryClient.getInstances(""node-microservice"");&#xA;    ServiceInstance serviceInstance=instances.get(0);&#xA;</code></pre>&#xA;&#xA;<p>From debug the result is <a href=""https://i.stack.imgur.com/ik08D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ik08D.png"" alt=""node-microservice not found""></a></p>&#xA;&#xA;<p><strong>node-microservice</strong></p>&#xA;&#xA;<pre><code>const Eureka = require('eureka-js-client').Eureka;&#xA;const express = require('express');&#xA;const server = express();&#xA;server.use(express.json());&#xA;server.use(function(req, res, next) {&#xA;    res.header(""Access-Control-Allow-Origin"", ""*"");&#xA;    res.header(""Access-Control-Allow-Headers"", ""Origin, X-Requested-With, Content-Type, Accept"");&#xA;    next();&#xA;});&#xA;server.listen(3001);&#xA;server.get('/', function (req, res) {&#xA;    res.send(""CIaooo"");&#xA;});&#xA;&#xA;&#xA;&#xA;// example configuration&#xA;const client = new Eureka({&#xA;    // application instance information&#xA;    instance: {&#xA;        app: 'node-microservice',&#xA;        hostName: 'localhost',&#xA;        ipAddr: '127.0.0.1',&#xA;        port:  {&#xA;            '$': 3001,&#xA;            '@enabled': 'true',&#xA;        },&#xA;        vipAddress: 'jq.test.something.com',&#xA;        statusPageUrl: 'http://localhost:3001/info',&#xA;        dataCenterInfo:  {&#xA;            '@class': 'com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo',&#xA;            name: 'MyOwn',&#xA;        }&#xA;    },&#xA;    eureka: {&#xA;        // eureka server host / port&#xA;        host: 'localhost',&#xA;        port: 8761,&#xA;        servicePath: '/eureka/apps/'&#xA;    },&#xA;});&#xA;&#xA;client.logger.level('debug');&#xA;&#xA;client.start(function(error){&#xA;    console.log(error || 'complete')});&#xA;</code></pre>&#xA;&#xA;<p>Other strange thing is that from spring debug I can list services, where also node-microservice is listed</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ihxiS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ihxiS.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What's wrong with my code?</p>&#xA;"
51060417,What is the difference between AddTransientHttpErrorPolicy and AddPolicyHandler?,2018-06-27 10:25:35,<microservices><asp.net-core-webapi><polly><resiliency><httpclientfactory>,1,83,0,0.0,0,"<p>I want to apply resiliency strategy using <a href=""https://github.com/App-vNext/Polly"" rel=""nofollow noreferrer"">Polly</a>. I am using HttpClientFactory from ASP.NET Core 2.1. I found some guide on <a href=""https://github.com/App-vNext/Polly/wiki/Polly-and-HttpClientFactory"" rel=""nofollow noreferrer"">Polly GitHub wiki</a>. There are two ways of such policy configuration - using AddTransientHttpErrorPolicy and AddPolicyHandler, but not much of an explanation. What is the difference between them? </p>&#xA;"
51123104,Istio request tracing for vert.x event bus messages,2018-07-01 12:02:02,<kubernetes><microservices><vert.x><zipkin><istio>,1,93,0,0.0,0,"<p>Vert.x and kubernetes go hand in and hand. If I am using istio as a service mesh will Zipkin's request tracing be able to track communication done via the event bus?</p>&#xA;&#xA;<p>client ->[rest/http1]-> service-A ->[eventbus]-> service-B</p>&#xA;&#xA;<p>Will istio be able to trace requests done over the eventbus?</p>&#xA;&#xA;<p><a href=""https://istio.io/docs/tasks/telemetry/distributed-tracing/"" rel=""nofollow noreferrer"">The tracing page</a> says that headers need to be propagated through in http or grpc - but the eventbus sends messages via tcp -- does that mean that istio will not be able to trace requests and show the visualisation tools [waterfall graph and visualisation of all the services]</p>&#xA;&#xA;<p><a href=""http://vertx.io"" rel=""nofollow noreferrer"">Vertx main page</a></p>&#xA;&#xA;<p><a href=""https://vertx.io/docs/vertx-core/java/#event_bus"" rel=""nofollow noreferrer"">Eventbus-Vertx page</a></p>&#xA;"
51017946,Task 'bootRepackage' not found in root project 'gateway',2018-06-25 07:07:00,<spring-boot><microservices><jhipster>,1,201,0,0.0,0,"<p>I am reading <a href=""https://www.safaribooksonline.com/library/view/full-stack-development/9781788476317/"" rel=""nofollow noreferrer"">Full Stack Development with JHipster</a> book.&#xA;I created a Microservice gateway with 'gateway' app name.&#xA;By following the book when I run </p>&#xA;&#xA;<blockquote>&#xA;  <p>./gradlew bootRepackage -Pprod buildDocker</p>&#xA;</blockquote>&#xA;&#xA;<p>in the terminal, it says </p>&#xA;&#xA;<blockquote>&#xA;  <p>Task 'bootRepackage' not found in root project 'gateway'</p>&#xA;</blockquote>&#xA;&#xA;<p>and then stop running.&#xA;My Jhipster version is <strong>5.0.0</strong></p>&#xA;"
50935969,accessing database between same instance of a micro service,2018-06-19 19:53:01,<microservices>,1,15,1,0.0,0,"<p>In my project, I have a microservice [say A] and it has a SQL database. We have a 5 node cluster and each of the node this microservice runs. So, We have 5 instances running of service A on the cluster. Now, suppose there is a select query in a particular function of the microservice that is retrieving data from the database. Now, since 5 instance are running, all the 5 instance will use the same query and will work on the same data. Is there any way, in which, we can divide data among 5 instances of service A.</p>&#xA;"
50935415,Microservices and messaging pattern,2018-06-19 19:09:46,<microservices><messages><messagebroker>,2,33,1,0.0,0,"<p>With a solution based on microservices, as it is usually described in ""literature"", in front of the services there is a lightweight layer used, for example, as a load balancer or to implement some kind of authentication and/or authorization.</p>&#xA;&#xA;<p>I am wondering how, in this type of solution, microservices can communicate using messages. If there are no at least one message broker, are messaging implemented directly at the level of JMS (or similar)?</p>&#xA;&#xA;<p>Is it really possible to implement a proper messaging solution without using any message broker?</p>&#xA;"
51087521,How to authenticate the request in this microservice?,2018-06-28 16:20:42,<java><microservices>,1,31,2,0.0,0,"<p>I have my web application(App1) storing user credential in DB.  App1 needs to talk to microservice app2(using same same DB).&#xA;I am not getting how to authenticate the request sent by app1 on app2 ?</p>&#xA;&#xA;<p>My Approach :-</p>&#xA;&#xA;<p>Send  user name/password (sent by client to app1) to app2. App2 will authenticate in DB, if success generate new jsessionId and send it back to app1.&#xA;Now whwn app1 needs to communicate with app2, it will use same jsession which app2 will validate and allow. Is this approach looks good or there can be some other better approach ?</p>&#xA;"
50930291,Eureka and Feign MicroWebservice failing to startup,2018-06-19 13:58:06,<microservices><eureka><feign>,1,65,2,0.0,0,"<p>i have managed to build a microservice with one Eureka server and two client servers, one of the server is using Feign and ribbon to call other service , and this service is getting shutdown immediately after startup. i tried to search for possible problem but i couldn't find any. please help me to resolve it.</p>&#xA;&#xA;<p><strong>controller class</strong></p>&#xA;&#xA;<pre><code>package com.booter.Company.controller;&#xA;&#xA;import java.util.List;&#xA;&#xA;import javax.websocket.server.PathParam;&#xA;&#xA;import org.slf4j.Logger;&#xA;import org.slf4j.LoggerFactory;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.http.ResponseEntity;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RequestMethod;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;import org.springframework.web.client.RestTemplate;&#xA;&#xA;import com.booter.Company.dto.CompanyDTO;&#xA;import com.booter.Company.dto.EmployeeDTO;&#xA;&#xA;@RestController&#xA;@RequestMapping(""/company"")&#xA;public class CompanyController {&#xA;&#xA;    private Logger log = LoggerFactory.getLogger(CompanyController.class);&#xA;&#xA;    @Autowired&#xA;    private CompanyControllerProxy proxy;&#xA;&#xA;&#xA;    @RequestMapping(path= {""/{name}""}, method= {RequestMethod.GET})&#xA;    public CompanyDTO companyDetails(@PathParam(""from"") String name) {&#xA;        CompanyDTO dto = new CompanyDTO();&#xA;        dto.setName(name);&#xA;        dto.setAffiliatedTo(""HCL Group Of Companies.."");&#xA;&#xA;        List&lt;EmployeeDTO&gt; employees = proxy.returnEmployeeList();&#xA;        log.info(""{}"",employees);&#xA;        dto.setEmployees(employees);&#xA;&#xA;        return dto;&#xA;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>feign proxy class to call other service</strong></p>&#xA;&#xA;<pre><code>    package com.booter.Company.controller;&#xA;&#xA;    import java.util.List;&#xA;&#xA;    import org.springframework.cloud.netflix.ribbon.RibbonClient;&#xA;    import org.springframework.cloud.openfeign.FeignClient;&#xA;    import org.springframework.web.bind.annotation.GetMapping;&#xA;&#xA;    import com.booter.Company.dto.EmployeeDTO;&#xA;&#xA;    @FeignClient(name=""person-service"")&#xA;    @RibbonClient(name=""person-service"")&#xA;    public interface CompanyControllerProxy {&#xA;&#xA;        @GetMapping(""/api/persons"")&#xA;        public List&lt;EmployeeDTO&gt; returnEmployeeList();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><strong>Bootstrap class</strong></p>&#xA;&#xA;<pre><code>    package com.booter.Company;&#xA;&#xA;    import org.springframework.boot.SpringApplication;&#xA;    import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;    import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;    import org.springframework.cloud.netflix.eureka.EnableEurekaClient;&#xA;    import org.springframework.cloud.openfeign.EnableFeignClients;&#xA;&#xA;    @SpringBootApplication&#xA;    @EnableFeignClients(""com.booter.Company.controller"")&#xA;    @EnableDiscoveryClient&#xA;    public class CompanyApplication {&#xA;&#xA;        public static void main(String[] args) {&#xA;            SpringApplication.run(CompanyApplication.class, args);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><strong>application.properties file::</strong></p>&#xA;&#xA;<pre><code>    spring.application.name = company-service&#xA;    server.port = 8200&#xA;    eureka.client.serviceUrl.defaultZone=http://localhost:8005/eureka&#xA;</code></pre>&#xA;&#xA;<p><strong>Log</strong></p>&#xA;&#xA;<pre><code>   org.springframework.context.ApplicationContextException: Failed to start bean 'eurekaAutoServiceRegistration'; nested exception is java.lang.NullPointerException&#xA;at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:184) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:52) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:157) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:121) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:885) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:161) ~[spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:553) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:395) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;at com.booter.Company.CompanyApplication.main(CompanyApplication.java:15) [classes/:na]&#xA;</code></pre>&#xA;"
50927770,.NET Microservices with CQRS handling dependencies,2018-06-19 11:52:54,<c#><.net><nuget><microservices>,1,110,2,0.0,0,"<p>Hello I would like you to ask for advise from people that already worked with Microservices on bigger scale thane TODO example.</p>&#xA;&#xA;<p>Let me explain base thoughts about architecture. I want to create system in Microservice architecture with CQRS. I imagine that Microservice A will Handle bunch of Commands and Events but other Microservice can listen on that Event too. So in general somehow I have to separate Event contract between those two Microservices. To get better overview see simple diagram:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/oigyR.jpg"" rel=""nofollow noreferrer"">Diagram</a></p>&#xA;&#xA;<p><em>i'm leave here all bus stuff and handlers and logic inside, I hope it's obvious. I want to focus on contracts only</em></p>&#xA;&#xA;<p>My idea on the beginnig was to put code with Microservice A with all Events for this domain in one solution, but Events will be placed in separate library that will be exposed as nuget. Then this nuget will be consumed by Microservice B which will implement own Handlers based on Contract.</p>&#xA;&#xA;<p>Microservice A solution:</p>&#xA;&#xA;<ul>&#xA;<li>MicroserviceCode (Commands and Handlers with business logic etc)</li>&#xA;<li>DomainContract (Events that can be shared between many services but&#xA;are connected to current solution domain)</li>&#xA;</ul>&#xA;&#xA;<p>MicroserviceCode has project dependency to own DomainContract and other DomainContract nugets</p>&#xA;&#xA;<p>But then I realized that when Microservices will grow and grow and more &#xA;dependencies will come it can start nuget hell and cause dependencies issues because of wrong nuget packages etc. </p>&#xA;&#xA;<p>I also thought about sharing contract as a Rest API in Json format and eliminate nuget versioning.</p>&#xA;&#xA;<p>I would like to discuss about any tips how to avoid hell dependencies between Microservices. </p>&#xA;&#xA;<p>Or maybe you worked with the approach that I describe and it's not that bad than I think?:)</p>&#xA;"
51122354,Coupling in microservices architecture,2018-07-01 10:11:20,<microservices><coupling>,1,33,3,0.0,0,"<p>When working on an application in microservices architecture I stumbled upon issues concerning coupling between services.</p>&#xA;&#xA;<p>This a typical application for ordering products. It seams reasonable to have a service that will operate as a product catalog. Our JavaScript client can ask this service for available products and show them in browser. When user clicks on a product we have to create an order. We would like to manage orders in another service. So an order is created - it means that user X ordered product Y. On the technical level we are simply persisting user id and product id in a database.</p>&#xA;&#xA;<p>To sum up we have:</p>&#xA;&#xA;<h3>Products service</h3>&#xA;&#xA;<p>Product class:<br/>&#xA;Product ID, Product Name </p>&#xA;&#xA;<h3>Orders service</h3>&#xA;&#xA;<p>Order class:<br/>&#xA;Order ID, Product ID,  User ID,   Order date  </p>&#xA;&#xA;<p>Now let's imagine following scenario - in JavaScript client we would like to list all products that user have ordered. Orders service provides a list of products ids for a given user. But user cares about product name, not the id. Unfortunately Orders service doesn't know anything about products names.</p>&#xA;&#xA;<p>We could tackle this in couple of ways:</p>&#xA;&#xA;<ul>&#xA;<li><p>Simply assume that the client is responsible for getting the information it needs. So after it calls Orders service and gets a list of products ids, it performs another call to Products service, passing products ids and getting corresponding products names in response. Then the client assembles both responses into something useful. This approach keeps our services clean, without leaking of domain knowledge from one service to another. But it requires more work on the client side.</p></li>&#xA;<li><p>Orders service when asked for ordered products makes a call on the backend to the Products service. It retrieves product names, assembles a response that contains orderDate and  productName and sends that to client. All that's left for client to do is to present the data. Downside of this approach is that Orders service now gains more knowledge about products than neccessary.</p></li>&#xA;<li><p>Duplicate information about product name in Orders service. When an order is created, we pass not only product id but also product name. That means that Order class will look like this:&#xA;Order class:<br/>&#xA;Order ID, Product ID, Product name, User ID, Order date<br/>&#xA;Now we can easly provide full information about order without additional call to Products service. Also this time Orders service has too much knowledge about products. What's beneficial tough is that Orders service can provide relevant data even if Products service is down.</p></li>&#xA;</ul>&#xA;&#xA;<p>Could any of these approaches be considered best practice? Or are there different solutions?</p>&#xA;"
51120978,Is REST a good fit for microservices?,2018-07-01 06:33:36,<rest><microservices><synchronous>,2,48,3,0.0,0,"<p>I am exploring micorservices architecture through books, blogs etc. </p>&#xA;&#xA;<p>What I have seen is that mostly people implement microservices using REST. Isn't it contradictory?</p>&#xA;&#xA;<p>Microservices are supposed to decouple services to achieve scalability, but REST communication protocol is synchronous. </p>&#xA;&#xA;<p>So how can these two go together?</p>&#xA;"
38048683,Permanent redirect from example.com/ to https://www.example.com/dir/,2016-06-27 08:01:15,<redirect><nginx><microservices>,2,30,0,0.0,0,"<p>I have some software build with microservice philosophy. On of them - which was hosted on <code>example.com/</code> became useless so I want the user to be redirected to <code>example.com/dir/</code> where another service is hosted. The most popular solution on <code>StackOverflow</code> is to use the following code in the configuration file:</p>&#xA;&#xA;<pre><code>location = / {&#xA;    return 301 $scheme://$http_host/dir/;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>or</p>&#xA;&#xA;<pre><code>location = / {&#xA;    return 301 https://$http_host/dir/;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>They both fail on my server - the server returns <code>503 - to many computations</code>. The stacktrace shows, that there is no rule-infinite-rule so this code might be returned by <code>load-balancer</code>.</p>&#xA;&#xA;<p>Is there any other well working solution for this issue? <code>StackOverflow</code> and <code>ServerFault</code> have just been carefully searched for the last 3 days by me and any solution worked.</p>&#xA;"
38121112,.NET Core Authorize attribute with external JWT authentication microservice?,2016-06-30 10:57:14,<asp.net-web-api><authorization><asp.net-core><jwt><microservices>,2,1615,0,1.0,0,"<p>So I'm just having a bit of trouble getting my head round the .NET Core [Authorize] attribute.</p>&#xA;&#xA;<p>I have an authentication service running (let's say <code>authapi.com</code>) which when provided with valid authentication details will return a JWT.  When this JWT is given back to it, it will validate the JWT and return a message indicating such.</p>&#xA;&#xA;<p>So, I'm now building another WebAPI (let's say <code>genericapi.com</code>)which will require authorization for some of the actions/controllers.  The idea being, the JWT will be passed in the headers of the request to <code>genericapi</code> which then needs to pass those on to <code>authapi.com</code> to validate them.</p>&#xA;&#xA;<p>I tried adding a Policy but it got convoluted really quick, and I had to write <code>[Authorize(Policy=""TokenValid"")]</code> on everything, when I'd rather just the default <code>[Authorize]</code> did this, since ALL authorization will have to hit <code>authapi</code>.</p>&#xA;&#xA;<p>How would I go about getting that JWT from the header and passing it to the <code>authapi</code> as standard behaviour for <code>[Authorize]</code>?</p>&#xA;&#xA;<p>Bear in mind: I don't want to do anything with the JWTs on <code>genericapi</code>, all authentication is to be handled by <code>authapi</code>.</p>&#xA;"
38178208,Can CakePhp 2.x or 3.x be used to develop web app based on micro service architecture,2016-07-04 06:35:33,<rest><cakephp><cakephp-3.0><microservices><cakephp-2.8>,1,447,5,0.0,0,<p>I was evaluating PHP based frameworks for development of highly available and scalable applications based on micro service architecture. </p>&#xA;&#xA;<p>I have not seen any documentation for using CakePhp 2.x or 3.0 for design and development of micro services. Where as Laravel ( which is another PHP MVC framework based on Symphony) seems to have these capabilities based on its Lumen modules or components.</p>&#xA;&#xA;<p>It appears that CakePhp frameworks are only suited for design and development of big gigantic monolithic app. </p>&#xA;&#xA;<p>Can anyone point me to a documentation or example about how to use CakePhp 2.x or 3.x for designing web apps based on Micro service architecture ? </p>&#xA;
36176403,Spring boot microservice with OAuth 2 and JWT for Security,2016-03-23 11:04:25,<oauth-2.0><spring-boot><jwt><microservices><api-management>,1,1343,0,0.0,0,"<p>I am developing a Spring boot application for payment using microservices, which will be consumed by mobile application and web application. </p>&#xA;&#xA;<p>1) Users need to be authenticated for accessing the mobile app</p>&#xA;&#xA;<p>2) Third party mobile apps using my services need to be authenticated (with my app)</p>&#xA;&#xA;<p>3) Web applications using my services need to be authenticated. </p>&#xA;&#xA;<p>My user details will be there in DB or LDAP. I have plans for integrating IBM API management and the deployment will be in on-premise servers. Based on this requirement how I need to design and implement my solution? </p>&#xA;&#xA;<p>After going through different blogs I am confused now. So a proper guidance will be very helpful for me.</p>&#xA;"
36285239,Acknowledgement to clients on asynchronous microservice,2016-03-29 13:08:53,<design-patterns><asynchronous><design><architecture><microservices>,1,324,0,0.0,0,"<p>I read everywhere that service to service calls should be asynchronous in microservices. When the request has to pass through 2 or more async services, how can we do the client acknowledgement? </p>&#xA;&#xA;<p>Here is my real time scenario. We are developing an email sending functionality in our organisation.  We are planning to have 4 API services for this in the following order.</p>&#xA;&#xA;<ol>&#xA;<li>Public API - exposing the email functionality to public</li>&#xA;<li>Validation API - to validate the genuineness of the email and other fields</li>&#xA;<li>Template fetching API - fetch the email templates from database/CMS and prepare the final content to be sent</li>&#xA;<li>Email sending API - will receive the recipient and the email content</li>&#xA;</ol>&#xA;&#xA;<p>The problem is, we have to acknowledge the client who initiated the request with some id if successful, otherwise have to return the error code. If we have to adapt the best practice of making asynchronous service to service call, how we can acknowledge the client from Email sending API(final API)? </p>&#xA;"
36318795,Example of Sidecar Application for Microservices,2016-03-30 20:12:22,<spring><spring-boot><spring-cloud><microservices>,1,1501,1,0.0,0,<p>Is Spring cloud config server an example of sidecar application for microservices?</p>&#xA;
36174288,Dockerize Applications or Machines?,2016-03-23 09:29:47,<docker><virtual-machine><containers><docker-compose><microservices>,1,236,1,0.0,0,"<p>I apologize if my question is too basic, but I just started to learn docker and there are some concepts that are not clear to me. </p>&#xA;&#xA;<p>I think of docker as a fully functional virtual machine, and therefore I thought of transforming a server with a set of services, into a container. Then I started reading about ""dockerizing"" applications (for instance <a href=""https://docs.docker.com/engine/examples/postgresql_service/"" rel=""nofollow"">postgresql</a>), and I learned that a <a href=""https://docs.docker.com/engine/reference/builder/#cmd"" rel=""nofollow"">Docker file can only have one default instruction, when executing a container</a>. I read that it is possible to coordinate multiple executing instructions using a <a href=""https://docs.docker.com/engine/admin/using_supervisord/"" rel=""nofollow"">supervisor</a>, but I started wondering if that is really the best approach, or if it would be better to lean towards a <a href=""https://medium.com/aws-activate-startup-blog/using-containers-to-build-a-microservices-architecture-6e1b8bacb7d1#.jbhr2uke1"" rel=""nofollow"">microservices architecture</a>?</p>&#xA;&#xA;<p>To state better my point, I would like to describe my use case. I want to create an environment that provides tomcat (with some services deployed through servlets) and a postgreSQL database. Ideally, I would like the services (and the database), to run in the same host (on different ports).</p>&#xA;&#xA;<p>Is it a best practice to create one container for Tomcat and one for the Database, or is it better to ship them in the same container?</p>&#xA;&#xA;<p>And if I create two different containers, which framework should I use to orchestrate them? Is it <a href=""https://docs.docker.com/compose/"" rel=""nofollow"">Docker compose</a> appropriated for this task?</p>&#xA;"
39343694,"when doing docker compose, is it possible to keep previous docker composition",2016-09-06 08:04:44,<docker><docker-compose><microservices><docker-container>,1,22,0,0.0,0,"<p>I have a docker composition with 3 contaiers. I would like to keep these 3 containers and recreate another instance of the composition, without reusing, nor deleteing the previous 3 containers. Conceptually, would be like running 2 intances of the same application, where the application is the composition.<br>&#xA;Docker compose always tries to reuse the existing containers.  </p>&#xA;"
39348995,Is there a design pattern for that : send a blank form and receive it back compeleted,2016-09-06 12:25:04,<rest><design-patterns><microservices>,1,31,0,0.0,0,"<p>Is there a design pattern for that ?&#xA;A rest microservice receives a JSon data structure, with no value (but maybe an id) and returns back the same data with blanks filed? Example :</p>&#xA;&#xA;<p>Input :</p>&#xA;&#xA;<pre><code>{&#xA;    id: 1546,&#xA;    name: ,&#xA;    height: ,&#xA;    color:&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Output :</p>&#xA;&#xA;<pre><code>{&#xA;    id: 1546,&#xA;    name: ""Bob"",&#xA;    height: 40,&#xA;    color: ""yellow""&#xA;}&#xA;</code></pre>&#xA;"
39369856,Tool for slicing app into microservices,2016-09-07 12:21:43,<ruby-on-rails><ruby><microservices>,1,41,0,0.0,0,<p>We've refactored our code a bit and I feel that we could separate some parts of our app into microservices. However it would be helpful to use a tool that would show me a graph of references between parts (directories) of our app.</p>&#xA;&#xA;<p>Our app is in Ruby on Rails.</p>&#xA;&#xA;<p>I know that I won't get 100% coverage of coupling between modules since ruby is a dynamic language... any graph would be useful though.</p>&#xA;
39306577,microservices - Best Practice for dealing with ghost records in transactionless systems,2016-09-03 11:50:43,<database><microservices><nosql>,2,68,1,0.0,0,"<p>I am developing a system based on NoSQL and microservices architecture.   </p>&#xA;&#xA;<p>I have a general architectural question - </p>&#xA;&#xA;<p>Le'ts say I have three types of documents - Countries, Cities and Streets.<br>&#xA;Where Street holds a CityId and City holds a CountyId.    </p>&#xA;&#xA;<p>At the country service I need to develop a <strong>deleteCountry()</strong> methods that: </p>&#xA;&#xA;<ol>&#xA;<li>Deletes the country. </li>&#xA;<li>Requests the city service to delete all the cities by countryID. </li>&#xA;<li>The city service in its turn then requests all the streets service to delete all of the streets by cityIds.   </li>&#xA;</ol>&#xA;&#xA;<p><strong>Problem:</strong> if this process fails after the country deletion, in a transaction-less world, I am left with a few 'ghost' documents.  </p>&#xA;&#xA;<ul>&#xA;<li>I can manage the failure in my orchestration so that it will clean&#xA;after it, but this is not scalable (code-wise) solution. </li>&#xA;<li>I can work with a choreography pattern but it doesn't really solve it.  </li>&#xA;<li>I can run a periodical sweeping process that will clean documents but it will&#xA;be hard to manage and will leave time holes where the problem will still exist.</li>&#xA;</ul>&#xA;&#xA;<p>What is the best practice to remove ghost records from a NoSQL db.<br>&#xA;Thanks.   </p>&#xA;"
39367722,spring cloud sleuth and Oauth2Template,2016-09-07 10:42:56,<java><rest><spring-data><microservices><spring-cloud-sleuth>,1,135,1,0.0,0,"<p>We are using microservices with oauth2 as security mechanism.&#xA;At the moment we are calling other microservices with <code>OAuth2RestTemplate</code> like this: </p>&#xA;&#xA;<pre><code>template.postForObject(""http://""+MY_DISCOVERY_NAME+""/path/to/restservice"", params, Void.class);&#xA;</code></pre>&#xA;&#xA;<p>We are using @Autowired to inject OAuth2RestTemplate as follows: </p>&#xA;&#xA;<pre><code>  @Configuration&#xA;  public class ApplicationConfig {&#xA;&#xA;      @Autowired&#xA;      OAuth2RestTemplate oauth2Resttemplate;&#xA;      ...&#xA;      @Bean&#xA;      public MyBean getMyBean() {&#xA;          MyBeanImpl myBean = new MyBeanImpl();&#xA;          oauth2Resttemplate.setErrorHandler(getErrorHandler());&#xA;          myBean.setTemplate(oauth2Resttemplate);&#xA;          return myBean;&#xA;      }&#xA;      ...&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>So next step for us is to make the calls tracable. &#xA;We want to use spring cloud sleuth.</p>&#xA;&#xA;<p>So I added the dependency as follows: </p>&#xA;&#xA;<pre><code>    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that Spring is not able to autowire OAuth2RestTemplate anymore: </p>&#xA;&#xA;<pre><code>Caused by: java.lang.IllegalArgumentException: Can not set org.springframework.security.oauth2.client.OAuth2RestTemplate&#xA;</code></pre>&#xA;&#xA;<p>In org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor an IllegalArgumentException is thrown: </p>&#xA;&#xA;<pre><code>            @Override&#xA;            protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable {&#xA;                 ...&#xA;&#xA;                            }&#xA;                            if (value != null) {&#xA;                                    ReflectionUtils.makeAccessible(field);&#xA;                                    field.set(bean, value);&#xA;                            }&#xA;                    }&#xA;                ...&#xA;</code></pre>&#xA;&#xA;<p><code>field.set(bean, value);</code> results in following Exception: </p>&#xA;&#xA;<pre><code>java.lang.IllegalArgumentException: Can not set org.springframework.security.oauth2.client.OAuth2RestTemplate field my.package.ApplicationConfig.oauth2Resttemplate to com.sun.proxy.$Proxy120&#xA;</code></pre>&#xA;&#xA;<p>How can I use OAuth2RestTemplate in combination with sleuth?</p>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<p>Max</p>&#xA;"
39361356,Azure Service Fabric Multi-Tenancy with microservice,2016-09-07 04:43:09,<asp.net><azure><multi-tenant><microservices>,1,350,2,0.0,0,"<p>I  want  to  develop   the  Micro-service   apps    using   Azure Service Fabric Multi-Tenant ,   for   this   i   already   Configured   Active   Directive   with   Multi   Domain   dev,Prod   etc.</p>&#xA;&#xA;<p>I  did   not  get  any   sample   reference    which   will  help   me   to   get  start   this   topic</p>&#xA;&#xA;<p>I   already   followed   this   link</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/35247726/azure-service-fabric-multi-tenancy"">Azure Service Fabric Multi-Tenancy</a></p>&#xA;&#xA;<p>But   not   find   any   sample   reference  </p>&#xA;"
39338259,Dropwizard: Microservice Architecture,2016-09-05 22:15:30,<dropwizard><microservices>,1,235,7,0.0,0,"<p>This is similar to <a href=""https://stackoverflow.com/questions/6994054/how-to-deserialize-from-a-file-to-different-class"">How to deserialize from a file to different class</a>. But, I'm developing micro-services using Dropwizard. </p>&#xA;&#xA;<p>I have two services, service A and service B. I have a message queue (RabbitMQ) setup between the two services. </p>&#xA;&#xA;<p>I am trying to send an object of type Class A (defined in service A) from service A to service B. I have not imported class A in service B. However in service B i have Class B defined which is exactly same as Class A. </p>&#xA;&#xA;<p>I am getting a ClassNotFoundException: Class A in service B when service B tries to deserialize and typecast the object to Class B.  </p>&#xA;&#xA;<p>I want the two jars to be as independent as possible. &#xA;Is there a way to do this. </p>&#xA;"
39139313,Which database for savings sets of variables with various types?,2016-08-25 07:36:48,<database-design><architecture><microservices>,1,31,0,0.0,0,"<p>I want to design a microservice. The goal is to save and serve sets of variables :</p>&#xA;&#xA;<p>1 set is composed of several variables :</p>&#xA;&#xA;<ul>&#xA;<li>height : <code>Float</code></li>&#xA;<li>name : <code>String</code></li>&#xA;<li>birthDate : <code>Date</code></li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Every set has a predefined list of variables : (height, name, birthDate) with different types, always the same list. BUT, the list can change sometimes and we dont want to write new code then build then deploy it every time we do that. Ideally this list will be also stored in the database.</p>&#xA;&#xA;<p>Also, one set must have a reference to an object which is stored outsilde the microservice. Let's say a set is linked to one <code>User</code>, so we have to keep a user identifier somewhere.</p>&#xA;&#xA;<p>The question is : I know SQL databases and I have understood that they are not very suited for this kind of problem (it is not impossible, just ugly). So what other solution do I have?</p>&#xA;"
39068073,Spring boot redirects from hostname to local ip address from discovery | Embedded Tomcat | Zuul proxy,2016-08-21 19:27:49,<spring-boot><reverse-proxy><spring-security-oauth2><microservices><service-discovery>,1,1062,0,0.0,0,"<p>I'm developing an application base on a micro service architecture.</p>&#xA;&#xA;<p>We have a few microservies: <em>oauth2</em>, <em>hello-web</em>, <em>discovery server</em> (eureka) and <em>reverse proxy</em> (zuul). The <em>oauth2</em> (authentication server sing on) and <em>hello-web</em> are behind the same <em>reverse proxy</em> with different path. Url to them are provided by <em>discovery server</em> (<strong>serviceId</strong> in zuul). </p>&#xA;&#xA;<p>Simple application is here: <a href=""https://github.com/akhmelov/test-zuul-oauth2"" rel=""nofollow"">https://github.com/akhmelov/test-zuul-oauth2</a></p>&#xA;&#xA;<p><em>Reverse proxy</em> is located on localhost:8083</p>&#xA;&#xA;<ul>&#xA;<li><em>oauth2</em> has route: /uaa/**</li>&#xA;<li><em>hello-web</em> has route: /hello-web/**</li>&#xA;</ul>&#xA;&#xA;<p>We met 2 problems during development:</p>&#xA;&#xA;<ol>&#xA;<li><p>When user hit to localhost:8083/hello-web, it forwards request to <em>hello-web</em> microservice. On the first request the user is unauthenticated, so <em>hello-web</em> service should redirects to localhost:8083/uaa/ (for log in user) </p>&#xA;&#xA;<p>Our problem is that during the first request (when user is unathenticated) <em>hello-web</em> redirects not to <em>localhost</em> but to ip  10.2.8.11:8083/uaa which is the same as in discavery server. It changes serverName. We checked x-forward-host in <em>hello-web</em> by debugging is <strong>localhost</strong>, so the serverName is changed in <em>hello-web</em> <strong>but where (how to disable it)? and how hello-web knows about gateway's ip from eureka?</strong> </p></li>&#xA;<li><p>When user hit instead of localhost:8083/hello-web to 10.2.8.11:8083/hello-web (where 10.2.8.11 is ip of <em>reverse proxy</em> from <em>discovery server</em>).On the first request (when user is unauthenticated) <em>hello-web</em> redirects to 10.2.8.11:8083/uaa (<em>oauth2</em> server) which redirect to 10.2.8.11:8083/uaa/login, when user fills in password it redirects to 10.2.8.11:8083/uaa and user get HTTP 404. &#xA;If user do the same without <em>reverse proxy</em> (I mean if <em>hello-web</em> is on localhost:8080, <em>oauth2</em> is on localhost:8087 and during first request <em>hello-web</em> redirects directly to localhost:8087 without <em>reverse proxy</em>) everything works fine. <strong>Why does it happen? How to fix it?</strong></p></li>&#xA;</ol>&#xA;&#xA;<p>We spend a couple of days trying to find solution or similar questions with no result, did we miss something? </p>&#xA;&#xA;<p>Note:</p>&#xA;&#xA;<ul>&#xA;<li>My /ect/hosts: </li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>127.0.0.1 localhost</p>&#xA;  &#xA;  <p>127.0.0.1 some_my_computer_name</p>&#xA;</blockquote>&#xA;&#xA;<ul>&#xA;<li>Discovery server (Eureka ""Instances currently registered with Eureka"")</li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>Application   AMIs    Availability Zones  Status</p>&#xA;  &#xA;  <p>GATEWAY   n/a (1) (1) UP (1) - 10.2.8.11:gateway:8083</p>&#xA;  &#xA;  <p>HELLO-WEB n/a (1) (1) UP (1) - 10.2.8.11:hello-web:8080</p>&#xA;  &#xA;  <p>UAA   n/a (1) (1) UP (1) - 10.2.8.11:uaa:8087</p>&#xA;</blockquote>&#xA;&#xA;<ul>&#xA;<li>We know about cookies&#xA;<strong>spring.io/guides/tutorials/spring-boot-oauth2/#_testing_the_oauth2_client</strong>&#xA;and from the same page</li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>The context path has to be explicit if you are running both the client and the auth server on localhost, otherwise the cookie paths clash and the two apps cannot agree on a session identifier.</p>&#xA;</blockquote>&#xA;&#xA;<p>Sorry for poor english</p>&#xA;"
39014049,Netty add httprequest to server handling,2016-08-18 09:03:54,<java><netty><microservices>,1,63,0,1.0,0,"<p>I use microservice architecture in my project. And for interservice communication I use message queue <a href=""http://nats.io/"" rel=""nofollow"">NATS</a>. I wrote a gateway, that handle all http requests and put it to queue. All end point services are subscribed to this queue.</p>&#xA;&#xA;<p>At endpoint services I use <a href=""http://xitrum-framework.github.io/"" rel=""nofollow"">Xitrum</a> based on Netty IO. When I get request from queue, I deserialise it to FullHttpRequest. But I don't know how to send it to my netty server, that can handle it  according to business logic   (without using external httpclient, for example, that can send it to localhost)</p>&#xA;&#xA;<p>Is there any possibility to send FullHttpRequest instance to netty server (listening localhost:8000) using netty api? Or may be another solution. What is the common approach?</p>&#xA;"
38970723,How to programmatically specify the IP and port of a dependent docker container created by Marathon?,2016-08-16 09:04:40,<docker><microservices><mesos><marathon>,1,101,0,0.0,0,"<p>I am learning Micro-services architecture by writing a small web app. The app has the following components, each of which will be hosted by a docker container.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/krHg8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/krHg8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In my API Gateway which is written in NodeJS, there is some place I will call:</p>&#xA;&#xA;<pre><code>request('http://service_b_ip_addr:port/get_service_b', callback);&#xA;</code></pre>&#xA;&#xA;<p>However, both <code>service_b_ip_addr</code> and <code>port</code> are not known until Marathon has the Service B's docker container created.</p>&#xA;&#xA;<p>With some Service Discovery mechanism, such as <em>mesos-dns</em> or <em>marathon-lb</em>, I guess that I could just change <code>service_b_ip_addr</code> to something like <code>service_b.marathon.com</code>. </p>&#xA;&#xA;<p>But I've no idea how should I put the <code>port</code> in my program.</p>&#xA;&#xA;<p>Thanks in advance for your help.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>PS: </p>&#xA;&#xA;<ol>&#xA;<li>I am using BRIDGED network mode given that multiple instances of a Service could locate on the same Mesos slave. So <code>port</code> is a NATted random number.</li>&#xA;</ol>&#xA;"
38974070,Difference between service registry and discovery,2016-08-16 11:45:10,<apache-zookeeper><microservices><curator>,1,122,0,0.0,0,<p>Like to know the difference between Service Registry and Discovery in Zookeeper in terms of Microsesrvices</p>&#xA;
39135928,Is it possible to use Hazelcast with Netflix OSS stack?,2016-08-25 02:47:14,<hazelcast><spring-cloud><microservices><netflix-eureka><spring-cloud-netflix>,1,159,0,0.0,0,"<p>Currently we are building a platform using Netflix OSS stack (Microservices). We want to use HazelCast as a caching solution. Can anyone please help me like, how can I integrate HazelCast into Netflix OSS. is it recommended ?</p>&#xA;"
37247409,Microservices database migration with existing foreign key,2016-05-16 05:45:09,<ruby-on-rails><rails-migrations><microservices>,1,109,0,0.0,0,<p>We have a rails application where we need to run a database migration (to add transactional reference data) which refers to a primary key on another independent service. The only way I can think of doing this as of now is adding a http call in the migration to get the key from the other service. Was wondering if there was a cleaner way of achieving this ? </p>&#xA;
37289487,Spring: How to Resolve a Property When There Are Multiple Resolvers?,2016-05-18 02:58:39,<spring><spring-mvc><spring-cloud><microservices><netflix-eureka>,1,124,0,1.0,0,"<p>We are building several Microservices using the Spring Cloud framework. One of the services has dependencies on some legacy shared libraries, and imports various XML files for bean configuration. The problem we are facing is that through these imports, multiple property resolvers are brought in and thus the following code in <a href=""https://github.com/spring-projects/spring-framework/blob/master/spring-beans/src/main/java/org/springframework/beans/factory/support/AbstractBeanFactory.java"" rel=""nofollow"">AbstractBeanFactory</a> is failing to resolve <code>spring.application.name</code> because the value comes in as <code>${spring.application.name:unknown}</code> that the first resolver fails to resolve and thus sets <code>result</code> to <code>unknown</code>. <code>embeddedValueResolver</code> does have a resolver than can resolve the property but because the property is set to it's default by a previous resolver, it doesn't get a chance. This is causing the service registration with Eureka to fail with a NPE.</p>&#xA;&#xA;<pre><code>@Override&#xA;public String resolveEmbeddedValue(String value) {&#xA;    String result = value;&#xA;    for (StringValueResolver resolver : this.embeddedValueResolvers) {&#xA;        if (result == null) {&#xA;            return null;&#xA;        }&#xA;        result = resolver.resolveStringValue(result);&#xA;    }&#xA;    return result;&#xA;}&#xA;</code></pre>&#xA;"
37213471,Best Practices when Migrating to Microservices,2016-05-13 15:05:28,<refactoring><microservices>,3,145,0,0.0,0,"<p>To anyone with real world experience breaking a monolith into separate modules and services.</p>&#xA;&#xA;<p>I am asking this question having already read the <a href=""http://martinfowler.com/bliki/MonolithFirst.html"" rel=""nofollow"">MonolithFirst</a> blog entry by Martin Fowler. When taking a monolith and breaking it into microservices the ""size"" element of the equation is the one that I ponder over the most.  Specifically, how to approach breaking a monolith application (we're talking 2001: A Space Oddessy; as in it is that old and that large) into micro services without getting overly fine grained or staying too monolithic.  The end goal is creating separate modules that can be upgraded indepenently and scaled independently.</p>&#xA;&#xA;<p>What are some recommended best practices based on personal experience of breaking a monolith into microservices?</p>&#xA;"
37150273,Spring cloud config specify netmask,2016-05-10 22:57:50,<java><spring><microservices><netflix-eureka><rancher>,2,146,0,0.0,0,"<p>I'm trying to deploy a cluster of microservices using <code>Rancher</code> on multiple Amazon instances.</p>&#xA;&#xA;<p>A problem that I've encountered is that every docker container now has 2 IP addresses; 1 local IP address, defined by docker itself, and another IP address that is routed to the Rancher bridge.</p>&#xA;&#xA;<pre><code>45: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default &#xA;    link/ether 02:b4:d3:52:be:25 brd ff:ff:ff:ff:ff:ff&#xA;    inet 172.17.0.4/16 scope global eth0&#xA;       valid_lft forever preferred_lft forever&#xA;    inet 10.42.232.123/16 scope global eth0&#xA;       valid_lft forever preferred_lft forever&#xA;</code></pre>&#xA;&#xA;<p>The IP address defined by <code>Rancher</code> is the one in the <code>10.42.*.*</code> range and is unique for every container, this is why I want to let my Spring cloud configs use this IP address.</p>&#xA;&#xA;<p>No I've found that you can specify in the config which interface to use, but is it also possible to specify the subnet? Because both IP's are on the same interface (<code>eth0</code>) but the services should use the 10.42.<em>.</em> (e.g. to register themselves with at the discovery service).</p>&#xA;&#xA;<p>I hope someone can help me further with this.</p>&#xA;&#xA;<p>Relevant part of my config:</p>&#xA;&#xA;<pre><code>eureka:&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>(Eureka uses the same config as spring cloud)</p>&#xA;"
37219072,MicroServices and ERP,2016-05-13 20:45:22,<c#><architecture><domain-driven-design><microservices>,1,489,1,0.0,0,"<p>I'm developing an ERP system ( logistics, WMS , Sales, etc.) in C # using DDD and I 'm trying to apply MicroServices and entered the big question:</p>&#xA;&#xA;<p>How to organize microservices in an ERP , the responsabilides and how the core functions ?</p>&#xA;&#xA;<p>Does anyone have any practical example ?</p>&#xA;"
37084619,Task ownership in microservices architecture,2016-05-07 04:50:56,<architecture><microservices>,1,108,2,0.0,0,<p>In my system tasks are stored in a central place. The services will pick a task they can handle and execute them. Multiple instances of same service are run to handle the demand.</p>&#xA;&#xA;<p>Now the question is how to make sure that a task is executed by only one instance of a service. Is there a common or widely used pattern to do this in microservices architecture?</p>&#xA;
44029177,"What are basic concepts one should know about OAuth, SAML, Microservices?",2017-05-17 15:32:46,<oauth-2.0><saml><microservices>,1,28,0,0.0,0,<p>What concepts about these topics a mid level java developer should know ?</p>&#xA;
44117865,RESTful APIs for unnormalized (NoSQL) entities?,2017-05-22 16:27:51,<rest><cassandra><microservices><nosql>,1,46,0,1.0,0,"<p>I am currently working on a project where we are developing a set of microservices in Scala with Cassandra as our database. I was wondering whether we have any standards&#xA;for writing RESTful APIs for entities that are not even in 1st Normal Form ??</p>&#xA;&#xA;<p>I will cite a typical example.</p>&#xA;&#xA;<p>Consider an entity set Fruits. In the traditional RDBMS if we were to store the colors of the fruits we could create a table Colors have&#xA;a integer associated with each color as its primary key. For mapping a color to a fruit you could have another relation that would map fruits to colors. Our database&#xA;design satisfies Boyce Codd Normal form and we can design intuitive REST end points.</p>&#xA;&#xA;<pre><code>/fruits(/:id)&#xA;/colors(/:id)&#xA;/fruits/:id/colors&#xA;/colors/:id/fruits&#xA;</code></pre>&#xA;&#xA;<p>Enter NoSQL databases. Colors is an attribute of the Fruits entity sets itself and it's domain is a set of varchar. If I were to insert Apple into the dataset and associate&#xA;colors red and green, I would have to store these strings as a part of that record in a set.</p>&#xA;&#xA;<p>What if I want to update the entity now and remove green from the list ? Or maybe add a new color to the list ?</p>&#xA;&#xA;<p>Should this be broken into a separate endpoint irrespective of the underlying database design ? Or should it be part of the payload ?</p>&#xA;&#xA;<p>Something similar to</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""Apple"",&#xA;    ""colors"": [""green', ""red""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Thanks,</p>&#xA;&#xA;<p>Utsav</p>&#xA;"
44097193,Snort or Suricata whilst using Docker?,2017-05-21 13:02:39,<security><containers><microservices><snort><suricata>,1,558,0,0.0,0,"<p>Guess I am going to use multiple docker files for my <strong>IDS/IPS</strong> - using microservice. Say more than 50 <em>docker</em> containers for it.&#xA;Would you use <em>Suricata</em> or <em>Snort</em>? Is it really important that Snort is not <em>multithread</em>, and does it snort <em>weaker</em> than Suricata??</p>&#xA;"
44170365,Output progress for console and web applications,2017-05-25 00:16:30,<php><logging><architecture><yii2><microservices>,1,63,0,0.0,0,"<p>I'm writing an yii2 app that is mainly used as an console application. I have components or (micro)services that fetches some data from a server, handle them and save the information I need to db. Of course there are several <strong>for loops</strong> and in these loops I output my current progress with the use of <code>yii\helpers\Console::updateProgress</code> or just <code>echo</code> to watch the progress and testing output (like <em>starting with xxx products</em>). On some events  I log important informations with <code>Yii::info()</code> or <code>Yii::error()</code> and so on. Normally a cron handling tasks like <code>pullProductUpdates</code> or something else and i.</p>&#xA;&#xA;<p>However in some cases I need the method (i.e. <code>pullProductUpdates</code>) in my webapplication too. But then there must not be any <code>echo</code> command active or <code>Console::updateProgress</code> commands.</p>&#xA;&#xA;<p>Of course I don't have problems with the logging methods from Yii because I configured the log targets and they will not echoing something. But I'm uncertain how to handle the <code>echo</code> commands...</p>&#xA;&#xA;<p>One way is to check wether <code>$_SERER['REMOTE_ADDR']</code> is set or not. In console it will evaluate to <code>null</code> so I can warp an <code>if {} else {}</code> around. A probably better solution is to write a <code>log()</code> or <code>progress()</code> method. A trait could be useful?</p>&#xA;&#xA;<p>So how should I design a solution? Is there any pattern for this? Should my services implement an interface like <code>loggable</code> or <code>proressable</code>? Or use an Logger/ Progress objects and use some kind of DI (dependency injection)? Because I don't want to write those <code>log()</code> or <code>progress()</code> methods functions more than one time. Besides I can't use a progress function in a webapplication. One reason is I don't know how to to that (if its possible with php here), but this would be another question.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
44067979,Spring Config Server Service with Heroku,2017-05-19 10:42:30,<heroku><spring-boot><microservices><heroku-api><configserver>,1,83,0,0.0,0,<p>I am exploring Heroku. I have a project which has <strong>10 micro services</strong>. One of which is a <strong>configuration server</strong> which takes care of <strong>managing configuration for all services</strong> using git hub.</p>&#xA;&#xA;<p>I want to use Heroku for deploying these services but I am not sure how would my Spring Boot Configuration Server would work as Heroku provides a way to configure each hosted app separately(Can configure DB settings for individual app).</p>&#xA;&#xA;<p>Any suggestions/ thoughts would be appreciated. </p>&#xA;
44203398,Cloud Foundry Mutual SSL 502 exception,2017-05-26 13:54:17,<spring-boot><microservices><pivotal-cloud-foundry>,1,157,0,0.0,0,<p>We are trying to implement mutual SSL through API gateway for our Springboot MicroService. Call from API Gateway to MicroService fails in PCF with 502 bad gateway. &#xA;502 Bad Gateway: Registered endpoint failed to handle the request.</p>&#xA;&#xA;<p>not sure what how to resolve it. I believe this is related to certificate configuration on PCF. Please help.</p>&#xA;
44105840,How to embed images and attach files from spring boot resources folder,2017-05-22 06:18:18,<rest><spring-boot><resources><microservices><amazon-ses>,1,932,0,0.0,0,"<p>Not able to embed images and attach files from spring boot resources folder</p>&#xA;&#xA;<p>I have created a Restful web service using Spring Boot (Jar file and not a War file). Some of the services will send emails and some of them will send emails with attachments (Will be created dynamically). Web part (Angular) resides in Apache server which is deployed in different server.</p>&#xA;&#xA;<p>I am using Freemarker template to compose email and using Amazon SES to send emails. </p>&#xA;&#xA;<p>from freemarker template</p>&#xA;&#xA;<pre><code>&lt;IMG src=""cid:gridEmailHeaderImage""&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Code to add image</strong></p>&#xA;&#xA;<pre><code>MimeBodyPart inlineImage = new MimeBodyPart();&#xA;DataSource fds = new FileDataSource(imagePath.getAbsolutePath());&#xA;inlineImage.setDataHandler(new DataHandler(fds));&#xA;inlineImage.setHeader(""Content-ID"", ""&lt;"" + contentId + ""&gt;"");&#xA;inlineImage.setFileName(fds.getName());&#xA;content.addBodyPart(inlineImage);&#xA;</code></pre>&#xA;&#xA;<p>I am able to embed and attach files if I provide absolute path. But if provide relative path it is not working. </p>&#xA;&#xA;<p><strong>My folder structure</strong></p>&#xA;&#xA;<pre><code>C:\workspace\service-1.0\src\main\resources\images\header.png&#xA;C:\workspace\service-1.0\src\main\resources\attachements\test-attachment-1.txt&#xA;</code></pre>&#xA;&#xA;<p>I tried the following with no sucess</p>&#xA;&#xA;<p><strong>Approach 1</strong></p>&#xA;&#xA;<pre><code>ServletContext context;&#xA;String path = context.getRealPath(""/resources/images"")+""/header.png"";&#xA;</code></pre>&#xA;&#xA;<p>It is looking for images in the following folder but the images is not available in that folder.</p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Users\username\AppData\Local\Temp\tomcat-docbase..\resources\images/header.png</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Approach 2</strong></p>&#xA;&#xA;<pre><code>basePath = this.getClass().getClassLoader().getResource(""/images/"").getPath();&#xA;</code></pre>&#xA;&#xA;<p>C:\workspace\service-1.0\src\main\resources\images\header.png</p>&#xA;&#xA;<p>/C:/workspace/service-1.0/build/libs/service-1.0.jar!/BOOT-INF/classes!/images/&#xA;(Works only from eclipse but not from command prompt java -jar build\lib\myapp.jar)</p>&#xA;&#xA;<p><strong>Approach 3</strong></p>&#xA;&#xA;<pre><code>ClassPathResource file = new ClassPathResource(""header.png"");&#xA;String mypath = file.getFile().getAbsolutePath();&#xA;</code></pre>&#xA;&#xA;<p>(This also didn't work)</p>&#xA;&#xA;<p>If I place the image in images folder under resource. I am able to view the image via the following URL.</p>&#xA;&#xA;<pre><code>http://localhost:7075/myservice/v1/images/header.png&#xA;</code></pre>&#xA;&#xA;<p>is it fine to load images from resource folder? Will spring boot jars get exploded at runtime. What is the correct way to load images from spring boot jar file.</p>&#xA;"
44096281,JWT/KONG: Cannot create JWTs with a shared secret,2017-05-21 11:23:30,<jwt><microservices><kong>,1,203,0,0.0,0,"<p>I'm playing around KONG API gateway recently.</p>&#xA;&#xA;<p>I want to sign each JWT with a secret that is shared in all micros. I need this because I want other micros to be able to decode given JWT and extract payload data and work upon it (e.g. _user_id_ field in the payload). </p>&#xA;&#xA;<p>When I try to create a JWT for the first consumer, it works just fine. But when I try to create it for the second consumer I'm getting the following error: </p>&#xA;&#xA;<p><code>{u'secret': u""already exists with value 'secret'}</code></p>&#xA;&#xA;<p>I'm not exactly sure but I think KONG/JWT requires unique secret for each consumer to create a JWT. Is it possible to configure JWT plugin properly to be able to use shared secret to sign JWTs? </p>&#xA;&#xA;<p>PS: I'm not entirely sure that using a shared secret is a good practice. If there is a better way to do this please let me know. Thanks!</p>&#xA;&#xA;<ul>&#xA;<li>Kong version <code>v0.10.2</code></li>&#xA;</ul>&#xA;"
44083919,Microservice Configuration in play 2 framework,2017-05-20 09:00:17,<playframework-2.0><microservices>,1,221,0,1.0,0,"<p>I have divided my application into different projects in PLay 2. But I just realised I do not know how to run multiple play application in the same server.</p>&#xA;&#xA;<p>Anyone knows how to do it?</p>&#xA;&#xA;<p>Let us suppose it is not possible,Therefore, I will just deploy multiple play application in the same root  project (The microservice will act as a plugin). Do you think this will defeat microservice architecture?. I will make each module act independently. </p>&#xA;"
44129347,Microservices for job/cron tasks,2017-05-23 08:14:47,<cron><scalability><microservices>,2,989,0,0.0,0,"<p>For example I want to have a microservice to send notifications(email, sms, push notification). Everything is ok for few users. After some time our application have a lot of users, so, this microservice doe not manage, and email a sent after 1 hour. </p>&#xA;&#xA;<p>So, how to handle this situation? Deploy another instance of microservice, but how to handle that only one microservice process one email and user don't receive multiple emails?</p>&#xA;"
44177783,Reactive stream Kafka Stream Fan-out to http actors,2017-05-25 10:07:51,<microservices><akka-http><akka-stream><apache-kafka-streams><reactive-streams>,1,243,0,0.0,0,"<p>I'm very new to Akka Streaming and reactive streaming. I have a question: is it possible to have a rest API receiving a message dropping it on Kafka Bus, and the Kafka streaming consumer then aggregates the messages in a max. time window and retrun the answer back?</p>&#xA;&#xA;<p>How to implement such a system? Or where to start?</p>&#xA;&#xA;<p>Thanks </p>&#xA;"
44167052,Is there a way to maintain a connection to a restful web service?,2017-05-24 19:33:05,<java><performance><web><connection><microservices>,1,44,1,0.0,0,<p>I'm working on an application which is a monolith.  We have some features in our roadmap that I think would fit into a microservices architecture and am toying around with building them as such.  </p>&#xA;&#xA;<p>My problem: the application processes ~150 requests per second during peak times. These requests come in on raw TCP/IP connections which are kept alive at all times.  We have very strict latency requirements (the majority of our requests are responded to within 25-50 milliseconds).  Each request would need to consume 1 to many microservices.  My concern is that consuming multiple restful web services (specifically creating/destroying the connection each time the service is consumed as well as TLS handshakes) is going to cause too much latency for processing these requests.  </p>&#xA;&#xA;<p>My question:  Is it possible (and is there a best practice) to maintaining the state of a connection to a restful web service while multiple threads consume that web service?  each request to consume the web service would be self contained but we would simply keep the physical connection alive.</p>&#xA;
44157540,Integrated AngularJS + Rails or separated Angular + Rails API-only (microservices architecture)?,2017-05-24 11:48:02,<ruby-on-rails><angularjs><architecture><microservices><saas>,1,46,1,1.0,0,"<p>As I understand it, there are two common approaches to running AngularJS (or ReactJS, VueJS etc. same idea...).</p>&#xA;&#xA;<ol>&#xA;<li><p>Integrate the AngularJS front-end into a Rails application (as in <a href=""https://thinkster.io/tutorials/angular-rails"" rel=""nofollow noreferrer"">this tutorial</a>)</p></li>&#xA;<li><p>Run an AngularJS application which communicates with a completely separate Rails API-only back-end a.k.a: microservices architecture (as in <a href=""https://www.angularonrails.com/getting-started-with-angular-and-rails/"" rel=""nofollow noreferrer"">this tutorial</a>)</p></li>&#xA;</ol>&#xA;&#xA;<p>Which approach would be most appropriate from a Software as a Service stand-point?</p>&#xA;"
44082917,Dropwizard Server shuts down automatically after some time,2017-05-20 06:59:34,<java><rest><jetty><microservices><dropwizard>,1,169,1,0.0,0,"<p>I wrote one java rest microservice using Dropwizard framework.&#xA;The service starts fine but if no activity is happening on the microservice, it shuts down automatically with following logs</p>&#xA;&#xA;<pre><code>INFO   [15:17:54.165] [dw-240 - GET /uid/requests/be7e2b1c-a694-4a11-b586-&#xA;c5082f61c2ef] c.t.u.b.UIDQueryService -  Transformed response for requestId &#xA;[be7e2b1c-a694-4a11-b586-c5082f61c2ef]&#xA;INFO   [15:55:43.040] [Thread-14] o.e.j.s.ServerConnector -  Stopped &#xA;application@f5a7226{HTTP/1.1}{0.0.0.0:8080}&#xA;INFO   [15:55:43.042] [Thread-14] o.e.j.s.ServerConnector -  Stopped &#xA;admin@519c6fcc{HTTP/1.1}{0.0.0.0:8081}&#xA;INFO   [15:55:43.043] [Thread-14] o.e.j.s.h.ContextHandler -  Stopped &#xA;i.d.j.MutableServletContextHandler@ee2ae9a{/,null,UNAVAILABLE}&#xA;</code></pre>&#xA;&#xA;<p>From the logs we can see that the server automatically shutdown after some inactivity on microservice. Diff in time between last GET and Server shutdown is about 40 minutes.</p>&#xA;&#xA;<p>I think its some configuration which kills the service after certain inactivity, Does any one has idea about this.</p>&#xA;"
44056521,Will it be a good approach to have two separate controllers for the same micro-service?,2017-05-18 19:41:40,<spring-boot><microservices>,1,178,1,0.0,0,"<p>I have a Spring-boot based microservice which is currently being hit from a Mobile-APP. Now we are developing a browser base client for the same microservice. Request &amp; Response parameters between mobile-App and browser are same. Number of users in mobile-APP is around 10000 per second and for browser  is around 20000 per second. Hence, there would be more than 30000 hits to this microservice each second.</p>&#xA;&#xA;<p>We know that ""Spring controllers are singletons (there is just one instance of each controller per web application) "".</p>&#xA;&#xA;<p>Will it be a good approach (with respect of performance) to have two separate Controllers for this same microservice, one for mobile-App users and other for browser users ?  Will it improve microservice performance by having two instances running in parallel ?</p>&#xA;&#xA;<p>I am looking the best way to handle increasing number of hits through both the channels ?</p>&#xA;&#xA;<p>Any suggestions would be highly appreciated.</p>&#xA;"
44177107,Measuring Microservices - Fault Tolerant,2017-05-25 09:34:57,<microservices>,1,149,2,0.0,0,"<p>One of the Microservices Architecture benefit is Fault Tolerant. Which means any issues in one service should not impact other services. As result, it should improve the particular service availability. However, some implementation such as HA, auto scaling also help in availability. Instead of measuring the general of service availability, how we able to have more specific quantitative measurement that Microservice is benefits in fault tolerant?</p>&#xA;"
44021110,Resource-based vs. Entity-based structure,2017-05-17 09:40:09,<data-structures><microservices>,1,66,3,0.0,0,"<p>When it comes to designing the architecture of a system and the underlying services (consider a SOA), the database models can be designed it some ways, right... The general one is <code>entity-based</code>, which speaks for itself - the business logic is built around the entities (f.e. <code>user</code>, <code>company</code>, <code>product</code>). But when <code>resource-based</code> comes in the picture, it gets confusing. And the problem continues when I get results with very abstract or ambiguous information in google.</p>&#xA;&#xA;<p>My focus here is on a CRM service (Customer Relations Management). But I deem it better for me to understand resource-based structure in general, in order to be able to design a service in such a way.</p>&#xA;&#xA;<p>Can someone provide a concise explanation of resource-based structure and maybe compare it with entity-based?</p>&#xA;"
44148076,Mail notification from denormalized view in CQRS,2017-05-24 02:44:16,<email><microservices><cqrs>,1,69,3,0.0,0,"<p>I want to develop a mail notification service to send order approval to customer. The order data is in the denormalized view (query side) and it should be filled to the mail template. Then, we send the email in html string format via mail notification service. But, the order status should be changed to ""order approval email sent"". </p>&#xA;&#xA;<p>I also try to implement the CQRS, ES, and DDD concept in microservices architecture.&#xA;Is this procedure correct and still align with the concept?</p>&#xA;&#xA;<ol>&#xA;<li>Develop HTTP POST API in order command to send approval mail so the order status could be changed in command-side.</li>&#xA;<li>The command side generate the event ""order approval mail processed""</li>&#xA;<li>The event processor process the event. It should get the order data from query-side / denormalized view. </li>&#xA;<li>The event processor generates the approval mail from the data and fill the data to the template. </li>&#xA;<li>The event processor call HTTP POST to the mail notification service with mail body (html format) in the payload.</li>&#xA;<li>The event processor call HTTP PUT to the order service (command-side) to change the order status to ""order approval mail sent"".</li>&#xA;</ol>&#xA;&#xA;<p>But, if this procedure is applied, the user can't get the response ""mail sent"" in real-time. How to trigger the client / front-end side that the mail is successfully sent? So, the client side don't have a need to refresh or retry many calls to the API.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44084744,Microservice architecture Flaws,2017-05-20 10:25:34,<architecture><microservices><restful-architecture>,1,189,3,1.0,0,"<p>We are facing performance related issues with microservice architecture.</p>&#xA;&#xA;<p>Let's say there is microservice for user and account management. which have api's like </p>&#xA;&#xA;<pre><code>GET /users/{id} &#xA;GET /users       (arrount 6 million users)&#xA;&#xA;GET /accounts/{accountId}&#xA;GET /accounts &#xA;and Other Operations on user and account&#xA;</code></pre>&#xA;&#xA;<p>We have other microservice which track's user activities and list all the activities done by the user in his last login.</p>&#xA;&#xA;<pre><code>GET /user/activity/{userId}  (on an average 1000 to 10000 records)&#xA;</code></pre>&#xA;&#xA;<p>We have protal for sales and marketing team to show individual user activities and  user info and account info based on search criteria,</p>&#xA;&#xA;<pre><code>let's say search criteria is like : get all user activies who are located in colombia&#xA;Algorithm : &#xA;&#xA;1)Get /users ? location = colombia&#xA;2)then for individual user Get /user/activity/{userId}&#xA;</code></pre>&#xA;&#xA;<p>it is like joining two tables from different databases.</p>&#xA;&#xA;<p>it is very slow and creating lot of performance issues.</p>&#xA;&#xA;<p>what i though of is replicating user table in other microservice by a job which makes sure it is up to date and using only one api like</p>&#xA;&#xA;<pre><code>GET /user/activities?location=colombia.&#xA;</code></pre>&#xA;&#xA;<p>but replicating a table(user) is breaking the micro-service architecture main fundamentals</p>&#xA;&#xA;<p>is there any other way to do it or support this type of filter criteria which join's tables from different micro-services.</p>&#xA;"
44198061,Decision path for Azure Service Fabric Programming Models,2017-05-26 09:25:59,<azure><microservices><azure-service-fabric>,1,225,4,1.0,0,"<p><strong>Background</strong></p>&#xA;&#xA;<p>We are looking at porting a 'monolithic' 3 tier Web app to a microservices architecture. The web app displays listings to a consumer (think Craiglist).</p>&#xA;&#xA;<p>The backend consists of a REST API that calls into a SQL DB and returns JSON for a SPA app to build a UI (there's also a mobile app). Data is written to the SQL DB via background services (ftp + worker roles). There's also some pages that allow writes by the user.</p>&#xA;&#xA;<p><strong>Information required:</strong></p>&#xA;&#xA;<p>I'm trying to figure out how (if at all), Azure Service Fabric would be a good fit for a microservices architecture in my scenario. I know the pros/cons of microservices vs monolith, but i'm trying to figure out the <em>application</em> of various microservice programming models to our current architecture.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is Azure Service Fabric a good fit for this? If not, other recommendations? Currently i'm leaning towards a bunch of OWIN-based .NET web sites, split up by area/service, each hosted on their own machine and tied together by an API gateway.</li>&#xA;<li>Which Service Fabric programming model would i go for? Stateless services with their own backing DB? I can't see how Stateful or Actor model would help here.</li>&#xA;<li>If i went with Stateful services/Actor, how would i go about updating data as part of a maintenance/ad-hoc admin request? Traditionally we would simply login to the DB and update the data, and the API would return the new data - but if it's persisted in-memory/across nodes in a cluster, how would we update it? Would i have to expose this all via methods on the service? Similarly, how would I import my existing SQL data into a stateful service? </li>&#xA;<li>For Stateful services/actor model, how can I 'see' the data visually, with an object Explorer/UI. Our data is our Gold, and I'm concerned of the lack of control/visibility of it in the reliable services models</li>&#xA;</ul>&#xA;&#xA;<p>Basically, is there some documentation on the <em>decision path</em> towards which programming model to go for? I could model a ""listing"" as an Actor, and have millions of those - sure, but i could also have a Stateful service that stores the listing locally, and i could also have a Stateless service that fetches it from the DB. How does one decide as to which is the best approach, for a given use case?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44050579,EntityFramework Core Loadbalanced,2017-05-18 14:27:33,<c#><entity-framework><asp.net-core><microservices>,1,78,9,0.0,0,"<p>I know this is a pretty general question, but please bear with me:</p>&#xA;&#xA;<p>I just tripped over the entityframework cache aka ChangeTracker.</p>&#xA;&#xA;<p>What we have is a small microservice using net core with entity core.  This microservice is loadbalanced (RoundRobin) behind an IIS (so far nothing to incommon I would guess).  Lets call them Instance1 and Instance2.</p>&#xA;&#xA;<p>Now what happens:</p>&#xA;&#xA;<p>I have one entry in the db, for example (Represented as JSON here for simplicity):</p>&#xA;&#xA;<p><code>&#xA;{ Name: ""Test"", FirstName: ""T."" }&#xA;</code></p>&#xA;&#xA;<p>Now I load this into a form (answer from Instance1) and modify the FirstName to Thomas and save it via a PUT, which is done by Instance2.  Now I do another request to get that entry.  This request is answered by Instance1, which will load this from cache (since the changetracker says it is unchanged).  And thus I get</p>&#xA;&#xA;<p><code>&#xA;{Name: ""Test"", FirstName: ""T.""}&#xA;</code></p>&#xA;&#xA;<p>There seems to be many people having problems with the change tracker and one common answer is to rebuild the dbcontext with every request, which to me seems utterly wrong, because this is a very ""expensive"" operation.</p>&#xA;&#xA;<p>Also I noticed that the inserting of new data gets slower and slower over time, because the change tracker is filling up, so I would have to recycle the microservice every once and a while.</p>&#xA;&#xA;<p>So my question is:&#xA;How can I get around this Problem without reinitialising the dbcontext with every request?&#xA;I also found some answers that allow to disable the caching, but only for a single db operation, which means I would have to add this option to every DB operation, which to me feels almost as wrong as reinitialising the db context with every request.&#xA;What did I overlook, there has to be a simple solution!</p>&#xA;"
38576865,Render remote view in local layout,2016-07-25 20:27:52,<ruby-on-rails><microservices>,2,55,0,1.0,0,"<p>My organization is considering re-implementing an existing Rails monolith as a collection of Rails services. For the content layer, our thought was that our API gateway would contain the layout information for the whole app, and would request individual views via HTTP. Individual services would then render their templates and send them back via HTTP as rendered HTML.</p>&#xA;&#xA;<p>My question is this: is there a mechanism in Rails to request remote content via HTTP, to render the received HTML into an ERB/HAML layout template, and then to serve the fully rendered HTML?</p>&#xA;"
38614201,"With Microservices, different services has similar entities to be stored in database, how to deal with it?",2016-07-27 13:20:51,<architecture><microservices>,2,107,0,0.0,0,"<p>I'm trying to understand what microservices are. </p>&#xA;&#xA;<p>As I understand right now, it's just separated self-contained services that can be invoked by each other or by the client. </p>&#xA;&#xA;<p>Let's say I have ProductService and UserService. If our system allows people to comment on product as well as user, should we store the comments of both systems in a comments table, or should each of them have separate comments table? </p>&#xA;&#xA;<p>Should each service use its own database or store them in one place?</p>&#xA;"
38647186,In a microservices based architecture how would i go about database access?,2016-07-28 21:40:04,<database><hibernate><microservices>,1,714,0,0.0,0,<p>I am trying to push myself into developing a set of microservices for a personal project that will essentially:</p>&#xA;&#xA;<p>Use elastic search&#xA;Poll various data stores&#xA;place data and read data from a data store&#xA;Expose a rest api to users</p>&#xA;&#xA;<p>for the purposes of this example lets say I had a bookings MS and a Sales MS</p>&#xA;&#xA;<p>The first thing that occurred to me was how to handle data storage.</p>&#xA;&#xA;<ol>&#xA;<li>Should each MS have its own data store?</li>&#xA;<li>Should I introduce a Persistence MS which handles all data from all other micro services (seems odd to do this).</li>&#xA;<li>Should each MS share a database but handle its own transactions.</li>&#xA;</ol>&#xA;&#xA;<p>In the case where you have each service handling its own persistence will that not significantly bloat a micro service to the point where you have a lot of boilerplate code and a large overall footprint of libraries (as an example hibernate would be a required library across every project and it seems terrible to have every MS having to load the same set of libraries).</p>&#xA;&#xA;<p>So I suppose the overriding question is what is the accepted methodology for managing database connectivity across a micro service architecture.</p>&#xA;
38615132,How to monitor (micro)services?,2016-07-27 14:00:08,<triggers><alert><soa><monitor><microservices>,2,153,1,0.0,0,"<p>I have a set of services. Every service contains some components.</p>&#xA;&#xA;<p>Some of them are stateless, some of them are stateful, some are synchronous, some are asynchronous.</p>&#xA;&#xA;<p>I used different approaches to monitoring and alerting.</p>&#xA;&#xA;<p>Log-based alerting and metrics gathering. New Relic based. Own bicycle.</p>&#xA;&#xA;<p>Basically, atm I am looking for a way, how to generalize and aggregate important metrics for all services in single place. One of things, I want is that we monitor more products, than separate services.</p>&#xA;&#xA;<p>As an end result I see it as a single dashboard with small amount of widgets, but looking at those widgets I would be able to say for sure, if services are usable to end-customer.</p>&#xA;&#xA;<p>Probably someone can recommend me some approach/methodology. Or give a reference to some best practices.</p>&#xA;"
38492639,Auditing Microservices,2016-07-20 23:52:50,<java><web-services><microservices>,1,892,2,0.0,0,<p>I have list of microservices I am calling multiple services from same controller.&#xA;I want to track the change of the object state before and after service.</p>&#xA;&#xA;<p>How the design should be or there any standards to audit microservices?</p>&#xA;&#xA;<p>Thanks Vijay</p>&#xA;
42216713,how to make a non-hardcoded URL path in docker image to call backend service?,2017-02-14 02:11:50,<url><docker><microservices><docker-swarm><docker-image>,2,275,0,0.0,0,"<p>I'm new in docker. Let me describe my scenario:&#xA;I made 2 docker images for a web application. one image is front-end web layer for presentation and the other is back-end layer supplying REST service.</p>&#xA;&#xA;<p>So I need to run 2 containers for this 2 images. the front-end calls services in back-end. Now I need to write the back-end's URL in front-end's code and build the image...I don't think this is the right way for micro service...</p>&#xA;&#xA;<p>because if my laptop's IP changes or others want to use my image,they cannot get the service...So how can I make the URL variable and make my front-end image can be used for others without rebuild?</p>&#xA;&#xA;<p>Thx!</p>&#xA;"
42375333,How to architect authenticate/authorise in microservice using JWT?,2017-02-21 18:37:48,<web-services><architecture><microservices><scalable>,2,25,0,0.0,0,<p>How to make a stateless architecture design so that if a user(A) is loggedIn and the Json web token is generated by Server(<strong>X1</strong>) and returned to user-A. And again user-A sends the request to server and the purpose is served by Server(<strong>X2</strong>) without making the user re-authenticate.&#xA;So that the architecture is highly scalable horizontally.</p>&#xA;
42250009,Activiti Timer Events in Ephemeral Environments,2017-02-15 12:54:45,<tomcat><containers><microservices><activiti><bpmn>,1,33,0,0.0,0,"<p>We are currently looking at Activiti for handling approval events in our organization, but we are looking to build the REST API within a containerized environment*. The containerized tomcat instances will be sharing a persistence layer, but due to the ephemeral nature of the instances, we can't have any state maintained by Activiti. </p>&#xA;&#xA;<p>We don't envision this to be a problem but for the timed boundary events, and it ties to a wider question about how Activiti Timers <em>work</em>. Is the execution of the timer a function of a date/time expression kept in the (permanent) persistence layer (thus it's evaluated when the engine interacts with that expression)? Or is it a process that keeps a running clock and then fires when it expires? The latter of the two is not preferable, but if that is the case, how does one recommend we keep track of boundary timers when the Activiti layer is impermanent?</p>&#xA;&#xA;<p>*(using ephemeral Tomcat layers that can be blown away at any time)</p>&#xA;"
42380585,Best way to load configurations to microservice docker container,2017-02-22 00:33:00,<design><microservices>,1,35,0,0.0,0,"<p>I have build a springboot application and containerized it. I have two ways to inject configurations to the service.</p>&#xA;&#xA;<ol>&#xA;<li>As part of the code(hard coded) in application.properties file with&#xA;multple profiles and my Dockerfile only accepts one variable for &#xA;-Dspring.profiles.active=${environment} as part of CMD to start the app container</li>&#xA;</ol>&#xA;&#xA;<h2>exp - applciation.properties:</h2>&#xA;&#xA;<p>spring:&#xA;  profiles: dev</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>spring:&#xA;  profiles: prod</p>&#xA;&#xA;<hr>&#xA;&#xA;<ol start=""2"">&#xA;<li>Load properties file to the host machine running app and inject to&#xA;container while start.</li>&#xA;</ol>&#xA;&#xA;<p>exp: docker run -d --env-file=environment(dev).properties myapp:latest</p>&#xA;&#xA;<p>I would like to know what is the best way industry does to inject properties in an microservice app with advantages and disadvantages.</p>&#xA;&#xA;<ul>&#xA;<li><p>Do you keep configurations close to app?</p></li>&#xA;<li><p>OR You prefer to  inject it as a dependency while app starts?</p></li>&#xA;</ul>&#xA;&#xA;<p>My understanding: I prefer configurations closer to container as I can have minimal dependency however a small change will warrant a new build and deploy</p>&#xA;&#xA;<p>The second option has advantage as the app code(image) do not require a change and you can inject the updated configuration with a container restart.</p>&#xA;"
42356195,Google Cloud modules vs namepaces vs services,2017-02-20 23:46:35,<google-app-engine><google-cloud-platform><microservices>,1,48,0,0.0,0,"<p>Im confused about these three different constructs in google cloud and trying to understand how these fit together.</p>&#xA;&#xA;<p>First, from what I have read ""modules"" are just the old name for ""services"" right? So anything I read about google cloud ""modules"" would also apply to services?</p>&#xA;&#xA;<p>Are you using namespaces AND services/modules together or are they generally mutually exclusive? </p>&#xA;&#xA;<p>Is this a good example of how to use these things together:</p>&#xA;&#xA;<ul>&#xA;<li>Put my shared resources (storage, DBs, etc) in a ""namespace"" and that way multiple modules/services can access them. ""Any App Engine request can access any namespace"" so namespaces resources are bound by their project container.</li>&#xA;<li>Create ""services"" that access the namespaced resources</li>&#xA;<li>All of this is in a single ""project"" which is used as an environment (so I'd have a ""dev"" and a ""prod"" project</li>&#xA;</ul>&#xA;"
42327562,Lagom Server: java.lang.IllegalArgumentException,2017-02-19 13:07:46,<scala><exception><microservices><lagom>,1,68,0,0.0,0,"<p>I am creating a module in lagom project. My module have only kafka consumer for consuming messages and store message events in cassandra. Thanks why, in my <code>LagomApplicationLoader</code> I am not defining any service and initialize <code>lagomServer</code> empty with <code>LagomServer.forServices()</code>. But whenever, I am start my application, I am getting following exception: </p>&#xA;&#xA;<pre><code>java.lang.IllegalArgumentException&#xA;    at com.lightbend.lagom.scaladsl.server.LagomServer$$anon$2.&lt;init&gt;(LagomServer.scala:35)&#xA;    at com.lightbend.lagom.scaladsl.server.LagomServer$.forServices(LagomServer.scala:31)&#xA;    at com.knoldus.consumer.impl.TwitterConsumerApplication.lagomServer$lzycompute(TwitterConsumerLoader.scala:33)&#xA;    at com.knoldus.consumer.impl.TwitterConsumerApplication.lagomServer(TwitterConsumerLoader.scala:33)&#xA;    at com.lightbend.lagom.scaladsl.server.LagomApplication.&lt;init&gt;(LagomApplicationLoader.scala:187)&#xA;    at com.knoldus.consumer.impl.TwitterConsumerApplication.&lt;init&gt;(TwitterConsumerLoader.scala:28)&#xA;    at com.knoldus.consumer.impl.TwitterConsumerLoader$$anon$1.&lt;init&gt;(TwitterConsumerLoader.scala:25)&#xA;    at com.knoldus.consumer.impl.TwitterConsumerLoader.loadDevMode(TwitterConsumerLoader.scala:25)&#xA;    at com.lightbend.lagom.scaladsl.server.LagomApplicationLoader.load(LagomApplicationLoader.scala:54)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1$$anonfun$2$$anonfun$3.apply(LagomReloadableDevServerStart.scala:151)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1$$anonfun$2$$anonfun$3.apply(LagomReloadableDevServerStart.scala:148)&#xA;    at play.utils.Threads$.withContextClassLoader(Threads.scala:21)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1$$anonfun$2.apply(LagomReloadableDevServerStart.scala:148)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1$$anonfun$2.apply(LagomReloadableDevServerStart.scala:124)&#xA;    at scala.Option.map(Option.scala:146)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1.apply(LagomReloadableDevServerStart.scala:124)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1$$anonfun$apply$1.apply(LagomReloadableDevServerStart.scala:122)&#xA;    at scala.util.Success.flatMap(Try.scala:231)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1.apply(LagomReloadableDevServerStart.scala:122)&#xA;    at play.core.server.LagomReloadableDevServerStart$$anonfun$mainDev$1$$anon$2$$anonfun$get$1.apply(LagomReloadableDevServerStart.scala:114)&#xA;    at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)&#xA;    at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)&#xA;    at java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)&#xA;    at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)&#xA;    at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)&#xA;    at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)&#xA;    at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)&#xA;</code></pre>&#xA;&#xA;<p>My Code: </p>&#xA;&#xA;<pre><code>class TwitterConsumerLoader extends LagomApplicationLoader {&#xA;&#xA;  override def load(context: LagomApplicationContext): LagomApplication =&#xA;    new TwitterConsumerApplication(context) {&#xA;      override def serviceLocator = NoServiceLocator&#xA;    }&#xA;&#xA;  override def loadDevMode(context: LagomApplicationContext): LagomApplication =&#xA;    new TwitterConsumerApplication(context) with LagomDevModeComponents&#xA;}&#xA;&#xA;abstract class TwitterConsumerApplication(context: LagomApplicationContext) extends LagomApplication(context)&#xA;  with CassandraPersistenceComponents with AhcWSComponents with LagomKafkaComponents {&#xA;&#xA;  lazy val twitterService = serviceClient.implement[TwitterProducerService]&#xA;&#xA;  override lazy val lagomServer = LagomServer.forServices()&#xA;  override lazy val jsonSerializerRegistry = TwitterSerializerRegistry&#xA;&#xA;  persistentEntityRegistry.register(wire[TweetEntity])&#xA;  wire[TwitterProducerSubscriber]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How can I declare empty services in lagom. If this is not possible, what are the other alternatives? Because may be in future, it may required, for creating some service in this module. How can i resolve this issue?</p>&#xA;"
42372431,Multiple clusters listening to the same JMS messaging queue,2017-02-21 16:11:43,<java-ee><queue><jms><messaging><microservices>,1,120,1,0.0,0,"<p>I've been searching for a JMS solution and I (surprisingly) haven't been able to find an easy answer.Â  I may be searching for the wrong thing, so hopefully the community on stackoverflow can help.</p>&#xA;&#xA;<p>What I'm working should be pretty basic: Using JMS for event notification across clusters of microservices. The setup is simple.  Suppose I have 3 clusters, each with 3 instances all separate from each other running on their own EE server instances on different machines.</p>&#xA;&#xA;<pre><code>Cluster A&#xA; A1, A2, A3&#xA;&#xA;Cluster B&#xA;Â  B1, B2, B3&#xA;&#xA;Cluster C&#xA;Â  B1, B2, B3&#xA;</code></pre>&#xA;&#xA;<p>And I have a central JMS server which has a queue they all listen to:</p>&#xA;&#xA;<pre><code>A1, A2, A3 |&#xA;B1, B2, B3 |&lt;-------&gt; JMS Queue (Q1)&#xA;C1, C2, C3 |&#xA;</code></pre>&#xA;&#xA;<p>Microservice instance A2 processes a request and publishes Message (M) onto (Q1).Â  What I want to happen is that for each of the other clusters - B,C - one instance in that cluster picks up the message and processes it for the cluster.Â  It obviously doesn't matter which instance picks it up as long as it is only processed one time per cluster.Â  So it would look like&#xA;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  </p>&#xA;&#xA;<pre><code>A2 | ---&gt; publish (M) ----&gt; JMS Queue (Q1)&#xA;&#xA;&#xA;B2 |&#xA;   | &lt;---- (M) &lt;----- JMS Queue (Q1)&#xA;C1 |&#xA;</code></pre>&#xA;&#xA;<p>This seems like a very common, almost default setup that everyone would need.Â  But so far what I've found with the way queues work is that once (M) get published to (Q1) then only one of B1,B2,B3,C1,C2,C3 will pick it up and process it and not one from each cluster like I'm looking for.  If I use a Topic, then every instance in every cluster would get a message so it doesn't seem like this is what I'm looking for either.</p>&#xA;&#xA;<p>So that's it. Thoughts?  Thanks in advance!</p>&#xA;"
42354108,how to do Integration testing in microservices architecture,2017-02-20 21:00:15,<c#><azure><asp.net-web-api><integration-testing><microservices>,1,484,1,0.0,0,"<p>I was looking for patterns/best practice for doing integration testing in microservices.  Below is quick description of my context.</p>&#xA;&#xA;<ol>&#xA;<li>microservice A  depends on<br>&#xA;a. azureAD for authentication<br>&#xA;b. Microservice B for authorization</li>&#xA;<li>microservice B talks to azure sql Db to CRUD for user/roles/permissions + exposes endpoints to check permission which is used by 1.  this service is also protected by azure AD authentication</li>&#xA;</ol>&#xA;&#xA;<p>What is the best approach to create integration test for such a case. ? Any references or guidance welcome. Some questions :</p>&#xA;&#xA;<p>a. what to mock , what not to mock<br>&#xA;b. setup teardown strategy<br>&#xA;c. others  </p>&#xA;"
42237967,Authenticate service for both applications and API microservices,2017-02-14 23:13:50,<node.js><reactjs><authentication><react-native><microservices>,2,81,2,0.0,0,"<p>I have a <code>node</code> server with express for a SaaS application. The <code>node</code>/<code>express</code> application serves the company landing page, registering or users, authentication, user and password changes. This is all build with <code>node</code>/expr<code>e</code>ss. Authentication is done using <code>passport</code>.</p>&#xA;&#xA;<p>When the user logs in, he is redirected to a dashboard application (the SaaS app itself) built with <code>React</code>, <code>react-route</code> and <code>Redux</code>. <code>Redux</code> needs to call the <code>node</code>/<code>express</code> API, that is currently in the same <code>node</code>/<code>express</code> service.</p>&#xA;&#xA;<p>The APIs are also going to be used by a mobile app to be developed using <code>React Native</code>.</p>&#xA;&#xA;<p>We want to split the services into different node modules, one for the SaaS application and another to handle the company page, registering, etc. A movement towards microservices architecture.</p>&#xA;&#xA;<p>Our doubt is how to handle user authentication. We need a single authentication mechanism that will allow the user to use the <code>React</code> SaaS app and also that will serve the mobile app. </p>&#xA;&#xA;<p>If the user is logged in from the web, he can use the SaaS app with the API. If he is logged from the mobile, he can use the API from the mobile.</p>&#xA;&#xA;<p>This is our first approach to splitting the server and would like to find out the recommended method to solve the authentication problem. Naturally if we could split the authentication service as another microservice that would be very interesting.</p>&#xA;&#xA;<p>Thanks in advance for helping.</p>&#xA;"
42332938,What is the difference between Service Fabric Applications and Services,2017-02-19 21:12:26,<azure><microservices><azure-service-fabric>,3,387,2,0.0,0,<p>What is the reasoning behind Applications concept in Service Fabric? What is the recommended relation between Applications and Services? In which scenarios do Applications prove useful?</p>&#xA;
43151368,Should I modify zipkin service libraries to pass generic feature flags?,2017-04-01 00:14:58,<microservices><tracing><zipkin>,1,77,0,0.0,0,"<p>We're looking to implement Zipkin in our stack.  As I look into Zipkin it makes sense to me to extend the Zipkin system to handle generic flags as well. </p>&#xA;&#xA;<p>Observations:</p>&#xA;&#xA;<ol>&#xA;<li>Any implementation of Zipkin needs to capture ""B3"" tagged values (headers in HTTP) and propagate them to requests further down the stack.</li>&#xA;<li>Some values are mutated</li>&#xA;<li>Some values are just propagated (Sampled, Debug)</li>&#xA;</ol>&#xA;&#xA;<p>Conclusion:</p>&#xA;&#xA;<ul>&#xA;<li>Extending Zipkin with the option to propagate (X-)B3-Flag- Key/Value pairs make sense. </li>&#xA;<li>This enables A/B testing and Blue/Green Deploy.  </li>&#xA;<li>These techniques often need to compare timings to ensure that timings are similar or improved unless noted by the service development team.</li>&#xA;</ul>&#xA;"
43125393,How does messaging queue work in service broker architecture?,2017-03-30 18:11:31,<asynchronous><message-queue><microservices><service-broker><asynchronous-method-call>,1,120,0,0.0,0,<p>With vague knowledge of service broker I cannot find out where to look understand how messaging queue works in coordinating and setting order that too asynchronously ?</p>&#xA;&#xA;<p>The question may be having a wide scope if I am not wrong but a general explanation for understanding when messaging queue comes into play in service broker would be great! Thanks</p>&#xA;
43232660,Separate microservice for database access,2017-04-05 13:28:40,<microservices><software-design><n-tier-architecture>,1,139,0,0.0,0,"<p>I'm managing a very large enterprise application in that I've implemented microservice architecture. Standalone microservices have been created based on business entities &amp; operations. &#xA;For example, </p>&#xA;&#xA;<ol>&#xA;<li>User Operations Service</li>&#xA;<li>Product Operations Service</li>&#xA;<li>Finance Operations Service</li>&#xA;</ol>&#xA;&#xA;<p>Please note that each service implemented using an n-tier architecture with WCF. i.e have separate tiers(which is independently deployable to separate server) for business and data access.</p>&#xA;&#xA;<p>There is a centralized database which is accessed by all the microservices. There are a couple of common entities like 'user' accessed by all the services, so we have redundant database calls in multiple services. More efforts required due to database access from many places(i.e a column rename requires deployment of all the apps)</p>&#xA;&#xA;<p>To reduce &amp; optimize code, I'm planning to create separate microservice and move all the database operations into it. i.e services can call ""Database Operations Service"" for any database operations like add/update/select.</p>&#xA;&#xA;<p>I want to know if there are any hidden challenges that I'm not aware of. Whether should I go with this thought? What can I consider as improvements in this concept?</p>&#xA;"
43142821,"Kubernetes: single POD with many container, or many Pod with single container",2017-03-31 14:11:28,<kubernetes><microservices>,5,420,0,0.0,0,"<p>I've rather a teoretical question which I can't answer  with the reousrces found online. The question is: <strong>what's the rule to decide how to compose containers in POD?</strong> . Let me explain with an example.</p>&#xA;&#xA;<p>I've these microservices:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Authorization </li>&#xA;<li>Serving content</li>&#xA;<li>(plus) OpenResty to forward the calls form one to the other and orhcestarate the flow. (is there a possibility to do so natively in K8?, it seems to have services base on nginx+lua, but not sure how it works)</li>&#xA;</ul>&#xA;&#xA;<p><em>For the sake of the example I avoid Databases and co, I assume they are external and not managed by kubernetes</em></p>&#xA;&#xA;<p>Now, what's the correct way here <em>LEFT</em> or <em>RIGHT</em> of the image?&#xA;<a href=""https://i.stack.imgur.com/b0VwE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b0VwE.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>LEFT</em> : this seems easier to make it working, everything works on ""localhost"" , the downside is that it looses a bit the benefit of the microservices. For example, if the auth become slows and it would need more instances, I've to duplicate the whole pod and not just that service.</p>&#xA;&#xA;<p><em>RIGHT</em> seems a bit more complex, need services to expose each POD to the other PODs. Yet, here, I could duplicate auth as I need without duplicating the other containers. On the other hand I'll have a lot of pods since each pod is basically a container.</p>&#xA;"
43295417,Spring Boot Registration Server(Eureka Server),2017-04-08 14:40:26,<java><spring><spring-boot><spring-cloud><microservices>,1,450,0,0.0,0,"<p>I am working on a Spring Boot Registration Server(Eureka Server).&#xA;Currently it is working with below configuration.</p>&#xA;&#xA;<p><strong>Project Name:</strong> registration-service<br>&#xA;<strong>Inside main method:</strong> System.setProperty(""spring.config.name"", ""registration-service"");</p>&#xA;&#xA;<p><strong>""yml file"":</strong><br>&#xA;   <strong>file name:</strong> registration-service&#xA;   <strong>content:</strong>  </p>&#xA;&#xA;<pre><code>     eureka:&#xA;      instance:&#xA;        hostname: eureka-server&#xA;      server:&#xA;        enableSelfPreservation: false&#xA;      client:&#xA;        register-with-eureka: false&#xA;        fetch-registry: false&#xA;        serviceUrl:&#xA;         defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/&#xA;&#xA;&#xA;    server:&#xA;      port: 2323   # HTTP (Tomcat) port&#xA;&#xA;&#xA;&#xA;&#xA;spring:&#xA; application:&#xA;  name: eureka-server&#xA;</code></pre>&#xA;&#xA;<p>With above configuration,application start running on 2323.&#xA;But if i change <strong>spring.config.name</strong>,it does not work,start giving connection refused exception.</p>&#xA;&#xA;<ol>&#xA;<li><p>why it is happening? even though this spring.config.name is no where used in yml file. Should it be necessarily same as project name? or it is specific to @EnableEurekaServer enabled spring boot application.</p></li>&#xA;<li><p>And in yml we have to write</p></li>&#xA;</ol>&#xA;&#xA;<p>spring:&#xA; application:&#xA;  name: eureka-server</p>&#xA;&#xA;<p>though in other spring boot application we give name of current project(here it should be registration-service).why we have to write here eureka-server? I know,I am missing something(or a lot of things).please help me in understanding the missing part.  </p>&#xA;"
43104831,How does the microservice API gateway pattern work with auto Horizontal scaling?,2017-03-29 21:52:49,<nginx><docker><kubernetes><microservices><kong>,2,264,1,0.0,0,"<p>If I would like to have a high available solution. So, I would have two API gateways in different data center. </p>&#xA;&#xA;<p>Each API gateway is connected to three microservices like billing, users, and account services. Each one has three replica.</p>&#xA;&#xA;<p>So is that true to have 6 copies for one microservice, and if not. How does it work?</p>&#xA;"
43228611,Micro-services with load balancing and commits,2017-04-05 10:31:13,<transactions><commit><microservices><serverless-architecture>,1,38,1,0.0,0,"<p>I am keen on understanding the following aspects of micro-services.</p>&#xA;&#xA;<ul>&#xA;<li><p><strong>Commit and roll-back</strong>. If a business goal is to be achieved by invoking multiple micro-services, who co-ordinates commit and roll-back? Are micro-services required to embed the commit-roll-back protocol in their implementation? Or, is it provided by some external factor?</p></li>&#xA;<li><p><strong>Load-balancing for micro-services</strong>. Is a micro-service front-ended by a load balancer to help it scale? And, therefore, scaling is out of scope of implementation of the service?</p></li>&#xA;<li><p><strong>Co-relation with AWS Lambda/Bluemix OpenWhisk/Azure Functions</strong>. How do micro-services compare with â€˜serverlessâ€™ architecture? </p></li>&#xA;</ul>&#xA;"
43088918,Java MicroService Projectstuckture with Spring and Neflix Stack,2017-03-29 08:59:41,<java><spring><microservices><netflix-eureka><spring-cloud-netflix>,1,83,1,0.0,0,"<p>Currently, I'm trying to create a small example project with a micro service architecture in Java to learn the basic concepts.&#xA;I am using the following tutorials: <a href=""https://spring.io/blog/2015/07/14/microservices-with-spring"" rel=""nofollow noreferrer"">tutorial1</a>, <a href=""https://exampledriven.wordpress.com/2016/07/01/spring-cloud-eureka-ribbon-feign-example/"" rel=""nofollow noreferrer"">tutorial2</a>.&#xA;In there it is mentioned that you have to configure an application.yml or application.properties file. But I don't know where I should put these files. And I couldn't find a clean project structure example for microservices with Java.</p>&#xA;&#xA;<p>So my questions are: &#xA;Is there a common project structure for micro services in Java with the mentioned frameworks?</p>&#xA;&#xA;<p>Where should I put the application.yml and could someone give me a full example of the file? (can be very basic. I only need a pattern)</p>&#xA;&#xA;<p>Could you pm me some good/better tutorials? (this would be opinion based. So that's why I'm asking for a pm)</p>&#xA;&#xA;<p>Thanks for possible answers.</p>&#xA;"
43187101,Data communication in a scalable microservice architecture,2017-04-03 14:19:01,<performance><amazon-web-services><architecture><scalability><microservices>,2,98,1,0.0,0,"<p>We are working on a project to gain some knowledge about microservices and automatically scalable architectures. In this project we are building a small game where a user can fly a plane and shoot down other players online, hosted on the Amazon Web Services. The duration of a game should be about 10 minutes, a million games should (theoretically) be able to be played at the same time and about a thousand players should be able to play in a single game. So the application must really be scalable.</p>&#xA;&#xA;<p>We are now hitting a hard part in the architecture. We want the server to calculate the positions of the players. Meaning that server gets key input requests with which it recalculates positions. Problem is that, because the application is scalable and there isn't just one server doing all the calculations and holding all the data, the input events will probably end up in different locations. We expect that constantly writing all positions to a database and reading it back to the client is too slow nor scalable enough. Also we don't want dedicated servers for single games as that could just waist the computation power (and money)</p>&#xA;&#xA;<p>We have searches for different implementations by other game architectures, like messaging, but to no avail, we could not find any method that seamed fitting. We would like to know if there is any kind of pattern that could make this kind of implementation work? All we really need is a sense of direction for some possible patterns.</p>&#xA;"
43177818,Microservices or SOA ready architecture,2017-04-03 06:26:39,<architecture><soa><microservices>,1,116,1,0.0,0,"<p>Is this(below) a good web architecture?</p>&#xA;&#xA;<ol>&#xA;<li>We have 2 services front-end service and back-end service. </li>&#xA;<li>Back-end service only provide APIs not traditional MVC.</li>&#xA;<li>The back-end service will structured as modules each module act as a small application with its own config, so each module may have a different database engine and dependencies. </li>&#xA;<li>All communications with models are done via repositories. </li>&#xA;<li>Trying to avoid any type of SQL joins and keep it simple by performing multi queries to get the result.</li>&#xA;<li>Using an API gateway that's will be the entry point for all requests.</li>&#xA;</ol>&#xA;&#xA;<p>So by this we can move to SOA or Microservices easily in future. </p>&#xA;&#xA;<p>What do you think about the above approach?</p>&#xA;&#xA;<p>Thank you in advance. </p>&#xA;"
43144337,The right way to define an API's base path in Api Connect,2017-03-31 15:22:29,<spring-boot><ibm-cloud><microservices><apiconnect>,1,269,5,0.0,0,"<p><strong>Problem:</strong></p>&#xA;&#xA;<p>I have two micro services (in Spring Boot) published in <a href=""https://en.wikipedia.org/wiki/Bluemix"" rel=""nofollow noreferrer"">Bluemix</a>'s Api Connect. I want to assign a base path to each one so that we have a way to separate them. I.E.:</p>&#xA;&#xA;<p>Path to API 1: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api1/[endpoint-of-api1]</code>&#xA;Path to API 2: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api2/[endpoint-of-api2]</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>My solution:</strong></p>&#xA;&#xA;<p>Assign a context path to each Api in their <strong>application.yml</strong> file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: /api1&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Even though this works, it doesn't seem right to have a base path for the entire server, when the microservice shouldn't be aware of its external context (the reason for a base path is exclusively to have a separation in Api Connect)</p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
46956866,OpenIddict - Authorization and authentication with Microservices,2017-10-26 14:22:22,<authentication><microservices><openiddict>,1,261,0,0.0,0,"<p>I have a mobile (native) and web app (SPA) that talks to backend microservices (developed in core 2.0) for authentication/authorization and other domain related functions, which has configured using Opendidict. Both apps are getting access token. What I'm struggling with is, all microservices should accept bearer access token and authentication/authorization logged in user (a central auth-service), access token generated in auth microservice (OpenIddict 2.*). So what changes I'm missing in microservices, where REST APIs are marked [Authorize]?</p>&#xA;&#xA;<p>Code from Auth Microservice:</p>&#xA;&#xA;<pre><code>public void ConfigureServices(IServiceCollection services)&#xA;{&#xA;    var connection = Configuration.GetConnectionString(""DefaultConnection"");&#xA;&#xA;    services.AddDbContext&lt;IdentityDbContext&gt;(options =&gt;&#xA;    {&#xA;        options.UseSqlServer(Configuration.GetConnectionString(""DefaultConnection""));&#xA;        options.UseOpenIddict();&#xA;    });&#xA;&#xA;    services.AddAuthentication().AddOAuthValidation();&#xA;&#xA;    services.AddOpenIddict(options =&gt;&#xA;    {&#xA;        options.AddEntityFrameworkCoreStores&lt;IdentityDbContext&gt;();&#xA;        options.AddMvcBinders();&#xA;        options.EnableTokenEndpoint(""/connect/token"");&#xA;        // Enable the password flow.&#xA;        options.AllowPasswordFlow().AllowRefreshTokenFlow();&#xA;        options.SetRefreshTokenLifetime(TimeSpan.FromHours(1));&#xA;        options.DisableHttpsRequirement();&#xA;    });&#xA;&#xA;    services.AddDbContext&lt;AuthDbContext&gt;(options =&gt; options.UseSqlServer(connection));&#xA;    services.AddScoped&lt;IUserRepository, UserRepository&gt;();&#xA;&#xA;    services.AddAuthentication(options =&gt;&#xA;    {&#xA;        options.DefaultScheme = OAuthValidationDefaults.AuthenticationScheme;&#xA;    });&#xA;&#xA;    services.AddAuthorization(options =&gt;&#xA;    {&#xA;        options.AddPolicy(""RequireAdministratorRole"", policy =&gt; policy.RequireRole(""Administrator""));&#xA;    });&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Existing code in Notification Microservice</p>&#xA;&#xA;<pre><code>public void ConfigureServices(IServiceCollection services)&#xA;{&#xA;    services.AddDbContext&lt;MastersDbContext&gt;(options =&gt; options.UseSqlServer(Configuration.GetConnectionString(""DefaultConnection"")));&#xA;&#xA;    services.AddAuthentication().AddOAuthValidation();&#xA;&#xA;    services.AddAuthentication(options =&gt;&#xA;    {&#xA;        options.DefaultScheme = OAuthValidationDefaults.AuthenticationScheme;&#xA;    });&#xA;&#xA;    services.AddAuthorization(options =&gt;&#xA;    {&#xA;        options.AddPolicy(""RequireAdministratorRole"", policy =&gt; policy.RequireRole(""Administrator""));&#xA;    });&#xA;}&#xA;&#xA;public void Configure(IApplicationBuilder app, IHostingEnvironment env)&#xA;{&#xA;    app.UseCors(builder =&gt;&#xA;        builder.WithOrigins(""*"")&#xA;            .AllowAnyHeader()&#xA;            .AllowAnyMethod()&#xA;            .AllowAnyOrigin()&#xA;    );&#xA;&#xA;    //app.UseAntiforgeryToken();&#xA;    app.UseMvc();&#xA;    app.UseAuthentication();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Notification Controller:</p>&#xA;&#xA;<pre><code>// POST api/values&#xA;[HttpPost]&#xA;[Authorize]&#xA;public IActionResult Post(Notification notification)&#xA;{&#xA;    //logic&#xA;    return Ok();&#xA;}&#xA;</code></pre>&#xA;"
47013636,Using Pact Framework for MSA using SDKs,2017-10-30 11:01:50,<microservices><pact><pact-broker>,1,32,0,0.0,0,<p>I am trying to introduce Pact in our company. However the consumer calls APIs using providers SDKs and the host-port is dynamically determined using Kubernetes. I am new to all this backend technology so trying to understand how do we deal with this since it will be impossible to get host/port into pom.xml if its dynamic?</p>&#xA;
47069673,How to call external service (Non MSA) from Api gateway (Zuul) in spring boot application,2017-11-02 07:20:18,<spring-boot><microservices><netflix-eureka><netflix-zuul><api-gateway>,1,291,0,0.0,0,"<p>In my Spring boot micro service application,I am using Zuul proxy as edge service in my API Gateway. I need to call external service which is not registered in eureka server(Non Micro Service Architecture). How Can I call that external service from my api gateway. (Thanks in advance)</p>&#xA;"
46997840,Handle 100 request per minute with micro service,2017-10-29 07:30:51,<javascript><node.js><heroku><microservices><pivotal-cloud-foundry>,1,47,0,1.0,0,"<p>Iâ€™ve node.js application which is should handle the following </p>&#xA;&#xA;<blockquote>&#xA;  <ol>&#xA;  <li>Get zip files extract those files (js module  files with some key and value - maximum 20 files but typically its 5-8 files for each&#xA;  request) </li>&#xA;  <li>Do some analyzing on those files and create new files from it and send it back to the client (if the request was with 5 files the&#xA;  analyzing should return the same 5 new files etcâ€¦)</li>&#xA;  <li>zip this new files and send it back to the client</li>&#xA;  </ol>&#xA;</blockquote>&#xA;&#xA;<p>Iâ€™ve created the module that do the analyzing which works ok, for about 10 files it takes about 250-300 ms to do the analysis and create the new files.</p>&#xA;&#xA;<p>Lets assume I need to serve 100 clients that can do this </p>&#xA;&#xA;<p>Now I want to create some <code>stateless</code> micro service that warp this functionality and do basically </p>&#xA;&#xA;<pre><code>get zip&#xA;extract zip&#xA;manipulate &#xA;zip&#xA;send files&#xA;</code></pre>&#xA;&#xA;<p>For that I want to create a <code>micro service</code> (stateless) in the cloud ( I want to deploy it to the cloud ( cloud foundry / Heroku  ) &#xA;that should handle it &#xA;And my question here is how should I handle multiple request? , let say iâ€™ve 100 request per minute â€¦&#xA;I understand that is should work <strong>async</strong> but still iâ€™m afraid that for 10 or more request my app will crushed â€¦</p>&#xA;&#xA;<p>queue? scaling? </p>&#xA;"
46949073,Should I be moving to a microservices based architecture?,2017-10-26 08:15:55,<node.js><web-services><domain-driven-design><microservices>,2,85,0,0.0,0,"<p>I am working on a monolith system. All of it's code is in one repository (Web API and background workers). System is written in Nodejs and MongoDB (Mongoose) is used as a data store.  My goal is to set a new path how project should evolve. At first I was wondering if I could move towards microservices based architecture.</p>&#xA;&#xA;<p>Monolith architecture creates some problems:</p>&#xA;&#xA;<ul>&#xA;<li>If my background workers needs to scale. I have to deploy all the project to the server despite only using a small fraction of it.</li>&#xA;<li>All system must be redeployed when code changes. What if payment processor calls webhook while system is being redeployed?</li>&#xA;</ul>&#xA;&#xA;<p>Using microsevices advantages are quite obvious:</p>&#xA;&#xA;<ul>&#xA;<li>Smaller code base for individual microservice. Easier to reason about it.</li>&#xA;<li>Ability to select programming tools best for particular use case.</li>&#xA;<li>Easier to scale.</li>&#xA;</ul>&#xA;&#xA;<p>Looking at the current code I noticed that Mongoose ODM (Object Document Mapper) models are used across all the project to create, query and update models in database. As a principle of a good programming all such interactions with database should be abstracted. Business logic should not leak into other system layers. I could do that by introducing REPOSITORY pattern (Domain Driven Design). While code is still being shared across web api and it's background workers it is not a hard task to do.</p>&#xA;&#xA;<p>If i decide to extract repositories into standalone microservices than all bunch of problems arise:</p>&#xA;&#xA;<ul>&#xA;<li>Some sort of query language must be introduced to accommodate complex search queries.</li>&#xA;<li>Interface must provide a way to iterate over search results (cursor based navigation) without returning all database documents over network.</li>&#xA;</ul>&#xA;&#xA;<p>Since project is in it's early stage and I am the only developer, going to microservices based architecture seems like an overkill. Maybe there are other approaches I should consider?</p>&#xA;&#xA;<p>Extracting business logic and interaction with database into separate repository and sharing among services to avoid complex communication protocols between services?</p>&#xA;"
47020906,Microservice per data model,2017-10-30 17:20:37,<architecture><microservices>,1,88,0,1.0,0,<p>I have an architectural question about microservices. We have 2 different data sources (2 tables with some simmilar fields but no connection between them). We want only to read data from these. Is it good practice to create a microservice (along it's model object) per each of these sources or it's enough to create a generic model with a generic service which will serve the data?</p>&#xA;
46934916,Microserivce Using Spring Boot to Consume SOAP,2017-10-25 14:20:55,<java><rest><spring-boot><soap><microservices>,3,632,0,0.0,0,"<p>I need to create a REST service that first consumes SOAP. What would the best way to go about this?</p>&#xA;&#xA;<p>I would like to use Spring Boot to create a microservice, but I have a few questions for those with experience:</p>&#xA;&#xA;<ul>&#xA;<li>What other architectures or technologies should I look into using&#xA;(with spring boot)?  </li>&#xA;<li>Is there a standard technology stack for this?</li>&#xA;<li>Are there pitfalls I should be aware of?</li>&#xA;</ul>&#xA;"
47020319,Microservice Communication in EDA using Event Sourcing,2017-10-30 16:45:25,<domain-driven-design><microservices><cqrs><event-sourcing>,2,137,0,1.0,0,"<p>I've been reading about microservices and event sourcing and how it decouples services from one another. There are 2 concepts I am not clear on. First, if in a microservices architecture, each service can be developed independently how do we account for inter-service communication dependencies ? </p>&#xA;&#xA;<p>For example, if Service A and Service B need to communicate, A needs to send an event to a central bus which B needs to listen for and act upon, but this seems to create a lot of dependencies. Now, if I am developing Service B, i need to know all of the events that Service A can generate. Also, if service A adds any new event, Service B also needs to change in order to handle that new event. All of this seems to create a dependency nightmare, and seems like you cannot truly develop each service 'independently'.</p>&#xA;&#xA;<p>Secondly, how is a request/response type scenario handled at the API gateway or process manager level ? If the top level request fires off a bunch of cascading or interdependent events which need to be handled before returning a response to the caller, is this a scenario suited well for microservices ?</p>&#xA;"
47058984,"Microservices - Spring AMQP/RabbitMQ, async calls between microservices best pattern",2017-11-01 16:03:52,<rabbitmq><microservices><spring-amqp>,1,170,0,1.0,0,"<p>I have three microservices - Service A, B and C. &#xA;Service A should call B and C asynchronously, A should build the response based B and C responses.</p>&#xA;&#xA;<p>I am using Rabbit MQ for async ipc. </p>&#xA;&#xA;<p>Tried RabbitTemplate's convertSendAndRecieve with direct-replyTo option to consume, which  makes the current processing thread wait/block on the  async call to complete which makes it synchronous. </p>&#xA;&#xA;<p>I wouldn't like to use the convertAndSend and let Service A listen on the reply queue and process based on correlation id as there would be thousands of responses in the reply queue and mapping the messages based on correlation id results in poor performance.</p>&#xA;&#xA;<p>Creating separate queues for each session is not an option either due to its own caveats (getting acknowledgement from all clusters on new queue creation impacts the performance too)</p>&#xA;&#xA;<p>Sorry if this problem has been solved before, I couldnt get much help on this on internet. Any help would be appreciated. </p>&#xA;"
47042162,Where in S3 my Lambda code stored,2017-10-31 18:21:25,<amazon-web-services><amazon-s3><aws-lambda><microservices>,2,703,0,0.0,0,<p>I have read the Lambda FAQ and it says it stores my code in S3 and it is encrypted.</p>&#xA;&#xA;<p>Where in S3 is it stored and can I decrypt it to edit my code?</p>&#xA;
47049241,Would socket.io be too much for a simple service monitor?,2017-11-01 06:16:55,<node.js><websocket><socket.io><ejs><microservices>,1,31,1,0.0,0,"<p>I am making a small service that will ping all the other services hosted on my server, this service will ping every other deployed service ever few seconds thus bringing data continuously. </p>&#xA;&#xA;<p>I would be using EJS to render this data in a simple tabular format the data would be URL to the service, response time, status of the service. </p>&#xA;&#xA;<p>So as the data may or may not change after every ping would it be too much to use socket.io and are there any other options available for such scenario which are much more feasible and simpler?</p>&#xA;"
47023636,Continuously running service in Google Cloud Engine,2017-10-30 20:27:28,<google-app-engine><cron><microservices>,1,36,1,0.0,0,"<p>I am trying to figure out how to run a service(1) when it does not receive any calls.</p>&#xA;&#xA;<p>I want to use Microservices Architecture.</p>&#xA;&#xA;<p>Basically i want to run this service (1) when the other service(2) is  receiving calls and all data.</p>&#xA;&#xA;<p>As the service(1) i mentioned is not receiving it would not have to spawn new instances and i would want only the service(2) to scale.</p>&#xA;&#xA;<p>I have noticed <a href=""https://cloud.google.com/appengine/docs/flexible/go/scheduling-jobs-with-cron-yaml"" rel=""nofollow noreferrer"">scheduling jobs with cron yaml</a> but the number of calls is limited. &#xA;I need to get this service(1) to be active every 1 min when service(2) is active. </p>&#xA;"
46947124,how to design a job scheduler for many kinds of job?,2017-10-26 06:20:26,<design><architecture><cluster-computing><instance><microservices>,1,116,1,0.0,0,"<p>I am junior developer and wanted to ask a question on design/architecture of a job scheduler.</p>&#xA;&#xA;<p>I am designing the architecture for a scheduler that manages multiples tasks.&#xA;There are multiple categories(over 70) eg movie, shopping, food.&#xA;Each category has three or more tasks that need to be implemented.&#xA;So my scheduler needs to execute tasks for each category when needed.&#xA;Tasks for each category are independent of one another. &#xA;So, tasks for categoryA can run in parallel with those of categoryB depending on the schedule. </p>&#xA;&#xA;<p>So, I have two types of design that I have in mind to do this. &#xA;One is turning each category as a separate service, to run on individual instance. This way, it's modular but the system will consume too many instances(over 70) even when there is no task running for each category.</p>&#xA;&#xA;<p>category1</p>&#xA;&#xA;<ul>&#xA;<li>task1 </li>&#xA;<li>task2</li>&#xA;<li>task3</li>&#xA;</ul>&#xA;&#xA;<p>...</p>&#xA;&#xA;<p>category2</p>&#xA;&#xA;<ul>&#xA;<li>task1</li>&#xA;<li>task2 </li>&#xA;<li>task3</li>&#xA;</ul>&#xA;&#xA;<p>...</p>&#xA;&#xA;<p>category3</p>&#xA;&#xA;<ul>&#xA;<li>task1</li>&#xA;<li>task2 </li>&#xA;<li>task3</li>&#xA;</ul>&#xA;&#xA;<p>... </p>&#xA;&#xA;<p>The other idea I have is to group categories by each task. So, each task becomes a module itself and inside each task, there is a collection of specific tasks that belong to different categories. </p>&#xA;&#xA;<p>task1</p>&#xA;&#xA;<ul>&#xA;<li>task1 related to category1 </li>&#xA;<li>task1 related to category2</li>&#xA;<li>task1 related to category3</li>&#xA;</ul>&#xA;&#xA;<p>... </p>&#xA;&#xA;<p>task2</p>&#xA;&#xA;<ul>&#xA;<li>task2 related to category1 </li>&#xA;<li>task2 related to category2</li>&#xA;<li>task2 related to category3</li>&#xA;</ul>&#xA;&#xA;<p>... </p>&#xA;&#xA;<p>task3</p>&#xA;&#xA;<ul>&#xA;<li>task3 related to category1</li>&#xA;<li>task3 related to category2    </li>&#xA;<li>task3 related to category3</li>&#xA;</ul>&#xA;&#xA;<p>Which one is do you think is a better design? I'd love your insight into this. Thank you :) </p>&#xA;"
46924175,Node JS application with Php Library,2017-10-25 04:47:15,<php><node.js><apache><payment-gateway><microservices>,1,61,2,0.0,0,"<p>I have a web application which is written in Node JS, and now I came up to implement a payment gateway which doesn't support NodeJS. Although it supports PHP, Asp etc. I wanted to know if there is a way I can work this out. Is it possible to host Node and PHP application in the same server? Can we write microservice using RabbitMQ which will be a communication bridge between both NodeJS and PHP? Please suggest.</p>&#xA;"
47017875,Scheduler in a java spring boot microservice,2017-10-30 14:34:41,<java><spring-boot><scheduler><microservices>,1,601,3,0.0,0,"<p>We have a microservice written using Spring boot which has its own NoSQL datastore. We are working on functionality whereby we want to delete some old data (in magnitude of 0.5 million documents) and want to do it on a regular basis(once a day) based on presence of records of particular type in data store. </p>&#xA;&#xA;<p>Is having a scheduler which runs once everyday and does the deletion, a correct approach for it ? Also since its a microservice and several instances of it will be running, how do we control that this scheduler runs on only 1 instance ?</p>&#xA;"
47061556,Microservice Setup,2017-11-01 18:39:46,<node.js><docker-compose><microservices>,3,55,4,0.0,0,"<p>I have a several git repo that I want to manage via docker-compose. I also want the project where the docker-compose resides to be a git repo. So I have the following organization:</p>&#xA;&#xA;<p><code>&#xA;UI-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Server-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Local-Development-Repo&#xA;  --&gt; .git&#xA;  --&gt; docker-compose.yml&#xA;</code></p>&#xA;&#xA;<p>Unfortunately, I cannot seem to access the UI-Repo and Server-Repo dockerfiles due to limitations in Docker. Having a sym link for the UI-Repo and Server-Repo inside the Local-Development-Repo does not work either. So I can think of two options.</p>&#xA;&#xA;<ol>&#xA;<li><p>Git Submodules</p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I will need to copy package.json and perform a <code>npm install</code> inside my dockerfiles since <code>node_modules</code> is on my .gitignore. I want this purely for development and ideally, should just use volumes instead of installing dependencies inside the docker container. </li>&#xA;</ul></li>&#xA;<li><p>House UI-Repo and Server-Repo inside a parent directory, which contains the docker-compose.yml file. </p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I want this parent to be tracked via Git as well. I do not think having .git in the parent directory that houses two more git repo will work. </li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>What is the suggested practice to set up microservices architecture having several independent git repos and manage these projects for local development using docker-compose?</p>&#xA;"
46947956,"MQ - How to guarantee message delivery in a non-transacted, lightweight environment?",2017-10-26 07:14:35,<transactions><zeromq><microservices><mq><2phase-commit>,2,96,11,0.0,0,"<p>How to guarantee message delivery in a non-transacted, lightweight environment?</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<ul>&#xA;<li>Normal situation: Write to database, commit, <strong>send message to ZeroMQ|Redis|OtherMQ</strong>, consumer pulls the message to continue processing...</li>&#xA;<li>0,05% situation: Write to database, commit, <strong>application dies!</strong>, no message sent, no consumer pull the message, incomplete processing.</li>&#xA;</ul>&#xA;&#xA;<p>How to not loose the message (avoid not send the message) in this situation?</p>&#xA;&#xA;<p><strong>Edit</strong>: The message must be delivery exactly once.</p>&#xA;"
43763479,Consul-Agent architecture .. the node-id issue after upgrading to 0.8.1 - conceptual issue?,2017-05-03 14:52:29,<docker><microservices><consul>,1,100,0,0.0,0,"<p>i am not sure where the root of my problem actually comes from, so i try to explain the bigger picture.</p>&#xA;&#xA;<p>In short, the symptom: After upgrading consul from 0.7.3 to 0.8.1 my agents ( explaining that below ) could no longer connect to the cluster leader due to dublicated node-ids ( why that probably happens, explained below).&#xA;I could neither fix it with <a href=""https://www.consul.io/docs/agent/options.html#_disable_host_node_id"" rel=""nofollow noreferrer"">https://www.consul.io/docs/agent/options.html#_disable_host_node_id</a> nor fully understand, why i run into this .. and thats where the bigger picture and maybe even different questions comes from.</p>&#xA;&#xA;<p>I have the following setup:</p>&#xA;&#xA;<ol>&#xA;<li><p>I run a application stack with about 8 containers for different services ( different micoservices, DB-types and so on).</p></li>&#xA;<li><p>I use a single consul server per stack (yes the consul server runs in the software stack, it has its reasons because i need this to be offline-deployable and every stack lives for itself)</p></li>&#xA;<li><p>The consul-server does handle the registration, service discovery and also KV/configuration</p></li>&#xA;<li><p><strong>Important/Questionable:</strong> Every container has a consul agent started with with ""consul agent -config-dir /etc/consul.d"" .. connecting the this one server. The configuration looks like this  .. including to other files with they encrypt token / acl token. Do not wonder about servicename() .. it replaced by a m4 macro during image build time</p></li>&#xA;<li><p>The clients are secured by a gossip key and ACL keys </p></li>&#xA;<li><p><strong>Important:</strong> All containers are on the same hardware node</p></li>&#xA;<li><p>Server configuration looks like this, if any important. In addition, ACLs looks like this, and a ACL-master and client token/gossip json files are in that configurtion folder</p></li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p>Sorry for this probably TLTR above, but the reasons behind all the explanation was, this multi-agent setup ( or 1-agent per container ).</p>&#xA;&#xA;<p>My reasons for that:</p>&#xA;&#xA;<ol>&#xA;<li><p>I use tiller to configure the containers, so a dimploy gem will try to usually connect to localhost:8500 .. to acomplish that without making the consul-configuration extraordinary complicated, i use this local agent, which then forwards the request to the actual server and thus handles all the encryption-key/ACL negation stuff</p></li>&#xA;<li><p>i use several 'consul watch' tasks on the server to trigger re-configuration, they also run on localhost:8500 without any extra configuration</p></li>&#xA;</ol>&#xA;&#xA;<p>That said, the reason i run a 1-agent/container is, the simplicity for local services to talk to the consul-backend without really knowing about authentication as long as they connect through 127.0.0.1:8500 ( as the level of security )</p>&#xA;&#xA;<p><strong>Final Question:</strong></p>&#xA;&#xA;<p>Is that multi-consul agent actually designed to be used that way? The reason i ask is, because as far as i understand, the node-id duplication issue i get now when starting a 0.8.1 comes from ""the host"" being the same, so the hardware node being identical for all consul-agents .. right?</p>&#xA;&#xA;<p>Is my design wrong or do i need to generate my own node-ids from now on and its all just fine?</p>&#xA;"
43979597,ELK logging in microservices architecture,2017-05-15 12:28:44,<elasticsearch><indexing><microservices><elastic-stack>,1,225,3,0.0,0,"<p>I am implementing centralized logging for all of my microservices using ELK. My doubt is whether I will have to create separate index for each microservice or a single index for all the microservices logs. My research so far shows that single common index for all the microservices make sense for centralized logging to achieve searches across microservices. Also I learnt that too many indices are a bit of overhead in elasticsearch. So I would like to hear from someone experienced</p>&#xA;&#xA;<p>I have already this question in Software recommendations  <a href=""https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture"">https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture</a></p>&#xA;"
43892712,Merge Microservice Frontends Together,2017-05-10 12:35:58,<microservices>,1,186,6,0.0,0,"<p>I want to merge serveral frontend parts of different microservices together to an whole website. My idea behind this was to have a <strong>frontend</strong>, <strong>backend</strong> and <strong>database</strong> part in each microservice.</p>&#xA;&#xA;<p>I already familiar with microservices but I never used them to create a website, especially the frontend part.&#xA;Are there any articles about that or something like tutorials or maybe someone at stackoverflow can explain me more in depth how or with which ""tool"" I could put the microservices together.</p>&#xA;"
43821553,What is the best way to run npm packages on demand as mircoservices without installing it locally?,2017-05-06 14:20:55,<node.js><npm><microservices>,1,86,8,0.0,0,"<p>Let's say I have these npm packages published to npm:&#xA;<code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;each package has a single function:</p>&#xA;&#xA;<pre><code>function run(extraStr) {&#xA;  return 'package_name_and_version' + extraStr; // i.e. service1 v1.0 extraStr&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I want to write nodejs code that use the packages without installing it locally</p>&#xA;&#xA;<pre><code>var server = require(""my-server-sdk"");&#xA;  // get(package_name, version, function_in_package, arguments, callback)&#xA;  server.get('service1', '2.0', 'run', ['app1'], (err, result) =&gt; {&#xA;  console.log(result); // this should print service1 v2.0 app1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>where <code>my-server-sdk</code> is an sdk that interface with my server's api where it <strong>install the required packages and cache it for later use</strong>.&#xA;What is the best way to do that? what the security concerns and how to prevent any?</p>&#xA;&#xA;<p>this is a simple diagram for what I want&#xA;<a href=""https://i.stack.imgur.com/aTdeG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aTdeG.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>NOTE: <code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;are just examples to any packages in npm i.e. <code>lodash</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Caching example:</strong></p>&#xA;&#xA;<p>Let's say we have TTL equal <strong>60 minutes</strong>.</p>&#xA;&#xA;<p><strong>client1</strong> requested a function from <code>lodash</code> and another function from <code>underscore</code> at 01:00.&#xA;Now in the server <code>lodash</code> and <code>underscore</code> are installed with timestamp <strong>01:00</strong>.</p>&#xA;&#xA;<p><strong>client2</strong> requested a function from <code>underscore</code> at <strong>01:30</strong> which get used instantly because <code>underscore</code> is installed before but it timestamp got updated to <strong>1:30</strong>.</p>&#xA;&#xA;<p>At <strong>02:01</strong> <code>lodash</code> get deleted because it didn't get used on the past TTL <code>currenttime - lodash_timestamp &gt; TTL</code> but <code>underscore</code> stays because <code>currenttime - underscore_timestamp &lt; TTL</code></p>&#xA;&#xA;<p>So when <strong>client3</strong> request <code>lodash</code> at <strong>02:30</strong> it get <code>intsalled</code> again with <strong>02:30</strong> as a <code>timestamp</code>.</p>&#xA;"
46813736,Microservices are compatible with existing SQL database?,2017-10-18 15:21:30,<sql><database-design><architecture><rabbitmq><microservices>,3,260,0,0.0,0,"<p>I'm creating a microservice architecture with Core, rabbitMQ, strangler pattern ... but I have to use an existing SQL database (Transaction requeriment).</p>&#xA;&#xA;<p>Doing a research I don't found a lot of information about how implement SQL database, but I think it's impossible to do a transactional operation on different services at the same time.</p>&#xA;&#xA;<p>1- Every service must have access to entirely database?</p>&#xA;&#xA;<p>2- Is a good idea do a service exclusive to do transactionals operations?</p>&#xA;&#xA;<p>3- SQL with microservices it's maybe too much slow?</p>&#xA;&#xA;<p>I don't know if exist a standard for this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46696171,How to achieve immediate consistency in microservice architecture?,2017-10-11 19:34:36,<microservices><distributed-transactions><eventual-consistency>,1,267,0,1.0,0,<p>For example amazon.com; they rely on microservice architecture and probably order and payment are seperate micro services but when you checkout order on amazon.com you can finally see the order id and details.If it's not eventual consistency approach what is it? Maybe 2PC?</p>&#xA;&#xA;<p>I'm generalizing my question; what if eventual consistency is not &#xA;appropriate for business transaction(end user should see the result end of transaction) but seperate microservices is meaningful(like order and payment)&#xA;how to handle immediate consistency?</p>&#xA;
46783912,How should I embed a Jetty server in an Apache Ignite service?,2017-10-17 06:37:37,<scala><jetty><microservices><embedded-jetty><ignite>,2,105,0,0.0,0,"<p>I'm trying to embed a Jetty server in an Apache Ignite service (as per <a href=""http://apache-ignite-users.70518.x6.nabble.com/WebServer-on-Ignite-td314.html"" rel=""nofollow noreferrer"">this thread</a>) so I can make the HTTP endpoint the entry point to my data pipeline. Here's my basic test:</p>&#xA;&#xA;<p><strong>Main.scala</strong></p>&#xA;&#xA;<pre class=""lang-scala prettyprint-override""><code>object Main {&#xA;    def main(args: Array[String]): Unit = {&#xA;        val ignite = Ignition.start()&#xA;        val group = ignite.cluster.forLocal&#xA;        val services = ignite.services(group)&#xA;        services.deployNodeSingleton(""myTestService"", new TestServiceImpl)&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>TestService.scala</strong></p>&#xA;&#xA;<pre class=""lang-scala prettyprint-override""><code>trait TestService {&#xA;    def test()&#xA;}&#xA;&#xA;class TestServiceImpl extends Service with TestService {&#xA;    val server = new Server(8090)&#xA;&#xA;    def cancel(ctx: ServiceContext) = {&#xA;        server.stop()&#xA;        server.join()&#xA;    }&#xA;&#xA;    def init(ctx: ServiceContext) = {&#xA;        println(""TestServiceImpl#init"")&#xA;    }&#xA;&#xA;    def execute(ctx: ServiceContext) = {&#xA;        println(""TestServiceImpl#execute"")&#xA;        server.start()&#xA;    }&#xA;&#xA;    def test() = {&#xA;        println(""Tested"")&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I run it, I get the following error:</p>&#xA;&#xA;<pre><code>[01:52:57] Ignite node started OK (id=626c1302)&#xA;[01:52:57] Topology snapshot [ver=1, servers=1, clients=0, CPUs=8, heap=2.0GB]&#xA;TestServiceImpl#init&#xA;TestServiceImpl#execute&#xA;Oct 17, 2017 1:52:57 AM org.apache.ignite.logger.java.JavaLogger error&#xA;SEVERE: Service execution stopped with error [name=myTestService, execId=565f4fb4-5726-4c37-857d-0c74f3b334ce]&#xA;java.util.concurrent.RejectedExecutionException: org.eclipse.jetty.util.thread.NonBlockingThread@56a1831d&#xA;  at org.eclipse.jetty.util.thread.QueuedThreadPool.execute(QueuedThreadPool.java:362)&#xA;  at org.eclipse.jetty.io.SelectorManager.execute(SelectorManager.java:160)&#xA;  at org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:258)&#xA;  at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)&#xA;  at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132)&#xA;  at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:106)&#xA;  at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:256)&#xA;  at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)&#xA;  at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236)&#xA;  at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)&#xA;  at org.eclipse.jetty.server.Server.doStart(Server.java:366)&#xA;  at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)&#xA;  at me.danellis.ignite.TestServiceImpl.execute(TestService.scala:23)&#xA;  at org.apache.ignite.internal.processors.service.GridServiceProcessor$2.run(GridServiceProcessor.java:1160)&#xA;  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&#xA;  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&#xA;  at java.lang.Thread.run(Thread.java:748)&#xA;</code></pre>&#xA;&#xA;<p>Does something need to be configured differently in either Ignite or Jetty for this to work?</p>&#xA;"
46850814,"pm2 Error: EMFILE, too many open files",2017-10-20 14:03:31,<node.js><microservices><pm2>,1,426,0,0.0,0,"<hr>&#xA;&#xA;<p>I am using PM2 to manage our Node.js based micro services platform. We wanted a dashboard from where we can see the micro services status e.g. if any service is taking too much CPU or memory and for that I used PM2's api and wrote the following piece of code.</p>&#xA;&#xA;<pre><code>function getMicroService(){&#xA;    pm2.connect(function(err) {&#xA;        if(!err){&#xA;            // Get all processes running&#xA;            logger.info('core_module','Connecting to PM2 Daemon for Micro Services List');&#xA;            var dataArr = {};&#xA;            var microServices = [];&#xA;            var counter = 0;&#xA;            var curDateTime = helperLib.getDateTimeISO();&#xA;            pm2.list(function(err, process_list) {&#xA;                if(process_list.length &gt; 0){&#xA;                    process_list.forEach(function(process){&#xA;                        delete process.pm2_env;&#xA;                        process.lastChecked = curDateTime;&#xA;                        microServices.push(process);&#xA;                        counter++;&#xA;                    })&#xA;                }&#xA;                if(counter == process_list.length){&#xA;                    dataArr.event = 'microServices';&#xA;                    dataArr.data = microServices;&#xA;                    publishStats(dataArr);&#xA;                }&#xA;            });&#xA;        }else{&#xA;            logger.error('core_module','on Line 245: '+err)&#xA;        }&#xA;    })  &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The above function is called every 15 seconds and it displays data on the Dashboard. But I noticed that this service started taking too much CPU over 100% and PM2 whole Daemon service went offline and stopped responding. Couldn't issue any command e.g. pm2 stop all etc. I had to manually kill the processes and then start the service again. The error I extracted from the Log file is</p>&#xA;&#xA;<pre><code>{""message"":""core_module Threw Exception: "",""stack"":""Error: EMFILE: too many open files, open '/root/.pm2/pm2.log'\n    at Object.fs.openSync (fs.js:584:18)\n    at module.exports.Client.launchDaemon (/etc/node/node_modules/pm2/lib/Client.js:207:14)\n    at /etc/node/node_modules/pm2/lib/Client.js:102:10\n    at /etc/node/node_modules/pm2/lib/Client.js:294:14\n    at _combinedTickCallback (internal/process/next_tick.js:73:7)\n    at process._tickDomainCallback (internal/process/next_tick.js:128:9)"",""errno"":-24,""code"":""EMFILE"",""syscall"":""open"",""path"":""/root/.pm2/pm2.log"",""__error_callsites"":[{},{},{},{},{},{}],""level"":""error"",""timestamp"":""2017-10-20T00:49:26.826Z""}&#xA;</code></pre>&#xA;&#xA;<p>Could anyone please help out if the above code is right. Calling it every 15 seconds is a good approach or how can I optimize it. Should I call pm2.disconnect() at the end of the function.</p>&#xA;&#xA;<p>Please advise.</p>&#xA;&#xA;<p>Regards&#xA;Habib</p>&#xA;"
46725906,Spring boot micro services rest API security,2017-10-13 08:43:38,<rest><security><spring-boot><oauth><microservices>,1,691,0,0.0,0,<p>Am newbie to spring boot micro services. I have 3 micro service that are</p>&#xA;&#xA;<pre><code>1. Login authentication&#xA;2. User service&#xA;3. Account service.&#xA;4. UI Service&#xA;</code></pre>&#xA;&#xA;<p>UI Service contains UI part this micro service will calls other API's. First 3 services should validate every rest api calls. I need to implement security for rest api calls that need to be global and shared across all micro services. What would be the best approach without using oauth. Because OAuth need server. Hence without this is there any way to achieve this. I googled and not getting clear view. how to resolve this</p>&#xA;
46829594,Session alternatives in Microservices,2017-10-19 12:13:28,<java><rest><session><microservices>,1,341,1,0.0,0,"<p>I have web client which invokes multiple services. As soon as the user is authenticated, I want to store the email Id somewhere as it sends the email Id for each request. </p>&#xA;&#xA;<p>I don't want to use session as I have heard that is the best practice. In REST, all data must be sent for the request and it must be stateless. What other alternatives are there? Is using DB for session management still not breaking the stateless principle of REST?</p>&#xA;&#xA;<p>I went through <a href=""https://stackoverflow.com/questions/3105296/if-rest-applications-are-supposed-to-be-stateless-how-do-you-manage-sessions"">If REST applications are supposed to be stateless, how do you manage sessions?</a> but there were many contradicting opinions there. Should the email Id be stored in session storage of the browser then?</p>&#xA;"
46828175,Manage property files inside common micro service in Spring Boot,2017-10-19 10:48:25,<java><spring-boot><microservices><netflix-eureka><spring-boot-configuration>,1,233,1,0.0,0,"<p>Currently I'm working in Spring boot micro services project. Consider I have 3 micro services named as A, B, C. Now My project have application.yml file separately for each micro service. Now I want to add one more microservice D, for manage all service property files. </p>&#xA;&#xA;<p>view my config-service structure</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/EXXW9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EXXW9.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>eureka.yml(inside config-service) file is:</p>&#xA;&#xA;<pre><code>server: &#xA;  port: 8761&#xA;eureka: &#xA;  client:&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;  server:&#xA;    waitTimeInMsWhenSyncEmpty: 0&#xA;endpoints:&#xA;  sensitive: false&#xA;</code></pre>&#xA;&#xA;<p>In eureka-service bootstrap.properties is: </p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: eureka&#xA;  cloud: &#xA;    config:&#xA;      uri: http://localhost:8888&#xA;</code></pre>&#xA;&#xA;<p>Config service application properties :</p>&#xA;&#xA;<pre><code>spring:&#xA;  application: &#xA;    name: config &#xA;  cloud: &#xA;    config: &#xA;      server:&#xA;        native:&#xA;          search-locations: classpath:/config/DEVELOP&#xA;  profiles:&#xA;     active: native&#xA;&#xA;server:&#xA;  port: 8888&#xA;</code></pre>&#xA;&#xA;<p>my config application file is:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableConfigServer&#xA;public class ConfigApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(ConfigApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I did the following steps:</p>&#xA;&#xA;<ol>&#xA;<li>start the config-service</li>&#xA;<li>start the eureka-service</li>&#xA;</ol>&#xA;&#xA;<p>unfortunately, eureka server getting error.</p>&#xA;&#xA;<pre><code>com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server&#xA;</code></pre>&#xA;&#xA;<p>the problem is while running eureka server, its not looking the config file which is inside the config service... </p>&#xA;&#xA;<p>help me to resolve this. or instead of micro service, how can I go with folder?</p>&#xA;"
46744067,Recommendations for microservice code / modules,2017-10-14 11:33:55,<spring-boot><intellij-idea><microservices>,2,243,2,0.0,0,<p>I am new to microservices and am learning Spring Boot&#xA;I have IntelliJ Ultimate and am wondering how best to structure my microservice code </p>&#xA;&#xA;<p>For the system that i am building that will have a few microservices should I..</p>&#xA;&#xA;<ol>&#xA;<li><p>Open 1 IntelliJ containing a module for each Spring Boot microservice </p></li>&#xA;<li><p>Open multiple instances of IntelliJ and have one Spring Boot microservice per instance of IntelliJ</p></li>&#xA;</ol>&#xA;&#xA;<p>I think it will be tricky to do 2 if I have a lot of microservices but I do not know if IntelliJ is able to have multiple Spring Boot microservices running at the same time in one instance of IntelliJ</p>&#xA;&#xA;<p>Any advice on how you work with microservice code / projects would be appreciated.</p>&#xA;
46717204,Microservices sequential data processing,2017-10-12 19:10:19,<multithreading><microservices><partitioning><seq>,1,31,3,0.0,0,"<p>Suppose I am receiving a stream of unordered sequential data in time.</p>&#xA;&#xA;<p>For example, input could be:</p>&#xA;&#xA;<pre><code>[&#xA;    {id:1, timestamp:1},&#xA;    {id:2, timestamp:1},&#xA;    {id:2, timestamp:2},&#xA;    {id:1, timestamp:2},&#xA;    {id:3, timestamp:1}&#xA;] &#xA;</code></pre>&#xA;&#xA;<p>Each entity is identified by 'id' field. There could be a large amount of entities and processing for each input could take some time. &#xA;The problem is that I need to process each of those events in order it was received for each entity. </p>&#xA;&#xA;<p>I was considering some solutions as to put messages to Kafka topic with partitions and receive parallelism?&#xA;Or create local storage of received messages and marking each processed message for each entity after successful processing (on other machine or on the same in Thread pool)?</p>&#xA;&#xA;<p>Questions:&#xA;Is it is a good solution? &#xA;How can I reach this functionality while scaling data consumers (having fixed number of services/ creating new instances)? &#xA;Maybe there is a better way to solve such kind of problem?</p>&#xA;"
46764158,"Design an application with multiple request sources: WS(SOAP\REST), MQ, batch",2017-10-16 06:29:57,<java><java-ee><design-patterns><microservices><enterprise-architecture>,1,41,3,1.0,0,"<p>I have to design an application which gets requests from multiple sources like Web service (can be SOAP or REST), online system, Message Queue or some batch job. Application needs to interface with 2 more applications for getting results. I understand that this can be done using microservices. This application needs to be built in Java. I am looking for some framework which can help me with accepting input from multiple sources as mentioned above.</p>&#xA;"
46782161,User preferences with microservice architecture,2017-10-17 03:49:05,<amazon-web-services><microservices><user-preferences>,1,178,4,0.0,0,"<p>Me and my team are implementing a product based on microservices architecture(<strong><em>every microservice has it's own data storage</em></strong>). We already have a couple of services deployed on AWS and we need to add an ability to save user preferences like:</p>&#xA;&#xA;<ol>&#xA;<li>Saved filters to query data</li>&#xA;<li>UI widget settings</li>&#xA;<li>Columns order</li>&#xA;<li>etc</li>&#xA;</ol>&#xA;&#xA;<p><strong>I think that we have the following options to implement saving user-preferences in my case:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Extend user profile(it is used to store companies and users, roles) service and add new items there</li>&#xA;<li>Create new microservice for keeping only user preferences</li>&#xA;<li>Use some of AWS services for that(I am still checking what is the best)</li>&#xA;</ol>&#xA;&#xA;<p><strong>What we use for security:</strong></p>&#xA;&#xA;<ul>&#xA;<li>AWS Cognito</li>&#xA;<li>SAML IDP</li>&#xA;<li>JWT tokens</li>&#xA;</ul>&#xA;&#xA;<p>We also have user-profile microservice(I mentioned earlier). It contains data received from other products like admin service.</p>&#xA;&#xA;<p>What do you think? What is the best option for my case?</p>&#xA;"
46786169,How to check the request body parameters type validation in akka http micro-services?,2017-10-17 08:52:38,<scala><akka><microservices><akka-http>,1,326,6,1.0,0,"<p>my Object is</p>&#xA;&#xA;<pre><code>case class  Request(id:Int,name:String,phone:String)&#xA;</code></pre>&#xA;&#xA;<p>my request in postman is</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"":   ""1205"", **here i have changed the request body parameter type Int to String**&#xA;    ""name"":     ""sekhar"",&#xA;    ""phone"":""1234567890""&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>how can I check the request parameter is valid or invalid when my request body field is the wrong data type</p>&#xA;&#xA;<p>I have used</p>&#xA;&#xA;<pre><code>implicit def myRejectionHandler = RejectionHandler.newBuilder()&#xA;    .handle {&#xA;      case MissingQueryParamRejection(param) =&gt;&#xA;        println("" Test1  "")&#xA;        val errorResponse = ErrorResponse(BadRequest.intValue, ""Missing Parameter"", s""The required $param was not found."")&#xA;        var json:JsValue=Json.toJson(errorResponse)&#xA;        complete(HttpResponse(BadRequest, entity = HttpEntity(ContentTypes.`application/json`, json.toString())))&#xA;    }&#xA;    .handle { case MissingFormFieldRejection(msg) =&gt;&#xA;      println("" Test2  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handle { case MalformedQueryParamRejection(msg,error,cause) =&gt;&#xA;      println("" Test3  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handleAll[MethodRejection] { methodRejections =&gt;&#xA;    val names = methodRejections.map(_.supported.name)&#xA;     println("" Test4  "")&#xA;    complete((MethodNotAllowed, s""Can't do that! Supported: ${names mkString "" or ""}!""))&#xA;    }&#xA;    .handleNotFound { complete((NotFound, ""Not here!"")) }&#xA;    .result()&#xA;&#xA;val routes: Route = handleRejections(myRejectionHandler) {&#xA;    //Routes &#xA;  }&#xA; Http().bindAndHandle(routes, ""localhost"", 8090)&#xA;</code></pre>&#xA;&#xA;<p>it's, again and again, takes only handleAll[MethodRejection] when being changed the query params(for the false parameter too) on that time too.</p>&#xA;"
33869866,Microservice architecture implementation of CRM HRM and Domain design problems,2015-11-23 11:22:57,<architecture><domain-driven-design><crm><erp><microservices>,2,988,8,0.0,0,"<p>We are building a enterprise platform that consists of CRM, HRM, SALE, PROPERTY etc.&#xA;We are working on the microservice architecture.</p>&#xA;&#xA;<p><strong>The real question is:</strong>&#xA;CRM and HRM will be deployed as separate independent microservices but often these two microservices need to talk to each other. A HRM user creates a company contact employee and the HRM microservice API saves the information related to HRM inside HRM module in 'hrm' database while the employee details like name, surname, address etc will be saved to CRM database calling the CRM microservice APIs i.e. the Contact API saves the above info as contact of type 'Internal' or 'Employee'.&#xA;So basically what I am trying to do here is separating the data related to each microservices. </p>&#xA;&#xA;<p><strong>Is this way of domain design correct?</strong> or should I have to process and store all the information (entered by a HRM permissioned user) inside HRM module and 'hrm' database? such that we don't care CRM. And if so, CRM only seems to manage EXTERNAL contacts only? Will this have any future problems?</p>&#xA;"
34841907,Ruby on rails microservices using HTTP explanation needed,2016-01-17 18:20:27,<ruby-on-rails><http><microservices>,1,154,2,0.0,0,"<p>So, i currently have a pretty big monolithic rails app. I want to split the app up into separate micro-service APIs, with a main app as the gateway. I've been reading a lot about how to do this and think i understand, however there isn't much info on how the communication between the main app and the micro-services. I understand that i can do this in a variety of ways but i want to use HTTP.</p>&#xA;&#xA;<p>Can someone provide an example of how this setup might look and how the communication works (in code) between the main app and the micro-service?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
34889229,Recreating Docker images instead of reusing - for microservices,2016-01-20 00:02:48,<docker><microservices>,2,102,3,0.0,0,"<p>One microservice stays in one docker container. Now, let's say that I want to upgrade the microservice - for example, some configuration is changed, and I need to re-run it.</p>&#xA;&#xA;<p>I have two options:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can try to re-use existing image, by having a script that runs on containers startup and that updates the microservice by reading new config (if there is) from some shared volume. After the update, script runs the microservice. </p></li>&#xA;<li><p>I can simply drop the existing image and container and create the new image (with new name) and new container with updated configuration/code.</p></li>&#xA;</ol>&#xA;&#xA;<p>Solution #2 seems more robust to me. There is no 'update' procedure, just single container creation.</p>&#xA;&#xA;<p>However, what bothers me is if this re-creation of the image has some bad side-effects? Like a lot of dangling images or something similar. Imagine that this may happens very often during the time user plays with the app - for example, if developer is trying out something, he wants to play with different configurations of microservice, and he will re-start it often. But once it is configured, this will not change. Also, when I say <em>configuration</em> I dont mean just config files, but also user code etc.</p>&#xA;"
48097374,Netflix Zull paths config,2018-01-04 14:29:07,<microservices><spring-cloud><netflix-eureka><netflix-zuul><spring-cloud-netflix>,1,29,0,0.0,0,"<p>I'm use eureka + zull and have the following config:</p>&#xA;&#xA;<p>Zull:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  prefix: /api&#xA;  routes:  &#xA;    user-service:&#xA;      path: /user-service/**&#xA;      serviceId: user-service&#xA;</code></pre>&#xA;&#xA;<p>User-service micro-service endpoint:</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(value = ""/api/user-service/users"")&#xA;public class HelloController {&#xA;&#xA;    @RequestMapping(value = ""/hello"")&#xA;    public String hello() {&#xA;        return ""Hello world!"";&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When i request <code>&lt;zull_url&gt;/api/user-service/users/hello</code> i've got 404</p>&#xA;&#xA;<p>but <code>&lt;zull_url&gt;/api/user-service/api/user-service/users/hello</code>&#xA;works fine.</p>&#xA;&#xA;<p>Is it possible to store <code>@RequestMapping(value = ""/api/user-service/users"")</code> path in microservice and request <code>&lt;zull_url&gt;/api/user-service/users/hello</code> by zull without duplicating? Thanks.</p>&#xA;"
48172337,Remove entry on Service Discovery if service not available,2018-01-09 16:12:11,<microservices><vert.x><service-discovery>,1,31,0,0.0,0,"<p>I have a scenario where two or more instances of the same verticle will be instantiated. I want to make sure that only one of the instances is consuming the key 'keyx' and in order to do that I check on a Service Discovery instance if a certain type of record is there and, if not, I can safely say that no one is consuming 'keyx'. </p>&#xA;&#xA;<p>Therefore, I publish a record on the Service Discovery instance and I subscribe to 'keyx'. All the other instances will now check with the Service Discovery that some instance is already registered for 'keyx'.  </p>&#xA;&#xA;<p>If the machine with the verticle instance has any serious problem, it will get the verticle killed and the record will still be on the Service Discovery (in this case, removing the record in the stop() method would not work because this method wouldn't be called) and all the other instances created will believe that an instance is still consuming 'keyx' when it is possibly not the case. </p>&#xA;&#xA;<p>Does someone know any viable solution for this problem?</p>&#xA;&#xA;<p>Thanks ;) </p>&#xA;"
48008198,GAE Microservices with dedicated Cron Jobs per microservice,2017-12-28 13:14:49,<google-app-engine><cron><microservices><app-engine-flexible>,1,78,0,0.0,0,"<blockquote>&#xA;  <p>Can different microservices in GAE, own dedicated cron jobs?  </p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Background</strong></p>&#xA;&#xA;<p>We have written multiple services on GAE microservices application.&#xA;One micronservice say Service1(default) [JAVA in GAE Standard environment] has 10 cron jobs, wheareas another microservice say, Service2 [Python in GAE Flexible environment] has 5 other cronjobs.</p>&#xA;&#xA;<p>When we deploy both the services, cron jobs get replaced with the latest service cron jobs.</p>&#xA;&#xA;<p>I know that Task Queue is shared resource in GAE Microservices and hence Cron jobs too may be shared. But is it impossible to let microservice have their dedicated cronjobs based on their service scope and get them uploaded on Server where all cronjobs can co-exist?</p>&#xA;&#xA;<p>Timely response is highly appreciated.</p>&#xA;"
48055121,How to reconnect a HazelcastClient to HazelcastServer after server restart,2018-01-02 02:59:38,<java><caching><kotlin><microservices><hazelcast>,1,223,0,0.0,0,"<p>I'm having a problem using the hazelcast in an architecture based on microservice and springboot.&#xA;I keep one of the applications with being the application that will be the server of hazelcast and the others are clients of this.&#xA;However if I have to update the application that is the hazelcast server, the clients applications of the cache overturn the connection to the server and when I up the new version of the server these client applications do not reconnect.&#xA;Is there any off setting the hazelcastclient to be doing pooling on the server to try to reconnect as soon as it comes back?&#xA;My client is like below:</p>&#xA;&#xA;<pre>&#xA;&#xA;    @bean&#xA;    open fun hazelcastInstance(): HazelcastInstance? {&#xA;    return try {&#xA;    val clientConfig = ClientConfig()&#xA;    HazelcastClient.newHazelcastClient(clientConfig)&#xA;    } catch (e: Exception) {&#xA;    log.error(""Could not connect to hazelcast server, server up without cache"")&#xA;    null&#xA;    }&#xA;&#xA;}&#xA;</pre>&#xA;&#xA;<p>and I receive ""com.hazelcast.client.HazelcastClientNotActiveException: Client is shutdown"" if my server goes down.</p>&#xA;&#xA;<p>I'm grateful if you could help me</p>&#xA;"
48167778,Kubernetes: should I use HTTPS to communicate between services,2018-01-09 11:59:14,<kubernetes><microservices><google-container-engine>,1,271,1,0.0,0,"<p>Let's say I'm using an GCE <code>ingress</code> to handle traffic from outside the cluster and terminate TLS (<code>https://example.com/api/items</code>), from here the request gets routed to one of two <code>services</code> that are only available inside the cluster. So far so good.  </p>&#xA;&#xA;<p>What if I have to call service B from service A, should I go all the way and use the cluster's external IP/domain and use HTTPS (<code>https://example.com/api/user/1</code>) to call the service or could I use the internal IP of the service and use HTTP (<code>http://serviceb/api/user/1</code>)? Do I have to encrypt the data or is it ""safe"" as long as it isn't leaving the private k8s network?</p>&#xA;&#xA;<p>What if I want to have ""internal"" endpoints that should only be accessible from within the cluster - when I'm always using the external https-url those endpoints would be reachable for everyone. Calling the service directly, I could just do a <code>http://serviceb/internal/info/abc</code>.</p>&#xA;"
48145352,Spring boot Microservice Deployment in Dockers,2018-01-08 06:35:43,<amazon-web-services><docker><microservices>,1,273,1,0.0,0,"<p>I need to develop a spring boot microservice and need to deploy in dockers. Now I developed one sample microservice. When I am learning Docker and container deployment I found many documentations for installing docker and building images and running the application as container packaging. Here I have some doubts in deployment procedure. I am adding my confusions below,</p>&#xA;&#xA;<ul>&#xA;<li><p>If I need to deploy 4 spring boot microservice in docker , Am i need to create separate Image for all?  Or Can I use the same docker file in all my spring boot microservices?</p></li>&#xA;<li><p>I am using postgreSQL database. So Can I include that connection into docker image file? Or I need to manage separately?</p></li>&#xA;</ul>&#xA;&#xA;<p>I am beginner in container , AWS and spring world, just started exploration. So Facing lot of confusions. Can anyone help to clarify my confusions please?</p>&#xA;"
48143008,consumer in kafka without loss message,2018-01-08 00:50:54,<apache-kafka><microservices>,2,113,1,0.0,0,"<p>Using microservices application layer using Spring, when a service publishes a message into kafka topic, &#xA;the other service that consumes that message is down.&#xA;When it comes back, will it reprocess from where it had stopped?&#xA;Is there something to be set up in order to not lose any messages?&#xA;The main idea is to process that message as streaming.</p>&#xA;"
48141031,Spring boot app scale up with mysql,2018-01-07 20:02:45,<mysql><docker><spring-boot><docker-compose><microservices>,1,132,1,0.0,0,"<p>I have created spring-boot app and database using mysql. Then I Dockerised And Deployed it. below show my docker-compse.yml </p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;  seat_reservation_service:&#xA;    image: springio/seat_reservation_service&#xA;    ports:&#xA;     - ""8090:8090""&#xA;    environment:&#xA;     - SPRING_PROFILES_ACTIVE=docker&#xA;  seat_reservation_sql:&#xA;    image: mysql:5.7&#xA;    ports:&#xA;    - 33306:3306&#xA;    environment:&#xA;    - MYSQL_ROOT_PASSWORD=root&#xA;    - MYSQL_DATABASE=seat-reservation-query&#xA;</code></pre>&#xA;&#xA;<p>this is my spring application.yml file</p>&#xA;&#xA;<pre><code>server:&#xA;  port: 8090&#xA;spring:&#xA;  profiles: docker&#xA;  main:&#xA;    banner-mode: 'off'&#xA;  datasource:&#xA;    url: jdbc:mysql://seat_reservation_sql:3306/seat-reservation-query?useSSL=false&#xA;    username: root&#xA;    password: root&#xA;    validation-query: SELECT 1&#xA;    test-on-borrow: true&#xA;  jpa:&#xA;    show_sql: false&#xA;    hibernate:&#xA;      ddl-auto: update&#xA;      dialect: org.hibernate.dialect.MySQL5&#xA;    properties:&#xA;      hibernate:&#xA;        cache:&#xA;          use_second_level_cache: false&#xA;          use_query_cache: false&#xA;        generate_statistics: false&#xA;  data:&#xA;    rest:&#xA;      base-path: /api/&#xA;  rabbitmq:&#xA;      host: rabbitmq-1&#xA;      username: test&#xA;      password: password&#xA;logging:&#xA;  level:&#xA;    org.springframework: false&#xA;    org.hibernate: ERROR&#xA;  path: logs/prod/&#xA;&#xA;axon:&#xA;  amqp:&#xA;    exchange: SeatReserveEvents&#xA;  eventhandling:&#xA;    processors: &#xA;      statistics.source: statisticsQueue&#xA;</code></pre>&#xA;&#xA;<p>My problem is I need more replicas form <code>seat_reservation_service</code> service. If I scale up <code>seat_reservation_service</code> that refer same database. According to micro-service architecture I need separate database for each replica. How can I do that? </p>&#xA;&#xA;<blockquote>&#xA;  <p>if I use in memory database it can do</p>&#xA;</blockquote>&#xA;"
48124856,How to make internal app available only to API gateway in microservices?,2018-01-06 06:22:33,<laravel><microservices>,1,224,1,0.0,0,"<p>I'm doing micro-service architecture in our app made of Laravel, Lumen. I have an API gateway that forwards the request to internal apps( say auth service is in 8001) then forwards the response to the client side. Other services like user, role etc is in different ports (8002 ...) </p>&#xA;&#xA;<p>How can I make sure that the client can access only the API gateway (in port 80) and not the other internal services? Let say the person (client) is in the same network environment. Firewall? Or am I doing it correctly?</p>&#xA;"
48062134,Connection refused with two microservices in Docker,2018-01-02 13:44:21,<java><docker><spring-boot><microservices>,1,1008,2,0.0,0,"<p>I have two microservices and I want that one consumes of the other but I'm obtaining this mistake: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path&#xA;  [] threw exception [Request processing failed; nested exception is&#xA;  org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  GET request for ""<a href=""http://localhost:8080/testMicroservicio"" rel=""nofollow noreferrer"">http://localhost:8080/testMicroservicio</a>"": Connection&#xA;  refused (Connection refused); nested exception is&#xA;  java.net.ConnectException: Connection refused (Connection refused)]&#xA;  with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused (Connection refused)</p>&#xA;</blockquote>&#xA;&#xA;<p>However if I execute the url in the browser, it works perfectly but if a microservice wants to access to the other microservice, I have this mistake.</p>&#xA;&#xA;<p>Does someone kown why?</p>&#xA;&#xA;<p>I'm consuming with: RestTemplate</p>&#xA;&#xA;<p>I put some of code:</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class MicroServiceController {&#xA;&#xA;&#xA;    private final AddressService service;&#xA;&#xA;    private static final String URL_API_INFO = ""http://localhost:8080/testMicroservicio"";&#xA;&#xA;    private RestTemplate restTemplate = new RestTemplate();&#xA;&#xA;    private final static Logger log = Logger.getLogger(""com.bernanetwork.web.controller.MicroServiceController"");&#xA;&#xA;    @Autowired&#xA;    public MicroServiceController(AddressService service) {&#xA;        this.service = service;&#xA;    }&#xA;&#xA;    @RequestMapping(value = ""/micro-service-test"")&#xA;    public String consumidor() throws Exception {&#xA;&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;        log.info(""-------------------------Iniciando mÃ©todo consumidor------------------------------------"");&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;&#xA;        ResponseEntity &lt;PruebasMicroservicio[]&gt; response = restTemplate.getForObject(URL_API_INFO, PruebasMicroservicio[].class);&#xA;&#xA;        Arrays.asList(response.getBody()).forEach(info -&gt; log.info(""---""+info));&#xA;&#xA;        return ""ok"";&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>These microservices are running in Docker</p>&#xA;&#xA;<p>Thanks so much.</p>&#xA;"
48153334,Microservices Monitoring Using Status Code,2018-01-08 15:30:31,<amazon-web-services><microservices>,1,34,3,0.0,0,"<p>We are using Amazon ECS for micro-services based architecture. We are right now using ALB service monitoring with target-group associated with each service in an ECS cluster. </p>&#xA;&#xA;<p>Right now, We are facing difficulty to monitor the microservices as they are hosted under route 53 private hosted zone. </p>&#xA;&#xA;<p>We have tried to monitor Route 53 health monitoring but route 53 doesn't allow to monitor the health of the endpoints with a simple routing policy. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Ref:&#xA;  <a href=""https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html</a></p>&#xA;</blockquote>&#xA;&#xA;<p>We need to monitor the status code of each microservice at any interval of time. </p>&#xA;&#xA;<p>We have also setup health-check for each microservice. Example: service-a.domain/ping. We need a status-page which represent the health of all available service we add using the status code we add. Also, any way if we can monitor them from application load balancer target group).</p>&#xA;&#xA;<p>What will be the best way to monitor every microservice. ?</p>&#xA;"
48030343,Microservice deployment --- simple jars vs docker containers,2017-12-30 02:14:56,<java><docker><war><microservices><continuous-deployment>,1,470,3,0.0,0,"<p>I am about to deploy a set of JAVA based microservices.&#xA;I am confused as to whether:</p>&#xA;&#xA;<ol>&#xA;<li>Run them as simple jars via ""java -jar [JAR_NAME]""</li>&#xA;<li>Run them in a JAVA based docker container.</li>&#xA;<li>Run them as a war.</li>&#xA;</ol>&#xA;&#xA;<p>Please offer me pros and cons of each implementation as this will save me a lot of headache if I use the suggested best approach :)</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
48095718,No service dependencies found in Jaeger UI,2018-01-04 12:50:20,<spring-boot><kubernetes><microservices><minikube><jaeger>,1,218,3,0.0,0,"<p>I am new to jaeger and I am facing issues with finding the services list in the jaeger UI.</p>&#xA;&#xA;<p>Below are the .yaml configurations I prepared to run jaeger with my spring boot app on Kubernetes using minikube locally.</p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/production-elasticsearch/elasticsearch.yml --namespace=kube-system</code></p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/jaeger-production-template.yml --namespace=kube-system</code></p>&#xA;&#xA;<p>Created deployment for my spring boot app and jaeger agent to run on the same container</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;    name: tax-app-deployment&#xA;spec:&#xA;    template:&#xA;      metadata:&#xA;        labels:&#xA;          app: tax-app&#xA;          version: latest&#xA;      spec:&#xA;        containers:&#xA;        - image: tax-app&#xA;          name: tax-app&#xA;          imagePullPolicy: IfNotPresent&#xA;          ports:&#xA;          - containerPort: 8080&#xA;        - image: jaegertracing/jaeger-agent&#xA;          imagePullPolicy: IfNotPresent&#xA;          name: jaeger-agent&#xA;          ports:&#xA;          - containerPort: 5775&#xA;            protocol: UDP&#xA;          - containerPort: 5778&#xA;          - containerPort: 6831&#xA;            protocol: UDP&#xA;          - containerPort: 6832&#xA;            protocol: UDP&#xA;          command:&#xA;          - ""/go/bin/agent-linux""&#xA;          - ""--collector.host-port=jaeger-collector.jaeger-infra.svc:14267""&#xA;</code></pre>&#xA;&#xA;<p>And the spring boot app service yaml</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: tax&#xA;  labels:&#xA;    app: tax-app&#xA;    jaeger-infra: tax-service&#xA;spec:&#xA;  ports:&#xA;  - name: tax-port&#xA;    port: 8080&#xA;    protocol: TCP&#xA;    targetPort: 8080&#xA;  clusterIP: None&#xA;  selector:&#xA;    jaeger-infra: jaeger-tax&#xA;</code></pre>&#xA;&#xA;<p>I am getting </p>&#xA;&#xA;<blockquote>&#xA;  <p>No service dependencies found</p>&#xA;</blockquote>&#xA;"
47975940,NodeJs micro services shared dependencies,2017-12-26 08:36:28,<node.js><npm><microservices><dependency-management>,1,66,7,0.0,0,"<p>i have built a microservices application using NodeJs . i have building this app for 4 month now and it starts to be big. i have used private modules to share code between the services but now i face anther problem. </p>&#xA;&#xA;<p>i am getting duplicate code for requiring this modules(and public modules) as many of them are being used in all the services and are called in my index file.</p>&#xA;&#xA;<p>so what i have try to do is build anther private module that it`s purpose is to include all this modules dependencies and control all the updates .</p>&#xA;&#xA;<p>that works good, the problem is the IDE ""phpstorm"" screams on me because now those dependencies are not in the service package.json  and also i dont have autocomplete on them(same reason) .</p>&#xA;&#xA;<p>is there a way to let the package json to use this dependencies from that package , or maybe anther technique to achieve this </p>&#xA;"
46171533,Calling Micro service inside a micro service,2017-09-12 08:31:12,<azure><microservices>,1,258,0,0.0,0,"<p><strong>Microsoft - Micro service architecture</strong></p>&#xA;&#xA;<p>Could it be reliable to call multiple micro services from a single micro service?</p>&#xA;&#xA;<p>If I have developed 2 different micro services of customers and orders with their own database (i.e. customer db and order db), and if I would like to get combined data of customers and orders, what would be the best option to do that?</p>&#xA;&#xA;<p>We want simply call one microservice which will call 2 separate microservices of customers and orders and combined their data and return a response of our choice. Is this usage is true?</p>&#xA;&#xA;<p>In another way, we will call 2 separate micro services from our application side and combined data there.</p>&#xA;&#xA;<p>I would like to get an option with the best performance, reliable and standard approach to do this process.</p>&#xA;&#xA;<p>Can anyone tell me what would be options ?</p>&#xA;&#xA;<p>and one more thing performance would be better in both side like in micro service response and in application side as well,</p>&#xA;&#xA;<p>If other options are available then also please specify.</p>&#xA;"
46131443,"java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing with microservices",2017-09-09 13:55:44,<java><microservices>,4,4903,0,0.0,0,"<p>I am new to the microservices + Spring Boot combinations and getting the below error while running the code from the link: <a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a> . Please guide me what is the nissue ?</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89) ~[spring-cloud-context-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at com.piggymetrics.statistics.StatisticsApplication.main(StatisticsApplication.java:34) [classes/:na]&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://config:8888/statistics-service/default"": config; nested exception is java.net.UnknownHostException: config&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    ... 7 common frames omitted&#xA;Caused by: java.net.UnknownHostException: config&#xA;    at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.PlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.SocksSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.NetworkClient.doConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.&lt;init&gt;(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:80) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:93) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$BasicAuthorizationInterceptor.intercept(ConfigServicePropertySourceLocator.java:179) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:85) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:69) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:596) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    ... 11 common frames omitted&#xA;&#xA;2017-09-09 19:19:34.861  INFO 4968 --- [           main] .b.l.ClasspathLoggingApplicationListener : Application failed to start with classpath: [file:/C:/Learnings/micro-services/PiggyMetrics/statistics-service/target/classes/, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-security/1.3.5.RELEASE/spring-boot-starter-security-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter/1.3.5.RELEASE/spring-boot-starter-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot/1.3.5.RELEASE/spring-boot-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.3.5.RELEASE/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-aop/4.2.6.RELEASE/spring-aop-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-config/4.0.4.RELEASE/spring-security-config-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-web/4.0.4.RELEASE/spring-security-web-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-expression/4.2.6.RELEASE/spring-expression-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-config/1.1.0.RELEASE/spring-cloud-starter-config-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter/1.1.0.RELEASE/spring-cloud-starter-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-context/1.1.0.RELEASE/spring-cloud-context-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-rsa/1.0.1.RELEASE/spring-security-rsa-1.0.1.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.47/bcpkix-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.47/bcprov-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-config-client/1.1.0.RELEASE/spring-cloud-config-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.6/jackson-annotations-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.6/jackson-databind-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.6/jackson-core-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/oauth/spring-security-oauth2/2.0.9.RELEASE/spring-security-oauth2-2.0.9.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-beans/4.2.6.RELEASE/spring-beans-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-core/4.2.6.RELEASE/spring-core-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-context/4.2.6.RELEASE/spring-context-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-webmvc/4.2.6.RELEASE/spring-webmvc-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-core/4.0.4.RELEASE/spring-security-core-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.3.5.RELEASE/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.3.5.RELEASE/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.0.33/tomcat-embed-core-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.0.33/tomcat-embed-el-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-logging-juli/8.0.33/tomcat-embed-logging-juli-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.0.33/tomcat-embed-websocket-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-validation/1.3.5.RELEASE/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/hibernate/hibernate-validator/5.2.4.Final/hibernate-validator-5.2.4.Final.jar, file:/C:/Users/pashtikar/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/org/jboss/logging/jboss-logging/3.3.0.Final/jboss-logging-3.3.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/classmate/1.1.0/classmate-1.1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-web/4.2.6.RELEASE/spring-web-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-feign/1.1.0.RELEASE/spring-cloud-starter-feign-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-core/1.1.0.RELEASE/spring-cloud-netflix-core-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-commons/1.1.0.RELEASE/spring-cloud-commons-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-crypto/4.0.4.RELEASE/spring-security-crypto-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-core/8.16.2/feign-core-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/jvnet/animal-sniffer-annotation/1.0/animal-sniffer-annotation-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-slf4j/8.16.2/feign-slf4j-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-hystrix/8.16.2/feign-hystrix-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-ribbon/1.1.0.RELEASE/spring-cloud-starter-ribbon-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon/2.1.5/ribbon-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-transport/2.1.5/ribbon-transport-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-contexts/0.4.9/rxnetty-contexts-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-servo/0.4.9/rxnetty-servo-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty/0.4.9/rxnetty-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec-http/4.0.27.Final/netty-codec-http-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec/4.0.27.Final/netty-codec-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-handler/4.0.27.Final/netty-handler-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport-native-epoll/4.0.27.Final/netty-transport-native-epoll-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-common/4.0.27.Final/netty-common-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-buffer/4.0.27.Final/netty-buffer-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport/4.0.27.Final/netty-transport-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-core/2.1.5/ribbon-core-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-httpclient/2.1.5/ribbon-httpclient-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-commons-util/0.1.1/netflix-commons-util-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-loadbalancer/2.1.5/ribbon-loadbalancer-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-statistics/0.1.1/netflix-statistics-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxjava/1.1.5/rxjava-1.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-archaius/1.1.0.RELEASE/spring-cloud-starter-archaius-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/archaius/archaius-core/0.7.4/archaius-core-0.7.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/commons-configuration/commons-configuration/1.8/commons-configuration-1.8.jar, file:/C:/Users/pashtikar/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-eureka/1.1.0.RELEASE/spring-cloud-starter-eureka-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-eureka-client/1.1.0.RELEASE/spring-cloud-netflix-eureka-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-client/1.4.6/eureka-client-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jettison/jettison/1.3.7/jettison-1.3.7.jar, file:/C:/Users/pashtikar/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-eventbus/0.3.0/netflix-eventbus-0.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-core/0.10.1/servo-core-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-internal/0.10.1/servo-internal-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-core/1.19.1/jersey-core-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-client/1.19.1/jersey-client-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/contribs/jersey-apache-client4/1.19.1/jersey-apache-client4-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-api/1.12.10/governator-api-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-core/1.4.6/eureka-core-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-core/1.10.30/aws-java-sdk-core-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-ec2/1.10.30/aws-java-sdk-ec2-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-autoscaling/1.9.3/aws-java-sdk-autoscaling-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-sts/1.9.3/aws-java-sdk-sts-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-route53/1.9.3/aws-java-sdk-route53-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator/1.12.10/governator-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-core/1.12.10/governator-core-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/woodstox-core-asl/4.4.1/woodstox-core-asl-4.4.1.jar, file:/C:/Users/pashtikar/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-eureka/2.1.5/ribbon-eureka-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/thoughtworks/xstream/xstream/1.4.2/xstream-1.4.2.jar, file:/C:/Users/pashtikar/.m2/repository/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar, file:/C:/Users/pashtikar/.m2/repository/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-data-mongodb/1.3.5.RELEASE/spring-boot-starter-data-mongodb-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/mongodb/mongo-java-driver/2.13.3/mongo-java-driver-2.13.3.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-mongodb/1.8.4.RELEASE/spring-data-mongodb-1.8.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tx/4.2.6.RELEASE/spring-tx-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-commons/1.11.4.RELEASE/spring-data-commons-1.11.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.21/jcl-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/1.3.5.RELEASE/spring-boot-starter-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-actuator/1.3.5.RELEASE/spring-boot-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-bus-amqp/1.1.0.RELEASE/spring-cloud-starter-bus-amqp-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-stream-rabbit/1.0.0.RELEASE/spring-cloud-starter-stream-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-binder-rabbit/1.0.0.RELEASE/spring-cloud-stream-binder-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-codec/1.0.0.RELEASE/spring-cloud-stream-codec-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-amqp/1.3.5.RELEASE/spring-boot-starter-amqp-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-rabbit/1.5.6.RELEASE/spring-rabbit-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-amqp/1.5.6.RELEASE/spring-amqp-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/http-client/1.0.0.RELEASE/http-client-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/amqp-client/3.5.7/amqp-client-3.5.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-amqp/4.2.5.RELEASE/spring-integration-amqp-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-jmx/4.2.5.RELEASE/spring-integration-jmx-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-bus/1.1.0.RELEASE/spring-cloud-bus-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-core/4.2.5.RELEASE/spring-integration-core-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-hystrix-stream/1.1.0.RELEASE/spring-cloud-netflix-hystrix-stream-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.3.5.RELEASE/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-classic/1.1.7/logback-classic-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-core/1.1.7/logback-core-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jul-to-slf4j/1.7.21/jul-to-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.21/log4j-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream/1.0.0.RELEASE/spring-cloud-stream-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-messaging/4.2.6.RELEASE/spring-messaging-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tuple/1.0.0.RELEASE/spring-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-tuple/1.0.0.RELEASE/spring-integration-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/retry/spring-retry/1.1.2.RELEASE/spring-retry-1.1.2.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/hystrix/hystrix-core/1.5.2/hystrix-core-1.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.7/HdrHistogram-2.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar]&#xA;</code></pre>&#xA;"
46240289,Spring security excluded path does not call controller's endpoint with Zuul Gateway,2017-09-15 13:03:48,<spring><spring-boot><spring-security><microservices><netflix-zuul>,1,82,0,0.0,0,"<p>I would like to disable security for a specific endpoint so that I can make a call to the Controller. Unfortunately, as I perform a call, I get a 304 (I see it in Chrome's developer tools) and I am redirected to the React frontend, ignoring my controller's endpoint</p>&#xA;&#xA;<pre><code>@EnableWebSecurity&#xA;@Configuration&#xA;@EnableOAuth2Sso&#xA;@EnableRedisHttpSession&#xA;public class MyWebSecurityConfig extends WebSecurityConfigurerAdapter {&#xA;    @Override&#xA;    protected void configure(HttpSecurity http) throws Exception {&#xA;        http.authorizeRequests().antMatchers(""/login*"").permitAll()        &#xA;                .and().anonymous()&#xA;            .disable()&#xA;            .exceptionHandling()&#xA;            .defaultAuthenticationEntryPointFor(new Http401AuthenticationEntryPoint(""""), new AntPathRequestMatcher(""/api/ **""))&#xA;&#xA;            .and()&#xA;            .authorizeRequests()&#xA;            .anyRequest().authenticated()&#xA;&#xA;            .and()&#xA;            .logout()&#xA;            .logoutUrl(""/logout"")&#xA;            .logoutRequestMatcher(new AntPathRequestMatcher(""/logout""))&#xA;            .invalidateHttpSession(true)&#xA;            .logoutSuccessUrl(ssoLogoutUrl)&#xA;&#xA;            .and()&#xA;            .csrf()&#xA;            .csrfTokenRepository(withHttpOnlyFalse());&#xA;    }&#xA;}&#xA;&#xA;@SpringBootApplication&#xA;@EnableZuulProxy&#xA;@EnableDiscoveryClient&#xA;@Import({AuthUserDetailService.class, GatewayWebSecurityConfig.class, VccLoginController.class})&#xA;public class GatewayApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        new SpringApplicationBuilder(GatewayApplication.class).run(args);&#xA;    }&#xA;}&#xA;&#xA;&#xA;@Controller&#xA;public class LoginController {&#xA;&#xA;    @RequestMapping(""/login"")&#xA;    public String login(Model model) {&#xA;        return ""login.html"";&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
46057423,Oracle Golden Gate for Integration with Microservices,2017-09-05 14:27:33,<integration><microservices><oracle-golden-gate>,1,95,0,0.0,0,"<p>I'm working on migration/integration of large on-premise Oracle monolithic app to cloud based Microservices. For a long time, microservices will need to be fed from and synchronized with the Oracle DB. </p>&#xA;&#xA;<p>One of the alternatives is using Oracle Golden Gate for DB-to-DB(s) near-real-time replication. The advantage is that it seems to be reliable and resilient. The disadvantage is that it works on low-level CDC/DB changes (as opposed to app-level events).</p>&#xA;&#xA;<p>An alternative is creating higher level business events from source DB by enriching data and then pushing it to something like Kafka. The disadvantage is that it puts more load on source DB, and requires durability on the source.</p>&#xA;&#xA;<p>Anybody dealt with similar problems? Any advice is appreciated.</p>&#xA;"
46067821,How to upload a CSV file in a microservice deployed in cloud foundry,2017-09-06 05:59:23,<csv><upload><microservices><cloudfoundry>,1,150,0,0.0,0,"<p>I am new to cloud foundry. I am currently working on a requirement where I have to upload a CSV file (via JSP UI) into a service deployed in cloud foundry and persists its data in service.&#xA;The issue is from UI, I only get a local path of that CSV file and when I am trying to parse that CSV via this path the file is not recognized. I guess the reason is service is already deployed in CF, so it does not recognize this local machine path.&#xA;   Can you please let me know how can I parse this CSV file in local machine and where to parse this CSV.</p>&#xA;&#xA;<p>Thanks in Advance!</p>&#xA;"
46180957,Pact verify not working - Annotated method not found during message provider test,2017-09-12 16:00:30,<microservices><pact><pact-jvm>,2,156,0,0.0,0,"<p>I have a project where we are using message provider since it involves Apache kafka based messaging.</p>&#xA;&#xA;<p>Consumer side maven goals are working fine from local as well as from Jenkins.</p>&#xA;&#xA;<p>Provider side pact-verify is failing in Jenkins saying ""No Annotated method found for interaction"".</p>&#xA;&#xA;<p>My POM.xml config as below:</p>&#xA;&#xA;<pre><code>&lt;plugin&gt;&#xA;&lt;groupId&gt;au.com.dius&lt;/groupId&gt;&#xA;&lt;artifactId&gt;pact-jvm-provider-maven_2.11&lt;/artifactId&gt;&#xA;&lt;version&gt;3.5.2&lt;/version&gt;&#xA;&lt;configuration&gt;&#xA;    &lt;!-- pactBrokerUrl,user name,password and project version required only &#xA;                    for consumer --&gt;&#xA;    &lt;pactBrokerUrl&gt;localhost&lt;/pactBrokerUrl&gt;&#xA;    &lt;projectVersion&gt;0.0.1&lt;/projectVersion&gt;&#xA;    &lt;!-- service provider required only for producer --&gt;&#xA;    &lt;serviceProviders&gt;&#xA;        &lt;!-- &lt;serviceProvider&gt;&lt;name&gt;provider&lt;/name&gt;&lt;verificationType&gt;ANNOTATED_METHOD&lt;/verificationType&gt;&lt;consumers&gt;&lt;consumer&gt;&lt;name&gt;consumer&lt;/name&gt;&lt;pactUrl&gt;pacturl&lt;/pactUrl&gt;&lt;/consumer&gt;&lt;/consumers&gt;&lt;/serviceProvider&gt; --&gt;&#xA;        &lt;serviceProvider&gt;&#xA;            &lt;name&gt;provider&lt;/name&gt;&#xA;            &lt;verificationType&gt;ANNOTATED_METHOD&lt;/verificationType&gt;&#xA;            &lt;consumers&gt;&#xA;                &lt;consumer&gt;&#xA;                    &lt;name&gt;consumer&lt;/name&gt;&#xA;                    &lt;pactUrl&gt;pacturl&lt;/pactUrl&gt;&#xA;                &lt;/consumer&gt;&#xA;            &lt;/consumers&gt;&#xA;        &lt;/serviceProvider&gt;&#xA;    &lt;/serviceProviders&gt;&#xA;    &lt;classpathElements&gt;&#xA;        &lt;classpathElement&gt;&#xA;          src/test/java&#xA;      &lt;/classpathElement&gt;&#xA;    &lt;/classpathElements&gt;&#xA;    &lt;configuration&gt;&#xA;        &lt;pact.showStacktrace&gt;true&lt;/pact.showStacktrace&gt;&#xA;    &lt;/configuration&gt;&#xA;&lt;/configuration&gt;&#xA;&lt;/plugin&gt;&#xA;</code></pre>&#xA;"
46153057,Can client-side call frontend microservices bypassing API gateway?,2017-09-11 10:05:24,<iframe><architecture><microservices><api-gateway>,1,178,0,0.0,0,"<p>Our system is build using microservices, that all sit behind an API gateway. Since all of them are REST API services, the benefits and whole point of using API gateway is clear to me. Now what about frontend microservices - the small components, that have both UI and corresponding backend to handle internal communication? Are there any scenarios where proxying every microservice HTTP calls is harmful?</p>&#xA;&#xA;<p><strong>Example</strong></p>&#xA;&#xA;<p>One of our microservice is a payment provider integration. As dealing with payments have specific regulations, one of those is a <strong>required</strong> web browser redirect to the user's bank page for authorization. Since this is impossible to do in a purely backend way, we deliver a <em>frontend microservice</em> - a service that essentially serves a HTML you must nest inside an iframe and should be able to process the payment in an e2e way. Very simplified and stripped example below.</p>&#xA;&#xA;<p>Let's say you are on <code>https://acme.com/order</code> and want to pay, where such snippet is embedded:</p>&#xA;&#xA;<pre><code>&lt;iframe src=""https://pay.acme.com?amount=42+USD&#xA;                                 &amp;returnUrl=https://acme.com/thankyou/[orderId]""&gt;&#xA;&lt;/iframe&gt;&#xA;</code></pre>&#xA;&#xA;<p>Basically a fire and forget thing for the developers of <code>https://acme.com</code>. What happens inside an iframe stays there. <code>https://pay.acme.com</code> however now worries about: collecting credit card details, validating them, redirecting user to the bank page to enter 2FA code or whatever needed, waiting until the payment is approved and finally moving user back to the <code>returnUrl</code> with a proper trail for which order the payment was finalized (<code>orderId</code>). </p>&#xA;&#xA;<p>Now, what about <code>pay.acme.com frontend &lt;-&gt; pay.acme.com backend</code> communication? Would it be OK to let microservice talk to itself, or rather all, even the internal communication that doesn't make any sense for API consumers, must go through the API gateway? That is of course possible to do and still keep the microservice decoupled and unaware of the API gateway, but this is much more costful than deviating from the <em>always do</em> constraint and bring very small benefits, as we don't use any advanced rate limiting or proxying features for now.</p>&#xA;"
46185813,Tracking and logging http calls made internally from a node.js server,2017-09-12 21:47:08,<node.js><http><logging><cloud><microservices>,1,211,0,0.0,0,"<p>I'm debugging calls made from my express app to another micro-service on my network. I'm receiving 401 errors and I need to get full raw http logs to give to my security team for analysis.</p>&#xA;&#xA;<p>I'm looking for some advice on tracking HTTP calls from a micro-service I have deployed on Pivotal Cloud Foundry. I've been doing some research and ran across tools like Zipkin and OpenTracing etc.. but those appear to be more about debugging latency and probably do not show HTTP logs. I've also tried using Morgan/Winston modules but they do not track internal calls. Morgan is currently what I'm using to log out the basic HTTP codes but it doesn't pick up on my calls from inside my app either, just the ones made to the app itself from the browser. I need to get the full raw HTTP request to assist the security team. I'm using the default logging output with morgan (STDOUT). I've console logged the headers to see the headers but would like to get them out in a slightly more readable format.</p>&#xA;"
46178051,Dynamic | User case Based logging,2017-09-12 13:42:36,<java><spring><logging><microservices><spring-cloud-sleuth>,2,22,1,0.0,0,"<p>Is there any logging framework, which helps me change logging levels dynamically based on the request parameters received ?</p>&#xA;&#xA;<p>If request has a parameter with debug enabled to true, then only it should log, else not.</p>&#xA;&#xA;<p>Does spring sleuth provide this feature in cloud environment?</p>&#xA;"
46117792,How to make one micro service instance at a time run a script (using dockers),2017-09-08 13:36:21,<node.js><docker><microservices>,1,25,1,0.0,0,"<p>I'll keep it simple. </p>&#xA;&#xA;<p>I have multiple instances of the same micro service (using dockers) and this micro service also responsible of syncing a cache.&#xA;Every X time it pulls data from some repository and stores it in cache. </p>&#xA;&#xA;<p>The problem is that i need only 1 instance of this micro-service to do this job, and if it fails, i need another one to take it place.</p>&#xA;&#xA;<p>Any suggestions how to do it simple?</p>&#xA;&#xA;<p>Btw, is there an option to tag some micro-service docker instance and make him do some extra work?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
46206775,Hotel communication microservice,2017-09-13 21:00:43,<microservices>,1,27,1,1.0,0,"<p>In a microservice architecture for a hotel I want to create a communication service that will handle all the emails, sms, ... This service should be triggered by asynchronous events. </p>&#xA;&#xA;<p>Should these events be called: SEND_RESERVATION_CONFIRMATION_EMAIL, making the reservation service aware of the email communication. Or should there be a more generic event RESERVATION_CONFIRMED, resulting in a confirmation email?</p>&#xA;"
46230643,Microservices with REST API and messaging,2017-09-15 02:06:02,<rest><messaging><microservices>,1,68,1,0.0,0,<p>Is it ok to have a microservice exposing a public REST API to a gateway but also communicate with other services through messaging? </p>&#xA;
46193708,How To Make Relations Between Two Entities From Different Microservices In Spring Boot?,2017-09-13 09:26:15,<spring-boot><spring-data><spring-data-jpa><microservices>,1,588,1,0.0,0,"<p>I am trying to make a simple <strong>Spring Boot</strong> web app using <strong>Microservice Architecture</strong>.</p>&#xA;&#xA;<p>I have two microservices with entities as defined below:</p>&#xA;&#xA;<pre><code>Microservice 1 :&#xA;&#xA;@Entity&#xA;public class Article {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and</p>&#xA;&#xA;<pre><code>Microservice 2 :&#xA;&#xA;@Entity&#xA;public class Tag {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I want to have a <strong>Many To Many</strong> relation between these two entities in my <strong>Gateway</strong>.</p>&#xA;&#xA;<p>I had tried to use feign client as below:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@FeignClient(value = ""article-service"")&#xA;public interface ArticleClient {&#xA;&#xA;    @RequestMapping(value = ""/articles/"", method = RequestMethod.GET)&#xA;    Set&lt;Article&gt; getArticleById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;&#xA;@FeignClient(value = ""tag-service"")&#xA;public interface TagClient {&#xA;&#xA;    @RequestMapping(value = ""/tags/"", method = RequestMethod.GET)&#xA;    Tag getTagById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And defined <strong>Article</strong> and <strong>Tag</strong> entities in my <strong>Gateway</strong> like this:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Entry {&#xA;&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;    @ManyToMany(cascade = CascadeType.ALL)&#xA;    @JoinTable(name = ""article_tag"",&#xA;        joinColumns = @JoinColumn(name = ""article_id"", referencedColumnName = ""id""),&#xA;        inverseJoinColumns = @JoinColumn(name = ""tag_id"",&#xA;                referencedColumnName = ""id""))&#xA;    private Set&lt;Tag&gt; tags;&#xA;}&#xA;&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Tag {&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    @ManyToMany(mappedBy = ""tags"")&#xA;    private Set&lt;Article&gt; articles;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have a table named <strong>article_tag</strong> in my database (<strong>Postgres</strong>).</p>&#xA;&#xA;<p>Now how can I define my repositories in the <strong>Gateway</strong>?&#xA;How to write getArticlesByTagId() or getTagsByArticleId() functions?&#xA;I did whatever I could to make this relation work but I think they are not going to get along with each other :)</p>&#xA;"
46065028,Unable to send the post request in spring cloud contract,2017-09-06 00:21:23,<java><spring><spring-boot><microservices><spring-cloud-contract>,1,84,1,0.0,0,"<p>I am trying to send a post request via <code>RestAssuredMockMvc.standaloneSetup()</code> and I am getting the below error for the request. I have my contracts in Groovy file with request and response code. I am getting the 400 response below the following exception.</p>&#xA;&#xA;<pre><code>org.springframework.http.converter.HttpMessageNotReadableException: Could not read document: Can not construct instance of com.organisation.online.myService.common.model.Payload, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information&#xA;at [Source: java.io.PushbackInputStream@6064493f; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of com.organisation.onlinebank.myService.common.model.Payload, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information&#xA;at [Source: java.io.PushbackInputStream@6064493f; line: 1, column: 1]&#xA;at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:240)&#xA;at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.read(AbstractJackson2HttpMessageConverter.java:225)&#xA;at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver.readWithMessageConverters(AbstractMessageConverterMethodArgumentResolver.java:201)&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:150)&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:128)&#xA;at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121)&#xA;at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:160)&#xA;at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:129)&#xA;at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)&#xA;at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)&#xA;at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)&#xA;at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)&#xA;at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)&#xA;at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)&#xA;at javax.servlet.http.HttpServlet.service(HttpServlet.java:595)&#xA;at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)&#xA;at org.springframework.test.web.servlet.TestDispatcherServlet.service(TestDispatcherServlet.java:65)&#xA;at javax.servlet.http.HttpServlet.service(HttpServlet.java:668)&#xA;at org.springframework.mock.web.MockFilterChain$ServletFilterProxy.doFilter(MockFilterChain.java:167)&#xA;at org.springframework.mock.web.MockFilterChain.doFilter(MockFilterChain.java:134)&#xA;at org.springframework.test.web.servlet.MockMvc.perform(MockMvc.java:155)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSenderImpl.performRequest(MockMvcRequestSenderImpl.java:174)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSenderImpl.sendRequest(MockMvcRequestSenderImpl.java:404)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSenderImpl.post(MockMvcRequestSenderImpl.java:590)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSenderImpl.post(MockMvcRequestSenderImpl.java:79)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSpecificationImpl.post(MockMvcRequestSpecificationImpl.java:752)&#xA;at com.jayway.restassured.module.mockmvc.internal.MockMvcRequestSpecificationImpl.post(MockMvcRequestSpecificationImpl.java:66)&#xA;at org.springframework.cloud.contract.verifier.tests.ContractVerifierTest.validate_should_Create_post_Request(ContractVerifierTest.java:25)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)&#xA;at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)&#xA;at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)&#xA;at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)&#xA;at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)&#xA;at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)&#xA;at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)&#xA;at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)&#xA;at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)&#xA;at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)&#xA;at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)&#xA;at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)&#xA;at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)&#xA;at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)&#xA;at org.junit.runners.ParentRunner.run(ParentRunner.java:363)&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>At the end of above exception.. here is the following junit assertion </p>&#xA;&#xA;<pre><code>expected:&lt;[2]00&gt; but was:&lt;[4]00&gt;&#xA;Expected :200&#xA;Actual   :400&#xA;&lt;Click to see difference&gt;&#xA;&#xA;org.junit.ComparisonFailure: expected:&lt;[2]00&gt; but was:&lt;[4]00&gt;&#xA;at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&#xA;at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;at org.springframework.cloud.contract.verifier.tests.ContractVerifierTest.validate_should_Create_post_Request(ContractVerifierTest.java:28)&#xA;</code></pre>&#xA;&#xA;<p>The actual payload which is sent inside the request is an interface and I know that could be the problem in creating the request payload. Other than that, I don't know how to deal with this error. Any clues will be appreciated.</p>&#xA;"
46092604,event-driven microservices id generation,2017-09-07 09:21:30,<java><microservices>,2,203,3,0.0,0,"<p>I'm a newbie with microservices. I'm trying to create a microservices architecture where there is an API gateway that should just receive the request and create an event accordingly. Then the event will be intercepted by a microservice that stores the needed data into a database. </p>&#xA;&#xA;<p>Maybe I'm making a mistake with the design but I expect that after a client calls the API gateway the request proceeds asynchronously and the data consistency won't be guaranteed. </p>&#xA;&#xA;<p>So how the client knows if the resource has been created and its id?</p>&#xA;&#xA;<p>Should the client listen to the events as well?</p>&#xA;&#xA;<p>Is this the right architecture or am I going through the wrong path?</p>&#xA;&#xA;<p>Thank you in advance for your comments!</p>&#xA;&#xA;<p>Note: I'm not using any structured framework. I like them but this is mostly an experiment and I'd like keep everything simple. Anyway I'm opened if your suggestion involve spring or whatever java framework. </p>&#xA;&#xA;<p>(Edit)</p>&#xA;&#xA;<p>Another interesting point. Let's give that the API response is asynchronous, if the client has to insert an aggregated data made by two resources (identified by their own id), how this can be achieved through an event-driven architecture?</p>&#xA;"
46190467,CQRS + Microservices Handling event rollback,2017-09-13 06:37:37,<domain-driven-design><microservices><cqrs><event-store>,3,223,3,1.0,0,"<p>We are using microservices, cqrs, event store using nodejs cqrs-domain, everything works like a charm and the typical flow goes like:</p>&#xA;&#xA;<ol>&#xA;<li>REST->2. Service->3. Command validation->4. Command->5. aggregate->6. event->7. eventstore(transactional Data)->8. returns aggregate with aggregate ID-> 9. store in microservice local DB(essentially the read DB)-> 10. Publish Event to the Queue</li>&#xA;</ol>&#xA;&#xA;<p>The problem with the flow above is that since the transactional data save i.e. persistence to the event store and storage to the microservice's read data happen in a different transaction context if there is any failure at step 9 how should i handle the event which has already been propagated to the event store and the aggregate which has already been updated?</p>&#xA;&#xA;<p>Any suggestions would be highly appreciated.</p>&#xA;"
46171136,"All my microservices have their own db's, should I create common microservice to handle connections?",2017-09-12 08:08:00,<database><architecture><microservices>,1,95,4,1.0,0,"<p>I have a number of microservices that maintain their own databases (mongodb, elastic, mysql) and each of the microservices I have to set-up a new connection constantly. </p>&#xA;&#xA;<p>I was considering would it be wise if I created another microservice, that could handle these connections for the microservices, before they start up.</p>&#xA;&#xA;<p>Example:&#xA;My API Gateway microservice gets a request for search, it then calls search microservice, which before the search starts, calls the database setup miscroservice and returns an established connection back to it, based on what microservice called it (in this case - the search microservice).</p>&#xA;&#xA;<p>Would it be better, if I just found out what connection is needed inside the API Gateway? Or should I just leave the logic separately in each microservice.</p>&#xA;"
41783283,RabbitMQ embedded broker is not starting from spring boot application,2017-01-21 19:02:28,<java><spring-boot><microservices><spring-rabbitmq><embedded-server>,1,1037,0,0.0,0,"<p>I am unable to send message in ""CustomerQ"" queue of rabbitmq broker. I have configured rabbitmq broker as embedded server through spring boot.</p>&#xA;&#xA;<pre><code> package com.testlab.chapter2;&#xA;&#xA;  import org.springframework.amqp.core.Queue;&#xA;  import org.springframework.amqp.rabbit.core.RabbitMessagingTemplate;&#xA;  import org.springframework.beans.factory.annotation.Autowired;&#xA;  import org.springframework.context.annotation.Bean;&#xA;  import org.springframework.context.annotation.Lazy;&#xA;  import org.springframework.stereotype.Component;&#xA;&#xA;&#xA;&#xA;  @Component &#xA;  @Lazy&#xA; class Sender {&#xA;&#xA;  RabbitMessagingTemplate template;&#xA;&#xA;  @Autowired&#xA;  Sender(RabbitMessagingTemplate template){&#xA;    this.template = template;&#xA;  }&#xA;&#xA;  @Bean&#xA;  Queue queue() {&#xA;    return new Queue(""CustomerQ"", false);&#xA;   }&#xA;&#xA;   public void send(String message){&#xA;    System.out.println(template.getRabbitTemplate().getConnectionFactory());&#xA;&#xA;    template.convertAndSend(""CustomerQ"", message);&#xA;    }&#xA;  }&#xA;&#xA; **application.properties file configuration:**&#xA;&#xA;  spring.rabbitmq.host=localhost&#xA;  spring.rabbitmq.port=5672&#xA;  spring.rabbitmq.username=guest&#xA;  spring.rabbitmq.password=guest&#xA;</code></pre>&#xA;&#xA;<p>I am getting below error when code is trying to connect/put any message in queue&#xA;<strong>Error:</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.messaging.MessagingException: java.net.ConnectException: Connection refused: connect; nested exception is org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused: connect] with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused: connect&#xA;      at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_25]&#xA;      at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:345) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_25]&#xA;      at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_25]&#xA;      at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_25]&#xA;      at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_25]</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate your help on this.</p>&#xA;"
41800036,Packaging ORM entities in microservice design,2017-01-23 05:55:06,<hibernate><entity><microservices>,1,534,0,1.0,0,"<p>I would like to build a microservice architecture. I am using Java technologies, such as Spring, Hibernate, etc. In this scenario, I have entities as Java classes. For instance, A microservice has A entity, B microservice has B entity, and so on. So, if there is a one-to-many relationship between A and B, I need to import one of the classes into other class to declare it.</p>&#xA;&#xA;<pre><code>// in A microservice&#xA;// need to import class of B like ""import com.project.B"", but can't&#xA;// because, it is different project.&#xA;@Entity&#xA;class A{&#xA;  @OneToMany&#xA;  B b;&#xA;}&#xA;&#xA;//in B microservice&#xA;@Entity&#xA;class B{&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, due to microservice design, they all are in different packages or services. Should I create another project as a shared library including all entities inside of it, then include in every microservice? Do you have another solution, or is this a solution?</p>&#xA;"
41779458,Application manager for microservices,2017-01-21 12:39:43,<microservices>,1,57,0,0.0,0,"<p>I'm trying to migrate some apps from a web container into microservices with Spring Boot.</p>&#xA;&#xA;<p>My question is, is there any application manager out there which looks like Systemd or other programing-language-agnostic managers which can manage all my applications?</p>&#xA;&#xA;<p>I don't like Systemd, because it requires Linux admin to start stop applications.</p>&#xA;&#xA;<p>FYI, I'm not using Docker for a moment.</p>&#xA;"
41830058,"Two way communication for Restful Microservices, Is it reasonable for notification?",2017-01-24 13:56:08,<rest><architecture><microservices>,1,443,0,0.0,0,"<p>Many books and articles state that cycles in Micro services are usually bad since they introduce mutual interdependency, that in result causes bigger dependency, versioning and deployment problems to solve. </p>&#xA;&#xA;<p>However, suppose that there is service <strong>A</strong>, calling service <strong>B</strong>, also suppose that since this call will initiate lengthy calculation so we should not make this call synchronous. A possible solution is service <strong>A</strong> passes a resource url to service <strong>B</strong>, so that when ever <strong>B</strong> calculates the result, it should post the result to the given url following restful paradigm. So this final resource is like some sort of callback. This approach indeed would solve my problem however as explained in the above paragraph it introduces a cyclic dependency. Is this okay? if not how else you would solve the same problem ?</p>&#xA;"
41880524,Microservices based architecture and individual cache for each node,2017-01-26 18:35:24,<java><hibernate><caching><architecture><microservices>,1,764,0,0.0,0,"<p>Is it considered bad practice to use separated, local cache for each node in distributed microservice application? I've heard that in monolithic application it's OK to use local EHCache as 2nd level cache provider for Hibernate, but in distributed environment it's common practice to use distributed caches, such as Memcached, Redis or Hazelcast. What are the consequences of using separated cache for each node?</p>&#xA;"
41809373,How to do Pen testing / Security testing on Microservices?,2017-01-23 15:03:25,<testing><sql-injection><microservices><penetration-testing><security-testing>,1,380,1,0.0,0,"<p>Wanted to test microservices for security requirements and did some google and found some good blogs e.g URL: <a href=""https://www.imbalife.com/sql-injection"" rel=""nofollow noreferrer"">https://www.imbalife.com/sql-injection</a>.   </p>&#xA;&#xA;<p>Eg.SQL Injection Vulnerable Dorks.&#xA;inurl:index.php?id=</p>&#xA;&#xA;<p>How to test if URL don't have any PHP stuff. And check for Vulnerability.&#xA;I am new in this security testing area. Please help me.<br>&#xA;Thank you</p>&#xA;"
41893566,Can/Should Spring AOP be used with Microservices & Spring Boot?,2017-01-27 12:03:15,<spring-boot><spring-aop><microservices>,2,481,1,0.0,0,"<p>We are analyzing different concepts for one of my projects. We decided to use <code>Spring Boot</code> &amp; <code>Microservices</code> architecture.</p>&#xA;&#xA;<p>After further discussions, we came to a query whether we <strong>CAN/SHOULD</strong> use <code>Spring AOP</code> to resolve cross cutting concerns of various <code>microservices</code>?</p>&#xA;&#xA;<p>If <strong>not</strong> how can we address common concerns of microservices like logging, transaction mgmt, etc?</p>&#xA;&#xA;<p>I have googled this topic extensively (even went to 5 pages for same search), but no luck. Any help appreciated.</p>&#xA;"
41783704,How can we route a request to every pod under a kubernetes service on Openshift?,2017-01-21 19:42:36,<kubernetes><microservices><restful-architecture><application-design><openshift-enterprise>,1,307,3,0.0,0,"<p>We are building a Jboss BRMS application with <em>two microservices in spring-boot</em>, one for <strong>rule generation (SRV1)</strong> and one for <strong>rule execution (SRV2)</strong>.&#xA;The idea is to <strong><em>generate the rules</em></strong> using the generation microservice (SRV1) and <strong><em>persist them in the database with versioning</em></strong>. The next part of the process is having the execution microservice <strong><em>load these persisted rules into each pods memory</em></strong> by querying the information from the shared database.</p>&#xA;&#xA;<p>There are two following scenarios when this should happen :</p>&#xA;&#xA;<blockquote>&#xA;  <ul>&#xA;  <li><p>When the rule execution service pod/pods <strong>starts up</strong>, it queries the db for the lastest version and every pod running the execution application loads those rules from the shared db.</p></li>&#xA;  <li><p>The second senario is we <strong>manually</strong> want to trigger the loading of a <strong>specific version</strong> of rules on every pod running the execution application preferably via a rest call.</p></li>&#xA;  </ul>&#xA;</blockquote>&#xA;&#xA;<p><strong><em>Which is where the problem lies!</em></strong> </p>&#xA;&#xA;<p>Whenever we try and issue a rest request to the api, since it is load balanced under a kubernetes service, the request hits only one of the pods and the rest of them do not load the specific rules.</p>&#xA;&#xA;<p>Is there a programatic or design change that may help us achieve that or is there any other way we construct our application to achieve a capability to load a certain version of rules on all pods serving the execution microservice.</p>&#xA;"
35772518,How to run Spring Cloud Config server in Fault Tolerance mode?,2016-03-03 12:42:50,<spring-boot><spring-cloud><microservices>,2,335,0,0.0,0,"<p>In my project we have a requirement to run two instances of spring cloud config server so if one instance goes down, other will take care the config server responsibilities. </p>&#xA;"
35875489,Are API Gateways always necessary in a Microservice styled architecture?,2016-03-08 18:46:19,<microservices>,2,362,0,1.0,0,<p>I have seen examples on the net where API gateway becomes the entry point for the client requests. Are API Gateways always necessary in a Microservice styled architecture ?</p>&#xA;
35820780,Handling dependencies in a Python micro service environment,2016-03-05 22:37:48,<python><dependencies><microservices>,1,113,0,0.0,0,"<p>Background: I want to make plenty of micro services written in Python (Django, Flask... does not matter for now) for intranet use. Let's say there's going to be an auth service, a notification service (email and/or internet communicators integration) and some kind of data resource service. &#xA;So a users goes though auth (e.g. get's a JWT) then hit's the data service to change something. That change should trigger a call to the notification service to send the notification.<br>&#xA;The questions begin from how to handle and should I even consider doing a kind of clients for my services? &#xA;What I have in mind right now is to make Python packages or simply use git sub modules to handle that, like so:<br>&#xA;Having and endpoint <code>data.service.local/api/v1/food</code> I would like (I think) to make a 'provider' that would allow me to use that endpoint in a easy way:  </p>&#xA;&#xA;<pre><code>class DataServiceProvider(object):&#xA;&#xA;    BASE_URL = settings.DATA_SERVICE_URL&#xA;&#xA;    def create_food(self, name):&#xA;        return requests.post(BASE_URL + 'food', {'name': name})&#xA;</code></pre>&#xA;&#xA;<p>Should I even bother? I aim for having dozens of my other services hitting this one (especially the notification one) so I guess I should. But where to store those providers? Outside in another repository named <code>{service_name}-client</code> and use the package in any other service that needs to use it?  </p>&#xA;&#xA;<p>Appreciate any advice. Thank you.</p>&#xA;"
35862481,Grails Micro Service Externalize Authentication,2016-03-08 08:31:52,<authentication><grails><spring-security><microservices>,1,129,0,0.0,0,"<p>I have a multi project composed by the following two app:</p>&#xA;&#xA;<blockquote>&#xA;  <p>1) App 1 (profile web)</p>&#xA;  &#xA;  <p>2) App 2 (profile rest) + spring-securyty-core-plugin + Spring&#xA;  Security REST plugin</p>&#xA;</blockquote>&#xA;&#xA;<p>App 1 the ""rest client"" of App2.&#xA;Now I'm going to install spring-securyty-core-plugin also in app 2.</p>&#xA;&#xA;<p>Now the question: it is possible to externalize the authorization process in App 1 without creating the User and Role domain class in App 1?&#xA;App 1 will use App 2 for User handling.</p>&#xA;"
35730116,How to connect microservice to SQS/SNS,2016-03-01 18:03:15,<amazon-ec2><docker><amazon-sqs><microservices>,2,434,0,0.0,0,<p>I have a java microservice that runs in a Docker container in a Ec2 instance . &#xA;It has to get notified when a file is dropped in a S3 bucker. We have a SNS and SQS that is connected to the S3 bucket. How can i connect the microserice to the SNS/SQS ? If there is a better way to get the java microservice get notified when the files is dropped into S3 bucket please let me know ? </p>&#xA;
35890054,Test automation for microservices architecture,2016-03-09 11:16:13,<automated-tests><microservices>,3,609,2,0.0,0,"<p>I am in charge of implementing QA processes and test automation for a project using microservices architecture.</p>&#xA;&#xA;<p>Project has one public api that makes some data available. So I will automate API tests. Tests will live in one repository. This part is clear to me, I did this before in other monolith projects. I had one repo for API tests. And possibly another repo for selenium tests.</p>&#xA;&#xA;<p>But then here the whole poduct consists of many microservices that communicate via restful apis and/or rabbit queues. How would I go about automating tests for each of these individual servicess? Would tests for each individual service be in a separate repo? Note: services are written in Java or PHP. I will automate tests with Python. It seems to me that I will end up with a lot of repos for tests/stubs/mocks.</p>&#xA;&#xA;<p>What suggestions or good resources can community offer? :)</p>&#xA;"
35817536,From local development to dockerized microservices,2016-03-05 17:46:26,<networking><docker><microservices><service-discovery>,1,100,2,0.0,0,"<p>I am getting started with dockerized micro services.</p>&#xA;&#xA;<p>A couple of them are running (see the code snippet below). In my local test setup, each service was available at <code>localhost:somePort</code>. E.g. the frontend would try to connect to the backend API at <code>localhost:backend1</code>.&#xA;Now in the containerized world this does not work anymore. Am I supposed to run a full fledged service discovery solution like <code>consul</code> or <code>etcd</code>? Or should I just try to access the backend from the frontend using docker's naming service? <a href=""https://docs.docker.com/compose/networking/"" rel=""nofollow"">https://docs.docker.com/compose/networking/</a></p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;  service1-backend:&#xA;    image: service1:0.0.1&#xA;    links:&#xA;      - service1-frontend&#xA;  service1-frontend:&#xA;      image: service1-frontend:0.0.1&#xA;      links:&#xA;            - service2-frontend&#xA;      ports:&#xA;              - ""8080:80""&#xA;  service2-backend:&#xA;      image: service2-backend:0.0.1&#xA;      links:&#xA;            - service1-backend&#xA;            - service2-frontend&#xA;            - service3&#xA;  service2-frontend:&#xA;      image: service2-frontend:0.0.1&#xA;      ports:&#xA;              - ""8081:80""&#xA;  service3:&#xA;      image: service3:0.0.1&#xA;</code></pre>&#xA;"
51362482,Is it okay to do database operations and API call in a single transaction?,2018-07-16 13:02:19,<rest><api><transactions><microservices><distributed-system>,1,19,0,0.0,0,"<p>Let's take an example scenario for a simple buy operation where a user can pay from his wallet or from credit card or in case the amount exceed from the amount he has in his wallet then the remaining amount will be billed to his credit card. SO in that scenario there are two distinct transactions one to debit the wallet and then also charge the credit card. And let's assume that wallet is a DB operation while Credit card is a call to third party, is it okay to do both these operations in a single DB transaction so that if an one fails the entire operations rollsback or should I do it in parallel as most modern apps now utilize parallel operations. If I do both operations in parallel then how would I ensure the atomicity of the entire operation?</p>&#xA;&#xA;<p>How do we implement such kind of functionality in a microservices architecture or distributed applications?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
51454135,Multi Module Project with maven in Spring,2018-07-21 08:07:52,<spring><maven><spring-boot><microservices><multi-module>,1,19,0,0.0,0,<p>I have a project in spring boot with maven and It has 5 module with 1 parent module.</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>Module Structure</strong></p>&#xA;</blockquote>&#xA;&#xA;<pre><code> &lt;modules&gt;&#xA;    &lt;module&gt;service-app&lt;/module&gt;&#xA;    &lt;module&gt;admin-app&lt;/module&gt;&#xA;    &lt;module&gt;service-api&lt;/module&gt;&#xA;    &lt;module&gt;admin-api&lt;/module&gt;&#xA;    &lt;module&gt;mail-api&lt;/module&gt;&#xA;    &lt;module&gt;storage-api&lt;/module&gt;&#xA;&lt;/modules&gt;&#xA;&#xA;&#xA;&#xA;    1. admin-app = {&lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;service-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storage-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mail-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;}&#xA; 2. service-api={&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storage-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;            &lt;scope&gt;compile&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;}&#xA; 3. service-app={&#xA;&lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;service-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storage-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;            &lt;scope&gt;compile&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mail-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I tried to add new module and I have created but when I run program it returned errors. My new module is named storage-api there are its application.properties file some config params. When I want to use them in classes of storage-api. with @Value annotation it did not see them.&#xA;in this case How I can fix it problem</p>&#xA;
51422793,Cloud Foundry back-end and public apps,2018-07-19 12:32:00,<security><microservices><cloudfoundry><pivotal-cloud-foundry><12factor>,1,23,0,1.0,0,"<p>In most solutions some apps should be public and some should be internal-only accessible.</p>&#xA;&#xA;<p><strong>Is there a proven configuration pattern of such a solution?</strong></p>&#xA;&#xA;<p>The simple way to do this may be to create two CF spaces (in the same CF organization):</p>&#xA;&#xA;<ul>&#xA;<li>the <code>internal space</code>&#xA;&#xA;<ul>&#xA;<li>apps in this space are binded to the <code>internal domain</code> (e.g: *.my-internal-cf.cloud) that points the <code>internal load-balancer</code></li>&#xA;<li>the <code>internal domain</code> is main shared domain</li>&#xA;<li>the <code>internal load-balancer</code> isn't accessible from the Internet, can be accessible only for apps from the Cloud Foundry</li>&#xA;<li>the <code>internal space</code> has access to the backing-services (cf security-groups)</li>&#xA;</ul></li>&#xA;<li>the <code>public space</code>: &#xA;&#xA;<ul>&#xA;<li>apps in this space are binded to the <code>public domain</code> (e.g: *.my-pub-cf.cloud) that points the <code>public load-balancer</code></li>&#xA;<li>the <code>public load-balancer</code> is accessible from the Internet and passing only traffic to the <code>public domains</code></li>&#xA;<li>the <code>public space</code> has limited access to the backing-services or even has only access to apps from the <code>internal space</code> (cf security-groups)</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p><strong>Is this configuration secure?</strong></p>&#xA;&#xA;<p><strong>Can it be done more easily?</strong></p>&#xA;"
51408476,Web UI code and microservices in the same monorepo?,2018-07-18 18:11:07,<docker><repository><microservices><web-application-design>,1,28,0,0.0,0,"<p>We are a startup and are beginning the process of porting over our entire web app to a decoupled concept where an Angular web UI talks to a collection of microservices. It's your standard modern approach.&#xA;What is not standard about our strategy is that our CTO has strongly suggested (basically insisted) that we include the code for the Angular front-end in the same monorepo along with all of the microservices that are written in PHP/Lumen. The supposed advantage being that changes to common protocols (like JSON structure, etc) will be easier to deal with if everything is in the same repo. &#xA;While I'm totally onboard for keeping all the microservices in the same monorepo I am really hesitant about throwing the Angular code in there as well mostly because I can't seem to find any best practices or precedent for doing this. I have searched and searched and no one seems to have an experience with this kind of setup that they are willing to share. Is there a recommended approach for this specific sort of setup?  </p>&#xA;"
51491162,How to exchange data between instances of the same service in Consul?,2018-07-24 05:38:10,<microservices><spring-cloud><consul>,1,32,0,0.0,0,"<p>I'm trying a combination of Spring cloud and Consul and I wonder if there is way to exchange data and state between instance the same of a microservice. </p>&#xA;&#xA;<p>For example, I have AuthenticationService1 (AS1) and AuthenticationService2 (AS2). When a user comes to AS1, he logs in, receives a token and next time he comes it's only verified. But at this moment AS2 is not aware of the state of AS1.</p>&#xA;&#xA;<p>I saw ideas about using a database table where information about user sessions is stored, but maybe there is an easier way for AS1 to share its state with AS2 or to send a message about log in?</p>&#xA;"
51423358,"Is there a way to ""npm install"" from AWS S3?",2018-07-19 13:00:55,<node.js><amazon-web-services><amazon-s3><microservices>,1,35,0,0.0,0,"<p>Is there a way to store projects/modules on AWS S3 and do an <code>npm install</code> from a client project?</p>&#xA;&#xA;<p>I've found a way to do an <code>npm install</code> from BitBucket in the npm docs <a href=""https://docs.npmjs.com/cli/install"" rel=""nofollow noreferrer"">[Go]</a> </p>&#xA;&#xA;<p>I'm trying to find different ways to store common project items (i.e. methods or other resources) to use across microservices.</p>&#xA;"
51422290,Advantage of using ThreadPool in Hystrix,2018-07-19 12:06:33,<spring><architecture><microservices><hystrix>,1,37,0,0.0,0,"<p>What is the advantage of using threadpool in Hystrix?&#xA;Suppose we are calling a third party service ,when we call a service or DB that thread goes into waiting state than what is the use of keep creating thread for each call?</p>&#xA;&#xA;<p>So,I mean how short circuited(Threadpooled) method is batter then normal(non short circuited) method?</p>&#xA;"
51511923,How to debug java microservices on openshift cluster,2018-07-25 06:10:12,<java><debugging><openshift><microservices>,1,41,0,0.0,0,<p>My java microservice mesh is deployed on openshift cluster and I am looking for a way to debug a particular (the buggy one) microservice locally.&#xA;I have tried the squash debugger and telepresence but nothing worked for me as squash provides support for java on intelliJ and I am using eclipse (Can't pay for intelliJ) and telepresence is not able to find my pod which is already existing on my openshift cluster.</p>&#xA;
51433860,Hystrix-> How circuit is closed again,2018-07-20 01:30:03,<architecture><microservices><hystrix>,2,47,0,0.0,0,"<p>I am trying to understand Hystrix. I understand when a service makes call to a 3rd party service and that service is not responding and threshold has been exceeded than the configuration. Circuit will be opened and onward calls will be short circuited.&#xA;But I am not able to understand how circuit is closed again.Let us suppose our service is making call to 3rd party service and that service not not working fine so circuit is opened, After 5 minute that service has started working fine now circuit should be closed. How calling service knows this that the 3rd party service has started behaving fine, now circuited should be closed?</p>&#xA;"
51379968,Example micoservice app with CQRS and Event Sourcing,2018-07-17 11:11:25,<microservices><cqrs><event-sourcing>,1,69,0,1.0,0,"<p>I'm planning to create a simple microservice app (set and get appointments) with CQRS and Event Sourcing but I'm not sure if I'm getting everything correctly. Here's the plan:</p>&#xA;&#xA;<ol>&#xA;<li>docker container: public delivery app with REST endpoints for getting and settings appointments. The endpoints for settings data are triggering a RabbitMQ event (async), the endpoint for getting data are calling the command service (sync).</li>&#xA;<li>docker container: for the command service with connection to a SQL database for setting (and editing) appointments. It's listening to the RabbidMQ event of the main app. A change doesn't overwrite the data but creates a new entry with a new version. When data has changed it also fires an event to sync the new data to the query service.</li>&#xA;<li>docker container: the SQL database for the command service.</li>&#xA;<li>docker container: the query service with connection to a MongoDB. It's listening for changes in the command service to update its database. It's possible for the main app to call for data but not with REST but with ??</li>&#xA;<li>docker container: an event sourcing service to listen to all commands and storing them in a MongoDB.</li>&#xA;<li>docker container: the event MongoDB.</li>&#xA;</ol>&#xA;&#xA;<p>Here are a couple of questions I don't get:</p>&#xA;&#xA;<ul>&#xA;<li><p>let's say there is one appointment in the command database and it already got synced to the query service. Now there is a call for changing the title of this appointment. So the command service is not performing an UPDATE but an INSERT with the same id but a new version number. What is it doing afterwards? Reading the new data from the SQL and triggering an event with it? The query service is listening and storing the same data in its MongoDB? Is it overwriting the old data or also creating a new entry with a version? That seems to be quite redundant? Do I in fact really need the SQL database here?</p></li>&#xA;<li><p>how can the main app call for data from the query service if one don't want to uses REST?</p></li>&#xA;<li><p>Because it stores all commands in the event DB (6. docker container) it is possible to restore every state by running all commands again in order. Is that ""event sourcing""? Or is it ""event sourcing"" to not change the data in the SQL but creating a new version for each change? I'm confused what exactely event sourcing is and where to apply it. Do I really need the 5. (and 6.) docker container for event sourcing?</p></li>&#xA;<li><p>When a client wants to change something but afterwards also show the changed data the only way I see is to trigger the change and than wait (let's say with polling) for the query service to have that data. What's a good way to achieve that? Maybe checking for the existing of the future version number?</p></li>&#xA;<li><p>Is this whole structure a reasonable architecture or am I completely missing something?</p></li>&#xA;</ul>&#xA;&#xA;<p>Sorry, a lot of questions but thanks for any help!</p>&#xA;"
51505849,Spring boot admin: Full authentication is required to access this resource,2018-07-24 19:03:17,<spring-boot><spring-security><microservices><spring-boot-admin>,1,85,0,0.0,0,"<p>we are using netflix oss for reverse proxying and security of microservices, we are following  the jhipster pattern mentioned here <a href=""https://www.jhipster.tech/microservices-architecture/"" rel=""nofollow noreferrer"">https://www.jhipster.tech/microservices-architecture/</a>, where request from UI application  goes to gateway which is Api Gateway and it proxies the request to our backend microservices , we are using jwt for authentication, we wanted a dashboard to monitor our microservices and api gateway which registers with eureka server , we started a separate spring boot admin server so that it registers with eureka server and poll microservices and gateway for metrics endpoint but we are getting exception  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Full authentication is required to access this resource</p>&#xA;</blockquote>&#xA;&#xA;<p>which is thrown by filters which are filtering for jwts at both api gateway and microservices level,&#xA;we also tried disabled </p>&#xA;&#xA;<pre><code>management.security.enabled: false &#xA;</code></pre>&#xA;&#xA;<p>but still no luck ,can some one please help to guide what changes i need to make   to enable spring boot admin to successfully poll  the microservices and api gateway?</p>&#xA;&#xA;<p>I tried the following approach </p>&#xA;&#xA;<p>firstly i enabled  web.ignoring().antMatchers(""/actuator/**""), so that actuator endpoints are ignored by spring security but this approach will risk my api's</p>&#xA;&#xA;<p>Second idea:</p>&#xA;&#xA;<p>if i enable 2 filters in spring security , the first filter would be for spring boot admin with basic authentication for actuator endpoints  and second filter will be of my jwt authentication for rest all api's and downstream api's not sure will it be feasible?</p>&#xA;&#xA;<p>i enabled the 2 filters one filter for actuator end points and 1 filter for api's but these filters are working perfectly but not able to connect to SBA </p>&#xA;&#xA;<pre><code>public class SpringSecurityAdminFilter extends WebSecurityConfigurerAdapter {&#xA;&#xA;&#xA;&#xA;@Autowired&#xA;public void configureGlobalSecurity(AuthenticationManagerBuilder auth) throws Exception {&#xA;&#xA;       String password = passwordEncoder().encode(""xxxx"");&#xA;    auth.inMemoryAuthentication().passwordEncoder(passwordEncoder()).withUser(""sam"").password(password).roles(""ADMIN"");&#xA;&#xA;}&#xA;&#xA;@Bean&#xA;public BCryptPasswordEncoder passwordEncoder() {&#xA;    return new BCryptPasswordEncoder();&#xA;}&#xA;&#xA;@Override&#xA;protected void configure(HttpSecurity http) throws Exception {&#xA;&#xA;  http.csrf().disable()&#xA;    .authorizeRequests()&#xA;    .antMatchers(""/actuator/**"").hasRole(""ADMIN"")&#xA;    .and().httpBasic()&#xA;    .and().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);//We don't need sessions to be created.&#xA;}&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;"
51531230,How to manage JPA entity in Spring boot micro services?,2018-07-26 04:51:51,<jpa><orm><architecture><spring-data-jpa><microservices>,1,23,1,0.0,0,"<p>I have two micro services with the shared database. like user management service and organization management service. both services have its own entities.</p>&#xA;&#xA;<p>now the problem is I have to manage one to many relationship between organization and user, I have few solutions with doubt.</p>&#xA;&#xA;<p><strong>solutions :</strong> </p>&#xA;&#xA;<blockquote>&#xA;  <ol>&#xA;  <li><p>I can duplicate entities in both services (but if there is any change in entity like add or remove attribute, I have to take care in&#xA;  all services).</p></li>&#xA;  <li><p>I can create a shared jar for entities (but in case of change in entities, I have to restart both services)</p></li>&#xA;  <li><p>I can fire pure <code>SQL</code> query.</p></li>&#xA;  </ol>&#xA;</blockquote>&#xA;&#xA;<p>any other suggestion or help will save my day.</p>&#xA;&#xA;<p>please suggest me a better solution!!</p>&#xA;"
51421205,How to trigger an action only after receiving two or more events in an event driven architecture?,2018-07-19 11:13:01,<architecture><microservices><event-driven-design>,1,28,2,1.0,0,"<p>I have started implementing microservices in an Event-Driven Architecture. Therefore some of my services are publishing events and listening to some other events. It is very straightforward to implement a listener when an action depends on one single event, for example;</p>&#xA;&#xA;<pre><code>ORDER SERVICE &#xA;  1. Publishes `ORDER_INTENT_EVENT` then&#xA;  2. Listens for `CREDIT_AVAILABLE_EVENT` then&#xA;  3. Finishes the `Order`&#xA;&#xA;CREDIT SERVICE&#xA;  1. Listens for `ORDER_INTENT_EVENT` then&#xA;  2. Verifies if the client has credit then locks the amount and&#xA;  3. Publishes `CREDIT_AVAILABLE_EVENT`&#xA;</code></pre>&#xA;&#xA;<p>The problem arises when OrderService has to wait for more than one event, for example;</p>&#xA;&#xA;<pre><code>ORDER SERVICE &#xA;  1. Publishes `ORDER_INTENT_EVENT` then&#xA;  2. Listens for `CREDIT_AVAILABLE_EVENT` &#xA;             and `INVENTORY_AVAILABLE_EVENT` then &lt;--- Problem here&#xA;&#xA;  3. Finishes the `Order`&#xA;&#xA;CREDIT SERVICE&#xA;  1. Listens for `ORDER_INTENT_EVENT` then&#xA;  2. Verifies if the client has credit then locks the amount and&#xA;  3. Publishes `CREDIT_AVAILABLE_EVENT`&#xA;&#xA;INVENTORY SERVICE&#xA;  1. Listens for `ORDER_INTENT_EVENT` then&#xA;  2. Verifies if inventory has items then locks the items and&#xA;  3. Publishes `INVENTORY_AVAILABLE_EVENT`&#xA;</code></pre>&#xA;&#xA;<p>The thing is; I am pooling both queues <code>CREDIT_AVAILABLE_QUEUE</code> and <code>INVENTORY_AVAILABLE_QUEUE</code>,&#xA;and both events has to be present so I can finish an order. <strong>How can I coordinate so that OrderService sees both events as only one?</strong></p>&#xA;&#xA;<p>I can implement it at the application level, for example; if one event arises I save it to the database and check if there is the other corresponding event to same order, if so I proceed with finishing the order, if not I do nothing then when the other event arrives I will have both of them so I am able to finish the order. The problem with this approach is that there is a minimal chance of receiving both events at the same time generating race conditions. </p>&#xA;&#xA;<p>What is the suggested pattern for this kind of scenario?</p>&#xA;&#xA;<p><em>PS.: I found <a href=""https://stackoverflow.com/questions/37509121/listening-on-multiple-events"">this similar question</a> but one answer suggests .net related tools and the other points to a third party service. I am interested in a pattern/code solution.</em></p>&#xA;"
51530578,How to create Django browsable REST API without auth or permissions?,2018-07-26 03:29:33,<python><django><rest><django-rest-framework><microservices>,1,35,2,0.0,0,"<p>I removed <code>admin</code>, <code>auth</code>, <code>permissions</code>, and a few other apps and middleware pieces from my DRF service. I'm running a microservice architecture where each service owns its own database. I don't need Django to pollute all those databases with its own set of <code>auth</code>/<code>user</code>/<code>permissions</code> tables.</p>&#xA;&#xA;<p>Now I'm getting:</p>&#xA;&#xA;<pre><code>Model class django.contrib.auth.models.Permission doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.&#xA;</code></pre>&#xA;&#xA;<p>What is still using the <code>auth</code> models and how do I get rid of it?</p>&#xA;&#xA;<p><strong>More Context:</strong></p>&#xA;&#xA;<p>I want a microservice with only three things:</p>&#xA;&#xA;<ol>&#xA;<li>A REST framework</li>&#xA;<li>A database abstraction layer </li>&#xA;<li>A browsable API (doesn't have to be HTML, can be pure JSON)</li>&#xA;</ol>&#xA;&#xA;<p>Is it even possible to do such a thing in DRF without having 20 sets of <code>auth</code> tables for 20 databases (for 20 services)?</p>&#xA;"
51498267,One authentication API to many other API microservices,2018-07-24 12:09:12,<.net><api><.net-core><microservices>,2,43,2,0.0,0,"<p>My plan is to build some separated WebApi backend apps in .Net Core 2.1. I would like to have also one big fronted application (built in Angular), which will use calls for the above microservices. </p>&#xA;&#xA;<p>So, in Frontend app I will have some modules:&#xA;Login , MicroSrv1 , MicroSrv2 , ... etc</p>&#xA;&#xA;<p>Login GUI will use LoginApi. After logging I want to show MicroSrv1 GUI (connected to MicroSrv1 Api) , MicroSrv2 (to MicroSrv2 Api) , and so on. </p>&#xA;&#xA;<p>My idea is:</p>&#xA;&#xA;<ul>&#xA;<li>open LoginGUI  click Log in</li>&#xA;<li>call to LoginApi to authenticate in Azure AD (with using JWT) and download User data and also roles for the user and return to LoginGUI</li>&#xA;<li>after Authenthication I will go to next panel with MicroSrv1GUI, MicroSrv2GUI</li>&#xA;<li>and next calls to MicroSrv1 Api or MicroSrv2 Api should be Authorized (so also send token , maybe stored in cookie)</li>&#xA;</ul>&#xA;&#xA;<p>Is this a good practice? To have only one separate microservice to authentication? Or every microservice should have built-in their own?&#xA;How I can share authentication token between microservices and use only one Login Api app? Could you please provide me some examples?</p>&#xA;"
51425111,"Should services have ""events"" in a micro service architecture?",2018-07-19 14:22:01,<c#><design-patterns><architecture><microservices>,2,54,2,1.0,0,"<p>I was looking for some kind of best practice about something:&#xA;In our application, we have a LOT of services, and there is a lot of interaction between them.</p>&#xA;&#xA;<p>Some services would need to be able to notify that there has been change on their ends.&#xA;Our intuitive developer approach would be to just an event in it and register on it. But I've the feeling that this is something that is kind of ""dirty"".</p>&#xA;&#xA;<p>The service for me was something that was ""offered"" to the one requesting it, and was, but we should not be aware of the lifecycle of the service(nor should the service garbage collection of the service be prevent because somebody is still registered.</p>&#xA;&#xA;<p>My alternatives are:</p>&#xA;&#xA;<ul>&#xA;<li>ask to the service an object, on which I will register for event--> I don't find this much cleaner</li>&#xA;<li>Provide to the service an object implementing a CallBack interface, and have the service calling the callback instead of notifying events.</li>&#xA;<li>???</li>&#xA;</ul>&#xA;&#xA;<p>What do you think is the best practice on this? What would be the cleanest approach? </p>&#xA;"
51419192,Using microservices architecture in spring,2018-07-19 09:36:33,<spring-boot><microservices><spring-cloud-netflix>,3,47,3,0.0,0,"<p>I'm building a project which based on microservices architecture in spring boot.The project was divided multiple modules and I used maven dependency management.</p>&#xA;&#xA;<p>Now I want to use services from one module in other module. I have many spring applications. For example, I have 2 application which is named A and B. I want to use classes from A in B and classes of B in A. In this case I used maven dependencies but it is not completely way to using services in one another because I faced with circular dependency. </p>&#xA;&#xA;<p>What should do to use for solve this problem?</p>&#xA;"
51463258,Call some different restful services from front-end,2018-07-22 08:20:05,<domain-driven-design><microservices><dbcontext><restful-architecture>,1,56,3,0.0,0,"<p>Imagine I have an angular project as a front-end which communicates with some other projects which are restful services.</p>&#xA;&#xA;<p>In some pages I need to fetch some data from different restful services, &#xA;Is that okay to request any restful service individually in angular?&#xA;Or call one restful service which itself call other restful services in back-end?</p>&#xA;&#xA;<p>Or I have to call one restful service but add other entities to this DbContext which I need here just to query?</p>&#xA;"
51542629,Multiple Azure applications with version independent common micro-services on the same cluster,2018-07-26 15:34:42,<azure><microservices><azure-service-fabric><azure-deployment>,1,36,5,0.0,0,"<p>We have multiple Azure applications that use shared micro-services (Indexing, Indexing Management, etc) via git submodules.  We deployed the first application without any problems, but when attempted to deploy the second application the micro-services where not created in the application.</p>&#xA;&#xA;<p>As these micro-services are submodules they share the same ServiceManifest and have identical names and version numbers.  Currently both are at the same commit, but in the future they can be independent of each other.</p>&#xA;&#xA;<p>Is the shared name causing our deployment issues despite being in separate applications?</p>&#xA;"
51515839,Nodejs not able to connect to mongodb on cloud shell,2018-07-25 09:47:36,<node.js><mongodb><google-app-engine><google-cloud-platform><microservices>,3,163,7,0.0,0,"<p>My MongoDB server is hosted on google-cloud VM. I wish to create App Engine microservice. to test connectivity,  </p>&#xA;&#xA;<p>my server.js looks like </p>&#xA;&#xA;<pre><code>const MongoClient = require('mongodb').MongoClient;&#xA;const test = require('assert');&#xA;// Connection url&#xA;const url = 'mongodb://testmongodb:27017';&#xA;// Database Name&#xA;const dbName = 'test';&#xA;// Connect using MongoClient&#xA;MongoClient.connect(url, { useNewUrlParser: true },function(err, client) {&#xA;if(err){console.log(err)}&#xA;else {console.log(""Connected successfully"")}&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>it works perfectly if i connect via another vm. But does not work when trying to execute (npm start) the same code via <strong>Google Cloud Shell</strong>. I get the error </p>&#xA;&#xA;<pre><code>{ MongoNetworkError: failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]&#xA;    at Pool.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/topologies/server.js:562:11)&#xA;    at emitOne (events.js:116:13)&#xA;    at Pool.emit (events.js:211:7)&#xA;    at Connection.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/pool.js:316:12)&#xA;    at Object.onceWrapper (events.js:317:30)&#xA;    at emitTwo (events.js:126:13)&#xA;    at Connection.emit (events.js:214:7)&#xA;    at Socket.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/connection.js:245:50)&#xA;    at Object.onceWrapper (events.js:315:30)&#xA;    at emitOne (events.js:116:13)&#xA;  name: 'MongoNetworkError',&#xA;  message: 'failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]',&#xA;  errorLabels: [ 'TransientTransactionError' ],&#xA;  [Symbol(mongoErrorContextSymbol)]: {} }&#xA;</code></pre>&#xA;&#xA;<p>i get exactly the same error when deployed the service [gcloud app deploy]</p>&#xA;&#xA;<p>please help. </p>&#xA;"
44905869,Inter-pod communication in kubernetes,2017-07-04 12:21:50,<kubernetes><microservices><prometheus>,1,519,0,0.0,0,"<p>I had previously created a pod with three containers namely - <strong>prometheus</strong>, <strong>blackbox-exporter</strong> and <strong>python-access-api</strong>. The <strong>blackbox-exporter</strong> runs on port 9115 and scrapes the targets generated by <strong>python-access-api</strong> container which is alerted in the <strong>prometheus</strong> for SSL Expiry certificate of the targets. Now I want to move the <strong>blackbox- exporter</strong> to a different pod. I have tried to establish this via <em>service</em> but I am failing to establish the communication between <strong>prometheus</strong> and <strong>blackbox-exporter</strong> now, since they are in a different pod. And as a result of this, I am unable to make probe for    SSL Expiry certificate and hence, cannot see the alerts on <strong>prometheus</strong>. Below is the yaml file that I have used, can anyone please point out a way out of this problem. Please note that my configuration looks fine for prometheus and also the pods for blackbox and prometheus are running fine individually. Like I said above, I dont see they communicate with each other.</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: ReplicationController&#xA;metadata:&#xA;  name: blackbox-deployment&#xA;  labels:&#xA;    app: prometheus&#xA;spec:&#xA;  replicas: 1&#xA;  selector:&#xA;    app: blackbox&#xA;  template:&#xA;    metadata:&#xA;      name: blackbox&#xA;      labels:&#xA;        app: blackbox&#xA;    spec:&#xA;      containers:&#xA;      - name: blackbox&#xA;</code></pre>&#xA;&#xA;<p>Yaml file for Prometheus deployment</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: ReplicationController&#xA;metadata:&#xA;  name: python-daemon&#xA;  labels:&#xA;    app: prometheus-python&#xA;spec:&#xA;  replicas: 1&#xA;  selector:&#xA;    app: python&#xA;  template:&#xA;    metadata:&#xA;      name: python&#xA;      labels:&#xA;        app: python&#xA;    spec:&#xA;      containers:&#xA;</code></pre>&#xA;&#xA;<p>The service that I have deployed:-</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: prometheus&#xA;spec:&#xA;  selector:&#xA;    app: prometheus&#xA;  ports:&#xA;  - name: http&#xA;    port: 80&#xA;    targetPort: 9115&#xA;    protocol: TCP&#xA;</code></pre>&#xA;&#xA;<p>The prometheus config is as follows</p>&#xA;&#xA;<pre><code>- job_name: blackbox&#xA;  params:&#xA;    module:&#xA;    - http_2xx&#xA;  scrape_interval: 1m&#xA;  scrape_timeout: 10s&#xA;  metrics_path: /probe&#xA;  scheme: http&#xA;  file_sd_configs:&#xA;  - files:&#xA;    - /var/suhas/targets.yml&#xA;    refresh_interval: 5m&#xA;  relabel_configs:&#xA;  - source_labels: [__address__]&#xA;    separator: ;&#xA;    regex: (.*)&#xA;    target_label: __param_target&#xA;    replacement: $1&#xA;    action: replace&#xA;  - source_labels: [__param_target]&#xA;    separator: ;&#xA;    regex: (.*)&#xA;    target_label: instance&#xA;    replacement: $1&#xA;    action: replace&#xA;  - source_labels: []&#xA;    separator: ;&#xA;    regex: (.*)&#xA;    target_label: __address__&#xA;    replacement: prometheus:9115&#xA;    action: replace&#xA;</code></pre>&#xA;"
44998425,micro service design business and user RestAPI,2017-07-09 16:11:05,<rest><api><design-patterns><microservices>,1,271,0,0.0,0,"<p>We are trying to design use case where privilege user can create business (privilege use is business owner). Each Business can have multiple users. For addressing this requirement we are thinking to create three services UserAPI, BusinessAPI and SubscriptionAPI. UserAPI responsible for user creation, deletion, updating and find likewise business and subscription api will do similar operation.</p>&#xA;&#xA;<ul>&#xA;<li>/api/v1/users/</li>&#xA;<li>/api/v1/business /</li>&#xA;<li>/api/v1/subscription/</li>&#xA;</ul>&#xA;&#xA;<p>For the scenario where we want to create new user for business we are thinking of SubscriptionAPI to be used</p>&#xA;&#xA;<p>Steps as follow:</p>&#xA;&#xA;<ul>&#xA;<li>Is business exist â€œBusiness API clientâ€ will be used to check.</li>&#xA;<li>Is user already exist for given mobile number â€œuser API clientâ€ will be used to check.</li>&#xA;<li>If above to condition passed, â€œuser API clientâ€ will be called for user creation.</li>&#xA;<li>Above step will provide user id</li>&#xA;<li>New record in subscription table Subscription_id, business_id, user_id</li>&#xA;</ul>&#xA;&#xA;<p>Request</p>&#xA;&#xA;<ul>&#xA;<li>POST /api/v1/subscription/business/{id}</li>&#xA;<li>Request Body UserVO</li>&#xA;</ul>&#xA;&#xA;<p>UserVO is repeated in SubscriptionAPI â€“ Is this correct?</p>&#xA;&#xA;<p>Also please share view on described service designing, what improvement can be done.</p>&#xA;"
44923182,Would Docker swarm assist me with managing containers with specific environment variables?,2017-07-05 10:08:47,<docker><kubernetes><microservices><docker-swarm><orchestration>,1,73,0,0.0,0,"<p>Essentially I need to be able to start container with a specific environment variable (an account ID). And I need to run a multiple number of such containers (each with different account IDs). </p>&#xA;&#xA;<p>I'd need to be able to start additional containers, without having to stop the existing containers. I'd also need to be able to stop specific containers. So kind of like a dynamic docker-compose config.</p>&#xA;&#xA;<p>Is Docker swarm something that could assist with the above functionality? Are there other tools (Kubernetes maybe?) alternatively?</p>&#xA;&#xA;<p>Otherwise, if I handled this with the docker-cli, I would start the containers using <code>docker run</code> passing the relevant environment variable, I'd need to make sure that a container does not already exist with this environment variable and restart the container if it exists.</p>&#xA;"
44984823,Docker for Mac Container to Host Networking - Consul Health Checks Connection Refused,2017-07-08 09:51:21,<docker><microservices><consul><health-monitoring>,1,85,0,0.0,0,"<p>I have a HTTP health check in my service, exposed on <code>localhost:35000/health</code>. At the moment it always returns <code>200 OK</code>. The configuration for the health check is done programmatically via the HTTP API rather than with a service config, but in essence, it is:</p>&#xA;&#xA;<pre><code>set id: service-id&#xA;set name: health check&#xA;set notes: consul does a GET to '/health' every 30 seconds&#xA;set http: http://127.0.0.1:35000/health&#xA;set interval: 30s&#xA;</code></pre>&#xA;&#xA;<p>When I run consul in dev mode (<code>consul agent -dev -ui</code>) on my host machine directly the health check passes without any problem. However, when I run consul in a docker container, the health check fails with:</p>&#xA;&#xA;<pre><code>2017/07/08 09:33:28 [WARN] agent: http request failed 'http://127.0.0.1:35000/health': Get http://127.0.0.1:35000/health: dial tcp 127.0.0.1:35000: getsockopt: connection refused&#xA;</code></pre>&#xA;&#xA;<p>The docker container launches consul, as far as I am aware, in exaclty the same state as the host version:</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;  consul-dev:&#xA;    image: ""consul:latest""&#xA;    container_name: ""net-sci_discovery-service_consul-dev""&#xA;    hostname: ""consul-dev""&#xA;    ports:&#xA;      - ""8400:8400""&#xA;      - ""8500:8500""&#xA;      - ""8600:8600""&#xA;    volumes:&#xA;      - ./etc/consul.d:/etc/consul.d&#xA;    command: ""agent -dev -ui -client=0.0.0.0 -config-dir=/etc/consul.d""&#xA;</code></pre>&#xA;&#xA;<p>I'm guessing the problem is that consul is trying to do the GET request to the containers loopback interface rather than what I am intending, which is for the loopback interface of the host. Is that a correct assumption? More importantly, what do I need to do to correct the problem?</p>&#xA;"
44941218,`serverless deploy` command in azure does not complete no response received in terminal,2017-07-06 06:23:13,<node.js><azure><microservices><azure-functions><serverless-framework>,1,98,0,0.0,0,"<p>I am using <a href=""https://serverless.com/framework/docs/providers/azure/"" rel=""nofollow noreferrer"">serverless framework</a> with <a href=""https://azure.microsoft.com/en-in/services/functions/"" rel=""nofollow noreferrer"">azure functions</a> for microservices and installed all the dependencies and there are no errors but when i run <code>serverless deploy</code> command it produces a code </p>&#xA;&#xA;<pre><code>$ serverless deploy&#xA;Serverless: Packaging service...&#xA;Serverless: Logging in to Azure&#xA;Serverless: Paste this code (copied to your clipboard) into the launched browser, and complete the authentication process: HS******&#xA;</code></pre>&#xA;&#xA;<p>After that this <a href=""https://login.microsoftonline.com/common/oauth2/deviceauth"" rel=""nofollow noreferrer"">Microsoft Link</a> opens in the browser and ask for the code then i have put the code <code>HS******</code> that was received and it asks for login and after i login with my azure account it opens a new link displaying this message </p>&#xA;&#xA;<blockquote>&#xA;  <p>You have signed in to the Microsoft Azure Cross-platform Command Line Interface application on your device. You may now close this window.</p>&#xA;</blockquote>&#xA;&#xA;<p>After closing the window nothing happens in the terminal the terminal does nothing and it got stuck i have tried many times but no help.</p>&#xA;"
44965110,How to call other REST APIs from your node micro-service and send the result as a response?,2017-07-07 07:35:37,<node.js><backend><microservices><es6-promise><request-promise>,2,1166,0,0.0,0,"<p>I am currently trying to implement a BFF (backend for front end architecture).</p>&#xA;&#xA;<p>Using <code>request-promise</code> library I can successfully hit the other microservice but not able to return the result as a response from BFF microservice.</p>&#xA;&#xA;<p>Each time it is returning this result <code>Promise { pending }</code> pending state, could somebody please help me out on this?</p>&#xA;&#xA;<p>My main issue is to know how to receive data into BFF microservice from the other microservice that we are hitting and returning the result from microservice which is hitting other one.</p>&#xA;&#xA;<p>Or if somebody could help me to let know how to access the result from inside <code>.then</code> of any promise?</p>&#xA;&#xA;<p>The flow is like this:</p>&#xA;&#xA;<pre><code>client(ios/android)===(sends request)==&gt;BFF Microservice==&gt;BP microservice&#xA;</code></pre>&#xA;&#xA;<p>(BFF Microservice handles the request and returns the response on the basis of result received from other microservice)</p>&#xA;&#xA;<p>Microservice code which is calling another microservice:</p>&#xA;&#xA;<pre><code>import yagmodel from '../../lib/models/yag-model'&#xA;import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;import config from 'config'&#xA;&#xA;//template below to call the REST APIs of other microservices.&#xA;&#xA;export async function getAllBP (req,res) {&#xA;    let yagresponse// this varaible is defined to get data from inside(rs.then )&#xA;&#xA;    const username= req.swagger.params.username.value&#xA;    const authheader= req.swagger.params.Authorization.value&#xA;    console.log(""Authorization:""+authheader)&#xA;&#xA;    let rs= await yagmodel.bp(username,authheader)&#xA;    console.log(rs)&#xA;&#xA;    rs.then((response)=&gt;{&#xA;        // console.log(response.body)&#xA;        yagresponse=response.body&#xA;        //console.log(rsp)&#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;&#xA;    res.status(200).send(yagresponse) &#xA;}&#xA;</code></pre>&#xA;&#xA;<p><code>yag-model.js</code> code:</p>&#xA;&#xA;<pre><code>import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;&#xA;module.exports.bp = async function getBP(username,authheader){&#xA;    const options={&#xA;        uri: `http://localhost:4000/Health/BP/`+username,&#xA;        json: true,&#xA;        resolveWithFullResponse: true,&#xA;        headers: {&#xA;            'Content-Type': 'application/json; charset=utf-8',&#xA;            'Accept': 'application/json; charset=utf-8',&#xA;            'Authorization':authheader&#xA;        },&#xA;        method: 'GET'&#xA;    }&#xA;&#xA;    return request(options).then ((response)=&gt;{&#xA;        return response.body        &#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;}&#xA;</code></pre>&#xA;"
45058457,How to Auto Scale Microservices in Local server without cloud using JAVA,2017-07-12 13:03:10,<spring-boot><microservices><spring-boot-maven-plugin>,1,1697,0,0.0,0,"<p>Hi I am new to the microservices. I have created spring boot(maven) microservices (2 services, 1 gateway and service registry). How can I scale (auto scaling) 2 services without cloud technology. Is it possible in the local configuration? </p>&#xA;"
45052215,Check number of TCP connections to the server,2017-07-12 08:22:16,<java><linux><tcp><connection-pooling><microservices>,1,194,0,0.0,0,"<p>We have two application servers viz. s1 and s2. &#xA;For every request come to s1, it calls the services exposed by s2.&#xA;s1 is running port <code>8585</code> and s2 runnng on port <code>8989</code></p>&#xA;&#xA;<ul>&#xA;<li>We have implemented the Http connection pooling on the s1, so connections will be re-used while communicating with s2. For that we are using apache httpclient library and PoolingHttpClientConnectionManager for connection polling.</li>&#xA;<li>HttpClient intance is created only once at startup and shared while calling service exposed by s2.</li>&#xA;<li>While creating HttpClient, we have configured HttpClient max connection to 50</li>&#xA;</ul>&#xA;&#xA;<p><strong>how to check the connection polling is working correctly?</strong></p>&#xA;&#xA;<p>We have added 10 sec delay in s2, so every request is waiting for 10 sec to get the response.</p>&#xA;&#xA;<p>We are trying with Jmeter to generate 200 concurrent request to server s1 and following netstat command to check number of connections established by the server s1 to s2</p>&#xA;&#xA;<pre><code>while [ 1 ] ; do netstat -apnt | grep -E '8585.*ESTABLISHED' ;echo ""---"";sleep 3; done&#xA;</code></pre>&#xA;&#xA;<p>it gives random behavior. &#xA;Some times connection count shows 100, some times it shows 65 or any other number. </p>&#xA;"
44949367,"Microservices, Dependencies and Events",2017-07-06 12:49:22,<events><dependencies><microservices>,1,197,0,1.0,0,"<p>Iâ€™ve been doing a lot of googling regarding managing dependencies between microservices. Weâ€™re trying to move away from big monolithic app into micro-services in order to scale organizationally and be able to develop faster and with multiple teams working in parallel.&#xA;However, as weâ€™re trying to functionally partition the monolith into the microservices, we see how intertwined business logic and data really is. This was not a problem when we were sitting on top of one big DB and were able to do big relational joins. But with microservices, this becomes a problem.</p>&#xA;&#xA;<p>One solution is to make microservice-A go to 5-10 other microservices to get necessary data (this is equivalent of DB view with join). Another solution is to make microservice-A listen to events from 5-10 other services and populate local storage with relevant into (this is an equivalent of materialized view). Either way, microservice-A is coupled with 5-10 other services, and if new info is needed in microservice-A, the some of the services that it depends upon might will need to be release prior to microservice-A. Please note that microservice-A is itself depended upon by other services. Bottom line, we end up with DISTRIBUTED dependency hell.</p>&#xA;&#xA;<p>Many articles advocate for second solution â€“ i.e. something along the lines of Event Sourcing, Choreography, etc.</p>&#xA;&#xA;<p>I would appreciate any shared experiences, recommendations and insights.</p>&#xA;&#xA;<p>Philometor.</p>&#xA;"
44980176,Is Event Sourcing applicable for batch inputs?,2017-07-07 21:53:06,<apache-kafka><distributed-computing><microservices><event-sourcing>,2,244,0,0.0,0,"<p>I have a use case where the inputs to the application comes in batches of XML files. For example, a nightly batch of bank transactions. I am trying to see if I can use event sourcing to create a log of events. Based on what I read so far, the examples seems to be based on user driven input (click streams, updates from a user interface etc.,). Is event sourcing using a distributed log mechanism(like Kafka) a valid approach for batch/file based inputs? </p>&#xA;&#xA;<p>Below is the approach I would like to take:</p>&#xA;&#xA;<ol>&#xA;<li>Accept input as a batch in file/xml</li>&#xA;<li>Run some basic validations in the memory.</li>&#xA;<li>Convert the batch input into a series of events </li>&#xA;<li>Write the event log to a Kafka topic(s).</li>&#xA;<li>Use the event log to store the data into the database, send the events &#xA;to a search engine, update caches, run spark jobs to do aggregations &#xA;etc.,</li>&#xA;<li>Repeat the process for other incoming batches.  </li>&#xA;</ol>&#xA;&#xA;<p>If this approach is not efficient, what other options are available for distributed processing of such inputs? </p>&#xA;"
44996290,Best way to mapping dto/domain for transport between microservices,2017-07-09 12:16:30,<java><domain-driven-design><microservices><dto>,2,319,1,0.0,0,"<p>I have DTO and DOMAIN models:</p>&#xA;&#xA;<pre><code>@Data&#xA;public class CarDomain {&#xA;    private String name;&#xA;    private int year;&#xA;    private String color;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and</p>&#xA;&#xA;<pre><code>@Data&#xA;public class CarDto {&#xA;    private String name;&#xA;    private int year;&#xA;    private String color;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have 3 microservices(MS) communicate with each other through RabbitMq.&#xA;And I have <code>models module</code> with all DTO classes. Each MS include <code>models module</code>&#xA;in maven.</p>&#xA;&#xA;<p>1 MS send carDto 2 MS recive CarDto and convert to Domain. For this I can use Several variants:</p>&#xA;&#xA;<ol>&#xA;<li>use library for example <code>mapstruct</code>:</li>&#xA;</ol>&#xA;&#xA;<blockquote>&#xA;<pre><code>@Mapper&#xA;public interface CarMapper {&#xA;    CarMapper INSTANCE = Mappers.getMapper(CarMapper.class );&#xA;    CarDto carToCarDto(CarDomain car);&#xA;}&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>and use:</p>&#xA;&#xA;<pre><code>CarDto carDto = CarMapper.INSTANCE.carToCarDto(carDomain);&#xA;</code></pre>&#xA;&#xA;<ol start=""2"">&#xA;<li>Create manual mapper:</li>&#xA;</ol>&#xA;&#xA;<blockquote>&#xA;<pre><code>class CarMapper {&#xA;        public static CarDto toDto(CarDomain car) {&#xA;            CarDto carDto = new CarDto();&#xA;            carDto.setName(car.getName());&#xA;            carDto.setYear(car.getYear());&#xA;            carDto.setColor(car.getColor());&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>Now we use 2 variant. Becouse when we build microservice and in <code>models module</code> some field of DTO model change we get error on compile time. For example somebody change name this dto model in <code>models module</code></p>&#xA;&#xA;<pre><code>private String name; &#xA;</code></pre>&#xA;&#xA;<p>to </p>&#xA;&#xA;<pre><code>private String name1;&#xA;</code></pre>&#xA;&#xA;<p>When we build project we get error on this line:</p>&#xA;&#xA;<pre><code>carDto.setName(car.getName());// getName not found becose now getName1&#xA;</code></pre>&#xA;&#xA;<p>But this way hard. For each dto/domain models we need create mapper and write each field. In 1 variants it easier  but if dto change we get error on runtime.</p>&#xA;&#xA;<p>Tell me the best approach how to match/mapping models dto/domain?</p>&#xA;"
45088519,Connecting microservices with APIs,2017-07-13 18:33:02,<javascript><rest><api><microservices>,1,71,1,0.0,0,"<p>I am very new to the concept of both microservices and APIs. My only coding experience has been simple programs in a variety of languages. I am trying to understand microservices and REST APIs. I have done a lot of searching, but  can't seem to find a clear example of how to connect microservices with APIs to send and receive information between them. Can anybody at least lead me in the right direction? I know there are problem a ton of ways and different for every language, so here an example below. </p>&#xA;&#xA;<p>For example, pretend I have a simple javascript program with HTML and CSS for a simple UI. Let's assume I also have a seperate javascript program with no UI and all it does it calculate some numbers. How would I use an API to GET/POST two numbers to the calculator ""microservice"" and after calculating, that ""microservice"" would GET/POST that result back to the UI ""microservice""? Can I test this as just two javascript files locally on my laptop by just using localhost for the URL in the API/HTTP Request?</p>&#xA;&#xA;<p>NOTE: I put microservice in quotes because I realize that this is an extremely simplified example of a microservice. I also understand that my question doesn't contain any code or anything, so I apologize for that. I have researched for hours and can't seem to understand how to go about this. I really appreciate anybody's help!</p>&#xA;"
45056729,What are the core kubernetes Microservice components which Istio can replace?,2017-07-12 11:42:30,<ibm-cloud><kubernetes><microservices><netflix><istio>,1,140,1,0.0,0,"<p>We are planning to integrate a microservices platform which is running in Kubernetes and the architecture will be similar to the below reference architecture.</p>&#xA;&#xA;<p><a href=""https://www.ibm.com/devops/method/content/architecture/microservices/1_0"" rel=""nofollow noreferrer"">https://www.ibm.com/devops/method/content/architecture/microservices/1_0</a></p>&#xA;&#xA;<p>What are the core components which can be replaces by Istio on the above Kubernetes microservices architecture? </p>&#xA;&#xA;<p>I understand it can help in request routing, traffic management, policies and control.</p>&#xA;&#xA;<p>If I need to migrate one of the similar project what are the components which is available in Istio which can be replaced in Kubernetes or vice versa?</p>&#xA;"
45085790,"Spring cloud DiscoveryClient. getLocalServiceInstance() deprecated, how to use Registration?",2017-07-13 15:57:59,<java><spring><microservices><spring-cloud><auto-registration>,1,734,1,0.0,0,"<p>I have a requirement to get the current instance-id of the running microservice, the problem is that I have the requirement that if the process is not registered a ""random generated"" instance id has to be provided.</p>&#xA;&#xA;<p>I'm trying to get the service instance id from the DiscoveryClient but as the code points out the <code>getLocalServiceInstance</code> is deprecated and I can't use it.</p>&#xA;&#xA;<p>I tried to use the <code>Registration</code> as stated in the javadoc but coudn't find a way to get it initialized.</p>&#xA;&#xA;<p>Is there a conventional/specific way to get a service own registration?</p>&#xA;&#xA;<p>Btw, I cannot use a direct implementation because it is a starter that does not know what DiscoveryService implementation will be available at runtime.</p>&#xA;&#xA;<pre><code>/**&#xA; * @deprecated use the {@link org.springframework.cloud.client.serviceregistry.Registration} bean instead&#xA; *&#xA; * @return ServiceInstance with information used to register the local service&#xA; */&#xA;@Deprecated&#xA;ServiceInstance getLocalServiceInstance();&#xA;</code></pre>&#xA;"
44977364,How does Microservices in practice work?,2017-07-07 18:20:26,<web><architecture><microservices>,2,165,2,2.0,0,"<p>In theory I understand how Microservices work and why they can be helpful in various cases but I still donÂ´t get how it works in practice.</p>&#xA;&#xA;<p>LetÂ´s say thereÂ´s an online shop based on a CMS as a monolith application.</p>&#xA;&#xA;<p>And thereÂ´s now the need to run the online shop in a MIcroservices architecture. </p>&#xA;&#xA;<p>How would this Microservices architecture differ technically from the current, monolith, architecture?</p>&#xA;&#xA;<p>For example, I pick out the productsearch.php. If i want to scale this function, normally I had to set up a new server and copy the whole CMS ressources folder to it for loadbalancing. </p>&#xA;&#xA;<p>And with Microservices, productsearch.php would be a single Microservice I guess, and I would have to just copy this php file to scale without the need to copy other ressources?</p>&#xA;"
45031529,Create service instances with parameters in Service Fabric,2017-07-11 10:09:01,<c#><azure><microservices><azure-service-fabric><azure-iot-hub>,1,171,3,0.0,0,"<p>I'm using Service Fabric on Azure for a project at work where, put simply, I have a service whose function is to read data from IoT Hub.</p>&#xA;&#xA;<p>As it stands, that service is reading data from 32 partitions at the same time (multiple threads), but I'm trying to refactor it into one service intance per partition. The problem is I can't find a way to create 32 instances of a service and inform each instance of the Hub partition it should read (paramethers perhaps?).</p>&#xA;&#xA;<p>I can provide code samples if needed, but I feel the problem is pretty self-explanatory.</p>&#xA;"
45023334,How to efficiently handle spring boot microservices?,2017-07-10 23:55:58,<java><spring><spring-boot><dns><microservices>,2,192,4,0.0,0,"<p>I have bunch of spring boot microservices running in unique ports. How do we handle these microservices in production ?</p>&#xA;&#xA;<p>In production, we only need the DNS, how do we handle the DNS mapping.</p>&#xA;&#xA;<p>For ex:&#xA;<em>example-microservice-1 (port: 8001)<br>&#xA;example-microservice-2 (port: 8002)<br>&#xA;example-microservice-3(port: 8003)<br>&#xA;example-microservice-4 (port: 8004)<br>&#xA;example-microservice-5 (port: 8005)</em>  </p>&#xA;&#xA;<p>I would want something like below,<br>&#xA;<em>myprod.com/example-microservice-1<br>&#xA;myprod.com/example-microservice-2</em>   ...</p>&#xA;&#xA;<p>Instead of,<br>&#xA;<em>myprod:8001/example-microservice-1<br>&#xA;myprod:8002/example-microservice-2</em>  </p>&#xA;&#xA;<p>(removed ""https/http"" above due to less reputation) </p>&#xA;&#xA;<p>All the microservices exists in a different codebase and when build will create individual runnable jars.</p>&#xA;"
44936115,Authorization in microservice architecture,2017-07-05 21:15:11,<scope><authorization><microservices>,1,695,8,1.0,0,"<p>currently I develop a backend based on the microservice architecture.&#xA;Unfortunately, I have a problem how to realize the authorization.</p>&#xA;&#xA;<p>So let me explaine my system - there are the following services:</p>&#xA;&#xA;<ul>&#xA;<li>OAuth 2.0 Service (issuing JWT)</li>&#xA;<li>Group Service</li>&#xA;<li>Some Ressource Services (e.g. ToDos Service)</li>&#xA;</ul>&#xA;&#xA;<p>Every user is in one or many groups.&#xA;Each resource (like a ToDo list) also belongs to a group.&#xA;That means if some user creates a todo list, that list gets stored in the name of the group.</p>&#xA;&#xA;<p>Szenario:</p>&#xA;&#xA;<ul>&#xA;<li>User A is in group A</li>&#xA;<li>User B is in group A and B</li>&#xA;<li>User C is in group C</li>&#xA;<li>User A creats a ToDo list in group A.</li>&#xA;<li>User B modifies this ToDo list (he is allowed to do this since he is also in group A)</li>&#xA;<li>User C also tries to modify this ToDo list, but he shouldn't allowed to do this since he is only in group C.</li>&#xA;</ul>&#xA;&#xA;<p>Has any body a great idea how I could realize this in a microservice architecture and keep the dependencies between the services on a minimum?</p>&#xA;&#xA;<p>Certainly, I could ask on every request the Group Service if the user is in the group to which the resource belongs to. But so I get a really hard dependency between the Resource Services and the existence of a Group Service - I like to avoid this dependency.&#xA;Another option would be to store all groups, to which the user belongs to, in the access token. But with this option the client has to ask every time the OAuth Service for a new token when the user gets a member of a new group.</p>&#xA;&#xA;<p>So is there any other option how I could realize this szenario?</p>&#xA;"
42428045,Hypermedia response in a microservice architecture,2017-02-23 23:21:50,<spring-cloud><spring-data-rest><microservices><spring-cloud-netflix>,2,265,0,0.0,0,"<p>I've started the journey of learning more about this architecture using Spring Cloud and the Netflix's projects.</p>&#xA;&#xA;<p>From a general standpoint, I do understand the architecture but now that I'm actually coding an app, a horizon of doubts has appeared about some minimal stuff that could have a big impact in the big approach of this architecture.</p>&#xA;&#xA;<p>First, my app is based on this tutorial which I assume as valid since it's from Spring itself: <a href=""https://spring.io/blog/2015/07/14/microservices-with-spring"" rel=""nofollow noreferrer"">https://spring.io/blog/2015/07/14/microservices-with-spring</a></p>&#xA;&#xA;<p>And now, the problem: (ALL THIS USES EUREKA) let's say I've a microservice ""accounts"" which consist only in Spring Data REST for the persistence/HATEOAS and on top of that I've a client service which consumes those endpoints using RestTemplate (because I'm using Ribbon's load balancer). From my view, this is how it works: user -> frontend -> client service -> Spring Data REST endpoints (the microservice) -> DB.</p>&#xA;&#xA;<p>This is nice and all but when I get the endpoint response (from the RestTemplate), it contains hypermedia going directly to the microservice, and per se, you now can drive your way through the microservice while ignoring the load balancer, which, for me, kills the purpose of it. And if I've like 5 microservices scaling to each other, it means the user is now focusing into just one of a broad way of 5 microservice that are supposedly managed by load balancer.  </p>&#xA;&#xA;<p><strong>Q1:</strong>&#xA;Is ok for an user to have that knowledge of the API (and then kinda killing part of the structure)?</p>&#xA;&#xA;<p>Even if I add the links to the services detected by Eureka and delete the current endpoints to that microservice, those links aren't going to work and such means I'm chopping of the hypermedia links.</p>&#xA;&#xA;<p><strong>Q2:</strong>&#xA;Is there another approach to this? Through some kind of proxy, external load balancer, dns or something like that?</p>&#xA;&#xA;<p>P.D: I don't know if I'm being clear enough. Please let me know if something is misty.</p>&#xA;&#xA;<p>P.D.2: <strong>Summary question:</strong> what to do with those media links? Let them be or use something else (please tell) to actually get them ""right""?</p>&#xA;&#xA;<p><strong>Edit:</strong> Based on the advices below, I added Zuul which seems to be the solution to my problem. Now, about Zuul, where should I use to filter? </p>&#xA;&#xA;<p>My app is like this right now: account-microservice (Spring Data REST) and account-web-service (client with the RestTemplate Load balancer). Those are the Eureka registered names.</p>&#xA;&#xA;<p>Where must go the @EnabledZuulProxy? Inside the microservice or inside the client?</p>&#xA;&#xA;<p>My current config is this one (currently, the @EnabledZuulProxy is in the client):</p>&#xA;&#xA;<p>My microservice:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaClient&#xA;public class AccountServer {&#xA;&#xA;    public static void main(String[] args) {&#xA;        System.setProperty(""spring.config.name"", ""AccountServerClient"");&#xA;        SpringApplication.run(AccountServer.class, args);&#xA;    }&#xA; }&#xA;&#xA; //Config:&#xA; spring.application.name=account-microservice&#xA; spring.application.freemarker.enabled=false&#xA; eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/&#xA; eureka.client.instance.leaseRenewalIntervalInSeconds=5&#xA;</code></pre>&#xA;&#xA;<p>My client:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaClient&#xA;@EnableZuulProxy&#xA;@EnableCircuitBreaker&#xA;public class AccountMicroService {&#xA;&#xA;    public static void main(String[] args) {&#xA;        // Tell server to look for registration.properties or registration.yml&#xA;        System.setProperty(""spring.config.name"", ""AccountMicroServiceClient"");&#xA;        SpringApplication.run(AccountMicroService.class, args);&#xA;    }&#xA; }&#xA;&#xA; //Config&#xA; # Spring properties&#xA; spring.application.name=account-web-service&#xA; spring.freemarker.enabled=false&#xA; eureka.instance.leaseRenewalIntervalInSeconds: 5&#xA; eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/&#xA; zuul.routes.account-web-service.path=/accounts/**&#xA; zuul.routes.account-web-service.serviceId=account-web-service&#xA; zuul.routes.account-web-service.stripPrefix=false&#xA;</code></pre>&#xA;&#xA;<p>Client code to consume SDR:</p>&#xA;&#xA;<pre><code>//@HystrixCommand(fallbackMethod=""test"")&#xA;public ResponseEntity&lt;PagedResources&lt;AccountResource&gt;&gt; findAll(Pageable pageable) throws RestClientException, URISyntaxException {&#xA;&#xA;    return restTemplate.exchange(serviceUrl + ""/accounts"" + ""?page={page}&amp;size={size}&amp;sort={sort}"", HttpMethod.GET,&#xA;            null, new ParameterizedTypeReference&lt;PagedResources&lt;AccountResource&gt;&gt;() {&#xA;            }, pageable.getPageNumber(), pageable.getPageSize(), pageable.getSort());&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Like this, it doesn't work at all. No filtering neither. If I change that and use it in the microservice, then it keeps sending everything directed to the microservice to the client, even the request from the client, which ends up with a loop and then an error (timeout, load balancer full, circuit broken...) which is generally this though: <strong>com.netflix.zuul.exception.ZuulException: Forwarding error.</strong></p>&#xA;&#xA;<p><strong>Edit 2:</strong> I finally got Zuul to work and understood what it does. Now, when I access my new gateway app, it forwards the request to my microservice and the resulting hypermedia is now pointing to that gateway, which is what I wanted.</p>&#xA;&#xA;<p>The problem was initially architectural and then turned into a coding problem, but now I think am clear about this technologies.</p>&#xA;&#xA;<p>The cup of tea was understanding what Zuul does, when and how it does it. @Ryan Baxter guideline and this two articles: <a href=""https://dzone.com/articles/microservice-architecture-with-spring-cloud-and-do"" rel=""nofollow noreferrer"">https://dzone.com/articles/microservice-architecture-with-spring-cloud-and-do</a> and <a href=""https://spring.io/guides/gs/routing-and-filtering/"" rel=""nofollow noreferrer"">https://spring.io/guides/gs/routing-and-filtering/</a> where fundamentals to get this done. I'm gonna redact an answer for this with what I did and what I understood.</p>&#xA;"
42449160,Architecture for communication between two microservices,2017-02-24 22:12:42,<java><architecture><communication><jhipster><microservices>,1,281,0,0.0,0,"<p>First of all, I'm using JHipster 4.0.x for my project. I'm using microservices architecture.</p>&#xA;&#xA;<p>For this example, I've got one gateway, one microservice for ""Store"" and a second one for ""Skill"".&#xA;I want to centralise all Stores in one database and Skills in a second one.</p>&#xA;&#xA;<p>Each one is a data repository that will not evolve at the same speed. On the other hand, they will be the central point of my infrastructure in order to update, via an ESB, the other software.</p>&#xA;&#xA;<p>Jhipster is great for that, I've got easily my CRUD for each service.</p>&#xA;&#xA;<p>The tricky point is a Store is defined by a Skill. The simplest way would be to say that I only do one service with ""Skill"" and ""Store"". But I can't do that because ""Skill"" must also be a central point for other data.</p>&#xA;&#xA;<p>I imagined this Entity's architecture </p>&#xA;&#xA;<p>[SKILL]</p>&#xA;&#xA;<p>[STORE]----many-to-one----[LINK_WITH_OTHER_ENTITIES]</p>&#xA;&#xA;<p>(with *.json generate by jhipster):</p>&#xA;&#xA;<ul>&#xA;<li><p>on Skill Service : </p>&#xA;&#xA;<ul>&#xA;<li>an entity Skill</li>&#xA;</ul>&#xA;&#xA;<p><code>{&#xA;""fluentMethods"": true,&#xA;""relationships"": [],&#xA;""fields"": [&#xA;    {&#xA;        ""fieldName"": ""code"",&#xA;        ""fieldType"": ""String""&#xA;    },&#xA;    {&#xA;        ""fieldName"": ""libelle"",&#xA;        ""fieldType"": ""String""&#xA;    }&#xA;],&#xA;""changelogDate"": ""20161201084915"",&#xA;""dto"": ""no"",&#xA;""service"": ""no"",&#xA;""entityTableName"": ""filiere_metier"",&#xA;""pagination"": ""no"",&#xA;""microserviceName"": ""metiers"",&#xA;""searchEngine"": ""elasticsearch""&#xA;}</code></p></li>&#xA;<li><p>on Store Service : </p>&#xA;&#xA;<ul>&#xA;<li>an entity Store </li>&#xA;</ul>&#xA;&#xA;<p><code>{&#xA;    ""fluentMethods"": true,&#xA;    ""relationships"": [&#xA;        {&#xA;            ""relationshipName"": ""categorie_metier"",&#xA;            ""otherEntityName"": ""pont_msvc"",&#xA;            ""relationshipType"": ""many-to-one"",&#xA;            ""otherEntityField"": ""id""&#xA;        }&#xA;    ],&#xA;    ""fields"": [&#xA;        {&#xA;            ""fieldName"": ""code"",&#xA;            ""fieldType"": ""String""&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""lib"",&#xA;            ""fieldType"": ""String""&#xA;        }&#xA;    ],&#xA;    ""changelogDate"": ""20161125141916"",&#xA;    ""dto"": ""no"",&#xA;    ""service"": ""no"",&#xA;    ""entityTableName"": ""store"",&#xA;    ""pagination"": ""no"",&#xA;    ""microserviceName"": ""store"",&#xA;    ""searchEngine"": ""elasticsearch""&#xA;}</code></p>&#xA;&#xA;<ul>&#xA;<li>an Entity to make a link with Skill</li>&#xA;</ul>&#xA;&#xA;<p><code>{&#xA;    ""fluentMethods"": true,&#xA;    ""relationships"": [],&#xA;    ""fields"": [&#xA;        {&#xA;            ""fieldName"": ""idext"",&#xA;            ""fieldType"": ""String""&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""msvcName"",&#xA;            ""fieldType"": ""MicroServices"",&#xA;            ""fieldValues"": ""gw,metier""&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""msvcEntityName"",&#xA;            ""fieldType"": ""String""&#xA;        }&#xA;    ],&#xA;    ""changelogDate"": ""20161208100401"",&#xA;    ""dto"": ""no"",&#xA;    ""service"": ""no"",&#xA;    ""entityTableName"": ""pont_msvc"",&#xA;    ""pagination"": ""no"",&#xA;    ""microserviceName"": ""store"",&#xA;    ""searchEngine"": ""elasticsearch""&#xA;}</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Then When I'll CRUD on Store I'll use CRUD from Skill too, thanks <a href=""http://stytex.de/blog/2016/03/25/jhipster3-microservice-tutorial/"" rel=""nofollow noreferrer"">this article</a> but this point is an another story.</p>&#xA;&#xA;<p>What do you think? Is this the right way?</p>&#xA;"
42546246,how to do network isolation among different applications in kubernetes or in docker cluster?,2017-03-02 03:23:58,<docker><kubernetes><microservices>,2,45,0,0.0,0,"<p>We're building a platform based on microservices which managed by k8s, each user could build application based on different microservices.&#xA;how to do isolation for different applications to avoid harm effective between them, is the network isolation ok or any better solution ?</p>&#xA;"
42595302,Microservice granularity: Per domain model or not?,2017-03-04 11:13:39,<web-services><rest><microservices>,1,392,0,1.0,0,"<p>When building a microservice oriented application, i wonder what could be the appropriate microservice granularity.</p>&#xA;&#xA;<p>Let's image an application consisting of:</p>&#xA;&#xA;<ul>&#xA;<li><p>A set of various resources types where each resource map a given business model. <em>(ex: In a todo app resources could be User, TodoList and TodoItem...)</em></p></li>&#xA;<li><p>Each of those resources are saved within a NoSQL database that could be replicated.</p></li>&#xA;<li><p>Each of those resources are exposed through a REST Api</p></li>&#xA;<li><p>The application manage an internal chat room.</p></li>&#xA;<li><p>An Api gateway for gathering chat room and REST api interaction.</p></li>&#xA;<li><p>The application front end: an SPA application connected to the API Gateway</p></li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>The first (and naive) approach when thinking about how microservices could match the need of this application would be:</p>&#xA;&#xA;<ol>&#xA;<li><strong>One monolith service for managing EVERY resources and business logic</strong>:&#xA;<em>By managing i mean providing the REST API for all of those resources and handling the persistance of those resources within the database.</em></li>&#xA;<li>One service for each Database replica.</li>&#xA;<li>One service providing the internal chat room using websocket or whatever.</li>&#xA;<li>One service for Authentification.</li>&#xA;<li>One service for the api gateway.</li>&#xA;<li>One service serving the static assets for the SPA front end.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>An other approach could be to split service 1 into as many service as business models exist in the system.</strong> (let's call those services <em>resource services</em>)</p>&#xA;&#xA;<p>I wonder what are the benefit of this second approach.&#xA;In fact i see a lot of downsides with this approach:</p>&#xA;&#xA;<ul>&#xA;<li>Need to setup an inter service communication process.</li>&#xA;<li>When requesting a service representing resource X that have a relation with resource Y, a lot more work are needed (i.e: interservice request)</li>&#xA;<li>More devops work.</li>&#xA;<li>More difficulty to share common code between <em>resource services</em>.</li>&#xA;<li>Where to put business logic ?</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>When starting a fresh project this second approach seams to me a bit of an over engineered work.</p>&#xA;&#xA;<p>I feel like starting with the first approach and THEN split the monolith resource service into several specific services depending on the observed needs will minimize the complexity and risks.</p>&#xA;&#xA;<p>What's your opinions regarding that ?&#xA;Is there any best practices ?</p>&#xA;&#xA;<p>Thanks a lot !</p>&#xA;"
42395345,Service fabric reliable collections data loss after service upgrade,2017-02-22 15:13:29,<.net><azure><microservices><azure-service-fabric><service-fabric-stateful>,1,395,0,2.0,0,"<p>Why reliable collections is empty after micro-service upgrade and not invoking event OnDataLossAsync to restore state from external backup?</p>&#xA;&#xA;<p>We have large scale system based on stateful services</p>&#xA;&#xA;<pre><code>&lt;StatefulServiceType ServiceTypeName=""UserServiceType"" HasPersistedState=""true"" /&gt;&#xA;</code></pre>&#xA;&#xA;<p>HasPersistedState is set as true, and data replicated across replicas, in case of VM failure data still valid and recovering with OnDataLossAsync but after upgrade collections is empty.</p>&#xA;&#xA;<p>I have tried all upgrade options (remove, keep, auto ugrade) application, result the same - collections is empty.</p>&#xA;&#xA;<p>For now we decided to replicate data to blob storage and recover it after service update which is not perfect solution, data recovery takes a few minutes and it makes some service unavailable/inconsistent for that time.</p>&#xA;&#xA;<p>So we are looking for solution that allows to save data after upgrade.</p>&#xA;"
42392301,Cross-Origin in JHipster's microservices,2017-02-22 13:04:11,<spring-security><jhipster><microservices>,1,226,0,0.0,0,"<p>I've created Microservices using Jhipster. The security mechanism is ""UAA"". the problem is a Cross-origin issue prevents loging in and communicating with uaa server. </p>&#xA;&#xA;<p>The below message I got from chrome browser: </p>&#xA;&#xA;<blockquote>&#xA;  <p>XMLHttpRequest cannot load <a href=""http://192.168.1.136:9999/login"" rel=""nofollow noreferrer"">http://192.168.1.136:9999/login</a>. No&#xA;  'Access-Control-Allow-Origin' header is present on the requested&#xA;  resource. Origin '<a href=""http://192.168.1.136:8080"" rel=""nofollow noreferrer"">http://192.168.1.136:8080</a>' is therefore not allowed&#xA;  access.</p>&#xA;</blockquote>&#xA;&#xA;<p>Where Gateway is on port 8080 and UAA is on port 9999. </p>&#xA;&#xA;<p>How to resolve Cross-Origin issue in Microservices Architecture? </p>&#xA;&#xA;<p>Could you help, please..</p>&#xA;"
42458964,logback settings and spring config-server,2017-02-25 17:03:42,<java><spring><spring-boot><cloud><microservices>,1,1272,0,0.0,0,"<p>There are many of microservices, all of them should write logs to  the same graylog server. In every of microservices is used a GelfLogbackAppender which has several settings like host, post and etc. These setting are the same for all of services and i want to store them in one place like a spring config-server. How can i do that? How can i get and use GELF_ADDRESS from config-server?</p>&#xA;&#xA;<pre><code>&lt;appender name=""gelf"" class=""biz.paluch.logging.gelf.logback.GelfLogbackAppender""&gt;&#xA;    &lt;host&gt;udp:${GELF_ADDRESS}&lt;/host&gt;&#xA;    &lt;port&gt;${GELF_PORT}&lt;/port&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>UPDATE</strong> I've decided to show simple example what i want to, let's imagine i want to change log level for all microservices through config-server. i make next things:</p>&#xA;&#xA;<p><strong>logback-spring.xml</strong></p>&#xA;&#xA;<pre><code>&lt;configuration&gt;&#xA;    &lt;property name=""LEVEL"" value=""${log_level}""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/defaults.xml""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/console-appender.xml""/&gt;&#xA;    &lt;root level=""${LEVEL}""&gt;&#xA;         &lt;appender-ref ref=""CONSOLE""/&gt;&#xA;    &lt;/root&gt;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong> is being in config-server</p>&#xA;&#xA;<pre><code>eureka:&#xA;  client:....&#xA;feign:&#xA;  hystrix:....&#xA;log_level: info&#xA;</code></pre>&#xA;&#xA;<p>it doesn't work, i always see DEBUG level, if i write</p>&#xA;&#xA;<pre><code>&lt;property name=""LEVEL"" value=""info""/&gt; &#xA;</code></pre>&#xA;&#xA;<p>manualy into  logback-spring.xml, the level will be changed, but i want to do that through central config-serverer</p>&#xA;"
42571279,Spring Boot micro services- Handling impacting changes from other microservice,2017-03-03 05:23:46,<spring><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,94,1,0.0,0,"<p>I just want to brief about what I am trying to do before asking question</p>&#xA;&#xA;<p>I am trying to build microservices using spring boot - where in I need to use many Spring Cloud Netflix features such as Service Discovery (Eureka), Circuit Breaker (Hystrix), Intelligent Routing (Zuul) and Client Side Load Balancing (Ribbon) etc - I'm planning to use docker containers to deploy and manage using tools like docker compose,docker swarm (or kubernetes).</p>&#xA;&#xA;<p>With this configuration - we have 3 microservices(let's assume ) , service A , service B and service C ,these are independent micro services developed by different developers ,assuming these developers are not in sync ,developer1 commits some changes to service A ,which might break functionality of other 2 services B and C (these are calling  service A for some purpose ), but services B and C are not aware of changes made in service A . **How to efficiently handle possible situations like this ? ** - thanks in advance</p>&#xA;"
42397788,Does my default app have to be deployed to appspot.com?,2017-02-22 17:00:33,<python><google-app-engine><google-cloud-platform><microservices>,2,110,1,0.0,0,"<p>I asked a question about the default app as it related to microservices on app engine and got a great response <a href=""https://stackoverflow.com/questions/42360790/why-do-i-need-to-deploy-a-default-app-before-i-can-deploy-multiple-services-in"">here</a>, but I have another question relating to this.</p>&#xA;&#xA;<p>Does my default app have to be accessible via appspot.com? when i run the deploy command thats where it puts it, but I'd rather have it not accessible like that. I really just want a semi-empty (like hello world sized) app that satisfies the default app requirement.</p>&#xA;&#xA;<p>It does seem like google is shoehorning multi-app/microservices into an environment that was originally setup to only serve a single web facing app backed by other modules. It seems very ungraceful and hacky. </p>&#xA;"
42400613,Azure Service Fabric register COM component,2017-02-22 19:31:20,<azure><com><microservices><azure-service-fabric>,2,147,1,0.0,0,"<p>We want to deploy a ASP.NET WebApi service to Azure Service Fabric. <br>&#xA;The service uses a mathematical COM component (32bit) that will be registered on a regular machine with regsvr32.<p>&#xA;The solution works perfectly on a local Service Fabric cluster (e.g Windows Server 2012 R2).&#xA;Unfortunately there is no managed dll available for that component and we do not want to rewrite the code all by ourselves.&#xA;</p></p>&#xA;&#xA;<p>&#xA;So my question is, can we deploy this service to an Azure hosted Service Fabric? <br>&#xA;And if yes, how?&#xA;</p>&#xA;"
42519116,How to use VSTS Build/Release to continuously integrate/deploy Docker containers to Azure Service Fabric?,2017-02-28 21:32:02,<docker><microservices><azure-service-fabric><vsts-build><vsts-release>,1,465,1,0.0,0,"<p>I'm asking this question here because Azure's documentation says a sample for Linux Containers is '<a href=""https://azure.microsoft.com/en-us/resources/samples/service-fabric-dotnet-containers"" rel=""nofollow noreferrer"">coming soon</a>'. Anyone has any insight on when this tutorial might be available?</p>&#xA;&#xA;<p>Meanwhile, I'm hoping someone can shed some light on how to effectively do this. &#xA;My use case is:</p>&#xA;&#xA;<ul>&#xA;<li><p>a microservices based application (say Microservices A, B, and C); each microservice should run in its own Docker container</p></li>&#xA;<li><p>use Visual Studio Team Services Build capability to build container images and push them to Docker Hub</p></li>&#xA;<li><p>use VSTS Release capability to <strong>individually</strong> deploy the microservices (containers) to a Service Fabric cluster as microservices are <strong>independently</strong> developed, that is, I don't want to update the entire application in Service Fabric, but only redeploy the changed microservice/container to the respective node(s)</p></li>&#xA;</ul>&#xA;&#xA;<p>There could be a custom solution for this where one can add Tasks to the Build and Release in VSTS (like Docker Build and Shell Script tasks), call some scripts to update the Application Manifest and Service Manifest to kick off the updates to the Service Fabric cluster, and so on.</p>&#xA;"
42462663,Microservice depends on other one to do anything,2017-02-25 23:02:54,<dependencies><microservices><relationships>,1,316,3,0.0,0,"<p>At the moment I deal with micro-services and ran into a few questions (regarding relations between services), I have a hard time to find a good answer/best practices for. It would be really great if you could give me a hint or an advice how you would handle this.</p>&#xA;&#xA;<p>Because these question are not directed to a specific project, I try to make it as clear as possible with the following example:</p>&#xA;&#xA;<p>Letâ€˜s assume you want to build some kind of Youtube channel observer, that logs different kinds of channelâ€˜s (meta-)data (videos, hourly views/sub count, currently subscribed to), that are imported in a specific time interval.</p>&#xA;&#xA;<p>So there are two major features the app has to offer, which should form a microservice each:</p>&#xA;&#xA;<ul>&#xA;<li>Add/remove channels to be watched (=> manager service)</li>&#xA;<li>import information (=> import service)</li>&#xA;</ul>&#xA;&#xA;<p>Both services provide an API to communicate with each other.</p>&#xA;&#xA;<p>The manager service is connected to a database which contains the channels that need to be watched, with their basic information (name, contact, ...) and the channels these observed channels are currently subscribed to, whereas the import service has a database containing all the other more time-series oriented information (videos, hourly views/sub count).</p>&#xA;&#xA;<p>To add a channel only the channel url has to specified. All the other information (name, contact, ...) are added by the import service (but can also be modified by the user).</p>&#xA;&#xA;<p>All in all the import service is totally useless without the information of the manager service, but also the manager service can only show the user specified channel information (worst case: only channel url) if no import service is available. In total: they depend heavily on each other.</p>&#xA;&#xA;<p>So much for the general architecture. </p>&#xA;&#xA;<p>The problem I have here is, that the import service depends on the data in the manager service database to such a great degree and also modifies it:</p>&#xA;&#xA;<ol>&#xA;<li>Would it be a good idea to share the manager service database between these two services or should it only be accessible by the provided API?</li>&#xA;<li>No matter if database is shared or not: both services need model classes for the channel. Is it fine to share those? </li>&#xA;<li>Is this architecture even a good idea at all (if we assume that there are also other services that need the basic channel information)? </li>&#xA;</ol>&#xA;"
42611968,"I have multiple flask microservices that all communicate with each other, how would I configure docker?",2017-03-05 18:02:18,<python><docker><flask><dockerfile><microservices>,1,480,6,0.0,0,<p>I have multiple flask microservices (this is obviously obfuscated to protect IP)</p>&#xA;&#xA;<pre><code>â”œâ”€â”€ README.md&#xA;â”œâ”€â”€ api_starter.py&#xA;â”œâ”€â”€ app_api.py&#xA;â”œâ”€â”€ service1&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â””â”€â”€ service1.py&#xA;â”œâ”€â”€ service2&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â”œâ”€â”€ service2.py&#xA;â”œâ”€â”€ dags&#xA;â”‚Â Â  â”œâ”€â”€ airflow_pipeline_runner.py&#xA;â”œâ”€â”€ service3&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â”œâ”€â”€ service3.py&#xA;â”œâ”€â”€ service4&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â””â”€â”€ service4.py&#xA;â”œâ”€â”€ service5&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â””â”€â”€ service5.py&#xA;â”œâ”€â”€ service6&#xA;â”‚Â Â  â”œâ”€â”€ __init__.py&#xA;â”‚Â Â  â”œâ”€â”€ api.py&#xA;â”‚Â Â  â””â”€â”€ service6.py&#xA;â”œâ”€â”€ requirements.txt&#xA;â””â”€â”€ service7&#xA;    â”œâ”€â”€ __init__.py&#xA;    â”œâ”€â”€ api.py&#xA;    â””â”€â”€ service7.py&#xA;</code></pre>&#xA;&#xA;<p>Each one of these microservices are being run by the api_starter. Each of these microservices communicate with each other. What's the best way to dockerize this application? Do I give each microservice a docker file and then have a docker-compose.yml in the root of the directory? Each of these microservices communicate with each other. Any and all </p>&#xA;
47133571,Guzzle ServerException resulted in a `500 Internal Server Error` response,2017-11-06 09:25:47,<php><laravel-5><microservices><guzzle><lumen>,1,1045,0,2.0,0,"<p>I'm trying to implement a MicroService Architecture Using Lumen and laravel </p>&#xA;&#xA;<p>I'm using laravel 5.4 as an ApiGetway and using Lumen 5.4 as a microService</p>&#xA;&#xA;<p>the thing here i'm using GuzzleHTTP version 6.3 in my laravel project, trying to hit the microService API, but i'm getting 500 Internal Server Error</p>&#xA;&#xA;<p>I'm trying this in my localhost </p>&#xA;&#xA;<p>This is how i'm making requests:</p>&#xA;&#xA;<pre><code>public function get_posts(){&#xA;    try {&#xA;&#xA;       $client = new Client(); //GuzzleHttp\Client&#xA;       $res = $client-&gt;request('GET', 'http://localhost/micro/posts_micro_service/public/posts');&#xA;         if($res-&gt;getStatusCode() == ""200""){&#xA;             echo $res-&gt;getBody();&#xA;         }else{&#xA;             return response()-&gt;json(['status',""error""]);&#xA;         }&#xA;     } catch (ClientException $e) {&#xA;            echo Psr7\str($e-&gt;getRequest());&#xA;            echo Psr7\str($e-&gt;getResponse());&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm getting this error :</p>&#xA;&#xA;<pre><code> (1/1) ServerException&#xA;Server error: `GET http://localhost/micro/posts_micro_service/public/posts` resulted in a `500 Internal Server Error` response:&#xA;&lt;!DOCTYPE html&gt;&#xA;&lt;html&gt;&#xA;&lt;head&gt;&#xA;&lt;meta name=""robots"" content=""noindex,nofollow"" /&gt;&#xA;&lt;style&gt;&#xA;(truncated...)&#xA;in RequestException.php (line 113)&#xA;</code></pre>&#xA;"
47269095,Working with Spring FeignClient with fallback behavior,2017-11-13 16:29:27,<spring><microservices><netflix-feign><spring-cloud-feign><feign>,1,281,0,0.0,0,"<p>I got a problem to solve with Spring FeignClient.</p>&#xA;&#xA;<p>I have two endpoints to send an SMS, both are the same behavior:</p>&#xA;&#xA;<ul>&#xA;<li>When I send a GET with all query parameters required, the service sends the SMS. </li>&#xA;<li>But I need to check if endpoint A is off â€“ in which case I must send to endpoint B, both with the same request path and payload.</li>&#xA;</ul>&#xA;&#xA;<p>How can I solve this problem?</p>&#xA;&#xA;<p>Today I have an interface with FeignClient annotation and just one URL.<br>&#xA;I tried to make use a FeignBuilder to create the request in runtime and change the URL but without success.</p>&#xA;&#xA;<p>How can I use Feign to control service fallback in client side, like:</p>&#xA;&#xA;<pre><code>@Value(${sms.urls})&#xA;List&lt;String&gt; endPoints;&#xA;&#xA;for (endPoint : endPoints){&#xA;  if(endPoint.isUp())&#xA;  return makeRequest(endPoint).&#xA;}&#xA;</code></pre>&#xA;"
47236551,Remote persistent views with Lagom,2017-11-11 09:51:04,<microservices><lagom>,1,55,0,0.0,0,"<p>In a classical microservice architecture, you have relevant domain events published on some messaging system which allows other parts of the system to react.</p>&#xA;&#xA;<p>Now imagine you have three microservices: <em>Customers, Orders and Recommendation</em>. The <em>Recommendation</em> microservice needs information from <em>Customers</em> and <em>Orders</em> to provide its functionality, such as the list of all customers and all the orders, which is going to be analyzed from some machine learning algorithm. <strong>Now, you need to have the state of Customers ""join"" Orders on the Recommandation microservice:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>You have the Recommandation microservice listen to domain events published by Customers and Orders and built its own state. This leads to logic duplication since you probably have that same logic inside Customers and Orders already</p></li>&#xA;<li><p>On each relevant domain message from Customers and Orders, you just go to them and ask the state of a specific customer or order. This works fine, however if you have N services rather than just one which needs to build a materialized view, you will cause a big load on Customers and Orders</p></li>&#xA;<li><p>You get Customers and Orders themselves publish ""heavy-weight"" events (not domain events) that allows any other microservice to build a materialized view without processing domain events. This allows you both a) not to duplicate the logic b) not to keep asking the same information</p></li>&#xA;</ol>&#xA;&#xA;<p>Has pattern n.3 some drawbacks we couldn't figure out and if not, how do you implement it in Lagom?</p>&#xA;"
47318596,Can spring Sleuth be used with Scala?,2017-11-15 22:43:04,<scala><microservices><tracing><zipkin><spring-cloud-sleuth>,1,59,0,0.0,0,"<p>I'm developing event-driven Microservices which I use Java and Scala. I used Spring Sleuth and Zipkin for request tracing with Java services, can I use Spring Sleuth with Scala? if not how can I generate trace id and span id in Scala to be sent to Zipkin. </p>&#xA;"
47129599,Does AppDynamics log request and response,2017-11-06 04:07:26,<microservices><zipkin><appdynamics><apm><opentracing>,1,65,0,0.0,0,"<p>Can AppDynamics show the request or response being exchanged between different microservices systems. They show the call trace, but couldnt find the details of what is passing between the calls.</p>&#xA;"
47312403,Inject external dependency Spring microservices,2017-11-15 16:20:44,<java><spring-boot><jar><log4j2><microservices>,1,68,0,0.0,0,"<p>We are using spring boot microservices in our product , we are having up to 10 applications . In order to log we use Log4j MDC to generate transaction id and pass it along the services [http headers] using interceptors and filters and its working fine.&#xA;The problem is we have to add interceptors and filters in all our applications (say 10) to track this transaction.Is there any way like creating jar and inject in our microservice applications.</p>&#xA;&#xA;<p>Can we achieve this using with minimal code changes in all our application ?</p>&#xA;"
47324184,How to add an API with oauth2 on the top of Kong,2017-11-16 07:47:32,<php><oauth-2.0><authorization><microservices><kong>,1,343,0,0.0,0,"<p>I'm trying to add an API on the top kong with using oauth2 authorization plugin of Kong. The steps &#xA;I have followed as per their <a href=""https://getkong.org/plugins/oauth2-authentication/"" rel=""nofollow noreferrer"">Kong documentation</a> :</p>&#xA;&#xA;<ul>&#xA;<li>Create an API and add oauth2 plugin</li>&#xA;<li>Create consumer </li>&#xA;<li>Create an application</li>&#xA;</ul>&#xA;&#xA;<p>I got client_id, client_secret, provision_key etc from the above steps, but I'm wondering that if I need to create oauth2 server at my end or kong itself configured it at their end and we just need to call their endpoints.&#xA;I'm building my APIs in laravel.</p>&#xA;"
47119752,How to scale up parallel consumers in microservices,2017-11-05 08:46:43,<architecture><rabbitmq><apache-kafka><microservices><scaling>,1,149,0,0.0,0,"<p>For a new project we are looking at using Microservices together with RabbitMQ or Kafka. For both technologies I have the same question, the answer might however differ.</p>&#xA;&#xA;<p>Consider three events:</p>&#xA;&#xA;<ol>&#xA;<li>Create product 1</li>&#xA;<li>Create profile 1</li>&#xA;<li>Delete product 1</li>&#xA;</ol>&#xA;&#xA;<p>We want to use these events to ""duplicate"" data among services. When using one consumer, all messages will be executed in the correct order and the database will be consistent. </p>&#xA;&#xA;<p>However, when this one consumer gets to slow at processing the messages, one might want to add another consumer in parallel. At this point it is uncertain that event 1 is executed before event 3, which  may lead to an inconsistent database (delete first, create after). </p>&#xA;&#xA;<p>Found some information <a href=""https://dzone.com/articles/performance-evaluation-disruptor-with-parallel-con"" rel=""nofollow noreferrer"">here</a> about the subject but both solution seem hard to implement. How would it be possible to scale up these consumers? Is there any difference in how one would handle this using RabbitMQ or Kafka?</p>&#xA;"
47143597,Spring Web-mvc not working with Spring Boot[Spring cloud],2017-11-06 18:41:47,<spring><jsp><spring-mvc><spring-boot><microservices>,2,176,0,0.0,0,"<p>I am new to microservices.I have created a microservice application using Spring.I am using ""<strong>spring-cloud-starter-eureka-server</strong>"".I have total 3 modules:</p>&#xA;&#xA;<ul>&#xA;<li>microservicecldm</li>&#xA;<li>account-microservice</li>&#xA;<li>webclient-microservice-server</li>&#xA;</ul>&#xA;&#xA;<p>Find below their main classes accordingly:</p>&#xA;&#xA;<pre><code> @EnableEurekaServer&#xA; @SpringBootApplication&#xA; public class MicroservicecldmApplication {&#xA;       public static void main(String[] args) {&#xA;          SpringApplication.run(MicroservicecldmApplication.class, args);&#xA;       }&#xA; }&#xA;&#xA;   @EnableDiscoveryClient&#xA;   @SpringBootApplication&#xA;   @ComponentScan(basePackages=""com.wmsdm.cloud"")&#xA;   public class WebclientMicroserviceServerApplication{ &#xA;        public static void main(String[] args) {&#xA;             SpringApplication.run(WebclientMicroserviceServerApplication.class, args);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>In application.properties I have following entries:</p>&#xA;&#xA;<pre><code>spring.application.name=WebclientMicroserviceServerApplication&#xA;eureka.client.serviceUrl.defaultZone:http://localhost:9091/eureka/&#xA;server.port=9993&#xA;eureka.instance.lease-renewal-interval-in-seconds=80&#xA;spring.mvc.view.prefix=/WEB-INF/view/&#xA;spring.mvc.view.suffix=.jsp&#xA;spring.mvc.static-path-pattern=/resources/**&#xA;</code></pre>&#xA;&#xA;<p>I have a AccountController class as follows:</p>&#xA;&#xA;<pre><code>@Controller&#xA;public class AccountController {&#xA;    @RequestMapping(value = ""/account"", method = RequestMethod.GET)&#xA;    public String viewAccount() {&#xA;        return ""accountSummary"";&#xA;    }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>I have the accountSummary.jsp page in my <code>/WEB-INF/view</code> path.Also in maven's pom.xml I have the following dependencies along with other dependencies:</p>&#xA;&#xA;<pre><code>   &lt;groupId&gt;com.wmsdm.cloud&lt;/groupId&gt;&#xA;   &lt;artifactId&gt;webclient-microservice-server&lt;/artifactId&gt;&#xA;   &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;   &lt;packaging&gt;war&lt;/packaging&gt;&#xA;&#xA;   &lt;name&gt;webclient-microservice-server&lt;/name&gt;&#xA;   &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;   &lt;parent&gt;&#xA;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;      &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;      &lt;version&gt;1.5.8.RELEASE&lt;/version&gt;&#xA;      &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;   &lt;/parent&gt;&#xA;&#xA;   &lt;properties&gt;&#xA;       &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF8&lt;/project.reporting.outputEncoding&gt;&#xA;      &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;      &lt;spring-cloud.version&gt;Dalston.SR4&lt;/spring-cloud.version&gt;&#xA;  &lt;/properties&gt;&#xA;&#xA;  &lt;dependencies&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;      &lt;/dependency&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;      &lt;/dependency&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&#xA;      &lt;/dependency&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;      &lt;/dependency&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;      &lt;/dependency&gt;&#xA;      &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&#xA;      &lt;/dependency&gt;&#xA;  &lt;/dependencies&gt;&#xA;&#xA;  &lt;dependencyManagement&gt;&#xA;      &lt;dependencies&gt;&#xA;          &lt;dependency&gt;&#xA;              &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;              &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;              &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;              &lt;type&gt;pom&lt;/type&gt;&#xA;              &lt;scope&gt;import&lt;/scope&gt;&#xA;          &lt;/dependency&gt;&#xA;      &lt;/dependencies&gt;&#xA;  &lt;/dependencyManagement&gt;&#xA;&#xA;  &lt;build&gt;&#xA;      &lt;plugins&gt;&#xA;          &lt;plugin&gt;&#xA;              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;              &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;          &lt;/plugin&gt;&#xA;      &lt;/plugins&gt;&#xA;  &lt;/build&gt;&#xA;</code></pre>&#xA;&#xA;<p>Inspite of these when I hit the URL:</p>&#xA;&#xA;<pre><code>http://localhost:9993/WebclientMicroserviceServerApplication/account&#xA;</code></pre>&#xA;&#xA;<p>I get the error <code>No mapping found for the requested uri</code></p>&#xA;"
47275278,Dividing microservices in Lagom,2017-11-13 23:33:39,<microservices><lagom>,1,176,0,0.0,0,<p>Lagom by default creates two modules for every microservice - API and implementation.</p>&#xA;&#xA;<p>Is it possible to divide one microservices into 3+ modules?</p>&#xA;
47314410,Running multiple ECS services in single EC2 instance using Elastic beanstalk,2017-11-15 18:06:50,<docker><elastic-beanstalk><microservices><amazon-ecs>,1,207,0,0.0,0,"<p>I have created 10 microservice dockers for web services and pushed the created images to ECS and deployed them using elastic beanstalk. Placed all the dockers in single Task definition and created a service for application-level auto-scaling. It created another task by duplicate it while auto-scaling. </p>&#xA;&#xA;<p>I want to apply the auto scaling only for dockers, not for the task. If one docker affected by CPU or memory load, auto-scaling should create the copy of the particular docker only(not the whole task). How can I achieve this in ECS using Elastic Beanstalk? Is it possible to create 10 services and each contains single task and single docker container to resolve this problem? </p>&#xA;"
47330878,Microservices internal communication,2017-11-16 13:26:21,<microservices>,2,237,0,0.0,0,"<p>I'm learning APIs with microservies architect. Here is small description about the setup  </p>&#xA;&#xA;<ul>&#xA;<li>I've two microservice applications and API gateway</li>&#xA;<li>All the applications including API gateway is nodeJs - express app.</li>&#xA;<li>Auth logic - JWT, handled on API gateway</li>&#xA;<li>Pass each incoming API gateway request to each of the microservice applications using http-proxy.</li>&#xA;<li>Also passes the user info as proxy header. </li>&#xA;</ul>&#xA;&#xA;<p><strong>Client request flow:</strong><br>&#xA;Client requesting API1 from microservice1 with JWT token which will be authenticated at API gateway and then information will be served from microservice1. which is fine.<br>&#xA;But I've one private API2 which should not be allowed from client side. Only internal applications can use it, but it should be callable upon another request from the client side.  </p>&#xA;&#xA;<p>eg.  </p>&#xA;&#xA;<pre><code>client request -&gt; /API/Gateway1 (has JWT)&#xA;/API/Gateway1 -&gt; API1 (has valid user)&#xA;API1 -&gt; /API/Gateway2 (has valid user)&#xA;/API/Gateway2 -&gt; API2 (has valid user)&#xA;</code></pre>&#xA;&#xA;<p><strong>Question:</strong><br>&#xA;How can I protect API2 from the client side, what if client fakes the valid user header.</p>&#xA;"
47196334,RestEasy with embedded Tomcat does not scan controllers,2017-11-09 07:35:12,<java><rest><tomcat><servlets><microservices>,2,254,0,0.0,0,"<p>&#xA;I use RestEasy with embedded Tomcat to export runnable jar file which deploy some Rest API (just for testing, I don't want to use SpringBoots).&#xA;&#xA;I've write some code in main entry point to register HttpServletDispatcher&#xA;</p>&#xA;&#xA;<pre><code>public class Main {&#xA;&#xA;public static void main(String[] args) throws Exception {&#xA;    try {&#xA;        new Main().run();&#xA;    } catch (Throwable t) {&#xA;        t.printStackTrace();&#xA;    }&#xA;}&#xA;&#xA;    public void run() throws Exception {&#xA;        Tomcat tomcat = new Tomcat();&#xA;        tomcat.setPort(8080);&#xA;&#xA;        Context ctx = tomcat.addContext(""/"", new File(""."").getAbsolutePath());&#xA;        String contextPath = ""/"";&#xA;        String appBase = ""."";&#xA;        tomcat.getHost().setAppBase(appBase);&#xA;        tomcat.addWebapp(contextPath, appBase);&#xA;&#xA;        Tomcat.addServlet(ctx, ""rest-easy-servlet"", new HttpServletDispatcher());&#xA;        ctx.addServletMapping(""/*"", ""rest-easy-servlet"");&#xA;        tomcat.start();&#xA;        tomcat.getServer().await();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>&#xA;Server starts successfully but without any Rest API. When access to the path localhost:8080/users/hello I've got error in log.&#xA;</p>&#xA;&#xA;<blockquote>&#xA;  <p>Nov 09, 2017 2:21:22 PM org.apache.coyote.AbstractProtocol start INFO:&#xA;  Starting ProtocolHandler [""http-nio-8080""] Nov 09, 2017 2:21:30 PM&#xA;  org.jboss.resteasy.core.ExceptionHandler  SEVERE: failed to execute&#xA;  javax.ws.rs.NotFoundException: Could not find resource for full path:&#xA;  <a href=""http://localhost:8080/users/hello"" rel=""nofollow noreferrer"">http://localhost:8080/users/hello</a>     at&#xA;  org.jboss.resteasy.core.registry.ClassNode.match(ClassNode.java:73)&#xA;    at&#xA;  org.jboss.resteasy.core.registry.RootClassNode.match(RootClassNode.java:48)&#xA;    at&#xA;  org.jboss.resteasy.core.ResourceMethodRegistry.getResourceInvoker(ResourceMethodRegistry.java:444)&#xA;    at&#xA;  org.jboss.resteasy.core.SynchronousDispatcher.getInvoker(SynchronousDispatcher.java:234)&#xA;    at&#xA;  org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:171)&#xA;    at&#xA;  org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:220)&#xA;    at&#xA;  org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56)&#xA;    at&#xA;  org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51)&#xA;    at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)     at&#xA;  org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)&#xA;    at&#xA;  org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)&#xA;    at&#xA;  org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)&#xA;    at&#xA;  org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)&#xA;    at&#xA;  org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502)&#xA;    at&#xA;  org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)&#xA;    at&#xA;  org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)&#xA;    at&#xA;  org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)&#xA;    at&#xA;  org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)&#xA;    at&#xA;  org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)&#xA;    at&#xA;  org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)&#xA;    at&#xA;  org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)&#xA;    at&#xA;  org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)&#xA;    at&#xA;  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&#xA;    at&#xA;  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&#xA;    at&#xA;  org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)&#xA;    at java.lang.Thread.run(Thread.java:745)</p>&#xA;</blockquote>&#xA;&#xA;<p>I think RestEasy don't have any signal to scan its components. Please help me the way to scan RestEasy components, or the way to register RestEasy same as using web.xml</p>&#xA;"
47191332,Can you make a centralized build.gradle for many projects?,2017-11-08 23:14:54,<java><gradle><build.gradle><microservices>,1,126,1,0.0,0,"<p>I have a number of microservices, each service/project has its own build.gradle file, but I was wondering if I could just make a centralized build.gradle that could be pulled in to not only cut down on the amount of code in each project, but also to help take less time going through each service to update dependencies.</p>&#xA;&#xA;<p>My initial thought is to maybe put something into JFrog's Artifactory and pull from there, but I was curious if there are already common practices out there for this.</p>&#xA;"
47335455,Can a non-SF project make use of the applicationmanifest configuration values?,2017-11-16 17:10:04,<c#><.net><visual-studio-2017><microservices><azure-service-fabric>,1,39,2,1.0,0,"<p>I've got a Service Fabric Application set up in the following way:</p>&#xA;&#xA;<pre><code>Solution&#xA;--SF Project&#xA;  --ApplicationManifest.xml&#xA;--Stateless Project (uses app manifest values)&#xA;--Stateless Project (uses app manifest values)&#xA;--Class Library (used as a repository by the above two projects)&#xA;</code></pre>&#xA;&#xA;<p><strong>How can I enable the class library to make use of the ApplicationManifest.xml configuration file from the SF Project?</strong></p>&#xA;&#xA;<p>To allow the projects to be able to use the AppManifest for build/deployment, they simply need to be created like so:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/lDZj1.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lDZj1.gif"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>How does a project that does not get added as a Service Fabric project make use of the applicationmanifest?</strong></p>&#xA;&#xA;<p>The Service Fabric projects are able to use the appmanifest by including parameters in settings.xml and servicemanifest (but non-SF projects cannot):</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QrPxr.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QrPxr.gif"" alt=""enter image description here""></a></p>&#xA;"
47258026,implement financial microservice using node.js | python | R,2017-11-13 06:07:00,<javascript><python><node.js><microservices><financial>,2,86,2,0.0,0,"<p>I'm developing a tourist web app with node.js and microservics.</p>&#xA;&#xA;<p>I need to develop a <code>pricing</code> service which will do all the calculation for the guest (price for night, taxes, VAT, discounts etc).</p>&#xA;&#xA;<p>Moreover, I need those calculation will be easy to dynamically change and control.</p>&#xA;&#xA;<p><strong>From my past experience, doing those calcs in common web programming languages and/or storing math formulas in the db end with a mess</strong>.</p>&#xA;&#xA;<p>Are there any alternative solutions for this? From what I read so far language like <code>python</code>, <code>R</code> or <code>Java</code> can fit to the job. However, is there any specific library within those which aimed for pricing?</p>&#xA;"
47276560,Authorization (not authentication!) patterns with graphql-subscriptions and microservices,2017-11-14 02:07:31,<microservices><apollo><apollo-client><apollo-server><graphql-subscriptions>,1,188,2,0.0,0,"<p>I've created an apollo-server with graphql-subscriptions, and that's all good so far. I can receive publications on the front-end. Great!</p>&#xA;&#xA;<p>What I want to do now is only send publications to <em>authorized</em> users, so, some sort of logic/test needs to be done. But where and how? All the examples and things I've seen involve blindly receiving messages from a redis server, and setting it back to the client. I can test which user is logged in, but what now? Individual microservices will talk to an auth/user service and decide allowed actions based on that. No problem. But how do I stop redis broadcasts from getting to the wrong users? All apollo-server does is listen to messages from redis - not validate them.</p>&#xA;&#xA;<p>The only thing I can really think of is have some sort of permissions object field on every broadcast, and using graphql to validate it against the auth service. Does not seem right. I want my auth done in the microservices. Anything pointing me in the right direction would be amazing.</p>&#xA;"
47178056,Spring boot Kubernetes Service Discovery,2017-11-08 11:04:17,<spring><spring-boot><kubernetes><microservices>,1,844,3,1.0,0,"<p>I am running into issues with Kubernetes Service Discovery on Spring Boot applications. </p>&#xA;&#xA;<p>I should be able to discover the services whether my spring boot application is running within or out of Kubernetes cluster. Our local development won't be on k8s cluster.</p>&#xA;&#xA;<p>I am using Service Discovery via DNS. I tried using <a href=""https://github.com/spring-cloud-incubator/spring-cloud-kubernetes"" rel=""nofollow noreferrer"">spring-cloud-starter-kubernetes</a></p>&#xA;&#xA;<pre><code>    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-kubernetes&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.2.0.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>As per documentation you should be able to autowire DiscoveryClient and good to go</p>&#xA;&#xA;<pre><code>@Autowire&#xA;private DiscoveryClient discoveryClient;&#xA;</code></pre>&#xA;&#xA;<p>DiscoveryClient is part of spring-cloud-commons. spring-cloud-starter-kuberenetes doesn't have it. </p>&#xA;&#xA;<p>Anyone solved similar problem using the same library or a different one? Please share the solution</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
49576208,How to make cross treatments on microservices,2018-03-30 14:24:43,<domain-driven-design><microservices><cqrs>,1,31,0,1.0,0,"<p>I'm learning about microservices, and I don't understand how to structure.</p>&#xA;&#xA;<p>Imagine that we are doing an ecommerce application. We are going to have one service for catalog (with products), one service for there prices, one service for promotions and one for shoppingcart.</p>&#xA;&#xA;<p>My question is : which service is in charge of applying the promotions on the shoppingcart cause this treatment need datas from shoppingcart service and from promotion service and must save results (shopping cart with new price) somewhere (but where ?).</p>&#xA;&#xA;<p>Thanks for any help !</p>&#xA;"
49548508,"Reliable, fault tolerant and scalable solution for tracking updates on different mongo collection",2018-03-29 05:15:53,<java><mongodb><design><rabbitmq><microservices>,1,37,0,0.0,0,"<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">&#xD;&#xA;<div class=""snippet-code"">&#xD;&#xA;<pre class=""snippet-code-js lang-js prettyprint-override""><code>//CouponCartRule - MongoDB&#xD;&#xA;{&#xD;&#xA;  ""id"": 1,&#xD;&#xA;&#xD;&#xA;  ""applicability"": {&#xD;&#xA;    ""validFrom"": ""12-MAR-2017T01:00:00Z"",&#xD;&#xA;    ""validTill"": ""12-MAR-2019T01:00:00Z""&#xD;&#xA;  },&#xD;&#xA;&#xD;&#xA;  ""maxUsage"": 100,&#xD;&#xA;  ""currentUsage"": 99,&#xD;&#xA;  ""maxBudget"": 1000,&#xD;&#xA;  ""currrentBudget"": 990&#xD;&#xA;}&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;//UniqueCoupon collection  - MongoDB&#xD;&#xA;{&#xD;&#xA;  ""ruleId"": 1,&#xD;&#xA;  ""couponCode"": ""CITIDEALMAR18"",&#xD;&#xA;  ""currentCouponUsage"": 90,&#xD;&#xA;  ""validFrom"": ""12-MAR-2018T01:00:00Z"",&#xD;&#xA;  ""validTill"": ""12-APR-2018T01:00:00Z""&#xD;&#xA;}&#xD;&#xA;&#xD;&#xA;{&#xD;&#xA;  ""ruleId"": 1,&#xD;&#xA;  ""couponCode"": ""CITIDEALAPR18"",&#xD;&#xA;  ""currentCouponUsage"": 9,&#xD;&#xA;  ""validFrom"": ""12-JAN-2018T01:00:00Z"",&#xD;&#xA;  ""validTill"": ""12-FEB-2018T01:00:00Z""&#xD;&#xA;}&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;//Order - MongoDB&#xD;&#xA;{&#xD;&#xA;  ""id"": 112,&#xD;&#xA;  ""total"": {&#xD;&#xA;    ""discountCode"": ""CITIDEALMAR18"",&#xD;&#xA;    ""discount"": 10,&#xD;&#xA;    ""total"": 90,&#xD;&#xA;    ""grandTotal"": 90&#xD;&#xA;&#xD;&#xA;  },&#xD;&#xA;  ""items"": []&#xD;&#xA;}</code></pre>&#xD;&#xA;</div>&#xD;&#xA;</div>&#xD;&#xA;</p>&#xA;&#xA;<p><strong>Problem Description</strong> </p>&#xA;&#xA;<p>A CouponCartRule will have conditions defined for a coupon code to be applied on order.</p>&#xA;&#xA;<p>Each shopping cart rule can have n coupons where specific conditions might be overriden.</p>&#xA;&#xA;<p>This is done to reuse CouponCartRule but create different coupons under them and also coupons under CouponCartRule can grow to max of 10K record.</p>&#xA;&#xA;<p>When order is succesffuly placed the order will have couponCode and discount applied. </p>&#xA;&#xA;<p>Order collection is managed by OM team and it is very big.&#xA;We receive order add / cancel event when order is created / cancelled.</p>&#xA;&#xA;<p>I have requirement to check if maxUsage and maxBudget is not breached during checkout.</p>&#xA;&#xA;<p>I  am planning to listen to order add and cancel event, update usage on order add and order cancel event.</p>&#xA;&#xA;<p>Steps </p>&#xA;&#xA;<ul>&#xA;<li>Update currentUsage of UniqueCoupon usage [inc operator of mongo]</li>&#xA;<li>Update currentUsage &amp; budget stats of CouponCartRule using </li>&#xA;</ul>&#xA;&#xA;<p>Any suggestion on making the code idempotent if there is downtime, If there is failure in step 2. The listener would send message to DLQ and the count would be update again which is not desired.</p>&#xA;&#xA;<p>One option that I thought of is to track and record stats at UniqueCoupon level and later aggregate at SCR level [The aggregation operation will eventually be consistent when subsequent coupon is used]. </p>&#xA;&#xA;<p>Since this code is invoked real time it should be efficient.</p>&#xA;"
49650746,REST API for sharing Files,2018-04-04 12:13:32,<c#><rest><microservices><restful-architecture>,1,38,0,0.0,0,<p>i would like to share files from a microservice. I have now some personal trouble during the feature to share files - especially PDF Files. </p>&#xA;&#xA;<p>Option one i thought about is to deserialize the file and send the binaries in the http response message.</p>&#xA;&#xA;<p>Option two is about the sharing from an link. The link will guide the user into an folder which is located in the microservice location.</p>&#xA;&#xA;<p>Are there more options to handle this problem or which possibilities do you prefer?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;
49486062,apache ignite cumpute service with affinity,2018-03-26 07:30:16,<java><microservices><distributed><ignite>,2,73,0,0.0,0,"<p>I would like to run a service/compute jub on ignite using a service but run the job where the data is.</p>&#xA;&#xA;<p>from the client I will either call a compute or service proxy but need the service to run near the cache data.</p>&#xA;&#xA;<p>I noticed you can use a service from a compute job:</p>&#xA;&#xA;<pre><code>compute.run(new IgniteRunnable() {&#xA;  @ServiceResource(serviceName = ""myCounterService"");&#xA;  private MyCounterService counterSvc;&#xA;</code></pre>&#xA;&#xA;<p>If I deploy the service on every node in the cluster can I use compute with near cach to do this?</p>&#xA;&#xA;<pre><code> compute.affinityRun(CACHE_NAME, key, () -&gt; { &#xA;      // call my servie here...&#xA;</code></pre>&#xA;&#xA;<p>maybe there is a way to directly call a service proxy with affinity to avoid using comupte?</p>&#xA;&#xA;<p>p.s. the reason is the service preduce more cache data and I would like to avoid transferring large data between nodes and clients back and forth.</p>&#xA;"
49584617,Distributed Database Design Architecture Use Case for Users & Authentication,2018-03-31 05:36:38,<microservices><distributed-database>,2,86,0,0.0,0,"<p>I am now trying to design database for my micro service-oriented application in a distributed way. My application is related with management of universities. I have different universities say A, B, C. Each university have separate users for using their business data. Now I am planning to design separate databases for separate universities for storing their user data. So each university has their own database for their users and additional one database for managing their application tables. If I have 2 universities, Then I have 2 user details DB and other 2 DB for application tables.</p>&#xA;&#xA;<p>Here My confusion is that, When I am searching for database design, I only see the approach of keeping one common database for storing all users (Here for one DB for all users of all universities). So every user is mixed within one database.</p>&#xA;&#xA;<p><strong>Confusion -</strong>  If I am following separate database for each university, Is possible to support distributed DB architecture pattern and micro service oriented standard? Or Do I need to keep one DB for all users? </p>&#xA;&#xA;<p>Can anyone please help me to find out that which method is appropriate for microservice / Distributed database design pattern?</p>&#xA;"
49502594,How to get a new access token with additional scope without re-login?,2018-03-27 00:22:58,<oauth-2.0><microservices><cloudfoundry-uaa>,1,87,0,0.0,0,"<p>I am working with Cloudfoundry UAA </p>&#xA;&#xA;<p>I am not sure if it is possible in standard oauth2.&#xA;The situation is -> </p>&#xA;&#xA;<ol>&#xA;<li>User logs into the app</li>&#xA;<li>He receives an access_token and refresh_token</li>&#xA;<li>He can keep on acquiring new access_tokens which has original scopes</li>&#xA;<li>His access permission changes so new scopes are added for him</li>&#xA;</ol>&#xA;&#xA;<p>Now I need a new access token, without him to log in again.&#xA;Is it possible that I can use the same refresh_token and ask for access_token with modified scopes?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
49640387,How to setup a data sync micro-services with a Message Queue,2018-04-03 23:12:36,<synchronization><message-queue><microservices>,1,99,0,0.0,0,"<p>I am currently building a system (SaaS-like) which is running with micro-services and larger services (due to various constraints) which will be used by multiple clients (e.g. multiple accounts), part of the core system requires data from other systems (e.g. The Client's systems) to be in the core systems database. I will manage this through having a sync micro-service which on a set time will call the other systems API(s) and process the data, apply it into the core database and mark any specific changes in state into a message queue for other services to then process.</p>&#xA;&#xA;<p>My core problem is that if I have multiple clients with multiple sync jobs and multiple sync services (e.g. 2+ sync service apps) how will I manage the jobs so that two syncs don't operate at once and the services all operate on mixed client systems etc. Overall the aim is be to able to scale easily.</p>&#xA;&#xA;<p>So far the options I have come up with are:</p>&#xA;&#xA;<ol>&#xA;<li>Use basic cron job and set a sync service to a single client (unable to scale easy)</li>&#xA;<li>Use another service to put items into a MQ for the sync services to pick it up (the other service cannot scale) </li>&#xA;<li>Use a AWS system such as Cloud Watch to push into MQ and multiple sync services work from the queue</li>&#xA;</ol>&#xA;&#xA;<p>Has anyone come up with this problem before? Whats a good option or recommendation?</p>&#xA;&#xA;<p><em>Technology dependent answers are fine, but the services are built on Node.js and using a mySQL database.</em></p>&#xA;"
49525246,Is it possible to have centralised configurations for all Node.js microservices?,2018-03-28 02:43:29,<node.js><config><microservices>,1,102,0,0.0,0,<p>we have set of nodeJS microservices and all of our micro services has individual configurations for different environments like </p>&#xA;&#xA;<pre><code> default.json&#xA; dev.json&#xA; staging.json&#xA; production.json&#xA;</code></pre>&#xA;&#xA;<p>Sorry if this is a theoretical question but please help me understand below </p>&#xA;&#xA;<ol>&#xA;<li>Is it feasible to create centralised configuration for all micro services instead of having individual?</li>&#xA;<li>Which is preferred centralised config or individual config?</li>&#xA;</ol>&#xA;&#xA;<p>I also google it but no info regarding this. I am mainly looking for suggestions on how this can be achieved and works.</p>&#xA;
49588249,How discovery service works in polyglot micro services architecture?,2018-03-31 13:23:29,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix><pivotal-cloud-foundry>,2,112,0,1.0,0,"<p>If we build all micro services using spring boot, all micro services(@EnableEurekaClient) can be discoverable using Eureka Server(@EnableEurekaServer). if some of micro-services built using other technologies ,how discovery, load-balancing, reverse proxying(gateway) is possible in cloud(PCF,AWS etc)?</p>&#xA;&#xA;<p>I read many blogs on web related to micro-services, I didn't get proper info this.</p>&#xA;"
49666398,Eureka Registered with weird IP address and Requests not working with zuul,2018-04-05 07:20:11,<docker><spring-boot><microservices><netflix-zuul><netflix-eureka>,1,126,0,0.0,0,"<p>I am developing a Rest Backend with microservices architecture using SpringBoot. I am using Eureka as discovery service and Zuul as API Gateway. Everything works fine when working in the localhost. But when I deploye the services on the cloud, zuul api gateway not behave as expected. All the services are still registered with the eureka. &#xA;Request come to the api gateway not forward to the required sevice, instead it stuck on the api gateway and give </p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Filter threw Exception&#xA;    at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:227) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at com.netflix.zuul.FilterProcessor.runFilters(FilterProcessor.java:157) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at com.netflix.zuul.FilterProcessor.route(FilterProcessor.java:118) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at com.netflix.zuul.ZuulRunner.route(ZuulRunner.java:96) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at com.netflix.zuul.http.ZuulServlet.route(ZuulServlet.java:116) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at com.netflix.zuul.http.ZuulServlet.service(ZuulServlet.java:81) ~[zuul-core-1.3.1.jar:1.3.1]&#xA;    at org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:165) [spring-webmvc-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;    ...&#xA;    at com.netflix.hystrix.HystrixCommand.queue(HystrixCommand.java:378) ~[hystrix-core-1.5.12.jar:1.5.12]&#xA;    at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:344) ~[hystrix-core-1.5.12.jar:1.5.12]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:159)&#xA;    ... 96 common frames omitted&#xA;Caused by: java.lang.RuntimeException: java.net.UnknownHostException: 3b7b691a42eb: unknown error&#xA;    at rx.exceptions.Exceptions.propagate(Exceptions.java:57) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:463) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at rx.observables.BlockingObservable.single(BlockingObservable.java:340) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) ~[ribbon-loadbalancer-2.2.5.jar:2.2.5]&#xA;    ... 158 common frames omitted&#xA;Caused by: java.net.UnknownHostException: 3b7b691a42eb: unknown error&#xA;    at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) ~[na:1.8.0_65]&#xA;    at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) ~[na:1.8.0_65]&#xA;    at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) ~[na:1.8.0_65]&#xA;    at java.net.InetAddress.getAllByName0(InetAddress.java:1276) ~[na:1.8.0_65]&#xA;    at java.net.InetAddress.getAllByName(InetAddress.java:1192) ~[na:1.8.0_65]&#xA;    at java.net.InetAddress.getAllByName(InetAddress.java:1126) ~[na:1.8.0_65]&#xA;    at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) ~[httpclient-4.5.5.jar:4.5.5]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112) ~[httpclient-4.5.5.jar:4.5.5]&#xA;    at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373) ~[httpclient-4.5.5.jar:4.5.5]&#xA;    at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381) ~[httpclient-4.5.5.jar:4.5.5]&#xA;    ...&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) ~[rxjava-1.3.6.jar:1.3.6]&#xA;    at rx.Observable.subscribe(Observable.java:10352) ~[rxjava-1.3.6.jar:1.3.6]&#xA;</code></pre>&#xA;&#xA;<p>Here is my zuul configurations</p>&#xA;&#xA;<pre><code>zuul:&#xA;    prefix: /api/v1&#xA;      routes:&#xA;        user-server:&#xA;          path: /user/**&#xA;          serviceId: USER-SERVER&#xA;        developer-server:&#xA;          path: /developer/**&#xA;          serviceId: DEVELOPER-SERVER&#xA;&#xA;    spring:&#xA;      application:&#xA;        name: zuul-server&#xA;&#xA;    server:&#xA;      port: 5000&#xA;&#xA;    eureka:&#xA;      client:&#xA;        register-with-eureka: true&#xA;        fetch-registry: true&#xA;        service-url:&#xA;          defaultZone : http://{{eureka_hosted_ip}}:8070/eureka/   &#xA;&#xA;&#xA;hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 2000000&#xA;    ribbon:&#xA;        ConnectTimeout: 200000&#xA;        ReadTimeout: 200000&#xA;</code></pre>&#xA;&#xA;<p>I have deployed services in docker containers.  What am I doing wrong ?</p>&#xA;"
49536335,what is a microservice in asp.net core,2018-03-28 13:48:55,<docker><asp.net-web-api><microservices>,1,152,0,0.0,0,<p>I am trying to understand containers and microservices. I have  created a sample application in asp.net core with docker support. It is a web api project and it is simply  showing some json values as the output in a browser. So is this a microservice? What if I want to add another microservice. Do I need to call another data source in my web api controller for that? </p>&#xA;&#xA;<p>thanks</p>&#xA;
49536369,"When we already have events in our application, why would we may need Event Sourcing?",2018-03-28 13:50:16,<events><microservices><cqrs><event-sourcing>,2,42,1,0.0,0,"<p>I have gone through a lot of links and information about Event Sourcing and CQRS as well. But still, don't understand their proper need. What I could deduce is, it definitely brings complexity and scalability issues. </p>&#xA;&#xA;<p><a href=""http://eventuate.io/whyeventsourcing.html"" rel=""nofollow noreferrer"">http://eventuate.io/whyeventsourcing.html</a></p>&#xA;&#xA;<p><a href=""https://martinfowler.com/eaaDev/EventSourcing.html"" rel=""nofollow noreferrer"">https://martinfowler.com/eaaDev/EventSourcing.html</a></p>&#xA;"
49600833,"Is a backend API using node, mongo to slow for front end client to get results for live suggestions?",2018-04-01 17:37:41,<node.js><mongodb><design-patterns><architecture><microservices>,1,29,2,0.0,0,"<p>I want to write a series of small apps for myself as micro services. This is for practicality and self learning. I want these apps to be able to work independently, but build a separate frontend client that has a search bar that can find data across all of the services. I wanted to implement a live autocomplete with search results as the user is typing that will search across multiple databases.</p>&#xA;&#xA;<p>My current approach was to split each app into two apps, backend API, and a frontend client. Have a common auth service that all of the apps utilize for authorization.</p>&#xA;&#xA;<p>I think this approach would work fine except for speed and performance, which I am not sure about. It is a personal requirement of mine to be able to implement this search bar with autocomplete search results. This means it will have to make API requests to each service to get those results, it just feels like it might be too slow.</p>&#xA;&#xA;<p>Also, in case anyone is wondering, I was planning on using node, express, and mongodb for backend. Probably go with node, express, vue or something for the front end. </p>&#xA;&#xA;<p>Q. Does anyone have personal experience with the performance aspect of working with multiple APIs? </p>&#xA;&#xA;<p>Q. If this approach is too slow, is there a better approach that still allows for a separation of the applications?</p>&#xA;"
49482516,Visual or UML tool to draw micro service connectivity,2018-03-26 00:48:16,<architecture><uml><microservices><tool-uml>,2,348,2,1.0,0,<p>what is the best way to represent microservice and their connection to each other via UML diagram? any open source tool to create UML/Visualize the different microservice and their connections?</p>&#xA;
49579074,Cache Implementation in Microservices best practises,2018-03-30 17:54:05,<caching><microservices>,1,28,4,0.0,0,<p>I want to ask one design related question as we have multiple micro-services and we want to implement cache for them. </p>&#xA;&#xA;<p>There is a possibility of having different services accessing the same cache for setting and fetching data from this cache So what should be the best way of doing it. </p>&#xA;&#xA;<p>Assuming we have customer service which updates the cache with customer data and we have a cart cache which do needs this data to set in cart object which contains this customer data so for this kind of scenario what would be the best way of implementing this.</p>&#xA;
48277437,Kubernetes: Databases & DB Users,2018-01-16 09:00:58,<postgresql><kubernetes><containers><microservices><stolon>,1,278,0,0.0,0,"<p>We are planning to use Kube for Postgres deployments. Our applications will be microservices with separated schema (or logical database). For security sake, we'd like to have separate users for each schema/logical_db. </p>&#xA;&#xA;<p>I suppose that the db/schema&amp;user should be created by Kube, so the application itself does not need to have access to DB admin account.</p>&#xA;&#xA;<p>In <a href=""https://github.com/sorintlab/stolon"" rel=""nofollow noreferrer"">Stolon</a> it seems there is just a possibility to create a single user and single database and this seems to be the case also for other HA Postgres charts. </p>&#xA;&#xA;<p>Question: What is the preferred way in Microservices in Kube to create DB users?</p>&#xA;"
48361365,Architect Predictive Search on 30-50K objects?,2018-01-20 21:38:41,<java><angular><caching><search><microservices>,1,26,0,0.0,0,"<p>I have to build a search functionality where GUI will provide a search field to search objects in Oracle database. There are currently 30K objects I have to search on but they will grow in number over time. 300-400 per month approx. </p>&#xA;&#xA;<p>As a part of the requirement, when user types in any text in search Like for example ""ABC"", then all objects in the DB that contains ABC should appear in a datatable more like system is predicting results based on what user has types in the search field. </p>&#xA;&#xA;<p>Question is how to architect such feature? </p>&#xA;&#xA;<p>Simple way to do is to load everything in the GUI Javascript object and run search on it. Since JS is ridiculously fast, performance wont be an  issue.   </p>&#xA;&#xA;<p>Another way is to run query in the Database everytime user types in text in search field. This does not seem convenient as it will put unnecessary load on the database. </p>&#xA;&#xA;<p>Is there a better way to architect this feature? Please share thoughts. </p>&#xA;"
48385783,Understanding how much of your microservice infrastructure should be shared with other business units,2018-01-22 16:08:01,<architecture><microservices>,1,31,0,0.0,0,"<p>Is it generally best to deploy separate microservice infrastructure, including&#xA;big components like container schedulers, by team/product?</p>&#xA;&#xA;<p>I get the feeling that this strongly depends on the organization's structure&#xA;and culture, much like&#xA;<a href=""http://www.ben-morris.com/should-microservices-share-technologies-and-capabilities/"" rel=""nofollow noreferrer"">this</a>&#xA;article suggests. Our organization is hierarchical, with areas in different&#xA;branches in charge of different specialties (database, OS admin, development,&#xA;QA all have different managers and even directors). All these areas naturally&#xA;have their different priorities and exist with somewhat large knowledge gaps&#xA;between them. Still though, the pressure for rapid delivery is felt, both from &#xA;market pressures and also regulatory obligations.</p>&#xA;&#xA;<p>As a software developer, I very much like the idea of <em>loose coupling</em> and&#xA;believe our team should have its own separate instances of container&#xA;management platform. Our team should be multifunctional, capable of delivering&#xA;to production ourselves. I can think of several advantages of this approach:</p>&#xA;&#xA;<ul>&#xA;<li>We would be responsible for the homogeinity of our environments</li>&#xA;<li>Faster iterations</li>&#xA;<li>Risk is spread out over several infrastructure/teams instead of having one&#xA;giant mega instance</li>&#xA;<li>Removal of external teams from the equation when considering an&#xA;internal change/upgrade to your platform</li>&#xA;</ul>&#xA;"
48363883,May i call service to service AWS Lambda directly in API Architecture?,2018-01-21 05:09:18,<amazon-web-services><lambda><microservices>,1,43,0,0.0,0,"<p>This is the first time I use AWS Lambda as an API architecture. &#xA;Because im trying to implement serverless. &#xA;Let say, I have three microservices where all of the microservices hosted on AWS Lambda. &#xA;And I use AWS API Gateway as router. I also implemented Jason web token in API Gateway.</p>&#xA;&#xA;<p>This is the public URL that the frontend will use.</p>&#xA;&#xA;<ol>&#xA;<li><p>URL Routing API - <a href=""https://mydomain.co/v1/lambda-service1"" rel=""nofollow noreferrer"">https://mydomain.co/v1/lambda-service1</a>&#xA;Â Â Â Â Lambda REAL URL - <a href=""https://cr7z0dds42.execute-api.ap-southeast-amazonaws.com/DEV/"" rel=""nofollow noreferrer"">https://cr7z0dds42.execute-api.ap-southeast-amazonaws.com/DEV/</a></p></li>&#xA;<li><p>URL Routing API - <a href=""http://mydomain.co/v1/lambda-service2"" rel=""nofollow noreferrer"">http://mydomain.co/v1/lambda-service2</a>&#xA;Â Â Â Â Lambda REAL URL - <a href=""https://cr7z0ddgg2.execute-api.ap-southeast-amazonaws.com/DEV/"" rel=""nofollow noreferrer"">https://cr7z0ddgg2.execute-api.ap-southeast-amazonaws.com/DEV/</a></p></li>&#xA;<li><p>API Routing URL - <a href=""http://mydomain.co/v1/lambda-service3"" rel=""nofollow noreferrer"">http://mydomain.co/v1/lambda-service3</a>&#xA;Â Â Â Â Lambda REAL URL - <a href=""https://cgf7z0ddgg2.execute-api.ap-southeast-amazonaws.com/DEV/"" rel=""nofollow noreferrer"">https://cgf7z0ddgg2.execute-api.ap-southeast-amazonaws.com/DEV/</a></p></li>&#xA;</ol>&#xA;&#xA;<p>Basically, if I am currently my client / frontend, I want to call data from API number 1 by using TOKEN, i will use the API routing URL. &#xA;But there are some cases that the API number 1 needs to call service number 2 before return to client / frontend. &#xA;Currently what I do is call directly service number 2 via Lambda REAL URL, not API Routing URL from service number 1 without using TOKEN.</p>&#xA;&#xA;<p>Is this justified?</p>&#xA;"
48295080,Using JSF for microservice based UI composition from different remote servers,2018-01-17 06:44:21,<user-interface><jsf><glassfish><microservices>,1,306,0,0.0,0,"<p>I am currently working on a project where we try to slice a monolitic 3-Layer Web application into different microservices.&#xA;The web server is glassfish and frontend is based on JSF (templating etc).</p>&#xA;&#xA;<p>What we want to do: We have different Microservices (hosted on different glassfish servers, using REST for communication). Each MS has its own UI. One Microservice (FrontendMicroservice) is in charge for the UserLogin and the dynamic composition of the various UI's depending on the logged in User. (E.g. Storemanger logged in -> StoreMicroserviceUI and ProductMicroserviceUI have to be loaded into FrontendMicroservice OR Enterprisemanger is logged in -> EnterpriseManager MicroserviceUI and ProductMicroserviceUI have to be loaded into FrontendMicroservice).&#xA;The FrontendMicroservice provides the frame with a Navigation/Menu Bar etc.</p>&#xA;&#xA;<p>Is JSF  appropriate for this task? And which tags can be used? I could not find any similar approach using JSF!</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
48397327,Apigee for internal microservices,2018-01-23 08:38:27,<security><microservices><apigee>,1,60,0,0.0,0,"<p>Recently I split a big monolithic enterprise application in a bunch of microservices in CloudFoundry, that will feed Spark etc... &#xA;Just one of them is on the edge and communicates with a service exposed externally. At this stage, we've been asked to add an additional security layer with <a href=""https://apigee.com/about/tags/microservices"" rel=""nofollow noreferrer"">Apigee</a>. Unfortunately at this stage we cannot use oauth2 yet. &#xA;My question is: should I use Apigee only on the edge or all the internal microservices should leverage Apigee API as well? My concern is about performance if each service calls Apigee proxy. </p>&#xA;"
48241005,Security in Zuul Gateway,2018-01-13 14:52:45,<spring><microservices><netflix-zuul>,1,329,0,0.0,0,<p>I am trying to set up a gateway server for microservices  using Zuul.</p>&#xA;&#xA;<p>I have created an authorization server to issue tokens.Should I validate the token in the gateway server using ZuulFilter for each request  or let each service&#xA;validate and parse the tokens.What will be the best way to implement it.or  Is there any other way ? Any Suggestion/Solutions will be helpful. Thanks</p>&#xA;
48384182,How to integrate Kubernetes with existing AWS ALB?,2018-01-22 14:47:07,<amazon-web-services><docker><amazon-ec2><kubernetes><microservices>,1,76,0,0.0,0,"<p>I want to use existing AWS ALB for my kubernetes setup. i.e. I don't want alb-ingress-controller create or update any existing AWS resource ie. Target groups, roles etc. </p>&#xA;&#xA;<p>How can I make ALB to communicate with Kubernetes cluster, henceforth passing the request to existing services and getting the response back to ALB to display in the front end?</p>&#xA;&#xA;<p>I tried <a href=""https://github.com/coreos/alb-ingress-controller/"" rel=""nofollow noreferrer"">this</a> but it will create new ALB for new ingress resource. I want to use the existing one.</p>&#xA;"
48261542,Service Fabric service instance failure notification,2018-01-15 10:54:11,<azure><cloud><microservices><azure-service-fabric><service-fabric>,1,36,1,0.0,0,<p>How can one service get notified about another(Guest executable) service instance failure?&#xA;I have two services &#xA; 1)stateless native service say Service A&#xA; 2)Guest executable service(Nodejs) say service B&#xA;what i want is that when any instance of service B fails(and restarted by SF) A gets a notification. &#xA;Any help will be appreciated.</p>&#xA;
48296421,Docker Microservice Architecture - Communication between different containers,2018-01-17 08:16:40,<azure><docker><microservices><docker-container>,1,130,1,2.0,0,"<p>I've just started working with docker and I'm currently trying to work out how to setup a project using microservice architecture.</p>&#xA;&#xA;<p>My goal is to move out different services from the api and instead have each one in their own container.</p>&#xA;&#xA;<p><strong>Current architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ewRMg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ewRMg.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Desired architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/mCKD7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mCKD7.png"" alt=""To""></a></p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ol>&#xA;<li>How does the API gateway communicate with the internal services? Should all microservices have their own API which only accept communication from the API gateway? Any other means of communications?</li>&#xA;<li>What would be the ideal authentication between the gateway and the microservices? JWT token? Basic Auth?</li>&#xA;<li>Do you see any problems with this architecture if hosted in Azure?</li>&#xA;<li>Is integration testing even possible in the desired architecture? For example, I use EF SQlite inmemory for integration testing and its easily accessible within the api, but I don't see this working if the database is located in it's own container.</li>&#xA;<li>Anything important here that i've missed?</li>&#xA;</ol>&#xA;"
48190148,What is the difference between SOA and Microservices,2018-01-10 14:56:32,<web><microservices><distributed-computing><soa>,1,344,3,0.0,0,"<p>Ok, as far as I've understood both in SOA and in Microservices modules should be independant and reusable. But what really differs SOA and Microservices ?</p>&#xA;"
48374452,Dao as a Seperate Module in Monolithic Considering Extendable to microservice in future,2018-01-22 03:54:23,<java><spring><microservices>,1,114,3,0.0,0,"<p>I am actually creating one project where we are having 2 or more database. I will use Spring Boot. I would like to know:</p>&#xA;&#xA;<ol>&#xA;<li><p>Why do we have Client of the Gateways while code as we already have REST endpoint in server (May be i am wrong )?</p></li>&#xA;<li><p>My project currently will be monolithic but I want to make it possible to change to a microservice architecture in the future. Should I have the DAO as separate module which will be dependency for other module considering I can have more than one database (RDBMS and NoSQL)?</p></li>&#xA;</ol>&#xA;&#xA;<p>Hope I am asking work question, but I am confused right now, while starting the project.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
49395113,Visualization for Microservice flow,2018-03-20 22:23:18,<workflow><visualization><microservices>,1,256,0,0.0,0,"<p>I have an application made of multiple microservices. I would like to visualize it for newer developer to understand the flow chart. </p>&#xA;&#xA;<p>In some previous experiences, I have seen people draw flowchart like this one below. </p>&#xA;&#xA;<p><strong>Question: What is this kind of flow chart called?<br>&#xA;Is there any software tool that can draw it?</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/tSkgz.png"" rel=""nofollow noreferrer"">flow chart</a></p>&#xA;"
49273441,urllib-like library that caches accordingly to HTTP headers in python?,2018-03-14 09:02:54,<python-3.x><rest><web-services><urllib><microservices>,1,11,0,0.0,0,"<p>I develop HTTP GET Webservices (REST) in a distributed microservices architecture.&#xA;For performance issues, I need the cache on the clients of the webservices.</p>&#xA;&#xA;<p>Is there an urllib-like library that uses HTTP cache headers of the webservices to cache?</p>&#xA;&#xA;<p>Note: requests-cache does not seem to read http headers</p>&#xA;"
49264474,"Can you use Windows to develop, build, and publish .NET Core 2.0 services for a Ubuntu based Service Fabric Cluster?",2018-03-13 19:33:21,<azure><microservices><azure-service-fabric><service-fabric-stateless><service-fabric>,1,40,0,0.0,0,"<p>I would like to build .NET Core 2.0 services for a Ubuntu based Service Fabric on my windows machine. From the docs, it seems like I can't use Visual Studios to do this.</p>&#xA;&#xA;<p>Does anyone know the workflow for developing, building, and publishing services in this way? Can't find anything in the docs.</p>&#xA;"
49345233,Amazon States Language - Global and transaction cache,2018-03-18 06:48:49,<amazon-web-services><caching><microservices><aws-step-functions>,1,63,0,0.0,0,"<p>In a flow-based application development system, two levels of cache exist. First, a cache for the transaction that is currently triggered due to an input. This cache is destroyed as soon as transaction ends - either successfully or with a failure.</p>&#xA;&#xA;<p>Second, a cache for all transactions that could possibly happen. This cache is created at the state machine start-up time and is destroyed at the termination of state machine.</p>&#xA;&#xA;<p>It is a bit of an overhead to maintain a cache (with any of the Elastic Cache services) than having the state machine itself provide with such features. My earliest programming experience was with IBM CICS product and they have work areas at global (<a href=""https://www.ibm.com/support/knowledgecenter/en/SSGMGV_3.1.0/com.ibm.cics.ts31.doc/dfhp3/dfhp36q.htm"" rel=""nofollow noreferrer"">CWA</a>) and at a transaction level (<a href=""https://www.ibm.com/support/knowledgecenter/en/SSGMCP_4.2.0/com.ibm.cics.ts.applicationprogramming.doc/topics/dfhp3_concepts_twa.html"" rel=""nofollow noreferrer"">TWA</a>). Not exactly a micro-services orchestration engine, but, definitely very handy in keeping track of transactions or the overall system itself.</p>&#xA;&#xA;<p>Does <a href=""https://aws.amazon.com/step-functions/"" rel=""nofollow noreferrer"">AWS Step Functions</a> have such features? Can <a href=""https://states-language.net/spec.html"" rel=""nofollow noreferrer"">state definitions</a> help?</p>&#xA;"
49324723,"Combining SpringBoot, Zuul and Eureka but bind Services to Localhost",2018-03-16 15:45:57,<microservices><netflix-zuul><netflix-eureka><netflix>,1,327,0,0.0,0,"<p>I have set up Zuul for routing and Eureka for service discovery, which works fine. Before setting up Eureka, I used <code>server.address=127.0.0.1</code> to bind my actual service to <code>localhost</code> so that they could only be accessed from within the Api gateway.</p>&#xA;&#xA;<p>When combining Zuul and Eureka, <code>server.address=127.0.0.1</code> does not work anymore. I cannot access my actual REST endpoints, neither from within my network nor from the outside.</p>&#xA;&#xA;<p><strong>application.properties of my Eureka service discovery:</strong></p>&#xA;&#xA;<pre><code>spring.application.name=service-discovery&#xA;server.port=8761&#xA;eureka.client.registerWithEureka=false&#xA;eureka.client.fetchRegistry=false&#xA;</code></pre>&#xA;&#xA;<p><strong>application.properties of my Zuul API gateway:</strong></p>&#xA;&#xA;<pre><code>spring.application.name=api-gateway&#xA;zuul.prefix=/api&#xA;server.port=8080&#xA;&#xA;ribbon.eureka.enabled=true&#xA;eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/&#xA;&#xA;zuul.routes.library.path=/library/**&#xA;zuul.routes.library.serviceId=library&#xA;</code></pre>&#xA;&#xA;<p><strong>application.properties of my actual REST service:</strong></p>&#xA;&#xA;<pre><code>spring.application.name=library&#xA;server.servlet.context-path=/library&#xA;server.port=8090&#xA;server.address=127.0.0.1&#xA;&#xA;ribbon.eureka.enabled=true&#xA;eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/&#xA;</code></pre>&#xA;&#xA;<p>When I remove <code>server.address=127.0.0.1</code> from the REST service's properties file, I can of course access the resource - But also from without <code>localhost</code>, which is not what I want.</p>&#xA;&#xA;<p>So what I try to achieve is that my little microservices can only be accessed from within <code>localhost</code> (after the request has passed the Zuul API gateway). Furthermore I want to use Eureka for service discovery and for having the chance to provide second instances of serives.</p>&#xA;"
49284804,Understanding Microservice Architecture,2018-03-14 18:02:37,<spring><mongodb><docker><jar><microservices>,3,74,0,0.0,0,"<p>Since I am trying hard to understand the microservice architecture pattern for some work, I came across the following question:</p>&#xA;&#xA;<p>It's always said that a microservice usually has its own database. But does this mean that it always has to be on the same server or container (for example having <strong>one</strong> docker container that runs a MongoDB and my JAR)? Or can this also mean that on one server my JAR is running while my MongoDB is located somewhere else (so <strong>two</strong> containers for example)?</p>&#xA;&#xA;<p>If the first one is correct (JAR <strong>and</strong> database within <strong>one</strong> container), how can I prevent that after some changes regarding my application and after a new deployment of my JAR my data of the MongoDB is resetted (since a whole new container is now running)?</p>&#xA;&#xA;<p>Thanks a lot already :-)</p>&#xA;"
49349235,"Micro-services architecture, need advise",2018-03-18 14:48:43,<microservices>,5,104,0,1.0,0,"<p>We are working on a system that is supposed to 'run' jobs on distributed systems.</p>&#xA;&#xA;<p>When jobs are accepted they need to go through a pipeline before they can be executed on the end system.</p>&#xA;&#xA;<p>We've decided to go with a micro-services architecture but there one thing that bothers me and i'm not sure what would be the best practice.</p>&#xA;&#xA;<p>When a job is accepted it will first be persisted into a database, then - each micro-service in the pipeline will do some additional work to prepare the job for execution.</p>&#xA;&#xA;<p>I want the persisted data to be updated on each such station in the pipeline to reflect the actual state of the job, or the its status in the pipeline.</p>&#xA;&#xA;<p>In addition, while a job is being executed on the end system - its status should also get updated.</p>&#xA;&#xA;<p>What would be the best practice in sense of updating the database (job's status) in each station:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each such station (micro-service) in the pipeline accesses the database directly and updates the job's status</p></li>&#xA;<li><p>There is another micro-service that exposes the data (REST) and serves as DAL, each micro-service in the pipeline updates the job's status through this service</p></li>&#xA;<li><p>Other?....</p></li>&#xA;</ol>&#xA;&#xA;<p>Help/advise would be highly appreciated.</p>&#xA;&#xA;<p>Thanx a lot!!</p>&#xA;"
49421760,Laravel Microservices & RabbitMQ,2018-03-22 06:14:26,<laravel><rabbitmq><microservices>,1,150,0,0.0,0,"<p>Just wondering what the best way of capturing ""fanout"" calls from RabbitMQ is in Laravel subscriber services? </p>&#xA;&#xA;<p>Service 1 sends out the message, say UserUpdated with their UUID, and this goes into RabbitMQ now. </p>&#xA;&#xA;<p>Service 2/3/4/n capture UserUpdated and perform their appropriate actions.</p>&#xA;&#xA;<p>I just don't know the best way to have a long running service on the Laravel subscribers to catch these messages and perform their own actions. I've tried multiple packages on GitHub so far but none go into this detail of where to place a class to receive the messages. </p>&#xA;&#xA;<p>All help is much appreciated. </p>&#xA;"
49334373,AmqpConnectException: ConnectException: Connection refused: connect,2018-03-17 09:16:50,<microservices><spring-cloud><spring-cloud-stream><spring-kafka><spring-rabbitmq>,1,159,0,0.0,0,"<p>Trying out Spring Cloud to send messages to RabbitMQ following a tutorial by Josh Long on Youtube. </p>&#xA;&#xA;<p><strong>OS: Windows</strong></p>&#xA;&#xA;<p>GIT URL:&#xA;<a href=""https://github.com/joshlong/bootiful-microservices/tree/master/bootiful-microservices-edgware"" rel=""nofollow noreferrer"">https://github.com/joshlong/bootiful-microservices/tree/master/bootiful-microservices-edgware</a></p>&#xA;&#xA;<p>I imported the reservation-client, eureka-service, config-service. I was successfully able to start up all the services. </p>&#xA;&#xA;<p>Every time I hit the service with a JSON payload, I am getting the below error message. </p>&#xA;&#xA;<p>Input URL: <a href=""http://localhost:9999/reservations"" rel=""nofollow noreferrer"">http://localhost:9999/reservations</a>&#xA;Body: <code>{""reservationName"":""Dr.Who""}</code></p>&#xA;&#xA;<p>Output JSON: </p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1521277278436,&#xA;    ""status"": 500,&#xA;    ""error"": ""Internal Server Error"",&#xA;    ""exception"": ""org.springframework.amqp.AmqpConnectException"",&#xA;    ""message"": ""java.net.ConnectException: Connection refused: connect"",&#xA;    ""path"": ""/reservations""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am getting the below error in the console. </p>&#xA;&#xA;<pre><code>2018-03-17 02:00:43.401  INFO [reservation-client,,,] 6188 --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9999&#xA;2018-03-17 02:00:43.408  INFO [reservation-client,,,] 6188 --- [           main] c.example.ReservationClientApplication   : Started ReservationClientApplication in 36.047 seconds (JVM running for 36.941)&#xA;2018-03-17 02:01:15.851  INFO [reservation-client,,,] 6188 --- [nio-9999-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'&#xA;2018-03-17 02:01:15.854  INFO [reservation-client,,,] 6188 --- [nio-9999-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started&#xA;2018-03-17 02:01:16.034  INFO [reservation-client,,,] 6188 --- [nio-9999-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 180 ms&#xA;2018-03-17 02:01:16.116  WARN [reservation-client,65c06760307f62f8,65c06760307f62f8,true] 6188 --- [nio-9999-exec-1] o.s.c.n.zuul.web.ZuulHandlerMapping      : No routes found from RouteLocator&#xA;2018-03-17 02:01:18.316 ERROR [reservation-client,65c06760307f62f8,65c06760307f62f8,true] 6188 --- [nio-9999-exec-1] o.s.c.sleuth.instrument.web.TraceFilter  : Uncaught exception thrown&#xA;&#xA;org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused: connect&#xA;    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:982) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;    at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;    at javax.servlet.http.HttpServlet.service(HttpServlet.java:661) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;    at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.23.jar:8.5.23]&#xA;    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;    at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;</code></pre>&#xA;&#xA;<p>I am getting a connection error even if I use Kafka, instead of RabbitMQ binder. </p>&#xA;&#xA;<p>Can somebody help? All the examples seemed to have been implemented on unix based platform. Please help.</p>&#xA;"
49384819,Best practice for implementing an Aggrregation Microservice within an API Gateway and using service discovery,2018-03-20 12:56:06,<microservices><service-discovery><api-gateway>,1,106,2,0.0,0,"<p>We are currently studying the possibility of transforming our existing monolith application into fine-grained Microservices running along an API gateway for coordination.</p>&#xA;&#xA;<p>I have this case where there are three microservices:</p>&#xA;&#xA;<p>1- Product Microservice: A REST API service for products.&#xA;2- Category Microservice: A REST API service for categories.&#xA;3- Aggregation Microservice: A REST API service which joins between a list of categories and their products and then return them into one model.</p>&#xA;&#xA;<p>According to the attached image, any client can send a request to the API Gateway specifying which microservice he wants to retrieve information from in addition to all request options like HTTP method and request body.</p>&#xA;&#xA;<p>The API gateway will receive the client's request and use service discovery reroute it to the designated microservice.</p>&#xA;&#xA;<p>My question is, what if the client tries to contact the aggregation microservice? This will result in a request to the API gateway and then the API gateway will reroute to the aggregation service. However, the aggregation service needs to contact both category and product services in order to reply back to the client with a unified model. This requires the aggregation microservice to also contact the API gateway again so it can reroute its requests to the category and product microservices.</p>&#xA;&#xA;<p>There seem to be a lot of communication traffic occurring here, am I missing something here or this is the right way to implement such scenario.</p>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/bHj2D.jpg"" rel=""nofollow noreferrer"">API Gateway Example</a></p>&#xA;"
49353369,Microservices and messaging,2018-03-18 22:16:25,<microservices><messaging>,1,43,3,0.0,0,<p>I'm in the process of restructuring my first application to use microservices and messaging using an event driven architecture. I will have a content microservice to retrieve content from various sources and add to a message queue for processing. My query is that should the content microservice store the content in its own database as well or is that redundant as I am using messaging?  </p>&#xA;
49390064,Is it possible to create an exposed kubernetes service based on a new deployment in one command?,2018-03-20 16:57:44,<kubernetes><containers><cluster-computing><microservices>,1,23,5,0.0,0,<p>I feel this must be possible but haven't managed to find docs on how to do this.</p>&#xA;&#xA;<p>I would ideally like to add service exposure details in a deployment yaml file and the service would come up with a host name and port upon the issuing of a create command with the deployment yaml. </p>&#xA;
50074667,Docker for linux is giving error,2018-04-28 08:50:47,<docker><microservices><core>,1,16,0,0.0,0,"<p>I am new learner for Docker.I have a very simple question.&#xA;I want my application to work on Linux system but I am writing application in Windows.So do I need to install Docker for Windows or Linux?</p>&#xA;&#xA;<p>If I run using Docker for Linux,i am not getting option to run in windows and it is getting failed(I understand it might be some other unrelated error) but I need to confirm if my approach is correct or not.</p>&#xA;&#xA;<p>Am I right in installing Docker for Linux?&#xA;Also,in case I plan to move to AWS, what docker I need in that case.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50066231,Best strategy to dockerize Java with Angular JS applications,2018-04-27 16:00:36,<docker><continuous-integration><microservices><continuous-deployment><continuous-delivery>,1,24,0,0.0,0,<p>I have a java/AngularJS project that needs to be dockerize for CI/CD process. My project is as below:</p>&#xA;&#xA;<pre><code>   Project:&#xA;      UI - Angular/Node JS&#xA;      Java - Project ABC: &#xA;                  -- Branch: Master&#xA;                               -- Service 1 (.jar/war)&#xA;                               -- Service 2 (.jar)&#xA;                               -- Service 3 (.jar)&#xA;</code></pre>&#xA;&#xA;<p>Should I put all jar/war files into one container/volume? I would like to automate the process as much as possible using CI/CD tools. Any suggestions would be appreciated. Thanks.</p>&#xA;
50076257,Keeping data layer as separate deployments,2018-04-28 11:52:40,<architecture><cloud><microservices>,1,27,0,0.0,0,"<p>Is there a name for this architectural style in which data is stripped out of a service into separate deployments? Or does it resemble something?</p>&#xA;&#xA;<ol>&#xA;<li>Every bounded context is composed of UI, one or several business services (BS) and one or several internal data providers (DP).</li>&#xA;<li>BS are stateless and are not allowed to store data anywhere else than via REST API exposed by their DP. They must not ""talk"" to any other service.</li>&#xA;<li>DP can use namespaces in databases running in a corporate cloud (for instance keyspace in Cassandra).</li>&#xA;<li>DP may talk to external services (outside bounded context) through their gateways.</li>&#xA;</ol>&#xA;&#xA;<p>I can see lots of problems in here and not that many benefits. Could you provide your non-biased opinion on this?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/3dMs2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3dMs2.png"" alt=""Architecture""></a></p>&#xA;"
49980008,Can we have two or more container running on docker at the same time,2018-04-23 11:28:15,<docker><containers><microservices>,2,539,0,0.0,0,"<p>I have not done any practical with the docker and container, But as per my knowledge. </p>&#xA;&#xA;<p>As per the documents available online I did not get the details about the running two or more containers at the same time.</p>&#xA;&#xA;<p>Docker allows container to map port address of container to the host machine.&#xA;Now, the question is can we run multiple container at the same time on docker? if yes then if two containers are mapped to same port number then how does the port is handled in this case?</p>&#xA;&#xA;<p>Also out of curiosity, can two containers on docker communicate with each other?</p>&#xA;"
50065026,How Amazon Elastic Container Service is Different from Kubernetes when we want to deploy our dockerize application over it?,2018-04-27 14:53:12,<docker><kubernetes><microservices><amazon-ecs>,1,28,0,1.0,0,<p>I am planning to start my project but a bit confuse between choosing Amazon ECS and Kubernetes perhaps I am really a beginner  with Micro-services architecture.</p>&#xA;&#xA;<p>I would really appreciate if someone can show some path for deploying my docker container on a fast easier to handle platform.</p>&#xA;&#xA;<p>Thanks </p>&#xA;
50070895,Getting response for user-initiated action from microservices with asynchronous communication,2018-04-27 22:09:25,<asynchronous><architecture><microservices>,1,35,0,0.0,0,"<p>I'm not sure how to put this into words well, so here's a (rather common) example.</p>&#xA;&#xA;<p>Say a user is using our blog service and clicks the ""Save"" button to publish his awesome blog post.&#xA;Now a common user story would be, he will be notified of his action's result - a notification like ""Successfully published!"" or ""An error occurred. Please try again."".</p>&#xA;&#xA;<p>In a synchronous world, this is not hard - you send a request to the server, wait for a response, and based on the response show a notification.</p>&#xA;&#xA;<p>But let's imagine our server is in microservice oriented architecture, leveraging asynchronous communication; we use a message queue for example. An API gateway microservice takes a request from front-end, publishes its message into the queue. Then a ""consumer"" microservice sends the result of the consumed message to the front-end.&#xA;What's a good way to give back the result of user action in this case?&#xA;If we set up a websocket session to take such responses for example, the code to initiate user action and the code to give feedback for user action would end up being completely separate, although it happens in the same user workflow. Is this a sensible idea? Or I'm missing some fundamental ideas here?</p>&#xA;"
50025857,"Optimistic Lock Mechanism in Event Sourcing ""UNDO"" flow",2018-04-25 15:16:41,<java><domain-driven-design><microservices><event-sourcing><optimistic-locking>,1,51,0,0.0,0,"<p>I have been asking a lot of questions on event sourcing so apologies on that but I would like to nail this right from the get go.</p>&#xA;&#xA;<h2><strong>SETUP</strong></h2>&#xA;&#xA;<pre><code>| p_key | invoice_id | EmployeeId | Event type        | Version | Data |&#xA;|-------|------------|------------|-------------------|---------|------|&#xA;| 1     | 12345      | E456       | Invoice_Generated | 1       | JSON |&#xA;| 2     | 12345      | E567       | Invoice_Reviewed  | 2       | JSON |&#xA;| 3     | 12345      | E456       | Invoice_Paid      | 3       | JSON |&#xA;| 4     | 12345      | E142       | Invoice_Comment   | 4       | JSON |&#xA;| 5     | 12345      | E412       | Invoice_Comment   | 5       | JSON |&#xA;| 6     | 12346      | E999       | Invoice_Paid      | 7       | JSON |&#xA;| 7     | 12345      | E456       | Invoice_Refunded  | 8       | JSON |&#xA;</code></pre>&#xA;&#xA;<p>I am assuming the invoiceId is the aggregate . Since the version numbers will increment for every change made to invoice.</p>&#xA;&#xA;<p><strong>Use Case:</strong></p>&#xA;&#xA;<p>The event store contains all events applied on invoice and also contains info on which employee applied it. In the current scenario an invoice is generated,reviewed,paid. Someone noticed some issue made a few comments and then we decide to post a new payment before we refunded the old one[the event that is being undone is earlier in history].</p>&#xA;&#xA;<p><strong>API CALL:</strong></p>&#xA;&#xA;<p>refund/invoice/{invoiceid}/{employeeid}</p>&#xA;&#xA;<p><strong>FLOW OF THINGS</strong></p>&#xA;&#xA;<p>Option 1</p>&#xA;&#xA;<ul>&#xA;<li>Retrieve all events for a given invoice </li>&#xA;<li>Save all events in event stream with the latest version saved.</li>&#xA;<li>Loop through all events to find the required instance of event.</li>&#xA;<li>Apply an ""UNDO"" action on that event and give it version number of (latest+1) </li>&#xA;<li>make a call to database to check the latest version in event store. Validate it is same as that saved in Event Stream.</li>&#xA;<li>Ensure that the new event is larger than last version in stream. We assume that is it also a higher version that ""DO ACTION"".</li>&#xA;</ul>&#xA;&#xA;<p><strong>ISSUES</strong></p>&#xA;&#xA;<ul>&#xA;<li>Retrieving and saving all events in application every time can start to get expensive.</li>&#xA;<li>Seems like a hell lot of work for just ""UNDO"" action.</li>&#xA;</ul>&#xA;&#xA;<p><strong>OPTION 2:</strong></p>&#xA;&#xA;<ul>&#xA;<li>I make 2 calls to database &#xA;&#xA;<ol>&#xA;<li>Call to get event based on invoice Id and employeeId</li>&#xA;<li>Call to get latest version of last event applied on invoice.</li>&#xA;</ol></li>&#xA;<li>Undo changes based on data in event </li>&#xA;<li>Create an ""UNDO"" event with version no 1 greater than latest.</li>&#xA;<li>make another call to  database to get the latest version again.</li>&#xA;<li>ensure the ""UNDO"" version is exactly  1 greater than latest version</li>&#xA;</ul>&#xA;&#xA;<p><strong>ISSUES</strong></p>&#xA;&#xA;<p>Not sure if this is right. Should we have things added to event stream multiple times.</p>&#xA;&#xA;<p>Also is it okay to query event database twice once with only invoice id and once with invoice id and employee id</p>&#xA;&#xA;<p>Please let me know if I am missing something or if my version style is wrong or if my assumption of aggregate is wrong.</p>&#xA;"
49931495,About gRPC Capacity/Adjustment,2018-04-19 23:02:04,<java><microservices><grpc><grpc-java>,2,55,0,0.0,0,"<p>I am running a micro service using gRPC, and got many onError() call-backs on the client side from the server.</p>&#xA;&#xA;<p>t.printStackTrace() shows:</p>&#xA;&#xA;<pre><code>io.grpc.StatusRuntimeException: UNKNOWN&#xA;    at io.grpc.Status.asRuntimeException(Status.java:526)&#xA;    at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)&#xA;    at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)&#xA;    at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:339)&#xA;    at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:443)&#xA;    at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)&#xA;    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:525)&#xA;    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:446)&#xA;    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:557)&#xA;    at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)&#xA;    at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:107)&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&#xA;    at java.lang.Thread.run(Thread.java:748)&#xA;</code></pre>&#xA;&#xA;<p>The Exception will go away if I shut down all connections except a test client.</p>&#xA;&#xA;<p>So, I am wondering if there are any limitations (on the server side) about the MAX numbers of instances of the:</p>&#xA;&#xA;<pre><code>io.grpc.ManagedChannel&#xA;io.grpc.stub.StreamObserver &#xA;</code></pre>&#xA;&#xA;<p>If there are some, how can I adjust/enlarge them?</p>&#xA;&#xA;<p>Any help will be appreciated. </p>&#xA;"
50006750,SNAPSHOT + Event sourcing,2018-04-24 16:32:44,<java><microservices><snapshot><event-sourcing>,2,91,0,0.0,0,"<p>The devil is in the details. I am looking into implementing event sourcing on existing catering application. I have an invoice which can be associated to a company,dept in company or employee in company.</p>&#xA;&#xA;<h1><strong>Setup</strong></h1>&#xA;&#xA;<p><strong>Use case:</strong></p>&#xA;&#xA;<ul>&#xA;<li>The company is sponsoring an event and has paid for the food.</li>&#xA;<li>There are clients coming in to visit a company dept and they have ordered food.</li>&#xA;<li>There is cafeteria and employee orders food. The company pays us but still needs to bill employee.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Domain Model</strong></p>&#xA;&#xA;<pre><code>Invoice&#xA;  -&gt; invoice Id&#xA;  -&gt; Status&#xA;  -&gt; CompanyId &#xA;  -&gt; DeptId  &#xA;  -&gt; EmployeeId &#xA;  -&gt; Balance&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li>Only companyId populated (bill company)</li>&#xA;<li>companyId + deptId (bill dept)</li>&#xA;<li>companyUd + deptId + employeeId (bill person)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Relation Table</strong></p>&#xA;&#xA;<pre><code>| p_key | invoice_id | Reltn_Table | Reltn_id |&#xA;|-------|------------|-------------|----------|&#xA;| 1     | 12345      | Company     | 245242   |&#xA;| 2     | 67890      | Company     | 1241243  |&#xA;| 3     | 79166      | Dept        | 534214   |&#xA;| 4     | 792131     | Dept        | 412213   |&#xA;| 5     | 489965     | Employee    | 412323   |&#xA;</code></pre>&#xA;&#xA;<p>Assume that the dept and employee table are somehow related to the company table.</p>&#xA;&#xA;<p>I have another Event Source Table with Domain Model as <strong>INVOICE</strong>.</p>&#xA;&#xA;<p><strong>Event Store Table.</strong></p>&#xA;&#xA;<pre><code>| event_id | invoice_id | Event            | Payload |&#xA;|----------|------------|------------------|---------|&#xA;| 1        | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>The rest service sometimes passes in either the employee,dept or employee id to apply updates to invoice. </p>&#xA;&#xA;<h2>QUESTION</h2>&#xA;&#xA;<p>I wanted to see if there is a way for event store to handle scenario where it does not need to query the relation table to retrieve the invoice/invoices and then apply events to it. </p>&#xA;&#xA;<p>I was initially leaning towards having snapshot of domain model but the problem still remains since the dept or companyId is in JSON I cannot run retrieve events based on that.</p>&#xA;&#xA;<p>No matter what way I see I will have make a call to retrieve invoice/invoices before I can apply event or do anything .Is there anything I am missing that will help me get rid of the <strong>Relational Table</strong> or that is a dream of the fools? </p>&#xA;&#xA;<p><strong>Also a side question</strong></p>&#xA;&#xA;<p>SNAPSHOTS are saved in same table as the event store correct ? The event type is SNAPSHOT right ? Please correct me if I am wrong on that  </p>&#xA;"
50051429,Asynchronous request/response pattern?,2018-04-26 20:35:54,<spring-boot><asynchronous><apache-kafka><microservices>,1,142,0,0.0,0,"<p>I am fairly new to microservices and asynchronous architectures and I am wondering how typical request/response works in such environments.</p>&#xA;&#xA;<p>Example 1:</p>&#xA;&#xA;<ol>&#xA;<li>Say I have a web app that sends POST request to /example/doStuff and expects a response letting it know if that request was completed successfully or not.</li>&#xA;<li>Microservice A's api handling /doStuff has logic that says whenever /doStuff is requested, send a doStuffInitiated event message to the message broker.</li>&#xA;<li>As a result of doStuffInitiated event, microservice B and C react to this message by setting a flag in a db, etc, and produce doStuffCompleted message to the broker</li>&#xA;<li><strong>This where I am stuck</strong>: Is there a way to make microservice A wait for doStuffCompleted to be consumed before sending a response back to the web app that made the original request?  Is that even the right way to go about this?</li>&#xA;</ol>&#xA;&#xA;<p>Example 2:</p>&#xA;&#xA;<ol>&#xA;<li>Client facing web app makes GET request to <strong>/example/getStuff</strong></li>&#xA;<li>Microservice A api handles getStuff by sending <strong>stuffRequested</strong> event to kafka.</li>&#xA;<li>In order to get the data to return a ""stuff"" object, data is required from 2 external data sources.  Microservice B is in charge of handling these 2 data sources, so it consumes the <strong>stuffRequested</strong> event, gets the data from the 2 data sources, and sends <strong>stuffRequestCompleted</strong> event (with the ""stuff"" data in the payload) for microservice A to consume so it can return the ""stuff"" object to the client app.</li>&#xA;<li><strong>This where I am stuck</strong>: With all of this going on in the background asynchronously, how can I ""suspend"" sending back a response until I can consume <strong>stuffRequestCompleted</strong> and send back the requested data?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you in advance.</p>&#xA;"
50064156,Continuous Delivery - Microservices Release/Versioning,2018-04-27 14:06:38,<docker><jenkins><microservices><continuous-delivery><kubernetes-helm>,2,175,0,0.0,0,"<p>We are developing Microservices using Spring Boot which are than packaged up as Helm Charts and deployed onto a Kubernetes cluster. Each service has a Jenkinsfile and we have been releasing each service individually below:</p>&#xA;&#xA;<ul>&#xA;<li>Service A --> Build --> Package --> QA --> Staging --> Production</li>&#xA;<li>Service B --> Build --> Package --> QA --> Staging --> Production</li>&#xA;<li>Service C --> Build --> Package --> QA --> Staging --> Production</li>&#xA;</ul>&#xA;&#xA;<p>This approach is fairly straight forward but it doesn't actually give you a shippable artifact and you end up with inconsistencies.</p>&#xA;&#xA;<p>What we would like to do is group the release using an umbrella Helm chart shown below (Parent A):</p>&#xA;&#xA;<ul>&#xA;<li>Parent A --> Build --> Package --> QA --> Staging --> Production&#xA;&#xA;<ul>&#xA;<li>Service A</li>&#xA;<li>Service B</li>&#xA;<li>Service C</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I'm struggling to think of a way to do this without having to manually release each service, then update the versions in the parent chart. Is anyone doing this in an automated way?</p>&#xA;"
50070987,SAM Template: multiple microservice lambdas sharing a single AWS::ApiGateway::DomainName,2018-04-27 22:21:36,<aws-lambda><microservices><aws-api-gateway><aws-sam-local>,1,212,0,0.0,0,"<p>My goal is allow several independent lambda resources (microservices) to share a common custom domain for test environment. Using the below template, deploying microservice #1 went off without issue. However, when deploying microservice #2, CloudFormation fails and rolls back because the domain name is assigned to microservice #1.</p>&#xA;&#xA;<p>Surely it must be possible to share a common custom domain among several microservices with unique paths?</p>&#xA;&#xA;<p>Service #1 template.yaml</p>&#xA;&#xA;<pre><code>Resources:&#xA;  ApiGatewayApi:&#xA;    Type: AWS::Serverless::Api&#xA;    Properties:&#xA;      StageName: !Sub ${apiGatewayStageName}&#xA;      DefinitionBody:&#xA;        swagger: ""2.0""&#xA;        info:&#xA;          title: !Sub ${functionName}&#xA;        paths:&#xA;          ""/service_one"":&#xA;            post:&#xA;              responses: {}&#xA;              x-amazon-apigateway-integration:&#xA;                uri: !Sub ""arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${functionName}:live/invocations""&#xA;                httpMethod: POST&#xA;                type: aws_proxy&#xA;&#xA;  ApiGatewayCustomDomainName:&#xA;    Type: AWS::ApiGateway::DomainName&#xA;    Properties:&#xA;      CertificateArn: !Sub ""arn:aws:acm:${AWS::Region}:${AWS::AccountId}:certificate/${apiGatewayCDNCertificateId}""&#xA;      DomainName: !Sub ""${envName}.${apiGatewayCustomDomainNameSuffix}""&#xA;    DependsOn:&#xA;      - ""LogsSubscriptionFilter""&#xA;      - ""ApiGatewayApi""&#xA;&#xA;  ApiGatewayBasePathMapping:&#xA;    Type: AWS::ApiGateway::BasePathMapping&#xA;    Properties:&#xA;      DomainName: !Ref ApiGatewayCustomDomainName&#xA;      RestApiId: !Ref ApiGatewayApi&#xA;      Stage: !Ref apiGatewayStageName&#xA;    DependsOn: ""ApiGatewayCustomDomainName""&#xA;</code></pre>&#xA;&#xA;<p>The Service #2 template is the same, except with a different path (.e.g. <code>/service_two</code>.</p>&#xA;"
50089242,Maven dependencies incompatibility when using spring cloud and spring boot 2.0.1,2018-04-29 17:10:16,<java><spring-boot><microservices><spring-cloud><pivotal-cloud-foundry>,1,294,1,1.0,0,"<p>my code is as below when I try to start the application. I see a lot of spring exceptions which seeks like dependencies issues.I used spring initializer to generate the application and using springboot 2.0.1. Please help in getting the appropriate configuration to work with pivotal cloud foundy service registry and discovery, this is happening when I try to use circuit breaker as well </p>&#xA;&#xA;<p>consolelog is as follows:</p>&#xA;&#xA;<pre><code>2018-04-29 12:05:00.512  INFO 17300 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@17497425: startup date [Sun Apr 29 12:05:00 CDT 2018]; root of context hierarchy&#xA;2018-04-29 12:05:00.970  INFO 17300 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2018-04-29 12:05:01.017  INFO 17300 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$aa3e011e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v2.0.1.RELEASE)&#xA;&#xA;2018-04-29 12:05:01.625  INFO 17300 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://localhost:8888&#xA;2018-04-29 12:05:02.767  WARN 17300 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""http://localhost:8888/message-generation/default"": Connection refused: connect; nested exception is java.net.ConnectException: Connection refused: connect&#xA;2018-04-29 12:05:02.778  INFO 17300 --- [           main] c.p.H.R.RestServiceProducerApplication   : No active profile set, falling back to default profiles: default&#xA;2018-04-29 12:05:02.800  INFO 17300 --- [           main] ConfigServletWebServerApplicationContext : Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3f390d63: startup date [Sun Apr 29 12:05:02 CDT 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@17497425&#xA;2018-04-29 12:05:03.463 ERROR 17300 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xA;&#xA;java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration.authenticationEventPublisher&#xA;    at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:64) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:108) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:179) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:141) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:117) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:328) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:233) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:93) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:694) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:395) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at com.poc.HystrixCircuitBreaker.RestServiceProducer.RestServiceProducerApplication.main(RestServiceProducerApplication.java:12) [classes/:na]&#xA;Caused by: java.lang.IllegalStateException: Failed to introspect Class [org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration] from ClassLoader [sun.misc.Launcher$AppClassLoader@6d06d69c]&#xA;    at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:659) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:556) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:541) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:599) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:724) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:665) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:633) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1489) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1012) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.addBeanTypeForNonAliasDefinition(BeanTypeRegistry.java:164) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.addBeanType(BeanTypeRegistry.java:153) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.updateTypesIfNecessary(BeanTypeRegistry.java:203) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.getNamesForType(BeanTypeRegistry.java:115) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.OnBeanCondition.collectBeanNamesForType(OnBeanCondition.java:265) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getBeanNamesForType(OnBeanCondition.java:254) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchingBeans(OnBeanCondition.java:196) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:116) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:47) ~[spring-boot-autoconfigure-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    ... 17 common frames omitted&#xA;Caused by: java.lang.NoClassDefFoundError: org/springframework/security/web/access/WebInvocationPrivilegeEvaluator&#xA;    at java.lang.Class.getDeclaredMethods0(Native Method) ~[na:1.8.0_161]&#xA;    at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) ~[na:1.8.0_161]&#xA;    at java.lang.Class.getDeclaredMethods(Class.java:1975) ~[na:1.8.0_161]&#xA;    at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:641) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    ... 34 common frames omitted&#xA;Caused by: java.lang.ClassNotFoundException: org.springframework.security.web.access.WebInvocationPrivilegeEvaluator&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_161]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_161]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338) ~[na:1.8.0_161]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_161]&#xA;    ... 38 common frames omitted&#xA;&#xA;2018-04-29 12:05:03.464  INFO 17300 --- [           main] ConfigServletWebServerApplicationContext : Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3f390d63: startup date [Sun Apr 29 12:05:02 CDT 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@17497425&#xA;2018-04-29 12:05:03.466  WARN 17300 --- [           main] o.s.boot.SpringApplication               : Unable to close ApplicationContext&#xA;&#xA;java.lang.IllegalStateException: Failed to introspect Class [org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration] from ClassLoader [sun.misc.Launcher$AppClassLoader@6d06d69c]&#xA;    at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:659) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:556) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:541) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:599) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:724) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:665) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:633) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1489) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:420) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:390) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:511) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:503) ~[spring-beans-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1198) ~[spring-context-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.getExitCodeFromMappedException(SpringApplication.java:889) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.getExitCodeFromException(SpringApplication.java:875) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.handleExitCode(SpringApplication.java:861) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:810) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) [spring-boot-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at com.poc.HystrixCircuitBreaker.RestServiceProducer.RestServiceProducerApplication.main(RestServiceProducerApplication.java:12) [classes/:na]&#xA;Caused by: java.lang.NoClassDefFoundError: org/springframework/security/web/access/WebInvocationPrivilegeEvaluator&#xA;    at java.lang.Class.getDeclaredMethods0(Native Method) ~[na:1.8.0_161]&#xA;    at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) ~[na:1.8.0_161]&#xA;    at java.lang.Class.getDeclaredMethods(Class.java:1975) ~[na:1.8.0_161]&#xA;    at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:641) ~[spring-core-5.0.5.RELEASE.jar:5.0.5.RELEASE]&#xA;    ... 20 common frames omitted&#xA;Caused by: java.lang.ClassNotFoundException: org.springframework.security.web.access.WebInvocationPrivilegeEvaluator&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_161]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_161]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338) ~[na:1.8.0_161]&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_161]&#xA;    ... 24 common frames omitted&#xA;&#xA;&#xA;&#xA;//pom.xml&#xA;&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0""&#xA;    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.poc.HystrixCircuitBreaker&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;RestServiceProducer&lt;/artifactId&gt;&#xA;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;    &lt;name&gt;RestServiceProducer&lt;/name&gt;&#xA;    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud-services.version&gt;2.0.0.M1&lt;/spring-cloud-services.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.pivotal.spring.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-services-starter-config-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.pivotal.spring.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-services-starter-service-registry&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;io.pivotal.spring.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-services-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud-services.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;repositories&gt;&#xA;        &lt;repository&gt;&#xA;            &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;            &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;            &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;            &lt;snapshots&gt;&#xA;                &lt;enabled&gt;false&lt;/enabled&gt;&#xA;            &lt;/snapshots&gt;&#xA;        &lt;/repository&gt;&#xA;    &lt;/repositories&gt;&#xA;&#xA;&#xA;&lt;/project&gt;&#xA;&#xA;//Config class&#xA;package com.poc.HystrixCircuitBreaker.RestServiceProducer;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;public class RestServiceProducerApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(RestServiceProducerApplication.class, args);&#xA;    }&#xA;}&#xA;&#xA;//applicatoin.yml&#xA;spring:&#xA;  application:&#xA;    name: message-generation&#xA;&#xA;security:&#xA;  basic:&#xA;    enabled: false&#xA;&#xA;&#xA;&#xA;&#xA;  Please help me in this regards, I wanted to deploy this app into PCF&#xA;</code></pre>&#xA;"
50006860,How to access one application.properties in microservices,2018-04-24 16:38:53,<spring><microservices>,1,45,1,0.0,0,<p>how is the file application.properties handled in microservices? Is there a way to have one global application.properties file that all microservices can access?</p>&#xA;
49953536,How to initiate connection to aws sqs in golang,2018-04-21 07:44:51,<go><microservices><amazon-sqs>,1,112,1,0.0,0,"<p>I am building microservices application in golang, and each service talks to another service through sqs, however, i am having the difficulty to initiate the sqs connection when the server is up, so how do i initiate the sqs connection and use it in my service. building the service using go-kit so i have a file named service.go, main.go, endpoint.go and transport.go.</p>&#xA;&#xA;<p>basically i have the code for the connection</p>&#xA;&#xA;<pre><code>creds := credentials.NewStaticCredentials(aws_access_key_id, aws_secret_access_key, token)&#xA;    cfg := aws.NewConfig().WithRegion(""region"").WithCredentials(creds)&#xA;    service := sqs.New(session.New(), cfg)&#xA;    qURL := ""q_url""&#xA;&#xA;    receive_params := &amp;sqs.ReceiveMessageInput{&#xA;        QueueUrl:            aws.String(qURL),&#xA;        MaxNumberOfMessages: aws.Int64(1),&#xA;        VisibilityTimeout:   aws.Int64(30),&#xA;        WaitTimeSeconds:     aws.Int64(1),&#xA;    }&#xA;    receive_resp, err := service.ReceiveMessage(receive_params)&#xA;    if err != nil {&#xA;        log.Println(err)&#xA;    }&#xA;    fmt.Printf(""[Receive message] \n%v \n\n"", receive_resp)&#xA;    return true, nil&#xA;</code></pre>&#xA;&#xA;<p>so how do i initiate the connection and start getting the messages in my services. Thank you all.</p>&#xA;"
49887495,Are there Application Variables in Vertx?,2018-04-17 21:06:53,<java><microservices><vert.x>,1,36,2,0.0,0,"<p>I am looking to set custom objects in Application scope variables so that vertx has access to it across all micro-service requests. I couldn't find anything in Vertx documentation. In Java EE Servlet the code for similar feature is </p>&#xA;&#xA;<pre><code>getServletContext().getAttribute(""application_data"")&#xA;getServletContext().setAttribute(""application_data"", data);&#xA;</code></pre>&#xA;"
50067214,How to access domain models of microservices in web api controller,2018-04-27 17:06:44,<json><azure><swagger><microservices><azure-service-fabric>,1,47,2,0.0,0,"<p>I have a. Net core microservice project.&#xA;The architecture goes like below&#xA;1. Application Project&#xA;2. Service Project (WebApi project) &#xA;3. Microservices project &#xA;4. Interface layer</p>&#xA;&#xA;<p>Since data, code and config should be inside the microservices, i have added all the domain models inside microservice project. But i access these microservices using a controller in WebApi project through the interface using service proxy class. </p>&#xA;&#xA;<p>So my question is if my microservice is going to return Employee object, how should i add it as return type in my controller. Since controller has dependencies only to interface project and not the microservice project, i can't access the domain model. I end up creating another domain model in webapi project or use dynamic variable type as return type.</p>&#xA;&#xA;<p>Also swagger doesnt return model object format since i used dynamic variable. </p>&#xA;&#xA;<p>Is there any better way to do it.?</p>&#xA;"
49890971,What are some best practices for deploying multiple microservices at the same time?,2018-04-18 04:00:43,<amazon-web-services><elastic-beanstalk><microservices><continuous-deployment>,1,64,2,0.0,0,"<p>I have been struggling with the best way to deploy multiple microservices at the same time if there is a change that affects more than one service.</p>&#xA;&#xA;<p>While I'd be interested in any general approaches, let me provide a specific example I'm running into.</p>&#xA;&#xA;<p>Our company uses AWS and Elastic Beanstalk to deploy microservice containers for a web site that are relatively decoupled. Right now our web application consists of:</p>&#xA;&#xA;<ul>&#xA;<li><p>A SPA written in Angular, deployed and hosted in an S3 bucket (Call&#xA;it SPA)</p></li>&#xA;<li><p>A webapi service, written in .NET Core, dockerized, and deployed to&#xA;an elastic beanstalk application (Call it WebAPI) </p></li>&#xA;<li><p>An integration service, written in Node.JS, dockerized, and deployed&#xA;to an elastic beanstalk application (Call it IntService)</p></li>&#xA;</ul>&#xA;&#xA;<p>The SPA and WebAPI talk via a REST API</p>&#xA;&#xA;<p>The WebAPI and IntService are loosely coupled and talk to each other through an AWS SQS Queue. </p>&#xA;&#xA;<p>If we have a change to any one of these services, our deploy process is fairly straightforward. For example, if we have a change to the WebAPI, we spin up a new elastic beanstalk application environment, deploy there, then swap the URLs (so basic blue-green deployment).</p>&#xA;&#xA;<p>However, I'm struggling with the right approach if there is a change that affects multiple services. For example, say there is a feature that requires changes to both WebAPI and IntService. Since each of these live in their own repo, they each have their own CI and CD pipelines independent of each other. </p>&#xA;&#xA;<p>If just one service is deployed, the whole app might break. How do people handle this type of deploy? Do you clone both the WebAPI and IntService environments, deploy both of them, then swap both URLs, just making sure you do it at about the same time to minimize the window of time where only one service is active?</p>&#xA;&#xA;<p>Alternatively, we were looking at using an API gateway. But would that mean every time we wanted to deploy we'd create a new API gateway stage? If we do that, is the blue-green deployment 'swap' actually happening in the API Gateway?</p>&#xA;&#xA;<p>Sorry if this is confusing, but I'm just trying to wrap my head around what I have to imagine is a fairly common problem with microservices.</p>&#xA;"
50035311,Difference between saga and service bus?,2018-04-26 05:17:14,<microservices><azureservicebus><saga>,1,80,2,0.0,0,<p>Upgrading skills from Azure Service bus to Rabbit MQ + Mass Transit. Please bear with me.&#xA;I have convoluted understanding in mind about Saga and State Machine (Automatonymous). Are they synonym of each other.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Does the name SAGA originates from integrated state machine functionalities&#xA;  in service bus? Can we say Saga is superset of service bus?</p>&#xA;</blockquote>&#xA;&#xA;<p>As Azure does not have integrated state machine in their service bus.</p>&#xA;
50039099,Separate one module from JSF application,2018-04-26 09:10:09,<rest><jsf><java-ee><architecture><microservices>,1,47,4,0.0,0,"<p>We have big JSF monolithic application. We want to change the architecture of this application. Currently, my goal - change one module in our application. I need to move the logic from one module to another application which will be implemented on another stack of technologies (it will be rest-service with some js-framework on frontend).</p>&#xA;&#xA;<p>The application should work in the same way. We should have the link to the page as it was earlier but this page should be rendered by another service. We should have the same session between these 2 applications. The user should be able to go throw the pages without an additional step of authentification.</p>&#xA;&#xA;<p>We are planning to move also other modules, not only this one. I need a help. Do you have any thoughts how it should be implemented? any examples?</p>&#xA;"
44902847,Recovering from failure in orchestrated deployments,2017-07-04 10:01:18,<architecture><kubernetes><microservices>,1,24,0,0.0,0,"<p>In monolithic systems without orchestration, whenever thereâ€™s a temporary problem accessing a resource (ex. Connecting to a database), the typical approach is to keep retrying until recovery is achieved.</p>&#xA;&#xA;<p>In systems with a microservices architecture, where typically the boot process is light, removing the retry logic from the application and abort the process, letting the orchestrator restart the process, can reduce the application's complexity. If the orchestrator can deal with service dependencies, it might even know exactly what needs to be recovered and when is appropriate to start the service again. Thereâ€™s no â€œblindâ€ retry.</p>&#xA;&#xA;<p>If the service has persistent connections from clients, then terminating the service might be a problem, other than that I think terminating the process is an approach to consider.</p>&#xA;&#xA;<p>Does anyone has any experiente that can share? Feedback would be very helpful.</p>&#xA;"
44690557,Pros / cons browser querying front end server to query separate backend Vs directly query backend,2017-06-22 05:05:56,<api><cross-domain><microservices>,1,59,0,1.0,0,"<p>I have a front end written in react and a backend API which connects to a db for getting data. They have been written separately and are different services.</p>&#xA;&#xA;<p>The front end server has a bunch of routes that connect to the backend API and I'm wondering what are the pros / cons of having these routes instead of directly accessing the backend API? </p>&#xA;&#xA;<p>An example of the structure:</p>&#xA;&#xA;<ol>&#xA;<li>Front end server serves index.html and browser.js.</li>&#xA;<li>Browser.js makes GET, POST, PUT requests to front end server. </li>&#xA;<li>Front end server takes these requests and then makes a GET, POST, PUT request to the backend API.</li>&#xA;</ol>&#xA;&#xA;<p>Alternative:</p>&#xA;&#xA;<ol>&#xA;<li>Front end server serves index.html and browser.js.</li>&#xA;<li>Browser.js makes GET, POST, PUT requests to backend API. </li>&#xA;</ol>&#xA;&#xA;<p>So what are the pros / cons of doing it either way? The prior developer before me told me they did it the first way to bypass CORS and obscure the IP address of the backend API. However that doesn't seem to me like it is worth the trouble considering all the extra code, tests, etc the front end server has to write and maintain, in addition to extra network hops. I'm wondering if I'm missing some other more crucial reason that my inexperience cannot see? (My gut says do it the second way). Note that we are in a microservices architecture .</p>&#xA;"
44774754,Is App engine ThreadManager still usable?,2017-06-27 07:41:57,<google-app-engine><microservices>,1,62,0,0.0,0,"<p>I'm using GAE standard environment. </p>&#xA;&#xA;<p>When calling</p>&#xA;&#xA;<pre><code>ThreadManager.createBackgroundThread({&#xA;                try {&#xA;                    doSomething()&#xA;                } catch (exception: Exception) {&#xA;                    //do nothing - logging failed&#xA;                }&#xA;            })&#xA;</code></pre>&#xA;&#xA;<p>I got  the error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: This feature is only available to backend instances.&#xA;</code></pre>&#xA;&#xA;<p>I'm using the new services (modules?), as the backend instances are documented as deprecated. So are there any methods that allows to mark an instance as a backend one?</p>&#xA;"
44839692,Do individual microservices in an orchestration interact with each other?,2017-06-30 06:09:42,<microservices>,1,63,0,0.0,0,"<p>My product is migrating to microservices and they have presented an architecture where there are 2 parts:</p>&#xA;&#xA;<ol>&#xA;<li>Micro App : This is UI + an Orchestration layer.</li>&#xA;<li>Microservices : The individual microservices that micro app interacts with.</li>&#xA;</ol>&#xA;&#xA;<p>Now, in this architecture, they said that the individual microservices can interact with each other directly despite the presence of the orchestration layer. This is contrary to what I read (and understood). My understanding is that individual microservices  don't interact with each other directly if there is an orchestrator. Is my understanding correct?</p>&#xA;"
44893574,Identity Server - multiple STS,2017-07-03 20:37:45,<microservices><openid-connect><identityserver4>,2,331,0,0.0,0,"<p>I have two groups of api applications (group 1: api11, api12; group 2: api21, api22) that are used by two different groups od javascript applications (group 1 and group 2). Each api group has different domain and use different instance of Identity Server (also each identity server has different domain). Business requirement is that user logged in to any application from group 1 can use any app from this group but can't use app or api from group 2.</p>&#xA;&#xA;<p>Under the hood both api1 and api2 often needs to talk to the same microservices. What I want to achive is to make microservices accessible with access tokens issued from any of the identity servers (used by group 1 or group 2 app). Is there any way to achieve this? For one identity server I can use UseIdentityServerBearerTokenAuthentication but as argument I can pass only one Authority there. </p>&#xA;"
44803729,SCDF: Can I use an outside microservice as a source?,2017-06-28 13:21:09,<spring><microservices><spring-cloud-dataflow><spring-rabbitmq>,2,101,0,0.0,0,"<p>I am trying to work through a solution where the workflow is like this:</p>&#xA;&#xA;<ul>&#xA;<li>User hits a microservice to upload images</li>&#xA;<li>That microservice de-duplicates the image and if it really is new, queues it up for processing</li>&#xA;<li>The processing chain lives in Spring Cloud Dataflow</li>&#xA;</ul>&#xA;&#xA;<p>The microservice already exists, and we are trying to extend it to do the fancy processing.  My initial cut was to use the Http Source from the sample starter pack since that would be something I didn't have to create.  The problem is that the source doesn't register itself with Spring Discovery server, so there is no way to get an end point without making gross assumptions (like it lives on the dataflow server at port XYZ).</p>&#xA;&#xA;<p>We can create a Queue endpoint and send the data directly a Queue source that receives the outside event and forwards it to an SCDF queue.</p>&#xA;&#xA;<p>What would be awesome is if DataFlow could connect the start of the queue for me, without repackaging the microservice as a Source.</p>&#xA;&#xA;<p>The major issue with Spring Data Flow is that it does not automatically start up deployed streams when the server starts up, and we need to be reasonably sure that microservice is always up.</p>&#xA;"
44697767,There is no implicit reference conversion from StatelessService to 'Microsoft.ServiceFabric.Services.Remoting.IService',2017-06-22 11:14:30,<azure><communication><microservices><azure-service-fabric><stateless>,1,128,0,0.0,0,"<p>I am writing a new azure service application which can communicate using service remoting.&#xA;I referenced <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-communication-remoting"" rel=""nofollow noreferrer"">this article</a>. I am facing error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>The type 'PushMsgStatelessService.PushMsgStatelessService' cannot be used as type parameter 'TStatelessService' in the generic type or method 'ServiceRemotingExtensions.CreateServiceRemotingListener(TStatelessService, StatelessServiceContext)'. There is no implicit reference conversion from 'PushMsgStatelessService.PushMsgStatelessService' to 'Microsoft.ServiceFabric.Services.Remoting.IService'. PushMsgStatelessService C:\Nirvana\DataPerPerson\Narendra\PushMessageService\PushMsgStatelessService\PushMsgStatelessService.cs 30  Active</p>&#xA;</blockquote>&#xA;&#xA;<p>My code:</p>&#xA;&#xA;<pre><code>using System.Collections.Generic;&#xA;using System.Fabric;&#xA;using System.Threading.Tasks;&#xA;using Microsoft.ServiceFabric.Services.Communication.Runtime;&#xA;using Microsoft.ServiceFabric.Services.Runtime;&#xA;using Microsoft.ServiceFabric.Services.Remoting.Runtime;&#xA;&#xA;namespace PushMsgStatelessService&#xA;{&#xA;    interface IPushMessageService&#xA;    {&#xA;        Task&lt;string&gt; GetMessageAsync();&#xA;    }        &#xA;&#xA;    /// &lt;summary&gt;&#xA;    /// An instance of this class is created for each service instance by the Service Fabric runtime.&#xA;    /// &lt;/summary&gt;&#xA;    internal sealed class PushMsgStatelessService : StatelessService, IPushMessageService&#xA;    {&#xA;        public PushMsgStatelessService(StatelessServiceContext context)&#xA;            : base(context)&#xA;        { }&#xA;&#xA;        public Task&lt;string&gt; GetMessageAsync()&#xA;        {&#xA;            return Task.FromResult(""Hello!"");&#xA;        }&#xA;&#xA;        /// &lt;summary&gt;&#xA;        /// Optional override to create listeners (e.g., TCP, HTTP) for this service replica to handle client or user requests.&#xA;        /// &lt;/summary&gt;&#xA;        /// &lt;returns&gt;A collection of listeners.&lt;/returns&gt;&#xA;        protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;        {&#xA;            return new[] { new ServiceInstanceListener(context =&gt; this.CreateServiceRemotingListener(context)) };&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am stuck here.</p>&#xA;"
44785897,securing user account microservice with spring,2017-06-27 16:56:42,<java><rest><spring-security><architecture><microservices>,1,158,0,0.0,0,"<p>I'm creating a microservice structured application using 3 spring-boot microservices:</p>&#xA;&#xA;<ul>&#xA;<li>web - handle incoming web requests for clients </li>&#xA;<li>user-account - manage clients accounts and logins     </li>&#xA;<li>products - manage clients products</li>&#xA;</ul>&#xA;&#xA;<p>The web microservice lets a client register/login and sends REST requests to the user-account microservice to manage their account details and login. It also lets a logged in client get and add products that are associated to their account via REST requests to the products microservice.</p>&#xA;&#xA;<p>That was the plan anyway. I've been looking into security and have added spring security to the web microservice for clients logging in. I've also added a jwt token to a header when the client logs in and was going to use that as the authentication for accessing the products microservice (which will be otherwise locked down with spring security).</p>&#xA;&#xA;<p>Assuming that all sounds reasonable, the thing i'm unsure of is how I should be locking down the user-account microservice. I need to be able to make REST requests to it from the web microservice to attempt to login users, register users etc. Should the web microservice send an authentication token with a fixed system user details to the user-accounts microservice and then lock down all other REST access to the user-accounts microservice using spring security.</p>&#xA;&#xA;<p>Apologies for asking what is probably a basic architecture question but i'd like to get this right (whilst not go too complicated with OAuth if possible)</p>&#xA;"
44810758,Storing usernames and passwords in separate databases,2017-06-28 19:12:59,<database><security><passwords><microservices>,2,184,0,0.0,0,"<p>Im currently in the early stages of engineering a system that utilises a microservices architecture.</p>&#xA;&#xA;<p>I'm at the point where I'm implementing a user login system. I had the idea to have one service that handles all insensitive user information (e.g. username, email, age etc) and then have another service that handles passwords (e.g. storing them, encryption, verification etc).</p>&#xA;&#xA;<p>Having this architecture would mean that user data and passwords would be stored in two completely seperate databases. </p>&#xA;&#xA;<p>I think this is a feasible approach and could improve security.</p>&#xA;&#xA;<p>Is this approach overkill? Obviously I am going to be salting and hashing passwords but having these stored completely seperately gives another level of security. </p>&#xA;&#xA;<p>Are there any drawbacks to this approach? </p>&#xA;"
44873885,AWS API Gateway for interprocess communication,2017-07-02 18:19:41,<amazon-web-services><aws-lambda><microservices><aws-api-gateway>,1,215,0,0.0,0,"<p>I'm learning about microservice architecture and putting together some proof of concepts but I've hit a wall.</p>&#xA;&#xA;<p>I've made a user service which serverless which is hosted on amazon AWS using Lambda with a public API Gateway which allows you to query the user database. It's pretty simple and just looks something like:</p>&#xA;&#xA;<pre><code>api/users?email=myemail@gmail.com&#xA;</code></pre>&#xA;&#xA;<p>This API has authorization associated with it because some users are allowed to know about other users and some are not. So for some users this would return 404 (or 403 perhaps) and for others they would get 200 and the result.</p>&#xA;&#xA;<p>Now I come to write the authentication service which takes an email address and password and returns a token. How should I approach getting the user data from the user service? I'd love to just call the REST API but it has authorization on it because it's public. Also, the public API wouldn't return the (hashed) password field which I would need.</p>&#xA;&#xA;<p>So my question:</p>&#xA;&#xA;<p><strong>Should I have a separate, private API for inter-service communication which returns all the information or should I have a magic authorization key that I send to the api which identifies the requester as an internal service and so to show everything.</strong></p>&#xA;&#xA;<p>Supplementary question:</p>&#xA;&#xA;<p><strong>If I do use the public API with a magic auth code, should I just be calling fetch using the same public api url that my client side service would use or should I call some internal amazon url?</strong></p>&#xA;"
44692737,Debugging Application Remotely on azure service fabric,2017-06-22 07:23:03,<azure><microservices><azure-service-fabric>,1,491,0,0.0,0,<blockquote>&#xA;  <p>Is there a way to debug application when it is deployed on a remote&#xA;  cluster?</p>&#xA;</blockquote>&#xA;&#xA;<p>As many real-time problem arises <strong>when it is deployed on remote cluster</strong>.</p>&#xA;
44901467,Rest API fields restrict for role,2017-07-04 08:57:17,<rest><microservices>,1,40,1,0.0,0,"<p>I'm designing some REST API and just wondering how to restrict frontend users access some of resource fields.</p>&#xA;&#xA;<p>Lets say this is our user resource:</p>&#xA;&#xA;<pre><code>{&#xA;  ""username"" : ""user"",&#xA;  ""email"" : ""email@example.com"",&#xA;  ""created_at"" : ""2011-06-13T21:56:36""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>It's obvious that email shouldn't be disclosed and returned to public audience. However in admin section I would like to receive this field.</p>&#xA;&#xA;<p>Is there any kind of strategies for such problems?</p>&#xA;&#xA;<p>My ideas: </p>&#xA;&#xA;<ul>&#xA;<li>Create separate endpoints for administration.</li>&#xA;<li>Auth mechanism for fields?</li>&#xA;</ul>&#xA;"
44786479,grpc architecture : where should be caching layer be?,2017-06-27 17:32:08,<c#><caching><microservices><grpc>,1,286,3,0.0,0,"<p>We have a monolithic system that we are currently breaking into microservices using gRPC. Currently, we are using enyim caching in C# client in our monolithic code.</p>&#xA;&#xA;<p>While creating our first gRPC service, we are confused that where should caching layer be:</p>&#xA;&#xA;<ol>&#xA;<li>Should it be moved to gRPC service code for this service? This way each service will have its caching code. This would lead to lots of duplicate caching code.</li>&#xA;<li>Should we create dll for caching related code and use it in new gRPC microservice? We would still need to place duplcate configurations across each gRPC service.</li>&#xA;<li>Handle caching from monolithic code only and call gRPC service only in case for cache miss?</li>&#xA;</ol>&#xA;&#xA;<p>Suggestions?</p>&#xA;"
44758955,Wildfly Swarm JGroups YAML,2017-06-26 11:42:23,<java-ee><yaml><microservices><jgroups><wildfly-swarm>,1,318,3,0.0,0,"<p>I've downloaded the Wildfly swarm examples and now I am trying to move the configurations in Main classes to YAML files.</p>&#xA;&#xA;<p>So far, everything is working, except the ribbon example. I took the configuration from the example project and tried to convert it into YAML file.</p>&#xA;&#xA;<p>Project source: <a href=""https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java"" rel=""nofollow noreferrer"">https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java</a></p>&#xA;&#xA;<p>My YAML file (as I think it should look like)</p>&#xA;&#xA;<pre><code>--- &#xA;swarm:&#xA;  context:&#xA;    path: proxy&#xA;  http:&#xA;    port: 8080&#xA;  jgroups: &#xA;    default-channel: swarm-jgroups&#xA;    stacks:&#xA;      udp:&#xA;        protocols:&#xA;          FD_SOCK:&#xA;            socket-binding: jgroups-udp-fd&#xA;          TCP:&#xA;            properties:&#xA;              bind_port:&#xA;                value: 9090&#xA;          TCPPING:&#xA;            properties:&#xA;              initial_hosts:&#xA;                value: ""localhost[9090],localhost[9091],localhost[9092],localhost[9093]""&#xA;              num_initial_members:&#xA;                value: 4&#xA;              port_range:&#xA;                value: 4&#xA;              timeout:&#xA;                value: 3000&#xA;          FD_ALL: null&#xA;          VERIFY_SUSPECT: null&#xA;          pbcast.NAKACK2: null&#xA;          UNICAST3: null&#xA;          pbcast.STABLE: null&#xA;          pbcast.GMS: null&#xA;          UFC: null&#xA;          MFC: null&#xA;          FRAG2: null&#xA;          RSVP: null&#xA;        transports:&#xA;          UDP:&#xA;            socket-binding: jgroups-udp&#xA;</code></pre>&#xA;&#xA;<p>But I am getting two Exceptions: On startup in the first line:</p>&#xA;&#xA;<pre><code>Error getting subresources for Stack java.lang.RuntimeException: Failed to adopt value java.util.Map&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:347)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:33)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshal(Marshaller.java:23)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller.marshal(SubsystemMarshaller.java:59)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller.marshal(DMRMarshaller.java:70)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer.start(RuntimeServer.java:182)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer$Proxy$_$$_WeldClientProxy.start(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.lambda$bootstrap$1(ServerBootstrapImpl.java:158)&#xA;        at org.wildfly.swarm.spi.api.ClassLoading.withTCCL(ClassLoading.java:43)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.bootstrap(ServerBootstrapImpl.java:113)&#xA;        at org.wildfly.swarm.Swarm.start(Swarm.java:369)&#xA;        at org.wildfly.swarm.Swarm.main(Swarm.java:623)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;        at java.lang.reflect.Method.invoke(Unknown Source)&#xA;        at org.wildfly.swarm.bootstrap.MainInvoker.invoke(MainInvoker.java:39)&#xA;        at org.wildfly.swarm.bootstrap.Main.run(Main.java:46)&#xA;        at org.wildfly.swarm.bootstrap.Main.main(Main.java:37) Caused by: java.lang.ClassCastException: java.util.HashMap cannot be cast to java.lang.String&#xA;        at org.wildfly.swarm.config.runtime.invocation.MapTypeAdapter.toDmr(MapTypeAdapter.java:22)&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:341)&#xA;        ... 24 more&#xA;</code></pre>&#xA;&#xA;<p>And then the jgroup sepcific exception:</p>&#xA;&#xA;<pre><code>    (""subsystem"" =&gt; ""jgroups""),&#xA;    (""stack"" =&gt; ""udp"")&#xA;]) - failure description: ""WFLYCLJG0010: Transport for stack udp is not defined. Please specify both a transport and protocol list, either as optional parameters to add() or via batching.""&#xA;</code></pre>&#xA;&#xA;<p>I am not sure what is wrong.</p>&#xA;&#xA;<p>Maybe you guys can give me a hint?</p>&#xA;"
44781219,Atomic insert of data in micro service architecture + NoSql database [Data consistency in Micro service architecture],2017-06-27 13:12:50,<database-design><cassandra><architecture><microservices><nosql>,2,132,3,0.0,0,"<p>I have 3 services A, B, C. </p>&#xA;&#xA;<p>Service A receives a request from client. Then A prepares a data for its own database, service B and C. Basically A is coo-ordinator.</p>&#xA;&#xA;<ol>&#xA;<li>A insert data in its database</li>&#xA;</ol>&#xA;&#xA;<p>If it is success </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>post request B's data to service B and B insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If it is success</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>then post request C's data to service C and C insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If anything fails at any step, we have to revert all data inserted.</p>&#xA;&#xA;<p>I am using Cassandra NoSQL DB.</p>&#xA;&#xA;<p><strong>Now i need a generic solution for all cases that could happen like :</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I.</p>&#xA;&#xA;<p>Suppose C is inserting data (in progress), in the mean time, some read query R on A-database reads the inserted data. After few millisec, C fails to insert, but R already read the false data which would be reverted soon.</p></li>&#xA;</ul>&#xA;&#xA;<p>What to do in this case? &#xA;--> change the DB design, such that this kind of condition would never happen??</p>&#xA;&#xA;<ul>&#xA;<li><p>II.</p>&#xA;&#xA;<p>What if service C data insert fails, and service B have application server downtime so it couldn't revert??</p></li>&#xA;</ul>&#xA;"
44692442,Https config dosn't work in zuul routing,2017-06-22 07:07:19,<https><routing><microservices><spring-cloud><netflix-zuul>,2,943,4,0.0,0,"<p>I have a router application with zuul and many services that are run in the backend and requests from client are routed to their services by zuul.</p>&#xA;&#xA;<p>Everything is working well over http but when I configure the router and all services to https the following error is raised:</p>&#xA;&#xA;<pre><code>javax.net.ssl.SSLPeerUnverifiedException: Certificate for &lt;127.0.0.1&gt; doesn't match any of the subject alternative names: []&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:467) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.createLayeredSocket(SSLConnectionSocketFactory.java:397) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:355) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;</code></pre>&#xA;&#xA;<p>The zuul yml file :</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredPatterns: /reza,/we&#xA;  routes:&#xA;    trp:&#xA;      path: /micro1/**&#xA;      sensitiveHeaders:&#xA;      url: https://127.0.0.1:8080/micro1&#xA;server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 80&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234  &#xA;</code></pre>&#xA;&#xA;<p>And the yml file of one of those services:</p>&#xA;&#xA;<pre><code>server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 8080&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234&#xA;</code></pre>&#xA;&#xA;<p>First I want to know that the concept of https over zuul works properly and secondly I want to know how I fix my problem.</p>&#xA;&#xA;<p>Note: I don't have Eureka server registration.</p>&#xA;"
50380259,Is there a reccomended practice for how kubernetes service names are included in a microservice?,2018-05-16 21:36:11,<service><kubernetes><microservices>,1,22,0,0.0,0,"<p>I know this is an odd question, and I make the bet that this is likely to depend on the scenario or preference. </p>&#xA;&#xA;<p>If I have a set of microservices, lets just generically call them A, B, and C. Each of these is running in its own bod. </p>&#xA;&#xA;<p>If A needs to get access to B and C to handle a request, then I would want to rely on Kubernetes DNS resolution and create a service that will route to B, and another service that would route to C. &#xA;Let's generically call these ServiceB, and ServiceC.</p>&#xA;&#xA;<p>Right now, I just store the service names in constants defined in the client code that makes the requests. </p>&#xA;&#xA;<p>Based on your own experience, is there a good reason for these to be stored in a config file (or configmap)? I can't imagine them changing much, if at all throughout the lifecycle of the application. </p>&#xA;&#xA;<p>What do you do in your practice, and why? </p>&#xA;"
50389344,Unable to connect to neo4j testcontainer from another testcontainer in the same network,2018-05-17 10:35:48,<docker><neo4j><integration-testing><microservices><testcontainers>,1,30,0,0.0,0,"<p>There is a nice example of creating Testcontainers in the same network here: <a href=""https://stackoverflow.com/questions/46548199/can-testcontainers-create-docker-network-for-me-if-it-does-not-exist"">Can Testcontainers create docker network for me if it does not exist?</a></p>&#xA;&#xA;<p>My environment differs a bit and unfortunately I don't get the connection between both containrs.</p>&#xA;&#xA;<p>Here how my setup looks like:</p>&#xA;&#xA;<pre><code>import org.junit.Rule;&#xA;import org.junit.rules.RuleChain;&#xA;import org.junit.rules.TestRule;&#xA;import org.springframework.boot.test.util.EnvironmentTestUtils;&#xA;import org.springframework.context.ApplicationContextInitializer;&#xA;import org.springframework.context.ConfigurableApplicationContext;&#xA;import org.springframework.test.context.ContextConfiguration;&#xA;import org.testcontainers.containers.GenericContainer;&#xA;import org.testcontainers.containers.Network;&#xA;import org.testcontainers.containers.wait.strategy.Wait;&#xA;&#xA;@ContextConfiguration(initializers = RuleCombination.Initializer.class)&#xA;public abstract class RuleCombination {&#xA;&#xA;private static final Integer NEO4j_EXPOSED_PORT = 7687;&#xA;&#xA;private static final Integer MYSERVICE_EXPOSED_PORT = xxxx;&#xA;&#xA;private static Network network = Network.newNetwork();&#xA;&#xA;private static GenericContainer neo4jContainer =&#xA;        new GenericContainer(""preconfigured-neo4j-container"")&#xA;                .withExposedPorts(NEO4j_EXPOSED_PORT)&#xA;                .withNetwork(network)&#xA;                .withNetworkAliases(""neo4j"")&#xA;                .withEnv(""NEO4J_dbms_security_auth__enabled"", ""false"")&#xA;                .waitingFor(Wait.forListeningPort());&#xA;&#xA;&#xA;static {&#xA;    neo4jContainer.start();&#xA;}&#xA;&#xA;private static GenericContainer myserviceContainer =&#xA;        new GenericContainer(""myservice-container"")&#xA;                .withExposedPorts(MYSERVICE_EXPOSED_PORT)&#xA;                .withNetwork(network)&#xA;                .withEnv(""spring.data.neo4j.uri"",&#xA;                        ""bolt://"" + ""neo4j"" + "":"" +&#xA;                                neo4jContainer.getMappedPort(NEO4j_EXPOSED_PORT));&#xA;&#xA;static {&#xA;    myserviceContainer.start();&#xA;}&#xA;&#xA;&#xA;@Rule&#xA;public TestRule containerCombination = RuleChain.outerRule(myserviceContainer).around(neo4jContainer);&#xA;&#xA;public static class Initializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; {&#xA;&#xA;    @Override&#xA;    public void initialize(ConfigurableApplicationContext configurableApplicationContext) {&#xA;        EnvironmentTestUtils.addEnvironment(&#xA;            configurableApplicationContext.getEnvironment(),   &#xA;            ""feign.myservice.url: http://"" + myserviceContainer.getContainerIpAddress() + "":"" + myserviceContainer.getMappedPort(MYSERVICE_EXPOSED_PORT));&#xA;    }&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Wenn I run the test using this configuration, I get the error</p>&#xA;&#xA;<pre><code>ServiceUnavailableException: Unable to connect to neo4j:32819&#xA;</code></pre>&#xA;&#xA;<p>Any idea how could I correctly pass the ip of the neo4j container to myservice container?</p>&#xA;"
50363538,How WSO2 API manager implements microservices service discovery and service registry feature,2018-05-16 06:09:17,<wso2><microservices><service-discovery>,1,33,0,0.0,0,<p>How WSO2 API manager implements microservices service discovery and service &#xA;registry feature</p>&#xA;
50397998,Session in Lagom,2018-05-17 18:12:23,<http><session><service><microservices><lagom>,1,36,0,0.0,0,<p>How can we manage session in Lagom and share data across multiple service calls using Session ?</p>&#xA;&#xA;<p>Basically I want to store a userId on account creation across multiple requests. I want to store this userId in a session. How can we do this in Lagom?</p>&#xA;
50320908,Migrating to Microservices - mysql,2018-05-13 21:46:34,<mysql><microservices>,1,42,0,0.0,0,"<p>The company I'm with is looking into migrating to a microservice/kubernetes architecture but hitting a couple hurdles in the research, so I thought I'd pitch them here.</p>&#xA;&#xA;<p>With a typical monolithic database, a lot of queries join from other sources/tables, which would typically be considered a different microservices responsibility (eg. Customers -> Orders). </p>&#xA;&#xA;<p>The question I have right now is, with microservices, what is considered the best practice?</p>&#xA;&#xA;<p>I've found a few suggested approaches:</p>&#xA;&#xA;<p>1) Join in code. Essentially running multiple queries. eg:&#xA;<code>&#xA;const user = UserService.getUserById(1);&#xA;const order = OrderService.getForUser(user);&#xA;</code></p>&#xA;&#xA;<p>I like this approach and can clearly see where data is from, and what is required etc. However this raises the issue of extra latency. Where as before I could JOIN this query and only have a single trip to a database. I now have 2 (or more depending on required data) requests to the db.</p>&#xA;&#xA;<p>2) Join in external service. Building out a seperate service that handles queries. - This feels a lot like having an internal api that every service is dependant on and seems like a bad practice as a single point of failure. Maybe i'm seeing this wrong.</p>&#xA;&#xA;<p>3) Join in mysql. Have all data in the same database and query as before. This has the benefit of single trip to mysql, however breaks the microservice approach and removes the ability to have database/schema per service.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I personally feel like option 1 is the most versatile option, but I'm curious about the added latency of multiple round trips, and how you guys have dealt with that. Or perhaps there is another solution I'm not seeing.</p>&#xA;"
50361821,kubernetes microservices Spring cloud,2018-05-16 02:54:15,<docker><kubernetes><microservices><spring-cloud>,1,50,0,0.0,0,"<p>I am trying to develop an application with microservices and Spring Cloud. I am using Zuul as a proxy server, Eureka as a Service discovery and couple of other microservices like product service, order service etc.</p>&#xA;&#xA;<p>For deployment purpose, I am trying to leverage features of Docker and Kubernetes. While learning kubernetes, I realized that kubernetes has ""service"" object which works as load balancer and can have static IP which does not change even if pods are rescheduled. In that case, can I remove Eureka server (Which works as discovery as well as client side load balancer) from spring cloud and utilize kubernetes ""service"" object for the same purpose?</p>&#xA;&#xA;<p>If yes, &#xA;    How zuul will identify the service to which it need to redirect the request? Is there any kubernetes object which perform the function of zuul proxy server?</p>&#xA;&#xA;<p>Also if I remove Eureka and Zuul, how can I make it work in local and non kubernetes env?</p>&#xA;"
50417003,web Api application subscribing to a queue. Is it a good idea?,2018-05-18 18:05:47,<asp.net-web-api><microservices><restful-architecture><event-bus>,1,80,0,1.0,0,"<p>We are designing a reporting system using microservice architecture. All the services are supposed to be subscribers to the event bus and they communicate by raising events. We also decided to expose each of our services using REST api. Now the question is , is it a good idea to create our services as web api [RESTful] applications which are also subscribers to the event bus? so basically there are 2 ponits of entry to each service - api and events. I have a feeling that we should separate out these 2 as these are 2 different concerns. Any ideas?  </p>&#xA;"
50438873,Microservices in Azure,2018-05-20 19:57:40,<azure><microservices><azure-container-service>,2,84,0,0.0,0,"<p>I understand that Microservices is about independent loosely coupled services. I have read <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Microservices</a>.</p>&#xA;&#xA;<p>When it comes to Azure, I understand there are many components like Azure Service Fabric, AKS and also have the option of deploying containers within Azure VMs using Docker or any other containerization tools. However, since Microservices is about developing atmoic individually scalable services, can this also be achieved by deploying each service as an Azure Web API APP within an App Service Plan and configure Auto-Scale based on Performance metrics (though each API APP may not be individually scalable, they can still be individually manageable in terms of deployment, configuration etc)? </p>&#xA;&#xA;<p>Can someone please suggest if this thought process is correct?</p>&#xA;"
50439512,can an instance of pilot configured to query both k8s and consul?,2018-05-20 21:24:11,<kubernetes><microservices><consul><istio>,1,88,0,0.0,0,"<p>we run services in k8s and non-k8s. Non-k8s services are registered in Consul. We are thinking of adding istio in our stack, and we, ideally, want k8s services to call non-k8s services. So, I have few questions about that</p>&#xA;&#xA;<p>1) Does a single instance of Pilot support query both k8s and consul?<br>&#xA;2) Can istio be configured to support such environment?</p>&#xA;&#xA;<p>I tried reading up istio docs but can't find if Pilot can be configured to query both consul and k8s together. Reference links to docs/blogs would be helpful as well. Thanks in advance! </p>&#xA;"
50340234,Sending Rest request with file(s) and JSON (Restsharp) on Framework and Standard,2018-05-14 23:09:02,<c#><azure><microservices><azure-functions><restsharp>,1,142,0,0.0,0,"<p>I currently have a wrapper I am building that employs a function (SendEmail) to send a JSON payload and a few files to an Azure function at an Http endpoint. However when I am using Restsharp 106.2.2 to send over my request it seems that no boundary information is being provided. When my Azure function receives the call and tries to setup the MultipartMemoryStreamProvider it can't because it doesn't see any boundaries.</p>&#xA;&#xA;<p><strong>Console Test App</strong></p>&#xA;&#xA;<pre><code>private static void Main(string[] args)&#xA;{&#xA;    var emailService = new EmailService();&#xA;    var email = new MicroserviceMailMessage(""from@test.com"", ""to@test.com"",&#xA;        ""Test Subject from Framework App"", ""Test Body from Framework App"", true, DateTime.Now);&#xA;    email.Attachments.Add(new Attachment(@""c:\Temp\soccor5.jpg""));&#xA;&#xA;    emailService.SendEmail(email);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Wrapper Library</strong></p>&#xA;&#xA;<pre><code>public void SendEmail(MicroserviceMailMessage email)&#xA;{&#xA;    var client = new RestClient(""http://localhost:7071/api"");&#xA;    var request = new RestRequest(""SendEmail"", Method.POST);&#xA;&#xA;    var transformedEmail = TransformEmail(email);&#xA;&#xA;    request.AlwaysMultipartFormData = true;&#xA;    request.AddHeader(""Content-Type"", $""multipart/form-data"");&#xA;&#xA;    foreach (var attachment in email.Attachments)&#xA;    {&#xA;        var inline = attachment.ContentDisposition.Inline ? ""inline."" : """";&#xA;        request.Files.Add(new FileParameter&#xA;        {&#xA;            Name = $""attachments.{inline}{attachment.Name}"",&#xA;            Writer = (s) =&gt;&#xA;            {&#xA;                attachment.ContentStream.CopyTo(s);&#xA;                attachment.ContentStream.Dispose();&#xA;            },&#xA;            ContentType = attachment.ContentType.ToString(),&#xA;            ContentLength = attachment.ContentStream.Length,&#xA;            FileName = attachment.Name&#xA;        });&#xA;    }&#xA;&#xA;    request.AddParameter(""email"", $""{JsonConvert.SerializeObject(transformedEmail)}"", ParameterType.RequestBody);&#xA;    IRestResponse response = client.Execute(request);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Azure Reciever Function</strong></p>&#xA;&#xA;<pre><code>[FunctionName(""EmailReceiver"")]&#xA;public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Function, ""post"", Route = null)]HttpRequestMessage req, ...)&#xA;{&#xA;    ...&#xA;    var provider = new MultipartMemoryStreamProvider();&#xA;    await req.Content.ReadAsMultipartAsync(provider) // Fails on this line&#xA;    ...&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Sample Data Comparison</strong></p>&#xA;&#xA;<p><em>Using RestSharp 106.2.2</em>&#xA;<a href=""https://i.stack.imgur.com/Ow2fB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ow2fB.png"" alt=""Data with RestSharp 106.2.2""></a></p>&#xA;&#xA;<p><em>Using RestSharp 105.2.3 (Similar results with Postman)</em>&#xA;<a href=""https://i.stack.imgur.com/KR5L4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KR5L4.png"" alt=""Data with RestSharp 105.2.3""></a></p>&#xA;&#xA;<p><strong>Error</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>Invalid 'HttpContent' instance provided. It does not have a&#xA;  'multipart' content-type header with a 'boundary'&#xA;  parameter.\r\nParameter name: content</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>What I've tried so far:</strong></p>&#xA;&#xA;<p>Reverting Restsharp to 105.2.3 brings back the boundary information in the Rest request and that works great for .Net Framework, but I need the wrapper to be cross compatible between Framework and .Net Standard so this won't fully solve my problem.</p>&#xA;&#xA;<p>Ideas? I've been trying to think if there is some way that I can manually enter the boundaries in with Restsharp 106.2.2 but I can't find a whole lot of documentation on it.</p>&#xA;"
50405838,Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'session' is not active for the current thread;,2018-05-18 07:18:25,<java><spring-boot><microservices><spring-cloud><spring-oauth2>,1,411,0,0.0,0,"<p><em>First of all I want to say that I googled my problem and apllied the advice but it doesn't help me.</em></p>&#xA;&#xA;<p>My source look like this:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaClient&#xA;@RibbonClient(name = ""say-hello""/*, configuration = RibbonConfig.class*/)&#xA;@EnableAutoConfiguration&#xA;@EnableOAuth2Sso&#xA;public class HelloWorldStarter {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(HelloWorldStarter.class, args);&#xA;    }&#xA;&#xA;    @Bean&#xA;    public RequestContextListener requestContextListener() {&#xA;        return new RequestContextListener();&#xA;    }&#xA;&#xA;&#xA;    @RestController&#xA;    @EnableDiscoveryClient&#xA;    @EnableCircuitBreaker&#xA;    public static class HelloWorldController {&#xA;        @Autowired&#xA;        private RestTemplate restTemplate;&#xA;        @Autowired&#xA;        private OAuth2RestTemplate oAuth2RestTemplate;&#xA;        @Autowired&#xA;        private DiscoveryClient discoveryClient;&#xA;&#xA;        @GetMapping(""/helloWorld"")&#xA;        @HystrixCommand(fallbackMethod = ""reliable"")&#xA;        public String hello() {&#xA;            //String response = restTemplate.getForObject(""http://localhost:8082/h/hello?name=World"", String.class);&#xA;            try {&#xA;                return this.oAuth2RestTemplate.getForObject(""http://hello-service/h/hello?name=World"", String.class);&#xA;            } catch (Exception e) {&#xA;                e.printStackTrace();&#xA;                return null;&#xA;            }&#xA;        }&#xA;&#xA;        public String reliable() {&#xA;            return ""Could not get response from service"";&#xA;        }&#xA;    }&#xA;&#xA;    @org.springframework.context.annotation.Configuration&#xA;    public static class Configuration {&#xA;        @Bean&#xA;        @LoadBalanced&#xA;        RestTemplate restTemplate() {&#xA;            return new RestTemplate();&#xA;        }&#xA;&#xA;        @Bean&#xA;        @ConfigurationProperties(""security.oauth2"")&#xA;        public ClientResources clientResources() {&#xA;            return new ClientResources();&#xA;        }&#xA;&#xA;        @Autowired&#xA;        private OAuth2ClientContext oAuth2ClientContext;&#xA;&#xA;        @Bean&#xA;        @LoadBalanced&#xA;        public OAuth2RestTemplate oAuth2RestTemplate() {&#xA;            return new OAuth2RestTemplate(clientResources().getClient(), oAuth2ClientContext);&#xA;        }&#xA;&#xA;        class ClientResources {&#xA;&#xA;            @NestedConfigurationProperty&#xA;            private AuthorizationCodeResourceDetails client = new AuthorizationCodeResourceDetails();&#xA;&#xA;            @NestedConfigurationProperty&#xA;            private ResourceServerProperties resource = new ResourceServerProperties();&#xA;&#xA;            public AuthorizationCodeResourceDetails getClient() {&#xA;                return client;&#xA;            }&#xA;&#xA;            public ResourceServerProperties getResource() {&#xA;                return resource;&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml:</strong></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: hello-world-service&#xA;server:&#xA;  port: 8081&#xA;  servlet:&#xA;    context-path: /hw&#xA;eureka:&#xA;  client:&#xA;    serviceUrl:&#xA;      defaultZone: http://localhost:8761/eureka&#xA;  instance:&#xA;    preferIpAddress: true&#xA;&#xA;security:&#xA;  oauth2:&#xA;    client:&#xA;      client-id: acme&#xA;      client-secret: acmesecret&#xA;      access-token-uri: http://localhost:8080/oauth/token&#xA;      user-authorization-uri: http://localhost:8080/oauth/authorize&#xA;    resource:&#xA;      user-info-uri: http://localhost:8080/me&#xA;&#xA;logging:&#xA;  level:&#xA;    org.springframework.security: DEBUG&#xA;    org.springframework.web: DEBUG&#xA;</code></pre>&#xA;&#xA;<p>When I invoke <code>/helloWorld</code> Rest method following error happens:</p>&#xA;&#xA;<pre><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'session' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet/DispatcherPortlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request.&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:362)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)&#xA;    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:193)&#xA;    at com.sun.proxy.$Proxy116.getAccessToken(Unknown Source)&#xA;    at org.springframework.security.oauth2.client.OAuth2RestTemplate.doExecute(OAuth2RestTemplate.java:125)&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680)&#xA;    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:332)&#xA;    at org.ntkachev.microservices.hello_world.HelloWorldStarter$HelloWorldController.hello(HelloWorldStarter.java:60)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:116)&#xA;    at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.executeWithArgs(MethodExecutionAction.java:93)&#xA;    at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:78)&#xA;    at com.netflix.hystrix.contrib.javanica.command.GenericCommand$1.execute(GenericCommand.java:48)&#xA;    at com.netflix.hystrix.contrib.javanica.command.AbstractHystrixCommand.process(AbstractHystrixCommand.java:145)&#xA;    at com.netflix.hystrix.contrib.javanica.command.GenericCommand.run(GenericCommand.java:45)&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302)&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298)&#xA;    at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46)&#xA;    at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:10151)&#xA;    at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51)&#xA;    at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:10151)&#xA;    at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)&#xA;    at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:10151)&#xA;    at rx.internal.operators.OperatorSubscribeOn$1.call(OperatorSubscribeOn.java:94)&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction$1.call(HystrixContexSchedulerAction.java:56)&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction$1.call(HystrixContexSchedulerAction.java:47)&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction.call(HystrixContexSchedulerAction.java:69)&#xA;    at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&#xA;    at java.util.concurrent.FutureTask.run(FutureTask.java:266)&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet/DispatcherPortlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request.&#xA;    at org.springframework.web.context.request.RequestContextHolder.currentRequestAttributes(RequestContextHolder.java:131)&#xA;    at org.springframework.web.context.request.SessionScope.get(SessionScope.java:55)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:350)&#xA;    ... 47 more&#xA;</code></pre>&#xA;&#xA;<p>In the most of answers advice just to add </p>&#xA;&#xA;<pre><code>@Bean&#xA;public RequestContextListener requestContextListener() {&#xA;    return new RequestContextListener();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But as you can see this advice already applied.</p>&#xA;&#xA;<p>Can you help me to execute authenticated request to another service?</p>&#xA;"
50410038,Implementing OAuth2 Implicit Grant with Spring Security,2018-05-18 11:10:32,<spring-security><oauth-2.0><microservices><spring-security-oauth2>,1,209,0,0.0,0,<p>I am building a new application using microservices with a frontend UI using React JS. I have created an auth microservice using Spring Boot and OAuth 2.0. For single page applications I have read that I should use the implicit grant instead of the password grant. The auth microservice will support this but my question is where would I implement the UI for the user to put their username and password? Would it be within the auth microservice or would I have to create a separate UI application?</p>&#xA;
50387947,inter micro-service request responds with Forbidden status in spring cloud application,2018-05-17 09:28:45,<java><spring-boot><microservices><spring-cloud><spring-security-oauth2>,1,263,1,0.0,0,"<p>I am investigating microservice architecture. I chose the spring cloud framework.</p>&#xA;&#xA;<p>My application shema looks like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/yvQ9E.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yvQ9E.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Also I have discovery server eureka but I decided to skip on the picture to simplify it.</p>&#xA;&#xA;<p>Full source code of example you can find on githib: <a href=""https://github.com/gredwhite/spring-cloud"" rel=""nofollow noreferrer"">https://github.com/gredwhite/spring-cloud</a></p>&#xA;&#xA;<h2>Problem explanation:</h2>&#xA;&#xA;<p><strong>hello world service:</strong></p>&#xA;&#xA;<pre><code>@GetMapping(""/helloWorld"")&#xA;@HystrixCommand(fallbackMethod = ""reliable"")&#xA;public String hello() {&#xA;    return this.restTemplate.getForObject(""http://hello-service/hello?name=World"", String.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>hello service:</strong></p>&#xA;&#xA;<pre><code>@GetMapping(""/hello"")&#xA;public String hello(@RequestParam(""name"") String name) throws UnknownHostException, InterruptedException {           &#xA;     return ""Hello "" + name + ""!"";&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>When I started the <code>hello service</code> and try to access <code>localhost:8082/h/hello?name=Vasya</code> (<code>/h</code> - context path) - request happens successfully and I see <code>Hello Vasya</code> mesage in the response. <strong>I need to say that authentication is disabled for that service.</strong></p>&#xA;&#xA;<p><code>hello world service</code> has <code>index.html</code> page and when I try to acces it - auth flow happens successfully and eventually this application log in successfully. Then I try to execute method <code>/hello</code> from the <code>hello world service</code> and I see response:</p>&#xA;&#xA;<pre><code>{""timestamp"":""2018-05-17T08:53:04.623+0000"",""status"":403,""error"":""Forbidden"",""message"":""Forbidden"",""path"":""/hw/helloWorld""}&#xA;</code></pre>&#xA;&#xA;<h2>Oauth2 configuration:</h2>&#xA;&#xA;<p><strong>hello world service</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaClient&#xA;@RibbonClient(name = ""say-hello"")&#xA;@EnableAutoConfiguration&#xA;@EnableOAuth2Sso&#xA;public class HelloWorldStarter {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(HelloWorldStarter.class, args);&#xA;    }&#xA;&#xA;&#xA;    @RestController&#xA;    @EnableDiscoveryClient&#xA;    @EnableCircuitBreaker&#xA;    public static class HelloWorldController {&#xA;        @Autowired&#xA;        private RestTemplate restTemplate;&#xA;        @Autowired&#xA;        private DiscoveryClient discoveryClient;&#xA;&#xA;        @GetMapping(""/helloWorld"")&#xA;        @HystrixCommand(fallbackMethod = ""reliable"")&#xA;        public String hello() {           &#xA;            return this.restTemplate.getForObject(""http://hello-service/hello?name=World"", String.class);&#xA;        }&#xA;&#xA;        public String reliable() {&#xA;            return ""Could not get response from service"";&#xA;        }&#xA;    }&#xA;&#xA;    @org.springframework.context.annotation.Configuration&#xA;    public static class Configuration {&#xA;        @Bean&#xA;        @LoadBalanced&#xA;        RestTemplate restTemplate() {&#xA;            return new RestTemplate();&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><em>application.yml:</em></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: hello-world-service&#xA;server:&#xA;  port: 8081&#xA;  servlet:&#xA;    context-path: /hw&#xA;eureka:&#xA;  client:&#xA;    serviceUrl:&#xA;      defaultZone: http://localhost:8761/eureka&#xA;  instance:&#xA;    preferIpAddress: true&#xA;&#xA;security:&#xA;  oauth2:&#xA;    client:&#xA;      client-id: acme&#xA;      client-secret: acmesecret&#xA;      access-token-uri: http://localhost:8080/oauth/token&#xA;      user-authorization-uri: http://localhost:8080/oauth/authorize&#xA;    resource:&#xA;      user-info-uri: http://localhost:8080/me&#xA;&#xA;logging:&#xA;  level:&#xA;    org.springframework.security: DEBUG&#xA;    org.springframework.web: DEBUG&#xA;</code></pre>&#xA;&#xA;<h2>Questions</h2>&#xA;&#xA;<ol>&#xA;<li>How can I fix this problem?  </li>&#xA;<li>After previous point fix I want to know how to execute authorized request to that service. In other words I want to enable oauth 2 authorization on hello service and have possibility to make request from the <code>hello world service</code></li>&#xA;</ol>&#xA;"
50434941,Microservices: how to deal with service self-registration?,2018-05-20 12:40:14,<microservices><service-discovery>,1,46,1,1.0,0,"<p>I've recently been working on a side-project where I use the microservice architecture. One of the main problems with this architecture is that multiple core microservices can be launched any time and they need to be available as soon as they're runnning. </p>&#xA;&#xA;<p>So I found a nice quick article on this website <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/self-registration.html</a>&#xA;but this only brings up the question, how do microservices register themselves on the service registry? </p>&#xA;&#xA;<ul>&#xA;<li>Does this mean that every microservice <strong>knows</strong> the location of the service registry? &#xA;If not then should each client also have some sort of service discovery method that only finds services of type service registry?</li>&#xA;</ul>&#xA;&#xA;<p>TL;DR</p>&#xA;&#xA;<p>I guess the underlying question really what is the proper way of implementing service registration?</p>&#xA;&#xA;<p>Thanks !</p>&#xA;"
50415015,How to use Cognito to Control API Access,2018-05-18 15:47:09,<aws-lambda><microservices><aws-api-gateway><amazon-cognito>,1,62,1,0.0,0,"<p>We are building a number of microservices using API Gateway+lambda+DynamoDB. We need to secure these APIs using Cognito which we are using for user management. We will have a user pool and two groups with a different IAM role attached to each group. The need is users in one group should not be able to access all services and so the users in other group.&#xA;Any suggestions, how we can implement this?&#xA;The issue is ID token generated by Cognito is not validated by API gateway to check what level of access user has. All it checks is if Cognito ID token is valid or not.</p>&#xA;"
50338845,Should a microservice take care of this or the api gateway?,2018-05-14 20:53:37,<microservices>,2,68,1,0.0,0,"<p>I am building out a microservice architecture and kinda confused on one part. I am using Kafka as a message broker system to communicate within my services. A perfect example would be <a href=""https://developer.uber.com/docs/riders/references/api/v1.2/requests-estimate-post"" rel=""nofollow noreferrer"">Uber's API for request estimation</a>. It returns duration, distance, price, etc. I would assume they have a microservice for each of those, i.e. service for pricing, service for duration/distance, service for drivers, etc. My question is when hitting the endpoint <code>/requests/estimate</code> does the requests microservice make rest calls to the other microservices to retrieve data for the duration, distance, etc? or does the API Gateway take care of that?</p>&#xA;"
50499849,Getting ClassCastException when trying to cast Logger object to my own wrapper logger,2018-05-24 02:01:28,<rest><spring-boot><microservices><log4j2>,1,19,2,0.0,0,"<p>I am trying write a wrapper logger class by extending Logger, which will log class name , method name, message and error/exception details.</p>&#xA;&#xA;<p>Getting exception in below line</p>&#xA;&#xA;<pre><code>ILogger logger = &#xA;(CustomLogger)org.apache.logging.log4j.LogManager.getLogger(name);&#xA;</code></pre>&#xA;&#xA;<p>Using below XML, sometimes it's taking SLF4J logger too and getting SLF4j binding exceptions too.</p>&#xA;&#xA;<p>My pom.xml:</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" &#xA;xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;&lt;groupId&gt;com.Logger&lt;/groupId&gt;&#xA;&lt;artifactId&gt;WrapperLogger&lt;/artifactId&gt;&#xA;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;name&gt;WrapperLogger&lt;/name&gt;&#xA;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;2.0.2.RELEASE&lt;/version&gt;&#xA;    &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;    &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;</code></pre>&#xA;&#xA;<p></p>&#xA;&#xA;<p>===================================================================        </p>&#xA;&#xA;<p>log4j.xml</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;Configuration&gt;&#xA;&lt;Appenders&gt;&#xA;&lt;!-- Console Appender --&gt;&#xA;&lt;Console name=""Console"" target=""SYSTEM_OUT""&gt;&#xA;  &lt;PatternLayout pattern=""%d{yyyy-MMM-dd HH:mm:ss a} [%t] %M,%C, &#xA;  %-5level %logger{36} - %msg%n"" /&gt;&#xA;&lt;/Console&gt;&#xA;&lt;!-- File Appender --&gt;&#xA;&lt;File name=""File"" fileName=""d:/app.log""&gt;&#xA;  &lt;PatternLayout pattern=""%d{yyyy-MMM-dd HH:mm:ss a} [%t] %-5level &#xA;  %logger{36} - %msg%n"" /&gt;&#xA;&lt;/File&gt;&#xA;&lt;/Appenders&gt;&#xA;&#xA;&lt;Loggers&gt;&#xA;&lt;!-- Log everything in custom package --&gt;&#xA;&lt;Logger name=""com.boraji.tutorial.springboot"" level=""debug"" additivity=""false""&gt;&#xA;  &lt;AppenderRef ref=""Console"" /&gt;&#xA;  &lt;AppenderRef ref=""File"" /&gt;&#xA;&lt;/Logger&gt;&#xA;&lt;!-- Log everything in Spring Boot --&gt;&#xA;&lt;Logger name=""org.springframework.boot"" level=""debug"" additivity=""false""&gt;&#xA;  &lt;AppenderRef ref=""Console"" /&gt;&#xA;  &lt;AppenderRef ref=""File"" /&gt;&#xA;&lt;/Logger&gt;&#xA;&#xA;&lt;!-- Log everything in Spring Core --&gt;&#xA;&lt;Logger name=""org.springframework.core"" level=""debug"" additivity=""false""&gt;&#xA;  &lt;AppenderRef ref=""Console"" /&gt;&#xA;  &lt;AppenderRef ref=""File"" /&gt;&#xA;&lt;/Logger&gt;&#xA;&#xA;&lt;Root level=""info""&gt;&#xA;  &lt;AppenderRef ref=""Console"" /&gt;&#xA;  &lt;AppenderRef ref=""File"" /&gt;&#xA;&lt;/Root&gt;&#xA;</code></pre>&#xA;&#xA;<p>&#xA;</p>&#xA;"
50430808,Which option to follow for microservices: Spring Boot or AWS Lamba,2018-05-20 00:58:59,<amazon-web-services><spring-boot><aws-lambda><microservices><aws-cognito>,2,143,2,1.0,0,"<p>I come from Java / Java EE background and new to Microservices and AWS; though, I did lot of reading over it. I tried my first microservice with Spring boot and I am impressed with Spring Boot.  I also used AWS for past 2 months and I am bit familiar with it now. </p>&#xA;&#xA;<p>Now I am working on a big application and thinking of designing the complete back end (APIs) and would like to use micro services for it - though I would still use only few microservices: One for managing users, and three more with business logic. I will have to also handle authentication. </p>&#xA;&#xA;<p>Based on my research and work I am considering two options:</p>&#xA;&#xA;<p>Option 1: AWS Cognito (for social media login support) + AWS API Gateway + multiple AWS Lambdas (Java Code) + One DynamoDB (preferably otherwise RDS MySQL). &#xA;My concern is Can I write complex business logic and handle complex tables relations (such as Many-to-Many; eager/lazy fetch, and so on) in AWS lambdas, which are very neatly done in Spring Boot + Spring Data JPA   </p>&#xA;&#xA;<p>Option 2: Start with writing business logic in Spring boot, that is, four spring boot applications with either MySQL or DynamoDb as backend; and deploy them on AWS EC2; I can also implement one more Sprint boot application with JWT for authentication &#xA;My concern here is How to manage authentication (one entry point for all API's) for multiple spring boot applications; If i will face challenge in integrating with AWS API Gateway (for centralized management of Authentication &amp; Authorization); and Will I face challenge in integrating with AWS Cognito if I want social media login </p>&#xA;&#xA;<p>I don't want face lot of complications in later stage, therefore, I need help in deciding.  </p>&#xA;&#xA;<p>Many Thanks</p>&#xA;"
50400384,"In the microservices architecture, why they say is bad to share REST Client libraries?",2018-05-17 20:57:09,<java><spring><microservices>,3,60,3,0.0,0,"<p>We have 15 services build with Java Spring, they talk each other using REST .</p>&#xA;&#xA;<p>Each time we add a new service to the pool we create from scratch all the code, including rest client code that will talk to other Services and the POJO classes used to map the resource(s) being requested.</p>&#xA;&#xA;<p>We end up copy and pasting from the source code of other services into the new service.</p>&#xA;&#xA;<p>I think it would be better to put all these POJO's and rest client code into a library for all the services to consume it, it would save us a lot of work coding, but ""they"" we should not do that with microservices.</p>&#xA;&#xA;<p>So, why is that?&#xA;We end up copy and pasting the exactly same code over and over again, I don't see the difference.</p>&#xA;"
50427036,Certificate Discovery Service,2018-05-19 15:54:30,<rest><ssl><ssl-certificate><microservices><keystore>,1,32,4,0.0,0,"<p><br/>&#xA;I'm designing a microservice architecture and I've already setted up the https protection by using SSL certificates generated with <a href=""https://letsencrypt.org/"" rel=""nofollow noreferrer"">Let's Encrypt and certbot</a>.</p>&#xA;&#xA;<p>The provided certificates are periodically regenerated and then I've to re-import the new certificates into the keystores of all my services.</p>&#xA;&#xA;<p>In order to avoid this, I'm trying to implement a set of <strong>REST APIs</strong> that may allow the services to <strong>programmatically and automatically retrieve the new certificates</strong> and import them into their own keystore or simply use it programmatically. </p>&#xA;&#xA;<p>As the title says: a sort of <em>""Certificate discovery service""</em> or, if you prefer, a <em>""Remote certificate repository""</em>.</p>&#xA;&#xA;<p>I know that there is the java.security.* package that allows me to deal with this kind of things, but I've two questions for all of you:</p>&#xA;&#xA;<ol>&#xA;<li>Do you think that, from a architectural point of view, this is the best approach to face my problem?</li>&#xA;<li>Which king of Serialization/Deserialization process do you recommend? Is already there any library/framework/tool that does something similar that I can exploit?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you.&#xA;Bye Bye</p>&#xA;"
50401105,How to implement TLS between microservices,2018-05-17 22:01:19,<ssl><microservices><pki>,2,309,5,1.0,0,"<p>Can someone please comment on, vet, critique, or otherwise blast holes in the microservices security design Iâ€™m considering?</p>&#xA;&#xA;<p>Letâ€™s say I have three microservices, each of which talks to the other two via REST endpoints. Each microservice contains a keystore. In this keystore is the containing microserviceâ€™s private/public keypair, signed by a trusted certificate authority. Also in this keystore is the other two microservicesâ€™ public key certificates, exported from the source microserviceâ€™s signed/trusted keypair.</p>&#xA;&#xA;<p>This implementation works, but something doesnâ€™t quite smell right about it.</p>&#xA;&#xA;<p>Namely, every time I introduce a new microservice I must add a) each existing microserviceâ€™s public key certificate to its keystore, and b) the new microserviceâ€™s public key certificate to every other microservice (the assumption being the new microservice must communicate bi-directionally, and securely, with each existing microservice).</p>&#xA;&#xA;<p>Now, repeat the above pattern for a second keypair, this one used to sign/verify authentication tokens supplied in REST calls.</p>&#xA;&#xA;<p>I am wondering if, instead of the above, it is a) advisable and b) safe to share a single trusted public key certificate between all microservices? Something completely different?</p>&#xA;&#xA;<p>Please be polite. I am by no means an expert it this area.</p>&#xA;&#xA;<p><strong>EDIT:</strong>&#xA;It occurred to me, after reading replies/comments to my original post, that I omitted detail that might have made the problem more clear, and therefore the commenters better able to address it:</p>&#xA;&#xA;<ol>&#xA;<li><p>The microservices in question exist within a private intranet, and will only ever be accessible by clients (browsers or other microservices) within that intranet.</p></li>&#xA;<li><p>There is in fact a trusted CAâ€”namely, the company that owns this intranetâ€”and it is that CA that signs the microservicesâ€™ keypairs.</p></li>&#xA;</ol>&#xA;&#xA;<p>The resolution to this problem, it seems, is implied in @Andreas first comment, in which he wrote, ""As long as the CA that issued them is trusted, they will be trusted too.â€</p>&#xA;&#xA;<p>As long as each new microservice is deployed with a) its own keypairs, signed by the CA (one for signing and the other for encryption), and b) the CAâ€™s certificate, I can deploy new microservices with reasonable assurance they will communicate securely with all other microservices (reasonable because of other potential vulnerabilities I am not even aware of).</p>&#xA;&#xA;<p>Somehow I got it into my head that I would have to create a brand new certificate for each microserviceâ€™s keypair, and include these in the other microservices' keystores (repeat for every new microservice). Instead all I need is one certificate, that of the CA that signs the keypairs, in each microserviceâ€™s keystore.</p>&#xA;"
50350198,Run Git commands in microservice,2018-05-15 12:26:47,<git><microservices><spring-cloud><jgit>,1,57,7,0.0,0,"<p>I'm implementing microservice (in Spring Cloud) which acts as facade for Git operations invoked by UI layer. I'm trying to use jgit, but the problem is that it requires filesystem. So I have to clone remote repository to local filesystem. Problem is that then microservice is not stateless, and also other problems arises:</p>&#xA;&#xA;<ul>&#xA;<li>cloning before every operation takes too much time so is not an option </li>&#xA;<li>having multiple instances of such microservice can lead to different repositories (push take some time) </li>&#xA;<li>commits on different nodes at the same time can lead to conflicts</li>&#xA;</ul>&#xA;&#xA;<p>I would like to treat Git repository in similar way to database, so all operations should be done without using filesystem, cloning etc. - just invoke command on remote and it's done.</p>&#xA;&#xA;<p>I would like to add that it's quite hard to search for solution, because ""Git microservice"" phrase is quite common but in other sense (storing sources in repository).</p>&#xA;&#xA;<p>Edit: I've just found&#xA;<a href=""https://stackoverflow.com/questions/9442788/are-there-any-restful-interfaces-to-git"">Are there any restful interfaces to git?</a>&#xA;but any other ideas would be nice</p>&#xA;"
45526675,Async HTTP request vs HTTP requests on new thread,2017-08-05 21:48:09,<java><multithreading><rest><asynchronous><microservices>,3,533,0,0.0,0,"<p>I have 2 microservices (A and B).</p>&#xA;&#xA;<p>A has an endpoint which accepts POST requests. When users make a POST request, this happens:</p>&#xA;&#xA;<ol>&#xA;<li>Service A takes the object from the POST request body and stores it in a database.</li>&#xA;<li>Service A converts the object to a different object. And the new object gets sent to service B via Jersey HTTP client.</li>&#xA;</ol>&#xA;&#xA;<p>Step 2 takes place on a Java thread pool I have created (Executors.newCachedThreadPool). By doing step 2 on a new thread, the response time of service A's endpoint is not affected.</p>&#xA;&#xA;<p>However, if service B is taking long to respond, service A can potentially create too many threads when it is receiving many POST requests. To help fix this, I can use a fixed thread pool (Exectuors.newFixedThreadPool).</p>&#xA;&#xA;<p>In addition to the fixed thread pool, should I also use an asynchronous non-blocking HTTP client? Such as the one here: <a href=""https://hc.apache.org/httpcomponents-asyncclient-dev/"" rel=""nofollow noreferrer"">https://hc.apache.org/httpcomponents-asyncclient-dev/</a>. The Jersey HTTP client that I use is blocking.</p>&#xA;&#xA;<p>It seems like it is right to use the async HTTP client. <strong>But if I switch to a fixed thread pool, I think the async HTTP client won't provide a significant benefit - am I wrong in thinking this?</strong></p>&#xA;"
45413309,How to use websoket with spring cloud (Micro-services) ?,2017-07-31 10:24:37,<spring><microservices>,1,22,0,0.0,0,<p>i have created micro-service project and need to integrate with WebSocket</p>&#xA;
45396642,Avalability in Microservices architecture,2017-07-30 05:22:14,<architecture><microservices><high-availability>,1,53,0,0.0,0,<p>I am learning to migrate a legacy(monolithic)based architecture to micro services architect. What techniques can I use to ensure availability of the system? How can I implement in the architecture?</p>&#xA;
45528718,circuit breaker for high avalability in microservices architecture,2017-08-06 05:06:06,<architecture><microservices><high-availability><circuit-breaker>,1,55,0,0.0,0,<p>I am trying to learn about Circuit breaker that ensures high availability of the services. I am new to it. Can somebody explain me what actually it is and how can I use to have avalability in the system. I see lot of arctiles for the same but I am not clear about. I want to implement it basically to have high avalability in the system. </p>&#xA;
45530657,What is the correct way of sharing common yet versioned infrustructural code between microservices?,2017-08-06 09:40:12,<.net><nuget><versioning><microservices>,1,59,0,2.0,0,<p>We'd like to extract some infrastructure related code (mostly extension methods or small helper classes) into separate NuGet packages. </p>&#xA;&#xA;<p>These packages in no way contain business logic pertaining to either of the services.</p>&#xA;&#xA;<p>But as soon as as we end up having a hierarchy of dependencies between packages we are probably asking for troubles with versioning:</p>&#xA;&#xA;<p>Service1 references package Av1.1 directly and Av2.0 indirectly via referenced package B.<br/></p>&#xA;&#xA;<p>ServiceN references package Av1.5 directly and Av1.3 indirectly via referenced package C.<br/></p>&#xA;&#xA;<p>NuGet does not support side-by-side versions and only one version is used per project. This problem of versioning is relevant for monolithic applications as well though with seemingly significantly fewer possible integration issues.</p>&#xA;&#xA;<p>There are some ideas like not extracting common code and letting it be duplicated across services or just not changing the version of the package forcing every service to work with the same version.</p>&#xA;&#xA;<p>Are there any good recommendations concerning code reuse between services which go well with versioning?</p>&#xA;
45550556,Who should own the logic for service resolution in Service Fabric Stateful Services?,2017-08-07 15:26:13,<azure><microservices><azure-service-fabric><service-fabric-stateful><service-fabric-stateless>,1,61,0,0.0,0,"<p>I am using Service Fabric stateful services to store state about users in the system.  My partitioning strategy is to use the normalized international string format phone number to address a named service instance, and the hash of the phone number to resolve a partition of that service. EX: fabric:/myapp/users/1/718 (where the international phone number is +1718xxxxxxx) This allows me to geo-locate services based on their country (and further in the US/Canada markets by area code).  </p>&#xA;&#xA;<p>My question is sort of theoretical, but also practical in nature.  <strong>Who owns the logic for service resolution?</strong>  A simple approach is to just require anyone taking a dependency on this service to know how its partitioned, but that feels like a leaky abstraction to me.  Furthermore, I would like to assign an Id to the user which is divorced from the concept of a phone number.  </p>&#xA;&#xA;<ol>&#xA;<li>My original approach was to make the Id a byte[] which included the service name, partition id, and local id of the user.  I dropped this idea since the size of the ID was very large, and would add up over time.  (this is problematic because all keys in a Reliable Dictionary need to fit into memory and I'd rather not kill a ton of memory on ids) Also, it still carries with it the baggage of everyone using the id knowing how to interpret the id and use it accordingly.</li>&#xA;<li>My next idea was to provide a client library to anyone consuming the service.  This also has the drawback of a binary dependency of a consuming service.  If i want to change the strategy in the future, I have to jump through a bunch of hoops to handle failures to correctly resolve the entity.</li>&#xA;<li>The last alternative i can think of is to have a stateless proxy in front of stateful service which handles the resolution for all services.  This is the most appealing from a design perspective but also involves managing, building another service just for resolution.  Not opposed to it, but it is an additional consideration.  If i go this route, should I tread this service as a separate service fabric application, or is it advisable to keep everything as one application. </li>&#xA;</ol>&#xA;&#xA;<p>I also, am open to entertaining the idea that partitioning users this way is a bad idea. However, using the phone is advisable for a number of reasons.</p>&#xA;"
45467995,jhipster jdl import with microservices,2017-08-02 18:03:25,<jhipster><microservices>,1,399,0,0.0,0,"<p>I have a model.jdl with all entities defined like</p>&#xA;&#xA;<pre><code>entity A{ ... }&#xA;entity B{ ... }&#xA;entity C{ ... }&#xA;entity D{ ... }&#xA;</code></pre>&#xA;&#xA;<p>and I added some options to distribute this entities in microservices with sometime like this:</p>&#xA;&#xA;<pre><code>microservice A,B with gateway &#xA;microservice C with app1&#xA;microservice D with app2&#xA;</code></pre>&#xA;&#xA;<p>when I run the ""yo jhipster:import-jdl model.jdl"" command in the gateway  folder, the liquibase's changelog don't include the entities A and B.</p>&#xA;&#xA;<p>If I run the import in the apps folders, the liquibase changelog show all entities ignoring the distribution defined </p>&#xA;&#xA;<p>I tested the model in a monolithic app without the microservices options and works well... </p>&#xA;&#xA;<p>Here a model for test:</p>&#xA;&#xA;<pre><code>entity Car{&#xA;    name String required&#xA;    color Color&#xA;}&#xA;&#xA;enum Color{&#xA;    BLACK,WHITE,BLUE,GREEN,YELLOW&#xA;}&#xA;&#xA;entity House{&#xA;    address String required&#xA;}&#xA;&#xA;entity Info{&#xA;    phone String required&#xA;}&#xA;&#xA;relationship OneToOne{&#xA;    Info{user(login) required} to User&#xA;}&#xA;&#xA;microservice Info with gateway&#xA;microservice Car with app1&#xA;microservice House with app2&#xA;search * with elasticsearch&#xA;</code></pre>&#xA;"
45559979,Access Token/Authorization Between Microservices,2017-08-08 05:30:47,<spring-security><oauth-2.0><microservices><spring-cloud><spring-security-oauth2>,3,670,0,0.0,0,"<p>I'm creating an online store REST API that will mainly be used by a mobile app. The plan is for a microservices architecture using the Spring Cloud framework and Spring Cloud OAuth for security.</p>&#xA;&#xA;<p>My question is really on best practices for communication between microservices: Should I have each service register for their own token, or should they just pass the user's token around?</p>&#xA;&#xA;<p>For example, I have 3 services: user-service, account-service, order-service.&#xA;I've been able to implement two procedures for creating an order: One passes the user's token around, and in the other each service gets their own token. I use Feign for both approaches.</p>&#xA;&#xA;<p>So for option 1: order-service -> GET account-service/account/current</p>&#xA;&#xA;<p>order-service calls the account-service which returns the account based on a userId in the token. Then the order-service creates an order for the account.</p>&#xA;&#xA;<p>Or for option 2: order-service -> GET account-service/account/user-id/{userId}</p>&#xA;&#xA;<p>order-service gets the userId from the sent token, calls the account-service with it's own token, then creates the order with the retrieved account.</p>&#xA;&#xA;<p>I'm really not sure which option is best to use. One better separates information but then requires two Feign Clients. However the other doesn't require the 2 clients and it becomes easier to block off end certain endpoints to outside clients, however it requires extra endpoints to be created and almost every service to go digging into the Authentication object.</p>&#xA;&#xA;<p>What are all your thoughts? Has anyone implemented their system in one way or another way entirely? Or perhaps I've got the completely wrong idea.</p>&#xA;&#xA;<p>Any help is appreciated.</p>&#xA;"
45554704,How to auth microservices in loopback,2017-08-07 19:52:33,<authentication><loopbackjs><microservices><loopback>,2,188,0,0.0,0,"<p>Hi i would like to know if there is an example of how to authenticate between microservices in loopback, using the USER model of loopback.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45533748,version management in microservices,2017-08-06 15:47:08,<version-control><cloud><microservices><service-discovery>,2,1982,0,1.0,0,"<p>Suppose that I have a UserService in my <strong>Microservice Architecture</strong> deployed on the cloud. There is a <strong>Service Discovery</strong> for routing the requests to different host of UserService. </p>&#xA;&#xA;<p>If I have two different versions of UserService. Lets say <em>user-service-1.0</em> and <em>user-service-2.0</em> and part of clients should still use older version, then how this can be managed in Microservice Architecture. </p>&#xA;"
45380558,Spring Cloud Stream with Kafka - message not being read after restarting the consumer,2017-07-28 18:56:51,<spring><microservices><spring-cloud>,1,197,0,0.0,0,"<p>I have a micro service based application which reads messages from a Kafka topic. When the service is down, if there are any messages being written on the topic, I want the consumer to read those messages when it is up and running the next time. But I am missing all the messages when the service was down. How can I get the consumer to read the messages that were not read when the service was down?</p>&#xA;&#xA;<p>I am getting all the messages when my micro service was up and any messages being return to the topic.</p>&#xA;&#xA;<p>My application.properties:</p>&#xA;&#xA;<pre><code>spring.cloud.stream.bindings.input.destination=test&#xA;spring.cloud.stream.bindings.input.consumer.headerMode=raw&#xA;spring.cloud.stream.bindings.input.consumer.startOffset=latest&#xA;spring.cloud.stream.bindings.input.consumer.resetOffsets=true&#xA;spring.cloud.stream.bindings.input.consumer.instanceCount=3&#xA;spring.cloud.stream.bindings.input.consumer.autoCommitOffset=false&#xA;</code></pre>&#xA;&#xA;<p>// this is my consumer code under my micro service root dir</p>&#xA;&#xA;<pre><code>@EnableBinding(Sink.class) &#xA;public class Consumer { &#xA;    @ServiceActivator(inputChannel = Sink.INPUT)&#xA;    public void consoleSink(Object payload){&#xA;        logger.info(""Type: ""+ payload.getClass() + "" which is byte array"");&#xA;        logger.info( ""Payload: "" + new String((byte[])payload));&#xA;    } }&#xA;</code></pre>&#xA;&#xA;<p>I appreciate any clue to fix this issue.</p>&#xA;"
45579511,A/B testing. Routing Clients in a gateway API,2017-08-08 23:34:40,<microservices><ab-testing><api-gateway><canary-deployment>,3,760,0,0.0,0,"<p>I am working on a new project that will be based on microservices. It's an internal app and only about 10 microservices. We will be using a gateway API for authentication and possibly some microservice aggregation. (Probably Netflix zuul with Spring Boot)</p>&#xA;&#xA;<p>What I'm not clear on is how we do the routing for A/B testing and Canary testing. Lets assume I have 100 clients and we want to A/B test a new version of a microservice. The client app needs no changes, it's just internal changes to the function that the microservice provides.</p>&#xA;&#xA;<p>I understand we would stand up a new microservice which is (say) v2. What I'm puzzled on is how do I direct (say) clients 1-10 to the new version. We need to be able to configure this centrally and not change anything on the client.</p>&#xA;&#xA;<p>We know their mac addresses (as well as other identifying attributes) and can insert any kind of header we want to identify their messages.</p>&#xA;&#xA;<p>So how would I direct these to v2 of the API for the A/B test or Canary deployment?</p>&#xA;"
45449806,How many Frontend pieces for 10 microservices?,2017-08-02 00:55:56,<angularjs><architecture><microservices>,1,80,1,0.0,0,"<p>I have a bunch of microservices (10 to be precise), each with itÂ´s own database, own code repo, own deployment pipeline, and all the recommended stuff for microservices architecture.</p>&#xA;&#xA;<p>However, I dont have a clue on how to build the front end pieces, which are about to be developed by front end programmers.</p>&#xA;&#xA;<p>Should I have 10 of them, one for each backend microservice?&#xA;Or should I have just one?</p>&#xA;&#xA;<p>Maybe I can group some microservices, related to ADMIN role for instance, and create a single frontend for it? And another for another ROLE? Since I have about 4 ROLES, I may have 4 frontend apps?</p>&#xA;&#xA;<p>For the final user, app (ui) should look like a monolithic.</p>&#xA;&#xA;<p>What can you tell??</p>&#xA;&#xA;<p>Briefly speaking, the services are (ADMIN, CLIENT, DISTRIBUTOR and RESPONDENT as roles):</p>&#xA;&#xA;<p>1) oauth server (ADMIN, DISTRIBUTOR)</p>&#xA;&#xA;<p>2) users service (ADMIN)</p>&#xA;&#xA;<p>3) products service (ADMIN)</p>&#xA;&#xA;<p>4) survey service (CLIENT)</p>&#xA;&#xA;<p>5) jobposition service (DISTRIBUTOR)</p>&#xA;&#xA;<p>6) answer service (RESPONDENT)</p>&#xA;&#xA;<p>7) Email template service (ADMIN)</p>&#xA;&#xA;<p>8) Credit/transaction service (ADMIN)</p>&#xA;&#xA;<p>9 and 10) Batch services, but UI for showing batch status and result (ADMIN)</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45498517,AWS API Gateway Lambda as a proxy for microservices,2017-08-04 04:55:03,<amazon-web-services><aws-lambda><microservices><aws-api-gateway><api-gateway>,2,387,1,0.0,0,"<p>As my project is going to be deployed on <strong>AWS</strong>, we started thinking about <strong>AWS API Gateway</strong> as a way to have one main entry point for all of our microservices(frankly speaking, we also would like to use by some other reasons like security). I <strong><em>was playing with API Gateway REST API and I had feeling that it it a bit incovinient if we have to register there every REST service we have.</em></strong></p>&#xA;&#xA;<p>I found very good option of using <strong>AWS API Gateway</strong> and <strong>lambda function</strong> as a proxy. It is described here:</p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://medium.com/wolox-driving-innovation/https-medium-com-wolox-driving-innovation-building-microservices-api-aws-e9a455cc3456"" rel=""nofollow noreferrer"">https://medium.com/wolox-driving-innovation/https-medium-com-wolox-driving-innovation-building-microservices-api-aws-e9a455cc3456</a></li>&#xA;<li><a href=""https://aws.amazon.com/blogs/compute/using-api-gateway-with-vpc-endpoints-via-aws-lambda"" rel=""nofollow noreferrer"">https://aws.amazon.com/blogs/compute/using-api-gateway-with-vpc-endpoints-via-aws-lambda</a></li>&#xA;</ol>&#xA;&#xA;<p>I would like to know your opinion about this approach. May be you could also share some other approaches that can simplify API Gateway configuration for REST API? </p>&#xA;"
45542936,Manually test grpc interfaces,2017-08-07 08:52:48,<soap><protocol-buffers><soapui><microservices><grpc>,1,185,1,0.0,0,"<p>When you have soap webservice, you can always use soapui to create test xml requests for manual interface tests. You insert you test data into the xml document and send the request to the soap provider. You can then analyse the response in soapui.</p>&#xA;&#xA;<p>We are currently thinking about switching from soap with xml to grpc with protobuf3. Is there a test gui for grpc that offers features as described above for grpc? </p>&#xA;"
45398103,Microservice architecture for projects with low budgets / little traffic,2017-07-30 08:58:23,<microservices>,2,218,1,0.0,0,"<p>When implementing a microservice architecture and keeping services really small, you soon have many services, let's say 100 for simplicity. Now when deploying each service to an AWS nano instance, this would cost ~500$ / month, a rather hefty sum for a smaller project or a hobby developer. <strong>What options do I have to reduce this price, while still being able to have many services?</strong></p>&#xA;&#xA;<p>I thought about putting multiple services on one nano instance (maybe dockerized). I can comfortably fit ~5 services on one nano instance, so the price would be 5 times lower. The problem I have with this, is that I have to manage a lot of things and it doesn't seem to scale well. Is there a better way or alternatively a web-service that does this for me?</p>&#xA;"
45524591,Fallback method is not being called when rest call is failed by using feign client,2017-08-05 17:21:50,<microservices><netflix-eureka><netflix-feign><spring-cloud-feign><feign>,1,510,1,1.0,0,"<p>I am trying to implement fallback by using Feign client but not getting success.Its a simplest code Please find below.</p>&#xA;&#xA;<p>Main Class</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;@RestController&#xA;@EnableFeignClients&#xA;public class EurekaClient1Application {&#xA;&#xA;    @Autowired&#xA;    public DiscoveryClient discoveryClient;&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(EurekaClient1Application.class, args);&#xA;    }&#xA;&#xA;    @Autowired &#xA;    FeingInterface feingInterface;&#xA;&#xA;&#xA;&#xA;&#xA;    @GetMapping(""/hi/{name}"")&#xA;    public String test(@PathVariable String name)&#xA;    {&#xA;        String h = feingInterface.test(name);&#xA;&#xA;        return h;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Feign interface</p>&#xA;&#xA;<pre><code>@FeignClient(name=""client22"",fallback=FallBack.class)&#xA;public interface FeingInterface {&#xA;&#xA;    @GetMapping(""/hiname/{name}"")&#xA;    public String test(@PathVariable(""name"") String name);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>fallback class</p>&#xA;&#xA;<pre><code>@Component&#xA;class FallBack implements FeingInterface{&#xA;&#xA;    @Override&#xA;    public String test(String name) {&#xA;        // TODO Auto-generated method stub&#xA;        return ""fall back methord being called"";&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Getting Error in rest client but not from fallback method</p>&#xA;&#xA;<blockquote>&#xA;  <p>""timestamp"": 1501950134118,&#xA;      ""status"": 500,&#xA;      ""error"": ""Internal Server Error"",&#xA;      ""exception"": ""java.lang.RuntimeException"",&#xA;      ""message"": ""com.netflix.client.ClientException: Load balancer does not have available server for client: client22"",</p>&#xA;</blockquote>&#xA;&#xA;<p>To get the fallback method message I passed client22 eureka id which is not there in eureka server. I have stater-feign in pom. Can someone look into this.</p>&#xA;"
45374744,What is the benefit of having health check address on different port instead of using a different path?,2017-07-28 13:26:09,<architecture><microservices><health-monitoring>,1,34,2,0.0,0,"<p>When i search best practices for microservice architectures, sometimes a different port from application is used for health check address. Is this a good practice for microservices and what is pros and cons for this method?</p>&#xA;"
45371705,How and where to resolve foreign key in microservice architecture,2017-07-28 10:58:30,<architecture><microservices>,1,423,2,0.0,0,"<p>We recently started splitting a big monolith into microservices. One of the challenges we come across is that <strong>how and where to resolve the foreign key</strong>.</p>&#xA;&#xA;<p>To give you a better perspective. We are planning to build the following microservices. Each of these services has their own dedicated database in order to make services independent.</p>&#xA;&#xA;<p><strong>PriceQuote Service</strong>, primarily responsible for managing prices based on variant and city</p>&#xA;&#xA;<pre><code>PriceQuote&#xA;-----------------------   &#xA;id(Pk)&#xA;veriant_id(Fk)&#xA;city_id(Fk)&#xA;price&#xA;</code></pre>&#xA;&#xA;<p><strong>CarData Service</strong>, There are three concerns clubbed in this microservice. Makes, Models, Variants</p>&#xA;&#xA;<pre><code>Variants&#xA;-----------------------&#xA;id(Pk)&#xA;model_id(fk)&#xA;name&#xA;</code></pre>&#xA;&#xA;<p><strong>Location Service</strong>, States, cities, and areas clubbed in single microservice</p>&#xA;&#xA;<pre><code>Cities&#xA;-----------------------&#xA;id(Pk)&#xA;state_id(fk)&#xA;name&#xA;</code></pre>&#xA;&#xA;<p>Please help me with the following concerns</p>&#xA;&#xA;<ol>&#xA;<li><p><strong>Is this the right way of designing microservices?</strong></p></li>&#xA;<li><p><strong>Where to resolve variant_id and city_id Fks while retrieving price<br>&#xA;quote? inside or outside microservice?. if outside microservice? where?</strong></p></li>&#xA;</ol>&#xA;"
45426194,Message format/specification for distributed REST services?,2017-07-31 22:23:26,<rest><message-queue><microservices><messages>,1,28,3,0.0,0,"<p>I have a growing number of REST services that talk to each other with JSON. Right now, the communication is direct, but it's possible that a broker might process and distribute later on. </p>&#xA;&#xA;<p>This is the only one I've found so far:&#xA;<a href=""https://github.com/cjus/umf/blob/master/umf.md"" rel=""nofollow noreferrer"">https://github.com/cjus/umf/blob/master/umf.md</a></p>&#xA;&#xA;<p>Are there others that would be better suited? Thanks.</p>&#xA;"
48799257,Configuring to assign Private Network IP over PublicIP to the Pods in Istio,2018-02-15 02:42:14,<kubernetes><microservices><istio>,1,36,0,0.0,0,"<p>I am facing an issue over the automatic assignment of Public IP(172.16/...) to the pods when I deploy the sample Bookinfo application in Istio.</p>&#xA;&#xA;<p>Now that I am running on this application on cloud, Is there any way I can configure Istio(or Kubernetes) to assign the Private Network IP available for the pods rather than automatically assigning the PublicIP's as it used to in the local machine. </p>&#xA;&#xA;<p>I understand in the local machine deployment there was only PublicIP available hence it was an automatic choice. But here we have the both Public and Private Network IP available for the pods, hence is there a possibility of configuration?</p>&#xA;"
48653762,"Architecture: How microservices are different from isolated, standalone service?",2018-02-06 23:45:15,<rest><architecture><microservices>,1,39,0,0.0,0,"<p>I would like to understand, how microservices is different from creating separate, stand-alone service(like <strong>REST</strong> or <strong>SOAP</strong>).</p>&#xA;&#xA;<p>For instance, I have to create a license system for my <strong>Webapp</strong>. This can be simply a separate REST service, which can be consumed by <strong>Webapp</strong>. Still it can be tweaked, scaled up/down, isolated from my <strong>Webapp</strong>, </p>&#xA;&#xA;<ol>&#xA;<li><p>Why it needs to be a microservice ? </p></li>&#xA;<li><p>What are the pros and cons of each approach ?</p></li>&#xA;</ol>&#xA;"
48788264,Microservice calling multiple functions vs custom client specific function,2018-02-14 13:20:52,<architecture><microservices>,1,76,0,1.0,0,"<p>I have a microservice which exposes some gRPC functions. Each gRPC function just gets data from a table as a single record (using id parameter) or all records. The client is a backend data management system and it needs to build a report which will require data from multiple service functions.</p>&#xA;&#xA;<p>Now the obvious thought while using microservices is that client should make multiple service calls and combine the data at its end as per the requirement.</p>&#xA;&#xA;<p>Pros - Client and Microservice will be independent of each other</p>&#xA;&#xA;<p>Cons - Multiple gRPC calls (consider 5 per record * 30 records)</p>&#xA;&#xA;<p>But somehow this doesn't feel right (maybe its monolithic architecture thinking), just to show 30 records we'll have to make 150 gRPC calls. Hence the alternative could be to create a new gRPC function which combines all the data at the service itself.</p>&#xA;&#xA;<p>Pros - Only 1 gRPC call</p>&#xA;&#xA;<p>Cons - Client and microservice become dependent of each other which kind of defeats the purpose of microservice.</p>&#xA;&#xA;<p>I am more biased towards first approach but want to confirm what others think about this scenario.</p>&#xA;"
48667874,Authentication in microservices,2018-02-07 15:47:13,<.net><authentication><asp.net-core><jwt><microservices>,3,347,0,0.0,0,"<p>I am developing a microservice system for my company using ASP.NET Core. But a have faced with the following problem: when authenticated user is requesting some service, how should it check if the token is an actual (not blacklisted). I mean the case when user takes a new token but his old token is not expired yet thus the last one is an actual and could be used for accessing the resource services. So I gonna make all ofthe microservices ask the authentication service whether the token is an actual at each request. Perhaps there are any elegant ways to do it?</p>&#xA;"
48663545,How to implement microservices architecture with docker compose?,2018-02-07 12:14:30,<docker><architecture><docker-compose><containers><microservices>,1,355,0,0.0,0,"<p>I am working on a web application that requires few microservices like a URL shorter, mailer, analytics, etc... Each of these services are implemented as REST api so they can talk to each other. Each of these services have a <em>docker-compose.yml</em> file and use containers like nginx, php, mysql, etcâ€¦ I want these to work as a single system. I donâ€™t want to expose these REST apis to anyone outside of the docker network</p>&#xA;&#xA;<p>My question is how can I combine multiple <em>docker-compose.yml</em> files from each service so they work together? Or should I use one big <em>docker-compose.yml</em> file to define all the services under one network? Or should I base each of my service only on one container (ubuntu as base and install php, mysql, nginx through Dockerfile) then run them through <em>docker-compose.yml</em>, on a shared network?  Or have I misunderstood implementing microservices with Docker?</p>&#xA;"
48707364,Restart server on node failure with Consul,2018-02-09 13:48:54,<microservices><consul><spring-cloud-consul>,1,109,0,0.0,0,"<p>Newbie to Microservices here.</p>&#xA;&#xA;<p>I have been looking into develop a microservice with spring actuator while having Consul for service discovery and fail recovery. &#xA;I have configured a cluster as explained in Consul documentation. </p>&#xA;&#xA;<p>Now what I'm trying to do is configure a Consul Watch to trigger when any of my service is down and execute a shell script to restart my service. Following is my configuration file.</p>&#xA;&#xA;<pre><code>{&#xA; ""bind_addr"": ""127.0.0.1"",&#xA; ""datacenter"": ""dc1"",&#xA; ""encrypt"": ""EXz7LsrhpQ4idwqffiFoQ=="",&#xA; ""data_dir"": ""/data"",&#xA; ""log_level"": ""INFO"",&#xA; ""enable_syslog"": true,&#xA; ""enable_debug"": true,&#xA; ""enable_script_checks"": true,&#xA; ""ui"":true,&#xA; ""node_name"": ""SpringConsulClient"",&#xA; ""server"": false,&#xA; ""service"": { ""name"": ""Apache"", ""tags"": [""HTTP""], ""port"": 8080,&#xA;   ""check"": {""script"": ""curl localhost &gt;/dev/null 2&gt;&amp;1"", ""interval"": ""10s""}},&#xA; ""rejoin_after_leave"": true,&#xA; ""watches"": [&#xA;    {&#xA;      ""type"": ""service"",&#xA;      ""handler"": ""/Consul-Script.sh""&#xA;    }&#xA;  ]&#xA; } &#xA;</code></pre>&#xA;&#xA;<p>Any help/tip would be greatly appreciate.</p>&#xA;&#xA;<p>Regards,&#xA;Chrishan</p>&#xA;"
48715395,Docker containers unable to connect to each other,2018-02-09 23:05:51,<docker><.net-core><docker-compose><microservices>,1,110,0,0.0,0,"<p>I am building a microservice solution using docker compose to run locally.&#xA;I'm using .netcore for the services. &#xA;When I run the projects using visual studio everything connects and works fine but when i run in docker i can connect to the services externally but the services are unable to connect to each other.When I inspect in docker everything looks ok and all containers are on the same network. I'm assuming it is some small setting or configuration I'm missing but haven't been able to find anyone with the same issue.</p>&#xA;&#xA;<p>Here's the docker-compose code</p>&#xA;&#xA;<pre><code>docker-compose.yml&#xA;&#xA;    version: '3'&#xA;&#xA;services:&#xA;  underrule.frontend:&#xA;    image: underrule.frontend&#xA;    build:&#xA;      context: ./UnderRule.FrontEnd&#xA;      dockerfile: Dockerfile&#xA;&#xA;  underrule.apigateway:&#xA;    image: underrule.apigateway&#xA;    build:&#xA;      context: ./UnderRule.ApiGateway&#xA;      dockerfile: Dockerfile&#xA;&#xA;  underrule.authentication:&#xA;    image: underrule.authentication&#xA;    build:&#xA;      context: ./UnderRule.Authentication&#xA;      dockerfile: Dockerfile&#xA;&#xA;  underrule.playerservice:&#xA;    image: underrule.playerservice&#xA;    build:&#xA;      context: ./UnderRule.PlayerService&#xA;      dockerfile: Dockerfile&#xA;&#xA;  underrule.registrationservice:&#xA;    image: underrule.registrationservice&#xA;    build:&#xA;      context: ./UnderRule.RegistrationService&#xA;      dockerfile: Dockerfile&#xA;&#xA;  underrule.worldservice:&#xA;    image: underrule.worldservice&#xA;    build:&#xA;      context: ./UnderRule.WorldService&#xA;      dockerfile: Dockerfile&#xA;&#xA;docker-compose.override.yml&#xA;&#xA;    version: '3'&#xA;&#xA;services:&#xA;  underrule.frontend:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""5000:80""&#xA;&#xA;  underrule.apigateway:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""9000:80""&#xA;&#xA;  underrule.authentication:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""5001:80""&#xA;&#xA;  underrule.playerservice:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""5002:80""&#xA;&#xA;  underrule.registrationservice:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""5004:80""&#xA;&#xA;  underrule.worldservice:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;    ports:&#xA;      - ""5003:80""&#xA;&#xA;all dockerfiles are basically the same&#xA;&#xA;    FROM microsoft/aspnetcore:2.0&#xA;    ARG source&#xA;    WORKDIR /app&#xA;    EXPOSE 80&#xA;    COPY ${source:-obj/Docker/publish} .&#xA;    ENTRYPOINT [""dotnet"", ""UnderRule.ApiGateway.dll""]&#xA;</code></pre>&#xA;&#xA;<p>Any ideas? I've tried messing with the ports without much luck.</p>&#xA;&#xA;<p>I am connecting internally using HttpClient with the path like&#xA;<a href=""http://localhost"" rel=""nofollow noreferrer"">http://localhost</a>:{port}</p>&#xA;&#xA;<p>Help is very much appreciated and let me know if you need more info.</p>&#xA;"
48699742,How to handle user authentication with microservices in AWS?,2018-02-09 06:10:16,<node.js><amazon-web-services><authentication><microservices>,3,374,0,0.0,0,"<p>I'm reading a tutorial provided by AWS explaining how to break up a monolithic NodeJS application into a microservice architectured one.</p>&#xA;&#xA;<p><a href=""https://aws.amazon.com/getting-started/container-microservices-tutorial/"" rel=""nofollow noreferrer"">Here is a link to it.</a></p>&#xA;&#xA;<p>One important piece is missing from <a href=""https://github.com/awslabs/amazon-ecs-nodejs-microservices/tree/master/3-microservices"" rel=""nofollow noreferrer"">the simple application example they've provided</a> and that is <strong>user authentication</strong>.</p>&#xA;&#xA;<p>My question is, where does authentication fit into all this? &#xA;How do you allow users to authenticate to all these services separately? </p>&#xA;&#xA;<p>I am specifically looking for an answer that <strong>does not</strong> involve AWS Cogntio. I would like to have my own service perform user authentication/management.</p>&#xA;"
48726644,Zuul Api Gateway mapped wrong service url (character set)?,2018-02-10 23:23:38,<encoding><utf-8><special-characters><microservices><netflix-zuul>,2,375,0,0.0,0,"<p>Im trying to create microservices but zuul api gateway service maped wrong url. Seems it is related to encoding problem. </p>&#xA;&#xA;<p>Zuul application.properties</p>&#xA;&#xA;<pre><code>spring.application.name=zuul-api-gateway&#xA;server.port=8765&#xA;&#xA;eureka.client.service-url.default-zone=http://localhost:8761/eureka&#xA;</code></pre>&#xA;&#xA;<p>Service application.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: car-service&#xA;  datasource:&#xA;    driver-class-name: com.mysql.jdbc.Driver&#xA;    url: jdbc:mysql://localhost:3307/car_service_db?useSSL=false&#xA;    username: root&#xA;    password: admin&#xA;  profiles:&#xA;    active: local&#xA;server:&#xA;  port: 8080&#xA;&#xA;eureka:&#xA;  client:&#xA;    service-url:&#xA;      default-zone: http://localhost:8761/eureka&#xA;&#xA;management:&#xA;  security:&#xA;    enabled: false&#xA;</code></pre>&#xA;&#xA;<p>Other service application.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: company-service&#xA;  datasource:&#xA;    driver-class-name: com.mysql.jdbc.Driver&#xA;    url: jdbc:mysql://localhost:3307/company_service_db?useSSL=false&#xA;    username: root&#xA;    password: admin&#xA;server:&#xA;  port: 8081&#xA;&#xA;eureka:&#xA;  client:&#xA;    service-url:&#xA;      default-zone: http://localhost:8761/eureka&#xA;&#xA;&#xA;management:&#xA;  security:&#xA;    enabled: false&#xA;</code></pre>&#xA;&#xA;<p>Eureka logs:</p>&#xA;&#xA;<pre><code>2018-02-11 00:02:41.204  INFO 22672 --- [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance CAR-SERVICE/localhost:car-service:8080 with status UP (replication=false)&#xA;2018-02-11 00:02:58.469  INFO 22672 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms&#xA;2018-02-11 00:03:06.468  INFO 22672 --- [nio-8761-exec-4] c.n.e.registry.AbstractInstanceRegistry  : Registered instance COMPANY-SERVICE/localhost:company-service:8081 with status UP (replication=false)&#xA;2018-02-11 00:03:26.139  INFO 22672 --- [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance ZUUL-API-GATEWAY/localhost:zuul-api-gateway:8765 with status UP (replication=false)&#xA;</code></pre>&#xA;&#xA;<p>And the zuul logs</p>&#xA;&#xA;<pre><code>2018-02-11 00:03:35.037  INFO [zuul-api-gateway,6944cfba5180a640,6944cfba5180a640,false] 2132 --- [nio-8765-exec-1] o.s.c.n.zuul.web.ZuulHandlerMapping      : Mapped URL path [/car-servÄ±ce/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController]&#xA;2018-02-11 00:05:06.872  INFO [zuul-api-gateway,773aa5fc779af5e6,773aa5fc779af5e6,false] 2132 --- [nio-8765-exec-3] o.s.c.n.zuul.web.ZuulHandlerMapping      : Mapped URL path [/company-servÄ±ce/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController]&#xA;2018-02-11 00:05:06.873  INFO [zuul-api-gateway,773aa5fc779af5e6,773aa5fc779af5e6,false] 2132 --- [nio-8765-exec-3] o.s.c.n.zuul.web.ZuulHandlerMapping      : Mapped URL path [/zuul-apÄ±-gateway/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController]&#xA;</code></pre>&#xA;&#xA;<p>In the zuul logs, all services mapped by special letter with 'Ä±' which is the turkish character instead of 'i' and i can not reach my services via zuul api gateway. </p>&#xA;&#xA;<p>I have also tried override Zuul configuration in this example : <a href=""https://stackoverflow.com/questions/41881610/spring-cloud-zuul-breaks-utf-8-symbols-in-forwarded-multipart-request-filename"">Spring-Cloud Zuul breaks UTF-8 symbols in forwarded multipart request filename</a></p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class WebConfig extends WebMvcConfigurerAdapter {&#xA;&#xA;    @Bean&#xA;    FormBodyWrapperFilter formBodyWrapperFilter() {&#xA;        return new FormBodyWrapperFilter(new MyFormHttpMessageConverter());&#xA;    }&#xA;&#xA;    private class MyFormHttpMessageConverter extends FormHttpMessageConverter {&#xA;&#xA;        private byte[] getAsciiBytes(String name) {&#xA;            try {&#xA;                // THIS IS THE ONLY MODIFICATION:&#xA;                return name.getBytes(""UTF-8"");&#xA;            } catch (UnsupportedEncodingException ex) {&#xA;                // Should not happen - US-ASCII is always supported.&#xA;                throw new IllegalStateException(ex);&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So when i try call service via Zuul api gateway, it returns 404 not found.</p>&#xA;&#xA;<p>Im using spring-boot 2.0.0.M3, spring-cloud Finchley.M2 versions</p>&#xA;"
48804675,"Connect-ServiceFabricCluster : No cluster endpoint is reachable, please check if there is connectivity/firewall/DNS issue",2018-02-15 10:14:45,<visual-studio><powershell><azure><visual-studio-2017><microservices>,1,171,0,0.0,0,"<p>I went through this <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-tutorial-deploy-app-to-party-cluster"" rel=""nofollow noreferrer"">document</a> for creating &amp; deploying the application into Party Cluster using Visual Studio 2017 &amp; Powershell.</p>&#xA;&#xA;<p>Now I am stuck with the following error in Power shell &amp; Visual Studio :</p>&#xA;&#xA;<p><strong>Power Shell :</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ZTQNt.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZTQNt.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Visual Studio 2017 :</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/aIbli.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aIbli.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>NB :</strong> I tried this <a href=""https://i.stack.imgur.com/ZTQNt.jpg"" rel=""nofollow noreferrer"">solution</a> in my application, But getting the same result. Any other solution ?</p>&#xA;"
48699765,UI with microservices,2018-02-09 06:12:15,<angular><web-services><web-applications><frontend><microservices>,2,1456,0,0.0,0,<p>I have fornt end Web application written in JSF with Richfaces. Its a kind of dashboard application. We are trying to move this in Angular 2 with Spring Boot rest api. &#xA;I want to write microservices where each functionality would be independent. There are total 10 functionality so i will write 10 different rest services and each one would have its own build process. But i am confused with fornt end part. Should i create separate artifacts or separate build for each UI as well ? Or should i bundle in each respective rest api? how should i take care of front end part in microservices?</p>&#xA;
48650993,Spring Cloud Stream is creating exchange on Consumer service startup,2018-02-06 19:59:35,<spring><microservices><spring-cloud-stream><spring-rabbitmq>,1,198,0,0.0,0,"<p>I have two microservices <code>Student</code> and <code>Teacher</code></p>&#xA;&#xA;<p>in <code>Student</code> microservice I am creating a <code>MessageSink</code> for exchange <code>XYZ</code> </p>&#xA;&#xA;<pre><code>@Input(""XYZ"")&#xA;SubscribableChannel xyz();&#xA;</code></pre>&#xA;&#xA;<p>and in <code>Teacher</code> microservice I am configuring exchange <code>XYZ</code> as a <code>fanout</code></p>&#xA;&#xA;<p><strong>application.properties</strong></p>&#xA;&#xA;<pre><code> spring.cloud.stream.rabbit.bindings.XYZ.producer.exchangeType=fanout&#xA; spring.cloud.stream.bindings.XYZ.contentType=application/json&#xA;</code></pre>&#xA;&#xA;<p>But problem I am facing here is <code>Student</code> service is starting before <code>Teacher</code> service and it is creating <code>XYZ exchange</code> with type <code>Topic</code> and then <code>Teacher</code> service starting is giving me following error:</p>&#xA;&#xA;<pre><code>amqp.rabbit.core.RabbitAdmin - Failed to declare exchange: Exchange [name=XYZ, type=fanout, durable=true, autoDelete=false, internal=false, arguments={}], continuing... com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=406, reply-text=PRECONDITION_FAILED - inequivalent arg 'type' for exchange 'XYZ' in vhost '/': received 'fanout' but current is 'topic', class-id=40, method-id=10)&#xA;</code></pre>&#xA;&#xA;<p>so is there any configuration to change the <code>exchangeType</code> or delete existing <code>exchange</code> and create new <code>exchange</code> or set <code>exchangeType</code> in <code>@Input</code> ?</p>&#xA;"
48784283,Oauth authentication with laravel passport for mobile app,2018-02-14 10:00:01,<oauth><authorization><microservices><access-token><laravel-passport>,1,219,0,0.0,0,<p>I am using laravel passport for authorization from mobile app. </p>&#xA;&#xA;<p>But I'm not sure where to place the <code>client credentials</code> i.e <code>client_id/client_secret</code> and <code>redirect_uri</code>. </p>&#xA;&#xA;<ol>&#xA;<li>Will it be placed at mobile app end and they will pass these to an API while authenticating to get tokens or these details be kept at server side in some env variables for security purpose? </li>&#xA;<li>And will the every user be having different client_id and secret or it will be same for all users throughout the application.</li>&#xA;</ol>&#xA;
48808722,Oauth 2 : Spring Boot - Separate Resource server protecting Microservices,2018-02-15 13:43:10,<java><spring-boot><oauth-2.0><microservices>,2,507,0,0.0,0,"<p>For my recent project, I have created a separate resource server using spring boot. Resource Server is configured in a way that it will check for 2 legged and 3 legged access to an API and also validates the JWT token. Resource server is an independent spring boot jar running in its container.<br/>&#xA;We have created several microservices using Spring Boot which are executable jars, deployed and running independently in their container. Resource server will protect end points exposed in these microservices. For that, I have created a RestController in resource server in which end point is exposed which will call the microservice end point when request comes in. for e.g <br/>&#xA;<b>Microservice.java</b> - Running at port 8080</p>&#xA;&#xA;<pre><code>@RequestMapping(""/getUser"")&#xA;public String getUserName(){&#xA;   return ""xyz"";&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><b>Resource Server</b> - Running at port 8090 <br/>&#xA;ResourceServerController.java</p>&#xA;&#xA;<pre><code>@RequestMapping(""/userInfo"")&#xA;public String getUserName(){&#xA; // calling above microservice using rest template&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There can be several end point in a several microservices and as we have to protect them, is it right to proxy every end point in the rest controller of a resource server? I am not sure whether it is a correct approach. Other approach which we think of is to create a jar of resource server and deployed as a dependency with every microservice. In this way, we do not need to proxy end points in the Rest Controller of Resource Server.<br/>&#xA;Just wanted to know the best way to Protect microservices using separate resource server.</p>&#xA;"
48784692,Azure Service Fabric:How to pass data to guest executable at run time?,2018-02-14 10:18:56,<azure><microservices><azure-service-fabric><azure-cloud-services>,1,44,1,0.0,0,<p>I have a stateless service that spin up a new guest executable on demand.I need to pass some data at service creation time to guest executable.&#xA;How can i do that??</p>&#xA;
48624302,Jenkins and git building only the changed folders,2018-02-05 14:02:08,<git><docker><jenkins><microservices>,1,73,2,0.0,0,"<p>I have a multibranch pipeline project in Jenkins. My Jenkins job mainly consists of building dotnet-core docker images and pushing them onto the docker repository then starting containers on a Jenkins slave using a compose file. In my VS solution file, I have 6-7 projects in separate folders. The number will increase. All of them are docker images that will run in containers. </p>&#xA;&#xA;<p>At the moment, I use <code>dotnet publish</code> for each project then build the images using the compose file. The problem is, I need to build all of them even when there are no changes in the image. I want to build only the apps which are not changed. Is there a way for me to filter out the unchanged folders and build only them?</p>&#xA;"
48802787,Open Source Projects that migrated to microservices,2018-02-15 08:24:11,<open-source><microservices>,1,208,2,0.0,0,<p>Are you aware of any open source projects that migrated to micro services?</p>&#xA;&#xA;<p>We are conducting some research works analysing architectural patterns of microservices-based OSS but we cannot find anything else than toy projects and students prototypes</p>&#xA;
48810786,is putting sqs-consumer to detect receiveMessage event in sqs scalable,2018-02-15 15:30:43,<microservices><amazon-sqs>,1,78,3,0.0,0,"<p>I am using aws sqs as message queue. After <code>sqs.sendMessage</code> sends the data , I want to detect <code>sqs.receiveMessage</code> via either infinite loop or event triggering in scalable way. Then I came accross <a href=""https://www.npmjs.com/package/sqs-consumer"" rel=""nofollow noreferrer"">sqs-consumer</a> &#xA;to handle <code>sqs.receiveMessage</code> events, the moment it receives the messages. But I was wondering , is it the most suitable way to handle message passing between microservices or is there any other better way to handle this thing?</p>&#xA;"
48760583,How to refresh request token with microservice multiple instances,2018-02-13 06:18:32,<java><microservices><access-token><spring-cloud>,1,177,3,0.0,0,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<p>When the request token expires and multiple requests happen from different service instances, that all request a new request token via the remote HTTP call, at the same time, the latter request token will make the former request token invalid. Because each request to get a new token will make the previous one invalid. The service to generate request token is a third party one, we can't change it.</p>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Our application architecture is microservice based, each service will have multiple instances, how can I reuse the request token between each service?(maybe store it in an external Redis is an option)</p></li>&#xA;<li><p>During the service starting up, how can we make sure only one refresh token request sent to the third party service?</p></li>&#xA;<li><p>Afterwards, when the request token expires, how can we renew it?</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>Tech Stack:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Java 8</li>&#xA;<li>SpringCloud</li>&#xA;<li>Redis</li>&#xA;<li>Rancher</li>&#xA;<li>MySQL</li>&#xA;</ul>&#xA;"
37939567,microservice architectural choice using api gateway with web portal application,2016-06-21 08:44:37,<spring-cloud><microservices><netflix-zuul>,1,259,0,0.0,0,<p>I'm currently working on a microservices architecture. Thoses microservices will be integrated in web-portal which will be the entry point. I'd need to use an api gateway(edge-server) but i'm wondering if it's better to create a separate microservice dedicated to api gateway or use the web-portal microservice as api gateway.</p>&#xA;&#xA;<p>What do you think would be a better choice?</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;
37839701,How to pass binary data between microservices in Spring Cloud?,2016-06-15 15:29:12,<spring><spring-cloud><microservices>,1,288,0,0.0,0,<p>I'd like to ask. How to pass binary data between microservices in Spring Cloud?</p>&#xA;&#xA;<p>Should (Can) I use @FeignClient or @RibbonClient ? How it should be? I've already read that @FeignClient is not deal with this issue What else? OkHttp?</p>&#xA;&#xA;<p>Thx in advance </p>&#xA;
37849739,Do Ldap Groups as Scopes work for cloud foundry uaa authorization_code grant type?,2016-06-16 04:07:56,<jwt><spring-cloud><microservices><spring-cloud-netflix><cloudfoundry-uaa>,1,303,0,0.0,0,"<p>I'm trying to get a micro-services environment working. I've already setup the config-server, eureka-server, zuul-server, and service. To handle security I have a Cloud Foundry's UAA server installed and running. </p>&#xA;&#xA;<p>Following the docs on how to setup the UAA server there's the option to have <a href=""https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md"" rel=""nofollow"">Ldap Groups as Scopes</a> which I have and I can see how they get created on the UAA Server logs, but they don't get into the JWT Token. Zuul is proxying correctly to the UAA Server, I do the authentication process on UAA and get the JWT Token on Zuul, and then zuul adds proxies it to the service behind it, but without the logged in user's groups/scopes only the openid scope that's on the client configuration. Am I missing something? Or this is how things work and I'll have to implement a workaround, which would be getting the user's username from the token and getting his access privileges on each request for each service?</p>&#xA;&#xA;<p>Here's my uaa.yml:</p>&#xA;&#xA;<pre><code>spring_profiles: ldap,mysql&#xA;&#xA;disableInternalUserManagement: true&#xA;&#xA;zones:&#xA;  internal:&#xA;    hostnames:&#xA;      - sso.example.com&#xA;&#xA;oauth:&#xA;  user:&#xA;    authorities:&#xA;      - openid&#xA;      - scim.me&#xA;      - password.write&#xA;      - scim.userids&#xA;      - uaa.user&#xA;      - approvals.me&#xA;      - oauth.approvals&#xA;  clients:&#xA;    sso:&#xA;      secret: changeme!&#xA;      authorized-grant-types: authorization_code, refresh_token&#xA;      # How do I add the user groups as scopes?&#xA;      # Is it possible with this grant type?&#xA;      scope: openid&#xA;      authorities: uaa.resource&#xA;&#xA;ldap:&#xA;  profile:&#xA;    file: ldap/ldap-search-and-bind.xml&#xA;  base:&#xA;    url: ldap://ldap.example.com:389&#xA;    mailAttributeName: mail&#xA;    mailSubstitute: '{0}@example.com'&#xA;    mailSubstituteOverridesLdap: true&#xA;    userDn: 'CN=Example User,OU=Admins,DC=example,DC=com'&#xA;    password: 'changeme!'&#xA;    searchBase: 'dc=example,dc=com'&#xA;    searchFilter: 'sAMAccountName={0}'&#xA;  groups:&#xA;    file: ldap/ldap-groups-as-scopes.xml&#xA;    searchBase: 'dc=example,dc=com'&#xA;    groupRoleAttribute: cn&#xA;    searchSubtree: true&#xA;    groupSearchFilter: 'member={0}'&#xA;    maxSearchDepth: 1&#xA;    autoAdd: true&#xA;  attributeMappings:&#xA;    first_name: 'givenName'&#xA;    last_name: 'sn'&#xA;&#xA;smtp:&#xA;  host: mail.example.com&#xA;  port: 25&#xA;&#xA;database:&#xA;  url: jdbc:mysql://mysql.example.com/uaa&#xA;  username: uaa&#xA;  password: changeme!&#xA;&#xA;jwt:&#xA;  token:&#xA;    verification-key: |&#xA;      -----BEGIN PUBLIC KEY-----&#xA;      -----END PUBLIC KEY-----&#xA;    signing-key: |&#xA;      -----BEGIN RSA PRIVATE KEY-----&#xA;      -----END RSA PRIVATE KEY-----&#xA;&#xA;login:&#xA;  url: https://sso.example.com/uaa/login&#xA;  branding:&#xA;    companyName: 'Example Company'&#xA;</code></pre>&#xA;"
37989016,Examples of using Avro in ruby for intercommunication for microservices,2016-06-23 10:28:28,<ruby><avro><microservices>,1,100,0,0.0,0,"<p>I'm doing a little research into intra microservice communication and I stumbled onto <a href=""http://blog.salsify.com/engineering/adventures-in-avro"" rel=""nofollow"">this web-blog</a> and found it interesting. The problem however is I can't seem to find any examples of using avro for communication so could some one link some resources on this, specifically aimed at ruby?</p>&#xA;&#xA;<p>Or have I completely misunderstood it's purpose and it's not meant for use in micro-services?</p>&#xA;"
37977210,Microservices and Joins for Large Lists of Data,2016-06-22 20:00:38,<sql><jpa><join><microservices>,1,449,0,0.0,0,"<p>Although I have found moving into the Microservice technology to be very compelling and rewarding in many ways, one challenge I came across is when you traditionally would write a query based on JPA that may join a Customer with an Address (this is just an example). </p>&#xA;&#xA;<p>The problem is, we need to return many customer records (say 100 at a time) where each Address is assigned to a Customer (let's assume one to one relationship).  </p>&#xA;&#xA;<p>Using a Join and JPA solves this problem very easily, but in Microservices, essentially we would need 2 Microservices, one for Customer, one for Address.  The problem is, we may first fetch the Customer records but how do we return all of the Address records that relate to each Customer since the Address records have a dependency on the Customer being queried?  </p>&#xA;&#xA;<p>I don't think we can use a single query in each Microservice that would return every Address unless we use every Customer ID from the first result as that would be horrible in so many ways. </p>&#xA;&#xA;<p>Since the criteria for the query may not pertain to both Microservices (example: if we search by last name), we don't have a single criteria value we can use in both Microservices that would allow us to easily map the data together in the gateway. </p>&#xA;&#xA;<p>So what do we do?</p>&#xA;"
37906461,Zuul and webapp architecture,2016-06-19 10:56:00,<spring-boot><microservices><netflix-zuul>,1,225,0,0.0,0,<p>I've a question about the global architecture of multiple webapplications and zuul.  With a classic webapp my pages talk to the webserver that hosts my webapp. With zuul do my pages need to directly talk to my zuul server.... and then be redirected to the appropriate service?</p>&#xA;
37806275,What are the best practices in building Microservices APIs in terms of communication technology?,2016-06-14 08:02:28,<web-services><architecture><microservices>,1,233,0,0.0,0,"<p>What are the best practices in chosing specific communication protocol in  building Microservices? </p>&#xA;&#xA;<p>For instance, when building MySQL microservice, shall I use the native MySQL connection or prefer a wrapping API in REST or something else?</p>&#xA;&#xA;<p>Secondly, shall I choose and use a single protocol like REST, JSON-RPC etc. for all interaction among microservices? </p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
37989803,Security between microservices layers,2016-06-23 11:04:52,<security><microservices>,2,323,1,0.0,0,"<p>I've read a lot about microservices, but one question remain : the security.</p>&#xA;&#xA;<p>What I would like to do is something similar to Netflix, i.e one general backend and many backends for each front end (for example mobile devices, desktop app, ...).</p>&#xA;&#xA;<p>On the top of that I plan to put my firewall security layer. Here is the problem : how to authorize a request through this layer only once and not in each microservice ?</p>&#xA;&#xA;<p>Is is possible to expose certain microservices to the whole internet, and others only to trusted sources ? If so, is it the right way ?</p>&#xA;"
37938389,Keystore Management in Cloud Environment,2016-06-21 07:44:39,<java><cloud><keystore><microservices><pki>,1,504,2,0.0,0,"<p>I have a java keystore in which I am storing a content signing key and few certificates to be used by my application. The keystore can be updated by a web portal i.e. certificates can be added, deleted from it.</p>&#xA;&#xA;<p>Now this application will be deployed on elastic cloud and will have multiple instances running. I am stuck in how can this keystore be synchronized between multiple instances so that all the instances have signing key and public certificates available. Should I store the keys and certificates in database instead?</p>&#xA;"
37864255,Security between microservices,2016-06-16 16:07:44,<spring-security><microservices><spring-cloud-feign><spring-cloud-security>,2,1835,3,0.0,0,"<p>I have two microservices, for example, A and B. The microservice B has the rest enpoint that must be accessible only from the microservice A.&#xA;How can I limit access between microservices? What is the best practice if at all possible?</p>&#xA;&#xA;<p>I'm using spring cloud security (oauth2, jwt).</p>&#xA;"
37336871,How to get url for sibling modules in app engine,2016-05-20 02:10:01,<python><google-app-engine><webapp2><microservices>,2,59,0,0.0,0,"<p>I have an App Engine application that has multiple independent modules. </p>&#xA;&#xA;<p>When <a href=""https://cloud.google.com/appengine/docs/python/designing-microservice-api"" rel=""nofollow"">deployed</a>, these modules become available at <code>http://&lt;module&gt;.&lt;app_id&gt;.appspot.com</code>, and when testing locally with <code>dev_appserver.py mod1.yaml mod2.yaml --port-9000</code>, then <code>mod1</code> runs in <code>http://localhost:9000</code> and <code>mod2</code> runs in <code>http://localhost:9001</code>. All the modules are running on the same project. So far so good.</p>&#xA;&#xA;<p>Let's assume <code>mod1</code> needs to talk to <code>mod2</code>. Is there a way I can get a url for <code>mod2</code> within <code>mod1</code>, dynamically? </p>&#xA;&#xA;<pre><code># In mod1's code&#xA;import google.some.magic&#xA;url_for_mod2 = magic.get_url_for_module('mod2') # http://localhost:9001 or http://mod2.id.appspot.com&#xA;</code></pre>&#xA;"
37461203,How can the WCF service be consumed by a client that is outside the azure fabric service,2016-05-26 12:42:35,<c#><microservices><azure-service-fabric>,2,359,0,0.0,0,<p>I need to expose a WCF endpoint and map this for external clients (not DOTNET) to consume. Is there a way to customize one of the listeners to allow a mappable external port?&#xA;This WCF need to be called from 3rd party.</p>&#xA;
37395986,IBM MQ vs Apache Kafka as a message broker/engine for Event Driven Architecture and Microservices Architecture,2016-05-23 16:23:21,<architecture><apache-kafka><mq><microservices><event-driven>,1,481,0,0.0,0,"<p><strong>Context:</strong> My company uses WebLogic AppServer and Oracle Service Bus for SOA service orchestration and choreography. We would like to move forward to an event-driven, microservices architecture. The key point is to eliminate the complex of service orchestration in back office.</p>&#xA;&#xA;<p><strong>Question:</strong> What is the recommended message engine for an event-driven, microservices architecture? If performance and high through put are not our top concerns. Our biggest concern is the guaranteed delivery, fail-over, and system Resilience. <strong>Resilience</strong> can be achieved in different ways in MQ and Kafka.</p>&#xA;&#xA;<p>Also consider: ""<strong>Dumb pipe, smart endpoint</strong>"" as a principle, is Apache Kafka more appealing, plus resilience?</p>&#xA;&#xA;<p>Any thoughts and opinions are welcome. Thanks in advance.</p>&#xA;"
37521011,Wso2 Microservices (MSF4j) : handling logging,2016-05-30 08:28:54,<logging><spring-boot><wso2><microservices><msf4j>,1,359,1,0.0,0,<p>Assume I have 5 MSF4j micro services and if those services are interconnected what will be the best mechanism to do logging? </p>&#xA;&#xA;<p>My main concerns are? </p>&#xA;&#xA;<p>1) Should logging has to be another separate micro service ? </p>&#xA;&#xA;<p>2) If not we have to add logging component into all 5 micro services. In this case it will create separate log files for each one. So in that case what will be the best way to find debug information on logs? We may have to use field like co-relation id. If we user core-relation id like field what will be the best open source logging tool to visualize logs by filtering multiple log file with core-relation id? </p>&#xA;
37445823,Force an Asynchronous call to behave Synchronously,2016-05-25 19:16:46,<javascript><asynchronous><reactjs><microservices>,2,250,3,0.0,0,"<p>In my React app, I'm trying to calculate a value based on three other values. I've contained all of the calculation logic to the back end, which is a microservice I make asynchronous calls to. The function in which I am asynchronously trying to get that calculated value is in the middle of many synchronous hooks. </p>&#xA;&#xA;<p>In the UI layer, I call the function which I want to return the end result (returned asynchronously). That called function calls another function, which calls another function, which returns a new Promise. See code below:</p>&#xA;&#xA;<pre><code>// DateUI.js (layer 1)&#xA;selectDate(dateField, flight, idx, saved, momentTime, e) {&#xA;    if (moment(momentTime).isValid()) {&#xA;        if (dateField == ""StartDate"") {&#xA;            // The initial problematic function call, need to set endDate before I continue on&#xA;            let endDate = PlanLineActions.calculateFlightEndDate(periodTypeId, numberOfPeriods, momentTimeUnix);&#xA;&#xA;            flight.set(""EndDate"", endDate);&#xA;        }&#xA;&#xA;        this.theNextSyncFunction(..., ..., ...);&#xA;    }&#xA;}&#xA;&#xA;&#xA;// DateActions.js (layer 2)&#xA;calculateFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let plan = new Plan();&#xA;&#xA;    plan.getFlightEndDate(periodTypeId, numberOfPeriods, startDate).then(function(response) {&#xA;        // response is JSON: {EndDate: ""12/05/2016""}&#xA;        response.EndDate;&#xA;    }, function(error) {&#xA;        log.debug(""There was an error calculating the End Date."");&#xA;    });&#xA;}&#xA;&#xA;&#xA;// DateClass.js (layer 3)&#xA;getFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let path = '/path/to/microservice';&#xA;    return this.callServer(path, 'GET', {periodTypeId: periodTypeId, numberOfPeriods: numberOfPeriods, startDate: startDate});&#xA;}&#xA;&#xA;&#xA;// ServerLayer.js (layer 4)&#xA;callServer(path, method = ""GET"", query = {}, data, inject) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        super.callServer(uri.toString(),method,data,inject).then((data) =&gt; {&#xA;            resolve(data);&#xA;        }).catch((data) =&gt; {&#xA;            if (data.status === 401) {&#xA;                AppActions.doRefresh();&#xA;            }&#xA;            reject(data);&#xA;        });&#xA;    });&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am under the impression that, because ServerLayer.js (layer 4) returns a <code>new Promise</code> (and thus DateClass.js (layer 3)), calling <code>plan.getFlightEndDate(...).then(function(response) {...</code> will not complete until the response comes back resolved or rejected. This is not currently happening, as the code in DateUI.js (layer 1) will continue on to call <code>this.theNextSyncFunction</code>, and then resolve ~50ms later with the proper data.</p>&#xA;&#xA;<p>How do I force PlanLineActions.calculateFlightEndDate(...) in DateUI.js (layer 1) to complete with a response before I continue on with selectDate()?</p>&#xA;"
37403682,A real world project using microservices architecture,2016-05-24 03:01:00,<node.js><architecture><microservices>,1,483,5,0.0,0,"<p>Anyone knows an open source project that is on microservices architecture? I need a more real app that has addressed cross-cutting concerns,etc not just an educational sample.</p>&#xA;&#xA;<p>Please introduce if you know any. Especially if it's on Node.js or C#.net stack.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37457765,Access microservice using Spring Boot,2016-05-26 10:09:12,<java><spring><spring-boot><microservices>,1,614,10,0.0,0,"<p>I have to implement my project as microservice arch. For that I am doing one sample app using Spring Boot of adding two no. I have three services. Here is my registration-server.yml.Similarly I have <code>account-server.yml</code> and <code>user-service.yml</code>. I want to call <code>add()</code> using <code>UserService.java</code> without RMI concept, since I am using Spring Boot. Also I don't want REST call since it will be costly for my project. How can I manually write code for <code>lookup()</code> in <code>UserService</code> so that it can call Adder?</p>&#xA;&#xA;<pre><code>@EnableAutoConfiguration&#xA;@EnableDiscoveryClient&#xA;public class AddService {&#xA;&#xA;public static int add(int x,int y){&#xA;    int z=x+y;&#xA;    System.out.println(""The sum of no. is ""+z);&#xA;    return z;&#xA;}&#xA;&#xA;public static void main(String[] args) {&#xA;    System.setProperty(""spring.config.name"", ""add-service"");&#xA;    SpringApplication.run(AddService.class, args);&#xA;}&#xA;&#xA;@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class RegistrationService {&#xA;&#xA;public static void main(String[] args) {&#xA;    // Tell server to look for registration.properties or registration.yml&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(RegistrationService.class, args);&#xA;}&#xA;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;public class UserService {&#xA;public static void main(String[] args) {&#xA;&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(UserService.class, args);&#xA;}&#xA;&#xA;&#xA;&#xA;&#xA;    eureka:&#xA;   instance:&#xA;    hostname: localhost&#xA;    client:  # Not a client, don't register with yourself&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;  server:&#xA;  port: 1111   # HTTP (Tomcat) port&#xA;</code></pre>&#xA;"
43378986,Multi-tenant microservice security,2017-04-12 20:23:09,<security><cloud><microservices>,2,282,0,0.0,0,"<p>In short I'm implementing a cloud for my boss. This cloud will be mainly used by angular2 based front-end applications, including mobile application. This cloud must have multi-tenant support so the company can monetize this investment. He prefers not to be reliant on third party providers. </p>&#xA;&#xA;<p>As a platform I intend to use the wso2 products as the ecosystem of the cloud. Information can be found <a href=""http://wso2.com/platform"" rel=""nofollow noreferrer"">here</a>. The one for this question is the wso2 identity server (installation on premise). you can find more information <a href=""http://wso2.com/identity-and-access-management"" rel=""nofollow noreferrer"">here</a>.</p>&#xA;&#xA;<p>The micro-services will be based upon <a href=""http://projects.spring.io/spring-cloud/"" rel=""nofollow noreferrer"">spring cloud</a>.</p>&#xA;&#xA;<p>For security I want to implement <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""nofollow noreferrer"">this</a> OAuth2 pattern, where an opaque token is shared with the front-end and an enterprise service bus translates this inbound token to an identity token containing RBAC information to provide stateless identity within the cloud.</p>&#xA;&#xA;<p>This is the part where it becomes unclear. For securing front-end applications I need an identity store. For web applications it is preferred to use the email and password combination for login. When I look to OpenLDAP or similar, I tend to find username and password combination. What technology would be best suited as identity provider using email and password combinations with role based access control and multitenancy? Perhaps I'm still missing some basic understanding, any help would be appreciated.</p>&#xA;"
43319806,API Gateway pattern implementation for microservices based on Akka cluster,2017-04-10 09:42:16,<api><design-patterns><akka><microservices>,1,549,0,0.0,0,"<p>I try create some microservices based on Akka which use CQRS. So my microservice has write (send command to cluster) and read side (read projections from database) with Http endpoints, but this is not the main problem. Because of many microservices, the question arose as to collect complex API for clients. I found answer: API Gateway pattern. But I have next question: How can I implement it? </p>&#xA;&#xA;<ol>&#xA;<li><p>I can create separate project, which will implement API Gateway pattern (in simple case it is a reverse proxy). Full stack will be:</p>&#xA;&#xA;<pre><code>Load balancer     &#xA;  -&gt; API Gateway project &#xA;    -&gt; Load balancer &#xA;      -&gt; Microcervice read part&#xA;        -&gt; Database &#xA;      -&gt; Microcervice write part&#xA;        -&gt; Akka cluster &#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>Pros:</p>&#xA;&#xA;<p>API Gateway separate project with own abstractions</p>&#xA;&#xA;<p>Cons:</p>&#xA;&#xA;<p>Two balancers, and not so fast proxy in API Gateway project</p>&#xA;&#xA;<ol start=""2"">&#xA;<li><p>API Gateway (auth, etc) implemented in Microservice parts, load balancer will collect endpoints in complex API. Full stack will be:</p>&#xA;&#xA;<pre><code>Load balancer&#xA;  -&gt; Microcervice read part (with public API)&#xA;    -&gt; Database &#xA;  -&gt; Microcervice write part (with public API)&#xA;    -&gt; Akka cluster &#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>Pros:</p>&#xA;&#xA;<ol>&#xA;<li>Direct access to cluster and databases</li>&#xA;<li>Fast response</li>&#xA;</ol>&#xA;&#xA;<p>Cons:</p>&#xA;&#xA;<p>Complex microservices parts, blending layers </p>&#xA;&#xA;<p>What variant is more preferable or is another best?</p>&#xA;"
43340819,How to load react component from an external service inside a React app via AJAX,2017-04-11 08:39:50,<javascript><node.js><ajax><reactjs><microservices>,2,558,0,1.0,0,<p>What are the best practices associated with loading/inserting and running  React components from an external service in an existing React application via AJAX.</p>&#xA;&#xA;<p>I have a main React app and want to load various React components (from external services) via AJAX. How could this be done?</p>&#xA;&#xA;<p>Is this feasible at all? If not what is the way to go about it?</p>&#xA;&#xA;<p>Can this work with webpack?</p>&#xA;
43502357,Scaling Service Boundary (SOA),2017-04-19 17:26:52,<domain-driven-design><nservicebus><soa><microservices>,2,83,0,1.0,0,"<p>I am new learner in SOA ( Service Oriented Architecture ) I have one question for below scenario:</p>&#xA;&#xA;<p>In a company (Mycompany), Sales Team is there ( which is a technical authority for business capability â€“here sales is the business capability). That company decided to create 2 products say Mycompany.Photos.com and Mycompany.Grocery.com. For both websites they need sales capability i.e. order acceptance capability. </p>&#xA;&#xA;<p>Hence Sales team has to work for both websites. Because, both website needs sales capability.</p>&#xA;&#xA;<p><strong>Now the question is should sales team create 2 different databases for each websites and 2 different endpoints also ?</strong></p>&#xA;&#xA;<p>for example:</p>&#xA;&#xA;<p>If Sales team initially had one queue ""Mycompany.Sales.Endpoint"" and it receives CreateOrderCommand. It handles CreateOrderCommand, creates order in sales DB and publishes OrderAcceptedEvent. When they were supporting just one website. If they start supporting both website with same endpoint then how would Sales differentiate weather this order is for Mycompany.Grocery.com or Mycompany.Photos ? Should we split Mycompany.Sales.Endpoint into 2 ? should sales team has to be aware of Photo website orders and Grocery Website orders ?</p>&#xA;&#xA;<p>One answer I can think of is: </p>&#xA;&#xA;<ol>&#xA;<li>Sales team can create 2 different databases each for Mycompany.Grocery.com &#xA;and Mycompany.Photos.com  </li>&#xA;<li>Deploy 2 different Business Components (BC) for each websites.</li>&#xA;<li><p>Sales will have 2 Endpoints say ""Mycompany.Grocery.Sales.Endpoint""&#xA;for Mycompany.Grocery.com BusinessComponent and  ""Mycompany.Photos.Sales.Endpoint"" for MycompanyPhotos.</p>&#xA;&#xA;<p><strong>Even though they are under same Sales Bounded context, can it have 2 Business&#xA;Components (BCs) ? Am I correct, Is this the way we scale sales team will support both products for the sales capability ?</strong></p></li>&#xA;</ol>&#xA;&#xA;<p>I am sorry for the long message. I could not find any shortcut way to explain this.</p>&#xA;"
43395580,Spring Cloud application and end-to-end automatic testing,2017-04-13 14:56:06,<testing><automated-tests><spring-cloud><microservices><end-to-end>,1,177,0,0.0,0,<p>I have an application based on Spring Cloud. It means I am using Eureka server service discovery and the system has couple of microservices. Can you recommend me any approach how to make automatic ent-to-end tests across my system? I have Docker so It is easy to start system. Of course I know SOAPui etc. but is here any way how to write these tests at Java and keep them in the project?</p>&#xA;
43379048,How to make other microservices aware of the IP address of the consul for service registry,2017-04-12 20:27:28,<docker><dockerfile><microservices><consul>,2,238,0,0.0,0,"<p>I am currently dockerizing a micro-service application and using Consul for service discovery. So all the services register themselves with the consul and also get their environmental variables from the consul. The starting script of the undockerized micro service application takes the Consul ip:port from the user and forwards it to all the other microservices which is good. But how do I replicate the same for dockerized microservice application as each container is independent. Also, all the services need to register themselves with the consul but they don't have the consul ip.</p>&#xA;&#xA;<p>I can hardcode the consul ip:port in each of the required microservice application but I don' t think that's an elegant way. So do you have any idea on how to make other services aware of the consul ip?</p>&#xA;&#xA;<p>Any help is appreciated.</p>&#xA;"
43512572,Should a microservice must have its own database even if it is not much database intensive service?,2017-04-20 07:09:57,<database><relational-database><microservices>,1,288,1,0.0,0,"<p>I have a monolith application on a server and I want to break it into multiple microservices using the best principles, the Application currently has one database and almost 10 tables and 6-7 services are using them.  </p>&#xA;&#xA;<p>My question is whether should I separate them or use a <strong>table-per-service</strong> approach as some services have only one table which they are interacting with? Or should I go with <strong>database-per-service</strong> approach and create a database even for only one table?</p>&#xA;"
43465704,A kind of A/B testing when B is a fallback,2017-04-18 07:03:52,<.net><testing><microservices><staging><abtest>,1,41,1,0.0,0,"<p>Actually better term may exist for what I need, but I am not aware of it and would be grateful to anyone who suggests one and/or edits the subject of the question appropriately.</p>&#xA;&#xA;<p>Consider web api service <code>S</code> which is deployed to production server. Let's treat it as a working source of truth.</p>&#xA;&#xA;<p>Then I, for example, need to update some external dependencies or change infrastructure code neither directly affecting core business logic nor service's public contract. </p>&#xA;&#xA;<p>Thus I get <code>S_updated</code> which must pass phase of staging and only then be deployed to production. Due to the kind of changes made to the codebase I would expect this service to either work as previous version or not to work at all due to integration issues. There is still a risk of somehow altering the behavior of the system, but I can live with it and expect unit tests to be a rather good safety net. This is also proved by the practice.</p>&#xA;&#xA;<p>What I actually want is to be able to deploy <code>S_updated</code> to production and to have some proxy service dispatching all or some (depends on configuration) failed requests to the former <code>S</code> service.</p>&#xA;&#xA;<p>Do some generic configurable solutions for such functionality exist?</p>&#xA;"
43515765,Turing a monolithic application into a Microservice based architecture and keeping the GIT history,2017-04-20 09:39:12,<git><version-control><microservices>,1,64,1,0.0,0,"<p>I'm planning to split a monolithic application into a micro service based architecture, but I want to keep the GIT history.</p>&#xA;&#xA;<p>The monolit should be split into three micro services. </p>&#xA;&#xA;<p>My first approach would be, copying the GIT Repository three times and removing all non domain specific parts from the new micro service which should keep the most parts of the git history alive. But I am not shure if this is the best way keeping the version control history.</p>&#xA;"
43382402,Preferred approach for inter-service communication in microservices/SOA,2017-04-13 02:06:30,<security><authentication><jwt><soa><microservices>,1,331,1,0.0,0,"<p>In my architecture, I have several internal services that need to communicate with each other. I also have a identity access management service that stores information about users, roles and (coarse-grained) permissions. </p>&#xA;&#xA;<p>Components (not exhaustive):</p>&#xA;&#xA;<ul>&#xA;<li>Service A </li>&#xA;<li>Service B </li>&#xA;<li>IAM service</li>&#xA;</ul>&#xA;&#xA;<p>Rather than giving services A and B full access to each other via IP whitelisting, I would like them to run as users who are managed by the IAM service. So the services need a way of interrogating each other's roles and permissions. I've considered the following approach:</p>&#xA;&#xA;<p>I create opaque API keys for the users that the services will be running under. I store them on each service. When service A calls service B, it passes its API key. Service B then calls the IAM service to validate the key and acquire information about service A's roles before processing the request. Service B caches its responses from the IAM service to reduce chattiness.</p>&#xA;&#xA;<p>I've seen solutions that involve an API gateway, but this assumes that the traffic is coming outside the network. I do not want to redirect internal traffic to the outside just for the sake of converting opaque tokens to by-value JWTs. </p>&#xA;"
43515150,Control the services in Azure SF application,2017-04-20 09:12:50,<azure><microservices><azure-service-fabric>,1,35,2,0.0,0,"<p>My azure SF application has two services. When I deploy the application to the local cluster, is it possible to deploy only one of the services, rather than both (services)?</p>&#xA;"
43446605,Microservices Architecture - Firefox requires exception to be added for every port,2017-04-17 06:49:20,<firefox><spring-boot><microservices>,1,44,2,0.0,0,"<p>I am working on a distributed web application using Spring Microservices design pattern where individual services are running on different ports like - </p>&#xA;&#xA;<pre><code>Product Management - domain:8500&#xA;&#xA;User Management - domain:8501&#xA;</code></pre>&#xA;&#xA;<p>Now If the user calls User Management by opening the URL ""domain:8501/some_url"" which internally calls Product Management i.e. ""domain:8500/some_other_url"" and also assume that certificate is self-signed i.e. for the browser, the CA is unknown and hence the exception needs to be manually added in the browser.&#xA;In this case, while Chrome works fine, Firefox and IE also probably adds the exception for domain with port and hence for internal call as well it waits internally for the security exception to be added. </p>&#xA;&#xA;<p>As a result, my API calling is failed. Is this a Firefox behaviour or I am doing something wrong?</p>&#xA;&#xA;<p>AJ</p>&#xA;"
43328943,Data-specific user permissions model / schema design,2017-04-10 16:57:21,<permissions><domain-driven-design><database-schema><acl><microservices>,1,111,3,0.0,0,"<p>My app manages user data that is shared between users, with different permissions such as read-only, edit, superuser, rename, delete etc. </p>&#xA;&#xA;<p>I'm weighing up two approaches to modelling the user permissions, the first is the simpler approach, the second involves more work but is more extensible, refactorable, <em>I think</em>. </p>&#xA;&#xA;<p>(1) quick solution, hard-coding against <code>user permission</code> properties:</p>&#xA;&#xA;<pre><code>-- basic data&#xA;CREATE TABLE symbol (&#xA;    id INT,&#xA;    name VARCHAR(255)&#xA;);&#xA;&#xA;CREATE TABLE user (&#xA;    id CHAR(10) &#xA;);&#xA;&#xA;CREATE TABLE user_permission (&#xA;    symbol_id INT,&#xA;    user_id CHAR(10),&#xA;    readable BIT,&#xA;    writable BIT,&#xA;    owner BIT,&#xA;    rename BIT,&#xA;    deletion BIT&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>(2) complete solution, hard-coding against <code>entitlements</code>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/boRWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/boRWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The areas I'm considering are:</p>&#xA;&#xA;<ol>&#xA;<li>extensibility - need or not to change model &amp; schema</li>&#xA;<li>microservices - possibilities to spin off into a separate DB?</li>&#xA;<li>performance - filter algos, number of joins in queries</li>&#xA;<li>no-sql caching - no idea but denormalising user permissions sounds crazy</li>&#xA;<li>admin for users - need good UX</li>&#xA;<li>admin for DBAs/Support - don't want complaints and endless support requests</li>&#xA;<li>web services API simplicity / complexity using Spring Data REST - HAL</li>&#xA;</ol>&#xA;&#xA;<p>I'd like to go with the more complex solution since it is unlikely to require re-working in the future, but I'm a bit concerned about both performance and the admin tasks involved in the UI to allow users to manage it. </p>&#xA;&#xA;<p>A utopian solution would be a third-party Java-based webapp providing a user interface to allow admin.</p>&#xA;&#xA;<p>EDIT: interesting to see other people tackling the same problem: <a href=""https://stackoverflow.com/questions/41161769/authorisation-in-microservices-how-to-approach-domain-object-or-entity-level-a"">Authorisation in microservices - how to approach domain object or entity level access control using ACL?</a></p>&#xA;"
43306842,.NET Microservices authorization,2017-04-09 12:46:57,<.net><authorization><microservices>,1,190,4,0.0,0,"<p>I am about to start a project that consists of several microservices and I was researching how can I implement authorization of each microservice.&#xA;My architecture is the following:&#xA;A web project that consists of an asp.net core site with angular 2. Each module (menu item and its submenus) will be communicating with a microservice (each microservice will have a database).&#xA;Each microservice will have its own permissions. e.g MS1 will have CRUD Products, MS2 will have CRUD Orders etc..&#xA;My questions are:</p>&#xA;&#xA;<ol>&#xA;<li>As I mentioned above each microservice will have its own database (e.g MS1 will hold the products database, MS1 the order database etc..). What about the permissions? Where these are better to be stored?</li>&#xA;<li>A microservice should not share code with other microservices but I was thinking that the code that does the actual auth checking ( IsAlllowed(PermissionType) ) would be repeated in each microservice. This will cause code redundancy.</li>&#xA;</ol>&#xA;"
43326844,swagger2 for springboot microservice do no produce response on ui,2017-04-10 15:11:06,<spring-boot><microservices><swagger-ui>,1,75,5,0.0,0,"<p>I created one micro service with spring boot, I don't have resource folder and i wanted to add swagger support. So I followed as per <a href=""http://www.baeldung.com/swagger-2-documentation-for-spring-rest-api"" rel=""nofollow noreferrer"">document</a></p>&#xA;&#xA;<p>So </p>&#xA;&#xA;<ol>&#xA;<li>Added swagger dependency.</li>&#xA;<li>Added docker class as it is </li>&#xA;<li>Added swagger's ui dependency</li>&#xA;</ol>&#xA;&#xA;<p>Results</p>&#xA;&#xA;<ol>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><p>But &#xA;<a href=""http://localhost:port/myservice/swagger-ui.html"" rel=""nofollow noreferrer"">http://localhost:port/myservice/swagger-ui.html</a> ->&#xA;Not expected response, on browser console i am getting error</p>&#xA;&#xA;<p>GET <a href=""http://localhost:port/myservice/configuration/ui"" rel=""nofollow noreferrer"">http://localhost:port/myservice/configuration/ui</a> 404 (Not Found)</p></li>&#xA;</ol>&#xA;&#xA;<p>As its microservice, I don't have <code>@EnableWebMvc</code> class. </p>&#xA;&#xA;<p>What Am I missing ? </p>&#xA;"
43460615,How to execute docker commands after a process has started,2017-04-17 22:25:10,<docker><docker-compose><dockerfile><microservices><consul>,2,112,5,0.0,0,"<p>I wrote a Dockerfile for a service (I have a CMD pointing to a script that starts the process) but I cannot run any other commands after the process has started? I tried using '&amp;' to run the process in the background so that the other commands would run after the process has started but it's not working? Any idea on how to achieve this?</p>&#xA;&#xA;<p>For example, consider I started a database server and wanted to run some scripts only after the database process has started, how do I do that?</p>&#xA;&#xA;<p><strong>Edit 1:</strong></p>&#xA;&#xA;<p>My specific use case is I am running a Rabbitmq server as a service and I want to create a new user, make him administrator and delete the default guest user once the service starts in a container. I can do it manually by logging into the docker container but I wanted to automate it by appending these to the shell script that starts the rabbitmq service but that's not working.</p>&#xA;&#xA;<p>Any help is appreciated!</p>&#xA;&#xA;<p>Regards</p>&#xA;"
47641231,How can you insert a templated number into an APIMocker response?,2017-12-04 20:12:28,<json><response><microservices>,1,11,0,0.0,0,"<p>According to the API Mocker GitHub page <a href=""https://github.com/gstroup/apimocker"" rel=""nofollow noreferrer"">here</a>, it says you can template your response using placeholders.</p>&#xA;&#xA;<p>As an example, if you use this configuration entry...</p>&#xA;&#xA;<pre><code>""template/:Name/:Number"" :{&#xA;    ""mockFile"": ""templateSample.json"",&#xA;    ""verbs"":[""get""],&#xA;    ""enableTemplate"": true&#xA;    ""contentType"":""application/json""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then you use this as your 'templateSample.json'...</p>&#xA;&#xA;<pre><code>{&#xA;    ""Name"": ""@Name"",&#xA;    ""Number"": ""@Number""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If you call <code>/John/12345</code> it says you will be returned this...</p>&#xA;&#xA;<pre><code>{&#xA;    ""Name"": ""John""&#xA;    ""Number"": 12345&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But that's not what we're getting.  We're getting this (note the quotes around '12345')...</p>&#xA;&#xA;<pre><code>{&#xA;    ""Name"": ""John""&#xA;    ""Number"": ""12345""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is our endpoints are expecting a pure number there, not a string.  Is there anything we can do to configure APIMocker to not wrap the values in quotes?</p>&#xA;"
47622392,Unique configuration per vhost for Micro,2017-12-03 19:32:00,<node.js><http><process><microservices>,1,18,0,0.0,0,"<p>I have a few Zeit <a href=""https://github.com/zeit/micro"" rel=""nofollow noreferrer"">micro</a> services. This setup is a RESTful API for multiple frontends/domains/clients </p>&#xA;&#xA;<p>I need to, in my configs that are spread throughout the apps, differentiate between these clients. I can, in my handlers, setup a <code>process.env.CLIENT_ID</code> for example that I can use in my config handler to know which config to load. However this would mean launching a new http/micro process for each requesting domain (or whatever method I use - info such as client id will prob come in a header) in order to maintain the <code>process.env.CLIENT_ID</code> throughout the request and not have it overwritten by another simultaneous request from another client.</p>&#xA;&#xA;<p>So I have to have each microservice check the client ID, determine if it has already launched a process for that client and use that else launch a new one.</p>&#xA;&#xA;<p>This seems messy but not sure how else to handle things. Passing the client id around with code calls (i.e. <code>getConfg(client, key)</code> is not practical in my situation and I would like to avoid that.</p>&#xA;&#xA;<p><strong>Options:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Pass client id around everywhere</li>&#xA;<li>Launch new process per host</li>&#xA;<li>?</li>&#xA;</ol>&#xA;&#xA;<p>Is there a better way or have I made a mistake in my assumptions?</p>&#xA;&#xA;<p>If the process per client approach is the better way I am wondering if there is an existing solution to manage this? Ive looked at <a href=""https://github.com/nodejitsu/node-http-proxy"" rel=""nofollow noreferrer"">http proxy</a>, <a href=""https://github.com/zeit/micro-cluster"" rel=""nofollow noreferrer"">micro cluster</a> etc but none seem to provide a solution to this issue.</p>&#xA;"
47716674,Node.js serve as microservice service,2017-12-08 14:48:00,<node.js><microservices>,1,28,0,0.0,0,"<p>I want to access my node.js server as service in microservice infrastructure. This means that if locally I can access node server services <code>/root-path-to-service</code>. But after deploying to infrastructure in AWS it is accessed as <code>/microservice-path/root-path-to-service</code> and <code>app.use('/root-path-to-service', ...)</code> does not work anymore. How can I configure to work in both cases?</p>&#xA;"
47630891,How to override services coupling caused by IdentityServer3.accesstokenvalidation,2017-12-04 10:08:36,<microservices><access-token><identityserver3><identityserver4>,1,29,0,0.0,0,"<p>I have an identityserver4 which validates tokens sent along with the requests my APIs receive.</p>&#xA;&#xA;<p>To do that I am using identityserver3.accesstokenvalidation. </p>&#xA;&#xA;<p>In startup:</p>&#xA;&#xA;<pre><code> JwtSecurityTokenHandler.InboundClaimTypeMap = new Dictionary&lt;string, string&gt;();&#xA; app.UseIdentityServerBearerTokenAuthentication(new IdentityServerBearerTokenAuthenticationOptions&#xA;    {&#xA;       Authority = Configurations.AuthorizationAuthority,&#xA;    });&#xA;</code></pre>&#xA;&#xA;<p>Now I might face cases where server running identityserver4  is shortly (multiple seconds) unavailable.</p>&#xA;&#xA;<p>If this happens the service containing my APIs will not be able to run saying that:</p>&#xA;&#xA;<blockquote>&#xA;  <p>No connection could be made because the target machine actively&#xA;  refused it</p>&#xA;</blockquote>&#xA;&#xA;<p>I want my API service to start even if IdentityServer server is not running, is there some kind of configuration Identityserver3.accesstokenvalidation provides to overcome this issue?</p>&#xA;"
47748434,Spring boot Microservice Cloud Deployment Packaging Format,2017-12-11 07:49:25,<amazon-web-services><spring-boot><microservices><packaging>,1,32,0,0.0,0,"<p>I am trying to develop a microservice using spring MVC and spring boot with spring cloud. Here I am practicing my java microservices using JAR packaging. When I am using Maven build tool , also uses JAR file when building project. My ultimate aim is to deploy my microservice into AWS cloud.</p>&#xA;&#xA;<ul>&#xA;<li>Here My confusion is that ,  when I am approaching for cloud deployment, Is necessary to build my microservices using WAR format? Or JAR ?</li>&#xA;<li>Which format I can utilize for my deployment of services into cloud? In local I am now only using JAR format. Can I follow the JAR format in cloud deployment? Which is better option for my service?</li>&#xA;</ul>&#xA;&#xA;<p>Can anyone give clarification for the packaging format of my microservices in cloud,since I am a beginner to cloud platform.</p>&#xA;"
47571761,microservice testing : in-process component(individual micro-service) testing,2017-11-30 10:57:12,<testing><microservices>,1,70,0,0.0,0,"<p>I am exploring individual microservice testing &amp; came across a good guide <a href=""https://martinfowler.com/articles/microservice-testing/#testing-component-in-process-diagram"" rel=""nofollow noreferrer"">https://martinfowler.com/articles/microservice-testing/#testing-component-in-process-diagram</a>. This post suggest there is a way to test the individual microservices ""in-process"".</p>&#xA;&#xA;<p>Which means the test &amp; service will execute in same process, it also provides the lib which can be used. However I am not able to understand following things&#xA;1) How exactly ""in-process"" testing will work in microservice architecture&#xA;2) Any pointers on how to use ""inproctester"" lib.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
47555732,How to correctly handle inter-service exception in a spring-based microservices architecture,2017-11-29 14:58:24,<java><exception-handling><microservices><spring-cloud-feign>,1,612,0,2.0,0,"<p>I have an application developed with a microservices architecture. Each microservice is a spring-boot application that communicates with others via FeignClient interface.</p>&#xA;&#xA;<p>Let A, a microservice (RestAPI) that calls microservice B. In normal conditions, B replies with an Object X, that is the JSON-response that A serves to client.</p>&#xA;&#xA;<p>But, if B throws an exception, I obtain a chinese-box exception to the client like this:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051071,&#xA;    ""status"": 500,&#xA;    ""error"": ""Internal Server Error"",&#xA;    ""exception"": ""Exception"",&#xA;    ""message"": { ""\""timestamp\"":1511965051052,\""status\"":422,\""error\"":\""Unprocessable Entity\"",\""exception\"":\""java.lang.MyException\"",\""message\"":\""Error message from B\"",\""path\"":\""PATH-OF-B-SERVICE\""}"",&#xA;    ""path"": ""PATH-OF-A-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In other words, MyException (status 422) is ""embedded"" in A Exception (status 500).</p>&#xA;&#xA;<p>I would like to reply the client with the inner JSON, that is:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051052,&#xA;    ""status"": 422,&#xA;    ""error"": ""Unprocessable Entity"",&#xA;    ""exception"": ""java.lang.MyException"",&#xA;    ""message"": ""ErrormessagefromB"",&#xA;    ""path"": ""PATH-OF-B-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How can I do that?</p>&#xA;"
47552159,how to get POST body from request during http exception handling?,2017-11-29 11:50:38,<java><spring><exception><spring-boot><microservices>,2,157,0,0.0,0,"<p>I have 2 microservices. 1 of them sends a request to 2, 2 microservice throws an exception and adds new addition field <em>errors</em> to response with useful data:</p>&#xA;&#xA;<pre><code>    public static class ErrorResponse  {&#xA;        private Integer status;&#xA;        private String transactionId;&#xA;        private String sessionId;&#xA;        private String message;&#xA;        private List&lt;FieldError&gt; errors;&#xA;    //....setters/getters&#xA;    }&#xA;&#xA;{&#xA;    ""status"": 400,&#xA;    ""message"": ""Validation failed for object='x'. Error count: 1"",&#xA;    ""sessionId"": """",&#xA;    ""transactionId"": ""xxx"",&#xA;    ""errors"": [&#xA;        {&#xA;            ""codes"": [&#xA;                """"&#xA;            ],&#xA;            ""arguments"": null,&#xA;            ""defaultMessage"": null,&#xA;            ""objectName"": """",&#xA;            ""field"": """",&#xA;            ""rejectedValue"": 0,&#xA;            ""bindingFailure"": false,&#xA;            ""code"": ""invalid value""&#xA;        }&#xA;    ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>in 1 microservice I have a global exception handler which sends it on client, but the problem is that I can't get the filed <em>errors</em> from <em>HttpServletRequest</em>. getReader() method throws another exception. And as result client gets </p>&#xA;&#xA;<pre><code>{&#xA;    ""status"": 400,&#xA;    ""message"": ""Validation failed for object='x'. Error count: 1"",&#xA;    ""sessionId"": """",&#xA;    ""transactionId"": ""xxx"",&#xA;    ""errors"": null&#xA;}&#xA;</code></pre>&#xA;"
47572543,Spring boot eureka server bean creation error,2017-11-30 11:36:24,<spring><spring-boot><microservices><netflix-eureka><eureka>,1,494,0,0.0,0,"<p>I am not able to run the spring eureka server, I do get the following error.</p>&#xA;&#xA;<p>org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration': Unsatisfied dependency expressed through field 'optionalArgs'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientOptionalArgs' defined in class path resource [org/springframework/cloud/netflix/eureka/config/DiscoveryClientOptionalArgsConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.NoClassDefFoundError: com/netflix/eventbus/spi/EventBus&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) ~[spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]</p>&#xA;&#xA;<p>Below is the my code which runs in my mac machine perfectly, But the same is not working in my windows machine and was not able to find out the solution for it I reinstalled sts tool suite, eclipse everything still the same error persists</p>&#xA;&#xA;<p>MyApplication.java</p>&#xA;&#xA;<pre><code>package com.example.microservice;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;&#xA;&#xA;@EnableEurekaServer&#xA;@SpringBootApplication&#xA;public class MicroserviceApplication {&#xA;&#xA;   public static void main(String[] args) {&#xA;       SpringApplication.run(MicroserviceApplication.class, args);&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<pre><code>server:&#xA;    port: 8000&#xA;&#xA;eureka:&#xA;   client:&#xA;       register-with-eureka: false&#xA;       fetch-registry: false&#xA;</code></pre>&#xA;&#xA;<p>pom.xml</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" &#xA;xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 &#xA;http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;&lt;groupId&gt;com.example&lt;/groupId&gt;&#xA;&lt;artifactId&gt;microservice&lt;/artifactId&gt;&#xA;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;name&gt;microservice&lt;/name&gt;&#xA;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&#xA;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;    &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;spring-cloud.version&gt;Edgware.RELEASE&lt;/spring-cloud.version&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;dependencyManagement&gt;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;            &lt;type&gt;pom&lt;/type&gt;&#xA;            &lt;scope&gt;import&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&lt;/dependencyManagement&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;</code></pre>&#xA;&#xA;<p></p>&#xA;&#xA;<p>Only in my windows machine it is not working and its throwing the above issue which I have mentioned? It woulb be good if somebody can get me an solution for this?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
47650139,Prevent multiple service access same document in MongoDB till processing is done,2017-12-05 09:29:09,<python><mongodb><nosql><mongodb-query><microservices>,1,26,1,0.0,0,"<p>I have multiple instances of a services. This service access a collection of unprocessed document. We are using MongoDB. The role of service is :</p>&#xA;&#xA;<ol>&#xA;<li>Fetch the first unprocessed document from collection A.</li>&#xA;<li>Make a Rest call using uuid.</li>&#xA;<li>Get the response and store the response in another collection B.</li>&#xA;</ol>&#xA;&#xA;<p>Multiple service may access the same document leading to duplicate. The steps which I can think to deal with this situation:</p>&#xA;&#xA;<ol>&#xA;<li><p>FindandModify() along with progress field. So we will call this function with query of progress field to be ""0"". We will update the value to 1 so other services can not access it. On getting the success from Rest call we can delete the record. On getting the failure we will again call the FindandModify() with update value to be ""0"" so other service can access  at later time.</p></li>&#xA;<li><p>We we call Find() function which will give us one document. We get the ""_id"" of the document and store it into another collection. If another service also gets the same document and that document ""_id"" is already present. Then it will not be insert again and that service again call Find() function.</p></li>&#xA;</ol>&#xA;&#xA;<p>What would be the performance and bottleneck of these approaches. Also do we have any other better approach which will enhance the performance.</p>&#xA;"
47613318,How to communicate from REST to message queue,2017-12-02 22:33:40,<spring><rest><apache-kafka><message-queue><microservices>,1,289,1,0.0,0,"<p>how is that possible that a REST Microservice can communicate with another Microservice which is a hybrid, which means he can communicate with REST and with a Message Queue. For Example an API-Gateway. For the outside world, he is able to communicate with an App, Mobilephone via REST but the communication from the backend is via message queue.</p>&#xA;&#xA;<p>Use case:</p>&#xA;&#xA;<p>My homepage wants to get a Vehicle from the database. He asks the API-Gateway via a GET-Request. The API-Gateway takes the GET-request and publishes it into the message queue. The other Microservice takes the message and publishes the result. Then the API-gateway consumed the result and send it back as a response. </p>&#xA;&#xA;<p>How can I implement it? Am I using Spring boot with Apache Kafka? Do I need to implement an asynchronous communication?</p>&#xA;&#xA;<p>(Sorry its german)&#xA;<a href=""https://i.stack.imgur.com/Qs7Zi.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qs7Zi.jpg"" alt=""enter image description here""></a></p>&#xA;"
47727201,Apache Camel and JMS cluster (distributed queues),2017-12-09 09:33:47,<java-ee><apache-camel><jms><microservices><messaging>,1,121,1,0.0,0,"<p>How to use Camel with distributed message queues? Basically I have system of three services, where A is the synchronous boundary to SOAP client. A calls service C, <strong>but gets the result set from service B instead</strong>. Multiple instances of each service is ran to guarantee high availability.</p>&#xA;&#xA;<p>I have to use asynchronous messaging (message queues), because the result to request has to come from different service than called (C can't obtain result set of B, neither A the result set of C, thus services can not be chained synchronically). The biggest challenge is to route response messages to correct instance/thread (A is <em>synchronous</em> service, which is blocking until it obtains the result). After doing research, I figured out JMS provides two means for this: <em>JMSCorrelationID</em> and <em>JMSReplyTo</em> headers. Camel seems to handle these headers transparently.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/7pWXR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7pWXR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But there is even bigger challenge. Of course, I have to run <strong>multiple instances of message queues</strong> also to guarantee high availability. If any message queue goes down, system would be still be available.</p>&#xA;&#xA;<p><strong>What kind of support Camel provides out-of-the-box for distributed queues?</strong> Let's say I have configured <em>JMS cluster</em> in Weblogic, and want to take advantage of it in Camel. What kind of special configuration do I need? Please note, in this example we are using two different queues (or clusters of queues), because Secret result and Result messages can't be meditated on the same queue or server instance, but still the correlation between messages must be preserved all along.</p>&#xA;"
47607210,One class common in few projects,2017-12-02 11:05:33,<java><shared-libraries><microservices>,1,23,2,0.0,0,"<p>I am building a microservice application and I have one class common for four modules(separate projects). Can I do sth about it (to not duplicate it in four projects)?. It's only one class, but it's for authentication so I don't want somebody to change it by mistake. Is it possible to do a one class library or it's a bad idea?</p>&#xA;"
47736658,Restricting access to api from another application ruby,2017-12-10 07:04:02,<ruby><api><http><ip><microservices>,1,33,4,0.0,0,"<p>I have a Grape API application built in Ruby. &#xA;And also some other microservices built in Python, Java etc.&#xA;I have to restrict some of these microservices from accessing a particular API in this grape application. </p>&#xA;&#xA;<p>Now, this is implemented using IP whitelisting. But every time the IP of other microservices gets changed, the code of grape application has also to be changed which is not stable. </p>&#xA;&#xA;<p>Is there any better solution for this? Please help.</p>&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;"
40938756,how to use hystrix to monitoring all microservices,2016-12-02 18:27:15,<microservices><netflix-zuul><hystrix>,1,276,0,0.0,0,"<p>I'm new on microservices and I have seen a tutorial(from udemy) where shows technologies like eureka, feign,spring cloud config,hystrix and zuul, but after make some examples I don't understand very well how hystrix monitor and zuul works, In the examples I noticed that hystrix is used by a main application that it access to microservices and in that way I can monitoring my microservices, but with zuul I noticed that it works like a proxy but this is calling the same microservices like the other application, so my question is how can I monitoring the microservices with hystrix if are called by zuul and by the another application, am I need two hystrix monitor or can I have one general?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
40837178,Spring + Microservice + JBoss,2016-11-28 04:26:30,<spring-mvc><microservices>,1,44,0,0.0,0,"<blockquote>&#xA;  <p>We are planning to build an application which has multiple modules&#xA;  (say [Common  which contains Admin, Registration], License Module,&#xA;  Stock Module ). We have planned to use Maven as our build tool</p>&#xA;</blockquote>&#xA;&#xA;<p>Each module acts like a separate folder(war) where in it has MVC layers in it. Main POM should encapsulate all the modules and form a war file.&#xA;If a customer doesn't need License Module, i can just unplug the settings and recreate a war file without much effort.</p>&#xA;&#xA;<p>Now i am struggling to find proper example to build a hierarchy(project structure like above) </p>&#xA;&#xA;<p>Could you please guide me on this ?</p>&#xA;"
40927853,Two vertx instances isolated from each other,2016-12-02 08:36:19,<java><cluster-computing><microservices><vert.x>,1,52,0,0.0,0,"<p>we would like to isolate client related (in-browser apps) vertx services from backend (server side) ones. Is there a way how to create two separated (isolated) buses? That all server services would be able to communicate with each other normally, but frontend services must not be on the same bus (got internal events, messages). </p>&#xA;&#xA;<p>I fould a classpath isolation (isolationGroup) feature, but it does not look like what we need.</p>&#xA;&#xA;<p>We need all backend services could communicate with each other. But only one backend module will be accessible from outside and will work as security gate for outer-external communication with frontend modules. So, this gate module would subscribe all messages from internal bus and process it and send them to outer world... and oposite, would subscribe all outer messages and re-send them to internal bus for internal processing.</p>&#xA;&#xA;<p>Any idea? Thanks&#xA;W</p>&#xA;"
40910259,expose jhipster microservice client classes,2016-12-01 12:06:55,<java><design><jhipster><microservices>,1,88,0,0.0,0,"<p>I have two micro services created with jhipster. (ms1 and ms2)</p>&#xA;&#xA;<p>I have used AuthorizedFeignClient to communicate between two micro services.</p>&#xA;&#xA;<p>ms1 has some DTO classes which are used as input and output classes for REST APIs.</p>&#xA;&#xA;<p>from ms2 I need to call some API of ms1, and hence I need those DTO classes(POJOs) for input and output data.</p>&#xA;&#xA;<p>These DTO classes are obviously not there in ms2.</p>&#xA;&#xA;<p>So I have two options in my mind currently: </p>&#xA;&#xA;<p>1) copy DTO classes from ms1 to ms2</p>&#xA;&#xA;<p>2) import ms1 as maven dependency in ms2</p>&#xA;&#xA;<p>Approach 1 - seems easy, but there will be duplicate code.</p>&#xA;&#xA;<p>Approach 2 - ms1 and ms2 both are packaged as war file and not as jar file. It doesn't look good to include whole war file just to use some classes.</p>&#xA;&#xA;<p>What are the other Approach I should take to get those DTO classes from ms1 to ms2 ?</p>&#xA;"
40960601,How to share large files between two microservices in Mesos?,2016-12-04 16:06:35,<microservices><mesos>,1,88,0,1.0,0,"<p>I have a mesos cluster and I need to run two types of microservices, one is producing very large files (might be more than 2GB for file) the other one is analyzing those files. The analyzing microservice is taking more time than the producer service.&#xA;After the analysis service is done - the file can be deleted.</p>&#xA;&#xA;<p>I thought of two options:</p>&#xA;&#xA;<ol>&#xA;<li>NFS - producer service creates all files on NFS and the analysis service is taking it directly from the shared folder. (I'm concerned that this approach will consume all internal bandwidth in my cluster)</li>&#xA;<li>Local Disk (my preferred) - in this case I need to somehow enforce the analysis micoroservice to run on the same Mesos slave as the producer service that created this specific file. (I'm not sure this approach is possible)</li>&#xA;</ol>&#xA;&#xA;<p>What would be best practice in this case?</p>&#xA;"
40918134,NPE while receiving messages from Azure Service bus Queue,2016-12-01 18:43:01,<java><azure><microservices><azureservicebus>,1,92,0,0.0,0,"<p>NPE while receving messages from Queue. ( Only when messages are present in Queue). I feel like there is an issue with de-serializing the messages.  </p>&#xA;&#xA;<p><em>java.lang.NullPointerException&#xA;        at com.sun.jersey.api.client.ClientResponse.getResponseDate(ClientResponse.java:738)&#xA;        at com.microsoft.windowsazure.services.servicebus.implementation.ServiceBusRestProxy.receiveMessage(ServiceBusRestProxy.java:288)&#xA;        at com.microsoft.windowsazure.services.servicebus.implementation.ServiceBusRestProxy.receiveQueueMessage(ServiceBusRestProxy.java:225)&#xA;        at com.microsoft.windowsazure.services.servicebus.implementation.ServiceBusExceptionProcessor.receiveQueueMessage(ServiceBusExceptionProcessor.java:142)</em></p>&#xA;&#xA;<p>RECEIVE_AND_DELETE option deletes the messages and throws NPE. </p>&#xA;&#xA;<p>All other operations like create queue , send messages etc working fine. Any thoughts one this ?</p>&#xA;&#xA;<p>Code to receive message</p>&#xA;&#xA;<pre><code>public void receiveMessage(String queueName) {&#xA;        try {&#xA;            ReceiveMessageOptions opts = ReceiveMessageOptions.DEFAULT;&#xA;            opts.setReceiveMode(ReceiveMode.PEEK_LOCK);&#xA;&#xA;            while (true) {&#xA;                ReceiveQueueMessageResult resultQM&#xA;                        = service.receiveQueueMessage(queueName, opts);&#xA;                BrokeredMessage message = resultQM.getValue();&#xA;                if (message != null &amp;&amp; message.getMessageId() != null) {&#xA;                    log.println(""MessageID: "" + message.getMessageId());&#xA;                    // Display the queue message.&#xA;                    log.print(""From queue: "");&#xA;                    byte[] b = new byte[200];&#xA;                    String s = null;&#xA;                    int numRead = message.getBody().read(b);&#xA;                    while (-1 != numRead) {&#xA;                        s = new String(b);&#xA;                        s = s.trim();&#xA;                        System.out.print(s);&#xA;                        numRead = message.getBody().read(b);&#xA;                    }&#xA;                    log.println("""");&#xA;                    log.println(""Custom Property: ""&#xA;                            + message.getProperty(""MyProperty""));&#xA;                    // Remove message from queue.&#xA;                    log.println(""Deleting this message."");&#xA;                    //service.deleteMessage(message);&#xA;                } else {&#xA;                    log.println(""Finishing up - no more messages."");&#xA;                    break;&#xA;                    // Added to handle no more messages.&#xA;                    // Could instead wait for more messages to be added.&#xA;                }&#xA;            }&#xA;        } catch (Exception e) {&#xA;            log.print(e);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;"
40930432,How to access secured backend services when using Spring Integration with CAS?,2016-12-02 10:49:30,<spring-security><spring-integration><cas><microservices>,1,151,0,1.0,0,"<p>I am seeking solutions to migrate current holistic system into microservices architecture. I want to use Spring Integration and Spring Security to integrate and secure the services. According to my understanding, to secure backend services is more like Single Sign On (SSO). I use Jasig CAS 4.2.7 (seems working fine with Spring Security) to authenticate users centrally, Spring Integration 4.2.11.RELEASE and Spring Security 4.0.4.RELEASE.</p>&#xA;&#xA;<p>I have created a Maven project with two modules named web and service which are both web application. I deploy the three war files on same local Tomcat (version 7.0.36) and just add jimi and bob into CAS properties file to ensure them passing the authentication of CAS. When I try to access URL <a href=""http://localhost:8080/prototype-integration-security-web/user"" rel=""nofollow noreferrer"">http://localhost:8080/prototype-integration-security-web/user</a>, I got authenticated into front-end application but access forbidden on backend services.</p>&#xA;&#xA;<p>The POM file looks as below.</p>&#xA;&#xA;<pre><code>    &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;  &lt;groupId&gt;prototype.integration.security&lt;/groupId&gt;&#xA;  &lt;artifactId&gt;prototype-integration-security&lt;/artifactId&gt;&#xA;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;  &lt;packaging&gt;pom&lt;/packaging&gt;&#xA;&#xA;  &lt;name&gt;prototype-integration-security&lt;/name&gt;&#xA;&#xA;  &lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;  &lt;/properties&gt;&#xA;&#xA;  &lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;      &lt;plugin&gt;&#xA;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;        &lt;version&gt;3.5.1&lt;/version&gt;&#xA;        &lt;configuration&gt;&#xA;          &lt;source&gt;1.7&lt;/source&gt;&#xA;          &lt;target&gt;1.7&lt;/target&gt;&#xA;        &lt;/configuration&gt;&#xA;      &lt;/plugin&gt;&#xA;      &lt;plugin&gt;&#xA;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.6&lt;/version&gt;&#xA;        &lt;configuration&gt;&#xA;          &lt;warName&gt;${project.name}&lt;/warName&gt;&#xA;        &lt;/configuration&gt;&#xA;      &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;  &lt;/build&gt;&#xA;&#xA;  &lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;      &lt;groupId&gt;junit&lt;/groupId&gt;&#xA;      &lt;artifactId&gt;junit&lt;/artifactId&gt;&#xA;      &lt;version&gt;4.12&lt;/version&gt;&#xA;      &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-integration-http&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.2.11.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.0.4.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-test&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.2.7.RELEASE&lt;/version&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.7&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.7&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;javax&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;javaee-api&lt;/artifactId&gt;&#xA;        &lt;version&gt;7.0&lt;/version&gt;&#xA;        &lt;scope&gt;provided&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-integration-security&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.2.11.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.7&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.0.4.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-security-cas&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.0.4.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&#xA;        &lt;version&gt;4.5.1&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.6.4&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;  &lt;/dependencies&gt;&#xA;  &lt;modules&gt;&#xA;    &lt;module&gt;prototype-integration-security-web&lt;/module&gt;&#xA;    &lt;module&gt;prototype-integration-security-service&lt;/module&gt;&#xA;  &lt;/modules&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>The deployment description files web.xml of two modules look same except the display name as following.</p>&#xA;&#xA;<pre><code>&lt;web-app xmlns=""http://java.sun.com/xml/ns/javaee""&#xA;         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;         xmlns:web=""http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd""&#xA;         xsi:schemaLocation=""http://java.sun.com/xml/ns/javaee&#xA;                             http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd""&#xA;         id=""IntegrationSecurityWeb"" version=""3.0""&gt;&#xA;  &lt;display-name&gt;Integration Security Web Prototype&lt;/display-name&gt;&#xA;&#xA;  &lt;servlet&gt;&#xA;    &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;&#xA;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&#xA;    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&#xA;  &lt;/servlet&gt;&#xA;  &lt;servlet-mapping&gt;&#xA;    &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;&#xA;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&#xA;  &lt;/servlet-mapping&gt;&#xA;&#xA;  &lt;filter&gt;&#xA;    &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&#xA;    &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&#xA;  &lt;/filter&gt;&#xA;  &lt;filter-mapping&gt;&#xA;    &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&#xA;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&#xA;  &lt;/filter-mapping&gt;&#xA;&lt;/web-app&gt;&#xA;</code></pre>&#xA;&#xA;<p>In the Spring application context configuration file of web module, dispatcher-servlet.xml looks as below.</p>&#xA;&#xA;<pre><code>&lt;beans xmlns=""http://www.springframework.org/schema/beans""&#xA;       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;       xmlns:task=""http://www.springframework.org/schema/task""&#xA;       xmlns:security=""http://www.springframework.org/schema/security""&#xA;       xmlns:int=""http://www.springframework.org/schema/integration""&#xA;       xmlns:int-http=""http://www.springframework.org/schema/integration/http""&#xA;       xmlns:int-security=""http://www.springframework.org/schema/integration/security""&#xA;       xsi:schemaLocation=""http://www.springframework.org/schema/beans&#xA;                           http://www.springframework.org/schema/beans/spring-beans.xsd&#xA;                           http://www.springframework.org/schema/task&#xA;                           http://www.springframework.org/schema/task/spring-task.xsd&#xA;                           http://www.springframework.org/schema/security&#xA;                           http://www.springframework.org/schema/security/spring-security.xsd&#xA;                           http://www.springframework.org/schema/integration&#xA;                           http://www.springframework.org/schema/integration/spring-integration-4.2.xsd&#xA;                           http://www.springframework.org/schema/integration/http&#xA;                           http://www.springframework.org/schema/integration/http/spring-integration-http-4.2.xsd&#xA;                           http://www.springframework.org/schema/integration/security&#xA;                           http://www.springframework.org/schema/integration/security/spring-integration-security-4.2.xsd""&gt;&#xA;&#xA;  &lt;bean id=""restTemplate"" class=""org.springframework.web.client.RestTemplate""&gt;&#xA;    &lt;constructor-arg&gt;&#xA;      &lt;bean class=""org.springframework.http.client.HttpComponentsClientHttpRequestFactory""&gt;&#xA;        &lt;constructor-arg&gt;&#xA;          &lt;bean class=""org.springframework.beans.factory.config.MethodInvokingFactoryBean""&gt;&#xA;            &lt;property name=""targetClass"" value=""org.apache.http.impl.client.HttpClients""/&gt;&#xA;            &lt;property name=""targetMethod"" value=""createMinimal""/&gt;&#xA;          &lt;/bean&gt;&#xA;        &lt;/constructor-arg&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;    &lt;property name=""messageConverters""&gt;&#xA;      &lt;list&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.StringHttpMessageConverter"" /&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"" /&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.FormHttpMessageConverter""&gt;&#xA;        &lt;/bean&gt;&#xA;      &lt;/list&gt;&#xA;    &lt;/property&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""serviceProperties"" class=""org.springframework.security.cas.ServiceProperties""&gt;&#xA;    &lt;property name=""service"" value=""http://localhost:8080/prototype-integration-security-web/login/cas"" /&gt;&#xA;    &lt;property name=""sendRenew"" value=""false"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;!-- Access voters --&gt;&#xA;  &lt;bean id=""accessDecisionManager"" class=""org.springframework.security.access.vote.AffirmativeBased""&gt;&#xA;    &lt;constructor-arg name=""decisionVoters""&gt;&#xA;      &lt;list&gt;&#xA;        &lt;bean class=""org.springframework.security.access.vote.RoleHierarchyVoter""&gt;&#xA;          &lt;constructor-arg&gt;&#xA;            &lt;bean class=""org.springframework.security.access.hierarchicalroles.RoleHierarchyImpl""&gt;&#xA;              &lt;property name=""hierarchy""&gt;&#xA;                &lt;value&gt;&#xA;                  ROLE_ADMIN &gt; ROLE_USER&#xA;                &lt;/value&gt;&#xA;              &lt;/property&gt;&#xA;            &lt;/bean&gt;&#xA;          &lt;/constructor-arg&gt;&#xA;        &lt;/bean&gt;&#xA;        &lt;bean class=""org.springframework.security.access.vote.AuthenticatedVoter"" /&gt;&#xA;      &lt;/list&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""casEntryPoint"" class=""org.springframework.security.cas.web.CasAuthenticationEntryPoint""&gt;&#xA;    &lt;property name=""loginUrl"" value=""https://localhost:8443/cas/login"" /&gt;&#xA;    &lt;property name=""serviceProperties"" ref=""serviceProperties"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""casFilter"" class=""org.springframework.security.cas.web.CasAuthenticationFilter""&gt;&#xA;    &lt;property name=""authenticationManager"" ref=""authenticationManager"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;!-- This filter handles a Single Logout Request from the CAS Server --&gt;&#xA;  &lt;bean id=""singleLogoutFilter"" class=""org.jasig.cas.client.session.SingleSignOutFilter"" /&gt;&#xA;&#xA;  &lt;!-- This filter redirects to the CAS Server to signal Single Logout should be performed --&gt;&#xA;  &lt;bean id=""requestSingleLogoutFilter"" class=""org.springframework.security.web.authentication.logout.LogoutFilter""&gt;&#xA;    &lt;constructor-arg value=""http://localhost:8080/cas/logout"" /&gt;&#xA;    &lt;constructor-arg&gt;&#xA;      &lt;bean class=""org.springframework.security.web.authentication.logout.SecurityContextLogoutHandler"" /&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;    &lt;property name=""filterProcessesUrl"" value=""/logout/cas"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;security:http entry-point-ref=""casEntryPoint"" access-decision-manager-ref=""accessDecisionManager"" use-expressions=""false""&gt;&#xA;    &lt;security:intercept-url pattern=""/admin/**"" access=""ROLE_ADMIN"" /&gt;&#xA;    &lt;security:intercept-url pattern=""/**"" access=""ROLE_USER"" /&gt;&#xA;    &lt;security:form-login /&gt;&#xA;    &lt;security:logout /&gt;&#xA;    &lt;security:custom-filter before=""LOGOUT_FILTER"" ref=""requestSingleLogoutFilter""/&gt;&#xA;    &lt;security:custom-filter before=""CAS_FILTER"" ref=""singleLogoutFilter""/&gt;&#xA;    &lt;security:custom-filter position=""CAS_FILTER"" ref=""casFilter"" /&gt;&#xA;  &lt;/security:http&gt;&#xA;&#xA;  &lt;security:user-service id=""userService""&gt;&#xA;    &lt;security:user name=""jimi"" password=""jimi"" authorities=""ROLE_ADMIN"" /&gt;&#xA;    &lt;security:user name=""bob"" password=""bob"" authorities=""ROLE_USER"" /&gt;&#xA;  &lt;/security:user-service&gt;&#xA;&#xA;  &lt;bean id=""casAuthenticationProvider"" class=""org.springframework.security.cas.authentication.CasAuthenticationProvider""&gt;&#xA;    &lt;property name=""authenticationUserDetailsService""&gt;&#xA;      &lt;bean class=""org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper""&gt;&#xA;        &lt;constructor-arg index=""0"" ref=""userService"" /&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/property&gt;&#xA;    &lt;property name=""serviceProperties"" ref=""serviceProperties"" /&gt;&#xA;    &lt;property name=""ticketValidator""&gt;&#xA;      &lt;bean class=""org.jasig.cas.client.validation.Cas20ServiceTicketValidator""&gt;&#xA;        &lt;constructor-arg index=""0"" value=""https://localhost:8443/cas"" /&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/property&gt;&#xA;    &lt;property name=""key"" value=""localCAS"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;security:authentication-manager alias=""authenticationManager""&gt;&#xA;    &lt;security:authentication-provider ref=""casAuthenticationProvider"" /&gt;&#xA;  &lt;/security:authentication-manager&gt;&#xA;&#xA;  &lt;int:channel-interceptor order=""99""&gt;&#xA;    &lt;bean class=""org.springframework.integration.security.channel.SecurityContextPropagationChannelInterceptor""/&gt;&#xA;  &lt;/int:channel-interceptor&gt;&#xA;&#xA;  &lt;task:executor id=""pool"" pool-size=""5""/&gt;&#xA;&#xA;  &lt;int:poller id=""poller"" default=""true"" fixed-rate=""1000""/&gt;&#xA;&#xA;  &lt;int-security:secured-channels&gt;&#xA;    &lt;int-security:access-policy pattern=""user*"" send-access=""ROLE_USER"" /&gt;&#xA;    &lt;int-security:access-policy pattern=""admin*"" send-access=""ROLE_ADMIN"" /&gt;&#xA;  &lt;/int-security:secured-channels&gt;&#xA;&#xA;  &lt;int-http:inbound-channel-adapter path=""/user*"" supported-methods=""GET, POST"" channel=""userRequestChannel"" /&gt;&#xA;&#xA;  &lt;int:channel id=""userRequestChannel""&gt;&#xA;    &lt;int:queue/&gt;&#xA;  &lt;/int:channel&gt;&#xA;&#xA;  &lt;int-http:outbound-channel-adapter url=""http://localhost:8080/prototype-integration-security-service/query?ticket={ticket}""&#xA;                                     http-method=""GET""&#xA;                                     rest-template=""restTemplate""&#xA;                                     channel=""userRequestChannel""&gt;&#xA;    &lt;int-http:uri-variable name=""ticket"" expression=""T(org.springframework.security.core.context.SecurityContextHolder).context.authentication.credentials""/&gt;&#xA;  &lt;/int-http:outbound-channel-adapter&gt;&#xA;&#xA;  &lt;int-http:inbound-channel-adapter path=""/admin/callback*""&#xA;                                    supported-methods=""GET, POST""&#xA;                                    channel=""adminRequestChannel"" /&gt;&#xA;&#xA;  &lt;int:channel id=""adminRequestChannel""&gt;&#xA;    &lt;int:queue/&gt;&#xA;  &lt;/int:channel&gt;&#xA;&#xA;  &lt;int:logging-channel-adapter id=""logging"" channel=""adminRequestChannel"" level=""DEBUG"" /&gt;&#xA;&lt;/beans&gt;&#xA;</code></pre>&#xA;&#xA;<p>In the context configuration file of service module, dispatcher-servlet.xml looks as following.</p>&#xA;&#xA;<pre><code>&lt;beans xmlns=""http://www.springframework.org/schema/beans""&#xA;       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;       xmlns:task=""http://www.springframework.org/schema/task""&#xA;       xmlns:security=""http://www.springframework.org/schema/security""&#xA;       xmlns:int=""http://www.springframework.org/schema/integration""&#xA;       xmlns:int-http=""http://www.springframework.org/schema/integration/http""&#xA;       xmlns:int-security=""http://www.springframework.org/schema/integration/security""&#xA;       xsi:schemaLocation=""http://www.springframework.org/schema/beans&#xA;                           http://www.springframework.org/schema/beans/spring-beans.xsd&#xA;                           http://www.springframework.org/schema/task&#xA;                           http://www.springframework.org/schema/task/spring-task.xsd&#xA;                           http://www.springframework.org/schema/security&#xA;                           http://www.springframework.org/schema/security/spring-security.xsd&#xA;                           http://www.springframework.org/schema/integration&#xA;                           http://www.springframework.org/schema/integration/spring-integration-4.2.xsd&#xA;                           http://www.springframework.org/schema/integration/http&#xA;                           http://www.springframework.org/schema/integration/http/spring-integration-http-4.2.xsd&#xA;                           http://www.springframework.org/schema/integration/security&#xA;                           http://www.springframework.org/schema/integration/security/spring-integration-security-4.2.xsd""&gt;&#xA;&#xA;  &lt;bean id=""restTemplate"" class=""org.springframework.web.client.RestTemplate""&gt;&#xA;    &lt;constructor-arg&gt;&#xA;      &lt;bean class=""org.springframework.http.client.HttpComponentsClientHttpRequestFactory""&gt;&#xA;        &lt;constructor-arg&gt;&#xA;          &lt;bean class=""org.springframework.beans.factory.config.MethodInvokingFactoryBean""&gt;&#xA;            &lt;property name=""targetClass"" value=""org.apache.http.impl.client.HttpClients""/&gt;&#xA;            &lt;property name=""targetMethod"" value=""createMinimal""/&gt;&#xA;          &lt;/bean&gt;&#xA;        &lt;/constructor-arg&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;    &lt;property name=""messageConverters""&gt;&#xA;      &lt;list&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.StringHttpMessageConverter"" /&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"" /&gt;&#xA;        &lt;bean class=""org.springframework.http.converter.FormHttpMessageConverter""&gt;&#xA;        &lt;/bean&gt;&#xA;      &lt;/list&gt;&#xA;    &lt;/property&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""serviceProperties"" class=""org.springframework.security.cas.ServiceProperties""&gt;&#xA;    &lt;property name=""service"" value=""http://localhost:8080/prototype-integration-security-service/login/cas"" /&gt;&#xA;    &lt;property name=""sendRenew"" value=""false"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;!-- Access voters --&gt;&#xA;  &lt;bean id=""accessDecisionManager"" class=""org.springframework.security.access.vote.AffirmativeBased""&gt;&#xA;    &lt;constructor-arg name=""decisionVoters""&gt;&#xA;      &lt;list&gt;&#xA;        &lt;bean class=""org.springframework.security.access.vote.RoleHierarchyVoter""&gt;&#xA;          &lt;constructor-arg&gt;&#xA;            &lt;bean class=""org.springframework.security.access.hierarchicalroles.RoleHierarchyImpl""&gt;&#xA;              &lt;property name=""hierarchy""&gt;&#xA;                &lt;value&gt;&#xA;                  ROLE_ADMIN &gt; ROLE_USER&#xA;                &lt;/value&gt;&#xA;              &lt;/property&gt;&#xA;            &lt;/bean&gt;&#xA;          &lt;/constructor-arg&gt;&#xA;        &lt;/bean&gt;&#xA;        &lt;bean class=""org.springframework.security.access.vote.AuthenticatedVoter"" /&gt;&#xA;        &lt;!-- &lt;bean class=""org.springframework.security.web.access.expression.WebExpressionVoter"" /&gt; --&gt;&#xA;      &lt;/list&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""casEntryPoint"" class=""org.springframework.security.cas.web.CasAuthenticationEntryPoint""&gt;&#xA;    &lt;property name=""loginUrl"" value=""https://localhost:8443/cas/login"" /&gt;&#xA;    &lt;property name=""serviceProperties"" ref=""serviceProperties"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;bean id=""casFilter"" class=""org.springframework.security.cas.web.CasAuthenticationFilter""&gt;&#xA;    &lt;property name=""authenticationManager"" ref=""authenticationManager"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;!-- This filter handles a Single Logout Request from the CAS Server --&gt;&#xA;  &lt;bean id=""singleLogoutFilter"" class=""org.jasig.cas.client.session.SingleSignOutFilter"" /&gt;&#xA;&#xA;  &lt;!-- This filter redirects to the CAS Server to signal Single Logout should be performed --&gt;&#xA;  &lt;bean id=""requestSingleLogoutFilter"" class=""org.springframework.security.web.authentication.logout.LogoutFilter""&gt;&#xA;    &lt;constructor-arg value=""https://localhost:8443/cas/logout"" /&gt;&#xA;    &lt;constructor-arg&gt;&#xA;      &lt;bean class=""org.springframework.security.web.authentication.logout.SecurityContextLogoutHandler"" /&gt;&#xA;    &lt;/constructor-arg&gt;&#xA;    &lt;property name=""filterProcessesUrl"" value=""/logout/cas"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;security:http entry-point-ref=""casEntryPoint"" access-decision-manager-ref=""accessDecisionManager"" use-expressions=""false""&gt;&#xA;    &lt;security:intercept-url pattern=""/**"" access=""ROLE_ADMIN""/&gt;&#xA;    &lt;security:form-login /&gt;&#xA;    &lt;security:logout /&gt;&#xA;    &lt;security:custom-filter before=""LOGOUT_FILTER"" ref=""requestSingleLogoutFilter""/&gt;&#xA;    &lt;security:custom-filter before=""CAS_FILTER"" ref=""singleLogoutFilter""/&gt;&#xA;    &lt;security:custom-filter position=""CAS_FILTER"" ref=""casFilter"" /&gt;&#xA;  &lt;/security:http&gt;&#xA;&#xA;  &lt;security:user-service id=""userService""&gt;&#xA;    &lt;security:user name=""jimi"" password=""jimi"" authorities=""ROLE_ADMIN"" /&gt;&#xA;    &lt;security:user name=""bob"" password=""bob"" authorities=""ROLE_USER"" /&gt;&#xA;  &lt;/security:user-service&gt;&#xA;&#xA;  &lt;bean id=""casAuthenticationProvider"" class=""org.springframework.security.cas.authentication.CasAuthenticationProvider""&gt;&#xA;    &lt;property name=""authenticationUserDetailsService""&gt;&#xA;      &lt;bean class=""org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper""&gt;&#xA;        &lt;constructor-arg index=""0"" ref=""userService"" /&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/property&gt;&#xA;    &lt;property name=""serviceProperties"" ref=""serviceProperties"" /&gt;&#xA;    &lt;property name=""ticketValidator""&gt;&#xA;      &lt;bean class=""org.jasig.cas.client.validation.Cas20ServiceTicketValidator""&gt;&#xA;        &lt;constructor-arg index=""0"" value=""https://localhost:8443/cas"" /&gt;&#xA;      &lt;/bean&gt;&#xA;    &lt;/property&gt;&#xA;    &lt;property name=""key"" value=""localCAS"" /&gt;&#xA;  &lt;/bean&gt;&#xA;&#xA;  &lt;security:authentication-manager alias=""authenticationManager""&gt;&#xA;    &lt;security:authentication-provider ref=""casAuthenticationProvider"" /&gt;&#xA;  &lt;/security:authentication-manager&gt;&#xA;&#xA;  &lt;int:channel-interceptor order=""99""&gt;&#xA;    &lt;bean class=""org.springframework.integration.security.channel.SecurityContextPropagationChannelInterceptor""/&gt;&#xA;  &lt;/int:channel-interceptor&gt;&#xA;&#xA;  &lt;task:executor id=""pool"" pool-size=""5""/&gt;&#xA;&#xA;  &lt;int:poller id=""poller"" default=""true"" fixed-rate=""1000""/&gt;&#xA;&#xA;  &lt;int-security:secured-channels&gt;&#xA;    &lt;int-security:access-policy pattern="".*"" send-access=""ROLE_ADMIN"" /&gt;&#xA;  &lt;/int-security:secured-channels&gt;&#xA;&#xA;  &lt;int-http:inbound-channel-adapter path=""/query*"" supported-methods=""GET, POST"" channel=""requestChannel"" /&gt;&#xA;&#xA;  &lt;int:channel id=""requestChannel""&gt;&#xA;    &lt;int:queue/&gt;&#xA;  &lt;/int:channel&gt;&#xA;&#xA;  &lt;int-http:outbound-channel-adapter url=""http://localhost:8080/prototype-integration-security-web/admin/callback?ticket={ticket}""&#xA;                                     http-method=""GET""&#xA;                                     rest-template=""restTemplate""&#xA;                                     channel=""requestChannel""&gt;&#xA;    &lt;int-http:uri-variable name=""ticket"" expression=""T(org.springframework.security.core.context.SecurityContextHolder).context.authentication.credentials"" /&gt;&#xA;  &lt;/int-http:outbound-channel-adapter&gt;&#xA;&lt;/beans&gt;&#xA;</code></pre>&#xA;&#xA;<p>No additional code is required, this is why I am fond of Spring Integration. Did I do anything wrong or miss some configurations? Please share your ideas, opinions and suggestions. Thanks in advance.</p>&#xA;"
40807126,Run powershell script as microservice,2016-11-25 14:25:28,<windows><powershell><automation><microservices>,1,343,6,0.0,0,"<p>Is it possible to make my powershell script, run as a microservice?</p>&#xA;&#xA;<pre><code>Param(&#xA;    $a,&#xA;    $b&#xA;)&#xA;&#xA;$x = [int]$a + [int]$b&#xA;&#xA;echo $x&#xA;</code></pre>&#xA;"
50227462,Self Updating Simulator for a Web-service Suite,2018-05-08 06:45:48,<java><kotlin><microservices><simulator><eureka>,1,18,0,0.0,0,"<p>I am presently working on an application which has an external dependency on micro-services, there are around 25 microservices, which are administrated via a eureka instance, every microservice has around 3-4 controllers.</p>&#xA;&#xA;<p>This is an external dependency for me and blocks my work if it goes down, also I am unaware of the code ad logics for these microservices. </p>&#xA;&#xA;<p>Currently, I am looking for a solution which can act as a simulator for these services in there absence, some application which can intercept and log, all the request and response to/from the external services, and in absence of these services it can match the last response to a requests from log and provide that response. </p>&#xA;"
50295779,Jhipster Extends Microservice Solution,2018-05-11 15:39:51,<java><architecture><microservices><jhipster>,1,37,0,0.0,0,"<p>I use jhipster in a new project that needs different customizations for each client. &#xA;Every microservice (registry office, accounting etc ...) must be able to be customized according to some customer needs. &#xA;Which is the best solution to manage an extendable microservice with different customizations for each client?</p>&#xA;&#xA;<p>Tnk!!</p>&#xA;"
50221166,"Good microservice pattern for ""object based"" sql database",2018-05-07 19:28:33,<c#><entity-framework><rest><microservices>,1,43,0,0.0,0,"<p>We have a legacy application based on SQL server and win32 middle-tier. Now, Iâ€™m searching for good solutions to write a microservice based REST based API to provide access to the data. We like to use VS, C# or JS and azure.&#xA;A specialty of this application is, the Database has an uncommon ""object based"" approach. Each entity, say persons, files, groups, articles have a relation to a common â€œobjectâ€ table. In this table common attributes are stored. There are also common 1-n related tables like categories. Each â€œobjectâ€ has a unique guid.</p>&#xA;&#xA;<pre><code>person      --&gt;&#xA;file        --&gt;   object   ---&gt; objectcategories&#xA;article     --&gt;            &#xA;</code></pre>&#xA;&#xA;<p>The new api should provide methods like:</p>&#xA;&#xA;<pre><code>GET /person/1 -&gt;&#xA;{&#xA;    lastname: ""Doe"", prename: ""John"", sex: ""m"",&#xA;    guid: ""{guid}"", owner: ""123"",  // object specific attributes&#xA;}&#xA;&#xA;GET /file/1 -&gt; &#xA;{&#xA;    filename:""test.docx"", size:""123"",&#xA;    guid: ""{guid}"", owner: ""123"",  // object specific attributes&#xA;}&#xA;&#xA;GET /object/{guid-a} --&gt;&#xA;{&#xA;    // Returns either file or Person data&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>It should also allow to load additional data like</p>&#xA;&#xA;<pre><code>GET /person/1?categories -&gt;&#xA;{&#xA;    lastname: ""Doe"", prename: ""John"", sex: ""m"",&#xA;    guid: ""{guid}"", owner: ""123"",  // object specific Attributes&#xA;    categories: [&#xA;         ""green"", ""blue""&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In reverse, it would be cool to simply safe an object back. The server must separate the data to the corresponding tables.</p>&#xA;&#xA;<pre><code>PUT /object/{guid} &lt;--&#xA; {&#xA;    lastname: ""Doe"", prename: ""John"", sex: ""m"",&#xA;    guid: ""{guid}"", owner: ""123"",  // object specific Attributes&#xA;    categories: [&#xA;         ""green"", ""blue""&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What is a good pattern? Could Entity Framework (Database-first) do this? Would you go for a manual linq-sql based solution? Are there other suitable libraries for this task?</p>&#xA;"
50261052,"Server constantly running a function to update a cache, will it block all other server functions?",2018-05-09 19:51:54,<node.js><service><redis><architecture><microservices>,2,46,0,0.0,0,"<p>About once a minute, I need to cache all orderbooks from various cryptocurrency exchanges. There are hundreds of orderbooks, so this update function will likely never stop running.</p>&#xA;&#xA;<p>My question is: If my server is constantly running this orderbook update function, will it block all other server functionality? Will users ever be able to interact with my server? </p>&#xA;&#xA;<p>Do I need to create a separate service to perform the updating, or can Node somehow prioritize API requests and pause the caching function?</p>&#xA;"
50248129,Is pact consumer test for generating contract json files only?,2018-05-09 07:46:54,<testing><microservices><pact>,1,70,0,0.0,0,"<p>Is pact consumer test for generating contract json files?</p>&#xA;&#xA;<p>I am studing pact and got qurioused about what is the consumer test for? It tests the response that the test class defindes.</p>&#xA;&#xA;<p>In my code below. I defined a response with 200 and simple body, then Test it calling by mockProvider. seems useless. Anybody please give me some guides.</p>&#xA;&#xA;<pre><code>public class PactTest {&#xA;&#xA;  @Rule&#xA;  public PactProviderRuleMk2 mockProvider&#xA;        = new PactProviderRuleMk2(""test-provider"", ""localhost"", 8017, this);&#xA;&#xA;&#xA;  @Pact(consumer = ""test-consumer"")&#xA;  public RequestResponsePact createPact(PactDslWithProvider builder){&#xA;    Map&lt;String, String&gt; headers = new HashMap&lt;&gt;();&#xA;&#xA;    return builder&#xA;            .given(""test Get"")&#xA;                .uponReceiving(""GET REQUEST"")&#xA;                .path(""/pact"")&#xA;                .method(""GET"")&#xA;            .willRespondWith()&#xA;                .status(200)&#xA;                .headers(headers)&#xA;                .body(""{\""condition\"": true, \""name\"":\""tom\""}"")&#xA;            .toPact();&#xA;  }&#xA;&#xA;  @Test&#xA;  @PactVerification&#xA;  public void givenGet_whenSendRequest_shouldReturn200withProperHeaderAndBody() {&#xA;    ResponseEntity&lt;String&gt; res = new RestTemplate()&#xA;                                        .getForEntity(mockProvider.getUrl()+""/pact"", String.class);&#xA;&#xA;    assertThat(res.getStatusCode().value()).isEqualTo(200);&#xA;  }&#xA;}&#xA;</code></pre>&#xA;"
50128046,How should I design my Spring Microservice?,2018-05-02 06:02:52,<spring><spring-boot><microservices>,3,78,0,0.0,0,"<p>I am trying to create a <code>Microservice architecture</code> for a hobby project and I am confused about some decisions. Can you please help me as I never worked using Microservice before?</p>&#xA;&#xA;<ol>&#xA;<li>One of my requirements is that my <code>AngularJS</code> GUI will need to show some drop-down or List of values (example: a list of countries). This can be fetched using a <code>Microservice</code> REST call, but where should the values come from? Can I fetch these from my <code>Config Server</code>? or should it come from <code>Database</code>? If the latter, then should each of the Microservice have their own Database for lookup value or can it be a common one?</li>&#xA;<li>How would server-side validation work in this case? I mean, there will certainly be a Microservice call the GUI will make for validation but should the validation service be a common Microservice for all Use Cases/Screens or should it be one per GUI page or should the <code>CRUD</code> Microservice be reused for validation as well?</li>&#xA;<li>How do I deal with a use-case where the back-end is not a Database but a Web-service call? Will I need some local <code>DB</code> still to maintain some state in between these calls (especially to take care of scenario where the Web-service call fails) and finally pass on the status to GUI?</li>&#xA;</ol>&#xA;"
50184065,Spring WebFlux: WebClient combines 2 Reactive RESTful Web Service,2018-05-04 22:57:03,<java><microservices><spring-webflux><project-reactor>,1,103,0,0.0,0,"<p>I'm working on a Microservices application with Reactive support using Spring WebFlux. Let see, I have a list of questions belong to a category and list of options for each question. I separate the question and the option into services with Reactive support and I want to have another service to combine them together using WebClient of Spring WebFlux. Of course, it needs to support Reactive also.</p>&#xA;&#xA;<p>QuestionServiceImpl:</p>&#xA;&#xA;<pre><code>public Flux&lt;Question&gt; getQuestions(String categoryId) {&#xA;    WebClient client = WebClient&#xA;        .builder()&#xA;        .baseUrl(getServiceUrl())&#xA;        .build();&#xA;&#xA;    WebClient.ResponseSpec responseSpec = client&#xA;        .get()&#xA;        .uri(""/questions/"" + categoryId)&#xA;        .retrieve();&#xA;&#xA;    return responseSpec.bodyToFlux(Question.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>OptionServiceImpl:</p>&#xA;&#xA;<pre><code>public Flux&lt;Option&gt; getOptions(String questionId) {&#xA;    WebClient client = WebClient&#xA;            .builder()&#xA;            .baseUrl(getServiceUrl())&#xA;            .build();&#xA;&#xA;        WebClient.ResponseSpec responseSpec = client&#xA;            .get()&#xA;            .uri(""/options/"" + questionId)&#xA;            .retrieve();&#xA;&#xA;        return responseSpec.bodyToFlux(Option.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I don't know how to combine a question with its options in the Reactive way. Can anyone suggest some ideas?</p>&#xA;&#xA;<p>Updated solution:</p>&#xA;&#xA;<p>I added a new class named CompositeQuestion</p>&#xA;&#xA;<pre><code>@Data&#xA;@AllArgsConstructor &#xA;public class CompositeQuestion {&#xA;&#xA;    private String id;&#xA;&#xA;    private String description;&#xA;&#xA;    private String categoryId;&#xA;&#xA;    private List&lt;Option&gt; options;&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>and now to get list options for a question, my code is as below:</p>&#xA;&#xA;<pre><code>Flux&lt;CompositeQuestion&gt; compositQuestion = questionsFromCoreQuestionService.flatMap(question -&gt;&#xA;        optionService.getOptions(question.getId())&#xA;            .collectList()&#xA;            .map(options -&gt; new CompositeQuestion(question.getId(), question.getDescription(), question.getCategoryId(), options)))&#xA;        .subscribeOn(Schedulers.elastic());&#xA;</code></pre>&#xA;"
50161783,Can't get config files when run ConfigServer and EurekaServer on docker container,2018-05-03 18:33:41,<spring-boot><docker-compose><microservices><spring-cloud-netflix>,1,182,0,0.0,0,"<p>[Spring boot Microservies]</p>&#xA;&#xA;<p>I have a microservices includes 2 services: ConfigService and DiscoveryService</p>&#xA;&#xA;<ul>&#xA;<li><strong>ConfigService</strong> is enabled ConfigServer, keep files config for microservice</li>&#xA;<li><strong>DiscoveryService</strong> is EurekaServer. It will get config file from ConfigService</li>&#xA;</ul>&#xA;&#xA;<p>When run 2 service on local (not docker), everything is good</p>&#xA;&#xA;<pre><code>Fetching config from server at: http://localhost:8088&#xA;Located environment: name=epl-discovery-service, profiles=[default], label=null, version=3f6887b5b355381341e02ad03615f2415d6a566d, state=null&#xA;Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='configClient'}, MapPropertySource {name='https://github.com/stomer90/epl-config-server.git/epl-discovery-service.yml'}]}&#xA;No active profile set, falling back to default profiles: default&#xA;</code></pre>&#xA;&#xA;<p>but when run 2 service on 2 container (docker), ConfigService run normal, but DiscoveryService have <strong>some error</strong> (can not connect to ConfigService)</p>&#xA;&#xA;<pre><code>Fetching config from server at: http://localhost:8088&#xA;Could not locate PropertySource: I/O error on GET request for ""http://localhost:8088/epl-discovery-service/default"": Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)&#xA;No active profile set, falling back to default profiles: default&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li><strong>ConfigService</strong></li>&#xA;</ul>&#xA;&#xA;<p>EplConfigServiceApplication.java</p>&#xA;&#xA;<blockquote>&#xA;  <p>Blockquote</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableConfigServer&#xA;public class EplConfigServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(EplConfigServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>bootstrap.yml</p>&#xA;&#xA;<pre><code>server:&#xA;  port: 8088&#xA;&#xA; spring:&#xA;  application:&#xA;    name: eplconfigserver&#xA;&#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: https://github.com/stomer90/epl-config-server.git&#xA;</code></pre>&#xA;&#xA;<p>Dockerfile</p>&#xA;&#xA;<pre><code>FROM openjdk:8-jdk-alpine&#xA;&#xA;MAINTAINER Phong Nguyen&#xA;&#xA;VOLUME /tmp&#xA;&#xA;# Add Spring Boot app.jar to Container&#xA;ADD ./target/epl-config-service-0.0.1-SNAPSHOT.jar app.jar&#xA;&#xA;RUN sh -c 'touch /app.jar'&#xA;&#xA;ENV JAVA_OPTS=""""&#xA;ENTRYPOINT [ ""sh"", ""-c"", ""java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar "" ]&#xA;</code></pre>&#xA;&#xA;<p><strong>* DiscoveryService</strong></p>&#xA;&#xA;<p>EplDiscoveryServiceApplication.java</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class EplDiscoveryServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(EplDiscoveryServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>bootstrap.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: epl-discovery-service&#xA;  cloud:&#xA;    config:&#xA;      uri: http://localhost:8088&#xA;</code></pre>&#xA;&#xA;<p>Dockerfile</p>&#xA;&#xA;<pre><code>FROM openjdk:8-jdk-alpine&#xA;&#xA;MAINTAINER Phong Nguyen&#xA;&#xA;VOLUME /tmp&#xA;&#xA;# Add Spring Boot app.jar to Container&#xA;ADD ./target/epl-discovery-service-0.0.1-SNAPSHOT.jar app.jar&#xA;&#xA;RUN sh -c 'touch /app.jar'&#xA;&#xA;ENV JAVA_OPTS=""""&#xA;ENTRYPOINT [ ""sh"", ""-c"", ""java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar"" ]&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li><strong>Docker-compose.yml</strong></li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;<pre><code>version: '3.1'&#xA;&#xA;services:&#xA;  epl-config-service:&#xA;    build: ./epl-config-service&#xA;    ports:&#xA;      - ""8088:8088""&#xA;    restart:&#xA;      unless-stopped&#xA;&#xA;&#xA;  epl-discovery-service:&#xA;    build: ./epl-discovery-service&#xA;    ports:&#xA;      - ""8061:8061""&#xA;    environment:&#xA;      - REGISTRY_HOST=epl-config-service&#xA;    depends_on:&#xA;      - epl-config-service&#xA;    restart:&#xA;      unless-stopped&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>Link source code: <a href=""https://github.com/stomer90/epl-spring-cloud-microservice"" rel=""nofollow noreferrer"">https://github.com/stomer90/epl-spring-cloud-microservice</a></p>&#xA;&#xA;<p>Please help me resolve this issue</p>&#xA;"
50276356,Systems that implement SAGA,2018-05-10 15:23:30,<microservices><saga>,1,57,1,0.0,0,"<p>Do you know some tool, or systems, or framework, or middleware that provide an implementation for the SAGA pattern for transactions?</p>&#xA;&#xA;<p>I found <a href=""https://github.com/eventuate-tram/eventuate-tram-sagas"" rel=""nofollow noreferrer"">eventuate</a>, are you aware of others?</p>&#xA;&#xA;<p>Thank you in advance</p>&#xA;"
50239555,microservice shared domain layer,2018-05-08 17:52:36,<domain-driven-design><microservices><soa><solid-principles>,2,96,1,0.0,0,"<p>I have a doubt about Microservices Architecture. We are developing an ERP and there're several microservices such as Human Resources, Identity, Orders and so on. </p>&#xA;&#xA;<p>We've implemented a shared domain layer for entities that are common for all those layers, including abstractions ( interfaces ) of Company, Location and some value objects. </p>&#xA;&#xA;<p>My question is: What's the boundary of shared items for microservices and how bad is that? </p>&#xA;&#xA;<p>In that case, Those shared entities would be the same for each microservice, so that help us to write less code BUT at the same time creates a small level of coupling. </p>&#xA;"
50289914,Deal with enumeration in Microservices architecture,2018-05-11 10:06:16,<architecture><microservices><enumeration>,2,41,3,1.0,0,"<p>I recently faced a problem when I designed the microservices architecture of our new system. &#xA;To give more context on that, let's suppose that we have two different services. </p>&#xA;&#xA;<ul>&#xA;<li><p>A service is responsible to make payments and the other one </p></li>&#xA;<li><p>B service is responsible to keep track of the orders. </p></li>&#xA;</ul>&#xA;&#xA;<p>We have a use case that we need to update an order state from the service A. </p>&#xA;&#xA;<p>We have these states in an enumeration list inside the service B. </p>&#xA;&#xA;<p>How can I avoid the sharing of this enumeration between two services? &#xA;I need to have decoupled services.</p>&#xA;&#xA;<p>Please feel free to ask for clarifications. </p>&#xA;"
50270206,Linking Microservices to test/dev/prod environments with ingress,2018-05-10 09:55:58,<kubernetes><microservices><kubernetes-ingress>,1,47,3,0.0,0,"<p>Let's consider we have three environments:</p>&#xA;&#xA;<ul>&#xA;<li><code>test.website.com</code></li>&#xA;<li><code>dev.website.com</code></li>&#xA;<li><code>prod.website.com</code></li>&#xA;</ul>&#xA;&#xA;<p>Each of the environment consists of the following microservices: webapp, service1, service2. I want to be able to easily call all the services from JS frontend without having to deal with domains. It would be great if I could just call <code>/services/service1/</code> and the fact I am on the same domain would keep me in the same environment.</p>&#xA;&#xA;<p>So let's consider dev environment:</p>&#xA;&#xA;<ul>&#xA;<li><code>dev.website.com/</code> -> goes to webapp</li>&#xA;<li><code>dev.website.com/services/service1/</code> -> goes to service1</li>&#xA;<li><code>dev.website.com/services/service1/</code> ...</li>&#xA;</ul>&#xA;&#xA;<p>To be able to do that, I configured ingress as follows:</p>&#xA;&#xA;<pre><code>    - path: /services/service1/*&#xA;      backend:&#xA;        serviceName: service1&#xA;        servicePort: 8080&#xA;    - path: /services/service2/*&#xA;      backend:&#xA;        serviceName: service2&#xA;        servicePort: 8080&#xA;    - path: /*&#xA;      backend:&#xA;        serviceName: webapp&#xA;        servicePort: 8080&#xA;</code></pre>&#xA;&#xA;<p>This would work great, but it doesn't.</p>&#xA;&#xA;<ol>&#xA;<li>First issue is that the <code>service1</code> receives full path (<code>/services/service1</code>) instead of just <code>/</code> when being called. For that I found this: <code>ingress.kubernetes.io/rewrite-target: /</code> - But I also foudn that this feature is not implemented, which is contradictory and doesn't make much sense.</li>&#xA;<li>Second problem is that, the order of the services is not followed and call on <code>/services/service1/</code> ends up in <code>webapp</code>.</li>&#xA;</ol>&#xA;&#xA;<p>Is this even a good approach? What is the best practice to do this?</p>&#xA;&#xA;<p><strong>Edit</strong>:</p>&#xA;&#xA;<p>According to suggestions I removed <code>*</code> from the path, which helped, but also removed necessary functionality. I need to be able to use:</p>&#xA;&#xA;<ul>&#xA;<li><code>/en/</code> -> <code>webapp</code></li>&#xA;<li><code>/services/service1/method1</code> -> <code>service1</code></li>&#xA;</ul>&#xA;&#xA;<p>This doesn't work without the <code>*</code> in path.</p>&#xA;"
51827636,How I can register IP address of micro service,2018-08-13 17:26:30,<microservices>,2,14,0,0.0,0,"<p>So I have for example a list of micro services</p>&#xA;&#xA;<p>In one micro service I need to make a call in to another, and I need to know ip adress, lets say I have some micro service REGISTER where I store host:ipdaress of all my services but how I can put this IP's to REGISTER micro-service ?  </p>&#xA;"
51932126,Is it possible to get type defs from an executable schema?,2018-08-20 13:45:21,<microservices><apollo><graphql-js>,1,15,0,0.0,0,"<p>Having a microservice architecture I want an API to be complete even if some microservices are down. I know that this issue can be resolved with a proper orchestration, but I'm interested whether it's possible to handle this situation using only the code.</p>&#xA;&#xA;<p>The problem:</p>&#xA;&#xA;<p>I have 3 microservices: core, A, B. If I start core and A is down I need core to boot successfully and contain A's api. To achieve this I've tried to get type definitions from each remote GraphQL schema and store them in etcd or elsewhere and use to create executable schema if the service is not reachable and thus its schema. </p>&#xA;&#xA;<p>How do I do this if in core I can only get executable schema via apollo link.</p>&#xA;&#xA;<pre><code>const getRemoteSchema = async ({ uri, name }) =&gt; {&#xA;  const link = setContext((request, previousContext) =&gt; ({&#xA;    headers: {&#xA;      context: `${JSON.stringify(previousContext.graphqlContext || {})}`,&#xA;    },&#xA;  })).concat(new HttpLink({ uri, fetch }));&#xA;&#xA;  let schema = await introspectSchema(link).catch(error =&gt; new ApolloError(error.message, 'INTERNAL_SERVER_ERROR', error));&#xA;&#xA;  if (schema instanceof ApolloError) // do something&#xA;</code></pre>&#xA;&#xA;<p>If I'm not mistaking I can only call the following methods on the fetched schema: getQueryType, getTypeMap, etc... these return an object not a string definitions. Is it possible to get typeDefs and store them. I don't want to store the whole executable schema because that may pose security issues as resolvers will be stored in the db. </p>&#xA;&#xA;<p>I don't want to use introspection as it will be disabled in production and also don't want each microservice to send it's typeDefs independently</p>&#xA;"
51755653,Consumer driven contract testing with cucumber,2018-08-08 21:06:54,<testing><cucumber><microservices><spring-cloud-contract><integration-tests>,1,16,0,0.0,0,<p>I have a rest endpoint in a non spring boot project that I am consuming from a spring boot micro-service. Does anyone know how I can use consumer driven contract test in cucumber step definitions when writing integration tests?</p>&#xA;
51808975,Using Amazon ECR Clusters - one per microservice or does each microservice reside on one Service,2018-08-12 12:47:01,<amazon-web-services><microservices><aws-ecr>,2,17,0,0.0,0,"<p>I am new to using AWS ECR Clusters for microservices projects.</p>&#xA;&#xA;<p>I want to deploy a microservices infrastructure, where I'm able to re-build and re-deploy any microservice on demand.  I have deployed a microservice using the ECR registry, and creating Task Definitions per images in ECR.</p>&#xA;&#xA;<p>Is it best practice to create one Cluster per microservice, or one Cluster for all the microservices, but one Service per microserivce? </p>&#xA;&#xA;<p>I would love to hear the best practices around this!</p>&#xA;"
51767389,Spring Eureka Ribbon method executed twice,2018-08-09 12:43:12,<spring><spring-boot><microservices><netflix-eureka><netflix-ribbon>,1,18,0,0.0,0,"<p>I'm encountering a really weird issue with my Spring boot application(s).&#xA;I'm working on a microservice app with Eureka/Ribbon for services discovery, the app is a stat generator providing an API for csv upload and linked to a database for data retrieving, comparison and persistency.</p>&#xA;&#xA;<p>The flow that's been buggy is quite simple :</p>&#xA;&#xA;<ol>&#xA;<li>Check for unprocessed files in the upload directory</li>&#xA;<li>Get the paths of unprocessed files and put them in an array</li>&#xA;<li>For each element of this array convert them from Csv to pojo</li>&#xA;<li>???</li>&#xA;<li>Get rich</li>&#xA;</ol>&#xA;&#xA;<p>The call is made from an api (tried through postman and browsers) this calls the converter microservice. &#xA;The converter microservice walks through the upload direct listing each unprocessed file.&#xA;This list is then used in the same microservice for being processed. At first, the converter calls the data-retriever microservice which returns three list of objects. And then use them to build the pojos based on the csvs.</p>&#xA;&#xA;<p>And here's where the problem appears, this method is executed twice whereas all the others are only executed once.</p>&#xA;&#xA;<p>Csv-uploader microservice (entry endpoint)</p>&#xA;&#xA;<pre><code>@GetMapping(""/proxy/csv/process"")&#xA;public void processProxyCsv(){&#xA;    logger.info(""Called for processing uploaded CSVs"");&#xA;    csvConverterServiceProxy.processPendingCsv();&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the used proxy :</p>&#xA;&#xA;<pre><code>@FeignClient(name=""bbx-rev-csv-converter"")&#xA;@RibbonClient(name=""bbx-rev-csv-converter"")&#xA;public interface CsvConverterServiceProxy {&#xA;    @GetMapping(""/csv/process/running"")&#xA;    public String processPendingCsv();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So far so good, everything seems to work fine, logs appears only once.</p>&#xA;&#xA;<p>Then we go to the csv-converter microservice where all the magic happens (and the bug too), the entry endpoint called previously :</p>&#xA;&#xA;<pre><code>@GetMapping(""/csv/process/running"")&#xA;public ResponseEntity&lt;String&gt; processPendingCsv() {&#xA;    HttpHeaders headers = new HttpHeaders();&#xA;    HttpStatus status = HttpStatus.BAD_REQUEST;&#xA;    String reason = ""Pending..."";&#xA;&#xA;    logger.info(""API call for processing pending CSVs."");&#xA;    if (fileHandlerService.checkForNonProcessedFiles()) {&#xA;        logger.info(""Check over, returning to entry flow."");&#xA;        logger.info(""file path : "" + fileHandlerService.getUploadedFilePath().toString());&#xA;        csvConverterService.convertAllCsv(fileHandlerService.getUploadedFilePath());&#xA;        reason = ""Processing pending CSVs in progress..."";&#xA;    } else {&#xA;        reason = ""No pending files found."";&#xA;    }&#xA;    status = HttpStatus.OK;&#xA;&#xA;    return new ResponseEntity&lt;String&gt;(reason, headers, status);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>From this point, based on logs, this is executed twice.</p>&#xA;&#xA;<p>I've looked through all my code and haven't a two time call or a loop made wrongly for calling this proxy method (or at least didn't found it and truly, I hope I made something silly).</p>&#xA;&#xA;<p>It even got weirder, after a while when all the services are running (after a few minutes) when i call the same endpoint, calls are only made once.</p>&#xA;&#xA;<p>And here are the logs :</p>&#xA;&#xA;<p>First the Csv-uploader logs:</p>&#xA;&#xA;<pre><code>2018-08-09 14:35:17.407  INFO 4588 --- [nio-8000-exec-7] Csv-up-ctrl : Called for processing uploaded CSVs&#xA;</code></pre>&#xA;&#xA;<p>And the csv-converter logs...</p>&#xA;&#xA;<pre><code>2018-08-09 14:35:17.470  INFO 17280 --- [nio-8006-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'&#xA;2018-08-09 14:35:17.470  INFO 17280 --- [nio-8006-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started&#xA;2018-08-09 14:35:17.504  INFO 17280 --- [nio-8006-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 34 ms&#xA;2018-08-09 14:35:17.547  INFO 17280 --- [nio-8006-exec-1] Csv converter controller                 : API call for processing pending CSVs.&#xA;2018-08-09 14:35:17.548  INFO 17280 --- [nio-8006-exec-1] File checker service                     : Checking for unprocessed files ...&#xA;2018-08-09 14:35:17.555  INFO 17280 --- [nio-8006-exec-1] File checker service                     : Found 1 unprocessed files : [test_file.csv]&#xA;2018-08-09 14:35:17.555  INFO 17280 --- [nio-8006-exec-1] Csv converter controller                 : Check over, returning to entry flow.&#xA;2018-08-09 14:35:17.555  INFO 17280 --- [nio-8006-exec-1] Csv converter controller                 : file path : E:\workspace\Blackbox-reversements\csv-uploader\uploads\todo&#xA;2018-08-09 14:35:17.555  INFO 17280 --- [nio-8006-exec-1] Csv converter service                    : convertAllCsv call&#xA;2018-08-09 14:35:17.561  INFO 17280 --- [nio-8006-exec-1] s.c.a.AnnotationConfigApplicationContext : Refreshing SpringClientFactory-bbx-rev-ext-data-retriever: startup date [Thu Aug 09 14:35:17 CEST 2018]; parent: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@7d18bd1a&#xA;2018-08-09 14:35:17.659  INFO 17280 --- [nio-8006-exec-1] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2018-08-09 14:35:18.002  INFO 17280 --- [nio-8006-exec-1] c.netflix.config.ChainedDynamicProperty  : Flipping property: bbx-rev-ext-data-retriever.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647&#xA;2018-08-09 14:35:18.034  INFO 17280 --- [nio-8006-exec-1] c.n.u.concurrent.ShutdownEnabledTimer    : Shutdown hook installed for: NFLoadBalancer-PingTimer-bbx-rev-ext-data-retriever&#xA;2018-08-09 14:35:18.079  INFO 17280 --- [nio-8006-exec-1] c.netflix.loadbalancer.BaseLoadBalancer  : Client: bbx-rev-ext-data-retriever instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=bbx-rev-ext-data-retriever,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:null&#xA;2018-08-09 14:35:18.090  INFO 17280 --- [nio-8006-exec-1] c.n.l.DynamicServerListLoadBalancer      : Using serverListUpdater PollingServerListUpdater&#xA;2018-08-09 14:35:18.125  INFO 17280 --- [nio-8006-exec-1] c.netflix.config.ChainedDynamicProperty  : Flipping property: bbx-rev-ext-data-retriever.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647&#xA;2018-08-09 14:35:18.127  INFO 17280 --- [nio-8006-exec-1] c.n.l.DynamicServerListLoadBalancer      : DynamicServerListLoadBalancer for client bbx-rev-ext-data-retriever initialized: DynamicServerListLoadBalancer:{NFLoadBalancer:name=bbx-rev-ext-data-retriever,current list of Servers=[192.168.0.130:8036],Load balancer stats=Zone stats: {defaultzone=[Zone:defaultzone;    Instance count:1;   Active connections count: 0;    Circuit breaker tripped count: 0;   Active connections per server: 0.0;]&#xA;},Server stats: [[Server:192.168.0.130:8036;    Zone:defaultZone;   Total Requests:0;   Successive connection failure:0;    Total blackout seconds:0;   Last connection made:Thu Jan 01 01:00:00 CET 1970;  First connection made: Thu Jan 01 01:00:00 CET 1970;    Active Connections:0;   total failure count in last (1000) msecs:0; average resp time:0.0;  90 percentile resp time:0.0;    95 percentile resp time:0.0;    min resp time:0.0;  max resp time:0.0;  stddev resp time:0.0]&#xA;]}ServerList:org.springframework.cloud.netflix.ribbon.eureka.DomainExtractingServerList@11bc0eb&#xA;2018-08-09 14:35:18.414  INFO 17280 --- [nio-8006-exec-5] Csv converter controller                 : API call for processing pending CSVs.&#xA;2018-08-09 14:35:18.414  INFO 17280 --- [nio-8006-exec-5] File checker service                     : Checking for unprocessed files ...&#xA;2018-08-09 14:35:18.415  INFO 17280 --- [nio-8006-exec-5] File checker service                     : Found 1 unprocessed files : [test_file.csv]&#xA;2018-08-09 14:35:18.415  INFO 17280 --- [nio-8006-exec-5] Csv converter controller                 : Check over, returning to entry flow.&#xA;2018-08-09 14:35:18.415  INFO 17280 --- [nio-8006-exec-5] Csv converter controller                 : file path : E:\workspace\Blackbox-reversements\csv-uploader\uploads\todo&#xA;2018-08-09 14:35:18.415  INFO 17280 --- [nio-8006-exec-5] Csv converter service                    : convertAllCsv call&#xA;2018-08-09 14:35:18.989  INFO 17280 --- [nio-8006-exec-5] Csv converter service                    : CSVs path will go here&#xA;2018-08-09 14:35:19.050  INFO 17280 --- [nio-8006-exec-1] Csv converter service                    : CSVs path will go here&#xA;2018-08-09 14:35:19.095  INFO 17280 --- [erListUpdater-0] c.netflix.config.ChainedDynamicProperty  : Flipping property: bbx-rev-ext-data-retriever.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647&#xA;</code></pre>&#xA;&#xA;<p>So for not so good. Could it be a configuration issue? I've kept it quite vanilla for my microservices configuration : </p>&#xA;&#xA;<p>For main classes :</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableFeignClients(""com.telemaque.blackbox.reversement.csvuploader"")&#xA;@EnableDiscoveryClient&#xA;public class CsvUploaderApplication {...&#xA;</code></pre>&#xA;&#xA;<p>For the application.properties files :</p>&#xA;&#xA;<pre><code>spring.application.name=bbx-rev-csv-converter&#xA;server.port=8006&#xA;eureka.client.service-url.default-zone=http://localhost:8761/eureka&#xA;</code></pre>&#xA;&#xA;<p>and the application.properties for the naming server :</p>&#xA;&#xA;<pre><code>spring.application.name=bbx-rev-naming-server&#xA;server.port=8761&#xA;&#xA;eureka.client.register-with-eureka=false&#xA;eureka.client.fetch-registry=false&#xA;</code></pre>&#xA;&#xA;<p>For naming server :</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class NamingServerApplication {...&#xA;</code></pre>&#xA;&#xA;<p>For proxies :</p>&#xA;&#xA;<pre><code>@FeignClient(name=""bbx-rev-ext-data-retriever"")&#xA;@RibbonClient(name=""bbx-rev-ext-data-retriever"")&#xA;public interface ExternalDataRetrieverProxy {...&#xA;</code></pre>&#xA;&#xA;<p>I've been looking through here, the eureka git, looked on spring side and still can't figure it out. That's making me crazy, if you have any idea i'd love to hear it!</p>&#xA;&#xA;<p>Thanks a lot for your help!</p>&#xA;&#xA;<p>EDIT : made a few more tests and I've found a weird log in the naming server :</p>&#xA;&#xA;<pre><code>2018-08-09 14:55:08.320  INFO 15068 --- [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BBX-REV-CSV-CONVERTER/192.168.0.130:bbx-rev-csv-converter:8006 with status UP (replication=false)&#xA;2018-08-09 14:55:08.832  INFO 15068 --- [io-8761-exec-10] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BBX-REV-CSV-CONVERTER/192.168.0.130:bbx-rev-csv-converter:8006 with status UP (replication=true)&#xA;</code></pre>&#xA;&#xA;<p>Also when I call the API directly (not through the first microservice) it's correctly executed only once.</p>&#xA;"
51934410,Project build error: 'dependencies.dependency.version' for io.zipkin.java:zipkin-autoconfigure-ui:jar is missing,2018-08-20 15:53:22,<spring><spring-boot><microservices><zipkin>,1,21,0,1.0,0,"<p>I am developing Microservices specifically <code>""zipkin-service""</code>. I have taken a reference from  link: <a href=""https://www.baeldung.com/tracing-services-with-zipkin"" rel=""nofollow noreferrer"">https://www.baeldung.com/tracing-services-with-zipkin</a>.</p>&#xA;&#xA;<p>Could anyone please guide what's the issue ?</p>&#xA;&#xA;<p>When I added below dependencies, then I get the </p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;    &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&#xA;&lt;/dependency&gt;&#xA;&lt;dependency&gt;&#xA;    &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&#xA;    &lt;scope&gt;runtime&lt;/scope&gt;&#xA;&lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>Error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Project build error: 'dependencies.dependency.version' for io.zipkin.java:zipkin-autoconfigure-ui:jar is missing.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>ZipkinServiceApplication.java</strong></p>&#xA;&#xA;<pre><code>@EnableZipkinServer&#xA;@EnableDiscoveryClient&#xA;@SpringBootApplication&#xA;public class ZipkinServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(ZipkinServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
51786390,Microservices in app with low load should I use?,2018-08-10 12:19:28,<web-services><docker><microservices>,2,25,0,0.0,0,"<p>My situation is as following:</p>&#xA;&#xA;<p>We have a complex app, and I would like to break it into multiple development teams that can work in parallel. Microservices concept handles it well, but since the app doesn't have high load it's an overkill to host many different microservices. Thus the question: should I use microservies, or it will involve extra cost in Infrastructure? </p>&#xA;&#xA;<p>Can I run microservices on the same machine in separate processes or I need Docker for each? </p>&#xA;&#xA;<p>Every microserivce provide Web Services/REST, can they even be bound to one IIS or Docker is the only option? how will they resolve to the main app? Will I need API gateway?</p>&#xA;&#xA;<p>If not Microservices, anything else I could use to avoid large monolithic application?</p>&#xA;&#xA;<p>BTW, with Microservices - how do they share the same data in one db? </p>&#xA;"
51779798,How to query when data is spread into different microservices?,2018-08-10 05:51:19,<database><architecture><microservices>,1,26,0,0.0,0,"<p>I'm new on microservices architecture and I'm facing this problem:</p>&#xA;&#xA;<p>I have a platform where basically Users manage the accounting of their Clients.</p>&#xA;&#xA;<p>I have one microservice in charge of the security. This one manages which Users have access to which Clients.</p>&#xA;&#xA;<p>Then I have another microservice that manages the Invoices of the Clients.&#xA;One of the functions here would be: given a User is logged, list all the Invoices of all the Clients that the User has access to.</p>&#xA;&#xA;<p>For that, I thought that I should ask the Security microservice to give me the list of the Clients the User has access to. And then, I go to the database of Invoices and query, filtering by all those clients.</p>&#xA;&#xA;<p>The problem is that I end up with a horrible query, as it's something like:</p>&#xA;&#xA;<p>SELECT * FROM Invoice WHERE clientId IN (CLI1, CLI2, CLI3, ...) -- Potentially 200 clients</p>&#xA;&#xA;<p>I thought to keep a copy of the User-Client relation in the Invoice database. Or to have both microservices sharing the same database. But none of them convince me as I have more microservices that may face the same problem, leading to a huge repetition of data or to a big monolithic database.</p>&#xA;&#xA;<p>Is there a better way to do this?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
51808718,Architectural pattern for a web application with backend server polling other APIs.,2018-08-12 12:12:57,<java><spring-boot><architecture><microservices>,1,30,0,0.0,0,"<p>I'm building a web application using Java/Spring Boot for the backend and uses Angular 5 for the front-end. I don't think the tech stack matters for this question. </p>&#xA;&#xA;<p>The key part is that I have a requirement for the backend to poll several RESTful APIs to retrieve data, store and do various analytics on this data in the future.  For now it's mostly just simple reporting.</p>&#xA;&#xA;<p>At the moment I haven't tried to construct a microservices approach. The application is monolithic and I'm using a simple scheduler on the Spring Boot side to poll the APIs. Some example code is this:</p>&#xA;&#xA;<pre><code>@Component&#xA;public class RestAPIDataScheduler&#xA;{&#xA;   @Scheduled(fixedRate = &lt;&lt;Polling Rate in Milliseconds&gt;&gt;)&#xA;   public void pollApis()&#xA;   {&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm after the most appropriate architectural pattern (microservices most likely) that would be better suited for handling this type of application. Is this a simple API gateway pattern as described here <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a>?  </p>&#xA;"
51929079,How and where to perform response composition in microservice architecture?,2018-08-20 10:46:35,<microservices>,1,30,0,0.0,0,"<p>We want to show alternate of a product like most of the e-commerce websites does. In our case, we need to fetch data from multiple microservices.</p>&#xA;&#xA;<ul>&#xA;<li><strong>Products</strong> - Stores all product information</li>&#xA;<li><strong>Prices</strong> - In our case prices are complex and subject to user's location and other parameters. Hence we made it a separate microservice.</li>&#xA;<li><strong>Reviews</strong> - It manages ratings and reviews about a product.</li>&#xA;</ul>&#xA;&#xA;<p>The end product will be <code>List&lt;AlternateProduct&gt;</code> which would have an image, description, rating out of 5 and a number of reviews.</p>&#xA;&#xA;<p>In microservice architecture, what is the right place to compose a response from multiple microservices?</p>&#xA;&#xA;<p><strong>Approatch 1</strong>: </p>&#xA;&#xA;<ul>&#xA;<li>MVC/Rest API approaches APIGateway </li>&#xA;<li>API Gateway make an async call to all microservices</li>&#xA;<li>The response will be returned to MVC/WebAPI. Where the composition of response can be performed.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Approatch 2</strong>:</p>&#xA;&#xA;<ul>&#xA;<li>MVC/Rest API approaches APIGateway</li>&#xA;<li>API Gateway make an async call to Products microservice.</li>&#xA;<li>Products microservice will call other microservice and perform composition and returns <code>List&lt;UlternateProduct&gt;</code></li>&#xA;</ul>&#xA;&#xA;<p>Please help me decide!</p>&#xA;"
51868586,Multiple micro-services backed by the same DynamoDB table?,2018-08-16 01:52:09,<amazon-dynamodb><microservices><aws-api-gateway>,2,34,0,0.0,0,<p>Is it an anti pattern if multiple micro-services read/write to/from the same DynamoDB table?</p>&#xA;&#xA;<p>Please note that:</p>&#xA;&#xA;<ul>&#xA;<li>We have a fixed schema which will not change any soon.</li>&#xA;<li>All read/write will go though REST services though API gateway + Lambda</li>&#xA;<li>micro-services are deployed on Kubernetes or Lambda</li>&#xA;</ul>&#xA;
51936401,How to restruct data model for microservices?,2018-08-20 18:13:25,<database><database-design><architecture><microservices><data-modeling>,1,36,0,0.0,0,"<p>How to restruct data model for microservices?</p>&#xA;&#xA;<p>for example I have a monolith application.&#xA;Lets name it 'Users and Events CRUD service'.</p>&#xA;&#xA;<p>Users and Events a tightly coupled in terms of physical data base model. Lets data model for them:</p>&#xA;&#xA;<pre><code>Users table:&#xA;    name PK&#xA;&#xA;Events table:&#xA;    title PK&#xA;    creator_user_name FK (points to Users:name)&#xA;</code></pre>&#xA;&#xA;<p>And now I want to separate my monolith application to two microservices. Lets name them</p>&#xA;&#xA;<ol>&#xA;<li>CRUD users service  </li>&#xA;<li>CRUD events service</li>&#xA;</ol>&#xA;&#xA;<p>Here I'm thinkih about separating above data model or not separating.</p>&#xA;&#xA;<p>1 st approach is to:&#xA;    keep going with data model as above one, so both services use one database.</p>&#xA;&#xA;<p>2nd approach is to:&#xA;    restructure my data model to look like this(where each service has its own database):</p>&#xA;&#xA;<pre><code>DB 1: users&#xA;        Users table:&#xA;            name PK    &#xA;&#xA;DB 2: events&#xA;    Event table:&#xA;        title PK&#xA;        creator_user_name (indexed)&#xA;</code></pre>&#xA;&#xA;<p>Considering this case, what approach is best? What is the best practice in that case?</p>&#xA;&#xA;<p>I guess that I can simply pick 1st approach and it will be nothing wrong with it, but&#xA;what about approach #2? Is it usable int practice? Could it cause some suprising consequences later then?&#xA;I guess that approach #2 is perfecrtly fine as well but I'm not sure, so need help to clarify.</p>&#xA;"
51916102,Is microservice architecture using message queues and event driven architecture same,2018-08-19 09:00:58,<microservices><system-design><event-driven-design>,2,38,0,1.0,0,<p>Edit v1: &#xA;I have been going through some system design videos and learnt about <em>microservice architecture</em> using message queues and <em>event-driven architecture</em>.</p>&#xA;&#xA;<p>But I don't seem to find any substantial point of difference between the two.&#xA;Both have different components/services <em>publishing or subscribing</em> to <em>eventBus/messagingQueues</em> and performing the tasks associated with the published event. </p>&#xA;&#xA;<p>Is microservice architecture with messaging queues a subset of event driven architecture or is there something more to it that I need to figure out. </p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Original V0:&#xA;I have been going through some system design videos and learnt about <em>microservice architecture</em> and <em>event-driven architecture</em>.</p>&#xA;&#xA;<p>But I don't seem to find any substantial point of difference between the two.&#xA;Both have different components/services <em>publishing or subscribing</em> to <em>eventBus/messagingQueues</em> and performing the tasks associated with the published event. </p>&#xA;&#xA;<p>Is microservice architecture a subset of event driven architecture or is there something more to it that I need to figure out. </p>&#xA;
51918410,Caused by: java.lang.ClassNotFoundException: org.springframework.messaging.converter.MessageConverter in microservices,2018-08-19 13:58:41,<spring><spring-boot><microservices>,1,38,0,1.0,0,"<p>I am following microservices tutorials from the link : <a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a> and I was able to successfully start the following services</p>&#xA;&#xA;<ol>&#xA;<li>config</li>&#xA;<li>registry</li>&#xA;<li>gateway</li>&#xA;</ol>&#xA;&#xA;<p>In each services .yml file, I changed registry to localhost and config to localhost too.</p>&#xA;&#xA;<p>but when I ran the ""monitoring"" service, I get the below error.</p>&#xA;&#xA;<pre><code>ava.lang.NoClassDefFoundError: org/springframework/messaging/converter/MessageConverter&#xA;    at java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.8.0_151]&#xA;    at java.lang.ClassLoader.defineClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.security.SecureClassLoader.defineClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.URLClassLoader.defineClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.URLClassLoader.access$100(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.URLClassLoader$1.run(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.URLClassLoader$1.run(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_151]&#xA;    at java.net.URLClassLoader.findClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at org.springframework.integration.config.IntegrationRegistrar.registerDefaultDatatypeChannelMessageConverter(IntegrationRegistrar.java:425) ~[spring-integration-core-5.0.6.RELEASE.jar:5.0.6.RELEASE]&#xA;    at org.springframework.integration.config.IntegrationRegistrar.registerBeanDefinitions(IntegrationRegistrar.java:106) ~[spring-integration-core-5.0.6.RELEASE.jar:5.0.6.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.lambda$loadBeanDefinitionsFromRegistrars$1(ConfigurationClassBeanDefinitionReader.java:358) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at java.util.LinkedHashMap.forEach(Unknown Source) ~[na:1.8.0_151]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromRegistrars(ConfigurationClassBeanDefinitionReader.java:357) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:145) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:117) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:328) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:233) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:93) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:694) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532) ~[spring-context-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:395) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at com.piggymetrics.monitoring.MonitoringApplication.main(MonitoringApplication.java:14) [classes/:na]&#xA;Caused by: java.lang.ClassNotFoundException: org.springframework.messaging.converter.MessageConverter&#xA;    at java.net.URLClassLoader.findClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;    ... 32 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p>Error:&#xA;<a href=""https://i.stack.imgur.com/8X0Uk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8X0Uk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Below error while starting the ""auth-service""</p>&#xA;&#xA;<pre><code>com.mongodb.MongoSocketException: auth-mongodb&#xA;    at com.mongodb.ServerAddress.getSocketAddress(ServerAddress.java:188) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    at com.mongodb.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:59) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    at com.mongodb.connection.SocketStream.open(SocketStream.java:57) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    at com.mongodb.connection.InternalStreamConnection.open(InternalStreamConnection.java:126) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    at com.mongodb.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:114) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    at java.lang.Thread.run(Unknown Source) [na:1.8.0_151]&#xA;Caused by: java.net.UnknownHostException: auth-mongodb&#xA;    at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress$2.lookupAllHostAddr(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress.getAddressesFromNameService(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress.getAllByName0(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress.getAllByName(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress.getAllByName(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.InetAddress.getByName(Unknown Source) ~[na:1.8.0_151]&#xA;    at com.mongodb.ServerAddress.getSocketAddress(ServerAddress.java:186) ~[mongodb-driver-core-3.6.4.jar:na]&#xA;    ... 5 common frames omitted&#xA;</code></pre>&#xA;"
51861095,Is Kafka with CQRS is a microservice approach?,2018-08-15 14:51:46,<architecture><apache-kafka><microservices><cqrs>,2,42,0,0.0,0,<p>Is Kafka with CQRS is a microservice approach ?or else kafka and CQRS are separate terms that describes the patterns in architecture.</p>&#xA;
51855075,Django microservices within Docker,2018-08-15 08:08:19,<django><docker><nginx><docker-compose><microservices>,3,44,0,0.0,0,"<p>I have the following <code>docker-compose.yml</code>:</p>&#xA;&#xA;<pre><code>version: '3.6'&#xA;&#xA;services:&#xA;  db:&#xA;    image: postgres:10.4&#xA;    volumes:&#xA;      - postgres_data:/var/lib/postgresql/data/&#xA;  cache:&#xA;    image: redis:4.0.10&#xA;    volumes:&#xA;      - redis_data:/data&#xA;  web:&#xA;    build: .&#xA;    image: dockerdjangoexample&#xA;    command: bash -c ""gunicorn demosite.wsgi:application -b 0.0.0.0:8000""&#xA;    volumes:&#xA;      - .:/code&#xA;    depends_on:&#xA;      - db&#xA;      - cache&#xA;  nginx:&#xA;    image: nginx:1.15.2-alpine&#xA;    ports:&#xA;      - ""8000:8000""&#xA;    volumes:&#xA;      - ./docker-config/nginx:/etc/nginx/conf.d&#xA;    depends_on:&#xA;      - web&#xA;&#xA;volumes:&#xA;  postgres_data:&#xA;  redis_data:&#xA;</code></pre>&#xA;&#xA;<p>The <code>Dockerfile</code> is:</p>&#xA;&#xA;<pre><code>FROM python:3.6.5&#xA;&#xA;ENV PYTHONDONTWRITEBYTECODE 1&#xA;ENV PYTHONUNBUFFERED 1&#xA;&#xA;WORKDIR /code&#xA;COPY . /code/&#xA;&#xA;RUN pip install --upgrade pip&#xA;RUN pip install pipenv&#xA;RUN pipenv install --deploy --system --skip-lock --dev&#xA;</code></pre>&#xA;&#xA;<p>The <code>Nginx</code> config file is:</p>&#xA;&#xA;<pre><code>upstream web {&#xA;  ip_hash;&#xA;  server web:8000;&#xA;}&#xA;&#xA;server {&#xA;  location / {&#xA;         proxy_pass http://web/;&#xA;  }&#xA;  listen 8000;&#xA;  server_name localhost;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This all works perfectly. What im trying to figure out now is how I can add a second <code>Django</code> app into the mix so I can create a microservice environment.</p>&#xA;&#xA;<p>For example, the existing web app from above would be an API that handles user registration / sign in etc. I would like to add another <code>Django</code> API into the mix that would do something else and would also use its own database.</p>&#xA;&#xA;<p>If this were to theoretically ever be put into a production environment, then the first API would be used through urls starting with <code>www.demosite.com/api/users</code> and the second API could be used through urls starting with <code>www.demosite.com/api/widgets</code>.</p>&#xA;&#xA;<p>Im not sure how to accomplish this from a <code>Docker</code> and <code>Nginx</code> perspective.</p>&#xA;&#xA;<p>Also, if im doing anything completely wrong so far, please correct me as I am new to this.</p>&#xA;"
51794404,Monolithic to Microservices with Sharing DB,2018-08-10 21:47:26,<java><spring-boot><microservices>,1,79,0,0.0,0,"<p>I am trying to move slowly moving the app from Monolithic to microservices but the first step is to move to a more like microservices ready state.  </p>&#xA;&#xA;<p>I have a monolithic system SA that needs to push large amount of data to Cassandra table TB and the service SB that consumes the TB table, does that against the microservices principle?</p>&#xA;&#xA;<p>Basically I want a large amount of data that to push to the service SB but if it pushes that via rest api that is too large and time consuming. </p>&#xA;"
51932616,Caused by: java.lang.NoClassDefFoundError: org/springframework/boot/bind/RelaxedPropertyResolver - microservices,2018-08-20 14:10:13,<spring><spring-boot><microservices><spring-cloud>,2,79,0,1.0,0,"<p>I am working on <strong>Spring Boot + Microservices</strong> project. In this project, have developed <code>""microservices-dashboard""</code> project as well.</p>&#xA;&#xA;<p>When I simply run this project, found the below error. I'm using <code>spring-boot-starter-parent</code> to <code>&lt;version&gt;2.0.4.RELEASE&lt;/version&gt;</code></p>&#xA;&#xA;<p><strong>Error:</strong></p>&#xA;&#xA;<pre><code>org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [com.its.MicroservicesDashboardApplication]; nested exception is java.lang.IllegalStateException: Could not evaluate condition on de.codecentric.boot.admin.config.SpringBootAdminClientAutoConfiguration due to org/springframework/boot/bind/RelaxedPropertyResolver not found. Make sure your own configuration does not rely on that class. This can also happen if you are @ComponentScanning a springframework package (e.g. if you put a @ComponentScan in the default package by mistake)&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.processImports(ConfigurationClassParser.java:646) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.lambda$processDeferredImportSelectors$2(ConfigurationClassParser.java:566) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at java.util.ArrayList.forEach(Unknown Source) ~[na:1.8.0_162]&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.processDeferredImportSelectors(ConfigurationClassParser.java:563) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:188) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:316) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:233) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:271) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:91) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:694) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:398) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:330) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.its.MicroservicesDashboardApplication.main(MicroservicesDashboardApplication.java:15) [classes/:na]&#xA;Caused by: java.lang.IllegalStateException: Could not evaluate condition on de.codecentric.boot.admin.config.SpringBootAdminClientAutoConfiguration due to org/springframework/boot/bind/RelaxedPropertyResolver not found. Make sure your own configuration does not rely on that class. This can also happen if you are @ComponentScanning a springframework package (e.g. if you put a @ComponentScan in the default package by mistake)&#xA;    at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:55) ~[spring-boot-autoconfigure-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:108) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:221) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.context.annotation.ConfigurationClassParser.processImports(ConfigurationClassParser.java:636) ~[spring-context-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    ... 17 common frames omitted&#xA;Caused by: java.lang.NoClassDefFoundError: org/springframework/boot/bind/RelaxedPropertyResolver&#xA;    at de.codecentric.boot.admin.config.SpringBootAdminClientEnabledCondition.isEnabled(SpringBootAdminClientEnabledCondition.java:59) ~[spring-boot-admin-starter-client-1.3.3.jar:1.3.3]&#xA;    at de.codecentric.boot.admin.config.SpringBootAdminClientEnabledCondition.getMatchOutcome(SpringBootAdminClientEnabledCondition.java:45) ~[spring-boot-admin-starter-client-1.3.3.jar:1.3.3]&#xA;    at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:47) ~[spring-boot-autoconfigure-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    ... 20 common frames omitted&#xA;Caused by: java.lang.ClassNotFoundException: org.springframework.boot.bind.RelaxedPropertyResolver&#xA;    at java.net.URLClassLoader.findClass(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_162]&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_162]&#xA;    ... 23 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p><strong>MicroservicesDashboardApplication.java</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;@EnableMicroservicesDashboardServer&#xA;public class MicroservicesDashboardApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(MicroservicesDashboardApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: microservices-dashboard&#xA;&#xA;server:&#xA;  port: 8083&#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;!-- Actuator --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;!-- Web --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;!-- Eureka Server --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;!-- MS Dashboard Server --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;be.ordina&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;microservices-dashboard-server&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.0.1&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;</code></pre>&#xA;"
51861930,seneca - communication between two microservices,2018-08-15 15:39:11,<microservices><seneca>,1,22,1,0.0,0,"<p>I'm new in Seneca. I have been trying to make two microservices to communicate each other but I keep failing and get this errors:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: Response Error: 404 Not Found&#xA;      at module.exports.internals.Utils.internals.Utils.handle_response (c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\seneca-transport\lib\transport-utils.js:71:11)&#xA;      at c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\seneca-transport\lib\http.js:154:25&#xA;      at read (c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\wreck\lib\index.js:590:24)&#xA;      at finish (c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\wreck\lib\index.js:398:20)&#xA;      at wrapped (c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\hoek\lib\index.js:879:20)&#xA;      at module.exports.internals.Recorder.onReaderFinish (c:\Users\Actiview\Desktop\microservices\orderManager\node_modules\wreck\lib\index.js:449:16)&#xA;      at Object.onceWrapper (events.js:313:30)&#xA;      at emitNone (events.js:111:20)&#xA;      at module.exports.internals.Recorder.emit (events.js:208:7)&#xA;      at finishMaybe (_stream_writable.js:614:14)</p>&#xA;  &#xA;  <p>=== SENECA FATAL ERROR === MESSAGE:  ::: seneca: Action  failed: Response Error: 404 Not Found. CODE:     ::: act_execute INSTANCE  :::&#xA;  Seneca/pcbyi7v5c76v/1534346071465/6536/3.7.0/- DETAILS   ::: {&#xA;  message: 'Response Error: 404 Not Found',&#xA;                  pattern: '',&#xA;                  fn: { [Function: transport_client] id: 'host:127.0.0.2,pg:,port:8080' },&#xA;                  callback: &#xA;                   { [Function: bound action_reply]&#xA;                     seneca: &#xA;                      Seneca {&#xA;                        'private$': &#xA;                         { act: &#xA;                            { parent: &#xA;                               { start: 1534346071559,&#xA;                                 end: 1534346071561, and more...</p>&#xA;</blockquote>&#xA;&#xA;<p>this is my code:</p>&#xA;&#xA;<p>orderIndex.ts</p>&#xA;&#xA;<pre><code>    {&#xA;    const orderPlugin = require('./orderManagerPlugin');&#xA;    const  express = require('express');&#xA;    const SenecaWeb = require('seneca-web');&#xA;    const seneca = require(""seneca"")();&#xA;    let bodyParser = require('body-parser');&#xA;&#xA;&#xA;&#xA;    var Routes = [{&#xA;        prefix: '/orders',&#xA;        pin: 'area:order,action:*',&#xA;        map: {&#xA;            fetch: { GET: true },&#xA;            create: { GET: false, POST: true },&#xA;            delete: { GET: false, DELETE: true },&#xA;        }&#xA;    }]&#xA;&#xA;    var config = {&#xA;        routes: Routes,&#xA;        adapter: require('seneca-web-adapter-express'),&#xA;        context: express().use(bodyParser.urlencoded({ 'extended': 'true' })).use(bodyParser.json()),&#xA;        options: {parseBody: false}&#xA;    }&#xA;&#xA;    seneca.use(SenecaWeb,config);&#xA;    seneca.use(  orderPlugin  );&#xA;&#xA;&#xA;    seneca.ready(function (err) {&#xA;        const app = seneca.export('web/context')();&#xA;        app.listen({ host: ""127.0.0.4"", port: 8081 });&#xA;    });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>orderPlugin.ts</p>&#xA;&#xA;<pre><code>{&#xA;var plugin = function orderPlugin(options) {&#xA;    var seneca = this;&#xA;    var senecaEmailer;&#xA;&#xA;    seneca.add({ area: ""order"", action: ""fetch"" }, function (args,&#xA;        done) {&#xA;        var orders = this.make(""orders"");&#xA;        orders.list$({ id: args.id }, done);&#xA;    });&#xA;&#xA;    seneca.add({ area: ""order"", action: ""delete"" }, function (args,&#xA;        done) {&#xA;        var orders = this.make(""orders"");&#xA;        orders.remove$({ id: args.id }, function (err) {&#xA;            done(err, null);&#xA;        });&#xA;    });&#xA;&#xA;    seneca.add({ area: ""order"", action: ""create"" }, function (args,&#xA;        done) {&#xA;        console.log('create order');&#xA;       senecaEmailer.act( 'role:web', {area: 'email', action:'send'}   , done);&#xA;&#xA;    });&#xA;&#xA;    this.add( { init: ""orderPlugin"" }, function (args, done) {  &#xA;        senecaEmailer = require(""seneca"")().client({ host: ""127.0.0.2"", port: 8080 });&#xA;        done();&#xA;    });&#xA;}&#xA;&#xA;module.exports = plugin;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>emailIndex.ts</p>&#xA;&#xA;<pre><code>{&#xA;&#xA;const mailPlugin = require('./emailingPlugin');&#xA;const  express = require('express');&#xA;const SenecaWeb = require('seneca-web');&#xA;const seneca = require(""seneca"")();&#xA;let bodyParser = require('body-parser');&#xA;&#xA;var Routes = [{&#xA;    prefix: '/emails',&#xA;    pin: 'area:email, action:*',&#xA;    map: {&#xA;        send: { GET: true },&#xA;    }&#xA;}]&#xA;&#xA;var config = {&#xA;    routes: Routes,&#xA;    adapter: require('seneca-web-adapter-express'),&#xA;    context: express().use(bodyParser.urlencoded({ 'extended': 'true' })).use(bodyParser.json()),&#xA;    options: {parseBody: false}&#xA;}&#xA;&#xA;seneca.use(SenecaWeb,config);&#xA;seneca.use(  mailPlugin  );&#xA;&#xA;&#xA;seneca.ready(function (err) {&#xA;    const app = seneca.export('web/context')();&#xA;    app.listen({ host: ""127.0.0.2"", port: 8080 } );&#xA;});&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>emailPlugin.ts</p>&#xA;&#xA;<pre><code>{&#xA;&#xA;import {EmailService} from './emailService';&#xA;var plugin = function emailPlugin(options) {&#xA;    var seneca = this;&#xA;    let mailer :EmailService ;&#xA;&#xA;&#xA;    seneca.add({area: ""email"", action: ""send""}, function(args, done) {&#xA;        mailer.sendMail('guzon56@gmail.com', done);&#xA;    });&#xA;&#xA;    this.add( { init: ""emailPlugin"" }, function (args, done) {  &#xA;        console.log('before init');&#xA;        mailer = require('./emailService')();&#xA;        console.log('after init');&#xA;        done();&#xA;    });&#xA;};&#xA;&#xA;   module.exports = plugin;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>please help me.&#xA;Tnx.</p>&#xA;"
51907715,Cannot use Feign client from a message consumer,2018-08-18 10:42:27,<microservices><jhipster><okta><spring-cloud-feign><feign>,1,24,1,0.0,0,"<p>I have a set of three microservices created with JHipster and configured with Okta OAuth2 autentication.</p>&#xA;&#xA;<p>I've also added the integration with RabbitMQ message service so one of the service produce messages on certain events and other one consume those messages to update its database.</p>&#xA;&#xA;<p>Now the second service, to full update its data, needs information from a third service that I would like to call with FeignClient but it fails with the following stack:</p>&#xA;&#xA;<pre><code>Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'request' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet/DispatcherPortlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request.&#xA;at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:362)&#xA;at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)&#xA;at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:193)&#xA;at com.sun.proxy.$Proxy237.getAccessToken(Unknown Source)&#xA;at it.myefm.myspot.people.security.oauth2.AuthorizationHeaderUtil.getAuthorizationHeaderFromOAuth2Context(AuthorizationHeaderUtil.java:26)&#xA;at it.myefm.myspot.people.client.TokenRelayRequestInterceptor.apply(TokenRelayRequestInterceptor.java:23)&#xA;at feign.SynchronousMethodHandler.targetRequest(SynchronousMethodHandler.java:158)&#xA;at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:88)&#xA;at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:76)&#xA;at feign.hystrix.HystrixInvocationHandler$1.run(HystrixInvocationHandler.java:108)&#xA;at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302)&#xA;at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298)&#xA;at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46)&#xA;... 113 more&#xA;&#xA;Caused by: java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet/DispatcherPortlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request.&#xA;at org.springframework.web.context.request.RequestContextHolder.currentRequestAttributes(RequestContextHolder.java:131)&#xA;at org.springframework.web.context.request.AbstractRequestAttributesScope.get(AbstractRequestAttributesScope.java:42)&#xA;at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:350)&#xA;... 126 more&#xA;</code></pre>&#xA;&#xA;<p>I think the problem is that the Feign execution does not start from a web request so there is no authentication infos in context...right?</p>&#xA;&#xA;<p>Is there other way to reach my data between services?</p>&#xA;"
51878195,Kubernetes Cross Namespace Ingress Network,2018-08-16 13:25:50,<kubernetes><microservices><kubernetes-ingress>,1,50,1,0.0,0,"<p>I have a simple ingress network, I want to access services at different namespaces, from this ingress network.</p>&#xA;&#xA;<p>How I can do this? &#xA;My ingress network yaml file: </p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Ingress&#xA;metadata:&#xA;  name: ingress&#xA;spec:&#xA;  rules:&#xA; - host: api.myhost.com&#xA; http:&#xA; paths:&#xA;  - backend:&#xA;      serviceName: bookapi-2&#xA;      servicePort: 8080&#xA;    path: /booking-service/&#xA;</code></pre>&#xA;&#xA;<p>I've set the ExternalNames service type to the yaml file: </p>&#xA;&#xA;<pre><code> apiVersion: v1&#xA; kind: Service&#xA; metadata:&#xA;   name: bookapi-2&#xA;   namespace: booking-namespace&#xA; spec:&#xA;   type: ExternalName&#xA;   externalName: bookapi-2&#xA;   ports:&#xA;     - name: app&#xA;     protocol: TCP&#xA;      port: 8080&#xA;      targetPort: 8080&#xA;   selector:&#xA;      app: bookapi-2&#xA;      tier: backend-2&#xA;</code></pre>&#xA;"
51918125,"java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing in Microservices",2018-08-19 13:27:27,<spring-boot><microservices>,1,32,2,1.0,0,"<p>I am following Microservices from link: <a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a>. I was able to simply start the ""config"" service successfully, but when I tried to start the ""registry"" service, I got the below error. </p>&#xA;&#xA;<p>Could anyone please guide on what is the issue ? I dont see any proper steps about setting or sequences to run the microservices.</p>&#xA;&#xA;<pre><code>2018-08-19 18:55:15.424  INFO 12700 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://config:8888&#xA;2018-08-19 18:55:17.805  INFO 12700 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://config:8888. Will be trying the next url if available&#xA;2018-08-19 18:55:17.826 ERROR 12700 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xA;&#xA;java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:136) ~[spring-cloud-config-client-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94) ~[spring-cloud-context-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:633) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:373) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:325) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) [spring-boot-2.0.3.RELEASE.jar:2.0.3.RELEASE]&#xA;    at com.piggymetrics.registry.RegistryApplication.main(RegistryApplication.java:12) [classes/:na]&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://config:8888/registry/default"": config; nested exception is java.net.UnknownHostException: config&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:732) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:600) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:218) ~[spring-cloud-config-client-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:96) ~[spring-cloud-config-client-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;    ... 7 common frames omitted&#xA;Caused by: java.net.UnknownHostException: config&#xA;    at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.PlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.SocksSocketImpl.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.NetworkClient.doConnect(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.http.HttpClient.&lt;init&gt;(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(Unknown Source) ~[na:1.8.0_151]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.connect(Unknown Source) ~[na:1.8.0_151]&#xA;    at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:76) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:723) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE]&#xA;    ... 11 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Wr8w0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wr8w0.png"" alt=""enter image description here""></a></p>&#xA;"
51921033,Project build error: 'dependencies.dependency.version' for org.springframework.cloud:spring-cloud-starter-eureka-server:jar is missing,2018-08-19 19:17:26,<spring><spring-boot><microservices>,1,39,2,1.0,0,"<p>I am developing a code from <a href=""https://www.dineshonjava.com/microservices-with-spring-boot/"" rel=""nofollow noreferrer"">https://www.dineshonjava.com/microservices-with-spring-boot/</a>. When I update the spring-boot-starter-parent from <code>1.5.4.RELEASE</code> to <code>2.0.4.RELEASE</code>, build got failed.</p>&#xA;&#xA;<p>Could anyone please guide me what is the issue ?</p>&#xA;&#xA;<blockquote>&#xA;  <p>Project build error: 'dependencies.dependency.version' for org.springframework.cloud:spring-cloud-starter-eureka-server:jar is missing.</p>&#xA;</blockquote>&#xA;&#xA;<p>Another error:</p>&#xA;&#xA;<pre><code>Multiple annotations found at this line:&#xA;    - For artifact {org.springframework.cloud:spring-cloud-starter-eureka-server:null:jar}: The version cannot be empty. (org.apache.maven.plugins:maven-resources-plugin:3.0.2:resources:default-resources:process-&#xA;     resources) org.apache.maven.artifact.InvalidArtifactRTException: For artifact {org.springframework.cloud:spring-cloud-starter-eureka-server:null:jar}: The version cannot be empty. at &#xA;     org.apache.maven.artifact.DefaultArtifact.validateIdentity(DefaultArtifact.java:148) at org.apache.maven.artifact.DefaultArtifact.&lt;init&gt;(DefaultArtifact.java:123) at &#xA;     org.apache.maven.artifact.factory.DefaultArtifactFactory.createArtifact(DefaultArtifactFactory.java:157) at org.apache.maven.artifact.factory.DefaultArtifactFactory.createDependencyArtifact(DefaultArtifactFactory.java:&#xA;     57) at org.apache.maven.project.artifact.MavenMetadataSource.createDependencyArtifact(MavenMetadataSource.java:328) at &#xA;     org.apache.maven.project.artifact.MavenMetadataSource.createArtifacts(MavenMetadataSource.java:503) at &#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;!-- Eureka registration server --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;!-- &lt;version&gt;Camden.SR5&lt;/version&gt; --&gt;&#xA;                &lt;version&gt;Finchley.RELEASE&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;</code></pre>&#xA;"
51810147,Spring Boot Microservice Intellij Idea,2018-08-12 15:17:54,<java><spring><spring-boot><intellij-idea><microservices>,1,42,2,0.0,0,<p>I want to create a multi artifact spring boot microservice application in intellij idea. I can do that in STS which allows multiple artifacts to be created inside a workspace. I am not able to do the same in intellij idea as whenever I try to add a new artifact it gives me an option of new window or this window thereby technically rendering only one artifact visible. I need to create several spring boot microservice application that can run on different ports. I am using intellij idea 18.</p>&#xA;
51799330,communication between 2 microservices,2018-08-11 11:46:22,<spring-mvc><microservices>,2,48,2,0.0,0,"<p>I have two small micro services developed using spring boot. For communication between these two services, I am not using any api gateway or messaging layer. </p>&#xA;&#xA;<p>I am planning to call other service using URL ( http://. I will be using rest template here.</p>&#xA;&#xA;<p>What could be the disadvantages for not using any api gateway here for communication between two services.</p>&#xA;"
51835569,Symfony 4 and Microservices,2018-08-14 07:05:33,<symfony><bundle><microservices><symfony4>,2,75,2,0.0,0,"<p>Say I'm going to create few microservices: Alpha, Beta, Gamma.&#xA;In terms of Application structure using older Symfony version like 2, I'd create a bundle for each service, but bundles are no longer recommended in Symfony 4. So... Should I create separate repositories for every service or still create a bundles in a one App?</p>&#xA;"
51781316,Unable to login through gateway jhipster 4.9.0 microservice architechture,2018-08-10 07:33:01,<java><microservices><jhipster><jhipster-registry>,1,33,4,0.0,0,"<p>I've generated microservice application through jHipster 4.9.0.&#xA;My UAA server is running on port 9999 and gateway on 8080 these microservices are connected through jHipster registry. When I try to log in through the gateway <strong>it's giving me 404 for /auth/login</strong> although gateway has this endpoint in AuthResource.java file.&#xA;I have just generated these microservices and trying to log in but unfortunately, I'm unable to log in. Please guide me if there is something wrong I do not want to use the latest version of jHipster. JHipster registry version is 3.3. war download from github. It would be great if you can help me in any way. Thanks in advance. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/LzYgn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LzYgn.png"" alt=""enter image description here""></a></p>&#xA;"
51911797,How to manage microservices that are live,2018-08-18 19:12:13,<java><spring><spring-boot><microservices>,3,68,5,0.0,0,"<p>I have been testing out microservices lately using springboot to create microservice projects. The more i understand about the setup the more questions i am confronted with. </p>&#xA;&#xA;<ol>&#xA;<li>How are all the microservices that are running, managed? How do developers manage, deploy or update microservices via a central location?</li>&#xA;<li>When deploying multiple instances of a microservice, do you leave the port to be decided during runtime, or should it be predefined?</li>&#xA;</ol>&#xA;&#xA;<p>I am sure there will be much more questions popping up later.&#xA;Links used:</p>&#xA;&#xA;<ul>&#xA;<li><a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started</a></li>&#xA;<li><a href=""https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/"" rel=""nofollow noreferrer"">https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/</a></li>&#xA;</ul>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
40671392,service fabric client just exits,2016-11-18 07:15:05,<wcf><azure><microservices><azure-service-fabric>,1,66,0,0.0,0,"<p>I've built an azure service fabric app/service which caches objects. Now with the code below I made a client in a console window which calls the service.&#xA;When putting a breakpoint on c.Add and then stepping over it the program just exits. No exception is thrown, ""done"" is not printed, the program just exits with code 0.&#xA;The service is running and is in healthy state. What can I do to find out whats wrong?</p>&#xA;&#xA;<pre><code>class Program&#xA;{&#xA;    static void Main(string[] args)&#xA;    {&#xA;        Test();&#xA;    }&#xA;&#xA;    static async void Test()&#xA;    {&#xA;        Uri serviceName = new Uri(""fabric:/CacheApp/PreorderCache"");&#xA;        ServicePartitionResolver resolver = new ServicePartitionResolver(() =&gt; new System.Fabric.FabricClient());&#xA;        NetTcpBinding binding = (NetTcpBinding)WcfUtility.CreateTcpClientBinding();&#xA;&#xA;        Client c = new Client(new WcfCommunicationClientFactory&lt;IPreorders&gt;(binding, null, resolver), serviceName, 1);&#xA;&#xA;        try&#xA;        {&#xA;            PreOrder po = await c.Get(""50"", ""11001"", OrderNumber = ""123456"" });&#xA;            Console.WriteLine(""done"");&#xA;        }&#xA;        catch (Exception ex)&#xA;        {&#xA;            Console.WriteLine(ex.ToString());&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After investigation it seems to have something to do with the transaction being used inside the service.</p>&#xA;&#xA;<p>The service never gets past</p>&#xA;&#xA;<pre><code>await tx.CommitAsync();&#xA;</code></pre>&#xA;&#xA;<p>here's the faulting code in the service, nothing special</p>&#xA;&#xA;<pre><code>await preOrders.GetAsync(tx, d, s, (k, v) =&gt; preOrder);&#xA;ServiceEventSource.Current.ServiceMessage(this, ""after update"");&#xA;await tx.CommitAsync();&#xA;ServiceEventSource.Current.ServiceMessage(this, ""after commit"");&#xA;</code></pre>&#xA;"
40556757,Self Hosted MS Service Fabric: Deploying Spring Boot to Windows?,2016-11-11 21:48:25,<azure><spring-boot><microservices><azure-service-fabric><windows2012>,1,324,0,0.0,0,"<p>Keep in mind that I'm completely new to Service Fabric and I'm not really a Windows guru either.</p>&#xA;&#xA;<p>Using Linux based servers is not an option for me, but the documentation does not give instructions on creating a Java application using the windows based installation.</p>&#xA;&#xA;<p>I'll be trying a few things out on my own, but it would be great if someone could point me in the right direction.</p>&#xA;&#xA;<p>Is it possible to deploy Java (Spring Boot) applications to a Windows 2012 R2 based Service Fabric installation on our own internal network? If so, then how?</p>&#xA;"
40784804,Registering with consul servers vs consul clients,2016-11-24 11:06:18,<spring-boot><spring-cloud><microservices><consul>,1,146,0,1.0,0,<p>I am creating a spring boot microservices application with 3 microservices. &#xA;I'm using consul for discovery. I have only a single data centre with 4 hosts.&#xA; <strong>Should I have 3 microservices connecting to 3 consul agents(clients) in their respective localhosts and a consul server running on the remaining one host?</strong>&#xA;It is mentioned that a cluster should have more than one server. Is it applicable in above situation?</p>&#xA;
40685900,Service Fabric: Addressing Service on Stand-Alone Cluster,2016-11-18 21:03:22,<microservices><azure-service-fabric>,1,236,0,0.0,0,"<p>I have set up a three node standalone cluster.  I have placed an application on the cluster that contains three services, the application is configured such that an instance of each service will reside on each node.  Of the three services, one of them is a front-end service that receives requests from external clients and then communicates with the other two services (which are not addressible from outside of the cluster) to get the information needed for the response.  An external client program has been written to communicate with the front-end service via http requests.  Currently, this external client must send its request to a particular service instance using the node ip address and port.  The problem I am having with this approach is that if the node that is being addressed by the external client goes down, the client is no longer able to address the service although the front end service is still running on two other nodes.</p>&#xA;&#xA;<p>Here is my question:  Is there a way for the external client to call the front-end service through Service Fabric without specifying a specific node to communicate with?  My hope is that such a communication method would allow requests to be routed to an alternate node if the original node receiving the request were to go down.</p>&#xA;"
40657733,Reload changes to a shared data base,2016-11-17 14:39:54,<java><spring><spring-boot><datasource><microservices>,1,28,5,0.0,0,"<p>I'm using Spring boot, and I have 2 services which share the same data base. each service has its own data source to communicate with the DB.</p>&#xA;&#xA;<p>My problem is when I apply changes via first data source the changes are not being affected or not being reloaded to the second data source.</p>&#xA;&#xA;<p>My question is how can I reload those changes, so whenever i apply changes to one data source they will be reflected by the second\other data source? </p>&#xA;"
40733857,Using Nginx as micro service API gateway,2016-11-22 04:37:08,<node.js><nginx><docker><kubernetes><microservices>,2,674,7,0.0,0,"<p>We are splitting our monolith API into micro services.</p>&#xA;&#xA;<p>We do not need rate-limiting, auth, caching or any other gateway like abilities. </p>&#xA;&#xA;<p>Would it be a valid approach to use very simple stateless Nginx containers that route to the underlying services?</p>&#xA;"
50785058,Does anyone use websocket instead of gRPC or REST api for intercommunication between microservices?,2018-06-10 15:09:17,<websocket><microservices><grpc>,1,259,0,0.0,0,"<p>Websocket has everything that gRPC does, and is implemented the same way.</p>&#xA;&#xA;<p>So is there any example of such system.</p>&#xA;&#xA;<p>If not why?</p>&#xA;"
50783648,Spring sidecar application failing to discover the Eureka server,2018-06-10 12:24:33,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix>,1,22,0,0.0,0,"<p>In order to integrate non-JVM applications to a microservice-based application, I am using the <code>Spring Boot</code> implmentation of Netflix <code>Sidecar</code> concept. I have looked at several examples and tried to learn from them including the official <a href=""https://cloud.spring.io/spring-cloud-netflix/multi/multi__polyglot_support_with_sidecar.html"" rel=""nofollow noreferrer"">spring documentation</a>. Unfortunately, the sidecar application cannot discover the <code>Eureka</code> server. The following error is thrown after I run the application:</p>&#xA;&#xA;<pre><code>DiscoveryClient_VISITS-SIDECAR/localhost:visits-sidecar:0 - registration failed There is no known eureka server; cluster server list is empty&#xA;</code></pre>&#xA;&#xA;<p>Here the main class of the sidecar application:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableSidecar&#xA;&#xA;public class VisitsSidecarApplication {&#xA;&#xA;public static void main(String[] args) {&#xA;    SpringApplication.run(VisitsSidecarApplication.class, args);&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The necessary dependencies are also included in the <code>pom</code>. I will appreciate any pointers as to where I am getting things wrong.</p>&#xA;"
50771405,How to decouple one backend service associated with a database into two separate services?,2018-06-09 06:05:23,<architecture><microservices><api-design><decoupling><decouple>,2,26,0,0.0,0,"<p>I have a big MySQL database, D_Big, with a bunch of data in it. I also have a service, S1, with APIs that read or write from this database. For example, one API might get something from the database. Another might write a row to the database. etc. </p>&#xA;&#xA;<p>I also have a small, secondary database, D_Small, that S1 (and only S1) is reading and writing to. I want to leave the small secondary database alone, but I want to change the way data is accessed from the big MySQL Database, D_Big.</p>&#xA;&#xA;<p>I want to make it so that the only way to access the big MySQL database is through API calls to a second service, S2, which also has access to the big database. When S1 want the data in D_big, it will have to call the APIs in S2 which will return the data in D_Big. Thus, I want to remove S1's direct dependency on D_Big.</p>&#xA;&#xA;<p>What are some good ways to go about doing that? What are some tips/advice? The most straightforward way seems to be to replace every single API call in S1 that accesses D_Big directly with an API to a corresponding API in S2 that just performs the exact same database access that S1 would have performed directly. For example, imagine that we have these APIs in S1:</p>&#xA;&#xA;<ul>&#xA;<li><p>API_1 returns columns [foo, bar, baz] from table1 in D_Big</p></li>&#xA;<li><p>API_2 writes value foo to table2 in D_Big</p></li>&#xA;<li><p>API_3 returns columns * from table3 in D_Big</p></li>&#xA;</ul>&#xA;&#xA;<p>I would just replace these with:</p>&#xA;&#xA;<ul>&#xA;<li><p>API_1 in S1 calls corresponding API in S2 which returns columns [foo, bar, baz] from table1 in D_Big</p></li>&#xA;<li><p>API_2 in S1 calls corresponding API in S2 which API_2 writes value foo to table2 in D_Big</p></li>&#xA;<li><p>API_3 in S1 calls corresponding API in S2 which API_3 returns columns * from table3 in D_Big</p></li>&#xA;</ul>&#xA;&#xA;<p>But what about cases where the ideal mapping isn't one to one? Like when you should combine APIs (ex. one API in S1 calls two different APIs in S2 to get the data it needs or two different APIs in S1 call the same API in S2 but with different parameters)? </p>&#xA;&#xA;<p>How do you make a good interface decoupling two services from what used to be a shared data source (D_Big)? Assume that both S1 and S2 use a Java/XML/Spring based system to transfer data over API calls.</p>&#xA;"
50891973,Shutdown a Service outside of Spring Boot,2018-06-16 21:39:57,<spring-boot><service><microservices><service-discovery><eureka>,1,32,0,0.0,0,"<p>I'm writing some simple Microservices to understand the way Netflix Eureka works.<br> &#xA;I was wondering if there is a general possibility of programmatically shutting down a Service in Java, with immediate deregistration from the Eureka Service Registry as a result. <br>I found out the solution with the Spring Boot actuator endpoint (with a POST request to <code>service-URL/actuator/shutdown</code>). <br>&#xA;How can the same result be reached in the case I wanted to shutdown a Service that is not Spring Boot based? </p>&#xA;"
50718353,Is there a way to get request and response body of a http request for a microservices application?,2018-06-06 10:40:29,<node.js><microservices><trace>,1,38,0,0.0,0,<p>I have an application consisting of 2 microservices. </p>&#xA;&#xA;<p>Is there a way I can get the request and response for each request received and sent by each of the microservice with minimal changes in code.</p>&#xA;&#xA;<p>The application is in node.js. </p>&#xA;&#xA;<p>I have tried some tracing frameworks but they only provide the timing information. </p>&#xA;
50800231,GraphQL: Provide more context to resolver from resolved stitched request,2018-06-11 14:34:55,<graphql><microservices>,1,49,0,0.0,0,"<p>I'm running a couple microservices where each one as a graphQL layer that's being stitched together in another exposed service.&#xA;I'm trying at all costs to avoid direct communication between services but now I need some information to be passed into one service, that only exists in another service.</p>&#xA;&#xA;<p>Does anyone know how to basically resolve some values from other service before proceeding with the request? These values shouldn't be exposed, but sent as arguments or some kind of context over to the service.</p>&#xA;&#xA;<p>Summing up:</p>&#xA;&#xA;<p><strong>Exposed Service</strong> stitching from <strong>Service 1</strong> and <strong>Service 2</strong>.</p>&#xA;&#xA;<p><strong>Service 1</strong> needs property from <strong>Service 2</strong> but <strong>can't communicate directly</strong>.</p>&#xA;&#xA;<p>Way from <strong>Exposed Service</strong> to resolve from <strong>Service 2</strong> and inject into <strong>Service 1</strong>.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
50772902,How to break into Microservices,2018-06-09 09:41:14,<microservices>,1,50,0,0.0,0,"<p>I am working on an application to create assessments for students. I want to use a microservices for this. However, I'm confused if Assessments and Questions go into the same micro service or should I split them. Every assessment contains a list of questions. But I feel that they come under the same domain and should come under the same micro service. Can some one help me decide. </p>&#xA;"
50873541,"Should I use JSend for wrapping json ajax responses, or is there a more standard standard?",2018-06-15 10:15:52,<json><microservices><jsend>,1,57,0,0.0,0,"<p>I'm setting up a json-over-http service. The responses should have some meta-data, primarily for success/failure. That could be done via http headers, but putting it in the json is nicer (it makes the meta-data available even if some higher-up part of the client code has consumed the http response object). </p>&#xA;&#xA;<p>Is there an emerging standard for this? </p>&#xA;&#xA;<p>I'm aware of JSend, but it doesn't seem to have widepsread adoption.</p>&#xA;&#xA;<p>JSend, in a nutshell, is: </p>&#xA;&#xA;<pre><code>{&#xA;status: ""success""|""fail""|""error"", &#xA;message: String, // optional error message &#xA;data: any, // the ajax payload&#xA;code: Number // optional numeric code for errors&#xA;}&#xA;</code></pre>&#xA;"
50841501,using apache kafka with spring cloud netflix stack,2018-06-13 15:55:01,<apache-kafka><microservices><netflix-zuul><netflix-eureka><netflix>,1,92,0,0.0,0,"<p>Currently I am using spring cloud Netflix stack for development of my microservices based application. where I have used different services provided by Netflix stack like</p>&#xA;&#xA;<pre><code>EUREKA : for service registration and discovery&#xA;ZUUL : for proxy gateway and&#xA;RIBBON : for load balancing&#xA;</code></pre>&#xA;&#xA;<p>now we want to use Apache kafka for inter-communication between microservices where kafka will have different topics to which our microservices will subscribe,&#xA;now real problem starts here is how the load balancing, proxy gateway and eureka will work here. </p>&#xA;&#xA;<pre><code>few questions I have in mind which are really confusing me are&#xA;1. how ribbon load balancing will work here, since while using HTTP we are using @loadbalanced restTemplate but now this will not be the case.&#xA;2. how service calls will be distributed among different instances of a same service&#xA;3. whether Zuul and Eureka are needed here or we just need to ignore these and go with kafka load balancing and service discovery through topics.&#xA;</code></pre>&#xA;&#xA;<p>I gooled but not found any satisfying answer if any expert here can help me  will be appreciated, if there is any similar questions that can also help.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
50816609,How to add a custom undertow HttpHandler to thorntail (fka. wildfly swarm),2018-06-12 11:56:37,<java><microservices><undertow><wildfly-swarm>,1,96,0,0.0,0,"<p>I started using thorntail V4 (www.thorntail.io) (formerly known as wildfly swarm) to create microservices. Yes i know the website states it as ""proof of concept"". Thorntail ships with undertow (www.undertow.io). </p>&#xA;&#xA;<p>Does anyone know, how to add or register a custom undertow HttpHandler?</p>&#xA;&#xA;<p>How do i get the next HttpHandler in the chain for calling it in handleRequest()?</p>&#xA;&#xA;<p>My current HttpHandler looks like this:</p>&#xA;&#xA;<pre><code>import io.undertow.server.HttpHandler;&#xA;import io.undertow.server.HttpServerExchange;&#xA;&#xA;import javax.enterprise.context.ApplicationScoped;&#xA;import javax.inject.Inject;&#xA;&#xA;@ApplicationScoped&#xA;public class MyCustomHttpHandler implements HttpHandler {&#xA;&#xA;    @Inject&#xA;    private HttpHandler next; // how do i get the next HttpHandler?&#xA;&#xA;    public MyCustomHttpHandler() {&#xA;      System.out.println(""MyCustomHttpHandler.java constructed""); // never gets called. How do i register it in Thorntail?&#xA;    }&#xA;&#xA;    @Override&#xA;    public void handleRequest(HttpServerExchange httpServerExchange) throws Exception {&#xA;      // never gets called :/&#xA;      System.out.println(String.format(""HttpHandler next=%s"", next));&#xA;&#xA;      // How do i get next? Is @Inject the way to go?&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;&#xA;<p>Btw. can someone add a ""thorntail"" tag? My StackOverflow-Rep doesn't allow this.</p>&#xA;"
50902528,Microservices: How the databases organized behind the microservice,2018-06-18 04:02:29,<database><cloud><microservices>,1,34,1,1.0,0,"<p>This is my first time reading about the microservices. Knowing that services is a subdivide system from a whole system which specialize in different domains. What about the data. I assumed all services using tradition db to store their data and data are stored distributed in different domain. What if there are data can belong in both of these domain services, what should I do with them.</p>&#xA;&#xA;<p>E.g. A basket service (handling user shopping cart), and Payment service (handling payment of their order they have placed in the basket).</p>&#xA;&#xA;<p>Maybe this isn't a great example, where do the product information to be stored. </p>&#xA;&#xA;<p>In monolithic application, we have single database which stored the whole business data where each data will have reference to each other. </p>&#xA;"
50725904,Minikube Kubernetes: two pods and service,2018-06-06 17:08:06,<kubernetes><microservices><minikube>,2,49,1,0.0,0,"<p>I'm running a simple spring microservice project with Minikube. I have two projects: lucky-word-client (on port 8080) and lucky-word-server (on port 8888). But I can't communicate client with server. Infact if lucky-word-client communicates with lucky-word-server, the result is the word ""Evviva"", else the word is ""Default"". When I run on terminal: minikube service lucky-client the output is Default, instead of Evviva. I want communicate client with server through DNS. I saw the guide: <a href=""https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a> but without success. How i can modify the service or pods to have the link between client and server?</p>&#xA;&#xA;<p>This is the pod of lucky-word-client:</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Pod&#xA;metadata:&#xA;  name: lucky-client&#xA;  namespace: default&#xA;spec:&#xA;  containers:&#xA;  - image: lucky-client-img&#xA;    imagePullPolicy: IfNotPresent&#xA;    name: lucky-client&#xA;</code></pre>&#xA;&#xA;<p>This is the pod of lucky-word-server:</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Pod&#xA;metadata:&#xA;  name: lucky-server&#xA;  namespace: default&#xA;spec:&#xA;  containers:&#xA;  - image: lucky-server-img&#xA;    imagePullPolicy: IfNotPresent&#xA;    name: lucky-server&#xA;</code></pre>&#xA;&#xA;<p>This is the service, where the lucky-word-client communicate with lucky-word-server:</p>&#xA;&#xA;<pre><code>kind: Service&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: lucky-client&#xA;spec:&#xA;  selector:&#xA;    app: lucky-client&#xA;  ports:&#xA;  - protocol: TCP&#xA;    targetPort: 8080&#xA;    port: 80&#xA;  type: NodePort&#xA;</code></pre>&#xA;"
50876475,JHipster microservice gateway temporarily throws HTTP 500 error when one service instance is terminating,2018-06-15 13:19:25,<microservices><jhipster><gateway><service-discovery>,1,104,1,0.0,0,"<p>We have a standard JHipster setup consisting of a gateway and one microservice application. JHipster-Registry is used for service discovery. We made no changes of any kind to the code or the config that was generated by the JHipster generator.</p>&#xA;&#xA;<p>Everything works as expected. However, when shutting down one of the microservice application instances (SIGINT, ^C on CLI, Kubernetes pod termination), we temporarily receive HTTP 500 internal server errors for requests to microservice endpoints through the gateway (<a href=""http://gateway/service/.."" rel=""nofollow noreferrer"">http://gateway/service/..</a>.).</p>&#xA;&#xA;<p>Please find below a stacktrace from the HTTP 500 error in the gateway:</p>&#xA;&#xA;<pre><code>Caused by: org.apache.http.NoHttpResponseException: 172.16.94.61:8085 failed to respond&#xA;    at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:141)&#xA;    at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)&#xA;    at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)&#xA;    at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)&#xA;    at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:165)&#xA;    at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)&#xA;    at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)&#xA;    at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)&#xA;    at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)&#xA;    at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)&#xA;    at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)&#xA;    at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)&#xA;    at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)&#xA;    at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)&#xA;    at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)&#xA;    at org.springframework.cloud.netflix.ribbon.apache.RetryableRibbonLoadBalancingHttpClient$1.doWithRetry(RetryableRibbonLoadBalancingHttpClient.java:93)&#xA;    at org.springframework.cloud.netflix.ribbon.apache.RetryableRibbonLoadBalancingHttpClient$1.doWithRetry(RetryableRibbonLoadBalancingHttpClient.java:71)&#xA;    at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287)&#xA;    at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:164)&#xA;    at org.springframework.cloud.netflix.ribbon.apache.RetryableRibbonLoadBalancingHttpClient.executeWithRetry(RetryableRibbonLoadBalancingHttpClient.java:113)&#xA;    at org.springframework.cloud.netflix.ribbon.apache.RetryableRibbonLoadBalancingHttpClient.execute(RetryableRibbonLoadBalancingHttpClient.java:104)&#xA;    at org.springframework.cloud.netflix.ribbon.apache.RetryableRibbonLoadBalancingHttpClient.execute(RetryableRibbonLoadBalancingHttpClient.java:50)&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:109)&#xA;    at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303)&#xA;    at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287)&#xA;    at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231)&#xA;    at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228)&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:10211)&#xA;    at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286)&#xA;    at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144)&#xA;    at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185)&#xA;    at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180)&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:10211)&#xA;    at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94)&#xA;    at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)&#xA;    at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)&#xA;    at rx.Observable.subscribe(Observable.java:10307)&#xA;    at rx.Observable.subscribe(Observable.java:10274)&#xA;    at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:445)&#xA;</code></pre>&#xA;&#xA;<p>It looks like the gateway's load balancer still uses the microservice instance which is terminating. </p>&#xA;&#xA;<p>We also tried Consul instead of JHipster-Registry/Eureka and found the same behaviour.</p>&#xA;&#xA;<p>Steps to reproduce:</p>&#xA;&#xA;<ul>&#xA;<li>Start one registry, one gateway and two microservice instances (using gradlew)</li>&#xA;<li>Wait and verify that everything is up and running (call <a href=""http://gateway/service/.."" rel=""nofollow noreferrer"">http://gateway/service/..</a>.)</li>&#xA;<li>Terminate one microservice instance</li>&#xA;<li>Relaod <a href=""http://gateway/service/"" rel=""nofollow noreferrer"">http://gateway/service/</a>... for a couple of times&#xA;&#xA;<ul>&#xA;<li>After a few seconds HTTP 500 errors will occur</li>&#xA;<li>After a few more seconds errors will disappear and the remaining microservice receives all traffic</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>Since we are using an out-of-the-box JHipster setup, we were pretty confused by not finding any articles addressing this issue on the Internet.</p>&#xA;&#xA;<p>Does anybody experience the same problem, have an idea what's wrong here or how to solve this problem? We tried pretty long to find the cause and a solution but we feel like we are stuck here.</p>&#xA;&#xA;<p>If you need more information (logs, configs, traces, etc.) we will be happy to post it here.</p>&#xA;"
50828793,Getting connection timed out error in microservice,2018-06-13 03:45:25,<spring-boot><postman><microservices>,1,104,2,0.0,0,"<p>I have built a microservice using <code>Java 8</code> and <code>SpringBoot 2</code>. From this microservice, I'm trying to consume another REST API service. However, I'm getting the following error on <code>Chrome</code>. I have already disabled the windows firewall and McAfee antivirus firewall but still getting the same error. I can call the REST API directly using the Postman tool but not through my microservice.</p>&#xA;&#xA;<p><strong>Error:-</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: The underlying HTTP client completed&#xA;  without emitting a response.</p>&#xA;  &#xA;  <p>2018-06-12 15:21:29.300 ERROR 17996 --- [ctor-http-nio-3]&#xA;  .a.w.r.e.DefaultErrorWebExceptionHandler : Failed to handle request&#xA;  [GET <a href=""http://localhost:8080/category/search]"" rel=""nofollow noreferrer"">http://localhost:8080/category/search]</a>&#xA;  io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection&#xA;  timed out: no further information: test.usdemo.xyz.com/92.54.41.24:443&#xA;  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&#xA;  ~[na:1.8.0_171] at&#xA;  sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)&#xA;  ~[na:1.8.0_171] at&#xA;  io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:325)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final] at&#xA;  io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)&#xA;  ~[netty-common-4.1.24.Final.jar:4.1.24.Final] at&#xA;  java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_171] Caused by:&#xA;  java.net.ConnectException: Connection timed out: no further&#xA;  information ... 10 common frames omitted</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Controller class:-</strong></p>&#xA;&#xA;<pre><code>@RestController&#xA;public class CategorySearchController {&#xA;&#xA;    private final CategorySearchService categorySearchService;&#xA;&#xA;    @Autowired&#xA;    public CategorySearchController(CategorySearchService categorySearchService) {&#xA;        this.categorySearchService = categorySearchService;&#xA;    }&#xA;&#xA;&#xA;    @GetMapping(path = ""/search-category"")&#xA;    public Mono&lt;CategoryResponse&gt; searchCategories(SearchRequest categorySearchRequest){&#xA;        return categorySearchService&#xA;                .searchCategories()&#xA;                .switchIfEmpty(Mono.error(&#xA;                        new EntityNotFoundException(""No category matching "" + categorySearchRequest.getSearchTerm() + "" was found"")));&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Service class:-</strong></p>&#xA;&#xA;<pre><code>@Service&#xA;public class CategorySearchServiceImpl implements CategorySearchService {&#xA;    private String baseUrl = ""https://demo0954903.mockable.io"";&#xA;&#xA;    @Override&#xA;    public Mono&lt;CategoryResponse&gt; searchCategories() {&#xA;        WebClient webClient = WebClient.create(baseUrl);&#xA;        return webClient.&#xA;                 get()&#xA;                .uri(""/category-search"")&#xA;                .retrieve()&#xA;                .bodyToMono(CategoryResponse.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
50845313,Cron Job Microservices,2018-06-13 19:59:50,<cron><microservices><cron-task><spring-cloud-dataflow><spring-cloud-task>,1,154,2,0.0,0,"<p>I am using spring cloud and have various microservices for an online shopping vendor. Everything is working as expected.</p>&#xA;&#xA;<p>But, I got a requirement where I need to run a <strong>cron job over customer's records</strong>, get the customer's who's statement date matches the current date and calculate the rate of interest to be paid. This needs to be run every day.</p>&#xA;&#xA;<p>I am confused about how to accommodate this cron job with MS architecture. Do I need to have another server having just this cron job?</p>&#xA;"
50790960,Seperation of Concerns - How to separate GET/PUT/PATCH/POST/DELETE/ETC into one Microservice that gets its models and DTOs externally,2018-06-11 05:26:36,<c#><rest><.net-core><microservices><separation-of-concerns>,1,56,3,0.0,0,"<p>Lets say you have a typical C# .netcore webapi you are wanting to use in a microservices architecture environment. It uses entity framework connects to a SQL database, has models and DTOs.</p>&#xA;&#xA;<p>If you want to separate the 'restfulness', the actions of actually responding to the individual GET/PUT/PATCH/POST/DELETE/ETC methods, from the data models (and into microservices) what approach would you take? </p>&#xA;&#xA;<p>IE instead of having to create 100 microservices that each expose the same exact RESTful functionality within the APIs but each have their own specific data models and DTOs, id want to create 1 API that exposes restful GET/PUT/PATCH/POST/DELETE/ETC and separate it from static models, dtos and entitybuilder configurations.  So i'd have 100 microservices concerned with passing data to the 1 REST microservice to get whatever job I need to do done in a dynamic fashion.</p>&#xA;&#xA;<p>I am not super experienced with object oriented programming methods and I thought maybe it would be possible to have my CRUD microservice that my child microservice talks to (through an API gateway or some other method that I haven't worked out yet) pass a set of models, DTOs and entity framework entitybuilder parameters into the CRUD microservices Program.cs's Main method? </p>&#xA;&#xA;<p>I am on the right path here? </p>&#xA;&#xA;<p>Thank you in advance for any advise or helpful examples!!!</p>&#xA;"
50810342,Spring Java Microservice war size is too large,2018-06-12 06:16:18,<java><spring><microservices>,1,59,3,0.0,0,"<p>Every time when we release on our production server, we need to copy 3-4 war(microservice war) file of size approx 150-200 MB. Even though we simply change a small thing in our code, but all maven dependency are combined to the war so the file size is very big.  </p>&#xA;&#xA;<p>Is there any way to reduce the size of war or how can we simply deploy our code not all the dependency with them?</p>&#xA;"
50814965,Getting connection timed out error in Java microservice,2018-06-12 10:29:31,<spring><spring-boot><postman><microservices>,2,119,5,1.0,0,"<p>I have built a microservice using Java 8 and SpringBoot 2. From this microservice, I'm trying to consume another REST API service. However, I'm getting the following error on Chrome</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: The underlying HTTP client completed&#xA;  without emitting a response.</p>&#xA;  &#xA;  <p>2018-06-12 15:21:29.300 ERROR 17996 --- [ctor-http-nio-3]&#xA;  .a.w.r.e.DefaultErrorWebExceptionHandler : Failed to handle request&#xA;  [GET <a href=""http://localhost:8080/category/search]"" rel=""nofollow noreferrer"">http://localhost:8080/category/search]</a>&#xA;  io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection&#xA;  timed out: no further information: test.usdemo.xyz.com/92.54.41.24:443&#xA;                  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.8.0_171]&#xA;                  at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)&#xA;  ~[na:1.8.0_171]&#xA;                  at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:325)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)&#xA;  ~[netty-common-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_171] Caused by: java.net.ConnectException: Connection timed&#xA;  out: no further information&#xA;                  ... 10 common frames omitted</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm able to consume the same service successfully using PostMan but not through my microservice.</p>&#xA;&#xA;<p>Please assist to advise on this.</p>&#xA;"
48549944,Using Google Cloud Functions API as Service Discovery,2018-01-31 19:24:14,<google-cloud-platform><microservices><google-cloud-functions>,2,267,0,0.0,0,"<p>We're working on developing a microservice based architecture employing Google Cloud Functions. </p>&#xA;&#xA;<p>We've developed a few functions and want to implement a discovery service.  This discovery service would be used to determine if a specific function exists and is operational. </p>&#xA;&#xA;<p>The service discovery itself is a cloud function.  It makes a rest request to the below API and succeeds in local development using functions emulator and the default application credentials.  </p>&#xA;&#xA;<p>Google provides an API for this [<a href=""https://cloud.google.com/functions/docs/reference/rest/v1beta2/projects.locations.functions/get][1]"" rel=""nofollow noreferrer"">https://cloud.google.com/functions/docs/reference/rest/v1beta2/projects.locations.functions/get][1]</a></p>&#xA;&#xA;<p>When deployed to production we're receiving:&#xA;{ ""code"": 401, ""message"": ""Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See <a href=""https://developers.google.com/identity/sign-in/web/devconsole-project"" rel=""nofollow noreferrer"">https://developers.google.com/identity/sign-in/web/devconsole-project</a>."", ""status"": ""UNAUTHENTICATED"" } }</p>&#xA;&#xA;<p>Cloud functions are stateless so there's no option to use a service account that I can see.  How do I go about authenticating a cloud function to call the functions api to determine if a function is available? </p>&#xA;&#xA;<p>Below is how we've accomplished this in a local dev environment:</p>&#xA;&#xA;<pre><code>var options = {&#xA;    method: 'get',&#xA;    uri: `https://cloudfunctions.googleapis.com/v1beta2/projects/${config.PROJECT_ID}/locations/${config.LOCATION_ID}/functions/${functionName}`&#xA;  }&#xA;&#xA;  console.log (options.uri);&#xA;  request(options, function (err, res, body) {&#xA;    if (!err &amp;&amp; res.status === 200) {&#xA;      if(typeof res.body.httpsTrigger.url !== undefined) {&#xA;        console.log('found a function');&#xA;        return cb(false, res.body.httpsTrigger.url);&#xA;      }&#xA;      else {&#xA;        console.log('no function found, looking for static content');&#xA;        return cb(true, `Service doesn't exist, returned ${res.status}`)&#xA;      }&#xA;    }&#xA;    else {&#xA;      console.log('no function found, looking for static content'); &#xA;      return cb(true, `Service doesn't exist, returned ${res.status}`);&#xA;    }&#xA;  });&#xA;</code></pre>&#xA;"
48479325,Enable CORS on API Gateway + Lambda Microservice template + DynamoDB,2018-01-27 18:50:00,<cors><aws-lambda><microservices><api-gateway>,1,48,0,0.0,0,"<p>I already enable CORS resource in the API Gateway, but it doesn't work</p>&#xA;"
48473966,Authentication/Authorization mechanism for microservices,2018-01-27 08:21:12,<authentication><authorization><microservices>,2,707,0,0.0,0,<p>I have project with many micro services each one doing its job. One of them responsible for authentication and authorization. But its not clear how other services should check users permissions. Is there any mechanism to deal with this task?</p>&#xA;
48437842,What are the advantages of Mountebank over Rest Assured?,2018-01-25 07:40:02,<testing><microservices><rest-assured><mountebank>,1,268,1,0.0,0,"<p>I'm started reading the Mountebank framework for our project which uses Microservices. Based on my learning on few days, Mountebank is mainly based on testing micro services using a concept of service virtualization.</p>&#xA;&#xA;<p>To test the Rest APIs we can use Rest Assured.</p>&#xA;&#xA;<p>I want to take seminar about the framework and I need an answer for the question why don't we use Rest Assured, even in RestAssured, we can use mock? so what are the major differences and similarities between Mountebank and Rest Assured? </p>&#xA;&#xA;<p>I'm not sure whether it is valid to compare Mountebank and RestAssured.</p>&#xA;"
48487563,Is there a way to upgrade and maintain dependencies programmatically for all Spring boot projects in a microservice architecture?,2018-01-28 14:44:49,<maven><spring-boot><microservices><project-structure>,1,31,1,0.0,0,"<p>In a Spring boot microservice architecture you have many project folders each representing each service. I'd assume you have mult-module maven project with all services each having their own subdirectory in a parent folder, each having their own maven dependencies.</p>&#xA;&#xA;<p>For maintainability and to keep all services updated with the latest dependencies how would you for example upgrade to the latest Spring BOM or upgrade a third party library like Apache commons for all services?</p>&#xA;"
48464383,Why should i mix repo level objects with controller/service level objects?,2018-01-26 15:27:08,<java><spring-mvc><spring-data-jpa><microservices><spring-data-mongodb>,2,33,2,0.0,0,"<p>I worked on many microservices, and saw we dont mix repo level objects(mogo document, entity) with service/controller level request/response. I wanted to know more about it ?&#xA;1. We dont want pojo and entity/document to behave in same way?(Could be one reason)&#xA;Please help me understanding reasons behind doing this.</p>&#xA;"
48441868,linking Microservices and allowing for one to be unavailable,2018-01-25 11:32:30,<microservices>,1,40,2,1.0,0,"<p>I'm new to the microservices architecture and am seeing that it is possible under the model to call a microservice from another via HTTP request. However, I am reading that if a service is down all other services should still operate.&#xA;My question is, how is this generally achieved?</p>&#xA;&#xA;<p>Example, a microservice that handles all Car record manipulation may need access to the service which handles the Vehicle data. How can the Car Microservice complete it's operations if that service is down or doesn't respond?</p>&#xA;"
48457264,Integrating SignalR for microservice with API Gateway,2018-01-26 07:31:45,<architecture><signalr><microservices><asp.net-core-signalr>,1,630,2,0.0,0,"<p>I'm designing a microservice system based on .Net core. The architecture system will look like as the following picture.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eIee4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eIee4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The problem is: There is a requirement which have to integrate SignalR (real-time) for notification&#xA;I've read about SignalR on Microsoft's website. But I consider that where should I put the Hub (API Gateway?, microservice? ...)? How can I apply signalR for this system.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48406730,How to deploy Envoy EDS/SDS,2018-01-23 16:38:03,<microservices><envoyproxy>,1,145,2,0.0,0,"<p>This is a micro services deployment question. How would you deploy <a href=""https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/service_discovery#service-discovery-service-sds"" rel=""nofollow noreferrer"">Envoy SDS</a>(service discovery service) so other envoy proxies can find the SDS server hosts, in order to discover other services to build the service mesh. Should I put it behind a load balancer with a DNS name( single point of failure) or just run the SDS locally in every machine so other micro services can access it? Or is there a better way of deployment that SDS cluster can be dynamically added into envoy config without a single point of failure?</p>&#xA;"
48440783,Is it possible to have 2 different services with the same application name?,2018-01-25 10:35:36,<spring><microservices><netflix-eureka><netflix-zuul>,1,40,3,0.0,0,"<p>Let's say I have a service named ""FooService"" running in a docker container and a second service named ""BarService"" running in a second docker container. Both services register with Eureka (running in another docker container). Is it possible to have the same application name for both services? E.g. <a href=""http://localhost/myservice/foo"" rel=""nofollow noreferrer"">http://localhost/myservice/foo</a> should call the FooService and <a href=""http://localhost/myservice/bar"" rel=""nofollow noreferrer"">http://localhost/myservice/bar</a> should call the BarService. Development environment is Spring Boot and the services are implemented as Spring RestControllers. Just put ""spring.application.name=myservice"" in both bootstrap.properties files and then put @RequestMapping(""${spring.application.name}"") in the RestController will not work, of course. But is it somehow possible to register the services with a unique identifier and still call them with a common URL path?</p>&#xA;"
48604664,How to share database connection between in spring cloud,2018-02-04 04:20:22,<spring><microservices>,3,389,3,0.0,0,<p>How can I share database connection aong in spring cloud module microservices. If there are many microservices how can i use same db connection or should i use db connection per microservices?</p>&#xA;
48493849,Should API and message consumer be in the same microservice?,2018-01-29 03:11:48,<apache-kafka><microservices><distributed-system>,1,96,4,1.0,0,"<p>My team is torn with how we should architect our microservices with using a message bus.</p>&#xA;&#xA;<p>We currently have an API Gateway with many microservices behind it all communicating over http.</p>&#xA;&#xA;<p>After looking into implementing Message Buses (Kafka) the team is torn on whether the consumer and API should live in the same service or if they should be two separate services.</p>&#xA;&#xA;<p>Some think they should be separate as they have different scaling concerns, while others think they should be in the same service since they are communicating with the same database and have the same domain concerns. IE) Not duplicating code between two services.</p>&#xA;&#xA;<p>What are your thoughts?</p>&#xA;"
37617556,Optimized http service invocation with in azure service fabric,2016-06-03 14:53:21,<azure><endpoint><microservices><azure-service-fabric><stateless>,1,257,0,0.0,0,"<p>I have 2 applications (A1 and A2) hosted in azure service fabric, each application with its own stateless reliable micro-service (S1 and S2). The app A1 depends on S1 and app A2 depends on S2. In addition, S2 service depends on S1. Both S2 and S1 are owin hosted REST api services. When the request for A2 ends up in S2, I need to make a call from S2 to S1. I am trying to figure out the optimized way of doing this.</p>&#xA;&#xA;<p>1) Should I use HttpClient in S2 to call S1? How do I get the resolution for S1 in side of S2? Is it just published uri for S1 and fabric will know how to optimize those calls?&#xA;2) Should I implement 2 listeners in S1 (one http endpoint for A1 clients and one service remoting endpoint with an interface to call from S2)? Again how does address resolution work?</p>&#xA;&#xA;<p>In either case, short code samples would be of immense help.</p>&#xA;&#xA;<p>Thanks.&#xA;Raghu/.. </p>&#xA;"
37684678,"Integration Tests with Microservices (NodeJS), Jenkins and Docker",2016-06-07 16:31:18,<node.js><git><jenkins><docker><microservices>,1,599,0,0.0,0,"<p>How would you typically configure Jenkins to build microservices (multiple NodeJS services, Rabbit, Mongo, etc), then test those services all together ?</p>&#xA;&#xA;<p>Let's say I've the following services:</p>&#xA;&#xA;<ul>&#xA;<li>RabbitMQ</li>&#xA;<li>Mongo</li>&#xA;<li>NodeJS Service 1</li>&#xA;<li>NodeJS Service 2</li>&#xA;</ul>&#xA;&#xA;<p>Each of them has their own tests (unit and integration) and their Dockerfile.</p>&#xA;&#xA;<p>I want to configure Jenkins in a way that it would enable me to clone all theses services, run them all at the same time in different containers with Rabbit and Mongo containers along them. It would then run the tests for each of those services (they do generate TAP and coverage reports). Then take those reports for the TAP/Coverage Jenkins plugins. If it works out, commit the image and push it to the docker registry.</p>&#xA;&#xA;<p>I've been lying around Stack and Google and I don't really see an easy way to get there that would not imply tons of bash.</p>&#xA;&#xA;<p>Maybe I see it in the wrong way, any input is more than welcome!</p>&#xA;"
37750547,"Dropwizard Liquibase, run db migrate.xml file, which is inside of jar",2016-06-10 14:16:50,<mysql><jar><liquibase><dropwizard><microservices>,1,355,0,0.0,0,"<p>I need run my dropwizard jar in the linux server.&#xA;Configuration files inside of jar. When I am using maven in my dev, all ok.&#xA;I have problem for both:liquibase  and dropwizard configuration files.&#xA;For dropwizard when I put config outside of jar</p>&#xA;&#xA;<pre><code>java -jar myapp.jar server config.yml&#xA;</code></pre>&#xA;&#xA;<p>it is ok, app. strated, but does not executed  liquibase migration, which configs I have in pom.xml</p>&#xA;&#xA;<pre><code> &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.liquibase&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;liquibase-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;3.5.0&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;changeLogFile&gt;&#xA;                        ${basedir}/src/main/resources/migrations.xml&#xA;                    &lt;/changeLogFile&gt;&#xA;                    &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt;&#xA;                    &lt;url&gt;jdbc:mysql://localhost:3306/twitterdb&lt;/url&gt;&#xA;                    &lt;username&gt;root&lt;/username&gt;&#xA;                    &lt;password&gt;root&lt;/password&gt;&#xA;                &lt;/configuration&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;phase&gt;process-resources&lt;/phase&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;update&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;</code></pre>&#xA;&#xA;<p>I downloaded liquibase, extracted, set liquibase home as ENV.</p>&#xA;&#xA;<p>now I try to run </p>&#xA;&#xA;<pre><code>java -jar liquibase/liquibase.jar --driver=com.mysql.jdbc.Driver --changeLogFile=migratedb.xml --url=""jdbc:mysql://localhost:3306/twitterDB"" --username=root --password=root update .&#xA;</code></pre>&#xA;&#xA;<p>but in this case liquibase did not find mysql driver.</p>&#xA;&#xA;<p>Basically I want start project using configs files which is inside of jar.</p>&#xA;&#xA;<p>Any suggestions?</p>&#xA;"
37750638,Clustering Microservice Components,2016-06-10 14:21:41,<cluster-computing><microservices><failover>,1,191,0,0.0,0,"<p>We have a set of Microservices collaborating with each other in the eco system. We used to have occasional problems where one or more of these Microservices would go down accidentally. Thankfully, we have some monitoring built around which would realize this and take corrective action.</p>&#xA;&#xA;<p>Now, we would like to have redundancy built around each of those Microservices. I'm thinking more like a master / slave approach where a slave is always on stand by and when the master goes off, the slave picks it up.</p>&#xA;&#xA;<p>Should we consider using any framework that we could use as service registry, where we register each of those Microservices and allow them to be controlled? Any other suggestions on how to achieve the kind of master / slave architecture with the Microservices that would enable us to have failover redundancy?</p>&#xA;"
37715757,Trade-offs of microservices and modularity architectural design?,2016-06-09 02:09:10,<design><osgi><polymorphic-associations><microservices><modularity>,1,124,3,0.0,0,"<p><a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow"">Microservices</a> and <a href=""https://en.wikipedia.org/wiki/Modular_programming"" rel=""nofollow"">Modular Programming</a> has proved to be a proper choice when design a software system. Benefits of it includes reusability, distributability, readability, etc.</p>&#xA;&#xA;<p>We are a MOOC site using OSGI as modularity implementation:</p>&#xA;&#xA;<ul>&#xA;<li>Each feature have its own database, service, and standalone web application</li>&#xA;<li>Direct access to database of other feature is prohibited</li>&#xA;</ul>&#xA;&#xA;<p>Take 3 features as a example:</p>&#xA;&#xA;<pre><code>     course               project         Q&amp;A(question&amp;answer)&#xA;&#xA;+---------------+    +---------------+    +---------------+&#xA;|     web       |    |     web       |    |     web       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     service   |    |     service   |    |     service   |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     dao       |    |     dao       |    |     dao       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     Database  |    |     Database  |    |     Database  |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;</code></pre>&#xA;&#xA;<p>Requirements:</p>&#xA;&#xA;<ol>&#xA;<li>Every course/project has Q&amp;A module, user that participated-in can ask question about this course/project here.</li>&#xA;<li>A standalone global(or common) Q&amp;A entry, listing questions that aggregated from all courses/projects, and user can ask context-independent(aka, not related to any course/project) question here.</li>&#xA;</ol>&#xA;&#xA;<p>I do not know if this design or architecture(<strong>completely isolation from top to bottom of every feature</strong>) is good or not, but I'm facing some inconveniences indeed:</p>&#xA;&#xA;<ol>&#xA;<li><p>modular web application</p>&#xA;&#xA;<p>Q&amp;A feature is either a standalone feature and part of course/project.  Currently I'm think both embed Q&amp;A module as web component of standalone course-webapp/project-webapp, and standalone qa-webapp itself, but I have no idea what's the best way to reuse controllers to avoid duplicated code on web layer</p></li>&#xA;<li><p>rational database <a href=""https://en.wikipedia.org/wiki/Polymorphic_association"" rel=""nofollow"">Polymorphic Association</a> problem</p>&#xA;&#xA;<p>A question maybe belong to course/project, or context-independent, and id of course/project came from another database, polymorphic association is inevitable. Currently I'm using a extra column post_to_type on table question to tackle with this.</p></li>&#xA;<li><p>Let me say course/project can be private or public. questions listed under global Q&amp;A entry only include questions that belong to public course/project, not private. But again, since each feature have its own database and direct access to database of other feature is prohibited, I do not have any idea what's the elegant and efficient way to deal with this.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is something wrong with our modular design when using OSGI, or its just me thinking so uncomfortable with this? and what's the best practices to design a microservices / modular architecture, specifically in object-oriented language like Java?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
46657234,Micro services multiple response from same controller,2017-10-10 01:14:56,<multithreading><microservices>,1,20,0,0.0,0,<p>Iam using micro services in my project I need to call Twp different URL or endpoint from my controller at same time and based on these two responses I will create a third response and send that third response back to controller now my doubt is simultaneously can we call two different URL from controller ??????in springboot application if yes what I need to use </p>&#xA;
46583498,How to create image and push image to docker hub,2017-10-05 10:31:55,<asp.net><.net><docker><microservices>,2,36,0,0.0,0,"<p>I want to push my microservice to dockerhub but i dont know how to push it to docker hub, after <code>docker login</code> &#xA;then im <code>using docker push</code>  then its go this message </p>&#xA;&#xA;<pre><code>The push refers to a repository [docker.io/library/microservicehelloworld]&#xA;An image does not exist locally with the tag: microservicehelloworld&#xA;</code></pre>&#xA;&#xA;<p>and then im using </p>&#xA;&#xA;<pre><code>docker tag microservicehelloworld  microservicehelloworld&#xA;</code></pre>&#xA;&#xA;<p>and it shows error message like this</p>&#xA;&#xA;<pre><code>Error response from daemon: No such image: microservicehelloworld:latest&#xA;</code></pre>&#xA;&#xA;<p>here is my full solution, is there any file missing , or something that i must do to create docker image ?&#xA;<a href=""https://i.stack.imgur.com/9WFWO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9WFWO.png"" alt=""enter image description here""></a></p>&#xA;"
46600671,"Docker swarm mode, internally running several services with unique domain names but each on port 80",2017-10-06 07:39:12,<docker><routing><docker-compose><microservices><docker-swarm>,1,95,0,0.0,0,"<p>I'm trying to setup a microservice deployment (deployment file at <a href=""https://github.com/mojlighetsministeriet/groups/blob/master/docker-compose.example.yml"" rel=""nofollow noreferrer"">https://github.com/mojlighetsministeriet/groups/blob/master/docker-compose.example.yml</a>) with several services that will use HTTP (hopefully HTTPS later on) to communicate internally without being exposed outside the network. I later on will add a proxy service that will expose specific features. I want to do this specifically with docker swarm mode and I like the possibility to define the deployment in a docker-compose.yml so I can initiate with:</p>&#xA;&#xA;<pre><code>$ docker stack deploy my-platform -c docker-compose.example.yml&#xA;</code></pre>&#xA;&#xA;<p>I want the API urls internally to be like GET <a href=""http://identity-provider/public-key"" rel=""nofollow noreferrer"">http://identity-provider/public-key</a> and GET <a href=""http://groups/b0c44674-58e0-4a8a-87e0-e1de35088964"" rel=""nofollow noreferrer"">http://groups/b0c44674-58e0-4a8a-87e0-e1de35088964</a> . I have done this with Kubernetes setups before and that works great but now I want to get this working with docker swarm mode.</p>&#xA;&#xA;<p>The DNS parts works without any problems, but docker swarm mode won't allow me to have each service listening on port 80 (will later be 443). It keeps complaining about port conflicts even though each service has it's unique domain name like identity-provider or groups and so on.</p>&#xA;&#xA;<p>Should I use a specific network driver to get this working? I currently use overlay.</p>&#xA;&#xA;<p>Using domain names without random ports would make calling in between the services much more simple to remember than e.g. <a href=""http://identity-provider:1234"" rel=""nofollow noreferrer"">http://identity-provider:1234</a> and <a href=""http://groups:1235"" rel=""nofollow noreferrer"">http://groups:1235</a>, the ports only adds complexity to the setup.</p>&#xA;&#xA;<p>I'm fine with using any super cutting edge version of docker-ce if that helps somehow.</p>&#xA;&#xA;<p>This should be possible right?</p>&#xA;"
46566667,Getting data from microservice (api) and joining it with main app data,2017-10-04 13:51:58,<php><database><api><design-patterns><microservices>,1,154,0,0.0,0,"<p>In the client application, we moving parts of a monotith system to microservices architecture. In a very simplistic way it looks so:&#xA;- core application has its own database with products&#xA;- microservices have own databases with various objects, which may be related to products.</p>&#xA;&#xA;<p>Scenario 1:&#xA;We want to show product ""Apple"" on the page, with related data from microservice. &#xA;It's easy: just get ""Apple"" from core-app database and retrieve additional data for this product from microservice. Good.</p>&#xA;&#xA;<p>Scenario 2:&#xA;We want to show a list of products with various conditions for core-app database and other conditions for the microservice database. How to do it?&#xA;Should I get - for example - 1000 products from the database (core-app) and call microservice for additional data for these products? But how? Should I send one query with 1000 ids or 1000 API calls or get data from API service in portions, for example, 10 API calls for 100 items? I don't like each of these options.</p>&#xA;&#xA;<p>Scenario 3:&#xA;We have ""Warehouse"" microservice.</p>&#xA;&#xA;<p>I want list of first 100 products sorted by name, ascending, which have flag available = true in the warehouse. How to do it? If I get 100 products from core-app db and then call API to check flag, then final list of products may be lower than 100. &#xA;Getting list of all items available in the warehouse is a bad idea, because there may be millions of items, so execution time and API response size will be not acceptable.</p>&#xA;&#xA;<p>Generally, I need an idea, how to merge some data from one db and some data from other DB and return it to a user view.</p>&#xA;&#xA;<p>The app is written in PHP, but maybe some guys experienced in J2EE know solutions for these problems?</p>&#xA;&#xA;<p>EDIT: I have found that: <a href=""http://microservices.io/patterns"" rel=""nofollow noreferrer"">http://microservices.io/patterns</a>. I will look at it closer.</p>&#xA;"
46476622,Authenticating Api Gateway (Kong) With A Public MicroService,2017-09-28 19:09:16,<api><microservices><kong><api-gateway>,1,220,0,0.0,0,"<p>We have a web app that is publicly available to access over the internet. This app runs on a web server that contains the monolithic set of APIs that the app could call (including user authentication). We want to expose an ""API"" (ex// gather data) for users to query a limited set of data about their account from their own code. This will allow them to write custom dashboards with the data we are collecting for them. </p>&#xA;&#xA;<p>With this new API, API calls are now able to come from somewhere other than our web-ap. So we want to set up an API gateway to manage the request ""load"". For example, the gateway can limit a user's requests to once every ten minutes. </p>&#xA;&#xA;<p>The end user will be given an API key to make requests through Kong and then Kong will carry out the API query for them using an HTTP GET/POST to the web server. Since our web-server is publicly available we need a way to verify that the request for the API (gather data) is only coming from Kong. I've done some research into JWTs and seems like a possible approach. Would it make sense to simply give the Kong server its own JWT issued by the web-server? Then any GET/POST to the web-server that doesn't have the Kong JWT are rejected.</p>&#xA;&#xA;<p>I know this might not be the most logical setup for an API gateway, normally you would have microservices on the same private network as Kong communicating with each other and wouldn't necessarily need to verify the authenticity of the requests coming in as Kong would be handling that. However, given our current setup would the JWT approach make the most sense?</p>&#xA;"
46521195,Multi service node.js web application backend in one free docker repository,2017-10-02 07:32:09,<docker><docker-compose><microservices><dockerhub>,1,266,1,0.0,0,"<p>I am fairly new to docker and I don't get the right workflow for me now.</p>&#xA;&#xA;<p>My goal is:</p>&#xA;&#xA;<ol>&#xA;<li>To write a web application with a frontend, a GraphQL API and an AuthServer. Other microservices will follow.</li>&#xA;<li>To easily deploy the application to my root server, when I make a commit to my master branch in Bitbucket. I want to use the automated build from docker hub.</li>&#xA;<li>To stay at the free account of docker hub, where I only have one free repository.</li>&#xA;</ol>&#xA;&#xA;<p>May it be possible to achieve these requirements, if my project structure is like the following:</p>&#xA;&#xA;<pre><code>- services&#xA;  - react frontend&#xA;      (I think it's okay to just put the built static files to the nginx html-folder)&#xA;  - graphqlapi&#xA;      Dockerfile&#xA;  - authservice&#xA;      Dockerfile&#xA;  - another service in the future&#xA;      Dockerfile&#xA;docker-compose.yml&#xA;</code></pre>&#xA;&#xA;<p>I have the docker-compose.yml in the root folder. But the automatic build in docker hub says that it needs a Dockerfile there to build the image.</p>&#xA;&#xA;<p>For me it would be okay to run all the services in just one image/container, because currently I just want to have it all run on the same machine.</p>&#xA;&#xA;<p>So again my question: Is it possible to dockerize a multi service web application into one docker image/container for the free docker hub repository?</p>&#xA;"
46532286,Organizing services dataflow / eip,2017-10-02 19:20:30,<rabbitmq><microservices><servicemix><consul>,1,37,1,0.0,0,"<p>Say I have like 1000 VMs with different services running on them with different technologies used like python, NET, java and different middleware like rabbitmq, redis etc.&#xA;How can I dynamically handle the interactions between the services and provide scalability?</p>&#xA;&#xA;<p>For Example, say I have Service A which is pushing Data to a rabbitmq then the data is processed by service B while fetching additional data from Service C. You see at the end I have a decentralized system which is pulling data somewhere and pushing it somewhere else... a total mess! Scale it up to 2000 microservices omg XD.</p>&#xA;&#xA;<p>The moment I change one thing a lot of other systems are affected.&#xA;Do you know something maybe like an ESB where I can couple two services together with a message transform adapter in the middle of it and I can change  dependenciesat runtime? Like the stream doesn't end in service F anymore and does end in G for example?</p>&#xA;&#xA;<p>I think microservices are a good idea because they can be stateless, can scale, can easily be deployed as a container. But I don't know a good tool/program for managing the data flow. The rabbitmq doesn't support enough enterprise integration patterns. Do you have any advice?</p>&#xA;"
46571540,Java Spring-boot micro-services Exception handling,2017-10-04 18:14:18,<java><spring-mvc><spring-boot><microservices><netflix>,1,1080,1,0.0,0,"<p>Java exception handling is sub divided in to Errors, checked exceptions and unchecked exceptions. This question is about exceptions.</p>&#xA;&#xA;<p>Normal Java exception handling is to extend the Exception class for checked exceptions and handle those as you need by considering exception hierarchy.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionA extends Exception {}&#xA;&#xA;public class RunClass {&#xA;&#xA;    public static void main() {&#xA;        try {&#xA;            RunClass runClass = new RunClass();&#xA;            runClass.doSomething();&#xA;        } catch(ExceptionA eA) {&#xA;            // Do ExceptionA related resolutions.&#xA;        } catch(Exception e) {&#xA;            // Do Exception related resolutions.&#xA;        }&#xA;    }&#xA;&#xA;    public doSomething() throws ExceptionA {&#xA;        throw new ExceptionA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I saw major Spring books and even on the Internet tutorials mentioned with Spring-boot and in the context of micro-services always extend from RuntimeException class even with the @ControllerAdvice.</p>&#xA;&#xA;<p>This is clear violation of Java exception handling basics. But still there is an argument saying that, it is extended with RuntimeException because of this exception is handled by @ExceptionHandler method and it is generated and handled both in runtime.</p>&#xA;&#xA;<p>Still, because of this extension from RuntimeException makes compile time exception handling trail not visible and makes hard to trace back how exception is thrown up. Due to these reasons, I still believe, follow the basic Java checked and unchecked exception handling concept still with @ExceptionHandler method.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionRA extends RuntimeException {}&#xA;&#xA;@ContollerAdvice&#xA;public class ExceptionHandler {&#xA;&#xA;    @ExceptionHandler(ExceptionRA.class)&#xA;    public String handleException (Exception exception, Model model) {&#xA;        return ""exception"";&#xA;    }&#xA;&#xA;}&#xA;&#xA;@Controller&#xA;public class RunClass {&#xA;&#xA;    @RequestMapping(""/url1"")&#xA;    public doSomething() {&#xA;        throw new ExceptionRA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Should I follow the extending RuntimeException for all exception scenarios with @ExcpetionHadler or follow the basic Java checked and unchecked mechanism with @ExceptionHaldler? Ideas, suggestions and corrections are welcome.</p>&#xA;"
46562115,Service Fabric flow pattern,2017-10-04 10:03:18,<azure><communication><microservices><azure-service-fabric>,1,112,1,0.0,0,"<p>For maintaining a vast amount of data in separate tables and databases I've written multiple console applications with different responsibilities. For instance, one application may seed a database, the next may process that new data and the last filters old vs new data. Etc. </p>&#xA;&#xA;<p>Right now the services are run sequential (by hand). &#xA;Depending on the result of such an application, you might have to run the previous one. </p>&#xA;&#xA;<p>To automate this process-flow, I'm thinking about using Service Fabric as I see that services may commune with one another.<br>&#xA;Is a pattern where there's one 'main' service that controls in/output from one services and sends it to the proper one correct? Or am I wildly over/under-thinking the use of the Service Fabric?</p>&#xA;"
46514002,wildfly swarm: lookup ejb remote interface,2017-10-01 15:42:14,<java><ejb-3.0><microservices><wildfly-swarm>,1,409,1,0.0,0,"<p>I have generated two simple wildfly swarm projects. First has EJB facade with Remote interface, second should lookup it and send message. So second should be as client.</p>&#xA;&#xA;<p>I am used&#xA;Wildfly swarm version 2017.9.4 </p>&#xA;&#xA;<p>My EJB facade lookup paths:</p>&#xA;&#xA;<pre><code>        java:global/ejb-one/PingFacade!io.project.core.interfaces.PingFacadeRemote&#xA;        java:app/ejb-one/PingFacade!io.project.core.interfaces.PingFacadeRemote&#xA;        java:module/PingFacade!io.project.core.interfaces.PingFacadeRemote&#xA;        java:jboss/exported/ejb-one/PingFacade!io.project.core.interfaces.PingFacadeRemote&#xA;        java:global/ejb-one/PingFacade&#xA;        java:app/ejb-one/PingFacade&#xA;        java:module/PingFacade&#xA;</code></pre>&#xA;&#xA;<p>My client :</p>&#xA;&#xA;<pre><code> public static void main(String[] args) {&#xA;        BackendConnectionManager manager = new BackendConnectionManager();&#xA;        try {&#xA;            manager.getPingFacadeRemote().savePingMessage(""halloooooo"");&#xA;        } catch (NamingException ex) {&#xA;            Logger.getLogger(BackendConnectionManager.class.getName()).log(Level.SEVERE, null, ex);&#xA;        }&#xA;    }&#xA;    public  PingFacadeRemote getPingFacadeRemote() throws NamingException {&#xA;        final Hashtable jndiProperties = new Hashtable();&#xA;        jndiProperties.put(Context.URL_PKG_PREFIXES, ""org.jboss.ejb.client.naming"");&#xA;        jndiProperties.put(Context.INITIAL_CONTEXT_FACTORY,  ""org.wildfly.naming.client.WildFlyInitialContextFactory"");&#xA;              jndiProperties.put(Context.PROVIDER_URL,""http-remoting://localhost:8080"");&#xA;                 //jndiProperties.put(Context.PROVIDER_URL,""http://localhost:8080"");&#xA;        final Context context = new InitialContext(jndiProperties);&#xA;&#xA;        return (PingFacadeRemote) context&#xA;                .lookup(""java:global/ejb-one/PingFacade!io.project.core.interfaces.PingFacadeRemote"");&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added client dependencies to pom.xml</p>&#xA;&#xA;<pre><code> &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.wildfly.swarm&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;ejb-remote&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.wildfly&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;wildfly-naming&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt; &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-ejb-client&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;  &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.xnio&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;xnio-api&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.xnio&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;xnio-nio&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.remoting3&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-remoting&lt;/artifactId&gt;&#xA;            &lt;version&gt;3.3.3.Final&lt;/version&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;        &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.sasl&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-sasl&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;            &lt;version&gt;1.0.5.Final&lt;/version&gt;&#xA;        &lt;/dependency&gt;     &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.marshalling&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-marshalling-river&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;     &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.spec.javax.transaction&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-transaction-api_1.2_spec&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.spec.javax.jms&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-jms-api_2.0_spec&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;     &#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.jboss.spec.javax.ejb&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jboss-ejb-api_3.2_spec&lt;/artifactId&gt;&#xA;            &lt;scope&gt;runtime&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>I do not what is whole dependencies for client and always has</p>&#xA;&#xA;<pre><code>javax.naming.CommunicationException: WFNAM00018: Failed to connect to remote host [Root exception is org.jboss.remoting3.ServiceOpenException: Unknown service name]&#xA;    at org.wildfly.naming.client.remote.RemoteContext.getRemoteTransport(RemoteContext.java:80)&#xA;    at org.wildfly.naming.client.remote.RemoteContext.lambda$lookupNative$0(RemoteContext.java:106)&#xA;    at org.wildfly.naming.client.NamingProvider.performExceptionAction(NamingProvider.java:150)&#xA;    at org.wildfly.naming.client.remote.RemoteContext.lookupNative(RemoteContext.java:104)&#xA;    at org.wildfly.naming.client.AbstractFederatingContext.lookup(AbstractFederatingContext.java:74)&#xA;    at org.wildfly.naming.client.AbstractFederatingContext.lookup(AbstractFederatingContext.java:60)&#xA;    at org.wildfly.naming.client.WildFlyRootContext.lookup(WildFlyRootContext.java:150)&#xA;    at javax.naming.InitialContext.lookup(InitialContext.java:417)&#xA;    at io.project.ejbtwo.rest.BackendConnectionManager.getPingFacadeRemote(BackendConnectionManager.java:57)&#xA;    at io.project.ejbtwo.rest.BackendConnectionManager.main(BackendConnectionManager.java:43)&#xA;Caused by: org.jboss.remoting3.ServiceOpenException: Unknown service name&#xA;</code></pre>&#xA;&#xA;<p>Also how to solve problem with passing security credentials in client lookup?</p>&#xA;&#xA;<p>Projects by itself here</p>&#xA;&#xA;<p><a href=""https://drive.google.com/open?id=0B45Md1_c5-gGQ0p3Q2pURUxOY00"" rel=""nofollow noreferrer"">https://drive.google.com/open?id=0B45Md1_c5-gGQ0p3Q2pURUxOY00</a></p>&#xA;"
46660853,How to run micro services using docker,2017-10-10 07:25:37,<docker><spring-boot><cassandra><docker-compose><microservices>,3,216,1,1.0,0,"<p>Am newbie to Spring boot. I need to create micro services and need to run by docker. I have attached my project structure here. Problem which is every time i need to up the micro services manually. For example am having 4 micro services and i just up this services manually. But all micro services should be started itself when deploying into docker. How to achieve this. <a href=""https://i.stack.imgur.com/QZFMw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QZFMw.png"" alt=""Project Structure""></a></p>&#xA;&#xA;<p>Also am using Cassandra database.</p>&#xA;"
46623194,Is a Spring boot microservice with a non-Java front end client possible?,2017-10-07 17:39:25,<javascript><java><client><load-balancing><microservices>,2,167,2,0.0,0,"<p>Ive implemented the shell of a microservices besed REST api application. I have simply followed the guides on Pivotal Springs own dicumentation using eureka and ribbon for load balancing. Everything works, I have a discovery server with a hanful of indepedant services which can register with the discovery server. </p>&#xA;&#xA;<p>Now, my problem is that I might prefer not to write my client-side app in java - maybe @Angular or node.js etc. But the loadbalancing and connecting to the discovery server is all  done in java in the examples I've followed. </p>&#xA;&#xA;<p>Is it possible to use javascript to do the same things that the eureka client does with the spring boot microservices so that I don't need to be constrained in my choices of browser client technology? Does anybody have any advice for how this should be aproached? I had difficulty finding any articles that cover this to be honest.</p>&#xA;"
46586380,Securing micro-service spring cloud security Oauth2,2017-10-05 13:05:29,<java><spring><security><spring-boot><microservices>,1,327,3,1.0,0,"<p>I am using Spring cloud security and Oauth2 to secure my micro- service. Now the Pom is as follows:</p>&#xA;&#xA;<p>&#xA;http://maven.apache.org/xsd/maven-4.0.0.xsd"">&#xA;    4.0.0</p>&#xA;&#xA;<pre><code>&lt;groupId&gt;com.oreilly.cloud&lt;/groupId&gt;&#xA;&lt;artifactId&gt;spring-microservices-oauth-server&lt;/artifactId&gt;&#xA;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;name&gt;spring-microservices-oauth-server&lt;/name&gt;&#xA;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;&#xA;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;    &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;spring-cloud.version&gt;Dalston.SR3&lt;/spring-cloud.version&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.hsqldb&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;hsqldb&lt;/artifactId&gt;&#xA;        &lt;scope&gt;runtime&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;dependencyManagement&gt;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;            &lt;type&gt;pom&lt;/type&gt;&#xA;            &lt;scope&gt;import&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&lt;/dependencyManagement&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;&#xA;&lt;repositories&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-snapshots&lt;/id&gt;&#xA;        &lt;name&gt;Spring Snapshots&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;true&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;        &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;false&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;&lt;/repositories&gt;&#xA;</code></pre>&#xA;&#xA;<p></p>&#xA;&#xA;<p>The Spring-boot main class is as below:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.security.access.prepost.PreAuthorize;&#xA;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;@SpringBootApplication&#xA;@EnableAuthorizationServer&#xA;@EnableResourceServer&#xA;@RestController&#xA;@EnableGlobalMethodSecurity(prePostEnabled=true)&#xA;public class SpringMicroservicesOauthServerApplication {&#xA;&#xA;    @RequestMapping(""/resource/endpoint"")&#xA;    @PreAuthorize(""hasRole('ADMIN')"")&#xA;    public String endpoint(){&#xA;        return ""This message is protected by the resource server."";&#xA;    }&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(SpringMicroservicesOauthServerApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The authorization server configuration is as follows:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;&#xA;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;&#xA;&#xA;@Configuration&#xA;public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;    @Autowired&#xA;    private AuthenticationManager authManager;&#xA;&#xA;    @Override&#xA;    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;        endpoints.authenticationManager(authManager);&#xA;    }&#xA;&#xA;    @Override&#xA;    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;        clients.inMemory().withClient(""webapp"").secret(""websecret"").authorizedGrantTypes(""password"")&#xA;                .scopes(""read,write,trust"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Note the Authentication manager is auto wired into the Authorization config</strong> </p>&#xA;&#xA;<p>In the below class The Authentication Manager is configured and returned as abean so that it can be autowired to the above class:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.context.annotation.Bean;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;&#xA;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;&#xA;&#xA;@Configuration&#xA;public class WebSecurityConfig extends WebSecurityConfigurerAdapter {&#xA;&#xA;    @Bean&#xA;    public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;        return super.authenticationManagerBean();&#xA;    }&#xA;&#xA;    @Override&#xA;    protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;        auth.inMemoryAuthentication().withUser(""user1"").password(""password1"").roles(""USER"").and().withUser(""admin"")&#xA;                .password(""password2"").roles(""ADMIN"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now the application.properties is as below:</p>&#xA;&#xA;<pre><code>server.port=9090&#xA;</code></pre>&#xA;&#xA;<p>Now i run the Spring boot application as below:</p>&#xA;&#xA;<p>mvn spring-boot:run</p>&#xA;&#xA;<p>The application starts successfully and is ready to accept request on port 9090 on localhost</p>&#xA;&#xA;<p>Now using postman i am sending a post request to get the access_token. A little background is that the Aoauth2 flow being used here is the password grant. So in the AuthorizationServerConfig class above i have defined a password grant flow and registered a simple web app with client name and secret. As can be seen the client configuration is in memory.</p>&#xA;&#xA;<p>The post man request to get access token from authorization server is as follows: Its post request, with Basic auth header header having the &#xA;username as webapp and password as websecret.</p>&#xA;&#xA;<p><a href=""http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1"" rel=""nofollow noreferrer"">http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1</a></p>&#xA;&#xA;<p>This request returns successfully with a access token json as follows:</p>&#xA;&#xA;<pre><code>{&#xA;    ""access_token"": ""2d632e54-17c3-41f7-af3b-935ca3022d78"",&#xA;    ""token_type"": ""bearer"",&#xA;    ""expires_in"": 43199,&#xA;    ""scope"": ""read,write,trust""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now when i try to access the /resourse/endpoint with the above access token as follows:</p>&#xA;&#xA;<p><a href=""http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78"" rel=""nofollow noreferrer"">http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78</a></p>&#xA;&#xA;<p>Rather than returning the text which is returned from the service /resourse/endpoint it returns the login page as below:</p>&#xA;&#xA;<pre><code>&lt;html&gt;&#xA;    &lt;head&gt;&#xA;        &lt;title&gt;Login Page&lt;/title&gt;&#xA;    &lt;/head&gt;&#xA;    &lt;body onload='document.f.username.focus();'&gt;&#xA;        &lt;h3&gt;Login with Username and Password&lt;/h3&gt;&#xA;        &lt;form name='f' action='/login' method='POST'&gt;&#xA;            &lt;table&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;User:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='text' name='username' value=''&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;Password:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='password' name='password'/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td colspan='2'&gt;&#xA;                        &lt;input name=""submit"" type=""submit"" value=""Login""/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;input name=""_csrf"" type=""hidden"" value=""8dbc1c38-6f89-43c5-a8f8-797c920722a1"" /&gt;&#xA;            &lt;/table&gt;&#xA;        &lt;/form&gt;&#xA;    &lt;/body&gt;&#xA;&lt;/html&gt;&#xA;</code></pre>&#xA;&#xA;<p>Can anyone please help what i am missing here?????. </p>&#xA;&#xA;<p><strong>NOTE</strong> I have both authorization server and resourse server configured in same application. this is a POC so i am trying out the Spring-cloud security, later i will separate the two ...but thats for later. </p>&#xA;"
46575898,What the hell is microservice?,2017-10-04 23:59:02,<architecture><microservices>,2,913,3,0.0,0,"<p>Microservice for this, microservice for that, but explain to a simple person what is microservice? I'm a simple programmer with a little almost none theoretical background. But I don't need a term microservice to do what I do. Could someone explain me in easy-peasant words what microservice is? Amazon AWS = microservice?</p>&#xA;&#xA;<p>I read this: <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Microservices</a> but apparently I'm too stupid to understand what is this.</p>&#xA;"
46522304,File upload spring cloud feign client,2017-10-02 08:50:39,<java><microservices><spring-cloud><multipart><feign>,2,1140,5,2.0,0,"<p>When make a post request from one microservice to another using feign client of spring cloud netflix, I get the following error in Postman :</p>&#xA;&#xA;<pre><code>{&#xA;""timestamp"": 1506933777413,&#xA;""status"": 500,&#xA;""error"": ""Internal Server Error"",&#xA;""exception"": ""feign.codec.EncodeException"",&#xA;""message"": ""Could not write JSON: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS); nested exception is com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile[\""inputStream\""]-&gt;java.io.FileInputStream[\""fd\""])"",&#xA;""path"": ""/attachments""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And my eclipse console shows the following exception :</p>&#xA;&#xA;<blockquote>&#xA;  <p>com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile[""inputStream""]->java.io.FileInputStream[""fd""])&#xA;      at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:284) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.SerializerProvider.mappingException(SerializerProvider.java:1110) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.SerializerProvider.reportMappingProblem(SerializerProvider.java:1135) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:69) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:32) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:704) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:689) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:704) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:689) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:292) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1429) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:951) ~[jackson-databind-2.8.9.jar:2.8.9]</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>UPDATE 1</strong></p>&#xA;&#xA;<p>This is my  feign interface :</p>&#xA;&#xA;<pre><code>@FeignClient(name=""attachment-service"", fallback=AttachmentHystrixFallback.class)&#xA;public interface AttachmentFeignClient {&#xA;&#xA;@RequestMapping(""upload"")&#xA;void upload(@RequestPart(name=""file"") MultipartFile file, @RequestParam(name=""attachableId"") Long attachableId, &#xA;        @RequestParam(name=""className"") String className, @RequestParam(name=""appName"") String appName);&#xA;</code></pre>&#xA;&#xA;<p>And this is the main microservice controller : </p>&#xA;&#xA;<pre><code>@RestController&#xA;public class AttachmentController implements Serializable {&#xA;&#xA;/**&#xA; * &#xA; */&#xA;private static final long serialVersionUID = -4431842080646836475L;&#xA;&#xA;@Autowired&#xA;AttachmentService attachmentService;&#xA;&#xA;@RequestMapping(value = ""attachments"", method = RequestMethod.POST, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)&#xA;public void upload(@RequestPart MultipartFile file, @RequestParam Long attachableId, @RequestParam String className, @RequestParam String appName) throws Exception {&#xA;    attachmentService.uploadFile(file, attachableId, className, appName);&#xA;}&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm certainly missing some kind of serializer here<br>&#xA;Any suggestion would be appreciated ! <br>&#xA;Thanks</p>&#xA;"
47888172,Searching for architecture approach for converting Kafka Message to other formats,2017-12-19 13:33:43,<spring-boot><apache-kafka><microservices><messaging><templating>,1,19,0,0.0,0,"<p>We're using Kafka as a broker which takes notifications from different message sources and then routes them to one or more target apps like Slack or E-Mail. Having such an approach it is necessary to convert the Kafka message into different output formats like JSON or E-Mail before they are sent to the apps.</p>&#xA;&#xA;<p>I thought of having Microservices with SpringBoot at the target ends which takes the message from Kafka, converts it using one of the common template languages like Velocity or Freemarker into the target format and then forwards the converted result to the given target app.</p>&#xA;&#xA;<p>Would you agree with such an approach or are there better ways, some caveats or even no-gos to do it this way? What about performance? Any experience in this?</p>&#xA;&#xA;<p>Thanks for your honest assessment.</p>&#xA;"
47833668,RabbitMQ is sending the request again if response is null,2017-12-15 13:46:56,<rabbitmq><microservices><masstransit>,1,29,0,0.0,0,"<p>I am using RabbitMq with masstransit for messaging between different services, let us say that we have the following scenario:</p>&#xA;&#xA;<p>First service asks about specific info from second service by sending a request.</p>&#xA;&#xA;<p>Second service looks for the info in database and respond with an object containing the found info.</p>&#xA;&#xA;<p>In case there is no info available in database, the second service responds with a null object.</p>&#xA;&#xA;<p>The issue is that RabbitMQ is considering that the request has failed thus it keeps sending the request again.</p>&#xA;&#xA;<p>Can I configure the bus to consider the null reponse as a normal response?</p>&#xA;"
47916614,Azure Service Fabric v monolithic,2017-12-21 01:22:38,<azure><architecture><microservices><service-fabric>,1,48,0,0.0,0,"<p>Can I just bounce something of you? Iâ€™m reading about microservices and the Azure Service Fabric and need a nutshell on a concept.</p>&#xA;&#xA;<p>To my understanding, it allows microservices to be deployed to its own container via Service Fabric magic. Each microservice container will be scaled out when a workload is put on it disregarding other services.</p>&#xA;&#xA;<p>For example imagine there are </p>&#xA;&#xA;<ul>&#xA;<li>only 2 microservices at play. </li>&#xA;<li>first is a query handler â€“ which uses n compute resources when idle and </li>&#xA;<li>a database microservice that uses m resources when idle.</li>&#xA;</ul>&#xA;&#xA;<p>Say that the query handler passes a ridiculously expensive query (e.g. <code>select * from aMultiBillionRowTable;</code>) to the database microservice that will require compute\VM scaling.</p>&#xA;&#xA;<p>In the monolithic approach, I understand that query handler microservice will have its resources scaled to n * x compute resources and the database microservice scaled to m * x.</p>&#xA;&#xA;<p>In the Azure Service Fabric approach, query handler microservice will remain at n compute resources and the database microservice will scale to m * x.</p>&#xA;&#xA;<p>Is this correct? If so, great, but are there corollaries Iâ€™m ignoring? What are they? I donâ€™t need a treatise, just the terms and Iâ€™ll research on my own.</p>&#xA;"
47804267,Can I have a custom UI for monitoring my microservices registered to Consul?,2017-12-14 00:40:39,<microservices><consul><health-monitoring>,1,51,0,1.0,0,"<p>I'm new to using Consul as a service discovery for the SOA. Please clarify whether I can enhance the monitoring web UI that Consul has inbuild to support my needs? Like I wish to monitor the Microservice health (CPU usage, Latency, and Disk space).  TIA</p>&#xA;"
47885225,"How can I create an entry point web app, to manage all other web apps?",2017-12-19 10:48:12,<spring><spring-mvc><spring-boot><active-directory><microservices>,2,55,0,0.0,0,"<p>I have several Spring web apps, each with its own database.&#xA;Now I have to create a web app, that works as <strong>enter point</strong> for all the other apps.. </p>&#xA;&#xA;<p>So if I want to use the web app <strong>B</strong> I have to pass through the <strong>enter point</strong> web app. I have to do the login inside this app. To do that I have to sign in against <code>Active Directory</code>.&#xA;After that the users can access only to the apps where they have permission, and inside each app they have also some different roles.</p>&#xA;&#xA;<p>what kin of solution can I adopt?</p>&#xA;&#xA;<p>I read about <code>SSO</code> but I'm not sure it is correct.. So, do you have any idea?</p>&#xA;&#xA;<p><strong>EDIT</strong>&#xA;What do you think about microservice? Is it good for my scenario?</p>&#xA;"
47915099,combining votes from microservices,2017-12-20 22:11:47,<machine-learning><microservices><voting-system>,1,58,0,1.0,0,"<p>Does it make sense and what would be a reasonable way to implement the following:</p>&#xA;&#xA;<p>This could happen for either single instances or a time series of data. There could be several micro-services consuming data (from kafka for example) and performing some kind of classification and assigning either binary or discrete value. How could we reasonably combine the results of such ""voting"" to save or present single value result.</p>&#xA;&#xA;<p>I'm thinking about another microservice which would match the data (in case of time series by some identifier) but it would need to know how many votes to expect or could assume that the result should appear within some timeframe, but then it gets a bit less asynchronous.</p>&#xA;"
47935575,how to communicate between 2 applications hosted on 2 aws elastic beanstalks,2017-12-22 03:41:59,<amazon-web-services><amazon-ec2><elastic-beanstalk><microservices><aws-api-gateway>,2,65,0,0.0,0,"<p>I have 2 different modules, one is <strong>loyalty</strong> and another one is <strong>wallet</strong>. (both are written in java)</p>&#xA;&#xA;<p>loyalty app is hosted on an AWS elastic beanstalk and I have an AWS API Gateway on top of it.</p>&#xA;&#xA;<p>now I'm about to build the wallet and it will need to use some functionalities of loyalty module. I can put it under loyalty but it wouldn't make sense since they both server different purposes.</p>&#xA;&#xA;<p>so I thought I would put wallet on another AWS elastic beanstalk with AWS API Gateway on top but then I wonder, if wallet wants to call loyalty to use any of its functions, how should it be done? I'm not sure if it's a good idea to call the API gateway on top of loyalty to access its functions. Or is it a correct way?</p>&#xA;"
47765389,Http Load Testing,2017-12-12 04:30:47,<scala><akka><microservices><akka-http>,1,129,0,0.0,0,"<p>I am trying to create a simple microservice that can handle 1 million requests at a time. But I am getting connection reset error on my client side. Correct me in case I am making any mistake.</p>&#xA;&#xA;<p><strong>Server Code</strong>&#xA;1. <strong>Listener</strong> :</p>&#xA;&#xA;<pre><code>  object Collection {&#xA;  case class calculate(values:Double)&#xA; }&#xA;&#xA; object EngineController{&#xA;&#xA; import Collection._&#xA;&#xA;&#xA;def main(args: Array[String]): Unit = {&#xA;try {&#xA;  implicit val system = ActorSystem()&#xA;  implicit val materializer = ActorMaterializer()&#xA;  implicit val executionContext = system.dispatcher&#xA;val requestHandler = system.actorOf(RoundRobinPool(3).props(RequestHandler.props), ""round-robin-pool"")&#xA;  val route: Route = {&#xA;    implicit val timeout = Timeout(100.seconds)&#xA;    path(""aggregate"") {&#xA;      log.info(""REQUEST RECEIVED"")&#xA;      post {&#xA;        entity(as[String]) { values =&gt;&#xA;          onSuccess(requestHandler ? calculate(values)) {&#xA;            case result: Double =&gt;&#xA;              log.info(""Response Sent -"" + result)&#xA;              complete(s""${result}"")&#xA;&#xA;          }&#xA;        }&#xA;      }&#xA;    } &#xA;  }&#xA;  val routeBinding :Future[ServerBinding] = Http().bindAndHandle(route, ""localhost"", 8080)&#xA;  log.info(""Connection Established! Waiting for Request"")&#xA;  routeBinding.failed.foreach { ex =&gt;&#xA;    log.error(ex, ""Failed to bind to {}:{}!"", host, port)&#xA;  }&#xA;  StdIn.readLine()&#xA;&#xA;  routeBinding.flatMap(_.unbind())&#xA;  system.terminate()&#xA;&#xA;}&#xA;&#xA;catch {&#xA;  case ex: Exception =&gt;&#xA;    log.error(ex, ex)&#xA;}&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<ol start=""2"">&#xA;<li><p>RequestHandler: This actor return max of the number.</p>&#xA;&#xA;<pre><code>object RequestHandler extends App {&#xA;def props: Props = {&#xA;Props(classOf[RequestHandler])&#xA;  }&#xA;&#xA;class RequestHandler extends Actor {&#xA;var doubleArray: Array[Double] = Array.empty&#xA;val system1 = ActorSystem(""system2"")&#xA;var routees: List[ActorRef] = _&#xA;override def preStart() = {&#xA;routees = List.fill(5)(&#xA;context.actorOf(AggregateCalculator.props)&#xA;)&#xA;}&#xA;val aggregateActor = system1.actorOf(AggregateCalculator.props.withRouter(RandomPool(100)), ""ag"")&#xA;&#xA; //CONVERT STRING TO ARRAY&#xA; def stringToArray(values: String): Array[Double] = {&#xA; return values.split("","").map(x =&gt; x.toDouble)&#xA; }&#xA;&#xA; override def receive: Receive = {&#xA; case calculate(values) =&gt;&#xA; doubleArray = stringToArray(values)&#xA; sender() ! doubleArray.max&#xA;   }&#xA;  }&#xA; }&#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p><strong>Client Code</strong> :</p>&#xA;&#xA;<pre><code> package Test&#xA; import scalaj.http.{Http, HttpResponse}&#xA; import org.apache.log4j.Logger&#xA;&#xA;&#xA; //libraryDependencies += ""org.scalaj"" % ""scalaj-http_2.11"" % ""2.3.0""&#xA; object RequestSender1 {&#xA;val log = Logger.getLogger(getClass.getName)&#xA;def main(args: Array[String]): Unit = {&#xA;try {&#xA;  val str = ""22.78, -1.23, 50, 60, 3, 32, 11, 54, 72, 78, 99, 70, 19, 47, 90, 81, 50, 69, 69, 72, 83, 14.7, 8, 41, 65, 73, 48, 63, 47, 17, 55, 39, 50, 87, 76, 8, 67, 51, 55, 94, 75, 14, 91, 35, 87, 36, 42, 74, 70, 81, 18, 14, 50, 22, 16, 55, 71, 17, 39, 44, 58, 61, 16, 4, 74, 61, 37, 31, 62, 36, 53, 30, 82, 72, 89, 96, 28, 36, 77, 89, 30, 2, 31, 79, 50, 34, 81, 39, 91, 85, 94, 25, 68, 98, 46, 42,14,14""&#xA;  var result: HttpResponse[String] = null&#xA;  var counter = 0&#xA;  for (i &lt;- 1 to 300) {&#xA;&#xA;    for (i &lt;- 1 to 13000) {&#xA;      val thread = new Thread {&#xA;        override def run {&#xA;          while (counter &lt; 1000024) {&#xA;            try {&#xA;              counter += 1&#xA;              result = scalaj.http.Http(""http://localhost:8080/aggregate"").postData(str).timeout(1200000, 120000000) //192.168.0.157:8089&#xA;                .header(""Content-Type"", ""text/plain"").asString&#xA;              println(""Thread Count----"" + java.lang.Thread.activeCount())&#xA;              j += 1&#xA;              println(result.body + ""   "" + j)&#xA;            } catch {&#xA;              case ex:Exception =&gt;&#xA;                log.error(ex)&#xA;            }&#xA;          }&#xA;        }&#xA;      }&#xA;      thread.start&#xA;      // slow the loop down a bit&#xA;    }&#xA;    println(""Sent request with --"" + i)&#xA;    Thread.sleep(1)&#xA;    // slow the loop down a bit&#xA; }&#xA;}&#xA;catch {&#xA;  case ex:Exception =&gt;&#xA;    println(""Exception""+""&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;"")&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>}&#xA;}</p>&#xA;&#xA;<p><strong>Error 1</strong> :</p>&#xA;&#xA;<pre><code>09:58:07 ERROR [Thread-12803] - Test.RequestSender1$.run 32 - java.net.BindException: Address already in use: connect&#xA;</code></pre>&#xA;&#xA;<p><strong>Error 2</strong> :</p>&#xA;&#xA;<pre><code>Thread-12418"" java.net.SocketException: Connection reset&#xA;</code></pre>&#xA;&#xA;<p><strong>Sorry for Bad Allignment</strong></p>&#xA;"
47939726,"micro service, reference and foreign keys",2017-12-22 10:15:47,<microservices>,1,150,0,0.0,0,"<p>We have 2 micro services.&#xA;account micro service (for registration, verification, etc..).&#xA;e-wallets micro service (create a wallet, deposit, withdrawals, etc..).</p>&#xA;&#xA;<p>the application first creates an account and then creates an e-wallet for every verified user.</p>&#xA;&#xA;<p>considering the user identity is manged in the account micro service.</p>&#xA;&#xA;<p>should the wallet service store a reference to the account entity (external-user-id)? or should the account micro service store a reference to the wallet entity (external-wallet-id)?</p>&#xA;&#xA;<p>i am mostly concerned with the account micro service becoming a hub which stores many references. are there any practices i should consider?</p>&#xA;"
47915158,How to connect Azure Api Management to micro services orchestrated by AKS,2017-12-20 22:17:04,<azure><containers><microservices><azure-api-management>,1,411,0,0.0,0,"<p>I have followed instructions in <a href=""https://fizzylogic.nl/2017/06/16/how-to-connect-azure-api-management-to-your-kubernetes-cluster/"" rel=""nofollow noreferrer"">https://fizzylogic.nl/2017/06/16/how-to-connect-azure-api-management-to-your-kubernetes-cluster/</a> and managed to get connection from the API Management to micro service running in Kubernetes cluster. However, the instructions cover connection ONLY TO A SPECIFIC NODE. In real world there will be multiple nodes and perhaps even auto scaling so that the nodes come and go. So, isn't it possible to connect the API management to the Kubernetes service instead?</p>&#xA;&#xA;<p>Or how should I work if I wanted to use AKS to orchestrate microservices and Azure API Manager to publish API's out from them?</p>&#xA;"
47774291,How can asynchronous microservices communication performs betters in the perspective of UI?,2017-12-12 13:51:03,<spring><angular><asynchronous><microservices><event-driven>,2,157,0,1.0,0,"<p>In my Angular UI, I call an endpoint from API gateway such as:</p>&#xA;&#xA;<pre><code>this.http.post(`/order`).subscribe(order =&gt; addNewOrderToList(order));&#xA;</code></pre>&#xA;&#xA;<p>According to best practise in microservices, the <code>/order</code> handler should publish an event that to be consumed by one or more microservices, instead of calling each other using synchronous REST.  So, I write the following handler:</p>&#xA;&#xA;<pre><code>@RequestMapping&#xA;public Future&lt;Order&gt; addOrder() {&#xA;  CompletableFuture&lt;Order&gt; future = new CompletableFuture&lt;&gt;();&#xA;  // publish event&#xA;  // ...&#xA;  // wait for final event raised by a service.&#xA;  future.complete(createdOrder);&#xA;  return future;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>From the perspective of the UI, isn't that user will not see the new order until my endpoint returned a new order?  I feel like the UI is still synchronous even when the backend is asynchronous. What is the best practice to improve the UI in this case?</p>&#xA;"
47922096,Circuit breaker Pattern,2017-12-21 09:44:55,<java><microservices><hystrix><circuit-breaker>,1,175,0,0.0,0,"<p>Is that fallback method and actual method should return same return type.</p>&#xA;&#xA;<pre><code>@HystrixCommand(fallbackMethod = ""reliable"")&#xA;  public String readingList() {&#xA;    URI uri = URI.create(""http://localhost:8090/recommended"");&#xA;&#xA;    return this.restTemplate.getForObject(uri, String.class);&#xA;  }&#xA;&#xA;  public String reliable() {&#xA;    return ""Cloud Native Java (O'Reilly)"";&#xA;  }&#xA;</code></pre>&#xA;&#xA;<p>What I should do to return String from the fallback method <code>reading list</code> and return some Object from the actual method <code>reliable</code>?</p>&#xA;"
47971020,Unary vs Stream benchmark,2017-12-25 18:15:23,<go><microservices><grpc>,1,207,0,0.0,0,"<p>I'm start to play with some GRPC with Golang microservice applications.</p>&#xA;&#xA;<p>After read the GRPC docs something is not clear to me:</p>&#xA;&#xA;<blockquote>&#xA;  <p>When to use Unary and when to use Streaming?</p>&#xA;</blockquote>&#xA;&#xA;<p>I mean, as example, i'm building a microservice that will parse a XLS and back JSON to stub. I will use a thrid-party lib to parse it for me. So, my job is to receive the xls, call lib and sent it forward. Quite simple.</p>&#xA;&#xA;<p>What is the best pratice/performance that i can reach? Send() row by row with streaming or send whole parsed json once?</p>&#xA;"
47908754,Setting two subject in JWT token generation in spring boot microservice,2017-12-20 14:54:53,<spring-boot><jwt><microservices>,1,213,0,0.0,0,"<p>I am trying to generate a JWT token for my microservice . And that token will use my front-end application for service accessing. Here I am setting subject by adding my username. I need to add user id along with username. Below code I am using for generating Token by only adding subject ""username"".</p>&#xA;&#xA;<p>My code is ,</p>&#xA;&#xA;<pre><code>protected String getToken(String encodedSecret, Users jwtUser){&#xA;    return Jwts.builder()&#xA;            .setId(UUID.randomUUID().toString())&#xA;            .setSubject(jwtUser.getUsername())&#xA;            .signWith(SignatureAlgorithm.HS512, encodedSecret)&#xA;            .compact();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Here I need to add two subject username with userid. How I can add two subject here? Can anyone help me to solve this issue?</p>&#xA;"
47939451,Linking data in a Microservices architecture?,2017-12-22 09:57:31,<architecture><microservices><soa>,2,147,1,0.0,0,"<p>I have a website and two Java microservices (user service, reports service)</p>&#xA;&#xA;<p>On the website I am trying to tie up reports to users. However both of these services are unaware of the entities they are related to.</p>&#xA;&#xA;<p>So my plan is to create a linking table in the website. Which allows it to query data from both services and then display it in a meaningful way.</p>&#xA;&#xA;<p>My question is essentially, should I add extra properties to those services e.g. <code>user_id</code> to reports service. So that each service is aware of the other service.</p>&#xA;&#xA;<p>Or use the website (PHP / MySQL) to persist the relationships between these two entities?</p>&#xA;&#xA;<p>My only worry with using the website to persist all relationships, is that it could have scaling issues when I add more services. Also if that website goes down, the data is useless.</p>&#xA;&#xA;<p>Is there any other ways to structure my data across these services.</p>&#xA;&#xA;<p>Any suggestions welcome!</p>&#xA;&#xA;<p>Note:- this is early stages, there are no other dependencies currently</p>&#xA;"
47934052,Continue Trace in downstream microservice,2017-12-21 23:25:24,<java><cloud><microservices><spring-cloud-sleuth><google-cloud-stackdriver>,2,170,1,0.0,0,"<p>We are trying to add tracing to micro services so it can viewed in the google Stackdriver UI.  We are using Java Springboot apps deployed into Kubernetes containers, each microservices communicates over http.  Weâ€™ve seen that there is Sleuth and Zipkin which if we move our RestTemplate to a bean will work.  However we donâ€™t really want to have to deploy a zipkin pod in each of our containers or create new zipkin collector pods.  Ideally we would like to get this working using just the google cloud tracing sdk with using sleuth/zipkin.  Playing around with the sdk we are able to get data into Stackdriver using the google cloud grpc library which just sends the data directly from the application into Stackdriver.&#xA;The problem we have now is that we can send the trace id to a downstream micro service but we cannot seem to find a way to create a new span on the same trace id, it always creates a new one.  I canâ€™t seem to find any documentation on how to do this.  Surely what we are doing is what this library was build for?&#xA;Any pointers help on this would be great.</p>&#xA;&#xA;<p>Adding a bit more info......</p>&#xA;&#xA;<p>I cannot supply actual code because this is my problem, I can't actually find what I want to do.<br>&#xA;Let me try to explain with a bit of code/pseudo code.&#xA;So lets assume this scenario, I have 3 microservices, A, B and C.</p>&#xA;&#xA;<pre><code>Microservice A (top level where trace is created)&#xA;  TraceContext context = tracer.startSpan(""myspan1"");&#xA;  TraceId traceId = context.getHandle().getCurrentSpanContext().getTraceId();&#xA;    Call Microservice B over http passing traceId in the B3-X-TraceId header&#xA;  tracer.endSpan(context);&#xA;&#xA;MicroService B  &#xA;  Read B3-X-TraceId from header&#xA;  So at this point I want to call Microservice C but I want to create a new span on the same trace&#xA;  I just do not see any mechanism to do this and this is where I'm stuck.&#xA;  This is what I want to do in pseudo code &#xA;    TraceContext context = tracer.startSpan(""myspan2"");&#xA;    attach the trace id that came in the header to the context&#xA;      Call Microservice C over http passing traceId in the B3-X-TraceId header&#xA;    tracer.endSpan(context);&#xA;</code></pre>&#xA;&#xA;<p>Hope this makes sense in what I'm trying to do.  </p>&#xA;"
47835162,how can i run my scala code coverage fully,2017-12-15 15:18:02,<scala><microservices><akka-http>,1,86,2,0.0,0,"<p>my scala code coverage report was 0.00% <strong>(Akka-HTTP microservices)</strong> and my report is</p>&#xA;&#xA;<pre><code>[info] Statement coverage.: 0.00%&#xA;[info] Branch coverage....: 0.00%&#xA;[info] Coverage reports completed&#xA;[info] All done. Coverage was [0.00%]&#xA;</code></pre>&#xA;&#xA;<p>how can i run the my code coverage report 100%</p>&#xA;&#xA;<p>am using this plugin <strong>addSbtPlugin(""org.scoverage"" % ""sbt-scoverage"" % ""1.5.1"")</strong> and in my code i don't have any unit test cases</p>&#xA;"
47957575,Go microservice in project and monolit git repository,2017-12-24 02:16:37,<git><go><microservices><directory-structure>,1,144,2,0.0,0,<p>Let's say I want to write one of my microservices in a project with go and I also want to keep monolit git repository for the whole project. The problem is that such microservice should be located under GOPATH and I can't even symlink it into my project cause git doesn't support symlinks.&#xA;What are options to keep the monolit repository for project while having go microservices in it?</p>&#xA;&#xA;<p>Edit:&#xA;I mean what the best practice to keep go microservice in git for non-golang project.</p>&#xA;
47889115,Spring boot API response(application/json) convert to response (text/xml),2017-12-19 14:28:23,<java><spring><rest><spring-boot><microservices>,1,508,2,0.0,0,"<p>Working on use case,A Springboot Microservice accepts JSON payload and then , in handler of the <code>@RestController</code> , the API will trigger another downstream application application which accepts payload in either <code>application/xml</code> or <code>text/xml</code> ??</p>&#xA;&#xA;<p><code>/api/v1/users Type:application/JSON</code> ---> <code>/api/v1/downstream/ Type: text/xml</code></p>&#xA;&#xA;<p>Using RestTemplate and HTTPEntity to represent Request and Response entity.</p>&#xA;&#xA;<p>Right now facing the below errors :</p>&#xA;&#xA;<pre><code>Could not extract response: no suitable HttpMessageConverter found for response type (How could I register new message converters), please bare with me I'm new to Spring boot and Spring.&#xA;</code></pre>&#xA;&#xA;<p>If I use <code>@XmlRootElement</code> annotation, then the error was : Could not instantiate JAXBContext for class.</p>&#xA;&#xA;<p>Also any suggestions how can I acheive this functionality ?? </p>&#xA;"
47479663,How to handle long requests on the frontend?,2017-11-24 20:31:45,<reactjs><rest><google-cloud-platform><google-cloud-endpoints><microservices>,1,28,0,0.0,0,"<p>My application allows a user to enter a URL of an article he/she wishes to analyze. It goes through our API gateway to reach the correct services engaged in this process. The analysis takes between 5 and 30 seconds depending on the article's word count.</p>&#xA;&#xA;<p>For now, my reactjs client sends the request to the API and waits for 5 to 30 seconds to receive the response. Is there a better way to handle this such as enqueuing the job and let the API ping the client (reactjs frontend) once it has been done?</p>&#xA;"
47529688,Hadoop integration with e-commerce portal,2017-11-28 10:50:10,<java><rest><hadoop><e-commerce><microservices>,1,33,0,0.0,0,"<p>We are building a new e-commerce portal from scratch using java rest services and we are planning to use MySQL (for now, Oracle in the future). We are using ElasticSearch also. We are building this whole portal as microservices. My Questions is, do I need to take care of analytics from the beginning (like hadoop and HDFS integration) ?</p>&#xA;"
47335582,Feign Exception 403 after updating to Spring Boot 1.5.8 and Finchley/Edgware Spring Cloud,2017-11-16 17:17:07,<java><spring><oauth-2.0><microservices><netflix-feign>,1,563,0,0.0,0,"<p>I'm relatively new to microservices and I've been trying to use this proof-of-concept application that uses Spring Boot and Spring Cloud: &#xA;<a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a></p>&#xA;&#xA;<p>The problem is that, while the app runs fine on Spring Boot 1.3.5 and Spring Cloud Brixton.RELEASE, it breaks when upgrading either one of them.</p>&#xA;&#xA;<p>The error ocurrs when registering a new account, and it gives the following error:</p>&#xA;&#xA;<p><code>status 403 reading AuthServiceClient#createUser(User); content:â†µ{""timestamp"":1510753211255,""status"":403,""error"":""Forbidden"",""message"":""Access Denied"",""path"":""/uaa/users""}</code></p>&#xA;&#xA;<p>And the stack trace:</p>&#xA;&#xA;<p><code>2017-11-15 15:40:11.284 ERROR 9072 --- [nio-6000-exec-1] o.a.c.c.C.[.[.[.[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [/accounts] threw exception [Request processing failed; nested exception is feign.FeignException: status 403 reading AuthServiceClient#createUser(User); content: {""timestamp"":1510753211255,""status"":403,""error"":""Forbidden"",""message"":""Access Denied"",""path"":""/uaa/users""}] with root cause</code></p>&#xA;&#xA;<p>As this seems to be a Feign error, and <code>AuthServiceClient.java</code> seems to be the culprit, I've included it here:</p>&#xA;&#xA;<pre><code>@FeignClient(name = ""auth-service"")&#xA;public interface AuthServiceClient {&#xA;&#xA;@RequestMapping(method = RequestMethod.POST, value = ""/uaa/users"", consumes = MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;void createUser(User user);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As there have been no changes to the code whatsoever, I don't understand what the cause could be and what to do to fix this error.</p>&#xA;"
47465212,Microservice communication,2017-11-24 01:33:52,<microservices>,1,60,0,0.0,0,"<p>Imagine the following:</p>&#xA;&#xA;<ul>&#xA;<li>You have two microservices called team and player each one with your own and separated databases (postgres).</li>&#xA;<li>I need to do association between team and player, so I need to store this relation inside player with team id attribute.</li>&#xA;</ul>&#xA;&#xA;<p>I have two options:</p>&#xA;&#xA;<p>1) using kafka, for every team inserted on database I send an event and player listen to this event and update its own team table inside player microservice. So, player microservice will have the information about team and player entities in order to make the relationship between them.</p>&#xA;&#xA;<p>We have some drawbacks here about data replication and integrity. Could be avoided using event sourcing and cqrs.</p>&#xA;&#xA;<p>2) Call microservice team in order to list team on view, make the association and post to player microservice.</p>&#xA;&#xA;<p>Drawbacks: calling http the team service could be down.</p>&#xA;&#xA;<p>What is the correct approach to communicate between microservices in order to archive dependency and doing releationship between microservices. Have data replicated on step 1 is reasonable??</p>&#xA;"
47486390,NGINX + Docker Compose Routing Issues,2017-11-25 13:16:55,<nginx><docker-compose><uri><microservices>,1,70,0,0.0,0,"<p>I have a docker compose file comprising of two microservices that I want to leverage URI routing for in order to handle CORS. Here is my compose file:</p>&#xA;&#xA;<pre><code>version: ""3.1""&#xA;services:&#xA;  auth-api:&#xA;    image: xxxx/auth-api:latest&#xA;    restart: always&#xA;    depends_on:&#xA;      - ""user-api""&#xA;  user-api:&#xA;    image: xxxx/user-api:latest&#xA;    restart: always&#xA;nginx:&#xA;    image: nginx&#xA;    restart: always&#xA;    ports:&#xA;      - ""80:80""&#xA;    links:&#xA;      - ""auth-api""&#xA;      - ""user-api""&#xA;    volumes:&#xA;       - ./nginx:/etc/nginx&#xA;</code></pre>&#xA;&#xA;<p>I want to use NGINX for the routing but am running into issues with 404's or 405's when trying to access the resources. I've tried several different configurations and for a while NGINX was saying it couldn't find the api endpoints when it started which I resolved so I think my issue is mostly around routing configuration. I want it to be <code>/auth</code> and <code>/user</code> for those requests.</p>&#xA;&#xA;<pre><code>worker_processes 1;&#xA;&#xA;events { worker_connections 1024; }&#xA;&#xA;http {&#xA;&#xA;    sendfile on;&#xA;&#xA;    upstream auth-target {&#xA;      server auth-api:8080;&#xA;    }&#xA;&#xA;    upstream user-target {&#xA;        server user-api:8080;&#xA;    }&#xA;&#xA;    server {&#xA;        listen       80;&#xA;&#xA;        location /auth {&#xA;&#xA;            proxy_pass http://auth-target;&#xA;&#xA;            proxy_redirect     off;&#xA;            proxy_set_header   Host $host;&#xA;            proxy_set_header   X-Real-IP $remote_addr;&#xA;            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;&#xA;            proxy_set_header   X-Forwarded-Host $server_name;&#xA;        }&#xA;&#xA;        location /user {&#xA;&#xA;            proxy_pass  http://user-target;&#xA;&#xA;            proxy_redirect     off;&#xA;            proxy_set_header   Host $host;&#xA;            proxy_set_header   X-Real-IP $remote_addr;&#xA;            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;&#xA;            proxy_set_header   X-Forwarded-Host $server_name;&#xA;        }&#xA;&#xA;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm pretty new to NGINX so I'm not sure if what I'm doing is right. I should also note that both APIs have 8080 exposed as part of the container build.</p>&#xA;"
47427629,Messaging Between Services Events vs Commands,2017-11-22 05:47:23,<c#><microservices><masstransit><saga><automatonymous>,1,339,0,1.0,0,"<p>I am trying to understand different methods used in messaging between services.</p>&#xA;&#xA;<p>Let us say that I have a scenario where I need first service to notify the other that a user has asked for product creation, and the second service should receive this message, create a product and then respond telling the first service that a product has been created.</p>&#xA;&#xA;<p>I am thinking that commands along with request/respond suits this scenario because the first service will need to address another specific &#xA;service and will wait for feedback.</p>&#xA;&#xA;<p>My understanding is that:</p>&#xA;&#xA;<p>Events vs commands:</p>&#xA;&#xA;<p><strong>Events:</strong></p>&#xA;&#xA;<ul>&#xA;<li>provide loose coupling between the services.</li>&#xA;<li>perform publishing to all queues and the services interested in such message will pick it.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Commands:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>perform sending to a specific queue hence only the services that receive using that queue will consume it.</li>&#xA;</ul>&#xA;&#xA;<p>Request/Respond vs Publish/Subsribe:</p>&#xA;&#xA;<p><strong>Request/Respond:</strong></p>&#xA;&#xA;<p>In Request/Respond the first service requests from the other to perform an operation and waits until respond is returned from the later.</p>&#xA;&#xA;<p><strong>Publish/Subscribe:</strong></p>&#xA;&#xA;<p>First service just publish a message and continue processing without waiting for feedback or response.</p>&#xA;&#xA;<p>Now I started to design the messaging system using RabbitMQ along with Masstransit saga (Masstransit.Automatonymous) which seems to follow Events with publish/subscribe methods.</p>&#xA;&#xA;<p>My Question is:</p>&#xA;&#xA;<p>can I use commands with publishing or events with request/respond?</p>&#xA;&#xA;<p>Is my understanding correct? and can sagas be used with request/response?</p>&#xA;"
47379427,How to consume response of one rest api in another rest API java Microservices?,2017-11-19 16:54:09,<java><rest><spring-mvc><microservices>,2,1458,0,0.0,0,"<p>I have 2 micro services running :-</p>&#xA;&#xA;<pre><code>1] user &#xA;   running on tomcat port :8081,&#xA;   database name:  user.&#xA;2] order&#xA;   running on tomcat port :8082,&#xA;   database name:  order.&#xA;</code></pre>&#xA;&#xA;<p>I have a REST API in order micro service as shown below:-</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/order/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;    public List registerCustomer() {&#xA;    List list=new ArrayList();&#xA;    list.add(""aaa"");&#xA;    list.add(""aab"");&#xA;    return list;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>now How can I consume this micro in user</p>&#xA;&#xA;<pre><code>  @RequestMapping(value = ""/user/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;&#xA;   // need to call REST API /order/getdetail and return list&#xA;    }   &#xA;</code></pre>&#xA;&#xA;<p>As I am new to micro services I am not aware of to communicate between micros?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47474453,REST Communication between microservices - Abstract away from host or port in REST call,2017-11-24 13:36:01,<angular><rest><spring-boot><microservices>,2,230,0,0.0,0,"<p>I just started diving into the microservices topic, so please excuse if this is a stupid question. </p>&#xA;&#xA;<p>Let's say I have two microservices, one providing a REST api and one being an angular microservice for a nice frontend. The angular microservice is expected to communicate with the other microservice.&#xA;I saw many examples implementing this and its basically not a big deal. I am well aware of that. However, in all these examples I saw something like this in the angular microservice:</p>&#xA;&#xA;<pre><code>this.http.get('http://....:8080....');&#xA;</code></pre>&#xA;&#xA;<p>At first I was just happy to get it running. However, right now I am wondering whether such implementations do not tightly couple the services to each other. In the http URL, we see the host and the port is also fix. That might work well in some cases, but, if our microservice e.g. chooses a port dynamically, we already have a problem right? Then we can't define the port in the other microservice in such a way. The same holds for the host information. If the microservice might be running on different hosts, we cannot always just define the host statically.</p>&#xA;&#xA;<p>Please correct me if I'm wrong. Is there any way we can abstract away from these details, i.e. the host or the port but is there another way to find this out dynamically? Or are there other good alternatives for the communication between microservices that don't imply this problem?</p>&#xA;&#xA;<p>I saw examples of services using a service registry. By means of this, we can abstract away from this a bit - no? Is this the only possibility? I am not sure whether this is relevant here, but so far I'm using Spring Boot to implement my microservices.</p>&#xA;"
47515021,Adding D3 librarie to Jhipster gateway,2017-11-27 15:58:20,<angular><d3.js><package><jhipster><microservices>,1,112,1,0.0,0,"<p>i want to add D3.js in the JHipster's gateway's project that i'm developing.&#xA;I used the command ""yarn add d3"" to add the library in node_modules folder and in the package.json.&#xA;This is the content of package.json :</p>&#xA;&#xA;<pre><code>  {&#xA;  ""name"": ""blog"",&#xA;  ""version"": ""0.0.0"",&#xA;  ""description"": ""Description for blog"",&#xA;  ""private"": true,&#xA;  ""license"": ""UNLICENSED"",&#xA;  ""cacheDirectories"": [&#xA;    ""node_modules""&#xA;  ],&#xA;  ""dependencies"": {&#xA;    ""@angular/common"": ""4.3.2"",&#xA;    ""@angular/compiler"": ""4.3.2"",&#xA;    ""@angular/core"": ""4.3.2"",&#xA;    ""@angular/forms"": ""4.3.2"",&#xA;    ""@angular/http"": ""4.3.2"",&#xA;    ""@angular/platform-browser"": ""4.3.2"",&#xA;    ""@angular/platform-browser-dynamic"": ""4.3.2"",&#xA;    ""@angular/router"": ""4.3.2"",&#xA;    ""@ng-bootstrap/ng-bootstrap"": ""1.0.0-beta.5"",&#xA;    ""bootstrap"": ""4.0.0-beta"",&#xA;    ""core-js"": ""2.4.1"",&#xA;    ""d3"": ""^4.12.0"",&#xA;    ""font-awesome"": ""4.7.0"",&#xA;    ""jquery"": ""3.2.1"",&#xA;    ""ng-jhipster"": ""0.2.12"",&#xA;    ""ng2-webstorage"": ""1.8.0"",&#xA;    ""ngx-cookie"": ""1.0.0"",&#xA;    ""ngx-infinite-scroll"": ""0.5.1"",&#xA;    ""reflect-metadata"": ""0.1.10"",&#xA;    ""rxjs"": ""5.4.2"",&#xA;    ""swagger-ui"": ""2.2.10"",&#xA;    ""tether"": ""1.4.0"",&#xA;    ""zone.js"": ""0.8.16""&#xA;  },&#xA;  ""devDependencies"": {&#xA;    ""@angular/cli"": ""1.4.2"",&#xA;    ""@angular/compiler-cli"": ""4.3.2"",&#xA;    ""@types/jasmine"": ""2.5.53"",&#xA;    ""@types/node"": ""8.0.18"",&#xA;    ""angular2-template-loader"": ""0.6.2"",&#xA;    ""awesome-typescript-loader"": ""3.2.2"",&#xA;    ""browser-sync"": ""2.18.13"",&#xA;    ""browser-sync-webpack-plugin"": ""1.2.0"",&#xA;    ""codelyzer"": ""3.1.2"",&#xA;    ""copy-webpack-plugin"": ""4.0.1"",&#xA;    ""css-loader"": ""0.28.4"",&#xA;    ""exports-loader"": ""0.6.4"",&#xA;    ""extract-text-webpack-plugin"": ""3.0.0"",&#xA;    ""file-loader"": ""0.11.2"",&#xA;    ""generator-jhipster"": ""4.10.2"",&#xA;    ""html-loader"": ""0.5.0"",&#xA;    ""html-webpack-plugin"": ""2.30.1"",&#xA;    ""jasmine-core"": ""2.7.0"",&#xA;    ""karma"": ""1.7.1"",&#xA;    ""karma-chrome-launcher"": ""2.2.0"",&#xA;    ""karma-coverage"": ""1.1.1"",&#xA;    ""karma-intl-shim"": ""1.0.3"",&#xA;    ""karma-jasmine"": ""1.1.0"",&#xA;    ""karma-junit-reporter"": ""1.2.0"",&#xA;    ""karma-notify-reporter"": ""1.0.1"",&#xA;    ""karma-remap-istanbul"": ""0.6.0"",&#xA;    ""karma-sourcemap-loader"": ""0.3.7"",&#xA;    ""karma-webpack"": ""2.0.4"",&#xA;    ""merge-jsons-webpack-plugin"": ""1.0.11"",&#xA;    ""ngc-webpack"": ""3.2.2"",&#xA;    ""node-sass"": ""4.5.3"",&#xA;    ""postcss-loader"": ""2.0.6"",&#xA;    ""proxy-middleware"": ""0.15.0"",&#xA;    ""puppeteer"": ""^0.13.0"",&#xA;    ""rimraf"": ""2.6.1"",&#xA;    ""sass-loader"": ""6.0.6"",&#xA;    ""sourcemap-istanbul-instrumenter-loader"": ""0.2.0"",&#xA;    ""string-replace-webpack-plugin"": ""0.1.3"",&#xA;    ""style-loader"": ""0.18.2"",&#xA;    ""to-string-loader"": ""1.1.5"",&#xA;    ""tslint"": ""5.5.0"",&#xA;    ""tslint-loader"": ""3.5.3"",&#xA;    ""typescript"": ""2.5.2"",&#xA;    ""uglifyjs-webpack-plugin"": ""1.0.0-beta.2"",&#xA;    ""web-app-manifest-loader"": ""0.1.1"",&#xA;    ""webpack"": ""3.6.0"",&#xA;    ""webpack-dev-server"": ""2.8.2"",&#xA;    ""webpack-merge"": ""4.1.0"",&#xA;    ""webpack-notifier"": ""1.5.0"",&#xA;    ""webpack-visualizer-plugin"": ""0.1.11"",&#xA;    ""write-file-webpack-plugin"": ""4.1.0"",&#xA;    ""xml2js"": ""0.4.17""&#xA;  },&#xA;  ""engines"": {&#xA;    ""node"": ""&gt;=6.9.0""&#xA;  },&#xA;  ""scripts"": {&#xA;    ""lint"": ""tslint --type-check --project './tsconfig.json' -e 'node_modules/**'"",&#xA;    ""lint:fix"": ""yarn run lint -- --fix"",&#xA;    ""ngc"": ""ngc -p tsconfig-aot.json"",&#xA;    ""cleanup"": ""rimraf target/{aot,www}"",&#xA;    ""clean-www"": ""rimraf target//www/app/{src,target/}"",&#xA;    ""start"": ""yarn run webpack:dev"",&#xA;    ""serve"": ""yarn run start"",&#xA;    ""build"": ""yarn run webpack:prod"",&#xA;    ""test"": ""karma start src/test/javascript/karma.conf.js"",&#xA;    ""test:watch"": ""yarn test -- --watch"",&#xA;    ""webpack:dev"": ""yarn run webpack-dev-server -- --config webpack/webpack.dev.js --progress --inline --hot --profile --port=9060 --watch-content-base"",&#xA;    ""webpack:build:main"": ""yarn run webpack -- --config webpack/webpack.dev.js --progress --profile"",&#xA;    ""webpack:build"": ""yarn run cleanup &amp;&amp; yarn run webpack:build:main"",&#xA;    ""webpack:prod:main"": ""yarn run webpack -- --config webpack/webpack.prod.js --progress --profile"",&#xA;    ""webpack:prod"": ""yarn run cleanup &amp;&amp; yarn run webpack:prod:main &amp;&amp; yarn run clean-www"",&#xA;    ""webpack:test"": ""yarn run test"",&#xA;    ""webpack-dev-server"": ""node --max_old_space_size=4096 node_modules/webpack-dev-server/bin/webpack-dev-server.js"",&#xA;    ""webpack"": ""node --max_old_space_size=4096 node_modules/webpack/bin/webpack.js""&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As you can see there is ""d3"": ""^4.12.0"" dependencie, but now i don't know how to include it in the project.&#xA;I'm using Angular 4.3.2.&#xA;Can you help me please??</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
47461815,how to design microservices with less network hops,2017-11-23 18:48:51,<design><microservices>,1,143,2,0.0,0,"<p>We have a couple of microservices A and B, each is an independent module with its own code and its own database, C* and Oracle. </p>&#xA;&#xA;<p>Service B has multiple tables - T1, T2, T3.</p>&#xA;&#xA;<p>For each POST request in Service A, it has to contact Service B to get some meta information from table T1 only. Since, service A is in a critical path and has a very heavy traffic, getting information from Service B for every single POST call is going to be a bottle neck.</p>&#xA;&#xA;<p>I was thinking of 2 options:</p>&#xA;&#xA;<ol>&#xA;<li>Caching data hosted in Service B on Service A, so the information can be fetched from a cache as it will be faster - the strong consistency is another other business requirement and there is a risk that we might use stale data from the cache.</li>&#xA;<li>Moving the information in T1 completely to Service A so it doesn't have to make a network hop - the problem with this approach is Service B has transactional boundaries during data creation that will affect T1, T2, T3 so all the data in Service B should stay together.</li>&#xA;</ol>&#xA;&#xA;<p>Is there a better way to design this kind of a high consistency system still being able to scale?</p>&#xA;&#xA;<p>Thanks and Regards</p>&#xA;"
47348422,Throw Exception through multiple services,2017-11-17 10:24:01,<spring><rest><spring-boot><microservices>,1,65,4,0.0,0,<p>I have a little microservice architecture with 3 depending services. Each service represents a seperate Spring Boot project. If an exception occurs on the lowest level of the architecture I would like to throw it through all other services up to the highest/user endpoint service.</p>&#xA;&#xA;<p>Each service API returns a <strong>HttpEntity(Response Entity)</strong> including a specific object. I found a lot of possible solutions like <strong>ResponseEntityExceptionHandlers</strong> but all examples shown for a single service architecture without multiple depending services.</p>&#xA;&#xA;<p>Are there any best practices how to throw an Exception through multiple services with Spring Boot?</p>&#xA;
45177029,Wildfly Swarm error connecting Postgres datasource on Docker container,2017-07-18 21:03:37,<java><jpa><docker><wildfly><microservices>,1,266,0,0.0,0,"<p>I am trying to build a simple rest service using Wildfly Swarm, Docker and PostgreSQL as database.</p>&#xA;&#xA;<p>The application works well on localhost (without docker).</p>&#xA;&#xA;<p>I am having problems to connect the database using a data source on docker infrastructure</p>&#xA;&#xA;<p>This is my <code>docker.compose.yml</code>:</p>&#xA;&#xA;<pre><code>version: '3'&#xA;&#xA;services:&#xA;&#xA;  web:&#xA;    build: .&#xA;    depends_on:&#xA;      - db&#xA;&#xA;  db:&#xA;    build: ./db&#xA;    ports:&#xA;      - ""5432:5432""&#xA;</code></pre>&#xA;&#xA;<p>My Web <code>Dockerfile</code>:</p>&#xA;&#xA;<pre><code>FROM fabric8/java-jboss-openjdk8-jdk:1.2.3&#xA;&#xA;ENV AB_OFF true&#xA;&#xA;ADD megasindico-billing-api-swarm.jar /opt/megasindico-billing-api-swarm.jar&#xA;&#xA;EXPOSE 8080&#xA;&#xA;ENTRYPOINT [""java"", ""-jar"", ""/opt/megasindico-billing-api-swarm.jar""]&#xA;</code></pre>&#xA;&#xA;<p>PostgreSQL <code>Dockerfile</code>:</p>&#xA;&#xA;<pre><code>FROM postgres:9.4-alpine&#xA;&#xA;ENV POSTGRES_USER=admin&#xA;ENV POSTGRES_PASSWORD=admin&#xA;</code></pre>&#xA;&#xA;<p><code>project-defaults.yml</code> is where is configure my DataSource:</p>&#xA;&#xA;<pre><code>swarm:&#xA;  datasources:&#xA;    data-sources:&#xA;      ### [datasource]&#xA;      megasindico-billing-ds:&#xA;        driver-name: postgresql&#xA;        connection-url: jdbc:postgresql://db/postgres&#xA;        user-name: admin&#xA;        password: admin&#xA;</code></pre>&#xA;&#xA;<p>And heres how the <code>persistence.xml</code> looks like:</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;persistence version=""2.1"" xmlns=""http://xmlns.jcp.org/xml/ns/persistence"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd""&gt;&#xA;&#xA;    &lt;persistence-unit name=""megasindico-billing-ds"" transaction-type=""RESOURCE_LOCAL""&gt;&#xA;&#xA;        &lt;provider&gt;org.hibernate.ejb.HibernatePersistence&lt;/provider&gt;&#xA;&#xA;        &lt;properties&gt;&#xA;            &lt;property name=""hibernate.hbm2ddl.auto"" value=""create-drop"" /&gt;&#xA;            &lt;property name=""hibernate.show_sql"" value=""true"" /&gt;&#xA;            &lt;property name=""hibernate.dialect"" value=""org.hibernate.dialect.PostgreSQLDialect"" /&gt;&#xA;            &lt;property name=""hibernate.hbm2ddl.import_files"" value=""scripts/reset.sql""/&gt;&#xA;            &lt;property name=""hibernate.connection.useUnicode"" value=""true"" /&gt;&#xA;            &lt;property name=""hibernate.connection.characterEncoding"" value=""UTF-8"" /&gt;&#xA;        &lt;/properties&gt;&#xA;&#xA;    &lt;/persistence-unit&gt;&#xA;&#xA;&lt;/persistence&gt;&#xA;</code></pre>&#xA;&#xA;<p>The app is built using <code>mvn clean package</code> command. </p>&#xA;&#xA;<p>To build the images I use a <code>build.sh</code> file:</p>&#xA;&#xA;<pre><code>#!/usr/bin/env bash&#xA;&#xA;# Copy jar file to this directory&#xA;cp ../target/megasindico-billing-api-swarm.jar megasindico-billing-api-swarm.jar&#xA;&#xA;# Build Docker image&#xA;docker-compose build&#xA;&#xA;# Remove temp file&#xA;rm -rf megasindico-billing-api-swarm.jar&#xA;</code></pre>&#xA;&#xA;<p>After that I execute <code>docker-compose up</code> command to get images running.</p>&#xA;&#xA;<p>The errors I get are these:&#xA;<a href=""https://i.stack.imgur.com/gfOHp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gfOHp.png"" alt=""error part 1""></a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/YrzL9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YrzL9.png"" alt=""error part 2""></a></p>&#xA;"
45179621,MicroServices Architecture,2017-07-19 01:37:15,<java><scala><lambda><soa><microservices>,1,314,0,0.0,0,"<p>I have few questions related to MicroServices Architecture. </p>&#xA;&#xA;<ul>&#xA;<li><p>What should be the granularity of the MicroServices? We have tables in both Relational and NoSQL Databases. Should there be one service per table? I think services per datasource would make more sense, but then it would be SOA. </p></li>&#xA;<li><p>If we create bunch of MicroServices, should we also provide client libraries to facilitate consumption of services? Or just let caller use any REST library to make calls. One way or another, it sounds a lot of work though. </p></li>&#xA;<li><p>Should three be one GIT repo for each MicroService? </p></li>&#xA;<li><p>Is it ok to deploy multiple MicroServices in same EC2 instance? </p></li>&#xA;<li><p>I would imagine deploying MicroServices on AWS Lambda would be perfect, but then the whole application would be just bunch of Lambda functions. Not to mention the tight coupling with AWS Lambdas. Has anyone implemented MicroServices on Lambdas? I'd appreciate any feedback on this.</p></li>&#xA;</ul>&#xA;"
45270940,How should I expose my API URL on a Docker Swarm cluster?,2017-07-23 23:53:49,<docker><docker-compose><microservices><docker-swarm>,1,385,0,0.0,0,"<p>So, I'm starting to play with docker, so far so good, but I got this question on my head. </p>&#xA;&#xA;<p>Having this two statements in mind (please also correct me if I am misunderstanding something):</p>&#xA;&#xA;<p>1) Docker Swarm provides out of the box service discovering, meaning micro services can talk to each other on the same network by service name without actually knowing on which hosts the other services are allocated.</p>&#xA;&#xA;<p>2) Services instances are ephemeral, so a service can be hosted by different machines in a swarm lifespan.</p>&#xA;&#xA;<p>How should I know which ip adress should expose as a central API gateway service, for instance?</p>&#xA;"
45301606,Consul - service detection Microservice/Domain architecture,2017-07-25 11:13:55,<c#><rest><microservices><consul>,1,156,0,0.0,0,"<p>I'm having a Microservice (MS)/Doamin (D) architecture where each MS/D service has its own rest api. I have been looking into using Consul for service detection but I cant figure out how to use it because. I have followed the documentation but it cant find how to use Consul in MS/D architecture where all MS/D has more than one rest endpoint...</p>&#xA;&#xA;<p>In documentation it feels like you are registrating a plain ""service host"" you are not registering a service endpoint like ""mydomain.com:8080/api// you are just registering ""mydomain.com:8080/ i.e the host running the service. It feels like I have missed something but I really cant figure out how to register rest-api urls using Consul. I'm using Consul.NET (<a href=""https://github.com/PlayFab/consuldotnet"" rel=""nofollow noreferrer"">https://github.com/PlayFab/consuldotnet</a>) and my setup for registering a Microservice is:</p>&#xA;&#xA;<pre><code>var client = GetServiceClient();&#xA;var httpCheck = new AgentServiceCheck()&#xA;{&#xA;  DeregisterCriticalServiceAfter = TimeSpan.FromMinutes(1),&#xA;  Interval = TimeSpan.FromSeconds(15),&#xA;  HTTP = $""http://{host}:{microservicePort.ToString()}/healthcheck/""&#xA;};&#xA;&#xA;var agentReg = new AgentServiceRegistration()&#xA;{&#xA;  Checks = new[] { httpCheck },&#xA;  Address = &lt;serviceIp&gt;,&#xA;  ID = microServiceUniqueIdentifier,&#xA;  Name = &lt;servicename&gt;,&#xA;  Port = microservicePort,&#xA;};&#xA;</code></pre>&#xA;&#xA;<p>How can I register all rest api endpoints for 1 Microservice like:</p>&#xA;&#xA;<pre><code>&lt;microservice1&gt;/api/&lt;entity&gt;/&lt;api-service1&gt; with &lt;servicename&gt; ms1_service1 &#xA;&lt;microservice1&gt;/api/&lt;entity&gt;/&lt;api-service2&gt; with &lt;servicename&gt; ms1_service2 &#xA;&lt;microservice1&gt;/api/&lt;entity&gt;/&lt;api-service3&gt; with &lt;servicename&gt; m1s_service3&#xA;</code></pre>&#xA;&#xA;<p>so another MS/D service can ask Consul get me rest-endpoint for ms1_service3</p>&#xA;&#xA;<p>If I cant do this the ""know how"" of how service endpoint look like must be in calling system which feels wrong so... It feels like I have missed some fundamental things here. </p>&#xA;&#xA;<p>I have also been looking into usin KV to store rest-api-endpoints but because its key value you only can register 1 service per key value so if I have 10 MS of one kind only 1 kan be stored in current ""key"" value.</p>&#xA;&#xA;<p>Would be very happy if someone could help me to explain best practice for how to use Consul in combination with MS/D-rest endpoints</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
45212821,Project structure and configuration for microservices,2017-07-20 11:01:47,<spring><spring-boot><microservices>,2,425,0,0.0,0,"<p>Please ignore English grammar.</p>&#xA;&#xA;<p>For Learning purpose I want to create a microservice project in Spring and I download some sample project and now I have some very basic&#xA;idea of microservices. But I am confused how I start my own project.&#xA;I want to implement the following simple use case.</p>&#xA;&#xA;<p>In my database I have three table&#xA;Product, &#xA;ProductStock&#xA;and Order and I want to write microservice for each table.</p>&#xA;&#xA;<p>Product microservice will have end point for crud operation.&#xA;ProductStock microservice will only have update stock and check stock end point.&#xA;Order microservice will only have posting order operation.</p>&#xA;&#xA;<p>I create a multi module maven project and now I have following question.</p>&#xA;&#xA;<p>1: Is creating multi module maven project is the only way to create microservices project. </p>&#xA;&#xA;<p>2: I am using Hibernate so in which module(microservice) I create model classes. I need model classes in every module(microservice).&#xA;    (Model classes are Product, ProductStock and Order).</p>&#xA;&#xA;<p>3: Where I set hibernate confiuration.</p>&#xA;"
45174891,"With Spring Cloud Stream, should I config channels for every event type?",2017-07-18 18:52:19,<apache-camel><messaging><microservices><spring-cloud-stream><event-driven-design>,2,198,0,0.0,0,"<p>I'm working on a project using springboot, spring cloud netflix, etc., to build microservices.</p>&#xA;&#xA;<p>And for some of the async communication, I'm using Spring Cloud Stream to produce and consume events. e.g. After a business contract is drafted in the contract-service, the service publish a contract-created-event, which will be consume by auditing-service, to init a auditing process. And also, user-service will consume the event to create notifications for related parties.</p>&#xA;&#xA;<p>The scenario is I have many events, consumer will subscribe the interested events based on event types.&#xA;The problem I have is, I have many event-types, soon, my configuration file is flooded with the channel configurations. e.g.</p>&#xA;&#xA;<pre><code>spring.cloud.stream.bindings.creation.destination=contract-creation&#xA;spring.cloud.stream.bindings.revocation.destination=contract-revocation&#xA;spring.cloud.stream.bindings.termination.destination=contract-termination&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>I'm doing something wrong? I'm considering those alternatives:</p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://dturanski.wordpress.com/2017/03/26/spring-cloud-stream-for-event-driven-architectures/"" rel=""nofollow noreferrer"">David Turanski</a>! has a example which will selectively consume the event by type. Which is a good solution, but I'm thinking, Is Spring Cloud Stream have the native solution?</li>&#xA;<li>Should I use Apache Camel or Spring Integration? I don't have complicated routing rules, these frameworks seem like an overkill.</li>&#xA;</ol>&#xA;&#xA;<p>I'm quite a newbie in messaging, hoping folks here could point me to a right direction.</p>&#xA;"
45278205,Spring microservice registered but getting UnknownHostException,2017-07-24 10:29:24,<java><spring><spring-boot><microservices><resttemplate>,1,198,0,0.0,0,"<p>I've got an issue with calling my microservice.</p>&#xA;&#xA;<p>I run the server, and my microservice registers correctly:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/UfPlv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UfPlv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But when I try and call a method in microservice, it fails with <code>UnknownHostException</code>.</p>&#xA;&#xA;<p>This is how my <code>RestTemplate</code> and <code>MsImageService</code> beans are made:</p>&#xA;&#xA;<pre><code>@Configuration&#xA;@EnableAsync&#xA;@EnableGlobalMethodSecurity(prePostEnabled = true)&#xA;public class MvcConfig extends WebMvcConfigurerAdapter {&#xA;&#xA;    @Bean&#xA;    @LoadBalanced&#xA;    public RestTemplate restTemplate() {&#xA;            return new RestTemplate();&#xA;    }&#xA;&#xA;    @Bean&#xA;    public MsImageService msImageService() {&#xA;            return new MsImageService(""http://IMAGES-MICROSERVICE"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And this is how I autowire it in my service: </p>&#xA;&#xA;<pre><code>@Autowired&#xA;@LoadBalanced&#xA;private RestTemplate restTemplate;&#xA;</code></pre>&#xA;&#xA;<p>These are the properties I use on my <strong>server</strong>:</p>&#xA;&#xA;<pre><code>server.port=8761&#xA;&#xA;spring.thymeleaf.enabled=false&#xA;&#xA;eureka.instance.hostname=localhost&#xA;eureka.client.register-with-eureka=false&#xA;eureka.client.fetch-registry=false&#xA;eureka.client.service-url.default-zone=http://${eureka.instance.hostname}:${server.port}/eureka/&#xA;&#xA;logging.level.com.netflix.eureka=INFO&#xA;logging.level.com.netflix.discovery=INFO&#xA;</code></pre>&#xA;&#xA;<p>And this is the properties in my <strong>service</strong>:</p>&#xA;&#xA;<pre><code>spring.application.name=images-microservice&#xA;spring.freemarker.enabled=false&#xA;spring.thymeleaf.enabled=false&#xA;security.basic.enabled=false&#xA;eureka.instance.instance-id=${spring.application.name}&#xA;eureka.client.service-url.default-zone=http://localhost:8761/eureka/&#xA;server.port=2222&#xA;logging.level.com.netflix.eureka=INFO&#xA;logging.level.com.netflix.discovery=INFO&#xA;</code></pre>&#xA;&#xA;<p>Any help is appreciated!</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
45145109,How can I configure gradle to start and stop spring boot microservices that stay alive after build completion?,2017-07-17 13:05:03,<spring-boot><gradle><microservices>,1,215,0,0.0,0,"<p>I'm developing an application server that relies on two emulators configured as spring boot microservices. We've recently extracted the emulators from the root project into a separate repository, as they're being used by some other projects as well, and this works a little nicer for inter-project maintenance. I would like to be able to run these emulators from the main project root, as opposed to having to check out their repository and run from that directory. We do something like this for our gradle integration tests - we're using ExecFork (<a href=""https://github.com/psxpaul/gradle-execfork-plugin"" rel=""nofollow noreferrer"">https://github.com/psxpaul/gradle-execfork-plugin</a>) to fire up the two processes. The problem here is that the processes die when the build completes.</p>&#xA;&#xA;<p>What I'm looking for is something similar to this, so that I can run e.g. <code>./gradlew startEmulators</code> and have both emulators check out the specified version and either block the gradle task (taking up the command window, ctrl-c to stop) or outlive the gradle task. The ability to stop them would be handy as well, but that's a would-like rather than a must-have at this point.</p>&#xA;&#xA;<p>I'll take solutions alternative to gradle too, but preferably nothing too complicated - this needs to be something that I can fairly simply blast out instructions for to the dev team</p>&#xA;"
45334075,JHipster microservices entities,2017-07-26 17:45:12,<jhipster><microservices>,1,266,1,0.0,0,"<p>I read the <a href=""https://www.thoughtworks.com/insights/blog/bff-soundcloud"" rel=""nofollow noreferrer"">BFF pattern</a> and I have a doubt, if one microservice is only for iOS and other microservice is only for Android, how must be created the entities if that two services use the same database and the same tables?</p>&#xA;&#xA;<p>I'm trying to use the JDL-Studio and importing the model with import-idl command but I don't know if the command must run in every micro service's workspace</p>&#xA;&#xA;<p>Edit:</p>&#xA;&#xA;<p>For more context, I want to build a full stack application that could have a lot of concurrency from a web page, iOS and Android applications with REST calls and I don't know if correct to repeat the entities in every microservices (to have separated the API for every plataform) or add just one microservices as database layer.</p>&#xA;&#xA;<p>Edit 2:&#xA;I found this <a href=""https://developer.okta.com/blog/2017/06/20/develop-microservices-with-jhipster"" rel=""nofollow noreferrer"">blog</a> talking about create jhipster applications with microservices and this guy show how the gateway have they own entities and the microservices have they own too..</p>&#xA;&#xA;<p>now, I have more clear the real base of the microservices architecture but what if I want a microservice with the all entities and the gateway with only the UI entities? the blog show how could be this but with just one entity and I have a full model.jhl with the all entities </p>&#xA;"
45176450,How do I handle OAuth2 in back-end microservices and front-end?,2017-07-18 20:27:03,<spring-boot><oauth-2.0><frontend><backend><microservices>,1,113,1,0.0,0,"<p>Iâ€™m developing back-end services and securing it using my custom OAuth server. At front-end Iâ€™m planning to support facebook, google and username and password OAuth. How can I implement this using spring boot ?</p>&#xA;"
45170527,Microservices Deployment,2017-07-18 15:03:05,<microservices>,2,116,1,0.0,0,<p>I have:</p>&#xA;&#xA;<p>Microservice-A&#xA;Microservice-B&#xA;Microservice-C</p>&#xA;&#xA;<p>Microservice-A calls Microservice-B and Microservice-C</p>&#xA;&#xA;<p>When I deploy Microservice-A I want make sure that other microservices it depends on have not changed since I last release it.</p>&#xA;&#xA;<p>Is there a recommended way to do this?</p>&#xA;&#xA;<p>I'm thinking:</p>&#xA;&#xA;<ul>&#xA;<li>when I deploy Microservice-A</li>&#xA;<li>Microservice-A makes calls to Microservice-B and Microservice-C</li>&#xA;<li>this call would fetch the endpoint specification for the endpoints it depends on and verify whether the endpoints have changed (in a  way that would break Microservice-A) since last release.</li>&#xA;</ul>&#xA;&#xA;<p>This should happen before I interrupt the currently running Microservice-A just before deployment procedure commences.</p>&#xA;&#xA;<p>Sure can do testing but that would be too late in my view. I'm looking for an automated way to verify this before deployment.  </p>&#xA;&#xA;<p>Has anyone done anything like this before?  What tooling can be used for this?</p>&#xA;
45325062,Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams?,2017-07-26 11:03:53,<jvm><microservices><datacontract><pact>,3,117,1,1.0,0,<p>Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams ?</p>&#xA;
45326767,Understanding Event Driven Microservices,2017-07-26 12:17:00,<microservices><event-driven-design>,1,128,1,1.0,0,"<p>So I've been doing some research around Event Driven design for Microservice architecture to help decouple some of the microservices I've been helping develop. Currently the problem I've been running into is that each microservice is calling other microservices directly for data which seems to be tightly coupling them and is outlined in the following article:</p>&#xA;&#xA;<p><a href=""https://thenewstack.io/synchronous-rest-turns-microservices-back-monoliths/"" rel=""nofollow noreferrer"">https://thenewstack.io/synchronous-rest-turns-microservices-back-monoliths/</a></p>&#xA;&#xA;<p>So event driven architecture seems to help with the overall design but where I get confused at is how would a GET request work for data if the API that is called needs data from another service? Would it post a request into a bus and subscribe for an answer? Do you just have to wait then for a response possibly delaying the response to the consumer? </p>&#xA;&#xA;<p>Or is this a case where you would need to call another API directly? Any resources would be very much appreciated.</p>&#xA;"
45203055,Microservice architecture,2017-07-20 00:11:39,<architecture><microservices><apache-nifi><distributed-system>,1,186,2,0.0,0,"<p>We have multiple separate applications written in Java,C#,nodeJS and python. All these application share a common property - they pull data from some source based on schedule per customer basis using REST API and store it in CSV file, later import data from CSV file to different SQL database using stored procs. Each application is used to integrate data from different third party service.</p>&#xA;&#xA;<p>For example - app A fetching data from source A' and app B fetching data from source B' </p>&#xA;&#xA;<p>I'm thinking of replacing these multiple separate applications by writing one multi-tenant single application which can handle pulling data from different sources. All these separate small applications will be configured as a custom job written in Java. For example - REST API authentication, pre-processing of data before creating CSV etc.</p>&#xA;&#xA;<p>So, I want to write a job (Java file) that fetches data from source A' and another job that fetches data from source B'. The main application will execute this custom job. The common functionality such as job scheduling, logging etc will be supported by the main application.</p>&#xA;&#xA;<p>Later I intend to use nifi to handle data import from CSV to SQL database.</p>&#xA;&#xA;<p>Will this be a good approach? I'm planning to write this application in Java.</p>&#xA;&#xA;<h3>Reason behind the solution</h3>&#xA;&#xA;<ul>&#xA;<li>Multiple code base to maintain</li>&#xA;<li>No concurrency in pulling data</li>&#xA;<li>All these applications are deployed as a single instance</li>&#xA;</ul>&#xA;&#xA;<p>If I need to update one job I need to deploy the whole application. How to get around this process? Is there any way I can deploy just the job and not the whole application?</p>&#xA;&#xA;<p>What would be the good way to architect this solution?</p>&#xA;"
45174699,jwt - Django-rest-framework-jwt authentication in microsevices,2017-07-18 18:42:36,<jwt><microservices>,1,163,3,0.0,0,"<p>I am newbie in JSON web token and micro services. I read in an articles that if i share the private, all services can verify user on their own. Then i tried to implement an application to practice.&#xA;Basically, I have two services A and B. A is used for authentication. Then, I tried implement a API that required authentication in service B. But when I used a token generated by authentication A in API, 401 status code and ""Invalid signature."" were returned. &#xA;So anyone can explain to me what I did wrong?</p>&#xA;"
40383122,Best approach docker,2016-11-02 14:57:47,<node.js><heroku><microservices>,1,31,0,0.0,0,"<p>I have an application with the following architecture microservices to implement. My question is how to use the docker:</p>&#xA;&#xA;<p>I must:&#xA;<a href=""https://i.stack.imgur.com/RLX90.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RLX90.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I see three scenarios and have no doubt that the most efficient:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/5LtKd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5LtKd.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>My service should be easy to scale because it is an application with significant amounts of requests, and your stay will be made at heroku, I wonder which of the three scenario will be more effective, I'm new to microservices and I have no idea what best approach.</p>&#xA;"
40429027,JHipster not throwing errors to UI when microservice fails,2016-11-04 17:56:45,<mongodb><jhipster><microservices><consul>,1,65,0,0.0,0,"<p>We are running JHipster microservice architecture using consul for service discovery. We have one micro service which connects to a docker instance of mongodb. While testing with the stock angular ui to save a new entity, we found that disabling the database does not throw an error in the UI. From the consul ui, I can see that the service is failing 1 of 2 health checks which will pass again when I re-enable the db.</p>&#xA;&#xA;<p>In the gateway logs, I have the following:&#xA;<code>Caused by: com.netflix.client.ClientException: Load balancer does not have available server for client: import</code></p>&#xA;&#xA;<p>I assume that consul is refusing to make the service available to gateway, but it seems there should be some way to configure  how gateway handles requests to unavailable services. Can anyone tell me where to look for this?</p>&#xA;"
40525468,Java 8 LocalDate displaying in swagger,2016-11-10 10:36:57,<java><documentation><swagger><microservices><swagger-2.0>,1,1693,0,0.0,0,"<p>I have a DTO which contains field of Java 8 LocalDate type. With Jackson annotations it's possible to set format to <code>ISO.DATE</code> and everything works good. But Swagger (I have version 2.+) see the <code>LocalDate.class</code> as object</p>&#xA;&#xA;<pre><code>LocalDate {&#xA;month (integer, optional),&#xA;year (integer, optional)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(That's true but...) I want to dipsay this as string with format as it works with <code>util.Date</code>.&#xA;How can I solve it?</p>&#xA;"
40436389,using entity in other jhipster microservice,2016-11-05 08:53:23,<jhipster><microservices>,2,673,0,0.0,0,"<p>I have problem to use entities between Microservices ,I have microservice1 has Team entity I need to use Team entity in microservice2 ,I mean I need to import TeamRepository.java in microservice2,How can do that with jhipster?</p>&#xA;"
40467382,how to use role authorization for micro services architecture?,2016-11-07 14:17:51,<ruby-on-rails><microservices><rails-api>,3,205,0,0.0,0,<p>I wrote an API in rails which is of micro services architecture.&#xA;In my API i need to implement Role authorization to authorize each and every user using their roles.&#xA;Is there any gem that fits into micro services architecture or should I write my own logic to authorize users.&#xA;i was using gem authorization gem but it does provide much capability that fits into micro services architecture.(rolify)&#xA;Is there any other that suits micro services architecture?</p>&#xA;&#xA;<p>Thanks in Advance.</p>&#xA;
40496999,Spring Boot - What's it got to do with microservices?,2016-11-08 21:47:08,<spring-boot><microservices>,1,70,1,0.0,0,"<p>Pardon my ignorance, but SpringBoot as far as I understand is an aid to set up a spring project.It simplifies dependency management by its opinionated view and takes away the pain associated with gathering all the dependencies on our own.&#xA;This apart it has a twist in the way it packages things up i.e it packages the container itself with my app(uber jar) and makes war deployment etc a thing of the past.This kind of blurs the line between a web-app and a non web-app in my opinion.</p>&#xA;&#xA;<p>From my understanding none of this is remotely related to micro-services but often I come across articles sounding like ""microservices with SpringBoot"". SpringBoot and microservices are used in the same breath giving one the notion that it is Spring's way of building in a microservices way?Isn't this wrong or am I missing something here?</p>&#xA;"
40469391,"Wait for condition in Enzyme and Jest (eventual consistency, assert with timeout)",2016-11-07 16:00:53,<reactjs><microservices><jestjs><enzyme>,1,431,4,0.0,0,"<p>I have a simple test:</p>&#xA;&#xA;<pre><code>import React from 'react';&#xA;import GenericButton from 'components/buttons/GenericButton';&#xA;import { shallow } from 'enzyme';&#xA;import { shallowToJson } from 'enzyme-to-json';&#xA;&#xA;describe('Generic Button', () =&gt; {&#xA;    test('Button action called when clicked', () =&gt; {&#xA;        var clicked = false;&#xA;        const component = shallow(&#xA;            &lt;GenericButton action={() =&gt; {&#xA;                clicked = true;&#xA;            }}&#xA;            id=""testComponent""/&gt;&#xA;        );&#xA;&#xA;        component.find('testComponent').first().simulate('click');&#xA;        expect(clicked).toBeTruthy();&#xA;    });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However this will fail as the action is done eventually,</p>&#xA;&#xA;<p>If i set the assertion to happen eventually (using setTimeout for example) it will work</p>&#xA;&#xA;<p>however it would be better if i do something of the following before the assert (found this on examples using jasmine)</p>&#xA;&#xA;<pre><code>        waitsFor(() =&gt; {&#xA;            return clicked;&#xA;        }, ""the value to change"", 1000);&#xA;</code></pre>&#xA;&#xA;<p>What is the equivalent call for enzyme/jest?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Edit: Content of component</p>&#xA;&#xA;<pre><code>render() {&#xA;    return &lt;Button id={this.props.id}&#xA;                   key={this.props.id}&#xA;                   onClick={() =&gt; this.props.action()}&#xA;                   bsStyle={this.props.style}&gt;&#xA;               {this.props.text}&#xA;           &lt;/Button&gt;;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(Button is a 3rd party library component)</p>&#xA;"
40518729,MassTransit Producer takes 60 seconds to Consume an event,2016-11-10 01:35:44,<c#><rabbitmq><microservices><masstransit>,1,143,12,0.0,0,"<p>I have 2 projects:</p>&#xA;&#xA;<ol>&#xA;<li>A MassTransit (Topshelf Windows Service) called <code>Service.Endpoints</code></li>&#xA;<li>A Console App client trying to communicate with it called <code>TestConsole</code>.</li>&#xA;</ol>&#xA;&#xA;<p>The overall requirement is as follows:</p>&#xA;&#xA;<ol>&#xA;<li><code>TestConsole</code> sends <code>SolveProblemCommand</code></li>&#xA;<li><code>Service.Endpoints</code> Consumes the command and Publishes <code>ProblemSolvedEvent</code></li>&#xA;<li><code>TestConsole</code> Consumes the event.</li>&#xA;</ol>&#xA;&#xA;<h2>The problem:</h2>&#xA;&#xA;<p>All the above steps work fine except that step 3 (<code>TestConsole</code> consuming the event) only happens around 60 seconds after the event is published. The following error is displayed first (after 60 seconds) and then the Consumer received the call.</p>&#xA;&#xA;<pre><code>Timeout waiting for consumer to exit: rabbitmq://localhost:5672/bus-PC-NAME-TestConsole.vshost-4sboyydjz6ne6mz6bdky1b7ad4?durable=false&amp;autodelete=true&amp;prefetch=16&#xA;</code></pre>&#xA;&#xA;<p>Timeout waiting for consumer to exit: rabbitmq://localhost:5672/problemsolved.queue?prefetch=16</p>&#xA;&#xA;<h2>The code:</h2>&#xA;&#xA;<h3>Service.Endpoints.csproj</h3>&#xA;&#xA;<pre><code>bus = BusConfigurator.ConfigureBus(new AppSettings(), (cfg, host) =&gt;&#xA;{&#xA;    cfg.ReceiveEndpoint(host, RabbitMqConstants.SolveProblemQueue, e =&gt;&#xA;    {&#xA;        e.Consumer&lt;SolveProblemCommandConsumer&gt;(NinjectConfig.CurrentKernel);&#xA;    });&#xA;});&#xA;&#xA;bus.Start();&#xA;&#xA;class SolveProblemCommandConsumer : IConsumer&lt;SolveProblemCommand&gt;&#xA;{&#xA;    public async Task Consume(ConsumeContext&lt;SolveProblemCommand&gt; context)&#xA;    {&#xA;        var controller = new Controller(context.Message.Problem);&#xA;        var results = await controller.Start(context.Message.Options);&#xA;        await context.Publish(new ProblemSolvedEvent(results));&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<h3>TestConsole.csproj</h3>&#xA;&#xA;<pre><code>var bus = BusConfigurator.ConfigureBus(new AppSettings(), (cfg, host) =&gt;&#xA;{&#xA;    cfg.ReceiveEndpoint(host, RabbitMqConstants.ProblemSolvedQueue, e =&gt;&#xA;    {&#xA;        e.Consumer&lt;ProblemSolvedEventConsumer&gt;();&#xA;    });&#xA;});&#xA;&#xA;var sendToUri = new Uri($""{RabbitMqConstants.RabbitMqUri}{RabbitMqConstants.SolveProblemQueue}"");&#xA;var endpoint = await bus.GetSendEndpoint(sendToUri);&#xA;bus.Start();&#xA;&#xA;await endpoint.Send(someMessage);&#xA;&#xA;&#xA;class ProblemSolvedEventConsumer : IConsumer&lt;ProblemSolvedEvent&gt;&#xA;{&#xA;    public async Task Consume(ConsumeContext&lt;ProblemSolvedEvent&gt; context)&#xA;    {&#xA;        ...&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
43598939,API gateway for event-driven architecture,2017-04-24 22:54:44,<rest><soa><microservices><event-driven>,1,516,0,1.0,0,"<p>We're trying to split our monolithic core into microservices and add some new ones connected with each other using the message system (e.g. Kafka).</p>&#xA;&#xA;<p>The next stage is to create API endpoints for communication between mobile apps and microservices through Api gateway.</p>&#xA;&#xA;<p>What would be a good solution for developing API gateway to transmit data to/from microservices?</p>&#xA;&#xA;<ol>&#xA;<li>use message system as request-reply one (transform requests on&#xA;API gateway into message commands, wait for response from message&#xA;system with status or necessary data)?</li>&#xA;<li>create REST endpoints on necessary microservices (e.g. using <a href=""https://github.com/linkedin/rest.li"" rel=""nofollow noreferrer"">REST.li</a>) to send or&#xA;get data through gateway; use message system for consistency of data&#xA;based on produced events by microservices?</li>&#xA;</ol>&#xA;&#xA;<p>Thanks for advice and some ideas</p>&#xA;"
43700905,Microservices - how to find DNS IP?,2017-04-29 22:05:26,<dns><microservices><service-discovery>,4,266,0,0.0,0,<p>In the world of microservices endpoints should not (must not) be hardcoded. One of the best ways to do this is to have a DNS and let each microservice register while starting. By doing this whenever microservice A wants to communicate with microservice B it just asks DNS for endpoints where B currently listens.</p>&#xA;&#xA;<p>What I do not understand is: <strong>How microservices know where the DNS lives?</strong></p>&#xA;&#xA;<p>Basically DNS is just a 'special' service and I can have one or multiple instances of it right? So I should not hardcode it's endpoint too or should I? And let's say I do - what if DNS instnace is moved to different location? Do I have to manually change it's location in configuration?</p>&#xA;&#xA;<p>Does anyone happen to know how to design this? (or can anyone just point me to any document where this is explained since although there are many information about microservices and dns I can not find this particular information anywhere - maybe it's just too trivial and I am the only one who does not get it)</p>&#xA;
43567411,PACT: java-maven,2017-04-23 04:32:40,<maven><microservices><pact><pact-java>,1,785,0,1.0,0,"<p>I need few answer for my doubt:</p>&#xA;&#xA;<ol>&#xA;<li>Pact-mock-service Vs pact-jvm-server, is both are same? Pls describe this.</li>&#xA;<li>Am implementing the PACT in java-maven</li>&#xA;</ol>&#xA;&#xA;<p>I can able to run this:</p>&#xA;&#xA;<p><a href=""https://github.com/anha1/microservices-pact-maven"" rel=""nofollow noreferrer"">https://github.com/anha1/microservices-pact-maven</a></p>&#xA;&#xA;<p><a href=""https://github.com/warmuuh/pactbroker-maven-plugin"" rel=""nofollow noreferrer"">https://github.com/warmuuh/pactbroker-maven-plugin</a></p>&#xA;&#xA;<p>Help me to understand this with pact-mock-service and pact-jvm-server</p>&#xA;"
43552529,own Configurations Server build with Spring Boot,2017-04-21 21:51:07,<java><rest><spring-boot><properties><microservices>,1,66,0,0.0,0,<p>Does anyone of you now how I can build my own Configurations Server as a microservice to store and load <code>.properties</code> Files ?&#xA;I find the Spring Cloud Config really interesting but there you use git as the target and in my case it would be just a Filesystem ..&#xA;Thanks for any advice </p>&#xA;
43721197,"I have two microservice, should it have its independent embedded tomcat or one common tomcat",2017-05-01 14:57:38,<spring-boot><microservices>,1,89,0,0.0,0,<p>Which is good in production environment? Individual embedded tomcat for each app or one tomcat for many apps?</p>&#xA;
43636544,Endpoint without port number,2017-04-26 14:05:59,<azure><microservices><azure-service-fabric>,2,109,0,0.0,0,"<p>Is there any way to expose a microservice endpoint without port number in Azure Service Fabric? Port number can be defined in <em>ServiceManifest.xml</em> or it can be dynamically assigned by Service Fabric cluster, but how to call a service without specifying port number?</p>&#xA;"
43753039,Openshift Container Platform V3.X vs. Fabric8,2017-05-03 06:49:48,<containers><openshift><kubernetes><microservices><fabric8>,1,660,0,0.0,0,"<p>I took a look at Fabric8 Microservices Platform and searched for some alternatives for comprehension. I found Red Hats Openshift Container Platform, which seems to be the same as Fabric8, but not Open-Source. &#xA;I tried to figure out what are the major benefits of Red Hats solution.&#xA;I am already on the Openstack. </p>&#xA;"
43659872,Fetching a list with Lagom framework,2017-04-27 13:51:55,<java><microservices><lagom>,1,164,0,0.0,0,"<p>I'm VERY new to Lagom framework and I have absolutely no idea what I'm doing. I have a simple CRUD lagom application that does work, but I can't figure out how to retrieve a list.</p>&#xA;&#xA;<p>So this is what I have for now, but I'm getting </p>&#xA;&#xA;<pre><code>@Override&#xA;    public ServiceCall&lt;NotUsed, Source&lt;Movie, ?&gt;&gt; getMovies() {&#xA;        return request -&gt; {&#xA;            CompletionStage&lt;Source&lt;Movie, ?&gt;&gt; movieFuture = session.selectAll(""SELECT * FROM movies"")&#xA;                    .thenApply(rows -&gt; rows.stream()&#xA;                    .map(row -&gt; Movie.builder()&#xA;                        .id(row.getString(""id""))&#xA;                        .name(row.getString(""name""))&#xA;                        .genre(row.getString(""genre""))&#xA;                        .build()));&#xA;                    //.thenApply(TreePVector::from));&#xA;                    //.thenApply(is -&gt; is.collect(Collectors.toList()))&#xA;&#xA;            return movieFuture;&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>but I'm getting a <code>[Java] Type mismatch: cannot convert from Stream&lt;Object&gt; to Source&lt;Movie,?&gt;</code> error on the <code>rows.stream()</code> line.</p>&#xA;&#xA;<p>Any help would be appreciated.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
43700824,Microservice Ribbon Load balancer Not working,2017-04-29 21:51:26,<load-balancing><ribbon><microservices>,1,426,0,0.0,0,"<p>I try to create one service which consume multiple the same instance of another microservice service.</p>&#xA;&#xA;<p>client microservice pom:</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.demotest&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;demotest&lt;/artifactId&gt;&#xA;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;    &lt;name&gt;happpredictservice&lt;/name&gt;&#xA;    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;Dalston.RC1&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;repositories&gt;&#xA;        &lt;repository&gt;&#xA;            &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;            &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;            &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;            &lt;snapshots&gt;&#xA;                &lt;enabled&gt;false&lt;/enabled&gt;&#xA;            &lt;/snapshots&gt;&#xA;        &lt;/repository&gt;&#xA;    &lt;/repositories&gt;&#xA;&#xA;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>//bootstrap.properties file:</p>&#xA;&#xA;<pre><code>spring.application.name=predict_service&#xA;spring.cloud.config.uri=http://localhost:8888     //this is my configuration //service path not related to my question here&#xA;&#xA;registration_service.ribbon.eureka.enabled=false&#xA;registration_service.ribbon.listOfServers= localhost:8083,localhost:8084&#xA;registration_service.ribbon.ServerListRefreshInterval=15000&#xA;eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/&#xA;</code></pre>&#xA;&#xA;<p>//application main class:</p>&#xA;&#xA;<pre><code>package com.demotest;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;import org.springframework.cloud.netflix.feign.EnableFeignClients;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;@EnableFeignClients&#xA;public class HapppredictserviceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(HapppredictserviceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>//clinte service controller class:</p>&#xA;&#xA;<pre><code>package com.demotest.controllers;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.client.loadbalancer.LoadBalanced;&#xA;import org.springframework.cloud.netflix.ribbon.RibbonClient;&#xA;import org.springframework.context.annotation.Bean;&#xA;import org.springframework.web.bind.annotation.PathVariable;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;import org.springframework.web.client.RestTemplate;&#xA;&#xA;import com.demotest.fiegns.Patient;&#xA;import com.demotest.fiegns.RegistrationServiceClient;&#xA;//registration_service is application to be called&#xA;@SpringBootApplication&#xA;@RestController&#xA;@RibbonClient(name=""registration_service"",configuration=Registration_Service_Ribbon_Config.class) //added for ribbon client&#xA;public class PredictController {&#xA;    // it is feign client instantiation&#xA;    @Autowired&#xA;    RegistrationServiceClient regClient;&#xA;&#xA;    @LoadBalanced&#xA;    @Bean&#xA;    RestTemplate restTemplate(){&#xA;        return new RestTemplate();&#xA;    }&#xA;&#xA;    @Autowired&#xA;    RestTemplate restTemplate;&#xA;    @RequestMapping(""/hi"")&#xA;    public String gussHi(){&#xA;        final String serviceURL=""http://registration_service"";&#xA;        String existingAge=restTemplate.getForObject(serviceURL+""/hi"", String.class);&#xA;        System.out.println(""exisiting age:""+existingAge);&#xA;        return existingAge;&#xA;    }&#xA;&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>//ribbon configuration:</p>&#xA;&#xA;<pre><code>package com.demotest.controllers;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.context.annotation.Bean;&#xA;&#xA;import com.netflix.client.config.IClientConfig;&#xA;import com.netflix.loadbalancer.AvailabilityFilteringRule;&#xA;import com.netflix.loadbalancer.IPing;&#xA;import com.netflix.loadbalancer.IRule;&#xA;import com.netflix.loadbalancer.PingUrl;&#xA;&#xA;public class Registration_Service_Ribbon_Config {&#xA;    @Autowired&#xA;    IClientConfig iClientConfig;&#xA;&#xA;    @Bean&#xA;    public IPing ribbonPing(IClientConfig config){&#xA;        return new PingUrl();&#xA;    }&#xA;&#xA;    @Bean&#xA;    public IRule ribbonRule(IClientConfig config){&#xA;        return new AvailabilityFilteringRule();&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>//now I have other microservice to be consumed by the above client. its pom:</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.demotest&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;demotest&lt;/artifactId&gt;&#xA;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;    &lt;name&gt;happregservice&lt;/name&gt;&#xA;    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-data-gemfire&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&lt;dependency&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;&lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;Dalston.RC1&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;repositories&gt;&#xA;        &lt;repository&gt;&#xA;            &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;            &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;            &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;            &lt;snapshots&gt;&#xA;                &lt;enabled&gt;false&lt;/enabled&gt;&#xA;            &lt;/snapshots&gt;&#xA;        &lt;/repository&gt;&#xA;    &lt;/repositories&gt;&#xA;&#xA;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>//the bootstrap.properties file of microservice to be consumed:</p>&#xA;&#xA;<pre><code>spring.application.name=registration_service&#xA;spring.cloud.config.uri=http://localhost:8888&#xA;server.port=8083&#xA;</code></pre>&#xA;&#xA;<p>//main class of the microservice to be consumed:</p>&#xA;&#xA;<pre><code>package com.demotest;&#xA;&#xA;import org.springframework.beans.factory.annotation.Value;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;import org.springframework.cloud.context.config.annotation.RefreshScope;&#xA;import org.springframework.cloud.netflix.feign.EnableFeignClients;&#xA;import org.springframework.context.annotation.ComponentScan;&#xA;import org.springframework.context.annotation.ComponentScans;&#xA;import org.springframework.data.gemfire.repository.config.EnableGemfireRepositories;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;@EnableFeignClients&#xA;@EnableGemfireRepositories//this is for gemfire it works perfect not releted to //my question here&#xA;public class HappregserviceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(HappregserviceApplication.class, args);&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>//the controller class of the microservice to be consumed:</p>&#xA;&#xA;<pre><code>package com.demotest.controllers;&#xA;&#xA;&#xA;import java.util.HashSet;&#xA;import java.util.List;&#xA;import java.util.Set;&#xA;import java.util.UUID;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.beans.factory.annotation.Value;&#xA;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;&#xA;import org.springframework.web.bind.annotation.PathVariable;&#xA;import org.springframework.web.bind.annotation.RequestBody;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RequestMethod;&#xA;import org.springframework.web.bind.annotation.RequestParam;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;import com.demotest.entities.Patient;&#xA;import com.demotest.repositories.PatientRepo;&#xA;import com.netflix.discovery.DiscoveryClient;&#xA;&#xA;@RestController&#xA;public class registrationcontroller {&#xA;&#xA;    @RequestMapping(""/hi"")&#xA;    private String getHi(){&#xA;        return ""hi from original"";&#xA;    }&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>/*I copy and paste the same microservice(the second one) to be consumed and only I changed the port to 8084. for some reason I Iam getting error due to unable to access the service to be consumed by its name. When I try to access the service using localhost: it works. as soon as I chaged to the service name in the RsetTemplate call I am getting the following error:</p>&#xA;&#xA;<p>java.lang.IllegalStateException: Request URI does not contain a valid hostname: <a href=""http://registration_service/hi"" rel=""nofollow noreferrer"">http://registration_service/hi</a> */</p>&#xA;"
43660545,Microservice - Database Security,2017-04-27 14:22:39,<sql-server><microservices><self-hosting>,1,187,0,0.0,0,"<p>We are going the microservices route to try breaking up a monolith. &#xA;Previously we had a single database which was being hit by multiple applications. The applications were given grants to specific table that they need to access. </p>&#xA;&#xA;<p>With microservice architecture we plan to contain a specific domain in a service and the service has its own database.</p>&#xA;&#xA;<p>We use Self hosting windows service to stand up microservices. They all hit SQL server for persistence. We plan to use integrated security for service to authenticate into the database. </p>&#xA;&#xA;<p>This is the point at which the problem starts. To authenticate a service and to ensure that the database is not being used by any other service,we plan to have one service account for each of the applications. Now, for few microservices, management of these accounts (frequent policy based password changes)  are okay. Once the number of services reaches beyond manually manageable scale, we are worried that the account management (1 account per service) will start becoming a pain.</p>&#xA;&#xA;<p>How is this done currently by the industry at large. Are there any tools that we can use for this purpose?</p>&#xA;"
43607751,How to create SPARK/Flink Stream Data Processing as a Microservice (REST API),2017-04-25 10:11:30,<apache-spark><playframework-2.0><microservices><apache-flink><lagom>,1,224,0,2.0,0,"<p>I am creating streaming analytics application using Spark, Flink &amp; Kafka. Each analytics/functionality will implement as a Microservice so that this analytics can able to use in the different project later.</p>&#xA;&#xA;<p>I run my Spark/Flink job perfectly in Simple Scala application and submit this job over Spark &amp; Flink cluster respectively. But I have to start/run this job when REST POST startJob() request invoke to my web service.</p>&#xA;&#xA;<p>How can I integrate my Spark &amp; Flink data processing functionality in a web service oriented application? </p>&#xA;&#xA;<p>Till now I tried <a href=""http://www.lagomframework.com/"" rel=""nofollow noreferrer"">Lagom Microservice</a> but i found so many issues you can check </p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/43255302/best-approach-to-ingest-streaming-data-in-lagom-microservice"">Best approach to ingest Streaming Data in Lagom Microservice&#xA;</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/43570899/java-io-notserializableexception-using-apache-flink-with-lagom"">java.io.NotSerializableException using Apache Flink with&#xA;Lagom</a></li>&#xA;</ol>&#xA;&#xA;<p>I think i am not taking the right direction for Stream Processing Microservice Application. Looking for right direction to implement this analytics over REST Service.</p>&#xA;"
43689879,How does one pass user context between an API and a microservice?,2017-04-28 22:50:00,<rest><microservices><azure-service-fabric>,2,412,3,1.0,0,"<p>I am trying to setup audit logging and we were wanting the log event to happen as close to the action as possible, while also knowing which user performed the action. This means we need to pipe in the user info.  What are best practices for this?</p>&#xA;"
43674924,What is the best way to manage microservice issue or bug on git,2017-04-28 07:51:48,<git><microservices><issue-tracking>,2,208,4,0.0,0,"<p>Micro-Service is about having many projects on git within different repositories.</p>&#xA;&#xA;<p>So, what is the best way to manage an issue, when there is a bug which needed to fix the code on multiple services?</p>&#xA;"
43682155,Sharing entity ID between microservices,2017-04-28 14:04:31,<rest><microservices><hateoas>,1,342,5,2.0,0,"<p>Let's say I have a <code>Users</code> microservice. Its data is consumed via REST API following HATEOAS ""pattern"", so a common request/response would be something like this:</p>&#xA;&#xA;<pre><code>GET /users&#xA;&#xA;{&#xA;  results: 5,&#xA;  data :[&#xA;    {&#xA;      name: ""John Doe"",&#xA;      email: ""whatever"",&#xA;      ...,&#xA;      links : [&#xA;        {&#xA;          rel: ""self"",&#xA;          href: ""/users/1""&#xA;        }&#xA;      ]&#xA;    },&#xA;    ...&#xA;  ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As HATEOAS says, the users' ID is not returned, but a link to ""self"". </p>&#xA;&#xA;<p>So far, so good. Now, I want another microservice to manage users' pictures. In that new microservice there is a relationship between one user an her pics, so I will need a user identifier.</p>&#xA;&#xA;<p>Should I use ""/users/1"" (""self"" link) as user ID in the pics microservice? </p>&#xA;&#xA;<p>If not, how can I approach this?</p>&#xA;"
41155377,How to account for open sessions in a stateless service,2016-12-15 02:20:29,<design-patterns><cloud><monitoring><microservices><instrumentation>,1,21,0,0.0,0,"<p>I am converting my app from a classic service to a microservice.&#xA;I need to count total number of open sessions.</p>&#xA;&#xA;<p>My classic version was writing a local windows perf counter: +1 on session open, -1 on session close. If the service died unexpectedly, the new instance reset the counter during start. A remote monitoring service was collecting the counter from all instances and showing total and average.</p>&#xA;&#xA;<p>My new service writes counters using diagnostics library that pushes the values to a remote monitoring service. </p>&#xA;&#xA;<p>I do not understand how to reset the counter if the service dies unexpectedly. The only idea I got is to start collecting heartbeats from each service and reset the counter if the service dies, but it seems to be over-design.</p>&#xA;&#xA;<p>Are there more elegant patterns to do a reliable accounting for open sessions for a stateless service?</p>&#xA;&#xA;<p>Is there a standard terminology for this scenario in microservice management systems?</p>&#xA;"
41115982,Can IIS Handle Thousands of AppPools/Worker Processes?,2016-12-13 07:51:04,<iis><architecture><microservices>,1,42,0,1.0,0,<p>I am currently investigating the feasibility of an architecture where we will have potentially thousands of AppPools and therefore Worker Processes for each of our micro-services running in IIS (10+). (It is one of a few options)</p>&#xA;&#xA;<p>I understand the overhead of each worker process. Currently my estimation would be that each worker is going to be about 20-30MB. Server resourcing should not be too much of an issue as we are likely going to be provisioning servers with 32-64GB of RAM. To add to this not all workers would be active at all times so we should gain headroom when AppPools are idle.</p>&#xA;&#xA;<p><strong>My question: Can IIS handle this many AppPools/Worker processes?</strong></p>&#xA;&#xA;<p>I don't see a reason it shouldn't given sufficient resources however have not been able to find any documentation around it after some brief searching.</p>&#xA;
41174987,Is it possible to do Hypermedia Driven RESTFul service in a microservices world?,2016-12-15 23:26:26,<microservices><restful-architecture><hypermedia>,1,74,0,0.0,0,"<p>Lets say that we are creating a Ticket processing system. Say there are two distinct bounded contexts within this domain.&#xA;Cancelling a Ticket&#xA;Changing a Ticket</p>&#xA;&#xA;<p>From what I understand, those two can be two different microservices, without having to know each other. What a ticket to a Cancel service could be completely different from what a ticket is to a Change service. </p>&#xA;&#xA;<p>From a REST API design perspective, i have read a lot about using hypermedia and letting client discover resources by including relevant operations as links within the REST response (<a href=""https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj9wczqq_fQAhXILyYKHZHhBgYQtwIIGjAA&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dpspy1H6A3FM&amp;usg=AFQjCNGLh50iMwLI2l_AgDcz1duWaS35gA&amp;bvm=bv.141536425,d.eWE"" rel=""nofollow noreferrer"">Stefan Tilkov's Talk</a>). If thats true, when my Change Service returns a response, it makes sense to include a link to Cancel Service, which the client can use to perform cancel. How can I achieve this when Cancel and Change are two different microservices, which are not aware of each other? Or are my bounded contexts wrong?</p>&#xA;&#xA;<p>Are we losing these hypermedia linking capabilities (or does it become harder) when use microservices in general?</p>&#xA;&#xA;<p>Thanks&#xA;Kay</p>&#xA;"
41188108,How to enable automatic routing in Netflix/Zuul and Netflix/Ribbon with discovery information from Netflix/Eureka Service?,2016-12-16 15:58:41,<java><spring-boot><microservices><netflix-zuul><netflix-eureka>,2,847,0,0.0,0,"<p>I'm quite new in things with the netflix cloud Microservice architecture.</p>&#xA;&#xA;<p>There are three Microservices running in my Network:</p>&#xA;&#xA;<ul>&#xA;<li><p>Zuul/Ribbon Service: localhost:8765</p>&#xA;&#xA;<p><code>Application.yml:&#xA;  ===============&#xA;  eureka:&#xA;   client:&#xA;    serviceUrl:&#xA;     defaultZone: http://localhost:8761/eureka/</code></p></li>&#xA;<li><p>Eureka Service: localhost:8761</p></li>&#xA;<li>RentCarService: localhost:8888</li>&#xA;</ul>&#xA;&#xA;<p>Now, my request is: <strong>localhost:8765/RentCarService/getAllAvailableCars</strong></p>&#xA;&#xA;<p>This request should automatically routed forward to the right Microservice (RentCarService with Port 8888) like <strong>localhost:8888/getAllAvailableCars</strong></p>&#xA;&#xA;<p>I have seen much tutorials and the most of them are forwarding the requests programmatically like in this tutorial:</p>&#xA;&#xA;<p><a href=""http://www.disasterarea.co.uk/blog/microservice-discovery-with-spring-boot-and-eureka/"" rel=""nofollow noreferrer"">Microservice discovery with spring boot and eureka</a></p>&#xA;&#xA;<p><a href=""https://github.com/callistaenterprise/blog-microservices/blob/B1/microservices/composite/product-composite-service/src/main/java/se/callista/microservices/composite/product/service/Util.java"" rel=""nofollow noreferrer"">Or here by a method called getServiceURL</a></p>&#xA;&#xA;<p>Do i have to code the forwarding by my own or is <strong>this possible automatically by Ribbon</strong>?</p>&#xA;&#xA;<p>Beste regards&#xA;lars</p>&#xA;"
41027573,Ansible playbook to find particular java process and kill,2016-12-07 21:20:12,<java><jar><find><ansible><microservices>,1,1195,0,0.0,0,"<p>I'm working on deploying microservices with ansible-playbook right now. And all of the microservices uses <code>java -jar</code> command to deploy. Right now I'm trying to write an ansible playbook to find and kill dependent java -jar process before deploying other one.</p>&#xA;&#xA;<p>I'm running out of ideas here. I was thinking of creating a script in init.d for java deamon. But, if i do that and stop service, it would stop all the java processes which i wouldn't want. </p>&#xA;&#xA;<p><strong>Output for</strong> <code>ps -ef | grep java</code></p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>root</strong>     28330     1  1 13:52 ?        00:00:56 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config /opt/app/microservices/deploy/dal-core/enrollment-vehicle-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29143     1  2 14:22 ?        00:00:49 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-vehicle-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29879     1  2 14:23 ?        00:00:48 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-account-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     31093     1  3 14:28 ?        00:01:04 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/listener/config  /opt/app/microservices/deploy/listener/enrollment-account-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p>asadmin  31208 18879  0 14:57 pts/1    00:00:00 grep --color=auto java</p>&#xA;</blockquote>&#xA;&#xA;<p>In the above scenario, If i happen do deploy enrollment-account-dal-core again, I should 1st kill enrollment-account-listener (pid:31093) and then enrollment-account-dal-core (pid:29879).</p>&#xA;&#xA;<p>I have one playbook for all of the microservices so I won't be able to hard code it either.</p>&#xA;"
41082938,Event sourcing microservices: How to manage timestamp,2016-12-11 04:16:25,<timestamp><microservices><cqrs><event-sourcing>,2,464,0,0.0,0,"<p>We have microservices, each generating events that are being stored by a event-sourcing repository. We use Cassandra to store the event data.</p>&#xA;&#xA;<p>As you may know, the order of the events is important. </p>&#xA;&#xA;<p>When we generate these events from different services running in different machines, how to manage the time (timestamp) going out of sync across these thereby resulting in an event order mismatch.</p>&#xA;"
41096759,How to prevent duplicate code while doing microservice or soa ? or how to define the bounded context without duplicating the models?,2016-12-12 08:25:58,<soa><microservices>,1,222,0,0.0,0,"<p>Can somebody please refer me how do we separate out the models while separating out each service to run of their own? So basically a few of the models we have right now overlaps among services. I went through some of the procedures which ask to use canonical pattern, however I also got that we should not use canonical pattern. </p>&#xA;&#xA;<p>One of the solution would be to keep all the models in a common place which we are doing right now. But its seems problematic for managing the services in the form of one repository per one service. </p>&#xA;&#xA;<p>Duplicate models are also fine with me if I can find good logic for it.</p>&#xA;"
41041058,Event-driven architecture - why is there no tool for this?,2016-12-08 13:47:36,<microservices><event-driven><event-driven-design>,1,161,1,0.0,0,<p>For a new application I am developing I am interested in creating a microservice that allows for events to be created (for example: New order placed) and other microservices to react to these events (for example the payment system listens to the New order event and processes the payment). </p>&#xA;&#xA;<p>Is there any open source project that I can use to do this in a reliable way?</p>&#xA;
41123857,How to publish an event in the microservice world?,2016-12-13 14:44:03,<amazon-web-services><events><microservices><grpc>,1,149,3,0.0,0,"<p>There are many books and blogs detailing how event-based communication between microservices is easier to maintain than services calling eachother directly. </p>&#xA;&#xA;<p>However how would this be implemented in the AWS world? I was considering Topics, but it is far from ideal.</p>&#xA;&#xA;<p>How is this patter usually implemented to give guarantees on latency, durability, guaranteed delivery, idempotency etc.</p>&#xA;"
45992134,enverse-how to customize user id in customized revision listner,2017-09-01 01:22:35,<jpa><spring-boot><spring-security><microservices><hibernate-envers>,1,32,0,0.0,0,"<p>i am using jpa with hibernate envers of micro service.&#xA;i tried </p>&#xA;&#xA;<pre><code>public class MyRevisionEntityListener implements RevisionListener {&#xA;  @Override&#xA;  public void newRevision(Object revisionEntity) {&#xA;    // If you use spring security, you could use SpringSecurityContextHolder.&#xA;    final UserContext userContext = UserContextHolder.getUserContext();&#xA;    MyRevisionEntity mre = MyRevisionEntity.class.cast( revisionEntity );       &#xA;    mre.setUserName( userContext.getUserName() );&#xA;  } &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>it saves username better.but i want to save user name as""by system"" when updates the record by another micro service and when user updates should save the user name as above.how to customize above code as my requirement</p>&#xA;"
45820257,Spring Eureka dynamic service lookup,2017-08-22 14:21:27,<spring-boot><microservices><eureka>,2,69,0,0.0,0,"<p>Very new to Spring/Eureka, sorry if this is a dumb question:</p>&#xA;&#xA;<p>I have multiple services, all implementing a common interface. I need to dynamically (at runtime) select the correct implementation. For example, I may have a front end that services multiple payroll systems. I want to select the correct payroll system based on some attribute.</p>&#xA;&#xA;<p>I don't want to have to define multiple endpoints for each (if I start servicing an additional system, I don't want to have to add even more endpoints). </p>&#xA;&#xA;<p>What I <strong><em>want</em></strong> to do is locate the correct service (maybe construct the name dynamically based on the desired payroll system) and interact via the interface. &#xA;Does that make sense? Possible? Obvious?</p>&#xA;"
45964545,Approaches to route request to relevant services in Microservices Architecture,2017-08-30 15:36:12,<tomcat><microservices>,1,85,0,0.0,0,"<p>Suppose we are having 5 services (Users and Authorisation, Product, Orders, Inventory, History) exposing REST based API and communicate internally between services via these exposed API's only. Now while developing this in a Microeservice Architectural pattern these will be different individual services which will be self reliant and communicate to each other via REST/Queues. </p>&#xA;&#xA;<p>To start of with lets consider we are deploying this on a single node as of now where all the 5 services are deployed on this single node only. So one approach is </p>&#xA;&#xA;<ol>&#xA;<li><strong>(Ideal)</strong> To have a Service Discovery and Registry Mechanism via Netflix tool chain (eureka) or via Zookeper to direct the request to relevant services after authentication and authorization e.g /api/v1/Products/{id} to be directed to Products services , /api/v1/order/{id} to be directed to Order services and so on.</li>&#xA;<li><strong>Another one</strong> (though not the right one for the scenario where the services are distributed on multiple nodes , but considering if we are having all the services on a single node and plan to go live quickly and then in next phases go towards Discovery/Registry , API gateway, circuit breaker approach of Microservices) in which we develop all the services as separate web apps deployed as individual war in tomcat (Spring based app) and let tomcat to handle the redirection on basis of URL e.g <a href=""https://ip:port/"" rel=""nofollow noreferrer"">https://ip:port/</a><strong>productservice</strong>/api/v1/products/{id} redirected by tomcat to <strong>productservice</strong> webapp and so on.</li>&#xA;</ol>&#xA;&#xA;<p>Will the <strong>option 2</strong> will be a viable option to go live with different services developed as a separate webapp , self reliant with it's own schema deployed in a single tomcat instance and being consumed from UI layer and then in next phases use this base code of individual and separate service and go towards discovery/registry approach.</p>&#xA;&#xA;<p>But the challenge i was foreseeing in <strong>Option 2</strong> where each service is a separate war (without discovery/registry) is the <strong><em>routing</em></strong>  - as main entry for each request e.g <a href=""https://ip:port/"" rel=""nofollow noreferrer"">https://ip:port/</a><strong>productservice</strong>/api/v1/products/{id} before going to <strong>productservice</strong> webapp need to go through a ""authentication service"" app and then to be routed to appropriate service and handling this routing in a separate war mechanism (though on a single instance) have following option</p>&#xA;&#xA;<ol>&#xA;<li>each request needs to landed on to the authentication service app (how ? can be URL redirection) and then some routing logic is written to send the authenticated request to the required app(service) which is REST based. This routing can be a camel based or simply DB based -  parsing the string and calling the REST API of the required service . The authentication app will then act as an API gateway.</li>&#xA;<li>Other is the one which you mentioned (missing of queues). All request lands on to the authentication service app (how ? can be URL redirection) and then this writes to individual queue dedicated to each service , where each service subscribes to it specific queue. </li>&#xA;</ol>&#xA;"
45917894,Blank Home Page JHipster Angular4 Gateway,2017-08-28 11:27:36,<node.js><angular><jhipster><microservices><gateway>,1,150,1,0.0,0,"<p>I am facing same kind of issue with Jhipster Gateway application (Angular 4) in some machines only,</p>&#xA;&#xA;<p>I am doing below common steps to check out application from SVN and run the application</p>&#xA;&#xA;<ol>&#xA;<li>We are loading the source code for below files of the application from SVN (Please look in to the image)</li>&#xA;</ol>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6uUaN.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6uUaN.jpg"" alt=""Files Structure""></a></p>&#xA;&#xA;<ol start=""2"">&#xA;<li>After that ran 'npm install/yarn install'</li>&#xA;<li>After that I have ran <strong>mvnw</strong> and <strong>yarn start</strong> in parallel CMD windows</li>&#xA;</ol>&#xA;&#xA;<p>Application is working fine with 9000 port (Provided by yarn), but I am unable to see home page with port 8080. It is not showing any exceptions or errors also.</p>&#xA;&#xA;<p>But in some systems it fine working fine, I am confused how to solve this.</p>&#xA;&#xA;<p><strong>Here is the log</strong></p>&#xA;&#xA;<pre><code>[INFO] Scanning for projects...&#xA;[INFO]&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building Agree Gateway V 1 0.0.1-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO]&#xA;[INFO] &gt;&gt;&gt; spring-boot-maven-plugin:1.5.4.RELEASE:run (default-cli) &gt; test-compile @ agree-gateway-v-1 &gt;&gt;&gt;&#xA;[INFO]&#xA;[INFO] --- maven-resources-plugin:3.0.1:copy-resources (default-resources) @ agree-gateway-v-1 ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 11 resources&#xA;[INFO] Copying 12 resources&#xA;[INFO]&#xA;[INFO] --- maven-resources-plugin:3.0.1:resources (default-resources) @ agree-gateway-v-1 ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 11 resources&#xA;[INFO] Copying 12 resources&#xA;[INFO]&#xA;[INFO] --- maven-enforcer-plugin:1.4.1:enforce (enforce-versions) @ agree-gateway-v-1 ---&#xA;[INFO]&#xA;[INFO] --- jacoco-maven-plugin:0.7.9:prepare-agent (pre-unit-tests) @ agree-gateway-v-1 ---&#xA;[INFO] argLine set to ""-javaagent:C:\\Users\\NSPL-1508\\.m2\\repository\\org\\jacoco\\org.jacoco.agent\\0.7.9\\org.jacoco.agent-0.7.9-runtime.jar=destfile=E:\\Recon Workspace New\\AgreeGateway\\target\\test-results\\coverage\\jacoco\\jacoco.exec"" -Djava.security.egd=file:/dev/./urandom -Xmx256m&#xA;[INFO]&#xA;[INFO] --- maven-compiler-plugin:3.6.0:compile (default-compile) @ agree-gateway-v-1 ---&#xA;[INFO] Nothing to compile - all classes are up to date&#xA;[INFO]&#xA;[INFO] --- maven-resources-plugin:3.0.1:testResources (default-testResources) @ agree-gateway-v-1 ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 5 resources&#xA;[INFO]&#xA;[INFO] --- maven-compiler-plugin:3.6.0:testCompile (default-testCompile) @ agree-gateway-v-1 ---&#xA;[INFO] Nothing to compile - all classes are up to date&#xA;[INFO]&#xA;[INFO] &lt;&lt;&lt; spring-boot-maven-plugin:1.5.4.RELEASE:run (default-cli) &lt; test-compile @ agree-gateway-v-1 &lt;&lt;&lt;&#xA;[INFO]&#xA;[INFO]&#xA;[INFO] --- spring-boot-maven-plugin:1.5.4.RELEASE:run (default-cli) @ agree-gateway-v-1 ---&#xA;[INFO] Attaching agents: []&#xA;Ignoring Class-Path entry lib/snakeyaml-1.13.jar found inC:\Users\NSPL-1508\.m2\repository\org\liquibase\liquibase-core\3.5.3\liquibase-core-3.5.3.jar as C:\Users\NSPL-1508\.m2\repository\org\liquibase\liquibase-core\3.5.3\lib\snakeyaml-1.13.jar does not exist&#xA;17:17:04.940 [main] DEBUG org.springframework.boot.devtools.settings.DevToolsSettings - Included patterns for restart : []&#xA;17:17:04.945 [main] DEBUG org.springframework.boot.devtools.settings.DevToolsSettings - Excluded patterns for restart : [/spring-boot-starter/target/classes/, /spring-boot-autoconfigure/target/classes/, /spring-boot-starter-[\w-]+/, /spring-boot/target/classes/, /spring-boot-actuator/target/classes/, /spring-boot-devtools/target/classes/]&#xA;17:17:04.946 [main] DEBUG org.springframework.boot.devtools.restart.ChangeableUrls - Matching URLs for reloading : [file:/E:/Recon%20Workspace%20New/AgreeGateway/target/classes/]&#xA;2017-08-28 17:17:07.200 DEBUG 5004 --- [kground-preinit] org.jboss.logging                        : Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property&#xA;&#xA;        â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—&#xA;        â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â•šâ•â•â–ˆâ–ˆâ•”â•â•â• â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â•â• â•šâ•â•â–ˆâ–ˆâ•”â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—&#xA;        â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•&#xA;  â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•â•â•   â•šâ•â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘&#xA;  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘  â•šâ–ˆâ–ˆâ•—&#xA;   â•šâ•â•â•â•â•â•  â•šâ•â•   â•šâ•â• â•šâ•â•â•â•â•â•â•â• â•šâ•â•       â•šâ•â•â•â•â•â•     â•šâ•â•    â•šâ•â•â•â•â•â•â•â• â•šâ•â•   â•šâ•â•&#xA;&#xA;:: JHipster ?  :: Running Spring Boot 1.5.4.RELEASE ::&#xA;:: https://jhipster.github.io ::&#xA;&#xA;2017-08-28 17:17:08.569  INFO 5004 --- [  restartedMain] com.nspl.app.AgreeGatewayV1App           : The following profiles are active: swagger,dev&#xA;2017-08-28 17:17:11.643 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.AsyncConfiguration   : Creating Async Task Executor&#xA;2017-08-28 17:17:12.800 DEBUG 5004 --- [  restartedMain] c.nspl.app.config.MetricsConfiguration   : Registering JVM gauges&#xA;2017-08-28 17:17:12.860 DEBUG 5004 --- [  restartedMain] c.nspl.app.config.MetricsConfiguration   : Monitoring the datasource&#xA;2017-08-28 17:17:12.868 DEBUG 5004 --- [  restartedMain] c.nspl.app.config.MetricsConfiguration   : Initializing Metrics JMX reporting&#xA;2017-08-28 17:17:14.198 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.CacheConfiguration   : Configuring Hazelcast&#xA;2017-08-28 17:17:14.229 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.CacheConfiguration   : Configuring Hazelcast clustering for instanceId: agreeGatewayV1&#xA;2017-08-28 17:17:14.229 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.CacheConfiguration   : Application is running with the ""dev"" profile, Hazelcast cluster will only work with localhost instances&#xA;2017-08-28 17:17:14.365  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1&#xA;2017-08-28 17:17:14.695  INFO 5004 --- [  restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson&#xA;2017-08-28 17:17:14.696  INFO 5004 --- [  restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson&#xA;2017-08-28 17:17:14.854  INFO 5004 --- [  restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml&#xA;2017-08-28 17:17:14.863  INFO 5004 --- [  restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml&#xA;2017-08-28 17:17:15.166  INFO 5004 --- [  restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration&#xA;2017-08-28 17:17:15.262  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false&#xA;2017-08-28 17:17:15.263  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null&#xA;2017-08-28 17:17:15.269  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false&#xA;2017-08-28 17:17:15.269  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false&#xA;2017-08-28 17:17:15.270  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true&#xA;2017-08-28 17:17:15.271  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true&#xA;2017-08-28 17:17:15.279  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server&#xA;2017-08-28 17:17:15.429  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200&#xA;2017-08-28 17:17:15.434  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 5&#xA;2017-08-28 17:17:15.443  INFO 5004 --- [  restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 12&#xA;2017-08-28 17:17:15.462  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1503920835462 with initial instances count: 1&#xA;2017-08-28 17:17:15.614 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.CacheConfiguration   : Adding Hazelcast (dev) cluster member 127.0.0.1:13781&#xA;2017-08-28 17:17:15.671  INFO 5004 --- [  restartedMain] c.h.instance.DefaultAddressPicker        : [LOCAL] [dev] [3.7.7] Picked [127.0.0.1]:13781, using socket ServerSocket[addr=/0:0:0:0:0:0:0:0,localport=13781], bind any local is true&#xA;2017-08-28 17:17:15.695  INFO 5004 --- [  restartedMain] com.hazelcast.system                     : [127.0.0.1]:13781 [dev] [3.7.7] Hazelcast 3.7.7 (20170404 - e3c56ea) starting at [127.0.0.1]:13781&#xA;2017-08-28 17:17:15.697  INFO 5004 --- [  restartedMain] com.hazelcast.system                     : [127.0.0.1]:13781 [dev] [3.7.7] Copyright (c) 2008-2016, Hazelcast, Inc. All Rights Reserved.&#xA;2017-08-28 17:17:15.702  INFO 5004 --- [  restartedMain] com.hazelcast.system                     : [127.0.0.1]:13781 [dev] [3.7.7] Configured Hazelcast Serialization version : 1&#xA;2017-08-28 17:17:15.934  INFO 5004 --- [  restartedMain] c.h.s.i.o.impl.BackpressureRegulator     : [127.0.0.1]:13781 [dev] [3.7.7] Backpressure is disabled&#xA;2017-08-28 17:17:16.354 DEBUG 5004 --- [  restartedMain] c.h.internal.cluster.ClusterService      : [127.0.0.1]:13781 [dev] [3.7.7] Updating members [Member [127.0.0.1]:13781 - 11614668-abd2-48d1-bc55-84e4ce6e6534 this]&#xA;2017-08-28 17:17:16.362 DEBUG 5004 --- [  restartedMain] c.h.i.p.InternalPartitionService         : [127.0.0.1]:13781 [dev] [3.7.7] Adding Member [127.0.0.1]:13781 - 11614668-abd2-48d1-bc55-84e4ce6e6534 this&#xA;2017-08-28 17:17:16.383  INFO 5004 --- [  restartedMain] com.hazelcast.instance.Node              : [127.0.0.1]:13781 [dev] [3.7.7] Creating TcpIpJoiner&#xA;2017-08-28 17:17:16.526  INFO 5004 --- [  restartedMain] c.h.s.i.o.impl.OperationExecutorImpl     : [127.0.0.1]:13781 [dev] [3.7.7] Starting 4 partition threads&#xA;2017-08-28 17:17:16.528  INFO 5004 --- [  restartedMain] c.h.s.i.o.impl.OperationExecutorImpl     : [127.0.0.1]:13781 [dev] [3.7.7] Starting 3 generic threads (1 dedicated for priority tasks)&#xA;2017-08-28 17:17:16.536  INFO 5004 --- [  restartedMain] com.hazelcast.core.LifecycleService      : [127.0.0.1]:13781 [dev] [3.7.7] [127.0.0.1]:13781 is STARTING&#xA;2017-08-28 17:17:16.537 DEBUG 5004 --- [  restartedMain] c.h.i.p.InternalPartitionService         : [127.0.0.1]:13781 [dev] [3.7.7] Adding Member [127.0.0.1]:13781 - 11614668-abd2-48d1-bc55-84e4ce6e6534 this&#xA;2017-08-28 17:17:16.539  INFO 5004 --- [  restartedMain] c.h.n.t.n.NonBlockingIOThreadingModel    : [127.0.0.1]:13781 [dev] [3.7.7] TcpIpConnectionManager configured with Non Blocking IO-threading model: 3 input threads and 3 output threads&#xA;2017-08-28 17:17:16.540 DEBUG 5004 --- [  restartedMain] c.h.n.t.n.NonBlockingIOThreadingModel    : [127.0.0.1]:13781 [dev] [3.7.7] IO threads selector mode is SELECT&#xA;2017-08-28 17:17:16.567 DEBUG 5004 --- [  restartedMain] com.hazelcast.cluster.impl.TcpIpJoiner   : [127.0.0.1]:13781 [dev] [3.7.7] [127.0.0.1]:13781 is local? true&#xA;2017-08-28 17:17:16.569 DEBUG 5004 --- [  restartedMain] com.hazelcast.cluster.impl.TcpIpJoiner   : [127.0.0.1]:13781 [dev] [3.7.7] This node will assume master role since no possible member where connected to.&#xA;2017-08-28 17:17:16.570 DEBUG 5004 --- [  restartedMain] com.hazelcast.cluster.impl.TcpIpJoiner   : [127.0.0.1]:13781 [dev] [3.7.7] PostJoin master: [127.0.0.1]:13781, isMaster: true&#xA;2017-08-28 17:17:16.571  INFO 5004 --- [  restartedMain] com.hazelcast.cluster.impl.TcpIpJoiner   : [127.0.0.1]:13781 [dev] [3.7.7]&#xA;&#xA;&#xA;Members [1] {&#xA;        Member [127.0.0.1]:13781 - 11614668-abd2-48d1-bc55-84e4ce6e6534 this&#xA;}&#xA;&#xA;2017-08-28 17:17:16.867  INFO 5004 --- [  restartedMain] com.hazelcast.core.LifecycleService      : [127.0.0.1]:13781 [dev] [3.7.7] [127.0.0.1]:13781 is STARTED&#xA;2017-08-28 17:17:17.932 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Registering CORS filter&#xA;2017-08-28 17:17:18.142  WARN 5004 --- [  restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.&#xA;2017-08-28 17:17:18.602  INFO 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Web application configuration, using profiles: swagger&#xA;2017-08-28 17:17:18.609 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Initializing Metrics registries&#xA;2017-08-28 17:17:18.615 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Registering Metrics Filter&#xA;2017-08-28 17:17:18.621 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Registering Metrics Servlet&#xA;2017-08-28 17:17:18.625  INFO 5004 --- [  restartedMain] com.nspl.app.config.WebConfigurer        : Web application fully configured&#xA;2017-08-28 17:17:18.955 DEBUG 5004 --- [  restartedMain] c.nspl.app.config.DatabaseConfiguration  : Configuring Liquibase&#xA;2017-08-28 17:17:18.968  WARN 5004 --- [-v-1-Executor-1] i.g.j.c.liquibase.AsyncSpringLiquibase   : Starting Liquibase asynchronously, your database might not be ready at startup!&#xA;2017-08-28 17:17:20.560  INFO 5004 --- [  restartedMain] c.h.h.HazelcastCacheRegionFactory        : Starting up HazelcastCacheRegionFactory&#xA;2017-08-28 17:17:20.661  INFO 5004 --- [  restartedMain] c.h.h.instance.HazelcastInstanceFactory  : Using existing HazelcastInstance [agreeGatewayV1].&#xA;2017-08-28 17:17:20.791  INFO 5004 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AGREEGATEWAYV1/agreeGatewayV1:bd66d684631aa5c9bfbec0fc594b7207 - Re-registering apps/AGREEGATEWAYV1&#xA;2017-08-28 17:17:20.792  INFO 5004 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AGREEGATEWAYV1/agreeGatewayV1:bd66d684631aa5c9bfbec0fc594b7207: registering service...&#xA;2017-08-28 17:17:20.814 DEBUG 5004 --- [-v-1-Executor-1] i.g.j.c.liquibase.AsyncSpringLiquibase   : Liquibase has updated your database in 1843 ms&#xA;2017-08-28 17:17:20.859  INFO 5004 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AGREEGATEWAYV1/agreeGatewayV1:bd66d684631aa5c9bfbec0fc594b7207 - registration status: 204&#xA;2017-08-28 17:17:24.980 DEBUG 5004 --- [  restartedMain] com.nspl.app.config.CacheConfiguration   : Starting HazelcastCacheManager&#xA;2017-08-28 17:17:28.070 DEBUG 5004 --- [  restartedMain] i.g.j.c.apidoc.SwaggerConfiguration      : Starting Swagger&#xA;2017-08-28 17:17:28.081 DEBUG 5004 --- [  restartedMain] i.g.j.c.apidoc.SwaggerConfiguration      : Started Swagger in 6 ms&#xA;2017-08-28 17:17:29.329  WARN 5004 --- [  restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.&#xA;2017-08-28 17:17:29.565  WARN 5004 --- [  restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with key 'zuulEndpoint' has been registered as an MBean but has no exposed attributes or operations&#xA;2017-08-28 17:17:30.066  INFO 5004 --- [  restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1503920850066, current=UP, previous=STARTING]&#xA;2017-08-28 17:17:30.833  INFO 5004 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AGREEGATEWAYV1/agreeGatewayV1:bd66d684631aa5c9bfbec0fc594b7207: registering service...&#xA;2017-08-28 17:17:31.038  INFO 5004 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AGREEGATEWAYV1/agreeGatewayV1:bd66d684631aa5c9bfbec0fc594b7207 - registration status: 204&#xA;2017-08-28 17:17:31.329  INFO 5004 --- [  restartedMain] com.nspl.app.AgreeGatewayV1App           : Started AgreeGatewayV1App in 26.345 seconds (JVM running for 27.598)&#xA;2017-08-28 17:17:31.338  INFO 5004 --- [  restartedMain] com.nspl.app.AgreeGatewayV1App           :&#xA;----------------------------------------------------------&#xA;        Application 'agreeGatewayV1' is running! Access URLs:&#xA;        Local:          http://localhost:8080&#xA;        External:       http://192.168.0.33:8080&#xA;        Profile(s):     [swagger, dev]&#xA;----------------------------------------------------------&#xA;2017-08-28 17:17:31.346  INFO 5004 --- [  restartedMain] com.nspl.app.AgreeGatewayV1App           :&#xA;----------------------------------------------------------&#xA;        Config Server:  Connected to the JHipster Registry config server!&#xA;----------------------------------------------------------&#xA;</code></pre>&#xA;"
46014427,spring-boot client unable to start with consul,2017-09-02 13:43:14,<spring><spring-boot><microservices><consul><spring-cloud-consul>,1,961,2,1.0,0,"<p>I have setup and run consul using docker on my system using following command:</p>&#xA;&#xA;<pre><code>sudo docker run -p 8500:8500 consul:0.9.2&#xA;</code></pre>&#xA;&#xA;<p>Consul is running fine as I can check from the consul UI (Image attached below):</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ggLtF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ggLtF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Now, I am trying to run my spring-boot service to use this consul instance for service discovery and registration. But, whenever i start it gives me following exception:</p>&#xA;&#xA;<pre><code>2017-09-02 18:58:17.091 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:18.183 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:19.375 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:20.691 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:22.114 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:23.671 ERROR 5578 --- [  restartedMain] o.s.c.c.c.ConsulPropertySourceLocator    : Fail fast is set and there was an error reading configuration from consul.&#xA;2017-09-02 18:58:23.691 ERROR 5578 --- [  restartedMain] o.s.boot.SpringApplication               : Application startup failed&#xA;&#xA;com.ecwid.consul.v1.OperationException: OperationException(statusCode=500, statusMessage='Internal Server Error', statusContent='No cluster leader')&#xA;    at com.ecwid.consul.v1.kv.KeyValueConsulClient.getKVValues(KeyValueConsulClient.java:159)&#xA;    at com.ecwid.consul.v1.ConsulClient.getKVValues(ConsulClient.java:487)&#xA;    at org.springframework.cloud.consul.config.ConsulPropertySource.init(ConsulPropertySource.java:66)&#xA;    at org.springframework.cloud.consul.config.ConsulPropertySourceLocator.create(ConsulPropertySourceLocator.java:157)&#xA;    at org.springframework.cloud.consul.config.ConsulPropertySourceLocator.locate(ConsulPropertySourceLocator.java:131)&#xA;    at org.springframework.cloud.consul.config.ConsulPropertySourceLocator$$FastClassBySpringCGLIB$$b35ebf8.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)&#xA;    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;    at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:91)&#xA;    at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:286)&#xA;    at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:163)&#xA;    at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:118)&#xA;    at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:152)&#xA;    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)&#xA;    at org.springframework.cloud.consul.config.ConsulPropertySourceLocator$$EnhancerBySpringCGLIB$$66375879.locate(&lt;generated&gt;)&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:93)&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:567)&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:338)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:301)&#xA;    at com.pyg.auth.AuthServiceApp.main(AuthServiceApp.java:71)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)&#xA;</code></pre>&#xA;&#xA;<p>SpringBoot Main Class is annotated fine (I guess), because my spring-boot service was working fine with another consul instance earlier.</p>&#xA;"
46021905,"microservices, server-sent events, and browser limitations",2017-09-03 09:15:10,<rest><microservices><server-sent-events>,1,110,3,0.0,0,"<p>In a micro-service oriented architecture, where each micro-service offers an SSE endpoint to stream events to the client, an HTTP connection is opened and kept alive between the client and the service. Unfortunately, this approach is almost unpractical when the client runs within a Web Browser because Web Browsers have a limitation on the number of HTTP connections that can be opened simultaneously on the same server (by domain name if I'm not wrong).</p>&#xA;&#xA;<p>It's a pity because SSE is a great technology for streaming events.</p>&#xA;&#xA;<p>What's the best approach for streaming events in a micro-service oriented architecture then, when the client runs in a browser?</p>&#xA;"
45964527,Microservice passing entity id guid or unique code,2017-08-30 15:35:26,<rest><wcf><domain-driven-design><microservices>,1,169,3,0.0,0,"<p>We have two different microservices Customer service and Order service. Customer service store information about customer i.e. Name, DOB, etc. The Order service will mange the order that a customer has place i.e order number, cost etc. Which is the best way to passing customer unique reference/ ID to order services.</p>&#xA;&#xA;<p>Solution 1:&#xA;Customer ID is a GUID uniquely in Customer service. This will be passed to the Order service</p>&#xA;&#xA;<p>Solution 2:&#xA;Generate a business/human friendly unique code in Customer service and pass it to Order service</p>&#xA;&#xA;<p>Solution 3:&#xA;Something else?</p>&#xA;"
45855433,Microservices Config and eureka service which one to start first?,2017-08-24 07:27:40,<spring-boot><intellij-idea><microservices><netflix-eureka><netflix>,1,577,4,0.0,0,"<p>I am creating a simple project in microservices using spring boot and netflix OSS to get my hands dirty. I have created two services</p>&#xA;&#xA;<ol>&#xA;<li>config service which has to register itself in discovery(eureka)&#xA;service. </li>&#xA;<li>discovery service which requires config service to be running to get its configuration.</li>&#xA;</ol>&#xA;&#xA;<p>Now when I am starting these services, both services fails due to inter dependency. What are the best practices resolve this issue and which one to start first.</p>&#xA;&#xA;<p>PS:- I know I am creating circular dependency, But what is the way to deal with situation like this where I want to keep eureka configuration also with the config server</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45996858,Self-contained microservices with Docker,2017-09-01 09:14:22,<docker><docker-compose><microservices>,1,92,5,0.0,0,"<p>I'm trying to setup a project built up of several microservices orchestrated with Docker. Here is the simplified schema of my project:</p>&#xA;&#xA;<pre><code>- Main-project&#xA;  - Dockerfile&#xA;  - docker-compose.yml (bundles Microservice1 and Microservice2)&#xA;&#xA;- Microservice1&#xA;  - Dockerfile&#xA;&#xA;- Microservice2&#xA;  - Dockerfile&#xA;</code></pre>&#xA;&#xA;<p>Now, each component has many dependencies such as RabbitMQ managed by the docker-compose.yml file. I manage to make the whole project run on Docker by using the compose file.</p>&#xA;&#xA;<p>However, I'm having problems in running the individual components by itself. The problem is that Microservice1 depends on rabbitMQ but it does not have a compose file to manage this dependency, and the same goes for all other components. So when I try to run any individual component by itself (for unit-tests, for instances) I have a problem of missing dependencies.</p>&#xA;&#xA;<p>Should I add all the dependencies also on the Dockerfile of each component? &#xA;Should I have one docker-compose file per component?&#xA;What are the best practices to setup a system like this?</p>&#xA;&#xA;<p>Thanks a lot!</p>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>As an important note, I forgot to mention that each microservice has its own repo.</p>&#xA;"
45626777,Inter process(service) communication without message queue,2017-08-11 04:03:21,<rabbitmq><jms><activemq><message-queue><microservices>,1,257,0,1.0,0,"<p>We want to develop an application based on micro services architecture.&#xA;To communicate between various services asynchronously, we plan to use message queues(like RabbitMQ,ActiveMQ,JMS etc.,) . Is there any approach other than message queue is available to achieve inter process communication? </p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
45766604,Linking a docker container a subdirectory of another one,2017-08-19 00:40:01,<docker><networking><subdomain><microservices>,2,276,0,1.0,0,"<p>I am trying to setup multiple docker containers that can be accessed through one main container.</p>&#xA;&#xA;<p>For example:<br>&#xA;<code>http://localhost:80</code> is the main container<br>&#xA;<code>http://localhost:80/site1</code> is a separate container<br>&#xA;<code>http://localhost:80/site2</code> is a separate container again</p>&#xA;&#xA;<p>I know that the <code>--link</code> flag has been deprecated and the new way of doing things is by using the <code>--network</code> flag. </p>&#xA;&#xA;<p>When I use the <code>--link</code> (for testing) I see an entry of the container I am linking to in the hosts file. That is where I am stuck.</p>&#xA;&#xA;<p>So I would like to set the above scenario up using the docker --networking option.</p>&#xA;&#xA;<p>Usage case: <code>/Site1</code> might be the admin area or member to a website, but I would like to have them in separate containers so I can maintain them easier.</p>&#xA;&#xA;<p>The containers are apache2 based, but if possible would like to refrain from editing any config files (but I can if I need to)</p>&#xA;&#xA;<p><strong>How would I go about that?</strong></p>&#xA;"
45698451,Where to store account/customer Data in a SPA for RESTful API (Gateway)?,2017-08-15 17:42:31,<angular><rest><api><single-page-application><microservices>,1,38,0,0.0,0,<p>WeÂ´re developing a SPA in Angular with a Microservice oriented architecture. Meaning there is an API gateway exposing an API to the SPA. Behind the API Gateway there a several microservices like a customer service. The API gateway is responsible also for authentication and acts as proxy for the underlying microservices at the moment. Authentication will be handled with Oauth and an encrypted Cookie.</p>&#xA;&#xA;<p>Now consider the API gateway exposes an endpoint like /customers/{id}/orders to the SPA meaning the SPA has to know the customer id in this case. How do you handle the situations where you have to store customer/account specific data in a SPA/Browser to call a RESTful API (gateway)? Should the API gateway expose such an endpoint? Or better get the data from the authenticated user and the call then related microservice? Meaning to expose an endpoint like e.g. customers/orders? Without customer specific information.</p>&#xA;&#xA;<p>I know there is LocalStorage etc. but it feels not good to store account/customer specific data in the browser.</p>&#xA;&#xA;<p>Many thanks for the discussion and input.</p>&#xA;
45789168,What is the difference between an API and Microservice?,2017-08-21 04:08:14,<api><microservices>,2,1331,0,1.0,0,"<p>I create my API rest with Django, but I don't understand how convert an API to micro services, I don't understand the real difference between these.&#xA;I see an API like a micro service, but I don't know convert an entire API in micro service, I need create micro web servers? </p>&#xA;&#xA;<p>Please, I can't understand a micro services, and I need understand this.</p>&#xA;"
45626670,Is it possible to generate '_id' as just numbers in MongoDB?,2017-08-11 03:47:52,<python><mongodb><python-3.x><pymongo><microservices>,1,313,0,0.0,0,<p>I am implementing Microservices in Flask application.</p>&#xA;&#xA;<p>Service A runs on MySQL and Service B runs on MongoDB using pymongo.</p>&#xA;&#xA;<p>The ID from Service B is linked as an Integer field in MySQL.</p>&#xA;&#xA;<p>Is it possible to make MongoDB generate '_id' as a sequence of just numbers instead of alphanumeric characters or should I go about changing the schema of MySQL ?</p>&#xA;
45735971,"When scaling a Cloud Foundry app, is the memory split among the instances?",2017-08-17 13:07:02,<cloudfoundry><microservices><scaling>,1,103,0,0.0,0,"<p>I have an application deployed through Cloud Foundry which has to be scaled. This can be achieved using the command <a href=""https://docs.cloudfoundry.org/devguide/deploy-apps/cf-scale.html"" rel=""nofollow noreferrer""><code>cf scale</code></a>, where the scaling can be done either <em>horizontally</em> (adjust number of instances) or <em>vertically</em> (adjust disk space limit and memory limit).</p>&#xA;&#xA;<p>Suppose that I scale my  application such that it has 5 instances and 32 GB memory. Does <strong>each</strong> instance get to have 32 GB memory, or is the memory divided among the 5 instances, resulting in 6.4 GB memory per instance? </p>&#xA;"
45630225,ETL on Google Cloud - (Dataflow vs. Spring Batch) -> BigQuery,2017-08-11 08:17:25,<google-bigquery><kubernetes><spring-batch><microservices><google-cloud-dataflow>,1,381,0,0.0,0,"<p>I am considering BigQuery as my data warehouse requirement. Right now, I have my data in google cloud (cloud SQL and BigTable). I have exposed my REST APIs to retrieve data from both. Now, I would like to retrieve data from these APIs, do the ETL and load the data into BigQuery. I am evaluating 2 options of ETL (daily frequency of job for hourly data) right now:-</p>&#xA;&#xA;<ol>&#xA;<li>Use JAVA Spring Batch and create microservice and use Kubernetes as deployment environment. Will it scale?</li>&#xA;<li>Use Cloud DataFlow for ETL</li>&#xA;</ol>&#xA;&#xA;<p>Then use BigQuery batch insert API (for initial load) and streaming insert API (for incremental load when new data available in source) to load BigQuery denormalized schema.</p>&#xA;&#xA;<p>Please let me know your opinions.</p>&#xA;"
45695032,Where to aggregate raw data analytics within microservice architecture,2017-08-15 14:30:39,<java><architecture><analytics><microservices><aggregation>,1,145,0,1.0,0,<p>We need to aggregate analytics for our backoffice. the analytics specs are crossed all over our system where each microservice create it's own raw data. question Where should we aggregate this raw data for analytics purposes: (I thought about two ways)</p>&#xA;&#xA;<ol>&#xA;<li><p>We should create another new service (e.g analytics-service) that will aggregate all the raw data from all services(by push the data to into it) and prepare the aggregations after that having backoffice taking final results </p></li>&#xA;<li><p>Each service will aggregate it's own analytics and our backoffice will send requests (and cache) the aggregated results from all the microservices ?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks.</p>&#xA;
45782033,Common protobuf data types in microservice architecture?,2017-08-20 12:17:52,<protocol-buffers><microservices><grpc>,1,169,0,0.0,0,"<p>We are thinking of implementing some kind of microservice architecture. We will have software maintained by multiple teams and we would use grpc with protobuf 3 as a serialization mechanism for point to point communication. The goal is to decouple business logic from application logic on one hand and to allow UIs spanning multiple business contexts on the other hand.</p>&#xA;&#xA;<p>Microservices will sometimes have to handle data similar or identical to data handled by other microservices. </p>&#xA;&#xA;<p>In this context, is it advisable to extract those common proto3 data types, handle them separately and import them as dependencies into each microservice? That way they could be reused in multiple services.</p>&#xA;&#xA;<p>Or is it better to focus on decoupling the microservices from each other by not sharing any (common) data types (share nothing architecture)?</p>&#xA;"
45666983,What Microservices pattern is appropriate for transfering large data file,2017-08-14 03:19:17,<design-patterns><microservices><enterprise-architecture>,1,171,0,0.0,0,<p>If a large JASON file(10mb) is needed for processing by multiple Microservices what's the best Enterprise Architectural/Design pattern to use? Entire data in the file is needed by each Microservices in order to process it.</p>&#xA;
45667346,Broadcast message in microservices and run it once in multiple instances,2017-08-14 04:09:51,<messaging><microservices><broadcast><jgroups>,2,218,0,0.0,0,"<p>I'm using micro services, suppose I have 3 services and they all are connected to each other through a JGroup UDP channel (JGroups can broadcast messages between them):</p>&#xA;&#xA;<pre><code> ---            ---  ---&#xA;| A | --msg--&gt; | B || C |&#xA; ---            ---  ---&#xA;</code></pre>&#xA;&#xA;<p>If I have just one instance of each service, everything in fine. But for example, if I have two instances of service <code>C</code>, both of them will receive the event and both of them will run their own procedure and the result would be duplicated in the database (sum the value two times).</p>&#xA;&#xA;<pre><code> ---            ---  ---  ---&#xA;| A | --msg--&gt; | B || C || C |&#xA; ---            ---  ---  ---&#xA;</code></pre>&#xA;&#xA;<p>Is there any way to manage this?</p>&#xA;"
45629284,How to manage nodejs microservices without service discovery?,2017-08-11 07:24:12,<node.js><microservices><service-discovery>,1,492,0,0.0,0,"<p>We are developing microservices in NodeJS and deploying them to an Application server. These services run on random port which is set in config file programmatically. I know these services could be managed using service discovery like Eureka / Consul and similar. However, is there a way to manage them without using any service discovery.</p>&#xA;"
45794390,how can i test angular app in docker environment without opening the browser?,2017-08-21 10:05:58,<angularjs><testing><docker><phantomjs><microservices>,1,284,1,0.0,0,"<p>currently, am trying to run the unit test cases of angular app in docker environment using ng test so it opens up a browser I don't need that in prod to happen so I tried RUN ng test --browser PhantomJS but it ain't working.</p>&#xA;&#xA;<p>am getting this error&#xA;22 08 2017 11:52:42.355:WARN [karma]: No captured browser, open <a href=""http://localhost:9876/"" rel=""nofollow noreferrer"">http://localhost:9876/</a>&#xA;22 08 2017 11:52:42.370:INFO [karma]: Karma v1.7.0 server started at <a href=""http://0.0.0.0:9876/"" rel=""nofollow noreferrer"">http://0.0.0.0:9876/</a>&#xA;22 08 2017 11:52:42.370:INFO [launcher]: Launching browser PhantomJS with unlimited concurrency&#xA;22 08 2017 11:52:42.382:INFO [launcher]: Starting browser PhantomJS&#xA; 68% building modules 507/523 modules 16 active .../rxjs/observable/PromiseObs22 08 2017 11:52:53.039:WARN [karma]: No captured browser, open localhost:9876/&#xA;22 08 2017 11:53:42.382:WARN [launcher]: PhantomJS have not captured in 60000 ms, killing.&#xA;22 08 2017 11:53:44.383:WARN [launcher]: PhantomJS was not killed in 2000 ms, sending SIGKILL.&#xA;22 08 2017 11:53:46.385:WARN [launcher]: PhantomJS was not killed by SIGKILL in 2000 ms, continuing.</p>&#xA;"
45729153,Spring Sleuth Logback Integration logs not displaying the service name,2017-08-17 07:35:57,<logstash><logback><microservices><spring-cloud-sleuth>,1,741,1,1.0,0,"<p>In my microservice i have added spring -sleuth 1.2.1 and i have received the logs as i expected, which is shown in below</p>&#xA;&#xA;<p>2017-08-16 09:58:51.864  INFO [microServiceName,9434118b965d573e,9434118b965d573e,true] 1328 --- [io-8081-exec-10] com.cibc.icap.MyController       : Eligible for Vote</p>&#xA;&#xA;<p>As per my requirement I need to pass the logs from my application to logstash server so i have created logback.xml and added dependency logstash-logback-encoder-4.5.1 and added the appender in logback.xml net.logstash.logback.appender.LogstashTcpSocketAppender my logback.xml looks like&#xA;now the logs are passing from my application to logstash but the problem is in the log I am not getting my microservice name as expected, The log looks like below after adding the logback.xml </p>&#xA;&#xA;<p>2017-08-17 12:35:27.781  INFO [bootstrap,0e26cf339a6e69bc,0e26cf339a6e69bc,true] 4884 --- [nio-8081-exec-7] com.cibc.icap.AssessmentController</p>&#xA;&#xA;<p>link for my logback.xml </p>&#xA;"
45644454,I can't consume microservice Spring,2017-08-11 22:10:47,<spring><spring-mvc><controller><microservices><axios>,1,39,2,0.0,0,"<p>I'm learning java Spring and I want to consume one microservice so I created a form in HTML and I try to send the user and password with axios</p>&#xA;&#xA;<pre><code>var helloWorld = new Vue({&#xA;el: '#vue-app',&#xA;    data: &#xA;{&#xA;    user: ""user"",&#xA;    username : """",&#xA;    password : """"&#xA;},&#xA;methods: &#xA;{&#xA;    enviar: function()&#xA;    {&#xA;         axios.post('/user/login', {&#xA;             user: this.username,&#xA;             password: this.password&#xA;         })&#xA;         .then(function (response) {&#xA;             console.log(response);&#xA;         })&#xA;         .catch(function (error) {&#xA;             console.log(error);&#xA;         });&#xA;    }&#xA;}&#xA;&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>and I try to get the information</p>&#xA;&#xA;<pre><code>@Controller(""/user"")&#xA;public class UserController {&#xA;&#xA;private final Log log = LogFactory.getLog(UserController.class);&#xA;&#xA;@PostMapping(""/login"")&#xA;public boolean login(@RequestParam(""user"") String user, @RequestParam(""password"") String password)&#xA;{&#xA;    log.info(""user: "" + user + "" password: "" + password);&#xA;    return user.equals(""hitzu"") &amp;&amp; password.equals(""250693"");&#xA;&#xA;}&#xA;}`&#xA;</code></pre>&#xA;&#xA;<p>But when I try to run the code I get error 404 and I try to set the URL in Postman </p>&#xA;&#xA;<p><a href=""http://localhost:8080/user/login?user=hitzu&amp;password=250693"" rel=""nofollow noreferrer"">http://localhost:8080/user/login?user=hitzu&amp;password=250693</a></p>&#xA;&#xA;<p>but get the same error. </p>&#xA;"
45757001,REST API Autowire remote or local implementation of a service automatically,2017-08-18 12:44:05,<java><spring><rest><spring-boot><microservices>,2,167,2,0.0,0,"<p>I have a REST API built on Spring Boot consisting of 2 seperate web services. I don't know if those two web services will be hosted on the same machine so I want to make remote and local implementation for all services. Example below:</p>&#xA;&#xA;<p>Local service implementation:</p>&#xA;&#xA;<pre><code>public class LocalExampleService implements ExampleService{&#xA;&#xA;   public Item getItem(long id){&#xA;      //Get item using implementation from another local project&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Remote service implementation:</p>&#xA;&#xA;<pre><code>public class RemoteExampleService implements ExampleService{&#xA;&#xA;   @Value(""${serviceURL}"")&#xA;   private String serviceURL;&#xA;&#xA;   public Item getItem(long id){&#xA;      //Get item calling remote service&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Controller:</p>&#xA;&#xA;<pre><code>public class MyController{&#xA;    @Autowired&#xA;    private ExampleService exampleService;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Web service has many services with local and remote implementation and I want to let Spring know which type of implementation it should choose for all services.</p>&#xA;&#xA;<p>I've been thinking about putting url in properties file and during intialization the app would check whether properties contain url and then autowire service approprietly. But then I would have to write logic for every service autowiring.  </p>&#xA;&#xA;<p>What's the best option to autowire correct service implementation automatically?</p>&#xA;"
45762128,Microservice architectural clarification,2017-08-18 17:36:48,<c#><microservices>,1,75,3,0.0,0,"<p>I have a microservice architectured application. Where i have a CompanyService, an OrderService and a TransactionSevice. A user logs in and he can load all orders for his company. So the order has a CompanyId. Then it loads all Transactions for that order, so the transaction has an OrderId. I am going through some security thoughts. How can i make sure that the user only loads or saves transactions for the orders that belong to his company. I mean the TransactionService should not need to know about the Company (CompanyId). Is it something i should check just before saving? Eg check that the orderid belongs to the company or is there some other pattern?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
27347820,Distributed systems where to send requests?,2014-12-07 21:04:46,<distributed><microservices>,1,50,0,0.0,1,"<p>How do different components in a distributed system know where to send messages to access certain services? </p>&#xA;&#xA;<p>For example, lets say  I have a service which handles authentication, and a service which handles searching. How does the component which handles searching know where to send an authentication request? Are subdomains more commonly used? If so, how does replication work in this scenario? Is there some registry of local IP addresses which handles all this routing?</p>&#xA;"
27116051,Legacy application to communicate with cloud foundry using RabbitMQ,2014-11-24 23:20:44,<rabbitmq><cloudfoundry><microservices>,1,101,0,0.0,1,<p>I am new to cloud foundry and investigating possible ways for our legacy Java EE application to communicate asynchronously with an application running on cloud foundry.</p>&#xA;&#xA;<p>We are doing a lot of asynchronous work already and are publishing events to Active MQ.</p>&#xA;&#xA;<p>I know that cloud foundry has a possibility to bind with Rabbit MQ and my question is with the possibility for a cloud foundry running application to connect (listen) to an existing out of CF platform Rabbit MQ?</p>&#xA;&#xA;<p>Any idea on other alternatives to achieve this?</p>&#xA;
26705784,"port binding, load-balancer and scale-out architecture with embedded-tomcat and apache http server",2014-11-02 23:40:02,<tomcat><load-balancing><embedded-tomcat-7><12factor><microservices>,1,235,0,0.0,1,"<p>The <a href=""http://12factor.net"" rel=""nofollow"">12-factor app</a> suggests to use <a href=""http://12factor.net/port-binding"" rel=""nofollow"">port-binding</a> so that the app is completely self-contained. We can use embedded tomcat or jetty to achieve this but I was wondering what how scaling out is handled in this scenario. </p>&#xA;&#xA;<p><strong>Setup</strong></p>&#xA;&#xA;<p>Currently I have services exposed using embedded tomcat. I can use Apache HTTP server for load-balancing.</p>&#xA;&#xA;<p><strong>Question</strong></p>&#xA;&#xA;<p>How to dynamically add new services to scale-out in this scenario? I ask because adding new service means that I also need to add it as part of the EXISTING cluster.</p>&#xA;"
27489124,Connecting two Node/Express apps with streaming JSON,2014-12-15 16:58:01,<node.js><rest><stream><microservices>,1,311,1,2.0,1,"<p>I currently have two apps running...</p>&#xA;&#xA;<p>One is my REST API layer that provides a number of services to the frontend. &#xA;The other is a 'translation app', it can be fed a JSON object (over http POST call) , perform some data translation and mappings on that object and return it to the REST layer </p>&#xA;&#xA;<p>My situation is I want to do this for a large number of objects. The flow i want is: </p>&#xA;&#xA;<p><strong><em>User requests 100,000 objects in a specific format -> REST layer retrieves that from the database -> passes each JSON data object to&#xA;translation service to perform formatting -> pass each one back to the&#xA; REST layer -> REST layer returns new objects to the user.</em></strong></p>&#xA;&#xA;<p>What I don't want to do is call tranlate.example.com/translate on 100,000 different calls, or pass megabytes of data through 1 single huge POST request. </p>&#xA;&#xA;<p>So the obvious answer is streaming data to the translate app, and then streaming data back. </p>&#xA;&#xA;<p>There seems to be a lot of solutions to stream data across apps: open a websocket (socket.io) , open a raw TCP connection between the two, or since the HTTP request and response data of Node is actually a stream I could utilize that then emit a JSON object when its successfully translated</p>&#xA;&#xA;<p>My question is Is there a best practice here to stream data between two apps? It seems I should use http(req, res) stream and keep a long-lived connection open to preserve the 'REST' model. Any samples that could be provided would be great. </p>&#xA;"
27470721,How can I avoid duplication of business logic when batch processing?,2014-12-14 15:19:48,<java><batch-processing><spring-batch><microservices>,2,626,0,0.0,1,"<p>I have a web application dedicated to batch processing (batch service here on out, api driven) and I have the main web application that is dedicated to everything else. I've been struggling with making a decision on what the best way is to avoid duplication of business logic in the batch service. Both applications are clustered. The separation for batch processing has been okay for simple jobs, but I have more complex jobs where it would just cause chaos if the business logic were duplicated. Here's my use case for the purposes of this question.</p>&#xA;&#xA;<ol>&#xA;<li>Customer schedules a cron job for user updates.</li>&#xA;<li>Batch service is given a CSV file with 20,000 user records.</li>&#xA;<li>The batch service rips through the file performing validation on the records, basically a dry run.</li>&#xA;<li>The batch service will check the allowable change and error thresholds (percentages are counts)</li>&#xA;<li>If validation thresholds pass, the batch service will begin creating/updating users.</li>&#xA;<li>When users are created or updated, there are a number of modules/features that need to know about these events.</li>&#xA;<li>Job progress is tracked and customer can view progress, logs, and status of job.</li>&#xA;</ol>&#xA;&#xA;<p>Here are a few solutions I have been thinking about:</p>&#xA;&#xA;<ul>&#xA;<li>Jar up the business logic and share it across the two applications. This wouldn't necessarily be easy because the main application is a Grails application and it's got GORM littered throughout.</li>&#xA;<li>Have the batch service hit APIs on the main application for the create and updates and possibly the more complex validation scenarios. Worried about the toll this would take on tomcat, but calls would be going through the load balancer so they would be distributed.</li>&#xA;<li>Have the batch service hit APIs on the main application for validation, then queue create/update requests and let the main application retrieve them. Same as above, queue would help reduce http calls. Also would need a queue to report status back to batch service.</li>&#xA;<li>Duplicate some logic by having batch service do it's own validation and inserts/updates, but then fire a user created event or user updated event so modules/features in the main app can deal with the changes.</li>&#xA;<li>Embed the batch processing service into the main application</li>&#xA;</ul>&#xA;&#xA;<p>Other details:</p>&#xA;&#xA;<ul>&#xA;<li>The batch service and web application are both clustered</li>&#xA;<li>Both are running on AWS, so I have tools like SQS and SNS easily accessible</li>&#xA;<li>Java 1.7 applications</li>&#xA;<li>Tomcat containers</li>&#xA;<li>Main application is Grails</li>&#xA;<li>Batch service uses Spring Batch and Quartz at it's core</li>&#xA;</ul>&#xA;&#xA;<p>So my question is what are accepted ways to avoid duplication of business logic based on the details above? Can/Should the architecture be changed to better accommodate this?</p>&#xA;&#xA;<p>Another idea to consider is what would this look like and a ""microservices"" architecture. That word has been tossed around a number of times in the office and we have been considering the idea of breaking up the main web application into services. So for example, we may end up with a service for user management.</p>&#xA;"
28112290,How to parametrize Cloud Foundry service instance?,2015-01-23 14:41:20,<configuration><cloudfoundry><microservices>,2,332,0,1.0,1,"<p>My problem can be reduced to this case:&#xA;I want to have a service with single REST entrypoint returning some message. Because it is very useful to me I would like to have few instances of it but each returning different message that I specify. Of course each of those service instances would be bound to few apps. So I wonder how to accomplish something like that.</p>&#xA;&#xA;<p>It looks to me that the best way to do this would be passing some parameters during <strong>create</strong> call on broker (<a href=""http://docs.cloudfoundry.org/devguide/services/adding-a-service.html#create"" rel=""nofollow"">http://docs.cloudfoundry.org/devguide/services/adding-a-service.html#create</a>). But doing this is impossible. Do you know any way to create multiple instances of some service differing by some parameters passed during startup? I want to have full CF instance management (if it crashes it should be restarted etc.) and I would like to avoid creating them as apps with different parameters passed as environment variables ...</p>&#xA;&#xA;<p>UPDATE: Amount of different messages (and instances) can be quite big and their content is unknown in advance. This somehow disqualifies using service broker plans (one plan per message).</p>&#xA;"
28329738,Design approach for hosting multiple microservices on the same host,2015-02-04 19:28:01,<ruby><web-applications><docker><unix-socket><microservices>,1,407,0,0.0,1,"<p>I'm working on a Web application that I decoupled it in multiple containerized microservices. I have now around 20 services, but the whole system will definitely need more than 300. Most of the services now and some in the future will not need an entire machine so I'll deploy multiple services on a same host. I'm wondering how others deal with interservice communication. My preferred way was to go with a REST based communication but...</p>&#xA;&#xA;<p>Isn't it too heavy to have multiple web servers running on the same machine? I'm developing in Ruby, but even a lightweight web server like Puma can consume a good amount of memory</p>&#xA;&#xA;<p>I started writing a custom communication channel using UNIX sockets. So, I'd start one web server and  my ""router"" app would communicate with the currently running services on that host through UNIX sockets.  But I don't know if it's worth the effort and on top of that, all services have to be written and customized to use this kind of communication. I believe it would be hard to use any framework like Ruby-on-Rails or others, even different languages which is the whole appeal with microservices architecture. I feel like I'm trying to reinventing the wheel.</p>&#xA;&#xA;<p>So, can someone suggest a better approach or vote for one of my current ones?</p>&#xA;&#xA;<p>I appreciate any help,</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
25824957,Grouping Data in Microservices,2014-09-13 15:55:18,<rest><design-patterns><soa><microservices>,2,542,0,1.0,1,"<p>In a REST-based microservice architecture, what is the correct way to group related data under a single entity. For example, we may have a user service responsible for managing users. Additionally, we may have a service responsible for managing some kind of data stored for each of those users (let's assume for this example that we're talking about a user's items/inventory)</p>&#xA;&#xA;<p>We could separate the inventory management service and use it for creating inventories for anything, so I would ideally not want the inventory management system to require users in order to function.</p>&#xA;&#xA;<p>Is there a typical pattern to use that would provide the grouping I'm looking for (multiple inventory items to a single owner)? What would the rest endpoints look like to support such an architecture?</p>&#xA;"
26218391,Testing reusable components / services across multiple systems,2014-10-06 14:26:05,<testing><components><agile><platform><microservices>,1,84,0,1.0,1,"<p>I'm currently starting a new project where we are hoping to develop a new system using reusable components and services.</p>&#xA;&#xA;<p>We currently have 30+ systems that all have common elements, but at the moment we develop each system in isolation so it feels like we are often duplicating code and then of course we have 30+ separate code bases to maintain and support.</p>&#xA;&#xA;<p>What we would like to do is create a generic platform using shared components to enable quick development of new collections, reusing code and reusing automated tests and reduce the code base that needs to be maintained.  </p>&#xA;&#xA;<p>Our thoughts so far are that we would have a common code base for specific modules for example User Management and Secure System Access, these modules could consist of their own generic web module, API and Context.  This would create a generic package of code.</p>&#xA;&#xA;<p>We could then deploy these different components/packages  to build up a new system to save coding the same modules over and over again, so if the new system needed to manage users, you could get the User Management package and boom it does what you need.  However, because we have 30+ systems we will deploy the components multiple times for each collection.  Also we appreciate that some of the systems will need unique functionality so there would be the potential to add extensions to the generic modules for system specific needs OR to choose not to use one of the generic modules and create a new one, but use the rest of the generic components.</p>&#xA;&#xA;<p>For example if we have 4 generic components that make up the system A, B, C and D.  These could be deployed to create the following system set ups:</p>&#xA;&#xA;<p>System 1 - A, B, C and D (Happy with all generic components)</p>&#xA;&#xA;<p>System 2 - Aa, B, C and D (extended component A to include specific functionality)</p>&#xA;&#xA;<p>System 3 - A, E, C and F (Can't reuse components B and D so create specific ones, but still reuse components A and C)</p>&#xA;&#xA;<p>This is throwing up a few issues for me as I need to be able to test this platform and each system to ensure it works and this is the first time I've come across having to test a set up like this.</p>&#xA;&#xA;<p>I've done some reading around Mircroservices and how to test them, but these often approach the problem for just 1 system using microservices where we are looking at multiple systems with different configurations.</p>&#xA;&#xA;<p>My thoughts so far lead me to believe that for the generic components that will be utilised by the different collections I can create automated tests at the base code level and then those tests will confirm the generic functionality and therefore it will not be necessary to retest these functions again for each component, other than perhaps a manual sense check after deployment.  Then at each system level additional automated tests can be added to check the specific functionality that may be created.</p>&#xA;&#xA;<p>Ideally what I'd like would be to have some sort of testing platform set up so that if a change is made to a core component such as User Management it would be possible to trigger all the auto tests at the core level and then all of the specific system tests for all systems that will share the component to ensure that any changes don't affect core functionality or create a knock on effect to the specific systems.  Then a quick manual check would be required.  I'm keen to try and remove a massive manual test overhead checking 30+ systems each time a shared component is changed.</p>&#xA;&#xA;<p>We work in an agile way and for our current projects we have a strong continuous integration process set up, so when a developer checks in some code (Visual Studio) this triggers a CI build (TeamCity / Octopus) that will run all of the unit tests, provided that all these tests pass, this then triggers an Integration build that will run my QA Automated tests which are a mixture of tests run at an API level and Web tests using SpecFlow and PhantomJS or Selenium Webdriver.  We would like to keep this sort of framework in place to keep the quick feedback loops.</p>&#xA;&#xA;<p>It all sounds great in theory, but where I'm struggling is trying to put something into practice and create a sound testing strategy to cover this kind of system set up.</p>&#xA;&#xA;<p>So really what I'm hoping is that there is someone out there who has encountered something similar in the past and has thoughts on the best way to tackle this and has proven that they work.</p>&#xA;&#xA;<p>I'm keen to get a better understanding of how I could set up a testing platform / rig to aid the continuous integration for all systems considering that each system could potentially look different, yet have shared code.</p>&#xA;&#xA;<p>Any thoughts or links to blogs / whitepapers etc. that you think might help would be much appreciated!!</p>&#xA;"
50686734,Microservice Circuit Breaker and Discovery Service patterns,2018-06-04 18:31:10,<microservices><circuit-breaker>,1,28,0,0.0,1,"<p>I'm new to microservices and have this doubt that google hasn't really helped me out.&#xA;I know that a microservice has to be independent, so even if one of its counterpart goes offline, one should keep working normally.</p>&#xA;&#xA;<p>Having that in mind, I can't really understand circuit breaker or even service discovery, like where should do I put it? Since every call I make to any microservice goes through the circuit breaker, let's say my Circuit Breaker  service's server goes offline, so my whole application is doomed until I fix it. How to go around that?</p>&#xA;&#xA;<p>Most importantly, WHERE should I put the Circuit Breaker, in a microservice as well?</p>&#xA;"
50645878,Why Microservices better to be stateless in cloud applications?,2018-06-01 14:39:00,<cloud><microservices>,1,40,0,0.0,1,"<p>As far as I  understood they better to be stateless because the state of the overall application will be encapsulated inside a subset of micro services, avoiding it spreads over to the other components of the system (allowing them to&#xA;be stateless)</p>&#xA;&#xA;<p>Can someone elaborate/add on this ?</p>&#xA;&#xA;<p>Thank you </p>&#xA;"
50635469,Should we use api gateway(such as zuul) between microservices?,2018-06-01 02:53:33,<microservices><netflix-zuul><api-gateway>,1,45,0,0.0,1,<p>There is no doubt that API gateway should be the edge server to outside world.<br>We are wondering that should we use API gateway in the communications between the microservices? <br></p>&#xA;
50563413,What is the purpose of generating an Entity into the Jhipster Gateway?,2018-05-28 09:42:52,<microservices><jhipster><jhipster-registry>,2,47,0,0.0,1,"<p>I saw in many tutorials that we need to go back to gateway and generate an entity after generating a microservice application with the same entity.</p>&#xA;&#xA;<p>Can someone explain me, the architectural benefits of doing so? </p>&#xA;&#xA;<p>What is the goal of generating those entities again in Gateway?</p>&#xA;"
50555353,How to handle in Event Driven Microservices if the messaging queue is down?,2018-05-27 18:40:54,<multithreading><reactive-programming><message-queue><microservices><event-driven-design>,1,51,0,2.0,1,"<p>Assume there are two services <strong>A</strong> and <strong>B</strong>, in a microservice environment.</p>&#xA;&#xA;<p>In between A and B sits a messaging queue <strong>M</strong> that is a broker.</p>&#xA;&#xA;<p><strong>A&lt;---->'M'&lt;----->B</strong></p>&#xA;&#xA;<p>The problem is what if the broker M is down?</p>&#xA;&#xA;<p>Possible Solution i can think of:&#xA;Ping from Service A at regular intervals to check on Messaging queue <strong>M</strong> as long as it is down. In the meantime, service <strong>A</strong> &#xA;stores the data in a local DB and dumps it into the queue once the broker M is up.</p>&#xA;&#xA;<p>Considering the above problem, if someone can suggest whether threads or reactive programming is best suited for this scenario and ways it could be handled via code, I would be grateful.</p>&#xA;"
50566406,How to convert mvc architecture to micro service architecture?,2018-05-28 12:25:09,<node.js><express><microservices>,1,82,0,0.0,1,"<p>i have developed a shopping cart application using node.js and express framework. and there are 3 main modules in my app. user, cart, products are the those modules. it has been developed in MVC architecture. i would like to convert it to micro service architecture. how can i able to do that ? </p>&#xA;"
50653819,Communication between two microservices in JHipster using JWT,2018-06-02 05:32:09,<spring-security><jwt><microservices><jhipster>,1,153,0,0.0,1,"<p>I'm building a small microservice-based webapp using JHipster with JWT authorization. The Architecture is simple, one gateway and two services with repositories. The problem that I had for the last few hours is the communication between the two backend-services.</p>&#xA;&#xA;<p>At first, I tried to find a token on the services themself, but couldn't find it. If I just missed it in all the docs (quite overwhelming when beginning with the full stack :P), I would be happy to revert my changes and use the predefined token.</p>&#xA;&#xA;<p>My second approach was that each service will authorize itself with the gateway at PostConstruct and save the token in memory to use it each API call. It works without a problem, but I find it hard to believe that this functionality is not already programmed in JHipster.</p>&#xA;&#xA;<p>So my question is whether my approach is usual? If neither is true and there are some best-practices for it, I'm also interested in them.</p>&#xA;"
50678338,How to define API gateway URLs when splitting a monolith into microservices,2018-06-04 10:20:36,<microservices><netflix-zuul><api-gateway>,1,49,1,0.0,1,"<p>We are splitting a monolith application into microservices. This will be a gradual process, it means initially we will start with 2 microservices, later we will split them into more and so on. </p>&#xA;&#xA;<p>The monoligh exposes a REST API which provides methods for managing tens of different entities (e.g. users, user_types, roles, role_types, etc.). There is only one consumer of the REST API exposed by the monolith - a Javascript frontend app. </p>&#xA;&#xA;<p>We are currently investigating two possibilities how to configure the API gateway (Zuul):</p>&#xA;&#xA;<ol>&#xA;<li><p>URLs will contain the microservice name, e.g. <code>/api/dictionary</code> will serve <code>/api/dictionary/user_types</code> and <code>/api/dictionary/role_types</code>, while <code>/api/data</code> will serve <code>/api/data/users</code> and <code>/api/data/roles</code>. It means the URLs will change over time as we create more microservices. Everytime we do it the consumer (frontend) will have to be changed. </p></li>&#xA;<li><p>URLs will be based on the entity names, e.g. <code>/api/users</code>, <code>/api/user_types</code>, <code>/api/roles</code> and <code>/api/role_types</code>. The disadvantage is that the Zuul configuration will have to contain an explicit configuration for every single entity managed by the system.</p></li>&#xA;</ol>&#xA;&#xA;<p>Which of the above approaches is correct?</p>&#xA;"
50552293,maven archetype for payara micro,2018-05-27 12:46:31,<spring-boot><java-ee><microservices><wildfly-swarm><payara-micro>,2,61,1,0.0,1,"<p>I want to start a microservice project base on JEE 8 with payara micro. ( or maybe wildfly swarm). Anyway does anybody have a maven archetype for creating a microservice structure like those exist for spring boot ?</p>&#xA;&#xA;<p>A complete structure containing DAO , MODEL , CONTROLLER , VIEW , CONFIGURATION file and ...</p>&#xA;"
50571546,How can we use lagom's Read-side processor with Dgraph?,2018-05-28 18:03:08,<java><microservices><lagom><dgraph>,1,55,2,1.0,1,<p>I am a newbie to lagom and dgraph. And I got stuck to how to use lagom's read-side processor with <strong>Dgraph</strong>. Just to give you an idea following is the code which uses Cassandra with lagom.</p>&#xA;&#xA;<pre><code>import akka.NotUsed;&#xA;import com.lightbend.lagom.javadsl.api.ServiceCall;&#xA;import com.lightbend.lagom.javadsl.persistence.cassandra.CassandraSession;&#xA;import java.util.concurrent.CompletableFuture;&#xA;import javax.inject.Inject;&#xA;import akka.stream.javadsl.Source;&#xA;public class FriendServiceImpl implements FriendService {&#xA;&#xA;private final CassandraSession cassandraSession;&#xA;&#xA;@Inject&#xA;public FriendServiceImpl(CassandraSession cassandraSession) {&#xA;    this.cassandraSession = cassandraSession;&#xA;}&#xA;&#xA;//Implement your service method here&#xA;&#xA;}&#xA;</code></pre>&#xA;
50634072,Observer pattern in microservice,2018-05-31 23:14:13,<java><design-patterns><microservices><observer-pattern>,1,118,6,0.0,1,"<p>Currently I am reading the book called: Head First Pattern Design, there is one design pattern called: Observer pattern, like this: <a href=""https://www.tutorialspoint.com/design_pattern/observer_pattern.htm"" rel=""nofollow noreferrer"">https://www.tutorialspoint.com/design_pattern/observer_pattern.htm</a></p>&#xA;&#xA;<p>While I was reading that design pattern, I was feeling that currently we often use queuing system to publish and subscribe tasks between each microservices. Got a feeling that the Observer pattern is not quite often be used currently.  <strong>Please correct me if I am not right, if could provide some example about using observer pattern in mircoservice will be excellent!</strong></p>&#xA;"
29924248,Must Microservices based systems be all in the same network?,2015-04-28 15:57:59,<performance><cloud><load-balancing><microservices>,2,66,0,0.0,1,"<p>I have an web application that is separated in several components. For some reasons (pricing) I'm considering to deploy future components in different clouds.</p>&#xA;&#xA;<p>Does anybody has references and experience on this to tell me if this is definitely not good? I know that components being in different networks will decrease the performance. At the same time, I do not like the idea of losing the power of choice where the new components will be.</p>&#xA;&#xA;<p>Must Microservices based systems be all in the same network? How do you handle  this problem?</p>&#xA;"
28727632,What are the practical disadvantages of using strongly typed data interchange format (eg thrift / capn proto) in a microservices context?,2015-02-25 19:12:15,<json><serialization><thrift><microservices><data-interchange>,2,493,0,0.0,1,"<p>I'm thinking of introducing a strongly typed (read - with predefined schema) data interchange format for communication between our internal services. For example, I guess something like Thrift or Cap'n Proto.</p>&#xA;&#xA;<p>At least two obvious advantages (to me) of using this over something like JSON is that</p>&#xA;&#xA;<ol>&#xA;<li>you would KNOW the exact format of the data the service can expect (so leaves less room for ambiguity and errors while communicating) and </li>&#xA;<li>the implementation generally deserializes the raw message for you and it provides methods for accessing the objects.</li>&#xA;</ol>&#xA;&#xA;<p>What are the practical disadvantages for going this route, versus something like JSON?</p>&#xA;&#xA;<p>For context - our system consists of services written in python and java - and possibly other languages in the future, and communicates via HTTP endpoints between services and message brokers like rabbitmq.</p>&#xA;"
27838280,Oauth2 grant for server-to-server communication,2015-01-08 10:48:57,<web-services><oauth><oauth-2.0><microservices>,1,307,0,1.0,1,"<p>I'm working in a microservice architecture, which has its own oauth2 provider in order to allow services interaction. </p>&#xA;&#xA;<p>I need to develop a service that is granted to access users' resources in order to perform internal tasks on user accounts. Since the service needing to access user resource is an internal one it's not a viable solution to ask the user to allow access to their own resources.</p>&#xA;&#xA;<p>I'm concerned about the choice of picking the right grant to perform this tasks, as the <code>client_credentials</code> seems the right one, it also seems to be used to only allow to only update service data, instead of accessing user resources. Another solution I thought is to automatically provide the authorization code at users signup, as if the user has clicked an ""allow"" button, and then perform requests with that <code>code</code> grant. The downside here is that I have to create new authorization codes each time a service with that needs is created, but it seems to be a more clear solution (as auth code for user XXX only allows to access resources of user XXX).</p>&#xA;&#xA;<p>I also understand that implementations are different as the standard gives a lot of flexibility, but &#xA;Which one, in your opinion, is the appropriate solution? How would you handle it? Would it be more clear to say, ""statistic service"" is allowed to access all users resources or ""statistic service"" is granted by all users to access their resources?</p>&#xA;"
30496218,How to avoid Undertow Connection RESET in apache benchmark test?,2015-05-28 02:27:41,<nio><microservices><undertow><sysctl>,3,587,2,0.0,1,"<h2>Using apache benchmarking 100K request 20K concurrent users:</h2>&#xA;&#xA;<pre><code>   $ ab -n 100000 -c 20000 http://localhost:8080/mrs/ping&#xA;    Completed 10000 requests&#xA;    Completed 20000 requests&#xA;    Completed 30000 requests&#xA;    Completed 40000 requests&#xA;    Completed 50000 requests&#xA;    Completed 60000 requests&#xA;    Completed 70000 requests&#xA;    Completed 80000 requests&#xA;    Completed 90000 requests&#xA;    apr_socket_recv: Connection reset by peer (104)  &lt;&lt;&lt; HOW to overcome??&#xA;</code></pre>&#xA;&#xA;<h2>Below is the Undertow (version 1.2.6 + xnio-api 3.3.1) PingServer:</h2>&#xA;&#xA;<pre><code>public class UndertowPingServer {&#xA;&#xA;    private static Logger log = Logger.getLogger(UndertowPingServer.class);&#xA;&#xA;    public static void main(String[] args) throws ServletException {&#xA;&#xA;        PathHandler path = Handlers.path()&#xA;                .addPrefixPath(""/mrs/ping"", new HttpHandler() {&#xA;                    @Override&#xA;                    public void handleRequest(HttpServerExchange exchange) throws Exception {&#xA;                        exchange.getResponseHeaders().put(&#xA;                                Headers.CONTENT_TYPE, ""text/plain"");&#xA;                        exchange.getResponseSender().send(""Server Time:"" + new Date().toString() + ""\n\n"");&#xA;                    }&#xA;                });&#xA;Undertow.Builder builder = Undertow.builder()&#xA;   .setHandler(path)&#xA;   .addHttpListener(8080, ""0.0.0.0"")&#xA;   .setBufferSize(1024 * 16)&#xA;//this seems slightly faster in some configurations&#xA;  .setIoThreads(Runtime.getRuntime().availableProcessors() * 2) &#xA;                    .setSocketOption(Options.BACKLOG, 500000)&#xA;                    .setWorkerThreads(2000)&#xA;//don't send a keep-alive header for HTTP/1.1 requests, as it is not required&#xA;                    .setServerOption(UndertowOptions.ALWAYS_SET_KEEP_ALIVE, false); &#xA;            Undertow server = builder.build();&#xA;            server.start();&#xA;            log.info(""micro-service running!"");&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>All the needed linux kernel sockets and thread settings via sysctl are already done. That is why it can do the first 90K request with 20k users without issue.</p>&#xA;"
49843956,How to perform database queries in async microservices?,2018-04-15 16:01:52,<database><microservices><messaging>,1,29,1,0.0,1,"<p>I have problem with one concept about async microservices.</p>&#xA;&#xA;<p>Assume that all my services are subscribe to some event bus, and I have exposed API Gateway which takes HTTP request and translate them to AMQP protocol. </p>&#xA;&#xA;<p>How to handle GET requests to my API Gateway? Should I use RPC? For single entity itâ€™s ok, but what about some search or filtering (eg. get games by genre from Games service)? </p>&#xA;&#xA;<p>Iâ€™m thinking about using RPC for getting single entities by ids and creating separate Search service with Elastic which will expose some GET endpoints to API Gateway. But maybe somewhere itâ€™s simpler solution for my problem. Any ideas?</p>&#xA;&#xA;<p>Btw., Itâ€™s correct to translate HTTP requests from API Gateway to AMQP messages?</p>&#xA;"
49708997,Simple application in Microservices,2018-04-07 15:36:40,<microservices>,2,56,2,1.0,1,"<p>I am a newbie in Microservices, having theoretical knowledge. I want to make a small application in Microservices. Can anyone please help me with the idea of how to implement microservices?&#xA;Thanks in Advance!!</p>&#xA;"
31449013,Micro-services vs spring boot vs ordinary spring,2015-07-16 08:26:10,<spring><spring-boot><microservices>,1,256,0,0.0,1,"<p>What are advantages that Spring Boot gives you other than regular Spring?&#xA;I have seen that people say following things...</p>&#xA;&#xA;<ol>&#xA;<li>Run your code with defaults</li>&#xA;<li>Embedded server</li>&#xA;<li>Easy start no configs needed</li>&#xA;<li>...etc</li>&#xA;</ol>&#xA;&#xA;<p>I'm fine about these facts. But is there anything that Boot gives us other than RAD (Rapid Application Development)?</p>&#xA;&#xA;<p><a href=""https://spring.io/guides/gs/spring-boot/"" rel=""nofollow"">https://spring.io/guides/gs/spring-boot/</a> has a simple HelloController application which we also develop using Spring MVC.</p>&#xA;&#xA;<p>Other than the RAD I don't see any advantage. Please correct me if I'm wrong.</p>&#xA;&#xA;<p>I have heard that Spring Boot has designed to facilitate micro-services. For example I take <a href=""https://spring.io/guides/gs/spring-boot/"" rel=""nofollow"">https://spring.io/guides/gs/spring-boot/</a> HelloController application, can I assume this as a micro-service? If yes, what happens If I wanted to create another micro-service? Do I have to create another project for that?</p>&#xA;&#xA;<p>Assume you use servers such as Tomcat, Glassfish, etc. When Spring boot has embedded servers, How do I handle server configurations.&#xA;For example you want to add some parameters into your  in Tomcat.</p>&#xA;&#xA;<p>I'm confused with Spring boot and usage of it. Appreciate if anyone can explain.</p>&#xA;"
31295897,Should I use FrisbyJS for my REST API testing?,2015-07-08 14:37:41,<microservices><frisby.js>,1,328,0,2.0,1,"<p>I am developing a complicated project with microservice architecture (only provides Rest API). So I need to make sure that the system works stably in development, staging, and production after having a deployment.</p>&#xA;&#xA;<p>I think that a testing framework as Frisby can help me prevent issues. Do you have any suggestion for my case?</p>&#xA;&#xA;<p>Thank you in advance.</p>&#xA;"
31404820,Service locator - why not use DNS?,2015-07-14 11:04:07,<dns><soa><microservices>,3,144,1,0.0,1,"<p>There are a lot of applications that can take role of Service Locator in distributed environment AKA SOA. For example, Zookeeper and Consul. Why not use DNS instead?</p>&#xA;&#xA;<ul>&#xA;<li>Standard, well-known, stable</li>&#xA;<li>Distributed, fault-tolerant</li>&#xA;<li>Can assign multiple IPs to the same name for load balancing in homogeneous clusters</li>&#xA;<li>Can serve additional metadata</li>&#xA;</ul>&#xA;&#xA;<p>So... why not?</p>&#xA;"
48841121,MicroService with DCOS,2018-02-17 12:10:36,<microservices><dcos>,1,32,0,0.0,1,"<p>I decided to move to MicroService architecture, divide a project into multiple services and run those services on DCOS.It really gives a good story to project deployment and maintenance. But it makes development process complex.</p>&#xA;&#xA;<p>For the developer, it was easy to run the application locally while implementation is in progress.Now the project is divided into multiple services and runs on DCOS which require good configuration. so to test application for the developer in the middle of implementation becomes a nightmare. </p>&#xA;&#xA;<p>Guys, anyone is using DCOS with Microservice, can you please suggest what process you are following for internal development.</p>&#xA;"
48833778,How should we structure our models with microservices?,2018-02-16 19:42:19,<database><microservices>,2,55,0,0.0,1,"<p>For example, if I have a microservice with  this API:</p>&#xA;&#xA;<pre><code>service User {&#xA;    rpc GetUser(GetUserRequest) returns (GetUserResponse) {}&#xA;}&#xA;&#xA;message GetUserRequest {&#xA;    int32 user_id = 1; &#xA;}&#xA;&#xA;message GetUserResponse {&#xA;    int32 user_id = 1;&#xA;    string first_name = 2;&#xA;    string last_name = 3;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I figured that for other services that require users, I'm going to have to store this <code>user_id</code> in all rows that have data associated with that user ID. For example, if I have a separate Posts service, I would store the <code>user_id</code> information for every post author. And then whenever I want that user information to return data in an endpoint, I would need to make a network call to the User service.  </p>&#xA;&#xA;<p>Would I always want to do that? Or are there certain times that I want to just copy over information from the User service into my current service (excluding saving into in-memory databases like Redis)? </p>&#xA;"
48869041,Encapsulating a workflow or a series of actions,2018-02-19 15:13:52,<c#><.net><visual-studio-2017><microservices><azure-service-fabric>,2,78,0,0.0,1,"<p>I have a simple CRUD repository service. It executes operations against a remote repository. </p>&#xA;&#xA;<p>When creating/updating data, I need to orchestrate a series of actions:</p>&#xA;&#xA;<ol>&#xA;<li>Update a different database</li>&#xA;<li>Update CRM records</li>&#xA;<li>Update another database</li>&#xA;</ol>&#xA;&#xA;<p>I'm having trouble designing this orchestration from the perspective of making it maintainable / understandable. </p>&#xA;&#xA;<p>Assuming the above 3 steps are each the responsibilities of <em>other</em> microservices, <strong>what kind of pattern / architecture would this workflow be?</strong></p>&#xA;"
48959272,VSTS Workflow for Microservices / Share Service Endpoints,2018-02-24 04:09:18,<vsts><microservices><sharing><endpoint><projects>,1,99,0,1.0,1,"<p>We're using VSTS to deploy to an Azure Container Service (AKS) which is running Kubernetes.  We are building out a collection of microservices to share between several applications and, for the time being, this Kubernetes instance will manage most or all of our service orchestration.</p>&#xA;&#xA;<p>My confusion is with VSTS and the fact that - as stated <a href=""https://docs.microsoft.com/en-us/vsts/build-release/concepts/library/service-endpoints"" rel=""nofollow noreferrer"">here</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Service endpoints are created at project scope. An endpoint created in one project is not visible in another team project.</p>&#xA;</blockquote>&#xA;&#xA;<p>Right now each microservice is its own project in VSTS.  We have another project for changes/updates to the Kubernetes Ingress (NGINX) services.  Each of these projects feels well-defined in terms of no overlap, different CI/CD tasks, etc.</p>&#xA;&#xA;<p>But, this means that for every single project, we have to set up duplicate Service Endpoints for Kubernetes (not to mention our private GitHub repos).  Apparently that is the intent of VSTS, but is there some other feature / workflow I'm missing that avoids all this redundancy?</p>&#xA;&#xA;<p>I've looked into Deployment Pools / Groups but that's a different use case.  I've also tried creating Teams, sharing across projects, etc. but to no avail.</p>&#xA;"
48984289,Accessing multiple services using single url docker-compose,2018-02-26 08:32:58,<python><docker><nginx><docker-compose><microservices>,2,103,0,0.0,1,"<p>I am using docker-compose to deploy multiple microservices in flask. Here is the compose code</p>&#xA;&#xA;<pre><code>version: '3'&#xA;&#xA;services:&#xA;  test-api:&#xA;    volumes:&#xA;      - ./test-api:/test-api&#xA;    build: test-api&#xA;    ports:&#xA;      - ""5000:5000""&#xA;&#xA;  redis:&#xA;    image: ""redis:alpine""&#xA;&#xA;  search:&#xA;    volumes:&#xA;      - ./seach:/search&#xA;    environment:&#xA;      - HTTP_PORT=5000&#xA;      - REDIS_URL=redis://redis:6379/0&#xA;    build: search&#xA;    ports:&#xA;      - ""5001:5000""&#xA;    link:&#xA;      - redis&#xA;</code></pre>&#xA;&#xA;<p>Now I have to access this service from single URL eg: <code>http://example.com/test-api</code> or <code>http://example.com/search</code>, but I am unable to figure it out since the 2 services are running are on 2 different ports. I know I need to use nginx and configure it so that I can access them. But I am not sure how to do that. Can someone help me with this or at least give me some docs to read so as to understand the routing?</p>&#xA;&#xA;<p>Also both the services use /health to report the result of health-check. How do I access the health check for both the services?</p>&#xA;"
48909754,rabbitmq message session stickiness for microservices,2018-02-21 15:35:06,<rabbitmq><microservices><amqp>,1,112,0,0.0,1,"<p>I was reading about session stickiness for monolithic applications. Wanted to understand the feasibility for microservices.</p>&#xA;&#xA;<p>Q1. what are the downsides of session stickiness for microservices in particular? The internet doesn't talk much about this! It seems to hit scaling badly as the same instance might be overloaded (depending on the other design factors of the application). Is there <strong>any</strong> advantage? Please throw some light on this</p>&#xA;&#xA;<p>Given rabbitMQ messaging is used for inter microservice communication, is it possible to have session stickiness for rabbitMQ messages, routed to a work queue. i.e, maybe a header in the message has <code>session=xxx</code> and all the messages with the same session reaching that queue are routed to the same client.</p>&#xA;&#xA;<p>RabbitMQ or AMQP doesnt seem to have a configuration like that.</p>&#xA;&#xA;<p>Possible client side implementation: </p>&#xA;&#xA;<ol>&#xA;<li>Publisher publishes handshake message with routing key <code>handshake</code> and session id payload.</li>&#xA;<li>Consumer creates <code>auto_delete</code> queue and a binding with topic,  <code>topic.sessionid</code></li>&#xA;<li>Publisher publishes message with routing key, <code>topic.sessionid</code></li>&#xA;<li>cleanup accordingly!</li>&#xA;</ol>&#xA;&#xA;<p>Can someone point out the mistakes here</p>&#xA;"
48836908,Azure Logic Apps - HTTP communication between microservices,2018-02-17 00:59:14,<azure><microservices><azure-logic-apps>,1,140,0,0.0,1,"<p>Are Logic Apps considered microservices? If so, is making HTTP API calls from Logic Apps, whether it's using HTTP/Function/APIM connectors, not a violation of direct HTTP communication between microservices?</p>&#xA;&#xA;<blockquote>&#xA;  <p>If possible, never depend on synchronous communication (request/response) between multiple microservices, not even for queries. The goal of each microservice is to be autonomous and available to the client consumer, even if the other services that are part of the end-to-end application are down or unhealthy. If you think you need to make a call from one microservice to other microservices (like performing an HTTP request for a data query) in order to be able to provide a response to a client application, you have an architecture that will not be resilient when some microservices fail.</p>&#xA;  &#xA;  <p>Moreover, having HTTP dependencies between microservices, like when creating long request/response cycles with HTTP request chains, as shown in the first part of the Figure 4-15, not only makes your microservices not autonomous but also their performance is impacted as soon as one of the services in that chain is not performing well.</p>&#xA;  &#xA;  <p>Source: <a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/architect-microservice-container-applications/communication-in-microservice-architecture"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/architect-microservice-container-applications/communication-in-microservice-architecture</a></p>&#xA;</blockquote>&#xA;"
48961984,How to handle common variables in microservices architecture?,2018-02-24 10:50:34,<design><microservices>,2,140,0,0.0,1,"<p>Let's consider a situation, where multiple services relay on data that can change any time and should be updated in each microservice roughly at the same time - for example there is a list of supported languages or some common policies that could change one day and affect many services at once.</p>&#xA;&#xA;<p>One solution that I could think of is to have another microservice that could hold that data and any service that needs current state can just ask for it. The drawback is that this data is not changing very frequently, asking by HTTP is not that cheap and there is a lot of traffic to this let's say global registry service. As it is not changing very often, many services could just cache the data - in order to not ask for it every time - and not be able to respond to change quick enough when the change is made to the configuration.</p>&#xA;&#xA;<p>The other solution could be to externalize such configuration - in AWS for example there could be some configuration file on S3 that would be available for others. The drawback here is that there is no way (as far as I know) to track changes in such file and there is no way to add some logic for verification if changed value in configuration is correct (there is no typos and so on), etc.</p>&#xA;&#xA;<p>So my question is how to handle global configuration/registry in microservice world so that there is little HTTP overhead, you can audit changes as well as introduce change at the same time in many services?</p>&#xA;"
48942153,Do we really need Event Sourcing and CQRS in microservices?,2018-02-23 06:11:21,<microservices><cqrs><event-sourcing>,3,1173,0,1.0,1,"<p>In my understanding when database transactions span across microservices ,we can solve this problem with using message-broker(kafka,RabbitMQ etc) by publishing events so that Subscriber Microservices can update their database by listening to these events.</p>&#xA;&#xA;<p>In case of exception we can send event for failure ,so that Subscriber services can update their state.</p>&#xA;&#xA;<p>Is this not sufficient? What is the problem with this approach?</p>&#xA;&#xA;<p>why and when we need event sourcing?</p>&#xA;&#xA;<p>Do we need really event sourcing ?</p>&#xA;"
48979234,how Orchestrate microservices,2018-02-25 22:36:02,<spring-boot><microservices><orchestration><mule-esb>,1,446,0,0.0,1,"<p>I've been triying to migrate part of our soa architecture (Mule ESB) to microservices (Spring Boot stack), but I'm facing a problem related to large flows where we have several orchestations.&#xA;Basically We a have a flow which has an user id as input and the response is compounded of user account, creditcards data, stocks and loans.&#xA;In this flow we have, at the beginning, a splitter (allows to send concurrent requests) and we send requests to account backend, 3 different credicard partners, stock partner and loans partner, at the end there is an agregattor (wait to all responses and merge all of them) and finally a node for prepare the response (apply business logic).</p>&#xA;&#xA;<p>During the migration we have developed an account microservice, loan microservice, stock microservie and creditcard microservices (1 for each partner). The problem here is the orchestation, We can't use and event model approach because we need to get all responses in a certain point. We considered the choreography approach too, but we don't want to add logic related ot how orchestrate calls to our microservices because that would be a stepback to heavy coupled services (N*N connections).</p>&#xA;&#xA;<p>We are thinking on make a new microservice that will be used as an orchestrator, but we don't know if this will be a good solution for microservices concepts.</p>&#xA;&#xA;<p>Note: The front end can't make the orchestrations because it is a closed product and we can't touch it.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
48993781,How work Jhipster microservices?,2018-02-26 17:18:57,<jhipster><microservices><jhipster-registry>,1,242,0,0.0,1,"<p>I try to understand the jhispter microservices architecture. This image is present in <a href=""http://www.jhipster.tech/microservices-architecture/"" rel=""nofollow noreferrer"">Jhipster web site</a>. I have some questions :</p>&#xA;&#xA;<ol>&#xA;<li><p>Is there the gateway mandatory ? What if I don't use one ( except linking the microservices to know each other). I know it add hard coupling. </p></li>&#xA;<li><p>Why do we need Eureka Config in Jhipster registry ? Jhipster registry does not the same thing that Eureka Server ? The aim of Jhipster Registry is to register microservices while starting. </p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks &#xA;<a href=""https://i.stack.imgur.com/hNPEl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hNPEl.png"" alt=""enter image description here""></a></p>&#xA;"
48914388,Separating Node.js applications into multiple,2018-02-21 19:55:11,<node.js><mongodb><web-applications><passport.js><microservices>,1,37,1,2.0,1,"<p>So me being stupid didn't think about that I build my whole application front to back on one Node.js application instance. Now I have to figure out how to make each thing its own service. My current application has the front end (main site), front end (application/software part) and the backend all together. I need to figure out how best to separate these into front/main, auth, front/app and backend/app</p>&#xA;&#xA;<p>How would I even go about doing this? I would post code examples but I am sure that is too long and would not let me thanks to a code to word ratio on here. The git repo is not public either so can't post that.  </p>&#xA;&#xA;<p>My stack is mongo, node.js and express, I am using passport.js to go with it also.</p>&#xA;"
48838101,How to perform validation across services in microservices,2018-02-17 05:13:31,<domain-driven-design><microservices>,3,316,1,0.0,1,"<p>Suppose there are two microservices: Order and Intentory. There is an API in order service that takes ProductId, Qty etc and place the order.</p>&#xA;&#xA;<p>Ideally order should only be allowed to place if inventory exists in inventory service. People recommend to have Saga pattern or any other distributed transactions. That is fine and eventually consistency will be utilized.</p>&#xA;&#xA;<p>But what if somebody wants to abuse the system. He can push order with productid which are either invalid (or which are out of inventory). System will be taking all these orders and place these orders in queue and Inventory service will be handling these invalid order.</p>&#xA;&#xA;<p>Shouldn't this be handled upfront (in order service) rather than pushing these invalid orders to the next level (specially where productId is invalid)</p>&#xA;&#xA;<p>What are the recommendations to handle these scenarios?</p>&#xA;"
26611387,"DDD: Can anyone explain the diffrences between DTO, Aggregate Root and Detached Entity?",2014-10-28 14:51:52,<java><jpa><domain-driven-design><microservices>,2,707,3,0.0,1,"<p>I'm a bit puzzled in figuring out the differences between these three. Presumed I have a Customer -> Address relation the (JPA) Detached Entity will have this as well (Eager Loading presumed). Where is the need to have an additional Aggregate Root? Where is the need to have a DTO? Is it all more or less the same?</p>&#xA;&#xA;<p>One of the reasons might be that the JPA compliant Entity has some info the client is simply not interested in, e.g. <code>@Entity</code>, <code>@Id</code>, <code>@OneToMany</code>.</p>&#xA;&#xA;<p>I can convert it easily to JSON/XML using JAX-RS/-WS and almost every client can deal with it, so where is the need for having it? Is it all almost the same or do I miss something important?</p>&#xA;"
29479454,Managing and Utilizing Multiple Docker Containers (Microservices) in a Single Server,2015-04-06 20:50:25,<nginx><docker><containers><lxc><microservices>,1,423,1,1.0,1,"<p>I have a GCE (Google Compute Engine) server running with the Nginx/Apache web server listing at port 80 which will serve the website. At the same time I have multiple microservices running in the same server as Docker containers. Each container will serve a website at it's appropriate local-IP Address as well as I have bind it to localhost:PORT. I don't want to bind the ports to the Public-IP address, Since it will publicly expose the microservices to the outside world.</p>&#xA;&#xA;<p>Now the problem is, I have to embed the website pages served by the containers to the website which is running at port 80 of the web server. Since the embed code with we executed by the browser, I cannot use either the local-IP (172.17.0.x) or localhost:PORT in the python/HTML code.</p>&#xA;&#xA;<p>Now how do I embed the pages of microservices running locally inside the containers to the website serving the users?</p>&#xA;&#xA;<p><strong>For Example:</strong></p>&#xA;&#xA;<p>My Server's Public IP: <strong><em>104.145.178.114</em></strong>&#xA;The website is served from: <strong><em>104.145.178.114:80</em></strong>&#xA;Inside the same server we have multiple microservices running in the local-IP like <strong><em>172.17.0.1</em></strong> and <strong><em>172.17.0.2</em></strong> and so on. Each container will have a server running inside itself which will server pages at <strong><em>172.17.0.1:8080/test.html</em></strong> and similarly for the other containers also. Now I need to embed this page test.html to another web page which is served by the Nginx/Apache webserver at <strong><em>104.145.178.114</em></strong> without exposing the internal/Local-IP Port to the public.</p>&#xA;&#xA;<p><strong><em>I would like to hear suggestions and alternative solutions for this problem</em></strong></p>&#xA;"
30915043,Setting up rabbitMQ on docker with python,2015-06-18 12:13:32,<python><docker><localhost><rabbitmq><microservices>,1,1325,0,1.0,1,"<p>I am fairly new to docker and I am learning about rabbitMQ. So far I have been able to run rabbitMQ, in the form of the python libary pika, on my ubuntu vm. This worked with no problems at all but I have now put it onto a small app in docker and does not work.</p>&#xA;&#xA;<p>The problem seems to be in the set up and it all ways fails this line of code:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>The Variables being imported:</p>&#xA;&#xA;<pre><code>USER = ""test""&#xA;PASS = ""testpass1""&#xA;HOST = ""dockerhost""&#xA;</code></pre>&#xA;&#xA;<p>The file:</p>&#xA;&#xA;<pre><code>import pika&#xA;from settings import USER, PASS, HOST&#xA;&#xA;def send(message):&#xA;&#xA;    message = str(message)&#xA;    print 'trying: credentials = pika.PlainCredentials(username=USER, password=PASS)'&#xA;    try:&#xA;        credentials = pika.PlainCredentials(username=USER, password=PASS)&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: credentials = pika.PlainCredentials(username=USER, password=PASS) \n' + str(Exception.message)&#xA;&#xA;    print 'trying: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials))'&#xA;    try:&#xA;        connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;            host=HOST, port=80, credentials=credentials))&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials)) \n' + str(Exception.message)&#xA;&#xA;    channel = connection.channel()&#xA;&#xA;    channel.queue_declare(queue='hello')&#xA;&#xA;    channel.basic_publish(exchange='',&#xA;                      routing_key='hello',&#xA;                      body=message)&#xA;    connection.close()&#xA;&#xA;    return ""Message Sent""&#xA;</code></pre>&#xA;&#xA;<p>Within this code it always fails on the line:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>And finally the Dockerfile:</p>&#xA;&#xA;<pre><code>FROM ubuntu&#xA;MAINTAINER Will Mayger&#xA;RUN echo ""deb http://archive.ubuntu.com/ubuntu/ $(lsb_release -sc) main universe"" &gt;&gt; /etc/apt/sources.list&#xA;RUN apt-get update&#xA;RUN apt-get install -y tar git curl nano wget dialog net-tools build-essential&#xA;RUN apt-get install -y python python-dev python-distribute python-pip&#xA;RUN git clone https://github.com/CanopyCloud/microservice-python&#xA;RUN pip install -r /microservice-python/requirements.txt&#xA;EXPOSE 80&#xA;WORKDIR /microservice-python/&#xA;CMD sudo rabbitmqctl add_user test testpass1&#xA;CMD sudo rabbitmqctl add_vhost myvhost&#xA;CMD sudo rabbitmqctl set_permissions -p myvhost test "".*"" "".*"" "".*""&#xA;CMD sudo rabbitmq-server&#xA;&#xA;CMD python /microservice-python/server.py&#xA;</code></pre>&#xA;&#xA;<p>For any additional information all the files are located on:&#xA;<a href=""https://github.com/CanopyCloud/microservice-python"" rel=""nofollow"">https://github.com/CanopyCloud/microservice-python</a></p>&#xA;"
30908725,"Adding an item in a microservice, with reference to another one",2015-06-18 07:11:48,<rest><amqp><hateoas><microservices>,2,417,0,0.0,1,"<p><strong>Context</strong></p>&#xA;&#xA;<p>I m having two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User that manages users (crud operations)</li>&#xA;<li>Billing that manages billing informations, with a reference to a user</li>&#xA;</ul>&#xA;&#xA;<p>Actually, for me (tell if I m wrong) it's a good idea to store user informations into billing data using hateoas. So we can ""walk through it"" with an hyperlink in the response of the API right ?</p>&#xA;&#xA;<p>We could obtain something like :</p>&#xA;&#xA;<pre><code>billing:{&#xA;// some informations&#xA;   _links:{&#xA;     owner:""http://80.80.80.80:7000/users/123456789""&#xA;   }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>How should I do, to create a new billing ? In fact, when somebody post a new billing on the microservice, he sends the user too. Does it mean that I <strong>need</strong> to have a UserEntity in my Billing service AND my User Service ? So the billing service will be able to marshall the request, meaning code duplication between the two services ? Or should I do something else ?</p></li>&#xA;<li><p>Then, is this the role of the front end (API consumer) to make 2 requests (one for billing, and one for the user related to the billing) to get the ressource ? Or should the BillingService get the User before responding to the front ?</p></li>&#xA;<li><p>I have seen in an article, that it's a good thing to use amqp / bus when dealing with microservice, to know if a ressource exists, or to check if it exists. Now we need a service container/registry to dynamically discover other services. In my case I use Zookeeper. But how can I do to tell Zookeeper ""give me the location of the service(s) related to the ressource with hateoas links : <a href=""http://80.80.80.80:7000/users/123456789"" rel=""nofollow"">http://80.80.80.80:7000/users/123456789</a>"" ? Am I missing an important information in my hateoas schema ?</p></li>&#xA;</ul>&#xA;"
29128437,"uWSGI: Using emperor mode, register internal routing rules for vassals",2015-03-18 17:11:36,<python><uwsgi><microservices>,1,250,0,0.0,1,"<p>I am using uWSGI to deploy python wsgi microservices.</p>&#xA;&#xA;<p>My architecture looks like :</p>&#xA;&#xA;<ul>&#xA;<li>Emperor => handles routing of all request starting by /api</li>&#xA;<li>Vassal ""users"" => handles request on /api/users</li>&#xA;<li>Vassal ""payments"" => handles request on /api/payments</li>&#xA;<li>etc.</li>&#xA;</ul>&#xA;&#xA;<p>The routing is handled by the emperor using internal routing rules.</p>&#xA;&#xA;<p>My problem is that routing rules are statically defined in the emperor configuration file.</p>&#xA;&#xA;<p>1/ Is there any way for a vassal to ""dynamically"" (= on startup) add rules to the emperor internal routing table ?</p>&#xA;&#xA;<p>2/ If not, is there any way for an emperor to ""get"" routing rules from the vassal when starting it ?</p>&#xA;"
41329351,How to send the message back to the sender with messaging architecture?,2016-12-26 09:53:32,<messaging><microservices><nsq>,1,75,1,0.0,1,"<p>I'm solving the communications between the microservices with messaging-architecture.</p>&#xA;&#xA;<p>Let's say I have a tradition application, and there're <code>User</code>, <code>Post</code> <code>Video</code> modules. </p>&#xA;&#xA;<p>You can create the posts, videos with it, but before that, I need to convert the username to user ID.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Bgpka.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Bgpka.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Once I've split the modules to microservice, I cannot chain them together, we visit the microservices directly instead.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/tdwan.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tdwan.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>And if I want to convert an username to an ID, </p>&#xA;&#xA;<p>I can call the <code>User</code> service in the <code>Post</code> service via Messaging, so far so good.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/33wSq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/33wSq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But here's the problem: </p>&#xA;&#xA;<ul>&#xA;<li><p><strong>How do I receive the converted user ID</strong>?  Send another message back to the <code>Post</code> service and continue the next step?</p></li>&#xA;<li><p><strong>What if I want to do this from the <code>Video</code> service</strong>? I'll need to make another function for it in the <code>User</code> service? </p></li>&#xA;</ul>&#xA;&#xA;<p>That will be a lot of the functions if I got more and more services right?</p>&#xA;&#xA;<p>I think this is not how messaging architecture works, but I have no clue how to communicate with the other services without messaging.</p>&#xA;&#xA;<p><em>(Or should I <a href=""https://softwareengineering.stackexchange.com/questions/333755/should-microservices-talk-to-each-other"">chain them together in the API Gateway</a> so I don't need the messaging architecture?)</em>.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/CcjoY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CcjoY.png"" alt=""enter image description here""></a></p>&#xA;"
41287712,Random ports for microservices registered with Consul,2016-12-22 16:31:20,<microservices><consul>,1,370,1,0.0,1,"<p>Note: I am not asking about Consul HTTP port 8500. Can I call an API exposed by a microservice, which is discovered using Consul, just by the .service.consul/ WITHOUT specifying the port number?</p>&#xA;&#xA;<p>I am using Consul for discovering multiple versions of a microservice. This microservice (written in Java) has port predetermined:</p>&#xA;&#xA;<p>Service registered in consul as - my-service.service.consul (service port is, let us say 3030). I have another version of the same micro service registered with consul: my-servicev2.service.consul (port 3033).</p>&#xA;&#xA;<p>Service definition (altered for the example):</p>&#xA;&#xA;<pre><code> {&#xA;    ""Address"": &lt;IP address&gt;,&#xA;    ""CreateIndex"": 111,&#xA;    ""ModifyIndex"": 000,&#xA;    ""Node"": &lt;node name&gt;,&#xA;    ""ServiceAddress"": """",&#xA;    ""ServiceEnableTagOverride"": false,&#xA;    ""ServiceID"": ""my-servicev2"",&#xA;    ""ServiceName"": ""my-servicev2"",&#xA;    ""ServicePort"": 3033,&#xA;    ""ServiceTags"": [&#xA;        ""v2""&#xA;    ],&#xA;    ""TaggedAddresses"": {&#xA;        ""lan"": &lt;LAN IP&gt;,&#xA;        ""wan"": &lt;WAN IP&gt;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I can ping and dig the service using <code>dig @localhost my-service.service.consul' or</code>ping -c2 my-service.service.consul`</p>&#xA;&#xA;<p>But, how can I access one of the APIs exposed by this microservice without explicitly using the <code>ServicePort</code>?</p>&#xA;&#xA;<p>Here is what is working:</p>&#xA;&#xA;<pre><code>curl http://my-servicev2.service.consul:3033/health -&gt; resolves the service name, maps it to one of the deployed VM IP, and gives back the API response. In this case something like: `{""build""`: 'OK""}`&#xA;</code></pre>&#xA;&#xA;<p>However, I should be able to access the API without specifying the port number like this:&#xA;<code>curl http://my-servicev2.service.consul/health -&gt;</code>{""build"": ""OK""}`</p>&#xA;&#xA;<p>Is this possible in Consul?</p>&#xA;&#xA;<p>I've tried registering the service without <code>Port</code> value, and it added <code>0</code> as port value.</p>&#xA;"
41431506,Zuul routing : One endpoint with multiple microservices,2017-01-02 18:14:51,<java><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1829,2,0.0,1,"<p>I would like to setup zuul and the underlying microservices in a way that all services will be under the '/gateway' context.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>Microservice 1 has : <a href=""http://localhost:8081/api/hello"" rel=""nofollow noreferrer"">http://localhost:8081/api/hello</a></p>&#xA;&#xA;<p>Microservice 2 has : <a href=""http://localhost:8082/api/bye"" rel=""nofollow noreferrer"">http://localhost:8082/api/bye</a></p>&#xA;&#xA;<p>I would want to be able to access the microservices via zuul as follows:</p>&#xA;&#xA;<p>Microservice 1 : <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice1/api/hello</p>&#xA;&#xA;<p>Microservice 2: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice2/api/bye</p>&#xA;&#xA;<p>I have tried to set this up, although it seems the requests are not getting routed correctly.</p>&#xA;&#xA;<p>The reason I would like the front end to route all client side REST calls to server that begin with '/gateway' is that it provides simpler maintenance to the front end.</p>&#xA;&#xA;<p>My application.yml:</p>&#xA;&#xA;<pre><code>zuul:&#xA; prefix: /gateway&#xA;   routes:&#xA;     microservice1:&#xA;        path: /microservice1/**&#xA;        serviceId: microservice1&#xA;        strip-prefix: true&#xA;     microservice2:&#xA;        path: /microservice2/**&#xA;        serviceId: microservice2&#xA;        strip-prefix: true&#xA;</code></pre>&#xA;&#xA;<p>Thank you </p>&#xA;"
49227957,How can I take advantage of Spring repositories if I am using RestFul Services?,2018-03-12 03:56:23,<mongodb><spring-boot><spring-data><microservices><restful-architecture>,1,35,0,0.0,1,"<p>I am currently working on a project using a microservice oriented architecture. I'm using Spring boot + MongoDB repositories so our team can save some time by not having to write the queries.</p>&#xA;&#xA;<p>We are facing a problem with this approach. If we have the entity user:</p>&#xA;&#xA;<pre><code>{&#xA;""name"":""Josh"",&#xA;""lastname"":""Smith""&#xA;""createdOn"":""2018-01-01 00:00:00""&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>And we want to expose this entity as a resource, but we don't really know what parameters the client will use to search on this repository, so we'll end up with something like:</p>&#xA;&#xA;<pre><code>    @GetMapping&#xA;    public ResponseEntity&lt;User&gt;get(@RequestParam(value = ""name"") String name,&#xA;    @RequestParam(value = ""name"") String lastname){...}&#xA;</code></pre>&#xA;&#xA;<p>And a repository:</p>&#xA;&#xA;<p><code>public List&lt;User&gt; findByName(String name);&#xA;public List&lt;User&gt; findByLastName(String lastname);&#xA;...</code></p>&#xA;&#xA;<p>We will have to create a lot of methods in the user repository and conditionals to use them to give an answer back according to the client's query. And this problem will grow as the entity gets more fields.</p>&#xA;&#xA;<p>I know that spring supports <a href=""https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#query-by-example.introduction"" rel=""nofollow noreferrer"">query by example</a> but it won't work if we need to search by range of date for example.</p>&#xA;&#xA;<p>Is there a way to take advantage of the Spring repositories even though we don't know what queries is our service receive?   </p>&#xA;"
49210733,Microservice Discovery With Docker And Consul,2018-03-10 15:24:56,<docker><microservices><consul>,1,121,0,0.0,1,"<p>I'm interested in building microservices, but I'm getting a bit stuck on how service discovery should work when I've got multiple instances of a single microservice.</p>&#xA;&#xA;<p>Suppose I've got an ""OCR"" app that reads text from an image.&#xA;Deploying that as 1 instance is easy, however, what if I want 50 instances of those?</p>&#xA;&#xA;<p>I can run docker swarm to spin up get those 50 instances, but how do I send a request to <em>any <strong>one</em></strong> of them, i.e. I don't want to have to know the exact container name of a specific instance, I don't care which one I get, as long as it's healthy, just send my request to any of the ""OCR"" containers.</p>&#xA;&#xA;<p>How do I achieve this?</p>&#xA;&#xA;<p>I've been looking into Consul and it seems very promising.&#xA;I especially like the HTTP api, (Although I'm a little unsure of how I would retrieve the url for the service I'm interested in.  Would I need to do it before <em>every</em> request to make sure I'm pointing to a healthy instance?).</p>&#xA;&#xA;<p>If I wanted to use consul, what would be the steps be in relation to docker swarm?  Do I just need to register the service in consul when the container starts up, and it will automatically get de-registered if it fails right?).</p>&#xA;&#xA;<p>After that, all of my containers just need to be aware of where consul is (And I guess I could stick a load balancer infront of it, incase I ever want to scale out consul itself to a bunch of instances?)</p>&#xA;&#xA;<p>Please let me know if I'm going completely in the wrong direction.</p>&#xA;&#xA;<p>If anyone could also suggest any articles or books on this topic I'd appreciate it.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
49176544,Hystrix and Turbine does not work with Spring boot 2 and Spring cloud Finchley.M8,2018-03-08 15:18:49,<spring-boot><microservices><spring-cloud><hystrix><turbine>,2,684,0,1.0,1,"<p>I tried turbine + hystrix  dashboard with Spring boot 2 and latest versions of Spring cloud, seems exist some problem and turbine could not get stream from reactive service. I just uploaded simple microservices to github</p>&#xA;&#xA;<p><a href=""https://github.com/armdev/reactive-spring-cloud"" rel=""nofollow noreferrer"">https://github.com/armdev/reactive-spring-cloud</a></p>&#xA;&#xA;<p>Exception like this:</p>&#xA;&#xA;<pre><code>com.netflix.turbine.monitor.instance.InstanceMonitor$MisconfiguredHostException: [{""timestamp"":""2018-03-08T17:22:05.809+0000"",""status"":404,""error"":""Not Found"",""message"":""No message available"",""path"":""/hystrix.stream""}]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.init(InstanceMonitor.java:318) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.access$100(InstanceMonitor.java:103) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:235) [turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:229) [turbine-core-1.0.0.jar:na]&#xA;    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_101]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]&#xA;</code></pre>&#xA;&#xA;<p>Or broken PIPE.</p>&#xA;&#xA;<p>Any one tried full spring cloud stack with Spring webflux? Any suggestions?</p>&#xA;"
49171571,Search queries in microservice architecture,2018-03-08 11:04:16,<architecture><microservices>,2,137,1,2.0,1,"<p>Assuming I have a microservice architecture where I have a Book microservice holding all book details and a Author microservice holding all author details, e.g.</p>&#xA;&#xA;<pre><code>Book Service&#xA;GET /     get all books&#xA;GET /id   get book details, including author_ids&#xA;POST /    create new book&#xA;etc.&#xA;&#xA;Author Service&#xA;GET /     get all authors&#xA;GET /id   get author details, including book_ids&#xA;POST /    create new author&#xA;etc.&#xA;</code></pre>&#xA;&#xA;<p>The real services are much more enterprise grade, I just choose Books and Authors with their own data storage option as a easy understandable example. </p>&#xA;&#xA;<p>Assuming, there will be millions of calls to the services and I have to uphold specific availability and throughput of systems. How can I efficiently search for authors where name starts with 'A' and all books written by the authors where book title starts with 'B'?</p>&#xA;&#xA;<p>I see following options, which all are not perfect:</p>&#xA;&#xA;<ol>&#xA;<li><p>I create a search endpoint in Author service, fetch all authors matching the search criteria, follow each book_id and filter for the books. -> This requires a lot of calls on the Book service.</p></li>&#xA;<li><p>Same as 1. but I create a search endpoint in Book service, fetch all books matching the search criteria, follow each author_id and filter for the authors. -> This requires a lot of calls on the Author service. In worst case, same load as in 1.</p></li>&#xA;<li><p>I create a new microservice Search. Search will have its own database which is optimized for searches. Search will return me the books and authors and can give me the search result with one call. -> This requires Search to frequently sync with Book and Author service.</p></li>&#xA;<li><p>I merge Book and Author into one service which defeats the purpose of mircroservices?</p></li>&#xA;</ol>&#xA;&#xA;<p>Maybe someone with more microservice experience can help me out how to best architect this.</p>&#xA;"
49107497,Microservices DDD CQRS,2018-03-05 09:49:34,<domain-driven-design><microservices><cqrs><aggregateroot><bounded-contexts>,1,88,2,0.0,1,"<p>I've been reading about DDD and microservices. Started to prototype by taking a use case for CQRS part. The use case is a sports soccer app which has videos, news, scores, and homepage. In this, I've identified the domains and Bounded context which are</p>&#xA;&#xA;<ol>&#xA;<li><p>News</p></li>&#xA;<li><p>Videos</p></li>&#xA;<li><p>Scores</p></li>&#xA;<li><p>Homepage</p></li>&#xA;</ol>&#xA;&#xA;<p>First, 3 domains are totally independent of each other.</p>&#xA;&#xA;<p>Now, homepage domain requirements.&#xA;1. Score section&#xA;2. Videos section&#xA;3. Content section</p>&#xA;&#xA;<p>Content Section: It has its own database</p>&#xA;&#xA;<p>Videos section:  It will make HTTP call video service and get the data</p>&#xA;&#xA;<p>Score section: It will make HTTP  call Score service and get the data</p>&#xA;&#xA;<p>My question is with homepage domain. &#xA;I find it is highly coupled with other services and it's not independent.</p>&#xA;&#xA;<p>How can I design homepage domain?</p>&#xA;"
49069281,"Rails, RabbitMQ and Sidekiq Architecture",2018-03-02 12:35:51,<ruby-on-rails><ruby><rabbitmq><microservices><sidekiq>,1,207,2,1.0,1,"<p>I have a very trivial - I guess - situation, and several implementation choices. I have a Rails app (call it Core) that, upon user request, crawls data from the internet. The crawler doesn't have any business logic - at least for now - however fetching and persisting data is a job that takes time and I would'n want it to be blocking. </p>&#xA;&#xA;<p>I've considered different architectures, however I am not sure which one will work the best when things scale up. Options:</p>&#xA;&#xA;<ol>&#xA;<li>Sidekiq: Every time a user requests data to be crawled, a background job in Sidekiq gets born and crawls data, persists them and job is done. Possible drawback here is that I will not pay for Sidekiq Pro edition and I am not sure whether the OSS version will suit my needs.</li>&#xA;<li>RabbitMQ: Develop a microservice, let's call it Fetcher, in Rails again, which will consume from RabbitMQ and fetch and persist data. I haven't not understood whether in this case I need background processing as well, so again Sidekiq (or Sneakers). If I do, what's the advantage of using a message broker (in this case) instead of having Sidekiq do the background processing in the same application?</li>&#xA;</ol>&#xA;"
30209442,Cross-Microservice Authorization and Authentication,2015-05-13 08:23:41,<authentication><authorization><microservices>,1,760,4,1.0,1,"<p>Suppose we have a number of (stateless, HTTP-based) (micro)services and a bunch of ""daemons"", which do all kinds of background processing by actually using said services.</p>&#xA;&#xA;<p>Now, I want to have a way for services and daemons to be able to mutually authenticate and authorize. For example, a daemon that performs full-text indexing of Orders needs:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Read-only</strong> access to the <em>Orders</em>, <em>Customers</em> (which itself needs read-only access to <em>Companies</em> service) and <em>Inventory</em> services </li>&#xA;<li><strong>Read and write</strong> access to the <em>OrdersSearch</em> service in order to be able to update the full-text index.</li>&#xA;</ul>&#xA;&#xA;<p>There are also applications, which operate ""on behalf"" of the user. For example, Inventory web app needs <strong>read and write</strong> access to the <em>Inventory</em> service, but the <em>Inventory</em> service itself needs to verify permissions of the user operating the application.</p>&#xA;&#xA;<p>All that said, how do I achieve what I just described? I'd prefer not to use gigantic enterprisey frameworks or standards. From what I've read, Two-Legged OAuth2 is what I need, but I'm not exactly sure.</p>&#xA;&#xA;<p>I was thinkinking of establishing an <em>Authorization</em> service which will be used to answer questions like ""Hey, I'm <em>Inventory</em> service. What permissions the <em>Customer</em> service that is calling me right now has for me?"", but that has two major weak with distributing shared secrets.</p>&#xA;"
33780962,Versioning services,2015-11-18 13:09:31,<microservices><azure-service-fabric>,1,308,0,2.0,1,"<p>We are trying to do Microservices with MS' ServiceFabric.</p>&#xA;&#xA;<p>The scenario:&#xA;We have a Service1 running version1 and getting ready to upgrade to v2.</p>&#xA;&#xA;<p>Three other services depend on the interface of Service1. We want to be able to release v2 of Service1, but keep v1 running until we have upgraded and tested the three services against v2.</p>&#xA;&#xA;<p>All the examples I have found, v2 replaces v1 immediately. Can this be configured? And is there a method to tell the service discovery mechanism that I rely on a specific version of a given service?</p>&#xA;"
33772776,What's an acceptable latency for service/message bus,2015-11-18 05:56:17,<amazon-ec2><architecture><rabbitmq><latency><microservices>,1,95,0,0.0,1,"<p>I'm developing a simple RPC style message bus where microservices will live on different virtualized machines.</p>&#xA;&#xA;<p>I'm just testing a simple proof of concept using c4.large instances on EC2 for RabbitMQ, the server and the client.</p>&#xA;&#xA;<p>I'm noticing round trips to the server and back are ~100ms with ~20ms for connecting to the amqp server and another ~80ms for returning a simple string.</p>&#xA;&#xA;<p>This seems quite high to have an overhead of 100ms for each RPC request. Is there a typical acceptable latency for this style of architecture? Should I be looking at different tools?</p>&#xA;"
33805449,How to store shared-by-same-instances data in spring microservices architecture,2015-11-19 13:35:55,<jpa><database-design><architecture><spring-cloud><microservices>,3,452,0,0.0,1,"<p>following situation: I am building a system that requires redundant microservices for failover or loadbalancing. So I am starting two (or more instances of a service) of for example a simple core rest service that provides data.</p>&#xA;&#xA;<p>My Question is: How would you store the data? Using two JPA-instances to access the same database (both writing and reading) will result in problems, especially in layer 2 caching and in consistency. Since the database must be redundent itself (requirement) it might be possible to make each service instance accessing its own database, but how would you synchronize them? Is there any common solution for this?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
33798965,Microservices advice concern to share state between two services,2015-11-19 08:45:43,<java><design><redis><datasource><microservices>,2,179,4,0.0,1,"<p>I am following the microservice architecture where we got two independed services</p>&#xA;&#xA;<p>(UserService, OtherService)</p>&#xA;&#xA;<p>UserService writes to it's own datasource (mysql and Redis)</p>&#xA;&#xA;<p>Clients writing updates to UserService</p>&#xA;&#xA;<p>In other hand Client's getting data from OtherService which need some user-state from UserService.</p>&#xA;&#xA;<p>Latency and throughput of OtherService are very important.</p>&#xA;&#xA;<p>few options: </p>&#xA;&#xA;<ol>&#xA;<li><p>UserService will update OtherService when state changes (than I break the domain responsibility of OtherService since it shouldnt maintenance users states</p></li>&#xA;<li><p>OtherService will ask UserService (via api) for the user states (adding lots of latency which is critical for me. I could cache but still.. not sure thats the right way)</p></li>&#xA;<li><p>having shared datastore while UserService write and OtherService reads.. breaking also the microservice principle when sharing same datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What do you guys think would be right to do?&#xA;Thank you,&#xA;ray.</p>&#xA;"
52070247,Eureka client works and communicates with each other even after i stopped the registered server. How?,2018-08-29 05:47:08,<java><spring-boot><microservices><netflix-eureka><netflix-ribbon>,2,21,0,1.0,1,"<p>I have created a Eureka server and registered two clients with it. The clients communicate with each other smoothly.</p>&#xA;&#xA;<p>After that, I stopped the Eureka server but still both my clients are communicating with each other smoothly. How is this possible? I'm using the following code in my 1st client to communicate to the 2nd client.</p>&#xA;&#xA;<pre><code>ServiceInstance instance = loadbalancerclient.choose(secondService);&#xA;URI uri=URI.create(String.format(""http://%s:%s""+""/test"",instance.getHost(),instance.getPort()));&#xA;ResponseEntity&lt;String&gt; result = restTemplate.getForEntity(uri.toString(),String.class);&#xA;</code></pre>&#xA;&#xA;<p>Since instead of hardcoding any URL I'm using the registered name of the 2nd client in Eureka server, I was not expecting it to work when the server is down. Can anybody explain to me why this is happening?</p>&#xA;"
52090842,Does the micro-service architecture for node reduce the efficiency and increase the response timeï¼ŸIs there any solution or my understanding is wrong?,2018-08-30 06:52:28,<javascript><node.js><microservices>,1,22,0,0.0,1,"<p>Recently, I use node to build a data processing system which involves many modules, so I plan to adopt a micro-service architecture and use a micro-service framework <a href=""https://www.npmjs.com/package/seneca"" rel=""nofollow noreferrer"">Seneca</a> and use tcp to communicate.</p>&#xA;&#xA;<p>the Seneca micro service are primarily responsible for communicating with database and data processing calculations(not time-consuming)</p>&#xA;&#xA;<p>However, I found through ab test that the Seneca micro service is much less efficient than the original modules. In some cases, the average response time is 1.5 times than before. I think it is not hard to understand: Seneca micro service will generate additional communication overhead and some other overhead.</p>&#xA;&#xA;<p>I am a little confused now. If I use micro-service architecture, I can solve the problem of mutual reference between modules in a large system. It is convenient for development. But it will reduce effciency and I feel that it is not worth the candle.</p>&#xA;&#xA;<p>I don't know if my understanding of micro service is wrong, or there is something wrong the way I use it. I don't want to see that I use micro service but it reduces efficiency. So if you have some ideas, please tell me, thank you very much.</p>&#xA;&#xA;<p>p.s. I temporarily think that there is no need to give sample code for this question, just want to hear your opinions. Thank you.</p>&#xA;"
51988439,Loose coupling between models in a Microservice Architecture,2018-08-23 14:42:54,<design><database-design><microservices>,1,33,0,0.0,1,"<p>Under a Microservice Architecture, I am implementing 2 different micro apps: one for users administration and another for tasks administration.</p>&#xA;&#xA;<p><strong>User Microservice:</strong></p>&#xA;&#xA;<p>Under this micro-app I am defining a <code>User</code> model which holds all the information of the user object in the database.</p>&#xA;&#xA;<p><strong>Task Microservice:</strong></p>&#xA;&#xA;<p>Under this micro-app I am defining a <code>Task</code> model which holds all the information of the task object in the database, plus the user reference in the task.</p>&#xA;&#xA;<p>Since the application is developed under a Microservice Architecture, the <code>User</code> and <code>Task</code> models will reside in two different micro-services, and given that any task contains a user reference, I am obliged to define the user model in the Task microservice too, and this is contradicting the loose coupling concept and is a bad approach for the maintainability of the application as a whole.</p>&#xA;&#xA;<p>Maybe my question is out of scope since I am new to this type of architecture, so thank you in advance for putting me on the right way.</p>&#xA;"
52023726,Should frontend or backend call microservices?,2018-08-26 06:23:53,<architecture><microservices>,2,36,0,1.0,1,"<p>I am confused as to whether my frontend application should be the one calling microservices or the backend?</p>&#xA;&#xA;<p>For example: let say I have an ""App A"" which uses ""Auth"" and ""Products"" services. Should my ""App A"" server call auth and products services? Or should my frontend call these services directly? </p>&#xA;&#xA;<p>I think in many cases, its more correct to call my services directly since I notice otherwise, my app server endpoints is purely a proxy to these services, which is quite useless. </p>&#xA;"
52011686,Docker: cannot get access to server,2018-08-24 21:02:13,<docker><.net-core><microservices>,1,38,0,0.0,1,"<p>Here is a little of backstory. I implemented a couple of web APIs using microservices architecture. I am trying to make my microservices accessible via HTTPS. The microservices are developed using .net core, so according to Microsoft document, to enforce HTTPS, I need to configure Kestrel. Following is how I did it.</p>&#xA;&#xA;<pre><code>.UseKestrel(options =&gt;&#xA;            {&#xA;                options.Listen(IPAddress.Loopback, 5000);&#xA;                options.Listen(IPAddress.Loopback, 5001, listenOptions =&gt;&#xA;                {&#xA;                    listenOptions.UseHttps(""cert.pfx"", ""pwd"");&#xA;                });&#xA;            }) &#xA;</code></pre>&#xA;&#xA;<p>To make it simple, I use kestrel by itself and skip reverse proxy. I will certainly include Nginx as reverse proxy but that is the future work. I tested locally, it worked. Then, I deployed it onto Docker. Here is the docker-compose.override file</p>&#xA;&#xA;<pre><code>version: '3.4'&#xA;&#xA;services:&#xA;dataservice:&#xA;  environment:&#xA;    - ASPNETCORE_ENVIRONMENT=Development&#xA;    - ASPNETCORE_URLS=https://+:443;http://+:80&#xA;  ports:&#xA;    - ""5000:80""&#xA;    - ""5001:443""&#xA;</code></pre>&#xA;&#xA;<p>In dockerfile, port 5000 and 5001 are exposed. I built the project into images, and run it on docker, using <code>docker run -it --rm -p 5000:80  --name *name* *imagename*</code>. Docker shows <code>Now listening on: http://127.0.0.1:5000</code> and <code>Now listening on: https://127.0.0.1:5001</code>. Now the problem is, leave the https part aside, the APIs cannot even accessed by http. The browser just shows <code>This page isnâ€™t working 127.0.0.1 didnâ€™t send any data. ERR_EMPTY_RESPONSE</code>. I found a similar question from here <a href=""https://stackoverflow.com/questions/40827230/docker-cannot-open-port-from-container-to-host"">Docker: cannot open port from container to host&#xA;</a>, somehow this is about server should listen to 0.0.0.0. Though I am not fully understand the reason, I changed the kestrel  configuration to</p>&#xA;&#xA;<pre><code>options.Listen(IPAddress.Any, 5000);&#xA;</code></pre>&#xA;&#xA;<p>built and ran docker images again, and Docker shows <code>Now listening on: http://0.0.0.0:5000</code>, still it doesn't work. I also tried to replace the IP with <code>localhost</code>, it has no use. I did not use <code>.UseHttpsRedirection()</code>, https should have nothing to do with the problem. </p>&#xA;&#xA;<p>Am I missing any configuration or doing anything wrong? It would be really helpful if anyone could shed some light. Thank you in advance.</p>&#xA;"
51944296,How to make dependent microservice calls async?,2018-08-21 08:07:36,<microservices>,1,22,1,0.0,1,<p>How to make microservices call async when microservice B depends on the response of A and microservice C depend on response B?</p>&#xA;
51965342,"Dynamic message ""routing"" pattern?",2018-08-22 10:58:07,<design-patterns><microservices><message-queue>,1,33,1,0.0,1,"<p>We are building an application using microservices and AWS SQS for messaging.</p>&#xA;&#xA;<p>We have a requirement for a single message to be handled by multiple microservices before being processed at a ""final destination"" microservice.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<ul>&#xA;<li>microservice A generates a message</li>&#xA;<li>the message must be validated by microservice B</li>&#xA;<li>the validated message must be transformed using microservice C</li>&#xA;<li>the transformed message must be applied to a data store using microservice D</li>&#xA;</ul>&#xA;&#xA;<p>Is there a pattern for dynamically (at message-creation time) prescribing the flow of a message between listeners on a message queue?</p>&#xA;"
51953129,Facing issue with Microservice using netflix zuul in SpringBoot,2018-08-21 16:33:46,<microservices><netflix-zuul>,2,42,2,0.0,1,"<hr>&#xA;&#xA;<p>APPLICATION FAILED TO START</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Description:</p>&#xA;&#xA;<p>The bean 'counterFactory', defined in class path resource [org/springframework/cloud/netflix/zuul/ZuulServerAutoConfiguration$ZuulCounterFactoryConfiguration.class], could not be registered. A bean with that name has already been defined in class path resource [org/springframework/cloud/netflix/zuul/ZuulServerAutoConfiguration$ZuulMetricsConfiguration.class] and overriding is disabled.</p>&#xA;&#xA;<p>Action:</p>&#xA;&#xA;<p>Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true</p>&#xA;"
51993175,org.springframework.web.client.ResourceAccessException: I/O error on GET request for in Microservices,2018-08-23 19:39:44,<spring><spring-boot><microservices>,2,49,5,1.0,1,"<p>I am developing microservices code from the link : <a href=""https://github.com/sivaprasadreddy/spring-boot-microservices-series"" rel=""nofollow noreferrer"">https://github.com/sivaprasadreddy/spring-boot-microservices-series</a>. In this code base, I was successfully able to start the services like <code>""config-service""</code>, <code>""service-registry""</code>, <code>""shoppingcart-ui""</code>, <code>""zipkin-server""</code> etc, but when I tried to start the <code>""inventory-service""</code>, I got the below error. </p>&#xA;&#xA;<p><strong>Error below for reference:-</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8200/v1/secret/inventory-service"": Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:732) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:332) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.lambda$doRead$1(VaultTemplate.java:320) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doWithSession(VaultTemplate.java:307) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doRead(VaultTemplate.java:317) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.read(VaultTemplate.java:212) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.doGetSecrets(SecretLeaseContainer.java:545) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.start(SecretLeaseContainer.java:357) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.addRequestedSecret(SecretLeaseContainer.java:316) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.loadProperties(LeaseAwareVaultPropertySource.java:147) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.&lt;init&gt;(LeaseAwareVaultPropertySource.java:133) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:151) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:88) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.doCreatePropertySources(VaultPropertySourceLocatorSupport.java:170) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.createCompositePropertySource(VaultPropertySourceLocatorSupport.java:145) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.locate(VaultPropertySourceLocatorSupport.java:116) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94) [spring-cloud-context-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:636) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:376) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:328) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.sivalabs.inventoryservice.InventoryServiceApplication.main(InventoryServiceApplication.java:12) [classes/:na]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_162]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;</code></pre>&#xA;&#xA;<p><strong>I updated parent pom version to 2.0.4.RELEASE.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N574F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N574F.png"" alt=""enter image description here""></a></p>&#xA;"
52092546,Create Pub/Sub service WITHOUT third parties tool,2018-08-30 08:34:30,<c#><asp.net><microservices><publish-subscribe>,1,38,11,0.0,1,"<p>I would like to find a solution to create a pub/sub medium for 2 microservices to talk to each other,&#xA;I am aware i can use some third parties E.g Redis, RabbitMQ&#xA;<a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/multi-container-microservice-net-applications/integration-event-based-microservice-communications"" rel=""nofollow noreferrer"">Implementing event-based communication between microservices (integration events)</a></p>&#xA;&#xA;<p>The challenge lies on the client is unable to allow install any third parties tool due to security reason. &#xA;The messageQueue server in Windows won't be allowed to use too. &#xA;I can only use the applications that is only existed in the server.</p>&#xA;&#xA;<p>Therefore i am asking if there is anyway that i can create one simple app using windows service.&#xA;It is a one-to-many relationship. I have one service that will be dealing with data, once if there is any update, it will publish to those services that is subsribed to it.</p>&#xA;&#xA;<p>It seems my problem could be similar with </p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/9919804/net-scalable-pub-sub-service-implementation"">.NET Scalable Pub/Sub service implementation</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/391296/wcf-pub-sub-with-subscriber-caching"">WCF Pub/Sub with subscriber caching</a>(link is dead on the WCF pub-sub)</p>&#xA;&#xA;<p>but i dont see any critical solutions. </p>&#xA;&#xA;<p>I was thinking to use data notifications that MSSQL offers as last alternatives, but seems like it could cause a bottle neck when the applications get scale up. &#xA;The internet is so much flooded with articles using third parties tool. </p>&#xA;&#xA;<p>Thanks </p>&#xA;"
36871886,Microservices Service-to-Service-Communication Need-to-Know principle,2016-04-26 17:32:34,<rest><microservices>,1,151,0,0.0,1,"<p>Are there any best practices to minimize the exchanged data between (internal) microservices when calling the API of a service (aka Need-to-Know)?</p>&#xA;&#xA;<p><strong>How to achive something like this:</strong></p>&#xA;&#xA;<p>There are three services:</p>&#xA;&#xA;<ul>&#xA;<li>User</li>&#xA;<li>Notification (let's assume just email)</li>&#xA;<li>Shipping</li>&#xA;</ul>&#xA;&#xA;<p>When the notification service needs the email address of a user it queries the API of the user service and should get the email (and NOT the full data set).</p>&#xA;&#xA;<p>When the shipping service needs the shipping address of a user it queries the API of the user service and should get the shipping address (and NOT the full data set).</p>&#xA;&#xA;<p><strong>Question:</strong></p>&#xA;&#xA;<p>Should this be handled inside the user service with kind of an ACL (what service ""XYZ"" is allowed to see)?</p>&#xA;&#xA;<p>Using JWT for authentication, there is a need to exchange keys at all, so during the setup-phase these ACLs could be discussed between the teams.</p>&#xA;"
36948775,Managing data-store concurrency as microservices scale,2016-04-29 23:04:45,<concurrency><scalability><microservices><data-consistency>,1,979,2,0.0,1,"<p>I am still trying to find my way around micro-services. I have a fundamental question.</p>&#xA;&#xA;<p>In an enterprise scenario, micro-services would probably have to write to a persistent data-store - be it a RDBMS or some kind of NoSQL. In most cases the  persistent data-store is enterprise grade, but a single entity (ofcourse replicated and backed up).</p>&#xA;&#xA;<p>Now, let's consider the case of a single micro-service deployed to private/public cloud environment having it's own persistent data-store (say enterprise grade RDBMS). As I scale my micro-service, there will be multiple instances of the micro-service trying to read/write from the same data-store. A traditional data-store can probably be tuned to handle ~50-200 concurrent connections. How do I handle a situation when my microservices has to be scaled much beyond that?</p>&#xA;&#xA;<p>What are the best practices in such a scenario? Any patterns that can be used?</p>&#xA;"
36954140,How to create JAX-RS Sub Resources with WSO2 MSf4J,2016-04-30 11:13:24,<java><wso2><jax-rs><microservices><msf4j>,1,195,4,0.0,1,"<p>I have create a sample micro service using WSO2 MSF4J. But i can't access the sub resources (services). Following are my service classes. </p>&#xA;&#xA;<p>Message Resource - </p>&#xA;&#xA;<pre><code>@Path(""/messages"")&#xA;@Consumes(MediaType.APPLICATION_JSON) &#xA;@Produces(MediaType.APPLICATION_JSON) &#xA;public class MessageResource {&#xA;&#xA;    @Path(""/{messageId}/comments"")&#xA;    public CommentResource getCommentResource(){&#xA;&#xA;        System.out.println(""inside the getCommentResource method"");&#xA;        return new CommentResource();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Comment Resource - </p>&#xA;&#xA;<pre><code>@Path(""/"") &#xA;public class CommentResource {&#xA;&#xA;    @GET&#xA;    @Path(""/{commentId}"")&#xA;    public String test2(@PathParam(""messageId"") long messageId, @PathParam(""commentId"") long commentId){&#xA;&#xA;        System.out.println(""method to return comment Id : "" + commentId + "" for message : "" + messageId);&#xA;        return ""method to return comment Id : "" + commentId + "" for message : "" + messageId;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have used following URI to access this service.</p>&#xA;&#xA;<p>GET : <a href=""http://localhost:8080/messages/1/comments/5"" rel=""nofollow"">http://localhost:8080/messages/1/comments/5</a></p>&#xA;&#xA;<p>But i got following result to my REST client.</p>&#xA;&#xA;<pre><code>404 Not Found&#xA;&#xA;Problem accessing: /messages/1/comments/5. Reason: Not Found&#xA;</code></pre>&#xA;&#xA;<p>Please help to resolve this. </p>&#xA;"
36913462,"Difference between Fabrica8, Vert.x , Karaf, Felix , Equinox, Spring DM and Fuse and Docker",2016-04-28 11:35:58,<java><spring><maven><containers><microservices>,1,794,5,1.0,1,"<p>I am planning to convert from my Monolithic Server Architecture to a Microservice Architecture. I have been doing some research based on my Pre-requisits. </p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>pre-requisits:</strong></p>&#xA;  &#xA;  <p>1) Spring-Boot Application </p>&#xA;  &#xA;  <p>2) Build Tool : Maven </p>&#xA;  &#xA;  <p>3) Create OSGI bundles from my packages</p>&#xA;</blockquote>&#xA;&#xA;<p>Based on my understanding, I want my inheritance to be maintained. I do not want a lot of disruption in my project. Here are two more cents from my end.</p>&#xA;&#xA;<p><strong>1) Containers are a good way to develop and deploy microservices, and the tools and platforms for running containers are a good way to manage microservice-based applications.</strong></p>&#xA;&#xA;<p>So I was keen on finding containers provided for Spring-Boot Application. There has been a lot of turbulence in the Spring Environment. After the Spring DM was shut, There was an inflow of multiple container providers. </p>&#xA;&#xA;<p><strong>2) I am not looking for Virtualization and hence do not require Docker.</strong></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>MAIN QUESTION</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>Which is the best container for OSGI Bundles in Spring?</strong></p>&#xA;</blockquote>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>ADDITIONAL QUESTIONS</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>1) Please let me know the nuances between <a href=""http://fabric8.io/gitbook/springBootContainer.html"" rel=""nofollow"">Fabrica8</a> and <a href=""http://karaf.apache.org/download.html"" rel=""nofollow"">Apache&#xA;  Karaf</a> which is apparently based on <a href=""http://felix.apache.org/"" rel=""nofollow"">Felix</a> or Equinox. There's&#xA;  new versions of Karaf coming up and competing with Fabrica8.l Which&#xA;  one is the best?</p>&#xA;  &#xA;  <p>2) Can Docker or <a href=""http://vertx.io/"" rel=""nofollow"">Vert.x.</a> be useful with such requirements.</p>&#xA;  &#xA;  <p>3) Optional. Please give more insights on the above mentioned&#xA;  frameworks if you will.</p>&#xA;</blockquote>&#xA;"
35039565,Collate several micro-services into a single swagger 2.0 spec/collection,2016-01-27 14:07:00,<swagger><swagger-ui><microservices><swagger-2.0><akka-http>,1,732,0,1.0,1,"<p>I am developing microservices using akka-http (scala). At the moment, I couldn't find any direct integration of swagger into akka-http. Nevertheless, I am starting my microservices with swagger 2.0 specs.  </p>&#xA;&#xA;<p>Now one of the challenge is to show a consolidated API spec to the consuming applications. I don't want to share multiple specs to the consumers and hence want to aggregate multiple swagger specs into one single spec (if this can be done on the fly, it would be great). Also how would this work with swagger-ui?</p>&#xA;"
35198346,"How to distinguish a deliberate, controller-generated 404 from an actual error in a REST API?",2016-02-04 10:21:05,<json><api><rest><http><microservices>,1,40,2,0.0,1,"<p>In a JSON-REST service architecture (following <a href=""http://www.restapitutorial.com/lessons/httpmethods.html"" rel=""nofollow"">these patterns</a> for methods and response codes) we often need to generate a deliberate 404 response - for example, if <code>GET /users/123</code> is routed to a controller, which is then unable to find a User entity with ID <code>123</code>, we return a 404 response, which in many cases will include a JSON payload with an error message/code/etc.</p>&#xA;&#xA;<p>Now, when we provide a client for a specific API, we want the client to behave differently under different conditions. For example, if we point the client to the wrong host, we might get a 404 not found from that host - as opposed to the 404 we might get for an invalid User ID if we do reach the service.</p>&#xA;&#xA;<p>In this case, a ""404 User ID not found"" is not an error, as far as the client is concerned - as opposed to any other ""404 Not Found"", which should cause the client to throw an exception.</p>&#xA;&#xA;<p>My question is, how do you distinguish between these 404 errors?</p>&#xA;&#xA;<p>Solely based on the response?</p>&#xA;&#xA;<p>By adding a header to indicate a valid response?</p>&#xA;&#xA;<p>Or some other way?</p>&#xA;"
32532736,What would be a good/correct term to designate a group of microservices?,2015-09-11 21:59:57,<service><deployment><configuration><microservices><vocabulary>,2,139,0,1.0,1,"<p>I am opening this topic looking for an advice to solve/help in the following problem:</p>&#xA;&#xA;<ul>&#xA;<li>I am currently working with other people on a project with a microservices architecture, using cloud computing.</li>&#xA;<li>There are 6 different microservices, and there are some couples of microservices that are not compatible, therefore not able of being instantiated within the same machine.</li>&#xA;<li>Each microservice has a version number.</li>&#xA;<li>In order to launch one or more new instances of any microservice, we have to define which microservices will run on this new machine, via a static configuration.</li>&#xA;<li>This static configuration, that we call so far as a ""deploy"" contains the microservices that are being deployed, and the version of each microservice. (ex: (XY,[(X,v1),(Y,v2)]) - X and Y are microservices, and the XY deploy instantiates version 1 of X and version 2 of Y)</li>&#xA;<li>Those ""deploys"" also have their own version number. Altering the version number of a microservice within a deploy requires altering the version of any ""deploy"" containing the microservice. (ex: (XY,v1,[(X,v1),(Y,v2)]) and (XY,v2,[(X,v1),(Y,v3)]))</li>&#xA;</ul>&#xA;&#xA;<p>The question is: what would be a correct, or at least, a good term to refer to this entity that I have previously called a ""deploy""?</p>&#xA;&#xA;<p>Many developers are writing programs around our architecture and using different names for such entity, which causes syntaxic and semantic incompatibility inside our team.</p>&#xA;&#xA;<p>Of those different names, all have pros and cons:</p>&#xA;&#xA;<ul>&#xA;<li>deploy: makes sense because you are deploying all the microservices in the list. However, the term deploy already designate another part of our process, and there could be some over utilization of the same term. (Deploying the XY deploy will deploy microservices X and Y in a machine)</li>&#xA;<li>cluster: good name for a group of things, but you can deploy multiple machines from a configuration, and the term cluster already applies to this group of machines. </li>&#xA;<li>service: a service would be a group of microservices. Makes sense, but many pieces of codes refer to a microservice as 'service', and that could lead to a confusion. (def get_version(service) - Is he talking about a service or a microservice?) </li>&#xA;</ul>&#xA;&#xA;<p>Does any of you could give us any opinion or enlightenment on the question?&#xA;Thanks!</p>&#xA;"
32481469,Linking between objects on different apps with Spring HATEOAS,2015-09-09 13:53:35,<rest><spring-boot><spring-cloud><spring-hateoas><microservices>,1,500,1,0.0,1,"<p>I'm investigating spring-cloud and I've set up two microservices ""offers"" and ""customers"" as eureka clients.</p>&#xA;&#xA;<p>The customers app has:</p>&#xA;&#xA;<pre class=""lang-java prettyprint-override""><code>@Data&#xA;public class Customer extends ResourceSupport {&#xA;    private Long customerId;&#xA;    private String name;&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/customers"")&#xA;@ExposesResourceFor(Customer.class)&#xA;public class CustomersController {&#xA;    ...&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the offers app has:</p>&#xA;&#xA;<pre class=""lang-java prettyprint-override""><code>@Data&#xA;public class Offer extends ResourceSupport {&#xA;    private final Long offerId;&#xA;    private final Long priceI;&#xA;    private final Customer customer;&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/offers"")&#xA;@ExposesResourceFor(Offer.class)&#xA;public class OfferController {&#xA;    ...&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How would I organize the code so that you can add a <code>Customer</code> link to the <code>Offer</code> instances? Autowiring an <code>EntityLink</code> would of course not work since the two controllers live in separate apps.</p>&#xA;&#xA;<p>Would it be reasonable to create interfaces for all the controllers with the <code>@RequestMapping</code> on them and shared the inerfaces in all apps so that you could use e.g. <code>Link link = linkTo(methodOn(OfferController.class).getOffer(2L)).withSelfRel();</code>?</p>&#xA;"
33059557,How to build a monolithic app(sinatra) with the intention to move components to microservices architecture,2015-10-10 22:22:27,<sinatra><microservices><transitions>,1,57,0,0.0,1,"<p>I'm going to be helping to build an app (obviously), I was thinking of going with a microservices architecture initially but in thinking about it it's not necessary at this stage but it will be in the future.</p>&#xA;&#xA;<p>So, how do I build an app but with the intention to move sub-components into microservices?</p>&#xA;&#xA;<p>What concepts or structure should I follow that will make such a future transition easier?</p>&#xA;&#xA;<p>What should I be aware of?</p>&#xA;&#xA;<p>Any gotchas or things that might make transitioning harder then necessary if I don't watch out for them?</p>&#xA;&#xA;<p>Any thing else that would be usefull to know as well thank you.</p>&#xA;&#xA;<p>P.s. Yes, this might be a bit vague/broad but I'm not asking for in depth responses, just links to useful bit of information that will be of help to me. I've looked but not found anything useful in the transition from monolithic to microservices architectures. </p>&#xA;&#xA;<p>EDIT: Since it's obviously not clear let me state that I'm looking for resources, I get some will be opinionated, but that's fine, opinionated resources are better then NO resources which is what I currently have.</p>&#xA;&#xA;<p>Some guidance > no guidance. </p>&#xA;"
32945623,Load balancing in distributed system,2015-10-05 09:49:56,<soa><distributed><distributed-computing><microservices>,1,116,5,0.0,1,"<p>Given:</p>&#xA;&#xA;<ul>&#xA;<li>n producers and m consumers, n >> m</li>&#xA;<li>consumers make requests to producers for data</li>&#xA;<li>any producer can be used by only one consumer at a time i.e. consumer can work with multiple producers but producer must work with single consumer</li>&#xA;</ul>&#xA;&#xA;<p>Needed:</p>&#xA;&#xA;<ul>&#xA;<li>Consumers need to coordinate so every consumer can own subset of producers.</li>&#xA;<li>If consumer goes down, other consumers should take his producers.</li>&#xA;<li>Consumers should exchange producers to ensure equal load on consumers.</li>&#xA;</ul>&#xA;&#xA;<p>Question:</p>&#xA;&#xA;<p>Are there papers/algorithms/libraries for that case or should I invent another wheel?</p>&#xA;"
34586306,Is it possible to implement microservices with oData.net,2016-01-04 07:14:16,<c#><.net><architecture><odata><microservices>,2,799,0,1.0,1,"<p>I've been reading about the <a href=""http://microservices.io/patterns/microservices.html"" rel=""nofollow"">Microservice Architecure</a> and with the limited valuable information available on internet, I believe, I have a fair understanding of it from the theory point of view. I understand that on a high level this architecture suggests to move away from <a href=""http://microservices.io/patterns/monolithic.html"" rel=""nofollow"">monoliths</a> and have small, independent services. However, all the examples that I see on the internet are suggesting to write loosely coupled windows services (daemons in case of non MS implementations) connected to an <a href=""https://en.wikipedia.org/wiki/Enterprise_service_bus"" rel=""nofollow"">ESB</a>. I understand that writing small, loosely coupled web services that adhere to <a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow"">SRP</a> also fits the bill of micro services.</p>&#xA;&#xA;<p>That said, oData.Net services, where all oData controllers (micro services?) are deployed as a monolith, is a clear violation of the Microservices Architecure pattern. Is it a correct statement to make that oData.net is not designed to work as micro services? If your answer is no then please explain with help of a an example. Also, help me understand, how to have the API gateway pattern in the mix.</p>&#xA;"
34652782,"In a microservice environment, who should 'own' services that are no longer in active development?",2016-01-07 10:28:34,<soa><microservices>,2,54,0,0.0,1,"<p>In typical development environment, sizeable teams are typically aligned with largish projects. New features are shoe horned into existing monoliths. The team owns the monolith. Despite many parts of the monolith being no longer developed they are still being released and owned by the associated team. If there is a fix to be made it is clearly that team who perform it.</p>&#xA;&#xA;<p>In a microservices world, many smaller services are built, typical by small teams of 1s and 2s that once built may no longer require changes. The developers then move on to something else. The service may be a dependency of a number of applications. There is no specific 'team' associated with the service. </p>&#xA;&#xA;<p>So, when changes are required to the service, how does one assign ownership?</p>&#xA;"
34525969,Docker container on windows server,2015-12-30 08:47:02,<windows><docker><windows-server-2012><microservices>,1,92,0,0.0,1,"<p>Are docker containers supported in windows server 2012?&#xA;I saw that the windows server 2016 will support them,&#xA;but I couldn't find any reference to older versions.</p>&#xA;"
34660949,Modulus Meteor Microservices Subscriptions not working,2016-01-07 16:59:08,<meteor><microservices><modulus.io>,1,154,0,0.0,1,"<p>We are moving our app from Rackspace to Modulus. We have 2 apps configured as microservices using meteorhacks:cluster package. It seems like Meteor Methods (server1 to server2) call is working but Meteor subscription (client2 to server1) is not working. I am trying to figure out if it is a Cross domain request issue. </p>&#xA;&#xA;<pre><code>// https://github.com/meteorhacks/cluster#microservices&#xA;&#xA;//server2/app.js&#xA;Cluster.register(process.env.APP_NAME,{endpoint:process.env.ROOT_URL});&#xA;mainApp = Cluster.discoverConnection(""server1"");&#xA;Cluster.allowPublicAccess(""server1"");  &#xA;&#xA;&#xA;//client2/app.js&#xA;mainApp = Cluster.discoverConnection(""server1"");&#xA;ContentLibrary= new Meteor.Collection('content_library',   {connection:mainApp,idGeneration : 'MONGO'});&#xA;&#xA;//client2/home.js&#xA;mainApp.subscribe('contentDocuments','all',function(e){&#xA;  if(!e)&#xA;    doSomething();//Never gets called&#xA;});&#xA;&#xA;//server1/publish.js&#xA;Meteor.publish(""contentDocuments"", function(){&#xA; return ContentLibrary.find({});&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>ContentLibrary collection on the client is never populated.</p>&#xA;&#xA;<p>Our apps works on Rackspace as expected.</p>&#xA;"
34637868,Mobile App with microservices (on Microsoft Azure service fabric),2016-01-06 16:25:43,<microservices><azure-service-fabric><azure-api-apps><azure-api-management><azure-mobile-services>,1,720,0,1.0,1,"<p>I am planning to build an enterprise grade mobile application that requires full offline capability. It would be used worldwide. For the backend application, I intend to realise it as microservices using Azure Service fabric. The backend application would be leveraged by both a web admin UI as well as by the above mobile app. For the mobile app, I intend to use Azure App service's the new mobile app service. This would provide me the capability to do offline data sync and also carry out the functions when network reachability is there.</p>&#xA;&#xA;<p>MobileApp --> Azure MobileApp service --> Azure API app service --> Azure Service Fabric (cluster of nodes hosting microservices). </p>&#xA;&#xA;<p>Following are some questions &amp; observations on which I require advice:</p>&#xA;&#xA;<ol>&#xA;<li><p>The reason I am putting in Azure API service in the middle is because I intend to do API management (I understand Azure has a separate API management offering - any pointers on how I can do true API management in the above architecture would be very helpful. Would API management replace API app service ? )</p></li>&#xA;<li><p>I intend to use Swagger generated code out of API app service, so that both the web admin UI layer and the Azure Mobile App service layer can leverage. Your thoughts ?</p></li>&#xA;<li><p>Here I am using 2 paradigms - App Service (for mobile &amp; API) and App Service fabric. I believe this is the only option given the fact that I have a mobile app requiring heavy duty offline feature.</p></li>&#xA;<li><p>Data Sync from mobile: How do you think I can sync data between Mobile App service and the microservice specific data stores ? Do I need to go via the APIs or I can easily do a data sync with the data stores of individual microservices. Your thoughts please ? </p></li>&#xA;</ol>&#xA;"
34604106,How to break relationships database when change to microservice,2016-01-05 04:22:59,<sql><node.js><microservices>,1,104,1,1.0,1,"<p>In monolithic application I have a sample database like this</p>&#xA;&#xA;<pre><code>User&#xA;id:  serial&#xA;name : string&#xA;password :string &#xA;..&#xA;Blog&#xA;id : serial&#xA;body : string&#xA;author_id : Int &#xA;</code></pre>&#xA;&#xA;<p>When I want to get a list of posts with author info, I simply make inner join query. If I change my system to microservice. Blog and User are independent services. They will have an own database.&#xA;Should I  add author_id column on blog database?&#xA;If blog database don't have author_id, how can I get a list of post with author info?&#xA;I really need an example of microservices in Nodejs</p>&#xA;"
35304113,Can I run a microservice which keeps a port open in the cloud?,2016-02-09 23:17:06,<linux><server><cloud><microservices>,1,359,0,0.0,1,"<p>I'm new to microservices. I envision them as a set of processes running in two or more machines (I suppose for a given process two instances must be run in separate machines for reliability). In that setup, depending on the kind of clients I have there may be one process working as a TCP server serving on a specific high port and speaking a non-HTTP protocol.</p>&#xA;&#xA;<p>However, for my low-bandwidth, testing purposes, I haven't found a free cloud service which provides that kind of environment (machines to run processes on â€“ say, Java on Linux â€“ while keeping a high port open).</p>&#xA;&#xA;<p>Maybe the facilities I'm expecting are only available to paying customers, or maybe implementing a microservice architecture in the cloud goes beyond simply running processes in machines and sharing a database? Could someone clarify? (and if possible direct me to one such free service)</p>&#xA;"
35324974,Query eureka without registering as a service,2016-02-10 20:13:08,<java><spring><microservices><netflix><netflix-eureka>,1,503,0,1.0,1,"<p>I'm building a service X that will use eureka. I use spring boot and spring cloud. I want to check if i configured X correctly (load balancing, service discovery etc). to do it i would like to run X locally and connect/query existing eureka (on company's UAT environment) but without registering X as a new service so no traffic is redirected to my local machine.</p>&#xA;&#xA;<p>is it possible? what configuration is needed to achieve it?</p>&#xA;"
35368503,Does proper Falcor architecture lead to monolithic routers?,2016-02-12 17:16:02,<architecture><microservices><falcor><falcor-router>,1,239,1,1.0,1,"<p>I'm trying to get a grasp of Falcor and the concept behind it. </p>&#xA;&#xA;<p>Having read all I could find about it, I understand that an application should employ a single Model. This Model has a single source, and that source is an endpoint in the backend with a Falcor Router. </p>&#xA;&#xA;<p>Having looked at the Router example, every single possible route is part of a single source file. </p>&#xA;&#xA;<p>I'm having problems mapping the micro service concept (which is apparently used by Netflix!) onto this. When I combine a micro service architecture with Falcor routing, how do I separate the routes?</p>&#xA;"
34180115,How to register service in Consul without address declaration,2015-12-09 13:33:02,<java><microservices><service-discovery><consul>,1,1620,2,0.0,1,"<p>Using Consul, I want a service to register itself with the Consul Agent, using the HTTP endpoint <code>/v1/agent/service/register</code>. The only problem is that the service may bind to different IP addresses (1st instance 10.0.0.1, 2nd 10.0.0.2, etc) and I want Consul to set the address automatically basing on the IP address of the request.</p>&#xA;&#xA;<p>For example,</p>&#xA;&#xA;<p>""Service instance 1 (10.0.0.1)"" sends <code>{name:'svs', id:'svs-01'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-01', Address: 10.0.0.1}</code></p>&#xA;&#xA;<p>""Service instance 2 (10.0.0.2)"" sends <code>{name:'svs', id:'svs-02'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-02', Address: 10.0.0.2}</code></p>&#xA;&#xA;<p>According to <a href=""https://consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow"" title=""Consul Agent Service Documentation"">Consul Agent Service Documentation</a> if the Address field is missing in service register query, the Address will default to that of the agent if not provided. But it is not what I need.</p>&#xA;&#xA;<p>I've tried to detect service's ip address at runtime but it may have several network interfaces and it's hard to distinguish them.</p>&#xA;"
36129008,How to Send a Response Using Seneca and Express,2016-03-21 10:48:12,<node.js><express><microservices>,2,1982,0,1.0,1,"<p>I'm using Seneca to route API calls and express to serve my files.&#xA;The problem is I can't seem to find a way to send a response back to the client after getting my data from the API.&#xA;With express, I would just use <code>res.send</code>, but since I'm in the Seneca context I can't. Haven't found any reference to this issue in the documentation.</p>&#xA;&#xA;<pre><code>""use strict""; &#xA;const bodyParser  = require('body-parser');&#xA;const express = require('express');&#xA;const jsonp = require('jsonp-express');&#xA;const Promise = require('bluebird');&#xA;const path = require('path');&#xA;const seneca = require('seneca')();&#xA;const app = express();&#xA;&#xA;module.exports = (function server( options ) {   &#xA;&#xA;    seneca.add('role:api,cmd:getData', getData);&#xA;&#xA;    seneca.act('role:web',{use:{&#xA;        prefix: '/api',&#xA;        pin: {role:'api',cmd:'*'},&#xA;        map:{&#xA;            getData: {GET:true}          // explicitly accepting GETs&#xA;        }&#xA;     }});&#xA;&#xA;     app.use( seneca.export('web') )&#xA;&#xA;     app.use(express.static(path.join(__dirname, '../../dist/js')))&#xA;     app.use(express.static(path.join(__dirname, '../../dist/public')))&#xA;&#xA;     app.listen(3002, function () {&#xA;         console.log('listening on port 3002');&#xA;     });&#xA;&#xA;    function getData(arg, done){&#xA;        //Getting data from somewhere....&#xA;&#xA;        //Here I would like to send back a response to the client.            &#xA;     }&#xA; }())    &#xA;</code></pre>&#xA;"
36049030,golang workspaces in practice,2016-03-16 23:37:52,<go><workspace><microservices>,3,314,2,0.0,1,"<p>According to the Go documentation they would like you to have a workspace that one should put all their projects in.<sup>1</sup> However, as far as I can tell, this all falls apart as soon as you want to make a project that does not use Go exclusively. </p>&#xA;&#xA;<p>Take a project where it is made up of many micoservices for example. Lets say that it is structured like this:</p>&#xA;&#xA;<pre><code>app/&#xA;    authentication/ (Using rust)&#xA;    users/ (Using NodeJS)&#xA;    posts/ (Using Go)&#xA;</code></pre>&#xA;&#xA;<p>Only one part of the app would be written in Go, and that part is nested in a subdirectory of the app. How would I apply the Go workspace philosophy to this situation?</p>&#xA;&#xA;<hr>&#xA;&#xA;<ol>&#xA;<li><a href=""https://golang.org/doc/code.html#Workspaces"" rel=""nofollow"">https://golang.org/doc/code.html#Workspaces</a></li>&#xA;</ol>&#xA;"
32838312,Architecture for microservices,2015-09-29 07:37:32,<node.js><express><microservices>,2,2619,0,0.0,1,"<p>I've recently started to work with node.js and I have to build an architecture that should use multiple express.js services. Some of these services will have to be located on one server, anothers - on other server machines. I want to build a base service (like API Gateway), but I don't know what the proper way to communicate between this Gateway and microservices, or between two microservices.</p>&#xA;&#xA;<p>Currently I'm working with a solution based on this:</p>&#xA;&#xA;<pre><code># inside Gateway server I call another service:&#xA;http.get('http://127.0.0.1:5001/users', (service_res) -&gt;&#xA;  data = ''&#xA;  service_res.on 'data', (chunk) -&gt;&#xA;    data += chunk&#xA;&#xA;  service_res.on 'end', -&gt;&#xA;    # some logic on data&#xA;&#xA;).end() &#xA;</code></pre>&#xA;&#xA;<p>I have a strong feeling that this approach is not right. What the proper way to build communication logic between API Gateway and microservices?</p>&#xA;"
32831192,microservices and domain logic joins,2015-09-28 20:24:19,<join><architecture><microservices>,3,160,0,1.0,1,"<p>Microservices are deployed hosting their own database.</p>&#xA;&#xA;<p>What strategies do you employ when business requirements necessitate joins across data in multiple services?</p>&#xA;&#xA;<p>Example problem:  You are implementing a movie review site.  You have a movie microservice that holds the movie DB.  You also have a review microservice that manages reviews in its own separate DB.  Reviews are linked to movies via a GUID; but as these are implemented as separate data stores, not a key constraint.</p>&#xA;&#xA;<p>You would like to have available, accurate to the last minute, a report that tells you the total number of reviews for each review level grouped by the first letter of the movie having a review word count > 25 words.  You currently host 5 million reviews for 40,000 movies.</p>&#xA;&#xA;<p>E.G.   Reviews with more than 25 words:</p>&#xA;&#xA;<ul>&#xA;<li>A  [8457 ""1 star""] [16615 ""2 star""] [...</li>&#xA;<li>B  [98445 ""1 star""] [80210 ""2 star""] [...</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Having chosen a microservice architecture for your project, what strategies would you now employ to implement this feature? </p>&#xA;"
39604499,What asp.net Core project for MicroService without endpoint,2016-09-20 22:09:26,<asp.net><asp.net-core><microservices>,1,547,0,0.0,1,"<p>I am looking at taking the Docker plunge with a Microservices Framework.  I have seen numerous examples of exposing an endpoint to be called by something to do something (get me the weather at a location, the exchange rate for currency, etc). I have not seen anything that talks about how to replace my current Windows Service type applications or applications that subscribe to queues to do their work.</p>&#xA;&#xA;<p>For Example, lets say I have a windows service that every day at 2:00 AM zips all of the files in a given directory and puts them into a different directory (then publishes a message that it was completed).</p>&#xA;&#xA;<p>Do I build a asp.net core ""console app"" and add a startup.cs?  Do I need a startup.cs or just a startup method in my main?</p>&#xA;&#xA;<p>Like I said, lots of demos of building a tiny web response but little about what else to do if I do not want/need and endpoint.</p>&#xA;"
39593580,Synchronous communication microservices,2016-09-20 12:02:45,<architecture><domain-driven-design><microservices>,1,388,0,1.0,1,"<p>I understand that micro-services are a good way to separate contexts and allow us to create smaller models. One of the ways to achieve decoupling is asynchronous publish/subscribe communication between micro-services.</p>&#xA;&#xA;<p>Let's say a micro-service <strong>A</strong> is in charge to process a request and for that it needs information which are stored in micro-service <strong>B</strong>.&#xA;One of the ways to solve this is, is to make micro-service <strong>A</strong> to subscribe to events from micro-service <strong>B</strong>, copy portion of needed data to it's data storage and use it for future processing.</p>&#xA;&#xA;<p>Now, if user sends a request to micro-service <strong>A</strong> to process something, and micro-service <strong>A</strong> did not process latest events from micro-service <strong>B</strong>, would it be a better way to use synchronous communication, and request that portion of data directly? If yes, is that considered a ""violation"" of current design and coupling?</p>&#xA;&#xA;<p>Could it also be considered as a wrong modeling? Such as - if the data were needed in <strong>A</strong> context, then it should have been part of that context from start.</p>&#xA;"
39476480,microservices: C:\....m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature),2016-09-13 18:11:12,<java><maven><microservices>,1,665,0,1.0,1,"<p>I was looking to developed the <code>microservices</code> example by following the link: <a href=""https://github.com/bjedrzejewski/tasklist-service"" rel=""nofollow"">https://github.com/bjedrzejewski/tasklist-service</a>. When I simply compile the whole source code I faced compilation error, not sure why ? It looks to me something wrong with my .m2 home not so sure though.</p>&#xA;&#xA;<p>The error coming for reference:-</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure: Compilation failure:&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature)&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\eclipse\jetty\jetty-servlet\9.2.13.v20150730\jetty-servlet-9.2.13.v20150730.jar; invalid LOC header (bad signature)&#xA;[ERROR] -&gt; [Help 1]&#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)&#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)&#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)&#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)&#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)&#xA;Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure&#xA;        at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:656)&#xA;        at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:128)&#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)&#xA;        ... 20 more&#xA;[ERROR]&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException&#xA;</code></pre>&#xA;&#xA;<p>I only updated pom.xml to use Java version 8, nothing special</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;bjedrzejewski&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;tasklist-service&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;dropwizard.version&gt;0.9.1&lt;/dropwizard.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.dropwizard&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;dropwizard-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${dropwizard.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jersey-common&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.23.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;2.3.2&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;${java.version}&lt;/source&gt;&#xA;                    &lt;target&gt;${java.version}&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;archive&gt;&#xA;                        &lt;manifest&gt;&#xA;                            &lt;mainClass&gt;com.bjedrzejewski.tasklistservice.TaskListServiceApplication&lt;/mainClass&gt;&#xA;                        &lt;/manifest&gt;&#xA;                    &lt;/archive&gt;&#xA;                    &lt;descriptorRefs&gt;&#xA;                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;&#xA;                    &lt;/descriptorRefs&gt;&#xA;                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;&#xA;                &lt;/configuration&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;&#xA;                        &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;single&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>Also pom.xml dont have much entry of dependencies but still I see many jars files gets download why this so ?</p>&#xA;&#xA;<pre><code>E:\Advance Java\MicroServices\Git code\tasklist-service&gt;mvn dependency:tree&#xA;[INFO] Scanning for projects...&#xA;[INFO]&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building tasklist-service 1.0-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO]&#xA;[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ tasklist-service ---&#xA;[INFO] bjedrzejewski:tasklist-service:jar:1.0-SNAPSHOT&#xA;[INFO] +- io.dropwizard:dropwizard-core:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-util:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0:compile&#xA;[INFO] |  |  +- com.google.guava:guava:jar:18.0:compile&#xA;[INFO] |  |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile&#xA;[INFO] |  |  \- joda-time:joda-time:jar:2.9:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jackson:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-core:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk7:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-joda:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.slf4j:slf4j-api:jar:1.7.12:compile&#xA;[INFO] |  |  \- ch.qos.logback:logback-classic:jar:1.1.3:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-validation:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.hibernate:hibernate-validator:jar:5.2.2.Final:compile&#xA;[INFO] |  |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile&#xA;[INFO] |  |  |  +- org.jboss.logging:jboss-logging:jar:3.2.1.Final:compile&#xA;[INFO] |  |  |  \- com.fasterxml:classmate:jar:1.1.0:compile&#xA;[INFO] |  |  \- org.glassfish:javax.el:jar:3.0.0:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-configuration:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- org.yaml:snakeyaml:jar:1.15:compile&#xA;[INFO] |  |  \- org.apache.commons:commons-lang3:jar:3.4:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-logging:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-logback:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.slf4j:jul-to-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- ch.qos.logback:logback-core:jar:1.1.3:compile&#xA;[INFO] |  |  +- org.slf4j:log4j-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- org.slf4j:jcl-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-util:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-metrics:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jersey:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.core:jersey-server:jar:2.22.1:compile&#xA;[INFO] |  |  |  +- org.glassfish.jersey.core:jersey-client:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-metainf-services:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-bean-validation:jar:2.22.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jersey2:jar:3.1.2:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile&#xA;[INFO] |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-server:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-io:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-xml:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-continuation:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-servlets:jar:0.9.1:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-annotation:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jetty:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jetty9:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlet:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-security:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlets:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-http:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-lifecycle:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-servlets:jar:3.1.2:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-json:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-healthchecks:jar:3.1.2:compile&#xA;[INFO] |  +- net.sourceforge.argparse4j:argparse4j:jar:0.6.0:compile&#xA;[INFO] |  \- org.eclipse.jetty.toolchain.setuid:jetty-setuid-java:jar:1.0.3:compile&#xA;[INFO] \- org.glassfish.jersey.core:jersey-common:jar:2.23.2:compile&#xA;[INFO]    +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile&#xA;[INFO]    +- javax.annotation:javax.annotation-api:jar:1.2:compile&#xA;[INFO]    +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.23.2:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-api:jar:2.5.0-b05:compile&#xA;[INFO]    |  +- org.glassfish.hk2:hk2-utils:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2.external:javax.inject:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-locator:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.javassist:javassist:jar:3.20.0-GA:compile&#xA;[INFO]    \- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD SUCCESS&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 2.860 s&#xA;[INFO] Finished at: 2016-09-13T23:39:38+05:30&#xA;[INFO] Final Memory: 17M/309M&#xA;[INFO] ------------------------------------------------------------------------&#xA;</code></pre>&#xA;"
39435028,How to use micro-services into core application/framework?,2016-09-11 10:16:13,<rest><microservices>,1,120,5,0.0,1,"<p>For example I have two micro-services, how can I use those services in my core application?</p>&#xA;&#xA;<p>I know the communication will be through REST API. </p>&#xA;&#xA;<p>My question is, should I create those services as sub-modules?</p>&#xA;&#xA;<p>If my question seems not clear to you then assume I am not clear about micro-services. Thus better explanation will be very helpful.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
32373324,OAuth Access token Validation with Microservices,2015-09-03 10:38:22,<oauth><architecture><microservices>,1,268,0,0.0,1,"<p>I am currently thinking about building an application following the microservice architecture. To authorize the user I was thinking of using the OAuth protocol. Now the question is where/when to validate the Access Token.&#xA;I basically see two possibilities:</p>&#xA;&#xA;<ol>&#xA;<li>Each microservice is doing it on it's own (meaning one call that might involve 10 microservices would result in 10 token validations)</li>&#xA;<li>Introduce an API gateway (which needs to be there anyways I guess) which does the token validation and passes on the user ID, scopes, ... that the other microservices trust and use (which also means that some kind of authentication between the API gateway and the microservice must be there, e.g. client secret!?)</li>&#xA;</ol>&#xA;&#xA;<p>As you probably have already guessed, I tend to go with the second approach. Is that a valid one? Do you have some practical experiece with one of those approaches? Or yould you suggest another approach?&#xA;I'm looking forward to your comments/remarks on that!</p>&#xA;&#xA;<p>Thanks and regards!</p>&#xA;"
32369075,Universal data model and microservices integration,2015-09-03 07:07:00,<design><data-modeling><domain-model><microservices>,2,498,2,1.0,1,"<p>Since the native-cloud applications or microservices architecture required decentralized data model (each microservices has own database), and <a href=""http://www.universaldatamodels.com/"" rel=""nofollow"">universal data model</a> is centralized data model</p>&#xA;&#xA;<p>So how we have microservices architecture with universal data model patterns?</p>&#xA;&#xA;<p>Is there any reference or implementation of universal data model and microservices?</p>&#xA;"
39668149,Service Fabric / Actor Pattern for List of Things,2016-09-23 19:22:41,<design-patterns><microservices><azure-service-fabric>,1,268,0,0.0,1,"<p><strong>Conceptually, I have the following objects:</strong></p>&#xA;&#xA;<ul>&#xA;<li><code>Item - (ItemId, Name, Color)</code></li>&#xA;<li><code>ItemGroup = (GroupId, Name, Item list)</code></li>&#xA;</ul>&#xA;&#xA;<p>Let's pretend items can belong to multiple groups and that Item identity and the ItemActor is necessary.</p>&#xA;&#xA;<p><strong>For <em>stateful</em> actors, I have this:</strong></p>&#xA;&#xA;<ul>&#xA;<li><code>ItemActor (ItemId) : Get() -&gt; returns ItemContract { ItemId, Name, Color }</code></li>&#xA;<li><code>ItemGroupActor (GroupId) : Get() -&gt; returns GroupContract { GroupId, Name, List&lt; ItemContract &gt; }</code></li>&#xA;</ul>&#xA;&#xA;<p><strong>Here's the questions:</strong>  </p>&#xA;&#xA;<ol>&#xA;<li><p>Should the GroupActor only keep the ItemIds, and force someone else to call each ItemActor (<strong>in a loop</strong>) for the ItemContracts? </p></li>&#xA;<li><p>Or does the GroupActor keep all of the item details and listen for Item change events to keep his data up to date (like a view)?</p></li>&#xA;<li><p>Or is there a third ""ViewActor"" who compiles the data together, calling ItemActors (<strong>in a loop</strong>), and listening to events to keep it's data up to date?</p></li>&#xA;<li><p>Or something else?</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>None of these options strike me as particularly attractive, because they either require looping actor calls, or high maintenance item management via events.</strong></p>&#xA;&#xA;<p>Is there some guideline to reassure me one way or the other or for a general approach to this scenario?</p>&#xA;"
39696697,How to load HTML fragment on-demand in AngularJS?,2016-09-26 07:09:39,<angularjs><microservices>,1,297,0,0.0,1,"<p>There are tons of examples of how to use AngularJS routing to load HTML and scripts dynamically. My scenario is different, and I can't find how to do it.</p>&#xA;&#xA;<p>Assume that this code is already loaded into the browser:</p>&#xA;&#xA;<pre><code>&lt;div ng-controller='masterController'&gt;&#xA;    &lt;button ng-click='loadOtherHtmlOnDemandAndAppendItAfterMe'&gt;&lt;/button&gt;&#xA;&lt;/div&gt;&#xA;&lt;script&gt;&#xA;    app.controller('masterController', ['$scope', function($scope){&#xA;        $scope.loadOtherHtmlOnDemandAndAppendItAfterMe = function() {&#xA;            /* &#xA;              how can I load another HTML file,&#xA;              that contains it's related script too here, on-demand&#xA;            */&#xA;        };&#xA;    }]);&#xA;&lt;/script&gt;&#xA;</code></pre>&#xA;&#xA;<p>Now I understand that a lot of people might now yell that <strong>You're doing it wrong, that's not how AngularJS should work</strong>, and stuff, yet we're stuck at an architecture of micro-services and mashup web UI, where a module loaded into the browser fires an event saying that it needs a functionality, and another module that is listening to that event, should load the related functionality on-demand. URL does not change, and routing is not used here.</p>&#xA;"
39721791,Can you reference other aggregates in a factory when implementing domain driven design?,2016-09-27 10:03:52,<java><domain-driven-design><microservices>,3,46,0,0.0,1,"<p>I have two aggregates, <code>Employee</code> and <code>Company</code>.  An <code>Employee</code> stores a reference to the <code>Company</code> via it's <code>UUID</code>.</p>&#xA;&#xA;<p>If I want to create an employee, I need to provide it with the company ID:</p>&#xA;&#xA;<pre><code>new Employee(name, companyId)&#xA;</code></pre>&#xA;&#xA;<p>What I can't get my head around is how to get the <code>id</code> of the <code>Company</code> if the client provides only the company name.  In other words, I see this happening:</p>&#xA;&#xA;<pre><code>Employee buildEmployee(String name, String companyName) {&#xA;    Company company = companyRepository.findByName()&#xA;    return new Employeee(name, company.getGUID())&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Something feels wrong to me, as now I've introduced a dependency on the <code>Company</code> aggregate in order to create an <code>Employee</code>.  Even worse would be that if these were two were separate microservices, as I'd have to make a rest call to get the company name.</p>&#xA;&#xA;<p>Is there a way to avoid this coupling, or are my entities modelled incorrectly?</p>&#xA;"
39764239,Recovering state consistency in Flink when using Kafka as EventStore,2016-09-29 07:40:17,<apache-kafka><aggregate><microservices><apache-flink><event-sourcing>,1,482,0,0.0,1,"<h1>The problem</h1>&#xA;&#xA;<p>I am implementing a microservice as an event-sourcing aggregate which, in turn, is implemented as a Flink FlatMapFunction. In the basic setup, the aggregate reads events and commands from two kafka topics. Then, it writes new events to that first topic and processing results in a third topic. Therefore, Kafka acts as the event store. Hope this drawing helps:</p>&#xA;&#xA;<pre><code>  RPC Request                              RPC Result&#xA;  |                                                 |&#xA;  ~~~~&gt; Commands-|              |---&gt; Results ~~~~~~|&#xA;                 |--&gt;Aggregate--|&#xA;  ~&gt; Input evs. -|              |---&gt; output evs. ~~~&#xA;  |                                                 |&#xA;  ~~~~~&lt;~~~~~~~~~~~&lt;~~~feedbak loop~~~~~&lt;~~~~~~~~&lt;~~~&#xA;</code></pre>&#xA;&#xA;<p>Due to the fact that Kafka is not checkpoined, commands could potentially be replayed twice and it seems that output events could also be written twice the topic. </p>&#xA;&#xA;<p>How could the state be recovered in those cases with repeated messages? Is it possible for the aggregate to know when its input streams are up-to-date to start processing commands?</p>&#xA;&#xA;<h1>My thoughts</h1>&#xA;&#xA;<p>I have thought several solutions:</p>&#xA;&#xA;<ol>&#xA;<li><p>If Flink implements a rollback unconfirmed events, a Sink could be implemented which will get the current offset from the event source. When restarted, this sink would remove newer-than-offset events in kafka topic. It his way, KafkaSource and KafkaSink would be generated from the same builder and then exposed to the topology. This solution has a strong problem given that other services could read the newer events in the topic and cause inconsistency.</p></li>&#xA;<li><p>If removing events from Flink is not possible in 2, the statefull source could potentially read events from the offset and try to match the repeated events in the aggregate and drop them. This options seems not robust as there can be situations where patches are not deterministic and subject to flaws as it should be rethought for each aggregate and topology and it would not warranty recovery (e.g. in case of consecutive restarts). Therefore this is a bad solution.</p></li>&#xA;<li><p>A different approach is this one. It is to create a special KafkaSource with two special watermarks: First one, KafkaSourceStartedWatermark, will be always sent at source startup to notify dependant operators. When this watermark is sent, the source internally records the current Kafka offset. Second one, KafkaSourceUpToDateWatermark, is sent by the source when the offset is reached. These watermarks would travel along the topology transparently. The operator should be able to handle these Watermarks, implementing a special WatermarkNotifiable interface.Then, the aggregate will be able to buffer or drop RPC commands until it is up-to-date in every input source. </p>&#xA;&#xA;<pre><code>interface WatermarkNotifiable  {&#xA;    void started(String watermarkId);//KafkaSourceStartedWatermark watermark&#xA;    void upToDate(String watermarkId);//KafkaSOurceUpToDateWatermark watermark&#xA;}  &#xA;</code></pre></li>&#xA;<li><p>If implementing the infrastructure in 3 is not possible, the KafkaSource could implement a constructor specifying a special watermark event that could travel to the operators, but this would require that all the operators depend on these watermarks an re-emits then.</p></li>&#xA;<li><p>Other different approach is to not process commands older that a criteria. For example, commands have an entry timestamp. If time is used, time synchronization is critical. </p></li>&#xA;</ol>&#xA;&#xA;<h1>Related StackOverflow questions</h1>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/17708489/using-kafka-as-a-cqrs-eventstore-good-idea"">Using Kafka as a (CQRS) Eventstore. Good idea?</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/34905577/kafka-know-if-consumer-is-up-to-date"">Kafka - Know if Consumer is up to date</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/39459315/kafka-flink-duplicate-messages-on-restart"">Kafka &amp; Flink duplicate messages on restart</a></li>&#xA;</ol>&#xA;"
39788745,How to use messaging (Amazon SQS) in web api to return created id to the client,2016-09-30 09:56:52,<c#><amazon-web-services><asp.net-web-api><amazon-sqs><microservices>,1,133,2,0.0,1,"<p>Just starting to use Amazon SQS service, so just wondering if someone can guide me into the right direction.&#xA;In case I have rest web-api interface exposed to the clients and after each http request I want to send asynchronous message to my separate service, which is responsible to create specific entity in the database and process with some logic. Something like this:</p>&#xA;&#xA;<pre><code>        var auctionRegistrationCommand = AuctionRegistrationCommand&#xA;            .CreateFromRequest(lotId, request);&#xA;&#xA;        //var sqsClient = new AmazonSQSClient();&#xA;        //var response = sqsClient.SendMessageAsync(..resitrationCommaon..);&#xA;</code></pre>&#xA;&#xA;<p>After entity is created I want to return Id of created entity to my client, so it can use it to update it or make some additional call to rest api. But I cannot find how to do it. Are there any patterns or approaches how to support such scenarios? Will be perfect to see some example using Amazon SQS, but general explanation will be also really helpful.</p>&#xA;"
39791667,Context mapping - relations,2016-09-30 12:34:52,<domain-driven-design><microservices><bounded-contexts>,2,264,3,0.0,1,"<p>Is it considered a bad idea that 2 bounded contexts can have upstream communication between them?</p>&#xA;&#xA;<p>Example for, order BC will publish event, and inventory BC will subscribe for that event and in the same time, inventory BC can publish events and order BC will subscribe</p>&#xA;"
39690815,java.lang.IllegalArgumentException: Only the target location may be specified,2016-09-25 19:16:30,<java><spring><spring-mvc><spring-boot><microservices>,2,330,4,0.0,1,<p>I'm writing my first spring boot application. on running the following command i'm getting the exception.</p>&#xA;&#xA;<pre><code>spring init --build maven --groupId com.redhat.examples\ --version 1.0 --java-version 1.8 --dependencies web\ --name hola-springboot hola-springboot&#xA;java.lang.IllegalArgumentException: Only the target location may be specified&#xA;    at org.springframework.util.Assert.isTrue(Assert.java:68)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.createProjectGenerationRequest(InitCommand.java:218)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.generateProject(InitCommand.java:209)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.run(InitCommand.java:189)&#xA;    at org.springframework.boot.cli.command.options.OptionHandler.run(OptionHandler.java:84)&#xA;    at org.springframework.boot.cli.command.OptionParsingCommand.run(OptionParsingCommand.java:54)&#xA;    at org.springframework.boot.cli.command.CommandRunner.run(CommandRunner.java:219)&#xA;    at org.springframework.boot.cli.command.CommandRunner.runAndHandleErrors(CommandRunner.java:171)&#xA;    at org.springframework.boot.cli.SpringCli.main(SpringCli.java:63)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)&#xA;    at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58)&#xA;</code></pre>&#xA;
40216232,How to move an email service into a thread?,2016-10-24 10:33:22,<java><email><microservices><netflix-feign>,1,80,0,0.0,1,"<p>I am using Feign to connect two microservices. One of them composes the email and the other one sends it. </p>&#xA;&#xA;<p>This is the Email Client:</p>&#xA;&#xA;<pre><code>@FeignClient(""holiday-client"")&#xA;public interface EmailClient {&#xA;    @RequestMapping(value = ""/api/email/sendEmail"", method = RequestMethod.POST)&#xA;    void sendEmail(@RequestBody Email email);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The service where the email is composed:</p>&#xA;&#xA;<pre><code>@Service&#xA;public class EmailService {&#xA;    @Autowired&#xA;    private EmailClient emailClient;&#xA;&#xA;    public void sendEmailForNewCampaign() {&#xA;        String to, subject, body;&#xA;&#xA;        to = ""test@domain.com"";&#xA;        subject = ""A new campaign has started"";&#xA;        body = ""This email has the purpose to inform you that a new campaign has been started. Please start your own performance reviews until it ends."";&#xA;        Email email = new Email(to, subject, body);&#xA;        emailClient.sendEmail(email);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And the controller from the other microservice which actually sends the email:</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class EmailController {&#xA;&#xA;    @Autowired&#xA;    private EmailSender emailSender;&#xA;&#xA;    @RequestMapping(value = ""/api/email/sendEmail"", method = RequestMethod.POST)&#xA;    public ResponseEntity sendEmail(@RequestBody Email email) {&#xA;        System.out.println(email); //printed 5 times&#xA;        emailSender.sendMail(email.getTo(), email.getSubject(), email.getBody());&#xA;        return new ResponseEntity(HttpStatus.ACCEPTED);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>It seems that this API is called 5 times until the email is processed and sent. It works cause I receive 5 emails, but I also got a SocketTimeOutException.&#xA;The problem is that the client waits too long for the email service to send the mail and I don't want that.&#xA;How can I move the method sendMail into a thread in order to solve this problem ?</p>&#xA;"
40097751,How can I access a service installed on Kubernetes from anywhere?,2016-10-18 00:38:00,<java><kubernetes><microservices><devops>,1,140,0,0.0,1,"<p>I am working on a mac machine and installed the latest Kubernetes and followed the <a href=""https://medium.com/@claudiopro/getting-started-with-kubernetes-via-minikube-ada8c7a29620#.xfrpcgv50"" rel=""nofollow"">example here</a> (this is for devâ€™t purpose). All went smooth but I was hoping that Kubernetes provide me an ip address and port number where my service will be listening to so that I can access it from anywhere. </p>&#xA;&#xA;<p>Please correct me if I am wrong. </p>&#xA;&#xA;<p>I was able to run <code>ifconfig</code> as well as <code>curl $(minikube service hello-minikube --url)</code> and I was able to see the ip address and port but I wasnâ€™t able to access it outside command line where Kubernetes lives in.</p>&#xA;&#xA;<p>The reason I am trying to access it outside the VM is because we have other projects that run on other machines and I wanted to call the REST service I installed while we are on dev env. This way we donâ€™t have to wait until the service is pushed to production. </p>&#xA;&#xA;<p>FYI: This is my first micro service project and I would appericiate your feedback.</p>&#xA;"
40201069,Not able to connect mongodb with Rails container using Docker compose,2016-10-23 08:38:33,<ruby-on-rails><mongodb><docker><docker-compose><microservices>,1,984,3,1.0,1,"<p>Getting this error when inserting values in Model through rails console .</p>&#xA;&#xA;<blockquote>&#xA;  <p>""Mongo::Error::NoServerAvailable: No server is available matching&#xA;  preference: # using server_selection_timeout=30 and local_threshold=&#xA;  0.015 ""</p>&#xA;</blockquote>&#xA;&#xA;<p>Both containers are running fine, but Rails not able to connect mongodb .&#xA;I have only one Dockerfile.</p>&#xA;&#xA;<p>My docker-compose.yml file contents are:</p>&#xA;&#xA;<pre><code> version: '2'&#xA;&#xA;services:&#xA;  mongo:&#xA;    image: mongo:3.0&#xA;    command: mongod --smallfiles --quiet&#xA;    environment:&#xA;      - RAILS_ENV=production&#xA;      - RACK_ENV=production&#xA;    ports:&#xA;      - ""27017:27017""&#xA;&#xA;  app:&#xA;    depends_on:&#xA;      - 'mongo'&#xA;      # - 'redis'&#xA;    build: .&#xA;    ports:&#xA;      - '3000:3000'&#xA;    volumes:&#xA;      - '.:/app'&#xA;    command: rails s -b '0.0.0.0'&#xA;    env_file:&#xA;      - '.env'&#xA;&#xA;volumes:&#xA;  mongo:&#xA;</code></pre>&#xA;&#xA;<p>My Dockerfile :</p>&#xA;&#xA;<pre><code>FROM ruby:2.3.0&#xA;RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs&#xA;&#xA;ENV APP_HOME /app&#xA;&#xA;RUN mkdir $APP_HOME  &#xA;WORKDIR $APP_HOME&#xA;&#xA;&#xA;ADD Gemfile* $APP_HOME/ &#xA;RUN bundle install&#xA;&#xA;&#xA;ADD . $APP_HOME&#xA;</code></pre>&#xA;"
35555602,Running Eureka Client with JDK 1.7,2016-02-22 14:01:40,<java><compiler-errors><microservices><netflix-eureka>,2,518,0,0.0,1,"<p>I am getting following error when running a eureka client discovery sample code.</p>&#xA;&#xA;<pre><code>Exception in thread ""main"" java.lang.UnsupportedClassVersionError: com/netflix/servo/monitor/Monitors : Unsupported major.minor version 52.0&#xA;</code></pre>&#xA;&#xA;<p>I guess this is probably due to the fact that eureka is compiled with Java 8 (52).&#xA;But does it mean that we can not use it with JDK 1.7 ? My project is in JDK7 and is it possible to run eureka(1) with JDK 1.7 ?</p>&#xA;"
35501600,How to config spring cloud oauth2 in docker container,2016-02-19 09:20:34,<spring><docker><spring-cloud><microservices><oauth2>,1,841,0,0.0,1,"<p>I met some problems with micro-spring-docker , i think maybe the sso token-url is not correct.</p>&#xA;&#xA;<p>The demo https://github.com/keryhu/micro-oauth2-docker</p>&#xA;&#xA;<p>In local computer , sso service and auth-service works fine .</p>&#xA;&#xA;<p>But not  in docker container , </p>&#xA;&#xA;<blockquote>&#xA;  <p>the problem is that redirecting to auth-server Timeout .</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>SSO(pc-gateway service) application.yml:</strong></p>&#xA;&#xA;<pre><code>security:&#xA;  user:&#xA;    password: none&#xA;  oauth2:&#xA;    client:&#xA;      accessTokenUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/token&#xA;      userAuthorizationUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/authorize&#xA;</code></pre>&#xA;&#xA;<p><strong>docker-compose.yml</strong></p>&#xA;&#xA;<pre><code>eureka:&#xA;  image: eureka:0.0.1-SNAPSHOT&#xA;  container_name: eureka&#xA;  hostname: eureka&#xA;  ports:&#xA;   - ""8761:8761""&#xA;&#xA;configserver:&#xA;  image: config-server:0.0.1-SNAPSHOT&#xA;  container_name: configserver&#xA;  hostname: configserver&#xA;  links:&#xA;    - eureka&#xA;  ports:&#xA;    - ""8888:8888""&#xA;&#xA;authserver:&#xA;  image: auth-server:0.0.1-SNAPSHOT&#xA;  container_name: authserver&#xA;  hostname: authserver&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;  ports:&#xA;    - ""9999:9999""&#xA;&#xA;pcgateway:&#xA;  image: pc-gateway:0.0.1-SNAPSHOT&#xA;  container_name: pcgateway&#xA;  hostname: pcgateway&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;    - authserver&#xA;  ports:&#xA;    - ""8080:8080""&#xA;</code></pre>&#xA;&#xA;<p>After starting in docker container :         </p>&#xA;&#xA;<p><a href=""http://192.168.99.100:8761/"" rel=""nofollow"">http://192.168.99.100:8761/</a> showing :</p>&#xA;&#xA;<pre><code>Instances currently registered with Eureka&#xA;Application   AMIs     Availability Zones   Status&#xA;AUTHSERVER   n/a(1)           (1)           UP (1) - authserver:authserver:9999&#xA;CONFIGSERVER n/a(1)           (1)           UP (1) - configserver:configserver:8888&#xA;PCGATEWAY    n/a(1)           (1)           UP (1) - pcgateway:pcgateway:8080&#xA;</code></pre>&#xA;&#xA;<p>But when open the auth page: <a href=""http://192.168.99.100:8080"" rel=""nofollow"">http://192.168.99.100:8080</a> </p>&#xA;&#xA;<p>It should be redirected to  auth-server login page , but it opened Timeout ï¼Œ the Address Bar is: </p>&#xA;&#xA;<pre><code>http://172.17.0.4:9999/uaa/oauth/authorize?client_id=clientapp&amp;redirect_uri=http://192.168.99.100:8080/login&amp;response_type=code&amp;state=cdXhfg&#xA;</code></pre>&#xA;&#xA;<p>I don't know why , maybe the above sso tokenurl is not correct . How to resolve ?</p>&#xA;"
35549233,How to Inject Kubernetes Service to my java class?,2016-02-22 08:46:24,<java-ee><cdi><kubernetes><microservices><fabric8>,1,142,0,0.0,1,"<p>I have created and deployed successfully one service in <code>kubernetes</code> named <em>rest_api_service</em>.</p>&#xA;&#xA;<p>I have another project which needs to call a resource from <em>rest_api_service</em>. So, in order to get out the IP of my service, I tried to inject:</p>&#xA;&#xA;<pre><code>@Inject&#xA;@ServiceName(""luz-person-service"")&#xA;String serivceUrl;&#xA;</code></pre>&#xA;&#xA;<p>But my Eclipse shows me this warn message:</p>&#xA;&#xA;<pre><code>&gt; No bean is eligible for injection to the injection point [JSR-346&#xA;&gt; Â§5.2.2]&#xA;</code></pre>&#xA;&#xA;<p>Therefore I can not build it in <code>wildfly</code>.</p>&#xA;&#xA;<p>Currently, I am working only on pure <code>Java EE 7</code> and I'm using the following dependency:</p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;    &lt;groupId&gt;io.fabric8&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;fabric8-cdi&lt;/artifactId&gt;&#xA;    &lt;version&gt;2.1.11&lt;/version&gt;&#xA;&lt;/dependency&gt; &#xA;</code></pre>&#xA;&#xA;<p>Do you guys have any idea?</p>&#xA;"
35531784,How to make available the identity of a user across multiple microservices?,2016-02-21 02:59:56,<authentication><authorization><microservices>,1,566,1,0.0,1,"<p>So let's take the basic e-commerce microservices. </p>&#xA;&#xA;<ol>&#xA;<li>Identity and access . This microservice will take care of user accounts, roles<br>&#xA;and authentication. The authentication method will be the based on the usual<br>&#xA;token based flow (user enters username + pass and server returns a unique and<br>&#xA;random token via cookie).  This service can also be used to get the user profile.</li>&#xA;<li>Cart microservice. This microservice can be used to put products in a cart.<br>&#xA;Check what products a cart has. Etc ...  </li>&#xA;</ol>&#xA;&#xA;<p>Asuming that ""Identity and access"" microservice will be used for generating the random token as a result of a succesful authentication, and for linking this token to a user, how will this token be used to make the user's identity available to the cart microservice? For example, when a user will add a product to his cart, he will send along the authorization token and the cart microservice will have to identify the user based on that token.  </p>&#xA;&#xA;<p>Could a distributed database be an option? A database which has these tokens stored and links to user built, and to which all microservices have access?  </p>&#xA;&#xA;<p>Or should all microservices get the user's identity from a special identity and access API which will expose users based on the access token?</p>&#xA;"
35639882,JWT Authentication within a Micro Service architecture,2016-02-25 22:42:00,<php><node.js><rest><authentication><microservices>,2,682,2,0.0,1,"<p><strong>Question</strong></p>&#xA;&#xA;<p>Question how is it possible to create an authentication service within a micro-service application and have other services check against that token (JWT) and retrieve a user?</p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p>My current thinking is based around the auth service inserting <code>{ token, user }</code> into Redis once a user is authenticated. All other service can check against the user's <code>Authorization: Bearer kdI8$dj$nD&amp;...</code> header token within Redis. </p>&#xA;&#xA;<ul>&#xA;<li>If <code>token</code> is present in Redis, user is authenticated.</li>&#xA;<li>If <code>token</code> is not present in Redis, user is not authenticated.</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/7fsl7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7fsl7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>User sends <code>{ username, password }</code> to auth service</li>&#xA;<li>Auth service authenticates credentials and retrieves <code>{ token, user }</code></li>&#xA;<li>Auth service inserts <code>{ token, user }</code> into Redis</li>&#xA;<li>User makes request to <code>Service-1</code> with <code>{ token }</code></li>&#xA;<li><code>Service-1</code> loooks for <code>{ token }</code> in Redis and retrieves <code>{ token, user }</code></li>&#xA;<li><code>Service-1</code> does its thing and sends back <code>{ data }</code></li>&#xA;</ol>&#xA;&#xA;<p>Are there any possible security, logic or architectural problems with this approach? </p>&#xA;"
41672971,Append request header post spring security authentication,2017-01-16 09:21:11,<spring><spring-security><microservices><netflix-zuul>,2,556,0,0.0,1,"<p>We would like to add header to our request post spring security authentication has happened. </p>&#xA;&#xA;<p>However, headers are not getting appended. &#xA;We were able to do it through a Zuul filter but not with spring security filter. </p>&#xA;&#xA;<pre><code>public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {&#xA;    httpServletRequestWrapper = new HttpServletRequestWrapper(request) {&#xA;        @Override&#xA;        public String getHeader(String name) {&#xA;            if (name.equalsIgnoreCase(ENV - HEADER)) {&#xA;&#xA;                return active;&#xA;            } else if (name.equalsIgnoreCase(USERID)) {&#xA;&#xA;                return (String) authentication.getPrincipal();&#xA;            } else {&#xA;                return super.getHeader(name);&#xA;            }&#xA;        }&#xA;    };&#xA;&#xA;    filterChain.doFilter(httpServletRequestWrapper, servletResponse);&#xA;}&#xA;</code></pre>&#xA;"
41631842,Handling user request in Microservice Architecture powered by Messaging inter-communication (f.e. RabbitMQ),2017-01-13 09:59:05,<rabbitmq><messaging><microservices>,1,178,0,1.0,1,"<p>I'm just starting with Microservice Architecture and investigating how to build that on top of messaging bus.</p>&#xA;&#xA;<p>There is one concern which bothers me right now - how do I handle a simple query-like request from user or when microservice needs some data from other microservice to serve a response? (f.e. getOrderList, or getUserNameById)</p>&#xA;&#xA;<p>I know there is a RPC pattern in RabbitMQ, but everybody is strongly recommending to avoid that (as it brings temporal coupling) and use async communication instead.</p>&#xA;"
41548676,Running Lagom in Production,2017-01-09 13:00:59,<java><akka><actor><microservices><lagom>,1,1214,0,1.0,1,"<p>I am working on setting up a Lagom application in production. I have tried contacting Lightbend for ConductR license but haven't heard back in ages. So, now I am looking for an alternative approach. I have multiple questions.</p>&#xA;&#xA;<p>Since the scale of the application is pretty small right now, I think using a static service locator works for me right now (open to other alternatives). Also, I am using MySQL as my event store instead of the default configuration of Cassandra (Reasons not relevant to this thread).</p>&#xA;&#xA;<p>To suppress Cassandra and Lagom's Service Locator, I have added the following lines to my build.sbt:</p>&#xA;&#xA;<pre><code>lagomCassandraEnabled in ThisBuild := false&#xA;</code></pre>&#xA;&#xA;<p>I have also added the following piece to my application.conf with service1-impl module.</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For the dev environment, I have been able to successfully run my application using <code>sbt runAll</code> in a tmux session. With this configuration, there is no service locator running on the default 8000 port but I can individually hit service1 on 8080 port. (Not sure if this is the expected behaviour. Comments?)</p>&#xA;&#xA;<p>I ran <code>sbt dist</code> to create a zip file and then unzipped it and ran the executable in there. Interestingly, the zip was created within the service1-impl folder. So, if I have multiple modules (services?), will sbt dist create individual zip files for each of the service?</p>&#xA;&#xA;<p>When I run the executable created via <code>sbt dist</code>, it tries to connect to Cassandra and also launches a service locator and ignores the static service locator configuration that I added. Basically, looks like it ignores the lines I added to build.sbt. Anyone who can explain this?</p>&#xA;&#xA;<p>Lastly, if I were to have 2 services, service1 and service2, and 2 nodes in the cluster with node 1 running service1 and node 2 running both the services, how would my static service locator look like in the application.conf and since each of the service would have its own application.conf, would I have to copy the same configuration w.r.t. static service locator in all the application.confs?</p>&#xA;&#xA;<p>Would it be something like this?</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;    service1 = ""http://1.2.3.4:8080""&#xA;    service2 = ""http://1.2.3.4:8081""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Since each specific actor would be spawned on one of the nodes, how would it work with this service locator configuration?</p>&#xA;&#xA;<p>Also, I don't want to run this in a tmux session in production. What would be the best way to finally run this code in production?</p>&#xA;"
41624628,How do you develop a microservice in isolation when it depends on other microservices?,2017-01-12 23:03:45,<microservices>,2,196,1,2.0,1,"<p>We are evaluating a move to microservices.  Each microservice would be its own project developed in isolation.  During planning, we have determined that some of the microservices will communicate with other via REST calls, pub/sub, messaging (ie. a order service needs product information from product service).</p>&#xA;&#xA;<p>If a microservice depends on retrieving data from another microservice, how can it be run in isolation during development?  For example, what happens when your order service requests product details, but there is nothing to answer that request?</p>&#xA;"
41516276,How should one go about making a microservice out of a reactjs module?,2017-01-06 23:56:33,<reactjs><microservices>,1,451,3,1.0,1,"<p>One possible way would be to run a separate node server making just the required API calls for said module, process and emit HTML as string. This could probably be imported in the main reactjs app via an API call. Or may be use a framework like Seneca that could use the node service output similarly. Can't figure out a way to import the node service output in the main reactjs app as a component along with props. That would allow me to add some pure front-end functionality and make a higher order component out of it.</p>&#xA;"
42843777,Microservices in Consul,2017-03-16 20:03:11,<microservices><consul>,2,271,0,0.0,1,"<p>I'm interested in knowing if I can use Consul to solve the following issues:</p>&#xA;&#xA;<p>1) Can Consul be used to load balance microservices?  For instance, if I put console on the server that hosts my API gateway, can it be used  to monitor all microservices it has discovered and load balance if I have two of the same microservice?</p>&#xA;&#xA;<p>2) Can Consul be used at the microservice level to spin up instances as needed?  Essentially, I'd like to not use IIS and find an alternative.</p>&#xA;&#xA;<p>3) If for whatever reason Consul monitors a microservice as offline, can it attempt to start it up again?  Or force a shut down of a microservice for whatever reason?</p>&#xA;&#xA;<p>If Consul software can't solve these issues, is there other alternatives?</p>&#xA;&#xA;<p>Thank you.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/fmEQK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fmEQK.png"" alt=""Simple microservices architecture""></a></p>&#xA;"
42873668,Separation of concerns in Microservice Architecture,2017-03-18 11:18:23,<microservices><amazon-kinesis-firehose>,1,78,0,0.0,1,"<p>I have some microservices that are plugged on our eCommerce plataform. &#xA;Today, We have our microservices broken as:&#xA; - customer-service&#xA; - order-service&#xA; - delivery-service&#xA; - ...&#xA;For e.g., when a new customer join the eCommerce or someone place and order, it makes a webhook for one of our microservices that just get the information and dump to firehose/S3.</p>&#xA;&#xA;<p>My question is: Is it better to maintain the functions that dump data to firehose on separated micro services handling specific subjects (customer, order and so on) or create for example another micro service called ""notification-service"" that handle all of them?</p>&#xA;&#xA;<p>The other example could be: Each micro service send notification, like email or sms. Or is it better to have a separate micro service that has total responsibility of making notification?</p>&#xA;"
43058415,How to load React components inside a container app via AJAX,2017-03-28 00:00:16,<javascript><node.js><reactjs><webpack><microservices>,1,84,0,1.0,1,"<p>What are the best practices associated with loading/inserting React components in an existing React application via AJAX.</p>&#xA;&#xA;<p>I am considering having a ""container app"" that loads various React components via AJAX. How could this be done?</p>&#xA;&#xA;<p>How can this work with webpack?</p>&#xA;"
42899966,Scheduled Communication between two Resource MicroServices,2017-03-20 09:30:24,<java><security><spring-boot><authorization><microservices>,2,120,0,0.0,1,"<p>The scenario is I have two Resource Micro Services(Secured with Spring Security), let us assume A &amp; B.&#xA;A wants to collect data from B on a scheduled way for ex A will call the B's endpoint every hour to collect some data.&#xA;The catch is two resource services can communicate with each other if they have a valid access token or we can say a user logged in.&#xA;But scheduled jobs have to run continuously independent of having a logged in User. So what should be the correct way to call B from A.</p>&#xA;&#xA;<p>a. To have a configuration for a super default user to run scheduled jobs, authenticating implicitly?</p>&#xA;&#xA;<p>NOTE: The scheduled job is independent of user intervention.</p>&#xA;"
42922250,Docker reuse port in a consul TCP health check cycle,2017-03-21 08:52:24,<docker><tcp><microservices><consul><service-discovery>,1,182,0,0.0,1,"<p>Examples:</p>&#xA;&#xA;<p>moment 1:&#xA;Docker run container A that listen 32781(export port)->8000(service port)&#xA;Consul health check done pass by TCP connection(cycle 10s).</p>&#xA;&#xA;<p>moment 2:&#xA;Docker restart container A and run container B at close time(Less than 10s).&#xA;Now the port 32781 is container B (reuse port), the new container A got another port.</p>&#xA;&#xA;<p>But next cycle of consul health check, the port 32781 is ok, and the consul take for container A is ok.</p>&#xA;&#xA;<p>How to solve the issue?</p>&#xA;"
42918707,What are the disadvantages of using Kerberos authentication for secure micro-service to micro-service communication?,2017-03-21 04:53:18,<kerberos><microservices>,1,404,4,0.0,1,"<p>Sam Newman's ""Building Microservices"" book has described several methods that can be used to perform secure service to service communication. Such as</p>&#xA;&#xA;<ol>&#xA;<li>HTTPS Basic Authentication</li>&#xA;<li>Client Certificates</li>&#xA;<li>HMAC API Keys</li>&#xA;</ol>&#xA;&#xA;<p>I think Kerberos protocol can also be used for service to service authentication. But I found less references of using Kerberos protocol. Are there any disadvantages of using kerberos protocol in microservice architecture than other methods? </p>&#xA;"
51249515,Is Kestrel - IIS | Apache an ideal runtime host process over queue backed Windows services for microservices?,2018-07-09 15:51:49,<iis><.net-core><windows-services><microservices><soa>,1,24,0,0.0,1,"<p>Message durability concerns aside for the moment, I'm afraid that, under load, web server runtimes aren't designed for long running processes that could invoke a few remote providers or DB calls per transaction. If I have IIS or Apache proxying traffic to the Kestrel hosted .Net Core app, are resources shared better or more efficiently than classic IIS .Net apps? </p>&#xA;&#xA;<p>I'm wondering if I have to wait for a volume event to buckle our resource knees before we transition to queue backed services. </p>&#xA;"
51248930,Data Model Share in Administrations Micro Service,2018-07-09 15:21:17,<spring-boot><java-ee><web-applications><microservices>,1,29,0,0.0,1,"<p>Can any one please help to understand better.</p>&#xA;&#xA;<p>We are developing an application using Micro Service Architecture Now we have different structure.</p>&#xA;&#xA;<p>Based on the functionality we made different micro services.</p>&#xA;&#xA;<p>Now we are blocked with one point.</p>&#xA;&#xA;<p>Apart from different Actors we have ""administration"" or ""customer service"" users.</p>&#xA;&#xA;<p>From them , we have some specific APIS.</p>&#xA;&#xA;<p>We have a questions around this.</p>&#xA;&#xA;<pre><code>1) Do we need to consider creating different micro service project.&#xA;2) Assume we consider different micro services, do we need to share all the domain models to this micro service.&#xA;&#xA;3) Assume, we keep Admin or Customer Service APIS in respective Micro services, how good it is. my point is about exposing or potential to expose Admin API to the world.&#xA;</code></pre>&#xA;"
51250307,Remote dockerised spring boot application registration in Netflix eureka service discovery server on another host,2018-07-09 16:40:06,<docker><microservices><netflix-eureka><spring-cloud-netflix><netflix>,1,34,0,0.0,1,"<p>We hosted Netflix Eureka service discovery server and API gateway on one host machine, and have a dockerized spring boot service on another host machine When we register that service into Eureka service discovery server it takes containers IP address. So when we call that service as expected that service was not found. So whats the best practice while registering the remote docker service into service discovery server.</p>&#xA;"
51143213,"What are the ""real-world"" solutions for not duplicating data in microservices?",2018-07-02 20:19:15,<microservices><denormalization><consistency>,1,36,0,0.0,1,"<p>Suppose that I have a microservice for messaging. The microservice knows how to send emails. The service have templates of emails that have some sort of ""template engine"" like pugjs, and can replace data in the body of the message.</p>&#xA;&#xA;<p>I have an user service (used for authentication/authorization for example), and a bank account service (each user have one). Between the User microservice and Bank Account microservice it's clear that we don't have to duplicate any data than de user's uuid.</p>&#xA;&#xA;<p>But I want now to send every day a message to each user with their account statement. The Messaging microservice needs data from the User microservice and the Bank Account microservice.</p>&#xA;&#xA;<p>Okay... This is a <strong>small</strong> case of the real world. Now I know that to have the benefits of <strong>decoupled</strong> microservices I must follow some rules:</p>&#xA;&#xA;<ul>&#xA;<li>I can't share databases between microservices</li>&#xA;<li>I can't make synchronous requests between microservices</li>&#xA;</ul>&#xA;&#xA;<p>Okay... I can use a broker and each time a new user is created/updated the Messaging microservice can store that data. But really, this is a stupid thing:</p>&#xA;&#xA;<ul>&#xA;<li>I don't want to have inconsistency with this data, and keeping things sync is hard</li>&#xA;<li>The <strong>development time and complexity</strong> of the Messaging Microservice must now consider: listen and extract the relevant data from events, keep data consistent about other domains/services, managing the saved data on database</li>&#xA;<li>And think about a Messaging microservice. Really I must store all the data needed to parse the templates?</li>&#xA;</ul>&#xA;&#xA;<p><strong>I read a lot</strong> about microservices and people creating rules for their simple examples. But I never really saw a good explanation and real-world examples like above.</p>&#xA;&#xA;<p>So how to have the microservices above without data duplication?</p>&#xA;"
51170392,"How to correct model ""summaries"" in REST?",2018-07-04 09:32:23,<rest><microservices>,1,38,0,0.0,1,"<p>A microservice exposes a canonical REST API to deal with two resources: <code>teams</code> and <code>matches</code>, where a match is played by two teams and have a score. </p>&#xA;&#xA;<ol>&#xA;<li><code>post /team</code> will add a new team</li>&#xA;<li><code>get /teams</code> will get all the teams</li>&#xA;<li><code>get /team/{id}</code> will return a specific team</li>&#xA;</ol>&#xA;&#xA;<p>The same canonical implementation is provided for the <code>match</code> resource. Now, there are two clients applications of this microservice:</p>&#xA;&#xA;<ul>&#xA;<li>A public website which needs to display for each team the total number of matches, the total number of wins and total losses</li>&#xA;<li>A private website which needs to display the greatest loss and the player who received most red cards</li>&#xA;</ul>&#xA;&#xA;<p>Let's add the following constraints:</p>&#xA;&#xA;<ol>&#xA;<li>We don't want to return this summary information in the <code>team</code> resource because it might be computationally expensive</li>&#xA;<li>The two summaries have different permissioning: according to the header in the HTTP request we might accept / reject the request</li>&#xA;</ol>&#xA;&#xA;<p>What would be an appropriate way to design an API for this use case?</p>&#xA;&#xA;<ul>&#xA;<li><p>A single endpoint with a query parameter, which doesn't lead to explosion in the number of endpoints but return responses which are very different one from each other</p></li>&#xA;<li><p>Multiple endpoints (internal-summary, external-summary, scores-summary, faults-summary) </p></li>&#xA;</ul>&#xA;"
51304242,Avoid ambigous GetMapping in Spring boot Rest,2018-07-12 11:16:23,<java><spring-mvc><spring-boot><microservices><restful-url>,2,40,0,0.0,1,"<p>I have two GET Requests</p>&#xA;&#xA;<pre><code>@GetMapping&#xA;public List&lt;Limit&gt; getAllLimits(@RequestParam() Map&lt;String, String&gt; limitFilters) throws ApiException {&#xA;    if(CollectionUtils.isEmpty(limitFilters)) {&#xA;        return limitService.getAllLimits();&#xA;    }&#xA;    else {&#xA;        return limitService.getLimitBySearchFilters(limitFilters);&#xA;    }&#xA;}&#xA;&#xA;@GetMapping(params = { ""id"", ""asOfDate"" })&#xA;public Limit getLimitByid(@RequestParam Long id, @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) @RequestParam(value = ""asOfDate"", required = false) LocalDate asOfDate) throws EntityNotFoundException, ApiException {&#xA;    return limitService.getLimitById(id, asOfDate);&#xA;}&#xA;&#xA;@GetMapping({""/{pid}""})&#xA;public Limit getLimitByPid(@PathVariable Long pid) throws EntityNotFoundException, ApiException {&#xA;    return limitService.getLimitByPid(pid);&#xA;}&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li><a href=""http://localhost:8080/limit"" rel=""nofollow noreferrer"">http://localhost:8080/limit</a> url goes to getAllLimits(@RequestParam() Map limitFilters) - this is correct</li>&#xA;<li><a href=""http://localhost:8080/limit/1"" rel=""nofollow noreferrer"">http://localhost:8080/limit/1</a> goes to getLimitByPid() - this is correct</li>&#xA;<li><a href=""http://localhost:8080/limit?id=1&amp;asOfDate=2018-07-12"" rel=""nofollow noreferrer"">http://localhost:8080/limit?id=1&amp;asOfDate=2018-07-12</a> goes to getLimitByid - this is correct</li>&#xA;</ul>&#xA;&#xA;<p>However, please note that <code>asOfDate</code> is optional&#xA;So, <code>http://localhost:8080/limit?id=1</code> goes to <code>getAllLimits(@RequestParam() Map&lt;String, String&gt; limitFilters)</code> whereas I want it to route to <code>getLimitByid()</code> method</p>&#xA;&#xA;<p>How can I achive this? Any help would be highly appreciated</p>&#xA;"
51153850,NServiceBus: is this an illusion or a best practice?,2018-07-03 11:47:15,<microservices><nservicebus>,1,45,0,0.0,1,"<p>Given an NServiceBus microservice that uses MSMQ, When I deploy few instances of that service into the same machine, Am I scaling out my application?, Am I improving the performance? or one instance is enough. shall I instead have a more powerful machine to handle messages?</p>&#xA;"
51242037,Hibernate Join table in microservice architecture,2018-07-09 09:18:52,<java><sql><hibernate><microservices><hibernate-mapping>,2,112,0,0.0,1,"<p>I have two micro-services, one is user service and other is product service, both has its own database</p>&#xA;&#xA;<p>Product service db tables</p>&#xA;&#xA;<pre>&#xA;user_products (id, user_id, product_id)&#xA;products (id, name)&#xA;</pre>&#xA;&#xA;<p>User service db tables</p>&#xA;&#xA;<pre><code>User(id, name, ..)&#xA;</code></pre>&#xA;&#xA;<p>User and and product have many to many relation. Since user_products is join table which is only present in product service. I am not sure how to create hibernate model objects for product service tables, so that I can get:</p>&#xA;&#xA;<ol>&#xA;<li>list of all products which belongs to particular user</li>&#xA;<li>list of all owners of product</li>&#xA;</ol>&#xA;&#xA;<p>Not sure how to define @ManyToMany relationship with just above two tables</p>&#xA;"
51317424,Microservices: What is the ESHOP_OCELOT_VOLUME_SPEC line mean in docker.compose file,2018-07-13 03:55:51,<docker><docker-compose><microservices>,2,25,1,1.0,1,"<p>I am looking at the code in eShopOnContainer under the docker-compose.override.yml. I can see a line in</p>&#xA;&#xA;<blockquote>&#xA;  <p>volumes:&#xA;        - ./src/ApiGateways/Web.Bff.Shopping/apigw:${ESHOP_OCELOT_VOLUME_SPEC:-/app/configuration}</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>webshoppingapigw:&#xA;    environment:&#xA;      - ASPNETCORE_ENVIRONMENT=Development&#xA;      - IdentityUrl=http://identity.api              #Local: You need to open your local dev-machine firewall at range 5100-5110.&#xA;    ports:&#xA;      - ""5202:80""   &#xA;    volumes:&#xA;      - ./src/ApiGateways/Web.Bff.Shopping/apigw:${ESHOP_OCELOT_VOLUME_SPEC:-/app/configuration}&#xA;</code></pre>&#xA;&#xA;<p>What does the line in the volumes ${ESHOP_OCELOT_VOLUME_SPEC .. is? I would think it will create a volumes of something but the ${ESHOP_OCELOT_VOLUME_SPEC â€¦ I can't see where it define in the project even not inside the .env file.</p>&#xA;&#xA;<p>When I went inside the docker-compose.override.prod, the line ${ESHOP_OCELOT_VOLUME not even there. </p>&#xA;&#xA;<p>Currently I have exception running the sample code, therefore I tried to do follow the code from eShopOnContainer but code a simple version so I can easily to follow. I start doing the ApiGateway and building up from there. </p>&#xA;&#xA;<p>I don't know is this question eligible to be asked. People here very fuzzy of the question. </p>&#xA;"
51312346,Mixing Communication Methods in Microservices,2018-07-12 18:33:13,<architecture><microservices>,1,64,2,1.0,1,"<p>So I'm struggling with a few concepts regarding microservices and communication between then. While I'm not expecting a tech specific answer I am working with <strong>asp.net core web api</strong> if that helps to answer my question.</p>&#xA;&#xA;<p><strong>Scenario</strong></p>&#xA;&#xA;<p>My resource is a widget. This widget can be updated in one of two ways:</p>&#xA;&#xA;<ol>&#xA;<li>By the user through the UI</li>&#xA;<li>Through external event (message published to a bus)</li>&#xA;</ol>&#xA;&#xA;<p><strong>Assumptions</strong></p>&#xA;&#xA;<p>Based on various articles, blogs, etc I'm also working under following assumptions:</p>&#xA;&#xA;<ol>&#xA;<li>Microservices should own their data. So in this case, I should only have one microservice that owns the widget resource</li>&#xA;<li>The direct update by the user represents a request/response communication so REST is recommended</li>&#xA;<li>The event message suggests that I should also be connecting to a queue and processing messages from the bus</li>&#xA;<li>Message consumers are better run as a service than inside something like a web project hosted in IIS</li>&#xA;</ol>&#xA;&#xA;<p><strong>Question(s)</strong></p>&#xA;&#xA;<p>So based on everything mentioned I thought about creating an ASP.NET Core project that runs as a windows service. I know there are some recent changes in .net core 2.1 that make this even easier. </p>&#xA;&#xA;<p>This is in contrast to just creating 2 services one to handle the rest calls and one to consume the bus messages which seems to go against my first assumption as well as just being more difficult to maintain in the long run.</p>&#xA;&#xA;<p>So my questions are </p>&#xA;&#xA;<ol>&#xA;<li>Are my assumptions valid?</li>&#xA;<li>Is mixing communication methods within the service like this a good idea or should I create the two services (one for each communication type)?</li>&#xA;<li>Is there another way to approach this that is more in line with the ideology behind Microservices?</li>&#xA;<li>If I were to do this in node, would the approach be similar as far as having node handle both messages from a bus as well as incoming REST calls?</li>&#xA;</ol>&#xA;"
51282761,Microservices Scalable Deployment,2018-07-11 10:09:21,<spring-boot><google-cloud-platform><microservices><google-kubernetes-engine>,1,49,3,0.0,1,"<p>I have recently developed REST API. My project is developed with microservices using SpringBoot. I have used Zuul API Gateway and Eureka Discovery server in the project. I deployed it on a google kubernetes cluster. When I do a load test for the Rest API calls it shows me, it can handle only a few requests per second. &#xA;What I need to know is, how to autoscale the kubernetes pods for my services. What parameter should I look into? Ram usage or CPU usage or any other ???</p>&#xA;"
36479452,Solve dependencies on docker-compose,2016-04-07 14:37:15,<java><docker-compose><spring-cloud><microservices><spring-cloud-config>,1,401,0,0.0,1,"<p>I have a Spring boot microservice connecting to a Spring configuration service to get the config, but apparently, the service cannot start after the config server it's completely up and running, otherwise it will never be able to connect again (?)</p>&#xA;&#xA;<p>Here's the error I see in the service's console when I run the docker-compose file: </p>&#xA;&#xA;<blockquote>&#xA;  <p>2016-04-07 14:25:51.305  WARN 1 --- [           main]&#xA;  c.c.c.ConfigServicePropertySourceLocator : Could not locate&#xA;  PropertySource: I/O error on GET request for&#xA;  ""<a href=""http://configserver:8888/myservice/default"" rel=""nofollow"">http://configserver:8888/myservice/default</a>"": Connection refused;&#xA;  nested exception is java.net.ConnectException: Connection refused</p>&#xA;</blockquote>&#xA;&#xA;<p>Here's my docker-compose file: </p>&#xA;&#xA;<pre><code>discovery:&#xA;  image:discovery-service&#xA;  ports:&#xA;   - ""8761:8761""&#xA;configserver:&#xA;  image:config-service&#xA;  ports:&#xA;   - ""8888:8888""&#xA;  links:&#xA;   - discovery&#xA;myservice:&#xA;  image:my-service&#xA;  ports:&#xA;   - ""9006:9006""&#xA;  links:&#xA;   - discovery&#xA;   - configserver&#xA;</code></pre>&#xA;&#xA;<p>And this is the service bootstrap.yml config:</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: myservice&#xA;  cloud:&#xA;    enabled: true&#xA;    config:&#xA;      uri: http://configserver:8888&#xA;encrypt:&#xA;  failOnError: false&#xA;</code></pre>&#xA;&#xA;<p>Once both services are running and registered on Eureka (discovery), I try to call <code>/refresh</code> on <code>myservice</code> but it keeps failing and returning the same error.</p>&#xA;&#xA;<p>If I restart the docker instance it connects without issues.</p>&#xA;&#xA;<p>Does that mean I have to keep the config server running continuously to be able to do that? </p>&#xA;"
33291874,"Microservices: Worker roles, APIs or both?",2015-10-22 22:32:19,<microservices>,1,976,1,0.0,1,"<p>I have seen mixed examples of Microservices implemented as worker roles processing requests off a queue and/or as APIs (REST). </p>&#xA;&#xA;<p>Supporting asynchronous scenarios, a queue can be utilized, with a simple dumb queue listener forwarding the request to a Microservice REST API, where as synchronous scenarios would  call the REST API directly. </p>&#xA;&#xA;<p>The term Microservice is vaguely defined I think; do people consider them APIs (e.g. RESTful services) or as any abstract service processing requests, however that request was provided ?</p>&#xA;"
33287495,Netflix OSS/ Spring cloud on Weblogic,2015-10-22 17:55:36,<oracle><weblogic><spring-cloud><microservices><netflix>,1,1177,3,0.0,1,"<p>We do currently have an infrastructure with Weblogic 11g, Java 6, Apache WL plugin and ZXTM. Our traffic flows as follows:</p>&#xA;&#xA;<pre><code>ZXTM &gt;&gt; Apache httpd (WL plugin) &gt;&gt; WL cluster &gt;&gt; Oracle DB (RAC)&#xA;</code></pre>&#xA;&#xA;<p>We want to start microservices and evaluating Netflix OSS/ Spring cloud. Are there any complexities having spring netflix cloud on Weblogic with the infrastructure explained above? Following are our findings.</p>&#xA;&#xA;<ol>&#xA;<li>Turbine needs Java 8, so we have to upgrade to Java 8.</li>&#xA;<li>WL 11g does not support Java 8, so WL needs be upgraded to 12.1.3.</li>&#xA;</ol>&#xA;&#xA;<p>And we are fine with above upgardes.</p>&#xA;&#xA;<ol>&#xA;<li>Along with WL upgrade, is orcale DB (currently 11g) upgrade required?</li>&#xA;<li>Any issues/ complexities with running Netflix cloud on Weblogic 12c?</li>&#xA;<li>Does WL 12c supports JDBC 4.1 and 4.2 and any dependency for Netflix OSS products on these JDBC versions?</li>&#xA;<li>How can Eureka and Ribbon be used along with WL cluster load balancing?</li>&#xA;<li>Is Apache WL plugin required anymore? at-least for session stikiness?</li>&#xA;</ol>&#xA;&#xA;<p>Appreciate if you could share your experience, thoughts.&#xA;(Doesn't matter if you do not answer all the queries above, please share what you know of :) )</p>&#xA;"
33335786,What is the best way for applications to communicate in micro-service architectures,2015-10-25 22:23:36,<python><json><xml-rpc><microservices><amp>,1,273,6,0.0,1,"<p>I have to design and implement a service delivery platform.  I have various services in my current design and all of those tools are using different technologies.  Some are erlang based concurrent map-reduce functions and some are simple bash scripts to aggregate some text files. </p>&#xA;&#xA;<p>I heared about <strong>XML/RPC</strong>, <strong>Protocol Buffer</strong>, <strong>message-pack</strong>, <strong>soup</strong> and <strong>AMQP</strong>.  currently I use <strong>JSON</strong>, but loading and dumping large json files are a bit time/memory consuming.  Is there any new or robust way to make a bridge between various technologies on HTTP infrastructure with wide range programming language support and well documentation?</p>&#xA;&#xA;<p>EDIT1: I also need to mention that i believe complexity is much more corrosive than latency problems or other connection related issues.  So the JSON replacement must not add complexity to design.  </p>&#xA;&#xA;<p>Thanks in advanced.</p>&#xA;"
38435582,Share code dependencies between micro services in nodejs,2016-07-18 11:29:17,<node.js><microservices>,1,188,0,0.0,1,"<p>I'm designing a platform that use 3 micro services; a <em>socket server</em>, a <em>front end server</em> running expressjs and a <em>email server</em> to send transaccional emails.</p>&#xA;&#xA;<p>The project file strutture is very simple:</p>&#xA;&#xA;<pre><code>project_root&#xA; |______________ socket&#xA; |______________ frontend&#xA; |______________ email&#xA;</code></pre>&#xA;&#xA;<p>Inside each folder there is a nodejs project. To comunicate with each other these micro services use a simple <a href=""http://redis.io/topics/pubsub"" rel=""nofollow"">Redis pub/sub implementation</a>. The thing is, inside each <em>node_modules</em> folder there is going to be an NPM package duplicate for the Redis dependency. So there is duplicated code and if I want update the package I'll have to do it 3 times.</p>&#xA;&#xA;<p>Am I using an incorrect approach? </p>&#xA;"
38460678,Architecture Microservices Jhipster,2016-07-19 13:57:51,<java><jwt><jhipster><microservices>,1,1781,0,0.0,1,"<p>I want to start an architecture with microservices of Jhipster but I have doubts.&#xA;I have 4 pieces.</p>&#xA;&#xA;<ul>&#xA;<li>""HR"" &lt;- front and backend application</li>&#xA;<li>""SELECTION"" &lt;- front and backend application</li>&#xA;<li>Validation &lt;- Only one database for all front</li>&#xA;<li>Customers &lt;- is shared between ""HR"" and ""SELECT"" back in front in microservice and ""HR"" and ""SELECT"".</li>&#xA;</ul>&#xA;&#xA;<p>Both applications must be validated against the same database (JWT).&#xA;Both applications must share a microservicio ""CUSTOMER"" which will have the backend, but the front will be in each of the two applications.</p>&#xA;&#xA;<ul>&#xA;<li>1 - ""HR"" It would be a gateway?</li>&#xA;<li>2 - ""SELECTION"" It would be a gateway?</li>&#xA;<li>3 - How to implement security that is both against the same database (JWT) validated</li>&#xA;<li>4 - ""CUSTOMER"" It would be a microservicio?</li>&#xA;</ul>&#xA;&#xA;<p>Sorry for my English.</p>&#xA;"
40010594,Consul deregister 'failing' services,2016-10-13 00:51:04,<microservices><mesos><mesosphere><consul><consul-template>,2,836,0,0.0,1,<p>I have consul running on Consul v0.5.2 version &amp; services running in Mesos. Services keep moving from 1 server to another.</p>&#xA;&#xA;<p>Is there way to deregister services in consul that are in 'failing' state? I am able to get the list of services in failing state using this curl</p>&#xA;&#xA;<pre><code>curl http://localhost:8500/v1/health/state/critical&#xA;</code></pre>&#xA;&#xA;<p>Issue that we are seeing is over a period of time in consul UI we have stale data &amp; making the whole UI unusable</p>&#xA;
39981115,Interfaces for microservice boundaries - how to import code?,2016-10-11 15:34:13,<git><haskell><rabbitmq><protocol-buffers><microservices>,1,71,0,0.0,1,"<p>I'm building some small services in Haskell. I'd like to make the boundary between services formal, such that the build process will tell the developer if the contract has been violated</p>&#xA;&#xA;<p>For a simple example, say we have an API with a route POST /users. It's supposed to add the user to the users queue. Then we have one worker, which reads from the queue and processes the new user. </p>&#xA;&#xA;<p>The contract between the two looks like:</p>&#xA;&#xA;<ol>&#xA;<li>The exchange is named ""exchange""</li>&#xA;<li>The queue is named ""users""</li>&#xA;<li>Messages should be user objects serialized to JSON (or msgpack, or protobuf)</li>&#xA;<li>users are: <code>{ name : String, age : Int }</code></li>&#xA;</ol>&#xA;&#xA;<p>How can I enforce this so that I get build errors if either service:</p>&#xA;&#xA;<ol>&#xA;<li>Connects to the wrong queue or exchange</li>&#xA;<li>Uses an incorrect schema for User</li>&#xA;</ol>&#xA;&#xA;<p>This would be easy if all the code were in one repository, but one of the main goals of microservices as I understand them is to make them independent. How could it be done with separate repos? </p>&#xA;&#xA;<p>I had the idea to create a 3rd repo for the contract, and have both services depend on it. If it contained some Haskell types, the API and the worker could both include it and typecheck their implementations against it. If I do this, how should I handle versioning? Should they include it as a git submodule, or through the package manager (which would allow depending on old versions, which might be bad)?</p>&#xA;&#xA;<p>If I wanted to update the schema of User, how would I architect things so that I then get errors in the two services until they are updated?</p>&#xA;&#xA;<p>For folks who use protobuf, where do you store those files in relation to the two services? Can protobuf surface errors in the implementations? </p>&#xA;"
39888380,"Spring Boot Microservice: dynamic role, permission based security",2016-10-06 05:47:33,<java><spring><spring-security><spring-boot><microservices>,1,1120,0,0.0,1,"<p>We have created application using Spring Boot Microservices,&#xA;application contains jsp pages and rest uri.</p>&#xA;&#xA;<p>For this type of architecture expect suggestions to secure pages and uri.&#xA;I want role and permission based access, where permission contains all pages and uri listed and role_permission_mapping has mapping of uri/pages against role.</p>&#xA;&#xA;<p>Admin have rights to add Role, Permission and Mapping dynamically using some UI. </p>&#xA;&#xA;<p>Image below shows sample table structure.</p>&#xA;&#xA;<p>Suggest me if we have built-in mechanism which provides out of box support for this type of requirement.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eBgNL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBgNL.png"" alt=""enter image description here""></a></p>&#xA;"
39956391,How can I use gradle submodule as a library in another modules?,2016-10-10 10:39:36,<java><spring><gradle><microservices>,1,233,0,0.0,1,"<p>I try to write my project with four microservices, where every service need to have opportunity to call any another.</p>&#xA;&#xA;<p>Thus I need a some client module, wich will be able to call any service. And I want to use this module as a library in my services.</p>&#xA;&#xA;<p>How can I do this?</p>&#xA;"
40034001,Can microservices be used to display a regular page?,2016-10-14 02:31:37,<c#><asp.net-mvc><microservices>,1,145,1,0.0,1,<p>I have been researching microservices and noticed that each author discourages use of monolithic architecture when its large. They say in enterprise environments microservices are highly advisable. My question is what about displaying normal data such as this stackoverflow question that you're reading. How would this page load in a microservice environment? The request would need to be queued then another microservice would need to fetch and return the data. When the request is queued the request context is lost - the page will return when the data is queued. How will the system display the data to the page when the request has already returned to the browser?</p>&#xA;&#xA;<p>The only way I can see this working is the browser would need to poll a web api for the new data.</p>&#xA;
39936184,Polyglot frontend in microservices,2016-10-08 18:58:16,<frontend><microservices><ssi><esi>,1,160,1,0.0,1,"<p>I'm new to microservices. In my project we're trying to break a monolith application into smaller microservices. &#xA;It is fairly easy to implement backend systems with polyglot technology. Is the same achievable for frontend?&#xA;BFF (backend for frontend) seems to be a popular pattern to implement frontend in microservices. However, doesn't it result in frontend monoliths? Maybe my understanding of BFF is partial/incorrect.&#xA;There are few options such as SSI (server side includes) &amp; ESI (Edge side includes) that could help in achieving polyglot in frontend.&#xA;But wasn't portlet technology trying to achieve something similar in early 2000's?&#xA;ESI is in trial stage at thoughtworks technology radar (<a href=""https://www.thoughtworks.com/radar/techniques/edge-side-includes-for-page-composition"" rel=""nofollow"">link</a>). &#xA;Do you think this is the right direction. Any advice will be appreciated.</p>&#xA;"
39998701,throw new TypeError('app.use() requires middleware functions');,2016-10-12 12:31:23,<javascript><node.js><express><microservices><seneca>,1,302,5,0.0,1,"<p>I'm just trying to run sample codes from Developing Microservices with Node js, and it says:</p>&#xA;&#xA;<pre><code>var express = require('express')&#xA;var bodyParser = require('body-parser')&#xA;var cookieParser = require('cookie-parser')&#xA;var methodOverride = require('method-override')&#xA;var seneca = require('seneca')()&#xA;var argv = require('optimist').argv&#xA;var app = express()&#xA;var cors = require('cors')&#xA;var routes = require('./../routes/index')&#xA;let path = require('path')&#xA;var webpack = require('webpack')&#xA;var webpackMiddleware = require('webpack-dev-middleware')&#xA;var config = require('./../webpack.config.js')&#xA;&#xA;var compiler = webpack(config)&#xA;&#xA;var conf = {&#xA;   port: argv.p || 7770&#xA;}&#xA;&#xA;app.engine('jsx', require('express-react-views').createEngine())&#xA;app.set('port', conf.port)&#xA;app.use(cors())&#xA;app.use('/public', express.static(path.join(__dirname,'./../public')))&#xA;app.use('/views', express.static(path.join(__dirname, './../views')))&#xA;app.use(webpackMiddleware(compiler));&#xA;app.use(cookieParser())&#xA;app.use(express.query())&#xA;app.use(bodyParser.urlencoded({extended: true}))&#xA;app.use(methodOverride())&#xA;app.use(bodyParser.json())&#xA;app.use(express.static('public'))&#xA;app.use(seneca.export('web'))  // Error line&#xA;&#xA;seneca.use('./../lib/registerAPI')&#xA;&#xA;app.use('/', routes)&#xA;&#xA;module.exports = app&#xA;</code></pre>&#xA;&#xA;<p>but Im getting an error that says:</p>&#xA;&#xA;<pre><code>/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177&#xA;     throw new TypeError('app.use() requires middleware functions');&#xA;     ^&#xA;TypeError: app.use() requires middleware functions &#xA;     at EventEmitter.use (/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177:11)&#xA;     at Object.&lt;anonymous&gt; (/home/quocdinh/workspace/ECommerce/ass-ECommerce/src/app.js:33:5) // --&gt; line: app.use(seneca.export('web'))&#xA;</code></pre>&#xA;&#xA;<p>I have tried to find solutions but ineffective.</p>&#xA;&#xA;<p>I tried adding</p>&#xA;&#xA;<pre><code> app.use(require('seneca-web'))&#xA;</code></pre>&#xA;&#xA;<p>but still not be</p>&#xA;&#xA;<p>I tried to lower the version of the node version that I have to 4.0 from 6.0, but still got the same error</p>&#xA;"
29831699,How do I share the URL of my application with another application in Bluemix?,2015-04-23 18:36:16,<ibm-cloud><microservices>,2,319,0,0.0,1,"<p>I have two applications on Bluemix and I need to give the URL of one application to the other one. </p>&#xA;&#xA;<pre><code>$response = http_get(""myOrdersApp12345.mybluemix.net/api"");&#xA;</code></pre>&#xA;&#xA;<p>Hard coding the URL in my source code seems like a bad idea... What if the url changes?</p>&#xA;"
44346827,Responsabilities in API gateway or specific service,2017-06-03 17:37:26,<architecture><microservices><separation-of-concerns>,1,31,0,0.0,1,"<p>I have a problem dividing responsibilities among services.</p>&#xA;&#xA;<h1>Example scenario</h1>&#xA;&#xA;<p>Imagine we have following reduced number of services, communicating each other via RabbitMQ:</p>&#xA;&#xA;<ul>&#xA;<li><strong>API service</strong>. A single HTTP entry point for all business logic.</li>&#xA;<li><strong>Users service</strong>. Which handles the users logic.</li>&#xA;</ul>&#xA;&#xA;<p>To implement the user creation feature: should I enforce the business restrictions in the API or in the users service?</p>&#xA;&#xA;<p>For example, if only admins can create users with ""isAdmin"" property set up as true, the following options comes to my mind:</p>&#xA;&#xA;<h1>Tentative solutions</h1>&#xA;&#xA;<h2>Checks in API service</h2>&#xA;&#xA;<p>API service checks if the user is authorized and if it is, send the operation to users service. operation to users service. </p>&#xA;&#xA;<p><strong>Advantages</strong>: Users service is more flexible. If other service want to create users in the future is not restrained to perform anything it wants (for example, create users without a ""creator user""). Data is also validated early.</p>&#xA;&#xA;<p><strong>Disadvantages</strong>: If the business logic is too common I have to duplicate the checks in multiple points. I have the business logic of Users split </p>&#xA;&#xA;<h2>Checks in Users service</h2>&#xA;&#xA;<p>Users service checks the authorization and returns an error to API. API pass that error to client.</p>&#xA;&#xA;<p>Do any good practice exists? Have you faced this dilemma before? How it worked?</p>&#xA;"
44416904,Use KONG as API Gateway to GraphQL/REST services,2017-06-07 15:27:36,<microservices><graphql><kong>,2,1594,0,0.0,1,<p>I'm trying to understand if it's possible to use KONG as API Gateway to microservices implementing REST and/or GraphQL interfaces</p>&#xA;&#xA;<p>As API Gateway will expose a GraphQL API and will request to our microservices currently implemented in REST/GraphQL and grpc coming soon.</p>&#xA;
44350408,Can't start jHipster microservice gateway out of box,2017-06-04 03:05:46,<tomcat><jhipster><microservices>,1,229,0,0.0,1,"<p>So I've built a jHipster microservices gateway out of the box. I have jHipster 4.5.2. I have done nothing to it beyond answering the setup questions (you can see my answers below). I assigned it to run on localhost:8082. I also have installed Tomcat 8.5.15, which works; when I turn it on I see the server page at localhost:8080.</p>&#xA;&#xA;<p>I have tried to run the gateway by doing the following:</p>&#xA;&#xA;<pre><code>/Users/jimstewart/apache-maven-3.3.9/bin/mvn -Pprod package&#xA;java -jar target/data-gateway-0.0.1-SNAPSHOT.war&#xA;</code></pre>&#xA;&#xA;<p>When it tries to start up I get the following warning early on:</p>&#xA;&#xA;<pre><code>Could not locate PropertySource: I/O error on GET request for ""http://localhost:8761/config/DataGateway/dev/master"": Connection refused; nested exception is java.net.ConnectExc&#xA;</code></pre>&#xA;&#xA;<p>But the Tomcat server is running: when I go to localhost:8080 the page is there. </p>&#xA;&#xA;<p>There is a ton of boilerplate, hundreds of lines, so I won't copy them all. But in the following errors keep repeating</p>&#xA;&#xA;<pre><code>2017-06-03 22:48:58.671 ERROR 1271 --- [           main] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error&#xA;&#xA;2017-06-03 22:48:58.674  WARN 1271 --- [           main] &#xA;c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with &#xA;message: java.net.ConnectException: Connection refused&#xA;&#xA;2017-06-03 22:48:58.675 ERROR 1271 --- [           main] &#xA;com.netflix.discovery.DiscoveryClient    : &#xA;DiscoveryClient_DATAGATEWAY/DataGateway:5ee0c99cb98fec0674d7db2672260892 - was &#xA;unable to refresh its cache! status = Cannot execute request on any known server&#xA;&#xA;2017-06-03 22:49:17.689  WARN 1271 --- [nfoReplicator-0] &#xA;c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: java.net.ConnectException: Connection refused&#xA;</code></pre>&#xA;&#xA;<p>Eventually it just shuts down without starting. </p>&#xA;&#xA;<p>I've also tried to start it by running it from NetBeans. When I have Tomcat turned on, it quits because ""Failed to start Tomcat: port 8080 is already in use."" So, fine, start it with Tomcat turned off so it can turn it on itself. Then it won't start because ""connection refused."" </p>&#xA;&#xA;<p>How can I get my app to start?</p>&#xA;&#xA;<p>I answered the setup questions the following way:</p>&#xA;&#xA;<pre><code>What kind of application? Gateway application&#xA;What is the base name? DataGateway&#xA;Would you like to install other generators? No&#xA;Which port do you want to run it on? 8082&#xA;What is your default package name? com.kidslearntocode.datagateway&#xA;Do you want to use the jHipster registry? Yes&#xA;What kind of authentication? JWT&#xA;What type of database? SQL&#xA;What production database? mySQL&#xA;What development database? mySQL&#xA;Maven or Gradle? Maven&#xA;Which other technologies? None&#xA;Which framework? [beta] Angular 4&#xA;LibSass? Yes&#xA;Internationalization? No&#xA;Other languages? None&#xA;</code></pre>&#xA;"
44301997,"Spring netflix eureka, zuul vs Spring cloud data flow",2017-06-01 08:10:23,<spring><microservices><spring-cloud-netflix><spring-cloud-stream>,2,1527,0,2.0,1,"<p>I am new to the microservice world. Would like to know when to use Spring eureka, zuul vs spring data flow. </p>&#xA;&#xA;<p>I am building a service which in turns will consume multiple granular services(aka micro service), aggregate all the data and returns aggregated data to the consumer. All the services will run in local intranet within company infrastructure. Also, I would like to load balance individual microservices.</p>&#xA;&#xA;<p>What should be the choice of technology for microservices deployment?</p>&#xA;&#xA;<p>I am using Spring 4.3, Spring boot, Rest, Spring data.</p>&#xA;"
44360649,Validate Command in CQRS that related to other domain,2017-06-05 01:47:28,<validation><domain-driven-design><microservices><cqrs>,2,551,2,1.0,1,"<p>I am learning to develop microservices using DDD, CQRS, and ES. It is HTTP RESTful service. The microservices is about online shop. There are several domains like products, orders, suppliers, customers, and so on. The domains built in separate services. How to do the validation if the command payload relates to other domains? </p>&#xA;&#xA;<p>For example, here is the addOrderItemCommand payload in the order service (command-side).</p>&#xA;&#xA;<pre><code>{&#xA;""customerId"": ""CUST111"", &#xA;""productId"": ""SKU222"",&#xA;""orderId"":""SO333""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How to validate the command above? How to know that the customer is really exists in database (query-side customer service) and still active? How to know that the product is exists in database and the status of the product is published? How to know whether the customer eligible to get the promo price from the related product?</p>&#xA;&#xA;<p>Is it ok to call API directly (like point-to-point / ajax / request promise) to validate this payload in order command-side service? But I think, the performance will get worse if the API called directly just for validation. Because, we have developed an event processor outside the command-service that listen from the event and apply the event to the materalized view.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
44395806,Communication between microservices for large data,2017-06-06 16:59:51,<java><spring-integration><spring-cloud><microservices><spring-cloud-stream>,1,414,2,0.0,1,"<p>I am building a spring cloud-based microservice ML pipeline.&#xA;I have a data ingestion service that (currently) takes in data from SQL, this data needs to be used by the prediction service.</p>&#xA;&#xA;<p>The general consensus is that writes should use async message-based communication using kafka/rabbitmq.</p>&#xA;&#xA;<p>What I am not sure about is how do I orchestrate these services?</p>&#xA;&#xA;<p>Should I use an API gateway that invokes ingestion that starts the pipeline?</p>&#xA;"
44313956,Microservices: model sharing between bounded contexts,2017-06-01 17:42:16,<mean-stack><microservices><bounded-contexts>,2,217,4,2.0,1,"<p>I am currently building a microservices-based application developed with the mean stack and am running into several situations where I need to share models between bounded contexts.  </p>&#xA;&#xA;<p>As an example, I have a User service that handles the registration process as well as login(generate jwt), logout, etc.  I also have an File service which handles the uploading of profile pics and other images the user happens to upload.  Additionally, I have an Friends service that keeps track of the associations between members.  </p>&#xA;&#xA;<p>Currently, I am adding the guid of the user from the user table used by the User service as well as the first, middle and last name fields to the File table and the Friend table.  This way I can query for these fields whenever I need them in the other services(Friend and File) without needing to make any rest calls to get the information every time it is queried.  </p>&#xA;&#xA;<p>Here is the caveat: </p>&#xA;&#xA;<p>The downside seems to be that I have to, I chose seneca with rabbitmq, notify the File and Friend tables whenever a user updates their information from the User table.  </p>&#xA;&#xA;<p>1) Should I be worried about the services getting too chatty?</p>&#xA;&#xA;<p>2) Could this lead to any performance issues, if alot of updates take place over an hour, let's say?</p>&#xA;&#xA;<p>3) in trying to isolate boundaries, I just am not seeing another way of pulling this off.  What is the recommended approach to solving this issue and am I on the right track?</p>&#xA;"
38698109,Adding a Microservice to WSO2 Identity Server as a component,2016-08-01 11:49:18,<wso2is><wso2carbon><microservices><msf4j>,1,73,0,0.0,1,"<p>I have microservice running independently doing some stuff by talking separately to WSO2 Identity Server. Now I want to add this microservice to Identity server or kind of extending Identity Server to include the capabilities of the microservice so that just starting the WSO2 Identity Server will take care of all my requirements. The microservice was created using msf4j and created as a OSGI bundle following the below link.</p>&#xA;&#xA;<p><a href=""https://docs.wso2.com/display/MSF4J200/Creating+a+Microservice+as+an+OSGi+Bundle"" rel=""nofollow"">https://docs.wso2.com/display/MSF4J200/Creating+a+Microservice+as+an+OSGi+Bundle</a></p>&#xA;&#xA;<p>After creating the bundle, I placed it in the 'repository/components/dropins' folder of the WSO2 Identity Server following the below link.</p>&#xA;&#xA;<p><a href=""https://docs.wso2.com/display/Carbon447/Config+Files+for+Third+Party+JARs"" rel=""nofollow"">https://docs.wso2.com/display/Carbon447/Config+Files+for+Third+Party+JARs</a></p>&#xA;&#xA;<p>After placing the bundle, started the Identity Server in '-DosgiConsole' mode hoping that everything will work fine. But typing 'ss <em>bundle_name</em>' dint return nothing in the console.</p>&#xA;&#xA;<p>Also the microservice independently ran on 8080 through msf4j. If what I am doing is meaningful and assume somehow I achieved it, at what port the service will run? How will I access the exposed resources?</p>&#xA;&#xA;<p>Any help would be greatly appreciated. </p>&#xA;"
38790603,Microservices resources discovery,2016-08-05 13:32:22,<microservices>,1,136,0,0.0,1,"<p>There are lots of articles discussing the importance of maintaining a central registry in a system based on microservices, with different strategies for registering and perform discovery. However, all the articles are centered around discovering other microservices.</p>&#xA;&#xA;<p>When a microservice requires access to a resource available on the network (ex. a database), should the service retrieve the database location from the registry?  </p>&#xA;&#xA;<p>If yes, in the database example only the <a href=""http://microservices.io/patterns/client-side-discovery.html"" rel=""nofollow"">client discovery pattern</a> makes sense to me, because it's necessary to create a connection pool.</p>&#xA;&#xA;<p>Any thoughts about this?</p>&#xA;&#xA;<p>EDIT: In the example above, the database is part of the microservice.</p>&#xA;"
38889466,How to run multiple Spring Boot application sharing same context?,2016-08-11 07:04:23,<spring><spring-security><spring-boot><microservices>,2,1676,0,1.0,1,"<p>I want to run multiple micro-services app sharing same context so that I can run my custom security filter for multiple spring boot(micro-services) app.</p>&#xA;&#xA;<p>Example: </p>&#xA;&#xA;<p>User services : <a href=""https://ip:port/myapp/user"">https://ip:port/myapp/user</a></p>&#xA;&#xA;<p>Product services : <a href=""https://ip:port/myapp/product"">https://ip:port/myapp/product</a></p>&#xA;&#xA;<p>Comment services : <a href=""https://ip:port/myapp/comment"">https://ip:port/myapp/comment</a></p>&#xA;&#xA;<p>And I should run  a common filter(Custom Security Filter) for all micro-services.</p>&#xA;"
38711908,How many database in a Microservices Event Driven architecture?,2016-08-02 04:42:50,<cqrs><microservices><event-sourcing><eventsource>,3,1161,4,1.0,1,"<p>I've read tons of documentation, blog posts and examples about CQRS with EventSource as a useful architecture in a Microservice system.</p>&#xA;&#xA;<p>A popular example is the banking transfer app:&#xA;<a href=""https://i.stack.imgur.com/zmxrc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zmxrc.jpg"" alt=""banking transfer app""></a></p>&#xA;&#xA;<p>It's clear there are four microservices, but I don't understand becouse the ""command side"" microservices don't have their own database.</p>&#xA;&#xA;<p>By this image all Microservices are using the same eventStore database, that's should be against the microservice pattern?</p>&#xA;&#xA;<p>And how should be the EventStore db? Single table? One table for each service&#xA;?</p>&#xA;"
46464455,Private calls to API,2017-09-28 08:30:02,<rest><api><microservices>,2,30,0,0.0,1,"<p>I have two microservices <code>registrations</code>, which is responsible for registering new users, and <code>users</code>, which hold information about users. Each of them has it's own database.</p>&#xA;&#xA;<p>When a user tries to register, a call to <code>users</code> is made via the API, e.g.</p>&#xA;&#xA;<pre><code>GET users/verify?email=foo%40bar.com&#xA;</code></pre>&#xA;&#xA;<p>to chech if the email has been already assigned to a profile. Although I could hide the access point <code>users/verify</code> in the public docs, it can still be accessible.</p>&#xA;&#xA;<p>What is the best way to allow only private IPs make requests to the API?</p>&#xA;"
46333428,Service end point with path variable is causing 404 with cloud contract,2017-09-21 00:03:43,<microservices><rest-assured><spring-cloud-contract><groovydsl>,1,87,0,0.0,1,"<p>I wrote a contract and the plugin autogenerated tests out of it. I'm seeing a very strange behavior with these autogenerated tests.</p>&#xA;&#xA;<p>Following is my service endpoint:</p>&#xA;&#xA;<pre><code>@RequestMapping(value=""/check/{id}"" method= RequestMethod.GET, produces = Media.APPLICATION_JSON_VALUE)&#xA;public ResponseEntity&lt;List&lt;Application&gt;&gt; getApplications(&#xA;@PathVariable (value = ""id"") String id){&#xA;&#xA;   return appService.findAll(id);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And here is the contract:</p>&#xA;&#xA;<pre><code>Contract.make {&#xA;    request {&#xA;        method GET()&#xA;        url '/check/1234567'&#xA;    }&#xA;    response {&#xA;        status 200&#xA;        body(""""""&#xA;            {&#xA;                .........&#xA;            }&#xA;            """""")&#xA;        headers {&#xA;            contentType(applicationJson())&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As I run ""mvn clean install"" tests are autogenerated and run. This works fine with the above contract and test passes perfectly.</p>&#xA;&#xA;<p>However, if I change the data in the path to ""/check/12345678"" it starts failing.</p>&#xA;&#xA;<p>The thing that I'm not able to understand is my endpoint is taking id path varaible which is a String type. For this type of path any value should be good. However the following paths work:</p>&#xA;&#xA;<pre><code>    url '/check/1234567'&#xA;    url '/check/12'&#xA;    url '/check/12347'&#xA;</code></pre>&#xA;&#xA;<p>And following doesn't work:</p>&#xA;&#xA;<pre><code>    url '/check/12345678' //added just one more digit&#xA;    url '/check/aa4567'   //prepended characters &#xA;    url '/check/123aa'    //appended characters&#xA;</code></pre>&#xA;&#xA;<p>It would be great If I can get an explanation about this behavior, or how to resolve it. Practically any string should work. For example <code>""/check/234df-dfs-fs234fds-sdf-fssd3rr""</code></p>&#xA;"
46283367,What are Hystrix benefits over normal exception handling?,2017-09-18 15:45:14,<microservices><hystrix>,4,600,0,0.0,1,"<p>I'm really new to Hystrix topic and concept of resilient services. I was going through some course and this question came into my mind. In Hystrix I need to define fallback method for a gracefull degradation. This method is then called when circuit is broken. But I can imagine to just wrap code with try and catch and when particular exceptions appear (for timeout for instance) and then call fallback method in catch clause. When called service is up then normal code would be called. Of course with Hystrix I can additionally monitor this, but what else it gives me ?. I'm pretty sure that I don't understand whole concept. </p>&#xA;"
46462610,monorepo VS. github submodules,2017-09-28 06:45:22,<git><github><microservices>,1,1447,0,0.0,1,"<p>Our app is built in microservice architecture, one service one repo. We are exploring whether we should create a monorepo, as many companies are following this practice. There are plenty of discussions about the pros and cons for mono vs. many. If we want to find an alternative to allow us have some cons from both options, should we use git submodules to provide 'looks-alike' mono structure? </p>&#xA;"
46370014,Call Microservice from another Microservice within Docker,2017-09-22 17:18:05,<c#><docker><microservices><docker-for-windows>,1,273,1,1.0,1,"<p>I created several Microservices in C# that are running on docker in windows, I need to call Microservice from another Microservice so I used this way to call:</p>&#xA;&#xA;<pre><code>    [HttpGet(""GetOrder/{Object_ID}"")]&#xA;    public Order GetOrder (int id)&#xA;    {&#xA;        string Baseurl = ""http://189.29.0.100/"";&#xA;        â€¦..&#xA;&#xA;        using (var client = new HttpClient())&#xA;        {&#xA;            //Passing service base url  &#xA;            client.BaseAddress = new Uri(Baseurl);&#xA;&#xA;            client.DefaultRequestHeaders.Clear();&#xA;            //Define request data format  &#xA;            client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;&#xA;            //Sending request to find web api REST service resource GetAllEmployees using HttpClient  &#xA;            borrowerData = await client.GetStringAsync(""api/order/"" + Id.ToString());&#xA;&#xA;        }&#xA;&#xA;       â€¦&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>I used the fix IP in Composed file as follows:</p>&#xA;&#xA;<pre><code> orderservice:&#xA;    environment:&#xA;     - ASPNETCORE_ENVIRONMENT=Development&#xA;   ports:&#xA;  - ""80""&#xA;networks:&#xA;  default:&#xA;    ipv4_address: 189.29.0.100&#xA;</code></pre>&#xA;&#xA;<p>The problem is when we deploy this project in VM, how to make it work with these Ips? </p>&#xA;"
46432262,How to achieve Statefullness in Microservices,2017-09-26 17:12:03,<microservices><stateful>,2,644,4,1.0,1,"<p>I have two microservices 1) Product Microservices 2) Checkout Microservices both are spring boot projects. In Checkout Microservice , i should get all the products that i have shopped, means my microservices should be STATEFUL to know what happend previously. Please suggest examples on how to achieve the statefulness it can be like Asyncronous with event source with Kafka/RabbitMQ. But please suggest architecture, code, example in detail how to get product details in checkout service.</p>&#xA;"
46451544,C++ MicroServices with desktop application,2017-09-27 15:16:38,<c++><microservices><desktop>,1,807,7,1.0,1,<p>I got a desktop application and it's getting bigger and bigger. And i wonder if i can make something like microservices with desktop application? I want to application for now stays desktop. Application it's written in C++.&#xA;I can exclude some of the modules with some preparations.&#xA;But is it possible and if anybody have idea how to start with this?</p>&#xA;
44610219,What are good use cases for an in-process events system vs microservices with a broker?,2017-06-17 23:05:40,<java><event-handling><messaging><microservices>,1,63,0,0.0,1,"<p>I've seen recently that there are different frameworks out there that allow the use of a messaging architecture but implemented in process, both using same and different threads. The ones I know about are Spring, Guava EventBus and Reactor. </p>&#xA;&#xA;<p>My question is about what are good use cases where someone would want to use them instead of sending messages to a full fledged broker. I understand that its usage allows for a better decoupling of the business logic but in a microservices architecture you would normally publish events to be consumed by other microservices. The advantage of that is the failure tolerance you have by adding a cluster of brokers where an erroneous message cause by a failure in an instance can be retried by another one. Implementing logic that is decomposed and executed by sending messages that are later consumed by the same system, specially when the subscribers are executed in different threads, seems to me difficult to then put the data back to a consistent state.</p>&#xA;"
44642751,AWS Kinesis for Microservice Choreography,2017-06-20 02:15:51,<amazon-web-services><domain-driven-design><microservices><cqrs><event-sourcing>,1,614,0,0.0,1,"<p>I am trying to develop microservices for online shop using CQRS, DDD, and Event sourcing concept. I looked to AWS Kinesis as event stream. I think it would be good for choreographed microservices. I have 2 services, service for customer data and service for ordering system. I want to see total number of unpaid orders and the total amount of orders for each customer. So, I should send orderCreated event and orderPaid event to the service for customer data and recalculate the total unpaid orders and total amount of orders for related customer.</p>&#xA;&#xA;<p>Could I put the ordering system events to AWS Kinesis and listen it in command-side service for customer? Should I persist the events (orderCreated and orderPaid event) from AWS Kinesis to database in customer command-side service? Or is it ok to just update the customer query-side service only? Should I use AWS Lambda as event processor? Could you give me some best practices for this model?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
44645743,Autherization service is not responsding with access_token while using zuul gateway,2017-06-20 06:47:48,<spring-boot><oauth-2.0><microservices><netflix-zuul>,1,256,1,0.0,1,"<p>I created multiple microservices with springboot 1.4. Last week I decided to implement oauth2 authorization service. My plan is something like,</p>&#xA;&#xA;<ol>&#xA;<li><p>Every request should be handled by zuul gateway which is registered by Eureka.</p></li>&#xA;<li><p>So the new Authorization service will be called by eureka to get access_token.</p></li>&#xA;</ol>&#xA;&#xA;<p>The problem I found is that I can able to get JWT access token directly from authorization server which is running in an another port(8081). when I tried to get the jwt token via zuul gateway, unfortunately I am getting an empty string.</p>&#xA;&#xA;<p>Please take a look at my gateway configuration</p>&#xA;&#xA;<p>application.yml (zuul-gateway)</p>&#xA;&#xA;<pre><code> zuul:&#xA;   routes: &#xA;    static:&#xA;    path: /static/** &#xA;   uaa:&#xA;    path: /uaa/**&#xA;    sensitive-headers: &#xA;    serviceId: microservice-security-oauth2-server&#xA;   users:&#xA;    path: /users/**&#xA;    serviceId: microservice-core-user&#xA;&#xA;&#xA;&#xA;security:&#xA; basic:&#xA;  enabled: false&#xA;</code></pre>&#xA;&#xA;<p>application class of zuul is</p>&#xA;&#xA;<pre><code> @SpringBootApplication&#xA; @EnableZuulProxy&#xA; @EnableEurekaClient&#xA; @ComponentScan(basePackages={""com.configuration"",""com.zullfilter""})&#xA; public class ZullGatewayServerApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;      SpringApplication.run(ZullGatewayServerApplication.class, args);&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the authorization server configuration class is</p>&#xA;&#xA;<pre><code>   @Configuration&#xA;   @EnableAuthorizationServer&#xA;   public class OAuth2AuthorizationConfiguration extends  AuthorizationServerConfigurerAdapter {&#xA;&#xA;@Autowired&#xA;private AuthenticationManager authenticationManager;&#xA;&#xA;@Autowired&#xA;private Environment environment;&#xA;&#xA;@Override&#xA;public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;    endpoints.tokenStore(tokenStore())&#xA;            .tokenEnhancer(jwtTokenEnhancer())&#xA;            .authenticationManager(authenticationManager);&#xA;}&#xA;&#xA;@Override&#xA;public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {&#xA;    security.tokenKeyAccess(""permitAll()"")&#xA;            .checkTokenAccess(""isAuthenticated()"");&#xA;}&#xA;&#xA;@Bean&#xA;public TokenStore tokenStore() {&#xA;    return new JwtTokenStore(jwtTokenEnhancer());&#xA;}&#xA;&#xA;@Bean&#xA;protected JwtAccessTokenConverter jwtTokenEnhancer() {&#xA;    String pwd = environment.getProperty(""keystore.password"");&#xA;    KeyStoreKeyFactory keyStoreKeyFactory = new KeyStoreKeyFactory(&#xA;            new ClassPathResource(""jwt.jks""),&#xA;            pwd.toCharArray());&#xA;    JwtAccessTokenConverter converter = new JwtAccessTokenConverter();&#xA;    converter.setKeyPair(keyStoreKeyFactory.getKeyPair(""jwt""));&#xA;    return converter;&#xA;}&#xA;&#xA;@Override&#xA;public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;    clients.inMemory()&#xA;            .withClient(""service-account-1"")&#xA;            .secret(""service-account-1-secret"")&#xA;            .authorizedGrantTypes(""client_credentials"")&#xA;            .scopes(""resource-server-read"", ""resource-server-write"")&#xA;            .accessTokenValiditySeconds(6000);&#xA; }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am getting access_token requesting directly to </p>&#xA;&#xA;<pre><code> curl service-account-1:service-account-1-secret@localhost:8081/uaa/oauth/token -d grant_type=client_credentials&#xA;</code></pre>&#xA;&#xA;<p>but when I am trying this with zuul proxy then I am getting an empty string</p>&#xA;&#xA;<pre><code> curl service-account-1:service-account-1-secret@localhost:8765/uaa/oauth/token -d grant_type=client_credentials&#xA;</code></pre>&#xA;&#xA;<p>I am using zuul gateway version of 1.3&#xA;and spring boot 1.4</p>&#xA;&#xA;<p>if anybody have faced this issue before please let me know</p>&#xA;"
44655441,Design Pattern for handling Microservices requests,2017-06-20 14:11:04,<design-patterns><asp.net-core><rabbitmq><microservices>,1,172,1,1.0,1,"<p>I have an application which is based on Microservices. I have a Broker/Gateway API which receives HTTP requests. Then I have two more services Service A and Service B. When the Broker API receives a message it uses RabbitMQ to send it to the services. Then in each one of them I should handle it and process it differently depending on the message (execute different action). </p>&#xA;&#xA;<p>This is the way I handle the messages currently:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Service A</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>    public string ProcessAsync(Message message)&#xA;    {&#xA;&#xA;        switch (message.EventCode)&#xA;        {&#xA;            case ""context 1"":&#xA;                return action1();&#xA;            case ""context 2"":&#xA;                return action2();&#xA;            case ""context 3"":&#xA;                return action3();&#xA;            case ""context 4"":&#xA;                return action4();&#xA;            case ""context 5"":&#xA;                return action5();&#xA;            default:&#xA;                throw new Exception(""Unknown message event code!"");&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>It makes sense to use switch statement if I have no more than 5 - 10 different message types. But in my app I have 30. Writing such a big conditional statement is ugly and different  to maintain. I am looking for a design pattern that is going to remove this problem from the application. Do you have any ideas? What do you think about State Pattern?</p>&#xA;"
44554638,How do I guarantee that the interface between two microservices is not broken?,2017-06-14 20:58:56,<java><microservices>,3,160,2,0.0,1,"<p>Imagine we have two microservices: client and server. One of the most fundamental features of microservice architecture is an ability to have a separated pipelines for each microservice meaning that we have to be able to deploy them to production independently. </p>&#xA;&#xA;<p>This implies that different microservices may be developed by different teams and some of the features are developed faster on one microservice than on the another. This quite often ends up with the contract (interface) being broken between client and server, so the JSON that the client sends to the server is no more valid.</p>&#xA;&#xA;<p><strong>The question is how to prevent cases where communication between two microservices is broken due to a broken contract between them? What is the best strategy to handle such issues?</strong></p>&#xA;"
51584078,Mirroring an external API and merging with other data as microservices,2018-07-29 20:00:20,<architecture><microservices>,1,19,0,0.0,1,"<h1>Use Case</h1>&#xA;&#xA;<p>I'm planning a system that should provide the following functionality:</p>&#xA;&#xA;<p><strong>Frontend</strong></p>&#xA;&#xA;<p>You have categories: ""Currently Popular"", ""Newcomers"", ""Classics"". Each category should show a list of movies that fit the category title.</p>&#xA;&#xA;<p><strong>Backend:</strong></p>&#xA;&#xA;<p>The decision of which movie belongs into which category is mostly based on the ratio of viewership numbers and release date / age of the movie.</p>&#xA;&#xA;<p>There are two external sources (Public APIs) from which I plan to gather my data from:</p>&#xA;&#xA;<ol>&#xA;<li><p><strong>Movies</strong> - A source of truth about which films exist and metadata around the movie itself. Basically <a href=""https://en.wikipedia.org/wiki/IMDb"" rel=""nofollow noreferrer"">IMDB</a>.</p></li>&#xA;<li><p><strong>Movie Viewership Numbers</strong> - An external API that tells me how many people have viewed a Movie per day, per medium (cinema, netflix, etc.) and other statistics.</p></li>&#xA;</ol>&#xA;&#xA;<p>I need to map the statistics from Source 2 to the movies of source 1, so theres an inherent necessity of communication (and coupling?) between the two domains.</p>&#xA;&#xA;<hr>&#xA;&#xA;<h1>How would this look like as a micro services oriented system?</h1>&#xA;&#xA;<p><strong>Solution A</strong></p>&#xA;&#xA;<p>Should I have a single ""game service"" that saves the data from Source 1 into one table and the stats from Source 2 into another table and exposes the combined data from a single endpoint.</p>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<p><strong>Solution B</strong></p>&#xA;&#xA;<p>Should I have two different services for each and combine the data in my api gateway. In this case, how do I model the inherent dependency of having to map the statistics to my source-of-truth movie service/database?</p>&#xA;&#xA;<hr>&#xA;&#xA;<h1>Thoughts</h1>&#xA;&#xA;<p>I understand that <a href=""https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-2/"" rel=""nofollow noreferrer""><code>domain object = microservice</code> is not the way to go</a>, so the literature and community ""tells"" me to pick Solution A, but I intuitively prefer Solution B. What if I want to display movie trailers in the future and theres a third external API for those. Would I cram those in the single service or create a new one?</p>&#xA;&#xA;<p>I don't have the experience and frankly a deep enough understanding of domain driven design or software architecture to come to a sensible conclusion here.</p>&#xA;&#xA;<p>Your help would be greatly appreciated.</p>&#xA;"
51593335,best managing microservice dependencies,2018-07-30 11:50:02,<microservices>,3,28,0,0.0,1,"<p>I need some advise on how to best manage microservices and their dependencies.</p>&#xA;&#xA;<p>Assuming I have a microservice ""pages"" that manages article pages with operations to create/delete/edit pages.</p>&#xA;&#xA;<p>Assume I have built on top a microservice ""books"" that manages a collection of pages, with operations to add/delete/edit pages that calls the downstream endpoints of pages service.</p>&#xA;&#xA;<p>If I want to build another microservice that needs to edit a certain page in a book, would it be best to call the edit pages endpoint of books or pages directly?</p>&#xA;"
51578263,Spring Initializer - Zipkin dependencies missing?,2018-07-29 07:36:23,<rabbitmq><microservices><spring-cloud><zipkin>,2,44,0,1.0,1,"<p>In spring initializer i couldn't find following dependencies <strong>zipkin ui</strong>, <strong>zipkin stream</strong>, <strong>stream rabbit</strong>.I know it was available but i don't know why they've deprecated those dependencies. Are there any other alternatives dependencies spring initializer provide?</p>&#xA;"
51664743,Setting the correct hostname in Kubernetes/Nginx for the client,2018-08-03 03:05:42,<docker><nginx><kubernetes><ssl-certificate><microservices>,1,46,0,1.0,1,"<p>I'm using a dockerized microservice architecture running on Kubernetes with Nginx, and am encountering an issue with hostnames. How do you correctly add the hostname to Kubernetes (or perhaps Nginx too)?</p>&#xA;&#xA;<p>The problem: When microservice A called <code>admin</code> tries to talk to microservice B called <code>session</code>, <code>admin</code> logs the following error and <code>session</code> is not reached: </p>&#xA;&#xA;<pre><code>{ Error [ERR_TLS_CERT_ALTNAME_INVALID]: Hostname/IP does not match certificate's &#xA;altnames: Host: session. is not in the cert's altnames: DNS:*.example.com, example.com&#xA;at Object.checkServerIdentity (tls.js:225:17)&#xA;at TLSSocket.onConnectSecure (_tls_wrap.js:1051:27)&#xA;at TLSSocket.emit (events.js:160:13)&#xA;at TLSSocket._finishInit (_tls_wrap.js:638:8)&#xA;  reason: 'Host: session. is not in the cert\'s altnames: &#xA;DNS:*.example.com, example.com',&#xA;  host: 'session',&#xA;  cert:&#xA;   { subject: { OU: 'Domain Control Validated', CN: &#xA;'*.example.com' },&#xA;     issuer: ...&#xA;</code></pre>&#xA;&#xA;<p>In response to this error, I tried to update the hostname in the kubernetes config yaml file unsuccessfully (based on <a href=""https://stackoverflow.com/questions/34609572/is-it-possible-to-set-a-hostname-in-a-kubernetes-replication-controller"">this</a>). See the added <code>hostname</code> below.</p>&#xA;&#xA;<pre><code>apiVersion: apps/v1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: session&#xA;  namespace: demo&#xA;spec:&#xA;  replicas: 1&#xA;  selector:&#xA;    matchLabels:&#xA;      app: session&#xA;      component: demo&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: session&#xA;        component: demo&#xA;    spec:&#xA;      hostname: session.example.com . ----&gt; added host name here&#xA;      imagePullSecrets:&#xA;        - name: docker-secret &#xA;      containers:&#xA;      - name: session&#xA;       ...&#xA;</code></pre>&#xA;&#xA;<p>However, when I try to apply this updated config file in Kubernetes, an error emerges that I cannot use a period.  If I cannot use a period, and the hostname is <code>*.example.com</code> (i.e. <code>session.example.com</code>), where/how should the hostname be updated.</p>&#xA;&#xA;<pre><code>The Deployment ""session"" is invalid: spec.template.spec.hostname: &#xA;Invalid value: ""session.example.com"": a DNS-1123 label must &#xA;consist of lower case alphanumeric characters or '-', and must start and &#xA;end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex &#xA;used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')&#xA;</code></pre>&#xA;&#xA;<p>Meanwhile, the server name in the nginx config file is indeed updated with <code>session.example.com</code>.</p>&#xA;&#xA;<pre><code>upstream session {&#xA;  server 127.0.0.1:3000;&#xA;  keepalive 32;&#xA;}&#xA;&#xA;server {&#xA;  listen 443 ssl http2 default_server;&#xA;  listen [::]:443 ssl http2 default_server;&#xA;&#xA;  server_name ""session.example.com"";  ---&gt; updated for hostname &#xA;&#xA;  ssl_certificate      /etc/ssl/nginx/certificate.pem;&#xA;  ssl_certificate_key  /etc/ssl/nginx/key.pem;&#xA;&#xA;  location / {&#xA;      proxy_pass http://session/;&#xA;      proxy_http_version 1.1;&#xA;      proxy_set_header Connection """";&#xA;  }&#xA;}&#xA;&#xA;&#xA;server {&#xA;  listen 80 default_server;&#xA;  listen [::]:80 default_server;&#xA;  server_name ""session.example.com"";    ---&gt; updated for hostname &#xA;&#xA;  return 301 https://$host$request_uri;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How do you suggest fixing this? My goal is for <code>admin</code> to successfully communicate with <code>session</code>.</p>&#xA;"
51737931,Micro-services - decision on technology/platform,2018-08-08 02:47:39,<microservices>,1,26,1,0.0,1,"<p>Is it good architecture of an application if,&#xA;I am using multiple technologies leveraging strong points of each.&#xA;for example:&#xA;Encryption in python,&#xA;integration of services in java etc.&#xA;or should I stick to one technology like Java as I am comfortable with it?&#xA;Also the reason for this question is I am thinking of developing a new application in which speed is a major concern, I am targeting to attain.</p>&#xA;&#xA;<p>Also Database that I am preferring for now is MongoDb. </p>&#xA;&#xA;<p>Any suggestions on the Technologies apart from these technologies?</p>&#xA;&#xA;<p>Also will this approach help in speeding up the application?</p>&#xA;"
42073576,Consul: SD architecture. What is the right way to access microservices from a front-end side?,2017-02-06 17:18:28,<node.js><docker><microservices><consul>,2,311,0,0.0,1,"<p>I have a few back-end microservices managed by consul, and to get some data from one service for the other one, I use service discovery feature of consul - like get all healthy servers, then get server address and port from the retrieved entry etc. But <strong>how should I do it from a front-end side?</strong> Just call needed microserver using it's actual ip or call it using namespace of docker container? It will be very helpful to get any response from someone who knows how to do it or even better, who did it before, because I stuck with it a bit.</p>&#xA;"
41983447,Implement rate limiting for public facing API deployed in AWS,2017-02-01 15:25:58,<api><amazon-web-services><microservices><rate-limiting>,1,363,1,1.0,1,"<p>Our public API is deployed in AWS. They are developed with different tech stacks.</p>&#xA;&#xA;<p>We want to introduce rate limiting (based on IP, access key, etc.) for the API across many services in a generic way. </p>&#xA;&#xA;<ul>&#xA;<li>Less or No ops effort to run</li>&#xA;<li>Introducing new services and paths to existing services should not require effort on configuring API gateway</li>&#xA;</ul>&#xA;&#xA;<p>We are considering the following.</p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://aws.amazon.com/api-gateway/"" rel=""nofollow noreferrer"">AWS API Gateway</a> Looks easy. Not sure adding routes require effort to keep it sync with services.</li>&#xA;<li><a href=""https://github.com/containous/traefik"" rel=""nofollow noreferrer"">traefik</a> Looks good. But, we need to run and maintain.</li>&#xA;</ul>&#xA;&#xA;<p>What would be the suggested approach for this? Any better tools/suggestions?</p>&#xA;"
42002512,Running multiple instance microservice using spring cloud config,2017-02-02 12:39:10,<spring><spring-boot><microservices><spring-cloud-config>,2,1485,2,0.0,1,"<p>I am developing a <strong>microservice, using <a href=""https://projects.spring.io/spring-boot/"" rel=""nofollow noreferrer"">Spring Boot</a></strong>, that exposes REST Endpoint. </p>&#xA;&#xA;<p>To meet the scalability constrains, <strong>multiple instance of the [same] service</strong> will be deployed (basically scale up when needed and scale down when not needed). </p>&#xA;&#xA;<p>I am using the <strong><a href=""https://cloud.spring.io/spring-cloud-config/spring-cloud-config.html"" rel=""nofollow noreferrer"">Spring Cloud Config Server</a></strong> to supply the configuration (such as port to bound, and other configurations) to this service. </p>&#xA;&#xA;<p><strong>Since the service exposing REST api, How can configure the config server to supply a unique port to each instance of the microservice?</strong></p>&#xA;&#xA;<p>One possible solution could be, running the service in individual machine/VM or create a docker container and deploy the service. This could be my solution if there is no way to supply random port to the service from cloud config server.</p>&#xA;"
36681094,How to setup intrusion detection system for micro services?,2016-04-17 19:20:27,<microservices><intrusion-detection>,1,87,0,0.0,1,"<p>What would be the best architecture to configure a IDS for micro services, two things came into my mind instantly as following. </p>&#xA;&#xA;<ol>&#xA;<li>Configure IDS at the entry point of all the micro services</li>&#xA;<li>Configure separate IDSs for each of the micro services</li>&#xA;</ol>&#xA;&#xA;<p>What are the pros or cons in following above methods, or are there anyother things to consider?</p>&#xA;"
36812791,Doing compex reports with microservices,2016-04-23 15:36:11,<report><microservices>,1,1655,0,0.0,1,"<p>I'm starting a new project and am interested in architecting it as microservices. I'm trying to wrap my head around it:</p>&#xA;&#xA;<p>Say that I have an order service and a product service. Now I want to make a report service that gives me all orders that contain a product from a certain product category. </p>&#xA;&#xA;<p>Since order's dont know about products that means that I would need to fetch all orders, loop them and fetch products for each order and then return those how match. </p>&#xA;&#xA;<p>Is this assumption correct or is there any more efficient way of doing this with microservices?</p>&#xA;"
36715395,Clustering Microservices Components,2016-04-19 10:15:07,<cluster-computing><microservices>,1,10957,1,1.0,1,"<p>I have a Microservice that is realised as a Play framework based HTTP service. We now want to add fault tolerance to this service by having another instance that picks up the requests when one instance goes down. Now I understand that Microservices are not designed from the ground up to be clustered as they are purely stateless, self sustaining components that are meant to simply run.</p>&#xA;&#xA;<p>Are there ways wherein I could add failover support? I'm thinking of some external component that checks for the status of the service and reacts upon failures by starting another instance on some other host. Any suggestions?</p>&#xA;"
36660279,Microservice grouping of modules,2016-04-16 04:55:50,<soa><microservices>,1,116,4,1.0,1,"<p>I'm developing an Employee Management System and following a microservice-style architecture. Initially, I have created the ERD and designed several master maintenance tables like Department, Project, Position etc...</p>&#xA;&#xA;<p>My question is do I have to create a single service for each of these tables? or should I create a single service called master maintenance for all these tables?</p>&#xA;&#xA;<p>Please help me to decide. Thank you in advance.</p>&#xA;"
36716838,Microservice architecturs and layers,2016-04-19 11:18:52,<architecture><microservices>,1,483,5,1.0,1,"<p>Let's discuss the architecture of a microservice environment. We are having a discussion internally at our company and I'd like some feedback. What I'm having serious thoughts about are an orchestration layer (code duplication, more moving parts changing an api).</p>&#xA;&#xA;<h2>Option one - with orchestration layer:</h2>&#xA;&#xA;<p>webapp -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>In this case services are not allowed to talk to each other. Aggregated services in orchestration layer</p>&#xA;&#xA;<h2>Option one - without orchestration layer:</h2>&#xA;&#xA;<p>webapp -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> service -> persistance</p>&#xA;&#xA;<p>Here services are allowed to talk to each other, aggregated services exist here.</p>&#xA;&#xA;<h3>Specific questions:</h3>&#xA;&#xA;<ul>&#xA;<li>Where does billing belong?</li>&#xA;<li>Which solution do you prefer? Pros/cons.</li>&#xA;<li>Other suggestions?</li>&#xA;</ul>&#xA;"
36645517,REST api service context and resources url,2016-04-15 11:08:33,<java><rest><jersey><jax-rs><microservices>,3,910,7,1.0,1,"<p>We have serveral services running on an application server and every service has a context. The name of the service is automatically added to the url, since there can be multiple services on the same application server.<br>&#xA;Now we are creating a new service, which is called Draws, meaning the url will be</p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws"" rel=""nofollow"">http://url:port/Draws</a></p>&#xA;</blockquote>&#xA;&#xA;<p>However, now the discussion is the api paths (Resources) to this service. Since we are getting draws, in my mind this should be draws.&#xA;Which means it will have the url   </p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws/draws/"" rel=""nofollow"">http://url:port/Draws/draws/</a>{gameNo}</p>&#xA;</blockquote>&#xA;&#xA;<p>2x draws - <strong>Thoughts?</strong> </p>&#xA;&#xA;<p>There are thoughts here that the service does only have draws and therefor Draws/{gameNo} is enough.<br>&#xA;But in my mind, draws resource is the api interface of the service, like Draws is the book in a library, draws is the chapter... And it should be possible to add more chapters to the book.</p>&#xA;&#xA;<p>Then to implementation, we are using Jersey. That would mean we would have a resource with @Path(""{gameNo}"").</p>&#xA;&#xA;<p><strong>Edit 1:</strong><br>&#xA;There are gateways in front of our services, so the context will never be exposed to end users, it's only there to point to an specific service. Since multiple services can run on the same host:port</p>&#xA;&#xA;<p><strong>Edit 2:</strong><br>&#xA;Context part of the url is part of the service discovery lookup</p>&#xA;&#xA;<p><strong>Edit 3:</strong><br>&#xA;We are actually not versioning in url, but in Accept header, so actually my url is the same as clementinos but the version part of the url</p>&#xA;"
36744042,"REST, Pagination with filters dependent on external system and sql",2016-04-20 12:37:23,<rest><design><architecture><pagination><microservices>,2,163,7,0.0,1,"<p>I have a REST web-service which is expected to expose a paginated GET call.</p>&#xA;&#xA;<p>For eg: I have a list of students( ""Name"" , ""Age"" , ""Class"" ) in my sql table. And I have to expose a paginated API to get all students given a class. So far so good. Just a typical REST api does the job and pagination can be achieved by the sql query.</p>&#xA;&#xA;<p>Now suppose we have the same requirement just that we need to send back students who are from particular state. This information is hosted by a web-service, S2. S2 has an API which given a list of student names and a state ""X"" returns the students that belong to state X. </p>&#xA;&#xA;<p>Here is where I'm finding it difficult to support pagination. </p>&#xA;&#xA;<p>eg: I get a request with page_size 10, a class C and a state X which results in 10 students from class C from my db. Now I make a call to S2 with these 10 students and state X, in return, the result may include 0 students, all 10 students, or any number students between 0 and 10 from state 'X'.</p>&#xA;&#xA;<p>How do I support pagination in this case?</p>&#xA;&#xA;<p>Brute force would be to make db calls and S2 calls till the page size is met and then only reply. I don't like this approach .</p>&#xA;&#xA;<p>Is there a common practice followed for this, a general rule of thumb, or is this architecture a bad service design?</p>&#xA;&#xA;<p>(EDIT): Also please tell about managing the offset value. &#xA;if we go with the some approach and get the result set , how can I manage the offset for next page request ?</p>&#xA;&#xA;<p>Thanks for reading :)</p>&#xA;"
42822348,How to tell from Npgsql exception if the call is worth a retry (transient fault strategy),2017-03-15 23:03:22,<c#><postgresql><microservices><npgsql><polly>,1,286,0,1.0,1,"<p>I'm writing a service which will be connecting to a remote postgres server.&#xA;I'm looking for a good way to determine which exceptions should be treated as transient (worth retrying), and how to define an appropriate policy for connecting to a remote database.</p>&#xA;&#xA;<p>The service is using Npgsql for the data access.&#xA;The documentation says that Npgsql will throw a PostgresException for sql errors and an NpgsqlException for ""server related issues"".</p>&#xA;&#xA;<p>So far the best I have been able to come up with is to assume all exceptions that are not PostgresExceptions should be treated as possibly transient, worth retrying, but a PostgresException would mean that there is something wrong with the query and that retrying would not help.  Am I correct in this assumption?  </p>&#xA;&#xA;<p>I am using Polly to create a Retry and Circuit Breaker policy.&#xA;Thus, my policy looks like this:</p>&#xA;&#xA;<pre><code>Policy.Handle&lt;Exception&gt;( AllButPotgresExceptions()) // if its a postgres exception we know its not going to work even with a retry, so don't&#xA;                       .WaitAndRetryAsync(new[]&#xA;                       {&#xA;                           TimeSpan.FromSeconds(1),&#xA;                           TimeSpan.FromSeconds(2),&#xA;                           TimeSpan.FromSeconds(4)&#xA;                       }, onRetry: (exception, span) =&gt; Log.Warning(exception, ""Postgres Retry Failure: ""))&#xA;                    .WrapAsync(&#xA;                           Policy.Handle&lt;Exception&gt;( AllButPotgresExceptions())&#xA;                               .AdvancedCircuitBreakerAsync(&#xA;                                   failureThreshold:.7, &#xA;                                   samplingDuration: TimeSpan.FromSeconds(30), &#xA;                                   minimumThroughput: 20, &#xA;                                   durationOfBreak: TimeSpan.FromSeconds(30), &#xA;                                   onBreak: (ex, timeSpan, context) =&gt; Log.Warning(ex, ""Postres Circuit Breaker Broken: ""), &#xA;                                   onReset: (context) =&gt; Log.Warning(""Postres Circuit Breaker Reset: ""), &#xA;                                   onHalfOpen: () =&gt; Log.Warning(""Postres Circuit Breaker Half Open: "")&#xA;                               )));&#xA;        }&#xA;    }&#xA;&#xA;    private static Func&lt;Exception, bool&gt; AllButPotgresExceptions()&#xA;    {&#xA;        return ex =&gt; ex.GetType() != typeof(PostgresException);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Is there a better way to determine which errors may be transient?</p>&#xA;&#xA;<p>UPDATE: </p>&#xA;&#xA;<p>Following Shay's suggestions I opened a new issue in Npgsql and updated my Policy to look like this:</p>&#xA;&#xA;<pre><code>public static Policy PostresTransientFaultPolicy&#xA;    {&#xA;        get&#xA;        {&#xA;            return postgresTransientPolicy ?? (postgresTransientPolicy = Policy.Handle&lt;Exception&gt;( PostgresDatabaseTransientErrorDetectionStrategy())&#xA;                       .WaitAndRetryAsync(&#xA;                            retryCount: 10, &#xA;                            sleepDurationProvider: retryAttempt =&gt; ExponentialBackoff(retryAttempt, 1.4), &#xA;                            onRetry: (exception, span) =&gt; Log.Warning(exception, ""Postgres Retry Failure: ""))&#xA;                    .WrapAsync(&#xA;                           Policy.Handle&lt;Exception&gt;( PostgresDatabaseTransientErrorDetectionStrategy())&#xA;                               .AdvancedCircuitBreakerAsync(&#xA;                                   failureThreshold:.4, &#xA;                                   samplingDuration: TimeSpan.FromSeconds(30), &#xA;                                   minimumThroughput: 20, &#xA;                                   durationOfBreak: TimeSpan.FromSeconds(30), &#xA;                                   onBreak: (ex, timeSpan, context) =&gt; Log.Warning(ex, ""Postres Circuit Breaker Broken: ""), &#xA;                                   onReset: (context) =&gt; Log.Warning(""Postres Circuit Breaker Reset: ""), &#xA;                                   onHalfOpen: () =&gt; Log.Warning(""Postres Circuit Breaker Half Open: "")&#xA;                               )));&#xA;        }&#xA;    }&#xA;&#xA;    private static TimeSpan ExponentialBackoff(int retryAttempt, double exponent)&#xA;    {&#xA;        //TODO add random %20 variance on the exponent&#xA;        return TimeSpan.FromSeconds(Math.Pow(retryAttempt, exponent));&#xA;    }&#xA;&#xA;    private static Func&lt;Exception, bool&gt; PostgresDatabaseTransientErrorDetectionStrategy()&#xA;    {&#xA;        return (ex) =&gt;&#xA;        {                &#xA;            //if it is not a postgres exception we must assume it will be transient&#xA;            if (ex.GetType() != typeof(PostgresException))&#xA;                return true;&#xA;&#xA;            var pgex = ex as PostgresException;&#xA;            switch (pgex.SqlState)&#xA;            {&#xA;                case ""53000"":   //insufficient_resources&#xA;                case ""53100"":   //disk_full&#xA;                case ""53200"":   //out_of_memory&#xA;                case ""53300"":   //too_many_connections&#xA;                case ""53400"":   //configuration_limit_exceeded&#xA;                case ""57P03"":   //cannot_connect_now&#xA;                case ""58000"":   //system_error&#xA;                case ""58030"":   //io_error&#xA;&#xA;                //These next few I am not sure whether they should be treated as transient or not, but I am guessing so&#xA;&#xA;                case ""55P03"":   //lock_not_available&#xA;                case ""55006"":   //object_in_use&#xA;                case ""55000"":   //object_not_in_prerequisite_state&#xA;                case ""08000"":   //connection_exception&#xA;                case ""08003"":   //connection_does_not_exist&#xA;                case ""08006"":   //connection_failure&#xA;                case ""08001"":   //sqlclient_unable_to_establish_sqlconnection&#xA;                case ""08004"":   //sqlserver_rejected_establishment_of_sqlconnection&#xA;                case ""08007"":   //transaction_resolution_unknown&#xA;                    return true;&#xA;            }&#xA;&#xA;            return false;&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;"
42641804,Authentication approach for REST API used by frontend app and another backend service,2017-03-07 06:39:04,<javascript><java><rest><microservices>,2,583,1,0.0,1,<p>I have a rest api backend service <strong>A</strong> which is used by two other services:</p>&#xA;&#xA;<ul>&#xA;<li><strong>B</strong> service which is web app running in a browser (separate node server)</li>&#xA;<li><strong>C</strong> service which is also backend service (separate server too)</li>&#xA;</ul>&#xA;&#xA;<p>My initial approach was to use basic auth for A-B communication but this does not make sense for A-C since there is no way to safely keep credentials in a browser. On the other hand introducing session and tokens seems weird for A-B communication.</p>&#xA;&#xA;<p>No matter what I do it seems like tug of war.</p>&#xA;&#xA;<p>What do you think might be reasonable solution for such setup?</p>&#xA;
42667203,How to use Cloud Tools for Eclipse plugin to create microservices in Google App Engine?,2017-03-08 09:13:51,<eclipse><google-app-engine><microservices><google-plugin-eclipse><google-cloud-tools>,1,289,2,0.0,1,"<p>As I upgraded my Eclipse to Neon 2 (Eclipse 4.6.2), as ""Google Plugin for Eclipse"" no longer support, so I switch to Google's ""Cloud Tools for Eclipse plugin"" (<a href=""https://cloud.google.com/eclipse/docs/quickstart"" rel=""nofollow noreferrer"">https://cloud.google.com/eclipse/docs/quickstart</a>) </p>&#xA;&#xA;<p>Last time that is easy to use ""Google Plugin for Eclipse"" to create multiple modules (known as microservices).  I just need create an ""Enterprise Application Project"" using GAE as runtime and then create ""Dynamic Web Project"" and tie to that Enterprise App. </p>&#xA;&#xA;<p>However in this ""Cloud Tools for Eclipse"", when I choose new Enterprise App, Google App Engine is not an option in runtime selection.  </p>&#xA;&#xA;<p>Any help on how to use ""Cloud Tools for Eclipse"" to create microservices for GAE?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
42653725,In which microservice should I store a liaison table,2017-03-07 16:45:01,<relational-database><relationship><microservices>,2,117,3,0.0,1,"<p>I'm splitting my zoo-management application into micro-services.&#xA;I have the following domain : animals, caretakers, cages </p>&#xA;&#xA;<p>I thinking about where I should store the relationships. </p>&#xA;&#xA;<p>For exemple a cage contain several animals :&#xA;Should I store the cage_animals table into the cages services database or into the animals database ?</p>&#xA;&#xA;<p>And several caretakers are attributed to several animals :&#xA;Should I store the caretakers_animals table into the caretakers service's database or into the animals service's database ?</p>&#xA;"
50966737,What is difference between Microservices and Decentralized applications,2018-06-21 10:53:20,<spring-boot><microservices><ethereum><bitcoin>,2,57,0,0.0,1,"<p>I am new to the decentralized application, after going through some articles I confused between the microservices and decentralized application. Can someone help me to understand the difference between them. I know that microservices can be built using spring boot &amp; docker. Is there any other technology present to build it.I think Ethereum is used to develop the decentralized application. Can someone help me to understand the difference?</p>&#xA;"
51000111,API Gateway Micro Service Lookup Method,2018-06-23 10:09:56,<aggregate><microservices><api-design><api-gateway>,1,65,0,0.0,1,"<p>I have built an API, with an API Gateway and two micro services.&#xA;The two micro services are Products and Categories.</p>&#xA;&#xA;<p>The API call can do the following:</p>&#xA;&#xA;<pre><code>/v1/account/getAccount          // gets all accounts&#xA;/v1/account/getAccount/44       // gets account 44&#xA;/v1/categories/getCategory      // gets all categories&#xA;/v1/categories/getCategory/24   // gets category 24&#xA;</code></pre>&#xA;&#xA;<p>Accounts can be in categories. What's the best way to go about getting all accounts with their corresponding categories.</p>&#xA;&#xA;<ol>&#xA;<li>The account micro service makes a call to the category micro service</li>&#xA;<li>The gateway makes a synchronous call to the account micro service, then loops through these accounts to make a call to the category micro service to get each corresponding category</li>&#xA;<li>Put point 2 into a new Aggregating micro service</li>&#xA;<li>Some other way?</li>&#xA;</ol>&#xA;&#xA;<p>Thanks</p>&#xA;"
51008734,Implementing request-level caching for my microservice(s),2018-06-24 09:47:23,<microservices><distributed-computing>,1,66,0,0.0,1,"<p>I am trying to reduce the time the application spends computing the same thing over and over again... This sounds like a caching use-case, but it may require an architectural change instead.</p>&#xA;&#xA;<p>The situation is this: there are many callers who, independently, submit near-identical requests to my micro-service. This happens for some time (on the same order of magnitude as the time needed to service one of these requests), then they all move to a new set of near-identical requests.</p>&#xA;&#xA;<p>I would like to try to compute each unique request only once, as much as this is feasible.</p>&#xA;&#xA;<p>At a given time, I will get several requests to compute each of</p>&#xA;&#xA;<p><code>{A, T0}</code>, <code>{B, T0}</code>, <code>{C, T0}</code>, <code>{A, B, T0}</code>, <code>{B, C, T0}</code>, etc.</p>&#xA;&#xA;<p>Then, my callers switch to <code>{A, T1}</code>, <code>{B, T1}</code>, etc.</p>&#xA;&#xA;<p>While I am computing the result for the <code>{A, T0}</code> request on one node, the cluster will receive several other requests for the same <code>{A, T0}</code> request. Even after I finish computing the result, but before the callers move to T1, I will still receive <code>{A, T0}</code> requests.</p>&#xA;&#xA;<p>Also, a <code>{A, B, T0}</code> request can be broken down into a <code>{A, T0}</code> and <code>{B, T0}</code> request plus a simple join.</p>&#xA;&#xA;<p>After an individual request is computed, it should be fairly easy to cache that result and serve it to subsequent requests. It's just that most of the duplicate requests come in while the first request is being computed...</p>&#xA;&#xA;<p>Is there any form of request-level caching that can alleviate this situation?</p>&#xA;&#xA;<p>It does sound a bit like trying to make POSTs idempotent, which might not be doable. </p>&#xA;&#xA;<p>The set of possible ""letters"", the <code>A</code>, <code>B</code> and <code>C</code>'s above is known, but large. The subset of ""letters"" that do form the requests can change slightly (e.g. there could be a <code>{A, C, D, T2}</code> request at some point).</p>&#xA;&#xA;<p>Is there a better architectural approach to this issue?&#xA;Just throwing more hardware at it would work but seems wasteful.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>One approach that I'm considering is this:</p>&#xA;&#xA;<ul>&#xA;<li>""like"" requests get routed to the same node. E.g. all <code>{A, T0}</code> requests go to node 12</li>&#xA;<li>locally, on each node I have a (LRU) cache of <code>Request</code> to <code>Future&lt;Response&gt;</code></li>&#xA;<li>any request either listens to an existing <code>Future</code> or registers and executes a new one</li>&#xA;<li>should the node go down, the ""like"" requests would all get assigned to another node and the request will be processed again</li>&#xA;</ul>&#xA;&#xA;<p>Where this becomes tricky is dealing with the <code>{A, B, T0}</code> kind of requests. These get split into smaller requests, each of which could be processed by different nodes.</p>&#xA;"
51026313,URL patterns for REST in Microservices,2018-06-25 14:50:34,<rest><url><design-patterns><microservices>,2,100,1,0.0,1,"<p>We are thinking about the best URL scheme for our (mostly) RESTful microservices. Each service has his own context. A service for hashtag (like Instagram) specific logic does all things that connect to hashtags.&#xA;A user service that does all the handling of registered users and so on.</p>&#xA;&#xA;<p>So we thought we start every URL with /api and then the context of every service. In this case for example /api/hashtag oder /api/user</p>&#xA;&#xA;<p>The problem is that those services have the same name as the ""core"" resource. The user service has a resource that lists all users for example so the URL must be something like /api/user/user.&#xA;Same goes for hashtags. There is a resource in that service that lists all hashtags. So the URL must be /api/hashtag/hashtag.</p>&#xA;&#xA;<p>And now you get the problem: The ""core"" resource sounds exactly like the service. And we are looking for a good solution for that. Are there any best practices for this?</p>&#xA;&#xA;<p>Thank you!</p>&#xA;"
51040814,Micro services: shared library vs code duplication,2018-06-26 10:37:23,<.net><asp.net-core><architecture><microservices>,3,117,3,0.0,1,"<p>Similar questions were asked a few times, but as every use-case can be different I thought it worth to ask it again with the specific case I'm facing with.&#xA;So, we are developing micro-services using .netCore.  Let's call these services <strong>ServiceA</strong>, <strong>ServiceB</strong>, <strong>ServiceC</strong>.</p>&#xA;&#xA;<h2>Common entities</h2>&#xA;&#xA;<p>If <strong>ServiceA</strong> calls  <strong>ServiceC</strong>, then <strong>ServiceC</strong> responds with a JSON content which can be serialized into <strong>ResponseC</strong> object.</p>&#xA;&#xA;<p>This means, that both <strong>ServiceA</strong> and <strong>ServiceC</strong> should know <strong>ResponseC</strong> class.&#xA;At this point I see two possibilities. <strong>ResponseC</strong> class can be in a shared library and both <strong>ServiceA</strong> and <strong>ServiceC</strong> should have a reference to this shared library.&#xA;However I read statements like <strong>do not share libraries among micro-services</strong>. This leads to an other possible solution. Let's introduce <strong>ResponseC</strong> class in both micro-services, but then somehow I find this a bit against maintainability, because of code duplication.</p>&#xA;&#xA;<h2>Common logic</h2>&#xA;&#xA;<p>Both <strong>ServiceA</strong> and <strong>ServiceB</strong> communicates with <strong>ServiceC</strong>. When communicating with <strong>ServiceC</strong> we intend to have some policy regarding read and connection timeout and regarding the maximum number of retries. These values are configurable and there is also some common parts in the retry logic to be able to read the relevant values from the configuration file and to wrap the http calls. &#xA;The question is pretty much the same like in the previous case, because I either put these classes into a shared library or I basically introduce the same classes in both <strong>ServiceA</strong> and <strong>ServiceB</strong>. These classes are quite simple and generic, so at the moment I cannot imagine, that these classes will change frequently.</p>&#xA;&#xA;<p>So the question is, that what is better in these cases, duplicate code and having independent micro-services or introduce a shared library which makes these services dependent?</p>&#xA;"
38099204,Session management using json web tokens in microservices,2016-06-29 12:13:43,<json><session><token><jwt><microservices>,1,808,0,0.0,1,"<p>I am trying to figure out how I will manage sessions using json web tokens in a microservice architecture. </p>&#xA;&#xA;<p>Looking at the design in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""nofollow"">article</a> what I currently have in mind is that the client will send a request that first goes through a firewall. This request will contain an opaque/reference token which the firewall sends to an authorization server.  The authorization server responds with a value token containing all the session information for the user.  The firewall then passes the request along with the value token to the API, and the value token will then get propagated to all the different microservices required to fulfill the request. </p>&#xA;&#xA;<p>I have 2 questions:</p>&#xA;&#xA;<ol>&#xA;<li>How should updates to the session information in the value token be handled? To elaborate, when the session info in a token gets updated, it needs to be updated in the authorization server.  Should each service that changes the token talk to the authorization server? </li>&#xA;<li>Should all the microservices use this single token to store their session info? Or would it be better for each service to have a personalized token? If it's the latter, please explain how to adjust the design.</li>&#xA;</ol>&#xA;"
38164006,How To Delay Observable emission in RxJava,2016-07-02 20:00:14,<rx-java><haproxy><microservices>,2,1410,0,0.0,1,"<p>We have Micro services architecture, where we make inter-service calls over a network.&#xA;We are using RxJava in top level service, which is resulting in creation of large no of parallel requests to bottom service.&#xA;Because of this i am getting ""No Route to Host error"" or ""connection error"".&#xA;For that purpose i want to slow down emission from RxJava Observable, so that earlier connection will get closed before creating new one.&#xA;Below is the sample code:</p>&#xA;&#xA;<pre><code>    package com.demo.rxjava.rxjaxa.creation;&#xA;    import rx.Observable;&#xA;    import rx.Subscriber;&#xA;    import rx.schedulers.Schedulers;&#xA;&#xA;    public class Delay {&#xA;&#xA;        public static void main(String[] args) throws InterruptedException {&#xA;            Observable.just(1, 2, 3, 4, 5).subscribeOn(Schedulers.io())&#xA;                    .flatMap(integer -&gt; {&#xA;                        return function1(integer);&#xA;                    }).observeOn(Schedulers.io())&#xA;                    .subscribe(new Subscriber&lt;String&gt;() {&#xA;                        @Override&#xA;                        public void onNext(String item) {&#xA;                            System.out.println(""Next: "" + item);&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onError(Throwable error) {&#xA;                            System.err.println(""Error: "" + error.getMessage());&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onCompleted() {&#xA;                            System.out.println(""Sequence complete."");&#xA;                        }&#xA;                    });&#xA;        }&#xA;&#xA;     public Observable&lt;String&gt; function1(String id) {&#xA;                // This is where we make network call&#xA;                Observable&lt;Response&gt; response = Rx.newClient(RxObservableInvoker.class)&#xA;                        .target(""http://example.com/resource"")&#xA;                        .request()&#xA;                        .queryParam(""id"", id)&#xA;                        .rx()&#xA;                        .get();&#xA;                response.obserOn(Schedulers.from(threadExecutor)).flatMap(response-&gt;{&#xA;                    return response.extractResponse();&#xA;                });&#xA;   }&#xA;}&#xA;</code></pre>&#xA;"
38172510,How to handle network calls in Microservices architecture,2016-07-03 17:25:50,<networking><architecture><rx-java><haproxy><microservices>,1,889,3,0.0,1,"<p>We are using Micro services architecture where top services are used for exposing REST API's to end user and backend services does the work of querying database.</p>&#xA;&#xA;<p>When we get <strong>1 user request we make ~30k requests to backend service</strong>. We are using RxJava for top service so all 30K requests gets executed in parallel.&#xA;We are using haproxy to distribute the load between backend services.&#xA;However when we get 3-5 user requests we are getting network connection Exceptions, No Route to Host Exception, Socket connection Exception.</p>&#xA;&#xA;<p>What are the best practices for this kind of use case?</p>&#xA;"
36265833,Microservices & Versioning,2016-03-28 15:50:24,<cloud><versioning><microservices><semantic-versioning><continuous-delivery>,3,353,0,0.0,1,"<p>I'm building a cloud-native application using microservices. Eventually I have arrived at the point where I must implement proper versioning for my microservices. In most places where I've looked everyone is talking about semantic versioning these days (in general, not just for microservices).</p>&#xA;&#xA;<p>One of the principals of a microservices architecture is to <em>never deliver a breaking changeset</em>. On the other hand, semantic versioning says that one should increase the major version number when a non-backwards compatible (read ""breaking"") changeset is delivered. How are these compatible?</p>&#xA;&#xA;<p>It seems to me that semantic versioning <em>might be</em> overkill for a microservices architecture. If all public APIs are versioned (example /api/v3/getSomething) then do I really need full semantic versioning? I'm considering a scheme whereby I use a single number to identify the API version currently available (v1, v2, v3 etc.) together with a build number (or perhaps date/timestamp) that identifies the continuous integration pipeline that produced the build. Note that v3 would also still support v2 API calls until everyone using the service has moved to using v3, so v3 is the ""target version"" in a sense. So my microservice foo would look like ""foo-v3-20160503142209.jar""</p>&#xA;&#xA;<p>Are there any obvious pitfalls to this? The way I see it, clients will be guaranteed that the API is compatible if I enforce <em>never delivering breaking changeset</em> (if it changes, it is a new API version). And clients can be sure of all latest bug fixes by using the latest build number/timestamp.</p>&#xA;"
36188740,Getting Started with Lagom gives Runtime Exception,2016-03-23 21:09:58,<java><microservices><typesafe><lagom>,2,255,0,0.0,1,"<p>Installed Activator as:</p>&#xA;&#xA;<p><code>brew install typesafe-activator&#xA;</code></p>&#xA;&#xA;<p>Created a new project as:</p>&#xA;&#xA;<p><code>activator new my-first-system lagom-java</code></p>&#xA;&#xA;<p>Change to the directory and running the project as <code>activator run</code> gives:</p>&#xA;&#xA;<p><code>[info] Set current project to my-first-system (in build file:/Users/arungupta/workspaces/my-first-system/)&#xA;[info] Updating {file:/Users/arungupta/workspaces/my-first-system/}my-first-system...&#xA;[info] Resolving jline#jline;2.12.1 ...&#xA;[info] Done updating.&#xA;java.lang.RuntimeException: No main class detected.&#xA;    at scala.sys.package$.error(package.scala:27)&#xA;[trace] Stack trace suppressed: run last my-first-system/compile:run for the full output.&#xA;[error] (my-first-system/compile:run) No main class detected.&#xA;[error] Total time: 0 s, completed Mar 23, 2016 12:08:22 PM&#xA;</code></p>&#xA;&#xA;<p>Here is the JDK version:</p>&#xA;&#xA;<p><code>java version ""1.8.0_60""&#xA;Java(TM) SE Runtime Environment (build 1.8.0_60-b27)&#xA;Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)</code></p>&#xA;&#xA;<p>What's missing?</p>&#xA;"
39260387,How do I connect a somata client to a remote registry?,2016-08-31 23:10:47,<node.js><microservices>,1,26,0,0.0,1,"<p>I'm using <a href=""https://github.com/somata"" rel=""nofollow"">somata</a> as my microservices platform for the web apps I'm building. I have successfully set up multiple clients on one machine with the somata registry running on the same machine. Now I want to have a client on one machine connect to a registry on another machine. How do I connect a client to a remote registry?</p>&#xA;"
39323769,Microservices user's access credentials,2016-09-05 04:01:33,<authorization><microservices>,1,149,0,0.0,1,"<p>We are building a web application in microservices architecture.<br>&#xA;We have a service that handles the authorization (i.e user's privileges, access credentials, roles etc...) and we are considering how to pass on these credentials in the system.  </p>&#xA;&#xA;<p>We have 2 option:<br>&#xA;1. Sign those credentials in the gateway (auth and proxy service) using JWT and pass on all the information so every service could verify it (with its public key) and read the user's info.<br>&#xA;2. Every service should make a request to the authorization service for querying the user's access on every action.</p>&#xA;&#xA;<p>We are having difficulties on deciding which way is better in terms of high cohesion and loose coupling and of course making it easy for service development. </p>&#xA;"
39323491,One set of tests for each version of a microservices?,2016-09-05 03:22:18,<unit-testing><testing><tdd><bdd><microservices>,1,47,1,0.0,1,<p>With microservices do I need to create tests folders for each version of each service like this:</p>&#xA;&#xA;<h2>A</h2>&#xA;&#xA;<pre><code>- Services&#xA;  - users&#xA;     - v1&#xA;         - src&#xA;         - tests&#xA;             - functional&#xA;             - unit&#xA;             - integration&#xA;     - v2&#xA;         - src&#xA;         - tests&#xA;             - functional&#xA;             - unit&#xA;             - integration&#xA;     - v3&#xA;         - src&#xA;         - tests&#xA;             - functional&#xA;             - unit&#xA;             - integration&#xA;</code></pre>&#xA;&#xA;<h2>B</h2>&#xA;&#xA;<pre><code>- Services&#xA;    - users&#xA;       - v1&#xA;            - src&#xA;       - v2&#xA;            - src&#xA;       - v3&#xA;            - src&#xA;       - tests&#xA;            - functional&#xA;            - unit&#xA;            - integration&#xA;</code></pre>&#xA;&#xA;<h2>C</h2>&#xA;&#xA;<pre><code>- Services&#xA;   - users&#xA;      - v1&#xA;      - v2&#xA;      - v3&#xA;   - tests&#xA;      - functional&#xA;      - integration&#xA;      - unit&#xA;</code></pre>&#xA;&#xA;<h2>D</h2>&#xA;&#xA;<pre><code>- Services&#xA;   - users&#xA;      - v1&#xA;      - v2&#xA;      - v3&#xA;- Tests&#xA;    - functional&#xA;    - integration&#xA;    - unit&#xA;</code></pre>&#xA;
39172786,Docker container: Huge size for Node.js-based microservice,2016-08-26 18:36:56,<node.js><docker><microservices><seneca>,1,460,2,1.0,1,"<p>I've been playing around with setting some microservices in a Docker container where the service is based on Seneca.js. Since this is a Node.js application, I derived the container ""FROM node"". However, the container image is about 600 MB in size. Not exactly ""micro"". The eventual application will use a conglomerate of several such service and if each of them is 600+ MB in size, it will blow up the application to several GB. </p>&#xA;&#xA;<p>Am I doing something wrong or is this how you'd go about setting up a Docker-Node.js-based microservice?<br>&#xA;Thanks a lot. </p>&#xA;&#xA;<p>Cheers, </p>&#xA;&#xA;<p>Martin</p>&#xA;"
39126454,JWT validation in a micro-services architecture and public key publishing,2016-08-24 14:42:57,<microservices><public-key-exchange>,1,151,0,0.0,1,"<p>We are refactoring our web app system to a micro-services architecture.<br>&#xA;We decided to authenticate our users with <code>JWT</code> and save some authorization data in it. For example, from the payload of the token one can infer if the user can access a certain resource.</p>&#xA;&#xA;<p>We consider two options:</p>&#xA;&#xA;<ol>&#xA;<li>Each micro-service will ask the signing service (API gateway for instance) if the token is valid.</li>&#xA;<li>Every micro-service will hold the public key and validate the token itself.</li>&#xA;</ol>&#xA;&#xA;<p>In the case of managing public keys, how could the gateway service publish its public key to all the other micro-services?</p>&#xA;&#xA;<p>It seems to have lots of information out there about how to design the system but not how actually to implement those things.</p>&#xA;"
39118038,How to know if my program is completely started inside my docker with compose,2016-08-24 08:21:12,<docker><continuous-integration><docker-compose><microservices>,2,51,2,1.0,1,"<p>In my CI chain I execute end-to-end tests after a ""docker-compose up"". Unfortunately my tests often fail because even if the containers are properly started, the programs contained in my containers are not.</p>&#xA;&#xA;<p>Is there an elegant way to verify that my setup is completely started before running my tests ?</p>&#xA;"
38989659,"Getting error using mvn spring-boot:run ""A child container fail to start""",2016-08-17 06:37:27,<spring-boot><microservices>,3,5088,2,0.0,1,"<p>If I am run using my spring tool suites, then it's working fine, but while running using command prompt <strong>mvn spring-boot:run</strong> I am getting these error:</p>&#xA;&#xA;<pre><code>8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) [na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_71]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;Caused by: java.lang.SecurityException: class ""javax.servlet.http.HttpSessionIdListener""'s signer information does not match signer information of other classes in the sa&#xA;ackage&#xA;        at java.lang.ClassLoader.checkCerts(ClassLoader.java:895) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.preDefineClass(ClassLoader.java:665) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.defineClass(ClassLoader.java:758) ~[na:1.8.0_71]&#xA;        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.access$100(URLClassLoader.java:73) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:368) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:362) ~[na:1.8.0_71]&#xA;        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.findClass(URLClassLoader.java:361) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4752) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) [spring-boot-1.2.8.RELEASE.j&#xA;.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) [spring-boot-1.2.8.RELEASE.jar:1&#xA;.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) [spring-boot-1.2&#xA;ELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) [spring-boot-1.2.8.RELEASE.jar:1.2.8.&#xA;ASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) [spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RE&#xA;E]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_71]&#xA;        ... 1 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: WARN  AnnotationConfigEmbeddedWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.&#xA;icationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to st&#xA;embedded Tomcat&#xA;8564: ERROR SpringApplication - Application startup failed&#xA;org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServlet&#xA;ainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.R&#xA;SE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) ~[spring-boot-1.2.8.RELEASE.jar:&#xA;8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) ~[spring-boot-1.&#xA;RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        ... 13 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        ... 18 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 20 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 22 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 24 common frames omitted&#xA;[WARNING]&#xA;java.lang.reflect.InvocationTargetException&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;        at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.Embe&#xA;ServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133)&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118)&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959)&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23)&#xA;        ... 6 more&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130)&#xA;        ... 13 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89)&#xA;        ... 18 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 20 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 22 more&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924)&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 24 more&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD FAILURE&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 10.858 s&#xA;[INFO] Finished at: 2016-08-16T16:33:40+05:30&#xA;[INFO] Final Memory: 50M/521M&#xA;[INFO] ------------------------------------------------------------------------&#xA;[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project core.eventhub: An exception occurred while run&#xA;. null: InvocationTargetException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Un&#xA; to start embedded Tomcat: Failed to start component [StandardServer[-1]]: Failed to start component [StandardService[Tomcat]]: Failed to start component [StandardEngine[&#xA;at]]: A child container failed during start -&gt; [Help 1]&#xA;[ERROR]&#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>This is the pom.xml I am using ,</p>&#xA;&#xA;<pre><code>&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;    &lt;groupId&gt;com.hm.msp.services&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;sample.springboot&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0.0&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;    &lt;name&gt;sample-server&lt;/name&gt;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;Angel.SR6&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;start-class&gt;com.hm.msp.event.Main&lt;/start-class&gt;&#xA;        &lt;mstack.version&gt;2.0.1&lt;/mstack.version&gt;&#xA;        &lt;json-lib.version&gt;2.4&lt;/json-lib.version&gt;&#xA;        &lt;msp.blp.version&gt;0.2.0&lt;/msp.blp.version&gt;&#xA;        &lt;msp.collection.version&gt;2.0.1&lt;/msp.collection.version&gt;&#xA;        &lt;msp.bundle.version&gt;0.2.0&lt;/msp.bundle.version&gt;&#xA;        &lt;camel.version&gt;2.17.0&lt;/camel.version&gt;&#xA;        &lt;xbean-spring-version&gt;4.5&lt;/xbean-spring-version&gt;&#xA;        &lt;!--following activemq version has dependencies. If you upgrade activemq &#xA;            libs make sure to pick up the right version --&gt;&#xA;        &lt;activemq-version&gt;5.11.1&lt;/activemq-version&gt;&#xA;        &lt;activemq-pool-version&gt;5.7.0&lt;/activemq-pool-version&gt;&#xA;        &lt;logback-version&gt;1.1.3&lt;/logback-version&gt;&#xA;        &lt;storm.version&gt;0.10.0&lt;/storm.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;&#xA;            &lt;!-- &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt; --&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-context&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.5&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;commons-logging&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Testing starter --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Setup Spring Data JPA Repository support --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;&#xA;        &lt;!-- Spring Cloud starter --&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;mysql&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&#xA;            &lt;version&gt;5.1.38&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;!-- Swagger dependency for mIDAS webservice --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.swagger&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;swagger-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.5.8&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storm-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${storm.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-spring-boot-starter&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-kafka&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;netty&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;io.netty&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&#xA;    &lt;/dependencies&gt;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;finalName&gt;${project.name}&lt;/finalName&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;"
39096701,DDD User-Domain specific settings,2016-08-23 08:57:59,<domain-driven-design><microservices>,1,150,12,1.0,1,"<p>I am currently developing micro service responsible for authentication (bounded context responsible for identity and permissions). We have specific settings based on user roles which are tied to another domains, but used to generate tokens</p>&#xA;&#xA;<p>(something like this <a href=""https://developer.zendesk.com/rest_api/docs/core/custom_roles"" rel=""nofollow"">https://developer.zendesk.com/rest_api/docs/core/custom_roles</a>)</p>&#xA;&#xA;<p>For an example</p>&#xA;&#xA;<pre><code>role_can_write_booking: true,&#xA;fetch_products_type : ""all/forUsersCompanyOnly""&#xA;</code></pre>&#xA;&#xA;<p>etc.</p>&#xA;&#xA;<p>Should I persist this information as a part of Identity BC, or each domain should persist it's part of settings.&#xA;Example:&#xA;<code>role_can_write_booking : true</code> inside Booking Bounded Context,&#xA;<code>fetch_products_type : ""all/forUsersCompanyOnly""</code> inside Booking products bounded context. ?</p>&#xA;"
37180556,Validate types in PactNet,2016-05-12 07:50:44,<c#><testing><microservices><pact><pact-net>,2,544,0,1.0,1,"<p>I am testing micro services and I'm using <a href=""https://github.com/SEEK-Jobs/pact-net"" rel=""nofollow"">PactNet</a> to create and validate pacts. I am finding that the tests are too brittle, as the verifier is checking for exact values and not verifying the types.</p>&#xA;&#xA;<p>For example, I am testing against the GitHub API and the test works. If a new Repo is added, the <code>public_repos</code> value increases by one and the test fails.</p>&#xA;&#xA;<p>Is anyone using this to check the types instead of the concrete values?</p>&#xA;&#xA;<p>Here is the verification code:</p>&#xA;&#xA;<pre><code>[Test]&#xA;public void VerifyPact()&#xA;{&#xA;&#xA;    // Arrange.&#xA;    var pactVerifier = new PactVerifier(() =&gt; { }, () =&gt; { });&#xA;    pactVerifier.ProviderState(""There is call with the name 'karlgjertsen'"");&#xA;&#xA;    // Act.&#xA;    using (var client = new HttpClient { BaseAddress = new Uri(""https://api.github.com/users/karlgjertsen"") })&#xA;    {&#xA;&#xA;        client.DefaultRequestHeaders.Accept.Clear();&#xA;        client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;        client.DefaultRequestHeaders.Add(""User-Agent"", ""Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident / 6.0)"");&#xA;&#xA;        // Assert.&#xA;        pactVerifier&#xA;            .ServiceProvider(""GitHub API"", client)&#xA;            .HonoursPactWith(""Pact Test"")&#xA;            .PactUri(@""C:\Pact\pacts\pact_test-git_api.json"")&#xA;            .Verify();&#xA;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And here's the PACT file.</p>&#xA;&#xA;<pre><code>{&#xA;  ""provider"": {&#xA;    ""name"": ""GitHub API""&#xA;  },&#xA;  ""consumer"": {&#xA;    ""name"": ""PACT Test""&#xA;  },&#xA;  ""interactions"": [&#xA;    {&#xA;      ""description"": ""A GET request for user deatils for 'karlgjertsen'"",&#xA;      ""provider_state"": ""There is call with the name 'karlgjertsen'"",&#xA;      ""request"": {&#xA;        ""method"": ""get"",&#xA;        ""path"": ""/users/karlgjertsen"",&#xA;        ""headers"": {&#xA;          ""Accept"": ""application/json""&#xA;        }&#xA;      },&#xA;      ""response"": {&#xA;        ""status"": 200,&#xA;        ""headers"": {&#xA;          ""Content-Type"": ""application/json; charset=utf-8""&#xA;        },&#xA;        ""body"": {&#xA;          ""login"": ""karlgjertsen"",&#xA;          ""id"": 4457667,&#xA;          ""avatar_url"": ""https://avatars.githubusercontent.com/u/4457667?v=3"",&#xA;          ""gravatar_id"": """",&#xA;          ""url"": ""https://api.github.com/users/karlgjertsen"",&#xA;          ""html_url"": ""https://github.com/karlgjertsen"",&#xA;          ""followers_url"": ""https://api.github.com/users/karlgjertsen/followers"",&#xA;          ""following_url"": ""https://api.github.com/users/karlgjertsen/following{/other_user}"",&#xA;          ""gists_url"": ""https://api.github.com/users/karlgjertsen/gists{/gist_id}"",&#xA;          ""starred_url"": ""https://api.github.com/users/karlgjertsen/starred{/owner}{/repo}"",&#xA;          ""subscriptions_url"": ""https://api.github.com/users/karlgjertsen/subscriptions"",&#xA;          ""organizations_url"": ""https://api.github.com/users/karlgjertsen/orgs"",&#xA;          ""repos_url"": ""https://api.github.com/users/karlgjertsen/repos"",&#xA;          ""events_url"": ""https://api.github.com/users/karlgjertsen/events{/privacy}"",&#xA;          ""received_events_url"": ""https://api.github.com/users/karlgjertsen/received_events"",&#xA;          ""type"": ""User"",&#xA;          ""site_admin"": false,&#xA;          ""name"": ""Karl Gjertsen"",&#xA;          ""company"": ""infiniforms.io"",&#xA;          ""blog"": ""http://www.karlgjertsen.com"",&#xA;          ""location"": ""UK"",&#xA;          ""email"": null,&#xA;          ""hireable"": null,&#xA;          ""bio"": null,&#xA;          ""public_repos"": 1,&#xA;          ""public_gists"": 0,&#xA;          ""followers"": 0,&#xA;          ""following"": 0,&#xA;          ""created_at"": ""2013-05-17T14:05:30Z"",&#xA;          ""updated_at"": ""2016-03-07T19:39:58Z""&#xA;        }&#xA;      }&#xA;    }&#xA;  ],&#xA;  ""metadata"": {&#xA;    ""pactSpecificationVersion"": ""1.1.0""&#xA;  }&#xA;}&#xA;</code></pre>&#xA;"
37176069,Docker container A dies after excuting query(insert/update) in cassandra running as another docker service B,2016-05-12 02:05:36,<python><docker><cassandra><microservices>,1,149,0,3.0,1,"<p>I am new to docker,Cassandra . &#xA;well I'm facing a weird issue, any help as how I could debug this issue would be great. I am using </p>&#xA;&#xA;<pre><code> Cassandra 3.3.0, &#xA;native Cassandra-driver for python- 3.3.0 &#xA;Docker 1.11.1&#xA;</code></pre>&#xA;&#xA;<p>I have two containers one is hosting cassandra service say container A and from the other container say B i'm performing an insert query to cassandra container.&#xA;here once B executes the query to A just after this container B which is my service container dies . </p>&#xA;&#xA;<p><strong>Logs that i see in container B</strong></p>&#xA;&#xA;<pre><code>[start] application exit with code 0, killing container&#xA;</code></pre>&#xA;&#xA;<p>i dont see any other relevant logs to debug further as what is the reason so that i am container dies right after insert.</p>&#xA;&#xA;<p>Just to make sure i am not missing  any exception i am catching all exceptions&#xA;i.e BaseException . i have added few loggers their to track my issue however even container dies it never comes to this except block.</p>&#xA;&#xA;<p><strong>What i suspect</strong>  </p>&#xA;&#xA;<p>it seems docker has error in memory and the moment it will write , it dies or something else.</p>&#xA;&#xA;<p><strong>what  i tried also</strong></p>&#xA;&#xA;<p>i tried to run my code without docker container to see offending lines  if any. here without docker it works and no exceptions  comes. I also make sure  to shutdown the cassandra session. </p>&#xA;&#xA;<p>Please advise .. </p>&#xA;"
37257673,Using Hystrix to get list of services from Eureka through the circuit breakers,2016-05-16 15:33:26,<java><spring><spring-cloud><microservices><netflix-eureka>,2,416,0,1.0,1,"<p>I exploit spring-cloud. As far as I understand, when client of Eureka gets a list of services from Eureka server, it uses the Ribbon for load balancing.</p>&#xA;&#xA;<p>Does the client use Hystrix to get the list of services from Eureka through  the circuit breakers? </p>&#xA;"
44060464,Managing table which is frequently updated and queried,2017-05-19 02:27:17,<mysql><sql><scalability><microservices><bigdata>,5,44,0,0.0,1,"<p>So far, I and my friend have made a small system which is for collecting weather data from sensors placed around our area.&#xA;Here is one of table in our database:</p>&#xA;&#xA;<pre><code>CREATE TABLE `Measurement` (&#xA;  `Id` varchar(255) COLLATE utf8_unicode_ci NOT NULL DEFAULT '',&#xA;  `SensorId` varchar(16) COLLATE utf8_unicode_ci NOT NULL,&#xA;  `Time` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',&#xA;  `Battery` double DEFAULT NULL,&#xA;  `Rain` double DEFAULT NULL,&#xA;  `Humidity` double DEFAULT NULL,&#xA;  PRIMARY KEY (`Id`,`Time`)&#xA;) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;&#xA;</code></pre>&#xA;&#xA;<p><strong>Environment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>ASP.Net Framework 4.6.</li>&#xA;<li>Web API 2.</li>&#xA;<li>MySQL Community edition.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Deployment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There is one database for storing user information, weather measurement and sensor information deployed onto a single server.</li>&#xA;<li>There is one WEB API to help client app to connect to and obtain data.</li>&#xA;</ul>&#xA;&#xA;<p>Our situation is:</p>&#xA;&#xA;<p>This table is for storing climate element measurements each 10 second from 60 sensors.&#xA;For now, we are facing a problem that data is increasing drammatically, just do the simple calculation:</p>&#xA;&#xA;<p><strong>1</strong> (record each 10 second) * <strong>6</strong> (records in one hour) * <strong>24</strong> (hours a day) * <strong>365</strong> (days a year) = <strong>52 560</strong> (records a year)</p>&#xA;&#xA;<p><strong>52 560</strong> (records a year) * <strong>60</strong> (sensors) = <strong>3 153 000</strong> (records)</p>&#xA;&#xA;<p>So, after a year of collecting data from <strong>60</strong> sensors, we have <strong>3 153 000</strong> records. That is too many records to store into one table (in my opinion).&#xA;That's why I'm thinking about a solution that:&#xA;- Divide measurement data of sensors into many database and deploy onto many servers. Each sensor will have one small PC to store its information (by using API)&#xA;- When user want to query database to search for their needed information, base on the information of sensor that they provide, Web server will make calls to different API endpoint to obtain data and summarize information then display them to UI.</p>&#xA;&#xA;<p>My question is:</p>&#xA;&#xA;<ul>&#xA;<li>Exclude the cost of PC we use to deploy our database and micro service of whether measurement. Is this deployment an efficient practise ?</li>&#xA;<li>Are there any way to manage this kind of Measurement table ? (Data is increasing each 10 second and can be queried many times) ?</li>&#xA;<li>If there is a way to optimize my table, please let me know ?</li>&#xA;<li>Should I deploy sensor measurement collecting function as micro services to increase performance and scalability ?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you,</p>&#xA;"
44131588,Is it a good practise to share models between Microservice and Client library projects?,2017-05-23 09:58:43,<client><microservices>,2,315,0,1.0,1,"<p>I am creating a REST microservice and a Client library for it. For both of them, I am going to use the same language (C# in this case). </p>&#xA;&#xA;<p>Is it a good practice to share Response/Request models between those projects? Or my Client project should be independent and so have own (and actually the same) models?</p>&#xA;"
44114755,How to do 2 phase commit between two micro-services(Spring-boot)?,2017-05-22 13:55:56,<spring-boot><microservices><distributed-transactions><2phase-commit>,2,892,0,0.0,1,"<p>I Have two mico-serives A and B where they connect to seperate database, From Mico-serives A i need to persist(save) objects of both A and B in same transtation how to achive this.</p>&#xA;&#xA;<p>I am using Spring micro-servies with netflix-oss.Please give suggestions on best way to do achive 2 phase commit.</p>&#xA;"
44000812,consul - connect client to server,2017-05-16 11:56:48,<service><microservices><consul><service-discovery>,1,663,0,0.0,1,"<p>I'm new at consul and I try to setup a server-client environment. I have started my server with the following command and configuration:</p>&#xA;&#xA;<pre><code>consul.exe agent -ui -config-dir=P:\Consule\config&#xA;</code></pre>&#xA;&#xA;<p>The config file looks the following (""P:\Consule\config\server.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""bootstrap"": false,&#xA;    ""server"": true,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""P:\\Consule\\data"",&#xA;    ""log_level"": ""INFO""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Output when I start consul from commandline with above command:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Consul agent running!&#xA;       Version: 'v0.8.3'&#xA;       Node ID: '1a244456-e725-44be-0549-33603ea7087d'&#xA;       Node name: 'MYCOMPUTERNAMEA'&#xA;       Datacenter: 'myservices'&#xA;       Server: true (bootstrap: false)&#xA;       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600)&#xA;       Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)&#xA;       Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false&#xA;       Atlas: &lt;disabled&gt;&#xA;</code></pre>&#xA;&#xA;<p>Now, at another computer in my domain I try to run an consul client with follwoing commandline and config-file:</p>&#xA;&#xA;<pre><code>consul.exe agent -config-dir C:\Consul -bind=127.0.0.1&#xA;</code></pre>&#xA;&#xA;<p>Config file (""C:\Consul\client.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""server"": false,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""C:\\TEMP"",&#xA;    ""log_level"": ""INFO"",&#xA;    ""start_join"": [""MYCOMPUTERNAMEA""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I always get follwing output/error message:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Joining cluster...&#xA;==&gt; 1 error(s) occurred:&#xA;&#xA;* Failed to join &lt;IP_OF_MYCOMPUTERNAMEA&gt;: dial tcp &lt;IP_OF_MYCOMPUTERNAMEA&gt;:8301: connectex: No connection could be made because the target machine actively refused it.&#xA;</code></pre>&#xA;&#xA;<p>Does anyone know what I'm doing wrong?</p>&#xA;&#xA;<p>Thanks and best regards</p>&#xA;"
44113228,How API gateway is correctly used in Microservice?,2017-05-22 12:45:52,<microservices><spring-cloud><netflix-zuul><netflix-feign><api-gateway>,2,434,0,1.0,1,"<p>Suppose there are 2 backend services:</p>&#xA;&#xA;<ol>&#xA;<li>A product service (to get the product info),</li>&#xA;<li>An inventory service (to get the available quantity).</li>&#xA;</ol>&#xA;&#xA;<p>Additionally to that, there is a frontend web application to display product details.</p>&#xA;&#xA;<p>All the examples I see on the internet are about the frontend and the API gateway being the same application and using Zuul just as a reverse proxy.</p>&#xA;&#xA;<p>My understanding is API gateway should be a separate application (layer) and frontend application should use it to call backend services. </p>&#xA;&#xA;<p>In that case what is the benefits of Zuul? why not just use feign to create a client for both services and provide an endpoint for the frontend application ? </p>&#xA;"
44038536,How to work on single gateway based microservice in a team?,2017-05-18 04:22:09,<java><jhipster><microservices>,2,183,0,0.0,1,"<p>We are developing microservice based application using Jhipster. For that, there are different components should run at the same time i.e, service registry, UAA server, Gateway, and other different services. To run all these components on my PC it consumes all the resources (16 GB of Ram). However, other developers, they don't have sufficient resources on their PC, which is the reason we are facing the problems continues development in the team.&#xA;So we are seeking some options for this problem to get efficiency over our development team.</p>&#xA;&#xA;<p>Currently, if someone wants to add/change features on the application, he needs to work with both microservice and gateway(for the frontend).&#xA;So, in this case, <strong>what happen? suppose multiple developers are working on gateway and service at the same time in the development environment.&#xA;How are they going to debug/test?</strong> do they have to deploy gateway individually?</p>&#xA;&#xA;<p>We are planning to deploy microservices on our own VPS server and in near future for the production heroku, kubernetes, jenkins, cloudfoundry can be used.</p>&#xA;&#xA;<p>Correct me if I am wrong and is there any better option for smooth development?</p>&#xA;&#xA;<p>I had read Sam Neuman's Microservice book that the problem of the single gateway based application while development.Now I am very curious about how Jhipster came to resolve this problem.</p>&#xA;"
44169046,How to manage microservice failure?,2017-05-24 21:49:57,<microservices>,4,227,1,0.0,1,"<p>Let's say, I have several micro-services (REST API), the problem is, if one service is not accessible (let's call service ""A"" ) the data which was sending to service ""A"" will be saved in temporary database. And after service worked, the data will be sent again. &#xA;Question:&#xA;1. Should I create the service which pings to service ""A"" in every 10 seconds to know service works or not? Or is it possible to do it by task queue? Any suggestions? </p>&#xA;"
44063886,How to achieve orchestration with spring boot micro service?,2017-05-19 07:21:59,<spring-boot><microservices><orchestration>,1,1793,2,0.0,1,<p>what is best way to orchestrate micro services in spring boot.</p>&#xA;
44186109,Share Domain DLL between webjob and web api?,2017-05-25 17:09:14,<c#><azure><domain-driven-design><microservices>,1,208,4,0.0,1,<p>I use webjob to process messages queue and web API to process REST request.&#xA;What is the solution for share domain between this two application types that have the same bounded context? &#xA;Can I reference the same Domain DLL or it is a bad design choose?</p>&#xA;
38466167,Microservice in Google App engine,2016-07-19 18:40:32,<python><google-app-engine><google-cloud-platform><microservices>,1,730,8,0.0,1,"<p>I plan to switch from a single app on a project to multiple apps on a project.&#xA;One being the current non-UI app and one will be based on Django.&#xA;I'm writing the code in Python2.7</p>&#xA;&#xA;<p>I saw google example of app.yaml, but there is no examples for 2 or more apps.&#xA;There is already a similar question. but still with no example (<a href=""https://stackoverflow.com/questions/38125926/run-google-app-engine-application-with-microservice"">Run Google App Engine application with microservice</a>)</p>&#xA;&#xA;<p>How do i call Django microservice/module and how do i call the other app (microservice/module)?</p>&#xA;&#xA;<p>My current structure is:</p>&#xA;&#xA;<pre><code>main_app directory&#xA;- dj (django app)&#xA;-- dj.yaml&#xA;-- manage.py&#xA;-- __init__.py (empty)&#xA;-- polls (from django tutorial)&#xA;-- mysite (from django tutorial)&#xA;- otherapp&#xA;-- otherapp.yaml&#xA;-- something.py&#xA;- app.yaml&#xA;- cron.yaml&#xA;</code></pre>&#xA;&#xA;<p>Here is a part of my app.yaml (that should control both apps):</p>&#xA;&#xA;<pre><code>runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;&#xA;handlers:&#xA;- url: /.*&#xA;  script: main.app&#xA;- url: /uploadcsv/.*&#xA;  script: main.app&#xA;&#xA;&#xA;libraries:&#xA;- name: MySQLdb&#xA;  version: ""latest""&#xA;</code></pre>&#xA;"
42379365,How to see the output of a service in a docker stack?,2017-02-21 22:40:31,<docker><docker-compose><microservices><docker-swarm>,1,1050,0,0.0,1,"<p>With Docker Compose, when we run <code>docker-compose up</code> we see the output of all services being presented on the console, even with different colors to make it easier to distinguish them. Even if we have multiple instances of a service, the output of all of them appears there.</p>&#xA;&#xA;<p>Now, today I've tried deploying a stack to a swarm with Docker Compose v3 for the first time.</p>&#xA;&#xA;<p>After I do</p>&#xA;&#xA;<pre><code>docker deploy stack --compose-file=docker-compose.yml the_stack&#xA;</code></pre>&#xA;&#xA;<p>I can see the services running by using </p>&#xA;&#xA;<pre><code>docker service ls&#xA;</code></pre>&#xA;&#xA;<p>However, I'd like to see the output of the services as in Docker Compose.</p>&#xA;&#xA;<p>For instance, if I have a service <code>background_worker</code> with 3 replicas running in one node, I'd like to be able to see in that node the output of these replicas as I do with Docker Compose.</p>&#xA;&#xA;<p>How can I see the output of a replicated service deployed in a Docker Stack with Docker Swarm?</p>&#xA;&#xA;<p><strong>Edit</strong>: As answered, I need to enable experimental options on your docker daemon, however, I'm running this inside a docker-machine created with the hyperv driver, since it is not yet possible to run a multi-node swarm with Docker for Windows. How can I enable this inside the docker machine?</p>&#xA;"
42265210,Eureka Ribbon LoadBalancer Cache update delay,2017-02-16 04:50:14,<spring-boot><microservices><netflix-eureka><service-discovery><netflix-ribbon>,1,352,0,0.0,1,"<p>I am setting up a micro service based application, where Aggregation layer / API gateway makes calls to micro services. Eureka is used for service discovery and Ribbon for providing a load balancing RestTemplate.</p>&#xA;&#xA;<p>Postman calls Aggregation--> Aggregation calls Micro service using Eureka/Ribbon/RestTemplate.</p>&#xA;&#xA;<p>I have 4 instances of one micro services type running on my machine on 4 different ports. Hitting the same REST endpoint repeatedly Postman causes the requests to get load balanced properly in a round robin fashion.</p>&#xA;&#xA;<p>When I stop one of the micro service instances the service is deregistered from Eureka, but the LoadBalancer still sends requests to the dead service and the call fails.</p>&#xA;&#xA;<p>Below is my code:</p>&#xA;&#xA;<p><strong>Aggregation:</strong></p>&#xA;&#xA;<pre><code> @Configuration&#xA;    @ComponentScan(basePackages = {""com.mycompany.aggregator""})&#xA;    @EnableAutoConfiguration&#xA;    @EnableEurekaClient&#xA;    public class AggregatorApplication {&#xA;&#xA;        public static void main(String[] args) {&#xA;            SpringApplication.run(AggregatorApplication.class, args);&#xA;        }&#xA;    }&#xA;&#xA;**Configuration:**&#xA;@Configuration&#xA;public class AggregatorConfig {&#xA;&#xA;    @Bean&#xA;    @LoadBalanced&#xA;    public RestTemplate restTemplate() {&#xA;        return new RestTemplate();&#xA;    }&#xA;}&#xA;&#xA;@Configuration&#xA;@RibbonClient(name=""microservice"", configuration = FooConfig.class)&#xA;public class TestConfig {&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>//FooConfig is excluded from component-scan</p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class FooConfig {&#xA;&#xA;    @Bean&#xA;    public IPing ribbonPing(IClientConfig config) {&#xA;        return new NIWSDiscoveryPing();&#xA;    }&#xA;&#xA;    @Bean&#xA;    public IRule ribbonRule(IClientConfig config) {&#xA;        return new AvailabilityFilteringRule();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>restTemplate call:</p>&#xA;&#xA;<pre><code>ResponseEntity&lt;Object&gt; responseEntity = restTemplate.getForEntity(myUrl, Object.class);&#xA;</code></pre>&#xA;&#xA;<p>Properties:</p>&#xA;&#xA;<pre><code>spring.application.name=aggregator&#xA;server.contextPath=/ott&#xA;server.port = 8090&#xA;my.url=http://microservice&#xA;eureka.instance.leaseRenewalIntervalInSeconds=1&#xA;eureka.instance.leaseExpirationDurationInSeconds=2&#xA;</code></pre>&#xA;&#xA;<p><strong>MicroService Code:</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaClient&#xA;public class MicroServiceApplication&#xA;</code></pre>&#xA;&#xA;<p>Properties:</p>&#xA;&#xA;<pre><code>spring.application.name=microservice&#xA;server.contextPath=/ott&#xA;server.port = 9000&#xA;eureka.instance.leaseRenewalIntervalInSeconds=1&#xA;eureka.instance.leaseExpirationDurationInSeconds=2&#xA;</code></pre>&#xA;&#xA;<p><strong>Eureka Server:</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class EurekaserverApplication {&#xA;</code></pre>&#xA;&#xA;<p>Properties:</p>&#xA;&#xA;<pre><code>server.port=8761&#xA;&#xA;eureka.server.enableSelfPreservation=false&#xA;eureka.client.registerWithEureka=false&#xA;eureka.client.fetchRegistry=false&#xA;&#xA;logging.level.com.netflix.eureka=OFF&#xA;logging.level.com.netflix.discovery=OFF&#xA;</code></pre>&#xA;"
42331661,"Google Cloud projects, how are they supposed to work as organizational units?",2017-02-19 19:14:15,<google-app-engine><cloud><google-cloud-platform><development-environment><microservices>,2,108,0,0.0,1,"<p>Google Cloud's structure related to ""projects"" has me really confused.</p>&#xA;&#xA;<p>On the one hand all GCP services are encapsulated in a ""project"" right? So I think, OK I'll create something like ""test"", ""stage"", and ""prod"" projects. All my applications can be tested in ""test"" and eventually move to ""prod"" when they are ready to go live. Also, I can have SQL,bigquery,bigtable and whatever else in the test project that developers can hack on without having to worry about effecting production.</p>&#xA;&#xA;<p>But I can only have one app engine app per project? How does that work? I can see how in app engine you have different versions so if I have one project per app engine app the test/staging mechanism is in that app's project, but what about the other GCP services?</p>&#xA;&#xA;<p>If I have a bigtable or bigquery or something on storage multiple apps need to access what ""project"" do I put that stuff in? </p>&#xA;&#xA;<p>Do I still have a ""test"",""stage"",""prod"" project for my services (where my DBs, storage, etc live), but then also create separate projects for each app engine app?</p>&#xA;&#xA;<p>If multiple apps need to access something, it can live in one of the app's projects- that doesn't make sense.</p>&#xA;&#xA;<p>Edit: google does have some good docs about how projects and services can be organized <a href=""https://cloud.google.com/appengine/docs/python/creating-separate-dev-environments"" rel=""nofollow noreferrer"">https://cloud.google.com/appengine/docs/python/creating-separate-dev-environments</a></p>&#xA;"
42353292,Does Service Discovery microservice break idea of loose coupling?,2017-02-20 20:02:25,<microservices><service-discovery>,4,120,0,1.0,1,"<p>As a mechanism to connect microservices together and make them work it is usually suggested to use APIs and Service Discovery. But they usually work as their own microservices, but these ones should apparently be ""hard-coded"" into others, as every microservice is supposed to register with them and query for other microservices' locations. Doesn't this break the idea of loose coupling, since a loss of a discovery service implies others being unable to communicate?</p>&#xA;"
42240919,How To Design The Layers in Azure Service Fabric,2017-02-15 04:44:52,<azure><architecture><microservices><azure-service-fabric>,1,166,0,1.0,1,"<p>I have been assigned to think of a layered microservices architecture for Azure Service Fabric. But my experience mostly been on monolithic architectures I can't come up with a specific solution.</p>&#xA;&#xA;<p>What I have thought as of now is like...</p>&#xA;&#xA;<p><strong>Data Layer -</strong> This is where all the Code First entities resides along with DBContext.</p>&#xA;&#xA;<p><strong>Business Layer -</strong> This is where all the Service Managers would be performing and enforcing the Business Logic i.e. UserManager (IUserManager), OrderManager (IOrderManager), InvoiceManager (IInvoiceManager) etc.</p>&#xA;&#xA;<p><strong>WebAPI (Self Hoted Inside Service Fabric) -</strong> Although this WebAPI is inside Service Fabric but does nothing except to receive the request and call respectic Services under Service Fabric. WebAPI Layer would also do any Authentication and Authorization (ASP.NET Identity) before passing on the call to other services.</p>&#xA;&#xA;<p><strong>Service Fabric Services -</strong> UserService, OrderService, InvoiceService. These services are invoked from WebAPI Layer and DI the Business Layer (IUserManager, IOrderManager, IInvoiceManager) to perform it's operation.</p>&#xA;&#xA;<p>Do you think this is okay to proceed with?</p>&#xA;&#xA;<p>One theoretical issue though, while reading up for several microservices architecture resources, I found that, all of them suggests to have Business Logic inside the service so that the specific service can be scaled independently. So I believe, I'm violating the basic aspect of microservices.</p>&#xA;&#xA;<p>I'm doing this because, the customer requirement is to use this Business Layer across several projects, such as Batch Jobs (Azure Web Jobs), Backend Dashboard for Internal Employees (ASP.NET MVC) etc. So If I don't keep the Business Layer same, I have to write the same Business Logic again for Web Jobs and Backend Dashboard which I feel is not a good idea. As a simple change in Business Logic would require change in code at several places then.</p>&#xA;&#xA;<p>One more concern is, in that case, I have to go with Service to Service communication for ACID transactions. Such as, while creating an Order, a Order and Invoice both must be created. So in that case, I thought of using Event Driven programming i.e. Order Service will emit an event which the Invoice Service can subscribe to, to create Invoice on creation of Order. But the complications are if the Invoice Service fails to create invoice, it can either keep trying do that infinitely (which is a bad idea I think), or emit another event to Order Service to subscribe and roll back the order. There can be lots of confusion with this.</p>&#xA;&#xA;<p>Also, I must mention that, we are using a Single Database as of now.</p>&#xA;&#xA;<p>So my questions are...</p>&#xA;&#xA;<ol>&#xA;<li>What issue do you see with my approach? Is it okay?</li>&#xA;<li>If not, please suggest me a better approach. You can guide me to some resources for implementation details or conceptual details too.</li>&#xA;</ol>&#xA;&#xA;<p><strong>NOTE :</strong> The requirement of client is, they can scale specific module in need. Such as, UserService might not be used much as there won't be many signups daily or change in User Profile, but OrderService can be scaled along as there can be lots of Orders coming in daily. </p>&#xA;&#xA;<p>I'll be glad to learn. As this is my first chance of getting my hands on designing a microservices architecture.</p>&#xA;"
42230797,Spring Cloud Stream Kafka - Eventual consistency - Does Kafka auto retry unacknowledged messages (when using autocommitoffset=false),2017-02-14 16:02:42,<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,1,689,0,0.0,1,"<p>Implementing an eventually consistent distributed architecture has turned out to be a pain. There are tons of blog posts telling stories about how to do it, but not showing (code) how to actually do it.</p>&#xA;&#xA;<p>One of the aspects I'm suffering is having to deal with manual retries of the messages when they haven't been ack'd.</p>&#xA;&#xA;<p>For instance: my order service sends a pay event to Kafka. Payment Service is subscribed to it and processes it, answering with payment ok or payment failure</p>&#xA;&#xA;<ol>&#xA;<li><p>Ask for payment: <code>Order Service ----Pay event----&gt; Kafka ----Pay Event ----&gt; Payment Service</code></p></li>&#xA;<li><p>Payment OK: -> <code>Payment Service ----Payment ok event ----&gt; Kafka ----Payment ok Event ----&gt; Order Service</code></p></li>&#xA;<li><p>Payment Fail -> <code>Payment Service ----Payment failure event ----&gt; Kafka ----Payment failure Event ----&gt; Order Service</code></p></li>&#xA;</ol>&#xA;&#xA;<p>The point is: </p>&#xA;&#xA;<p>I know for sure when a message has been delivered to Kafka by using sync sendings. BUT, the only way I have to know that the payment has been processed by Payment Service is by expecting an answer event (Payment ok| Payment failure).</p>&#xA;&#xA;<p>This forces me to implement a retry mechanism in Order server. If it hasn't gotten an answer in some time, retry with a new Pay event.</p>&#xA;&#xA;<p>What's more, this also forces me to take care of duplicated messages in Payment Service in case they were actually processed but the answer didn't get to Order Service.</p>&#xA;&#xA;<p><strong>I was wondering if Kafka has a built in mechanism to send retries if the consumer didn't acknowledge the new offset of the messages</strong>.</p>&#xA;&#xA;<p>In Spring Cloud Stream we can set a <code>autoCommitOffset</code> property to false and handle the ack of the offset in the consumer:</p>&#xA;&#xA;<pre><code> @StreamListener(Sink.INPUT)&#xA; public void process(Message&lt;?&gt; message) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         System.out.println(""Acknowledgment provided"");&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p><strong>What happens if we don't execute <code>acknowledgment.acknowledge();</code> Will the message be automatically resent by Kafka to this consumer?</strong></p>&#xA;&#xA;<p>If it is possible we wouldn't need to retry manually any more and could do stuff like this:</p>&#xA;&#xA;<p>Paymen Service:</p>&#xA;&#xA;<pre><code> @Autowired&#xA; private PaymentBusiness paymentBusiness;&#xA;&#xA; @StreamListener(Sink.INPUT)&#xA; public void process(Order order) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         paymentBusiness(order);            &#xA;         //If we don't get here because of an exception &#xA;         //Kafka would retry...&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>If this were possible, how is the retry period configured in Kafka?</p>&#xA;&#xA;<p>In the worst case (and most likely) scenario, this isn't supported and we would have to retry manually. Do you know any real example of Spring Cloud Stream apps dealing with eventual consistency using Kafka?</p>&#xA;"
42360790,"Why do I need to deploy a ""default"" app before I can deploy multiple services in GAE?",2017-02-21 07:08:05,<python><google-app-engine><google-cloud-platform><microservices>,1,505,0,0.0,1,"<p>Reading <a href=""https://cloud.google.com/appengine/docs/python/tools/uploadinganapp"" rel=""nofollow noreferrer"">this doc</a> it says ""You must initially deploy a version of your app to the default service before you can create and deploy subsequent services.""</p>&#xA;&#xA;<p>I don't understand this because I thought the GAE microservices were separate things as in:&#xA;<a href=""https://i.stack.imgur.com/VS8x1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VS8x1.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But it seems this is not an accurate depiction of how GAE microservices work? Is there like a master controller ""default"" service that sets top level config or does some kind of routing? If I'm just running a bunch of non web apps (meaning apps that wil run on a scheduled and process data) and a frontend ""app"" for accepting web requests isn't necessary than why do I still need to create the default service?</p>&#xA;"
42311050,How to register spring boot microservices on spring cloud Netflix eureka?,2017-02-18 04:28:10,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix>,2,1029,1,0.0,1,"<p>We were planning to use spring cloud Netflix oss components. So I was doing a small sample project.&#xA;I developed 2 spring microservices and those services runs well on &#xA;<a href=""http://localhost:9000/microsvc-one"" rel=""nofollow noreferrer"">http://localhost:9000/microsvc-one</a> <a href=""http://localhost:9001/microsvc-two"" rel=""nofollow noreferrer"">http://localhost:9001/microsvc-two</a> </p>&#xA;&#xA;<p>And also wrote a sample spring cloud etflix eureka maven project which runs well on&#xA;<a href=""http://localhost:8761"" rel=""nofollow noreferrer"">http://localhost:8761</a></p>&#xA;&#xA;<p>I used annotations @EurekaDiscoveryClient and @SpringBootApplication on both the spring boot microservices main class</p>&#xA;&#xA;<p>I used annotation @EnableEurekaServer and @SpringBootApplication</p>&#xA;&#xA;<p>Now I am facing a problem in registering those services in eureka server. I referred some samples. I am not understanding those.&#xA; I did some changes in  application.yml files of microsvc-one and microsvc-two and also application.yml file of eureka server.&#xA;But still it shows empty. </p>&#xA;&#xA;<p>What all changes are required or missing or correct configuration to be done so that my services are being registered on eureka.</p>&#xA;&#xA;<p>I also have other question like do i need to create a separate project which has @EnableConfigServer and @SpringBootApplication Annotations other than the above 2 microservices and eureka server project module to register the services on eureka.&#xA;I see those in most of the examples.</p>&#xA;&#xA;<p>If yes..how do we link between all these?</p>&#xA;"
42190315,splitter aggregator pattern with microservices,2017-02-12 16:44:17,<spring-boot><apache-camel><spring-integration><microservices>,1,439,1,0.0,1,"<p>I need to create a system that does the following:</p>&#xA;&#xA;<ol>&#xA;<li>receive uploaded file via http multipart request - and return 200 ok upon success</li>&#xA;<li>passing the uploaded file to multiple external services</li>&#xA;<li>wait to all results from external services , and calculating the final response</li>&#xA;<li>return the response to a activemq as a publisher</li>&#xA;</ol>&#xA;&#xA;<p>there are some constraints:</p>&#xA;&#xA;<ol>&#xA;<li><p>those external services are services of 3rd party companies, so some of them might be using different apis/protocols.</p></li>&#xA;<li><p>i want to be able to plug &amp; unplug 3rd party vendors at runtime.</p></li>&#xA;<li>be able to support scaling of multiple instances from the same vendor to enhance performance</li>&#xA;</ol>&#xA;&#xA;<p>my thought process has brought me so far:</p>&#xA;&#xA;<ol>&#xA;<li>using spring-integration or apache camel as a splitter-aggregator pattern module</li>&#xA;<li>each 3-rd party vendor will be an independent spring boot application</li>&#xA;<li>the entry point to the the application will be another spring boot application</li>&#xA;</ol>&#xA;&#xA;<p>i have some open questions</p>&#xA;&#xA;<ol>&#xA;<li><p>i still don't know what is the best way to pass the files between the different services? by message queue? just proxy the request to multiple microservices?</p></li>&#xA;<li><p>how to support plug &amp; unplug at run time?</p></li>&#xA;</ol>&#xA;&#xA;<p>any pointers or help will be very helpful!</p>&#xA;"
42178648,Miroservices interservice communication with Sockets,2017-02-11 17:03:11,<node.js><sockets><network-programming><microservices>,1,241,2,0.0,1,"<p>I'm currently designing a system for the following scenario:&#xA;Data is streamed from a client, being processes by multiple services one after the other (no parallel). Then, the data is streamed back to the client while it's being analyzed. It's important that the server will return to the client partial analyzed data during the process (That's why I need sockets).</p>&#xA;&#xA;<p>The client can even send more information during the analyze on the server and it may impact the analysis results.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hS4bp.png"" rel=""nofollow noreferrer"">A high level sketch I made</a></p>&#xA;&#xA;<p>I have made a lot of research into this, and I have seen only <strong>REST microservices</strong> OR async processing with sockets using all kinds of <strong>messaging queues</strong>. &#xA;I have not seen anyone who implements microservices with so many opened sockets directly between the services. </p>&#xA;&#xA;<p>Now for my question:&#xA;Am I doing the right thing here? Is opening sockets between all of my servers is wrong or unreliable?</p>&#xA;"
43238799,Tools for Monitoring Restful Services,2017-04-05 18:19:19,<.net><monitoring><microservices><restful-architecture>,2,78,0,0.0,1,"<p>When coming to monitoring synchronous restful APIs that are initially developed using .net core, what are the best recommended tools that might have any of:</p>&#xA;&#xA;<ul>&#xA;<li>Performance Monitoring</li>&#xA;<li>Service Health checks</li>&#xA;<li>Logging</li>&#xA;<li>Tracing</li>&#xA;<li>Dashboards</li>&#xA;</ul>&#xA;&#xA;<p>I would be interested with any open source platform tools if available that can monitor APIs not running in containerized environments.</p>&#xA;"
43132158,How to apply different policies to service and proxy service?,2017-03-31 03:54:03,<mule><microservices>,4,213,0,0.0,1,"<p>I have a mule service, named IS, deployed on mule runtime and proxied on API gateway. I'd like to set up different policies to the IS and its proxy service. How can I do it?</p>&#xA;&#xA;<p>My environment:</p>&#xA;&#xA;<ul>&#xA;<li>Mule runtime: 3.7.4</li>&#xA;<li>Mule API gateway: 2.1.1</li>&#xA;</ul>&#xA;"
43167750,Update sorted list,2017-04-02 11:25:21,<database><algorithm><sorting><microservices><sortedlist>,1,68,1,0.0,1,"<p>I think there is common name for algorithm I am searching.</p>&#xA;&#xA;<p>I have a big list of players sorted by their score. e.g 1 million or billion players.&#xA;Every second one player is changing its score and I wish to updated sorted list to keep it sorted and I wish to know a new player position.</p>&#xA;&#xA;<p>I can update score and re-sort hole list. (not efficient)&#xA;or I can re-sort from [oldpos, newpos] (better)&#xA;or I can move player and shift other players. (best)</p>&#xA;&#xA;<p>Is there name for such algorithm?</p>&#xA;&#xA;<p>Is that correct that regular databases will not handle that task efficiently and I have to develop service in Java, C#, Go, etc that will keep sorted list in RAM and make shifts?</p>&#xA;"
43243883,"distributed transactions in microservice architecture, how to handle timeouts and failed commits",2017-04-06 00:49:46,<rest><rabbitmq><microservices><distributed-transactions>,1,787,2,0.0,1,"<p>Lets say you have a service <code>A</code> that is part of large microservice architecture, where those services communicate between each other either via REST APIs or via messaging where some broker is involved (RabbitMQ). Service <code>A</code> expose REST endpoint that needs to communicate with some 3rd party service (so with service that is not in our architecture) and to create some stuff there, when service <code>A</code> receives a response from 3rd party that everything went good there, it should persist some data from that response in its own database. </p>&#xA;&#xA;<p>What would be the best way of covering following issues, having in mind that 3rd party does not provide any idempotence mechanism.</p>&#xA;&#xA;<ol>&#xA;<li><p>Creation on 3rd party side went good, but DB write failed in service <code>A</code>. This would lead to inconsistent state, you created something on 3rd party side, but you don't have needed data about it in your own database.</p></li>&#xA;<li><p>You received timeout from 3rd party, so you can't just repeat the call, cause they are not providing any idempotence mechanism. If you repeat the call, potentially you can end with two (or more) created resources instead of one.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem number 1. could be solved having whatever retry mechanism that could retry DB call for whatever number of times. Problem with that approach is that, if service <code>A</code> instance that is repeating the DB call goes down suddenly. </p>&#xA;&#xA;<p>Presumably, better approach would be that service after successful creation on 3rd party side, publish a RabbitMQ message about successful creation. This service would listen to that message and it could do DB call when it receive the message. Having nice retry mechanism and taking benefit of ACKing messages, one could solve the issue about, <code>What if service instance goes down suddenly</code>. <strong>So in this solution service is publisher and consumer of its own message(s).</strong> Any better idea? This solution will also introduce <strong>eventual-consistency</strong>, because API caller (guy who is calling service <code>A</code> endpoint) will receive response <strong>right after</strong> successful creation on 3rd party side, <strong>but before</strong> anything is persisted in service database (what API client need actually)</p>&#xA;&#xA;<p>What about timeout problem? <strong>How one would handle timeouts from 3rd party in this case?</strong>. I don't see anything better than issuing GET calls to check do they created something. Still again that GET call can fail, but it can be repeated until it succeed. Here also marginal use case is what if service goes down in time of issuing GET calls.</p>&#xA;"
46961616,what are best practices for health checks?,2017-10-26 18:42:12,<amazon-web-services><microservices>,1,100,0,0.0,1,"<p>We have a REST API. Right now our <code>/health</code> makes an <em>smoke test</em> on every dependency we have (a database and a couple microservices) and then returns <code>200</code> if there are no errors.</p>&#xA;&#xA;<p>The problem is that not all dependencies are <em>mandatory</em> for our application to work. So while a problem accessing the database can be critical, problems accessing some microservices will only affect a small portion of our app.</p>&#xA;&#xA;<p>On top of that we have Amazon ELB. It doesn't seem right to tag our app as <em>unhealty</em> only because one dependency is <em>unhealty</em>. ELB should only try to recover the <em>unhealty</em> dependency and with that our app will be <em>healty</em> again.</p>&#xA;&#xA;<p>Which leads to the question: what should we actually check in our health-check? because it looks like we shouldn't be checking for any dependency at all. On the other hand, it's actually realy helpful to know the status of our app accessing all its dependencies (e.g for troubleshooting problems), so is it common to use some other endpoint for that purpose (say <code>/sanity</code> or <code>/diagnostics</code>)?</p>&#xA;"
47077380,Spring Cloud Services - Eureka,2017-11-02 14:10:53,<angular><spring-boot><microservices><spring-cloud>,1,630,1,0.0,1,"<p>I am trying to learn microservices using spring and spring boot , and learning to deploy into cloud platform. I am planning to create a angular 2 front-end application which communicates with my deployed microservice. Now I just going through spring cloud services eureka, Zuul , circuit breakers etc. </p>&#xA;&#xA;<ol>&#xA;<li>When I reading I found that Eureka is using for service registry for finding services each other. Here My doubt is that , When I am communicating from my angular 2 http request, I need to use these service registering?? What cloud configuration I need to follow to make a ReST API to microservice?? I am totally getting confusing what i need to push my sample microservice to cloud,Since I am a beginner. Can anyone help me to clarify these doubts??</li>&#xA;</ol>&#xA;"
43926591,Microservices on docker - architecture,2017-05-11 22:30:02,<node.js><docker><architecture><openshift><microservices>,1,316,0,0.0,1,"<p>I am building a micro-services project using docker.</p>&#xA;&#xA;<p>one of my micro-services is a listener that should get data from various number of sources.</p>&#xA;&#xA;<p>What i'm trying to achieve is the ability to start and stop getting data from sources dynamically.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/4hpqu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4hpqu.png"" alt=""architecture""></a> </p>&#xA;&#xA;<p>For example in this drawing, i have 3 sources connected to 3 dockers.</p>&#xA;&#xA;<p>My problem starts because i need to create another docker instance when a new source is available. In this example lets say source #4 is now available and i need to get his data (I know when a new source became available) but i want it to be scaled automatically (with source #4 information for listening)</p>&#xA;&#xA;<p>I came up with two solutions, each has advantages and disadvantages:</p>&#xA;&#xA;<p>1) Create a docker pool of a large number of docker running the listener service and every time a new source is available send a message (using rabbitmq but i think less relevant) to an available docker to start getting data.</p>&#xA;&#xA;<p>in this solution i'm a little bit afraid of the memory consumption of the docker images running for no reason - but it is not a very complex solution.</p>&#xA;&#xA;<p>2) Whenever a new source is becoming available create a new docker (with different environment variables) </p>&#xA;&#xA;<p>With this solution i have a problem creating the docker.&#xA;At this moment i have achieved this one, but the service that is starting the dockers (lets call it manager) is just a regular nodejs application that is executing commands on the same server - and i need it to be inside a docker container also.</p>&#xA;&#xA;<p>So the problem here is that i couldn't manage create an ssh connection from the main docker to create my new Docker.</p>&#xA;&#xA;<p>I am not quite sure that both of my solutions are on track and would really appreciate any suggestions for my problem.</p>&#xA;"
43943033,Microservices & Kafka: To couple or not to couple,2017-05-12 17:03:58,<apache-kafka><microservices><loose-coupling>,1,125,0,0.0,1,<p>I'm having a problem wrapping my mind around a probably normal setup of Microservices and Kafka we  are currently setting up. </p>&#xA;&#xA;<p>We are having one Topic in Kafka and multiple consumers reading from this Topic via separate consumer groups. &#xA;But somehow I think this could lead to coupling in terms of Microservices as we are having two consumers reading the exact data from the same Topic. Additionally we do not have any retention time for the messages and therefore I'm treating The Kafka as some Kind of data store. So I would think we should rather replicate the messages into its own topic for another Service/consumer. </p>&#xA;&#xA;<p>We are having different opinions on how this is coupling or decoupling and I'd like to hear you opinions on what I'm getting wrong because I feel like I do. Thank you for your support! </p>&#xA;
43835206,input and authentication validation in microservices and api-gateway architecture,2017-05-07 18:35:13,<node.js><express><microservices><gateway>,1,167,0,0.0,1,"<p>in short, where the input validation and authentication validation should be executed?&#xA;In api-gateway and each microservice? only in api-gateway? only in each microservice?</p>&#xA;&#xA;<p>Maybe part of it in api-gateway and part in each?</p>&#xA;&#xA;<p>Thanks for answer!</p>&#xA;"
43939970,What does Social SSO look like in a Microservices Architecture?,2017-05-12 14:16:25,<facebook><security><authentication><single-sign-on><microservices>,1,183,0,0.0,1,"<p>Evening all</p>&#xA;&#xA;<p>I am trying to grasp the concept of how Social SSO (Facebook/Google etc) would work within a Microservices Architecture.</p>&#xA;&#xA;<p><strong>Scenario</strong></p>&#xA;&#xA;<p>Lets say I have 2 backend microservices (Order, User) and one front end (WebApp)</p>&#xA;&#xA;<ul>&#xA;<li>User: Holds user profile details, email, name, address.</li>&#xA;<li>Order: Holds a list of orders which are linked to a user</li>&#xA;<li>WebApp: Provides a front end which interacts with the two back end services.</li>&#xA;</ul>&#xA;&#xA;<p>Adding Social SSO, is to simplify the process of users signing up to the website <a href=""http://www.myproduct.com"" rel=""nofollow noreferrer"">http://www.myproduct.com</a></p>&#xA;&#xA;<p>When a person uses Social SSO, I want to create a user account in the user service.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<p>Assuming a user clicks ""Login with Facebook"" on the WebApp and logged in as ""John""</p>&#xA;&#xA;<ol>&#xA;<li><p>What is the best approach to creating an account for John in my User&#xA;service ?</p></li>&#xA;<li><p>Once logged in as John, how does the WebApp propagate the identity&#xA;of John to the Order service ?</p></li>&#xA;<li><p>How does the Order service validate that John is logged in ?</p></li>&#xA;<li><p>How can interdependent services Order &amp; User trust each other ?</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>Concerns</strong></p>&#xA;&#xA;<ol>&#xA;<li>Downstream services will become very ""chatty"" with the Authorisation Server (Facebook, Google)</li>&#xA;</ol>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<p>Daniel</p>&#xA;"
43896718,Architecture for monitoring system state within microservices,2017-05-10 15:22:34,<graph><microservices>,1,49,2,0.0,1,"<p>I'm trying to build a service, which will monitor the current system state in graph structure. For example, if userA is subscribed on userB and have a chat with it, the graph should contain next relations:</p>&#xA;&#xA;<p>A --subscribed on --> B</p>&#xA;&#xA;<p>A --in chat with --> B</p>&#xA;&#xA;<p>B --in chat with --> A</p>&#xA;&#xA;<p>If userA exit chat, then the relation should be deleted. </p>&#xA;&#xA;<p>Also, new microservices should be introduced, so no hardcoded decision (like to support subset of relations) cant be implemented. </p>&#xA;&#xA;<p>Main problems are consistency of data and new relations which cannot be hardcoded.</p>&#xA;&#xA;<p>I wonder if there are any solutions, or libraries, which can help me with this problem. Any suggestions will be appreciated.</p>&#xA;"
43870576,Batch - Get Requests from different Microservices,2017-05-09 13:01:35,<rest><get><microservices>,2,368,3,0.0,1,"<p>I am dividing a monolithic service to a microservice architecture. What I have done is separate the services and now the REST call is distributed but the problem is if I call a <code>service A</code> which returns 10000 instances and it is dependent on some other <code>service B</code>, so call comes to <code>service A</code> and for each instance, call goes to <code>service B</code> to get its data, so converting a single call to 10000 additional calls so now the call takes alot of time. </p>&#xA;&#xA;<p>I want to make multiple Get Requests in a single request. </p>&#xA;&#xA;<p>What I have searched is to use batch requests to POST different instances, but this is recommended on Creating &amp; Updating multiple instances together. Can this be done for getting information as well? </p>&#xA;&#xA;<p>And is there any other way to do it?</p>&#xA;&#xA;<p>Edit: A similar use case as to mine e.g. There are two services one service gets the details of students and the other gets the details of teachers. In teachers table there is student's ID that it teaches not as a foreign key but a simple key, Now in the UI for the teacher, it shows the teacher details and the student ID and student names and class it belongs to, so for getting the student name and class details, I would have to call the student's service with the student's ID.</p>&#xA;"
43910795,Microservices async operation HTTP response,2017-05-11 08:53:19,<http><asynchronous><architecture><microservices><event-driven>,1,182,9,1.0,1,"<p>We're building a microservice app where clients can create <em>projects</em>. The following diagram shows the technical flow of this process:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/UWDMy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UWDMy.png"" alt=""Create Project Flow""></a></p>&#xA;&#xA;<p>My question: <strong>what HTTP response should the API gateway return to the client (step 1.)?</strong> </p>&#xA;&#xA;<p>My initial idea was to give back a 202, but the problem there is that I don't know the <code>Location</code> yet (<code>/projects/{id}</code>), because the id of the <em>project</em> will be created at the Project Management Service.</p>&#xA;"
46822414,Apache Ignite service won't start if second node is running,2017-10-19 03:29:47,<microservices><ignite>,1,80,0,0.0,1,"<p>I have a basic service that starts a Jetty server and responds to requests. The repo is here: <a href=""https://github.com/danellis/ignite-test"" rel=""nofollow noreferrer"">https://github.com/danellis/ignite-test</a></p>&#xA;&#xA;<p>When I run Ignite with that configuration file, and both my service's JAR and the Scala library JAR in libs, everything seems to work as expected. However, if I start a second, identical node on another computer, it delays a few seconds during startup, then starts without my service running (but without any exceptions). If I restart the original node while another node is running, the same problem then occurs there too.</p>&#xA;&#xA;<p>Here's the <code>ignite -v</code> output. </p>&#xA;&#xA;<p>Single node: &#xA;<a href=""https://gist.github.com/danellis/6678a28b38084598de84cd87ba7773af"" rel=""nofollow noreferrer"">https://gist.github.com/danellis/6678a28b38084598de84cd87ba7773af</a></p>&#xA;&#xA;<p>Second node: &#xA;<a href=""https://gist.github.com/danellis/63605ba511801d6867439472befe22db"" rel=""nofollow noreferrer"">https://gist.github.com/danellis/63605ba511801d6867439472befe22db</a></p>&#xA;&#xA;<p>What am I doing wrong? </p>&#xA;"
46892720,Query language for DDD repository,2017-10-23 15:08:37,<domain-driven-design><microservices>,1,82,1,0.0,1,<p>Currently I am working toward splitting monolith REST api into microservices. I would like to introduce <code>Domain Driven Design</code> (currently learning). My biggest concern at this moment is implementing <code>Repository</code>.</p>&#xA;&#xA;<p>Domain UBIQUITOUS LANGUAGE defines <code>Profile</code> entity (Social media profile e.g Twitter profile). I am thinking to extract <code>Profile</code> in to separate microservice. To query profiles i would introduce <code>ProfileRepository</code>.</p>&#xA;&#xA;<p>Other microservices including API gateway have their own <code>Profile</code> search patterns. How should I design Repository to meet all those search patterns. Should I create <code>find</code> method for every query? Should I introduce some sort of dynamic query language?</p>&#xA;&#xA;<p>In a monolith architecture I could create multiple repositories. One for each use case. In microservices architecture I would need to change microservice responsible for <code>Profile</code> every time other microservices needs new query.</p>&#xA;
46804482,Microservice Architecture Diagram,2017-10-18 07:04:19,<architecture><microservices>,1,340,1,0.0,1,"<p>I am developing micro-services architecture using Spring Boot.</p>&#xA;&#xA;<p>My architecture has around 10 Service each running with 2 instances each behind HAProxy(Load-balancer)</p>&#xA;&#xA;<p>Also there are applications running like Jenkins, Grafana etc.</p>&#xA;&#xA;<p>Now I want an interface where I can view all nodes which are working as green, not working as red, show dependency b/w nodes. I mean I want to view the complete architecture so that any one can understand the architecture. How should I do it?</p>&#xA;"
34043861,How to keep track of the services registered in SOA service registry & discovery,2015-12-02 13:23:30,<c#><soa><microservices><service-discovery><consul>,1,459,0,0.0,1,"<p>I have been working on the SOA POC since last few days. For service discovery &amp; registry, we are considering Consul. Once we have registered the services in consul, how we should keep track of running status of the registered services? &#xA;We are implementing things on .net platform where some wcf services are hosted on the different appdomains, some in separate console process. We can keep track of the services in two ways.</p>&#xA;&#xA;<ol>&#xA;<li>Listening the ports using socket connection with heartbeats .</li>&#xA;<li>Handling the appdomain unload &amp; console exit events.</li>&#xA;</ol>&#xA;&#xA;<p>A. Is there any other way to handle this scenario? </p>&#xA;&#xA;<p>B. How we can get notification when console application process gets terminated ? procss might be killed,closed etc. How we can gracefully remove the service registry entry from Consul central repository?</p>&#xA;&#xA;<p>C. Listening all the ports with certain heartbeat is efficient way as it will keep threads busy all the times?</p>&#xA;&#xA;<p>Any help is most appreciated? </p>&#xA;"
34049118,Tracking Issues across multiple repositories,2015-12-02 17:26:04,<github><jira><microservices>,1,493,6,1.0,1,"<p>We often have epic stories which span multiple repositories.  I am looking for a mechanism to track all the work that is associated with a single story.  GitHub has Issues which is a close to the solution I seek.  The problem with Issues is they do not span multiple repositories. On deployment day I still need to scan ~10 repositories (there are 100 repo's, 10 are commonly used) to discover which ones have commits related to the story.</p>&#xA;&#xA;<p>As a manual workaround I create multiple Issues.  One Issue for each repository.  Then I manually list the Issue#'s related to the epic story in Jira.</p>&#xA;&#xA;<p>Is there a tool or alternative technique I can use to automatically combine these issues and treat them as one?</p>&#xA;"
47992254,Microservice on GAE+ Mix of Standard and Flexible GAE Services,2017-12-27 12:31:25,<google-app-engine><microservices>,1,148,0,0.0,1,"<p>We have two separate projects as follows</p>&#xA;&#xA;<ol>&#xA;<li>GAE Standard on JAVA runtime, let us say- APP1</li>&#xA;<li>GAE Flexible on Python runtime, let us say- APP2</li>&#xA;</ol>&#xA;&#xA;<p>We want to move both the projects in one micro-services application project with two services, say APP1service (default), and APP2service.</p>&#xA;&#xA;<p>Wanted to check if it is possible to host standard and flexible GAE services sharing one application identity in microservices setup?</p>&#xA;&#xA;<p>Quick answer is highly appreciated.</p>&#xA;&#xA;<p>ps.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Google documentation does not answer this question directly and hints&#xA;  that it is unlikely.</p>&#xA;</blockquote>&#xA;"
48004725,How does it connect various microservices with Docker?,2017-12-28 09:16:25,<rest><docker><spring-boot><microservices>,2,148,0,1.0,1,"<p>I have two microservices into Docker and I want to connect one with other, but I donÂ´t know to do it. The two (and the future apps) are API Rest with Spring-boot, I am searching info, tutorials... but I don`t see nothing. My idea is have an main app that it is be able to connect with the other microservices that they are API Rest and afterwards this main app publish and all this I want to have it inside of the container (Docker).</p>&#xA;&#xA;<p>Is it possible?</p>&#xA;&#xA;<p>Anyone knows any tutorial that explain this?</p>&#xA;&#xA;<p>Thanks so much!</p>&#xA;"
48180454,Rails Engines scalability issue,2018-01-10 04:45:17,<ruby-on-rails><performance><microservices><scalability><rails-engines>,1,96,1,0.0,1,"<p>I need to find a way for scaling my rails monolith application with the help of rails engines.</p>&#xA;&#xA;<p><strong>Goal:</strong> I have database connection timeout issue and monolith has more than 200+ models. what we want to do is divide our models into the tree-like structure of engines. and we will be able to use a separate database for each engine.</p>&#xA;&#xA;<p><strong>UseCase:</strong>  let's say we have engine A as the base engine and which is included in engine B and C respectively. Both B and C engines live on the same level of the tree.</p>&#xA;&#xA;<p>So i have models seggrated in different engines.</p>&#xA;&#xA;<p><strong>Engine A:</strong> has all data related to user.</p>&#xA;&#xA;<pre><code>Class User &#xA;end&#xA;</code></pre>&#xA;&#xA;<p><strong>Engine B:</strong> has all data related to products</p>&#xA;&#xA;<pre><code>class Product&#xA;end&#xA;</code></pre>&#xA;&#xA;<p><strong>Engine C:</strong> has all data related to reports.</p>&#xA;&#xA;<pre><code>class Report&#xA;end&#xA;</code></pre>&#xA;&#xA;<p><em>now the main issue comes while defining the associations</em>. earlier we were having associations and several other methods which access associations. For eg. </p>&#xA;&#xA;<pre><code>class User&#xA;  has_many products&#xA;&#xA;  def get_title_product&#xA;    products.pluck(:title)&#xA;  end&#xA;end&#xA;</code></pre>&#xA;&#xA;<p>now I cannot define it in engine A as products table doesn't live there.</p>&#xA;&#xA;<p><strong>Option:</strong>&#xA;what I know is I have to open that User model inside Engine B and define all the association and get_title_product logic related to this Domain in engine B itself.&#xA;I can't even include Engine B in Engine A because it will result in circular dependency.  </p>&#xA;&#xA;<p>I don't want to follow above approach because it will get messy and my application is significantly large, additionally I don't think it is good as per rails best practices.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
48043523,PACT provider verification against public APIs,2017-12-31 15:06:54,<microservices><pact><pact-jvm>,1,114,3,0.0,1,"<p>am trying to do test for consumer driver contract testing using pact jvm and able to generate consumer side contract file.During provider side verification, how to provide public API's instead of localhost most of the examples uses only localhost as provider, any help pls</p>&#xA;&#xA;<pre><code>@RunWith(PactRunner.class) // Say JUnit to run tests with custom Runner&#xA;@Provider(""WeatherProvider"") // Set up name of tested provider&#xA;@PactFolder(""D:\Workspace\pactConsumer\pactConsumer_v2\pacts"") // Point where to find pacts (See also section Pacts source in documentation)&#xA;@VerificationReports(value = {""markdown"",""json""}, reportDir = ""D:\Workspace\pactConsumer\pactConsumer_v2\target"")&#xA;&#xA;public class ProviderVerifyer {&#xA;@State(""Weather information is available for Chennai"") // Method will be run before testing interactions that require ""with-data"" state&#xA;public void getWeather() {&#xA;System.out.println(""Weather information is available for Chennai"" );&#xA;}&#xA;@TestTarget // Annotation denotes Target that will be used for tests&#xA;public final Target target = new HttpTarget(8114); // Out-of-the-box implementation of Target (for more information take a look at Test Target section)&#xA;&#xA;}&#xA;</code></pre>&#xA;"
31135664,Has anyone tested Akka-http-testkit?,2015-06-30 10:20:53,<scala><akka><karma-jasmine><microservices><akka-testkit>,1,678,0,0.0,1,"<p>I'm working in a microservice architecture based in akka-http and akka clustering . I have seen in akka documentation this library <a href=""http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala/http/index-testkit.html"" rel=""nofollow"">akka-http-testkit</a>. Actually, it's in an experimental state , but haven't found any documentation . Seems it's on progress . </p>&#xA;&#xA;<p>Has anyone used this library ? Can anyone suggest me any way to test rest microservices ? . My first option is using <a href=""http://karma-runner.github.io/0.12/index.html"" rel=""nofollow"">Karma</a>, and do the testing via javascript, but it would be great to hear different opinion and options (as Akka-http-testkit ... maybe ... :))</p>&#xA;"
31141688,Deployment methods for docker based micro services architecture on AWS,2015-06-30 14:53:50,<amazon-web-services><docker><elastic-beanstalk><microservices><ec2-container-service>,1,371,1,2.0,1,"<p>I am working on a project using a microservices architecture.&#xA;Each service lives in its own docker container and has a separate git repository in order to ensure loose coupling.</p>&#xA;&#xA;<p>It is my understanding that AWS recently announced support for <a href=""http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_v2config.html"" rel=""nofollow"">Multi-Container Docker environments in ElasticBeanstalk</a>. This is great for development because I can launch all services with a single command and test everything locally on my laptop. Just like Docker Compose.</p>&#xA;&#xA;<p>However, it seems I only have the option to also deploy all services at once which I am afraid defies the initial purpose of having a micro services architecture.</p>&#xA;&#xA;<p>I would like to be able to deploy/version each service independently to AWS. What would be the best way to achieve that while keeping infrastructure management to a minimum?</p>&#xA;"
31201083,How to point to specific DNS with custom port in Java,2015-07-03 07:31:07,<java><dns><service-discovery><microservices><consul>,1,506,1,0.0,1,"<p>I'm using DNS Interface of Consul. It is available at <code>localhost, port 8600</code>. How can I point to this DNS in my Java program?</p>&#xA;&#xA;<p>So far I can only change the address to localhost using Java system properties</p>&#xA;&#xA;<pre><code>System.setProperty(""sun.net.spi.nameservice.nameservers"", ""localhost"");&#xA;System.setProperty(""sun.net.spi.nameservice.provider.1"", ""dns,sun"");&#xA;</code></pre>&#xA;&#xA;<p>But I could not find the way for the port 8600. Please help?</p>&#xA;&#xA;<p>This is the command to query for <code>web.service.consul</code></p>&#xA;&#xA;<pre><code>dig @127.0.0.1 -p 8600 web.service.consul&#xA;</code></pre>&#xA;"
31161436,How to use Apache ZooKeeper with Spring Cloud service discovery and load balancing?,2015-07-01 12:32:33,<java><apache-zookeeper><spring-cloud><service-discovery><microservices>,1,969,2,2.0,1,"<p>I'm new to Apache ZooKeeper concept to implement the service discovery and load balancing with netflix ribbon client. I seen some examples in github (<a href=""https://github.com/spring-cloud/spring-cloud-zookeeper"" rel=""nofollow"">https://github.com/spring-cloud/spring-cloud-zookeeper</a> ). Could anyone help me to know how to set-up the ZooKeeper and service discovery implementation on app service instances. I'm very curious to know about this concept.</p>&#xA;&#xA;<p>Thanks in advance..,</p>&#xA;"
31088764,Design strategy for Microservices in .NET,2015-06-27 12:28:35,<microservices>,3,591,3,0.0,1,<p>What would be a good way for Microservices .NET to communicate with each other? Would a peer to peer communication be better (for performance) using NETMQ (port of ZeroMQ) or would it be better via a Bus (NServiceBus or  RhinoBus)?&#xA;Also would you break up your data access layer into microservices too?</p>&#xA;&#xA;<p>-Indu</p>&#xA;
46120795,Steeltoe service registry discovery and prefixing a hostname to the resolved url,2017-09-08 16:20:51,<asp.net-core><microservices><pivotal-cloud-foundry><service-discovery>,1,265,0,0.0,1,"<p>I am using PCF Service Registry to register my micro services and using discovery client to resolve the actual service urls for inter service calls like below</p>&#xA;&#xA;<pre><code>[Route(""api/[controller]"")]&#xA;    public class CustomerController: Controller&#xA;    {&#xA;        private DiscoveryHttpClientHandler discHttpHandler;&#xA;&#xA;        private ILogger&lt;ValuesController&gt; logger;&#xA;&#xA;        private const string RANDOM_CUSTOMER_URL = ""https://CustomerService/api/v1/customer/"";&#xA;&#xA;        //private const string RANDOM_CUSTOMER_URL = ""http://localhost:58227/api/v1/customer/"";&#xA;&#xA;        public CustomerController(IDiscoveryClient client, ILogger&lt;ValuesController&gt; logger)&#xA;        {&#xA;            this.logger = logger;&#xA;            this.discHttpHandler = new DiscoveryHttpClientHandler(client);&#xA;        }&#xA;&#xA;        /// &lt;summary&gt;&#xA;        /// Retrieves the customer name by invoking Customer Service via &#xA;        /// Service registry lookup&#xA;        /// &lt;/summary&gt;&#xA;        /// &lt;param name=""id""&gt;&lt;/param&gt;&#xA;        /// &lt;returns&gt;&lt;/returns&gt;&#xA;        [Route(""GetCustomerName/{id}"")]&#xA;        [HttpGet]&#xA;        public async Task&lt;IActionResult&gt; GetCustomerName(int id)&#xA;        {&#xA;            try&#xA;            {&#xA;                var client = GetClient();&#xA;                var resString = await client.GetAsync(RANDOM_CUSTOMER_URL + id).&#xA;                    Result.Content.ReadAsStringAsync();&#xA;                var respObj = JsonConvert.DeserializeObject&lt;ApiResponse&lt;CustomerDTO&gt;&gt;(resString);&#xA;                if (respObj != null)&#xA;                {&#xA;                    return Ok(new { CustomerName = respObj.Result.FirstName + "", "" + respObj.Result.LastName });&#xA;                }&#xA;                return NotFound();&#xA;            }&#xA;            catch (Exception ex)&#xA;            {&#xA;                logger.LogError(default(EventId), ex, ex.ToString());&#xA;                return StatusCode(500);&#xA;            }&#xA;        }&#xA;&#xA;        /// &lt;summary&gt;&#xA;        /// Create an Http client backed by Steeltoe's DiscoveryHttpClientHandler&#xA;        /// &lt;/summary&gt;&#xA;        /// &lt;returns&gt;&lt;/returns&gt;&#xA;        private HttpClient GetClient()&#xA;        {&#xA;            var client = new HttpClient(discHttpHandler, false);&#xA;            return client;&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>This is working fine and I am able to resolve the target service url. But there is a new requirement to support an access gateway host name like the resolved url should be prefixed with the dns name of access gateway like <a href=""http://GatewayUrl/CustomerService/api/v1/customers"" rel=""nofollow noreferrer"">http://GatewayUrl/CustomerService/api/v1/customers</a>. I don't know how to accomplish this in Eureka configuration. I tried to put the hostname in eureka:instance configuration as mentioned in <a href=""http://steeltoe.io/docs/steeltoe-discovery/"" rel=""nofollow noreferrer"">http://steeltoe.io/docs/steeltoe-discovery/</a>, but ended up being the same url resolved as before. Any thoughts on this. Thanks in advance.</p>&#xA;"
46110222,What's the recommended way to handle microservice processing bugs new insights?,2017-09-08 06:45:56,<asynchronous><message-queue><microservices>,1,44,0,0.0,1,"<p>Before I get to my question, let me sketch out a sample set of microservices to illustrate my dilemma.</p>&#xA;&#xA;<h2>Scenario outline</h2>&#xA;&#xA;<p>Suppose I have 4 microservices:</p>&#xA;&#xA;<p>An <strong>activation service</strong> where features supplied to our customers are (de)activated. A <strong>registration service</strong> where members can be added and changed. A <strong>secured key service</strong> that is able to generate secure keys (in a multi step process) for members to be used when communicating with them with the outside world. And a <strong>communication service</strong> that is used to communicate about our members with external vendors.</p>&#xA;&#xA;<p>The <strong>secured key service</strong> may however only request secured keys if this is a feature that is activated. Additionally, the <strong>communication service</strong> may only communicate about members that have a secured key AND if the communication feature itself is activated.</p>&#xA;&#xA;<p>Because they are microservices, each of the services has it's own datastore and is completely self sufficient. That is, any data that is required from the other microservices is duplicated locally and kept in sync by means of asynchronous messages from the other microservices.</p>&#xA;&#xA;<h2>The dilemma</h2>&#xA;&#xA;<p>I'm actually facing two main dilemma's. The first is (pretty obviously) data synchronization. When there are multiple data stores that need to be kept in sync you have to account for messages getting lost or processed out of order. But there are plenty of out of the box solutions for this and when all fails you could even fall back to some kind of ETL process to keep things in sync.</p>&#xA;&#xA;<p>The main issue I'm facing however is the actions that need to be performed. In the above example the <strong>secured key service</strong> must perform an action when it either </p>&#xA;&#xA;<ol>&#xA;<li>Receives a message from the <strong>registration service</strong> for a new member when it already knows that the <em>secured keys</em> feature is active in the <strong>activation service</strong></li>&#xA;<li>Receives a message from the <strong>activation service</strong> that the <em>secured keys</em> feature is now active when it already knows about members from the <strong>registration service</strong></li>&#xA;</ol>&#xA;&#xA;<p>In both cases this means that a message from the external system must lead to both an update in the local copy of the data as well as some logic that needs to be processed.</p>&#xA;&#xA;<h2>The question</h2>&#xA;&#xA;<p>Now to the actual question :)</p>&#xA;&#xA;<p>What is the recommended way to cope with either bugs or new insights when it comes to handling those messages? Suppose there is a bug in the message handler from the <strong>activation service</strong>. The handler does update the internal data structure, but it fails to detect that there are already registered members and thus never starts the <em>secure key generation</em> process. Alternatively it could be that there's no bug, but we decide that there is something else we want the handler to do.</p>&#xA;&#xA;<p>The system will have no reason to resubmit or reprocess messages (as the message didn't fail), but there's no real way for us to re-trigger the behavior that's behind the message.</p>&#xA;&#xA;<p>I hope it's clear what I'm asking (and I do apologize if it should be posted on any of the other 170 Stack... sites, I only really know of StackOverflow)</p>&#xA;"
46098754,Stateless Micro services and database,2017-09-07 14:19:43,<database><distributed-computing><microservices><high-availability><stateless>,1,355,0,1.0,1,<p>We have a requirement of building stateless micro services which rely on a database cluster to persist data. </p>&#xA;&#xA;<p>What is the approach that is recommended for <b>redundant</b> stateless micro services(for high availability and scalability) using the database cluster. For example: Running multiple copies of version 1.0 <b>Payment</b> service.</p>&#xA;&#xA;<p>Should all the redundant micro services use a common shared DB schema or they should have their own schema? In case of independent DB schema inconsistency among the redundant services may exist. </p>&#xA;&#xA;<p>Also how can the schema upgrade handled in case of common DB schema?</p>&#xA;
46247154,Docker run failed to run the container,2017-09-15 20:37:18,<docker><microservices>,2,161,1,0.0,1,"<p>I'm new to docker, trying to build my the first docker container on AWS free tier account t2.micro instance</p>&#xA;&#xA;<p>I am able to build my docker based on below <strong>Dockerfile</strong>.</p>&#xA;&#xA;<pre><code>FROM java:8&#xA;COPY content-service /&#xA;RUN chmod +x /bin/start.sh&#xA;&#xA;CMD bash -C '/bin/start.sh'&#xA;&#xA;EXPOSE 8081&#xA;&#xA;MAINTAINER Velu&#xA;</code></pre>&#xA;&#xA;<p>It's failing and exits while is trying to run the container command following error message is getting.</p>&#xA;&#xA;<pre><code>[ec2-user@ip-172-31-30-38 cis-docker]$ sudo docker images&#xA;REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE&#xA;content-service     latest              9fa3ca5a8ac3        10 minutes ago      705.7 MB&#xA;docker.io/java      8                   d23bdf5b1b1b        8 months ago        643.1 MB&#xA;&#xA;[ec2-user@ip-172-31-30-38 cis-docker]$ sudo docker --debug run -p 8082:8082 content-service&#xA;DEBU[0000] framesize: 18&#xA;Starting service.&#xA;DEBU[0000] Corrupted prefix: []&#xA;DEBU[0000] [hijack] End of stdout&#xA;</code></pre>&#xA;&#xA;<p>Any help would be appreciated.</p>&#xA;"
46143509,How to capture log on each instance of the microservice through zuul,2017-09-10 17:24:13,<microservices><spring-cloud><netflix-eureka><netflix-zuul><netflix-ribbon>,1,265,2,0.0,1,<p>I have setup multiple instances of my microservice and registered to my eureka server. It uses ribbon for client side load balancing and uses zuul as gateway server. All usual stuff. I would like to capture the logs of which instance of my service is responding for each request. So that I can able to bring some conclusion based on my usage of each instances. How to do that?</p>&#xA;
41880229,Send a message from one microservice to another in Azure Service Fabric (APIs),2017-01-26 18:16:09,<asp.net-web-api><architecture><microservices><azure-service-fabric><service-fabric-stateful>,2,651,0,3.0,1,"<p><a href=""https://i.stack.imgur.com/Og0vb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Og0vb.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What is the best architecture, using Service Fabric, to guarantee that the message I need to send from Service 1 (mostly API) to Service 2 (mostly API) does not get ever lost (black arrow)?</p>&#xA;&#xA;<p>Ideas:</p>&#xA;&#xA;<h1>1</h1>&#xA;&#xA;<p>1.a. Make service 1 and 2 stateful services. Is it a bad call to have a stateful Web API?</p>&#xA;&#xA;<p>1.b. Use Reliable Collections to send the message from API code to Service 2.</p>&#xA;&#xA;<h1>2</h1>&#xA;&#xA;<p>2.a. Make Service 1 and 2 stateless services</p>&#xA;&#xA;<p>2.b. Add a third service</p>&#xA;&#xA;<p>2.c. Send the message over a queuing system (i.e.: Service Bus) from service 1</p>&#xA;&#xA;<p>2.d. To be picked up by the third service. Notice: this third service would also have access to the DB that service 2 (API) has access to. Not an ideal solution for a microservice architecture, right?</p>&#xA;&#xA;<h1>3</h1>&#xA;&#xA;<p>3.a. Any other ideas?</p>&#xA;&#xA;<p>Keep in mind that the goal is to never lose the message, not even when service 2 is completely down or temporary removedâ€¦ so no direct calls.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
41837933,Accessing Kubernetes Web UI (Dashboard),2017-01-24 20:02:38,<docker><kubernetes><microservices><kubectl><kube-dns>,1,2484,0,0.0,1,"<p>I have installed a Kubernetes with Kubeadm tool, and then followed the <a href=""https://kubernetes.io/docs/user-guide/ui/"" rel=""nofollow noreferrer"">documentation</a> to install the Web UI (Dashboard). Kubernetes is installed and running in one node instance which is a taint master node. </p>&#xA;&#xA;<p>However, I'm not able to access the Web UI at <code>https://&lt;kubernetes-master&gt;/ui</code>. Instead I can access it on <code>https://&lt;kubernetes-master&gt;:6443/ui</code>.</p>&#xA;&#xA;<p>How could I fix this?</p>&#xA;"
41745636,Angular get CSV file in browser by calling URL,2017-01-19 15:28:06,<javascript><java><angularjs><microservices><angularjs-ng-click>,1,296,1,0.0,1,"<p>I have made a Java micro service to export a table from a database into a CSV file and get it in browser by following this: <a href=""https://stackoverflow.com/questions/18100416/downloading-a-csv-file-in-browser-by-using-java"">Downloading a CSV File in Browser by using Java</a>&#xA;It works well and I get the file in the browser when I call the URL (by copying and pasting in the browser) :&#xA;<a href=""http://localhost:8080/api/fileDownload/2"" rel=""nofollow noreferrer"">http://localhost:8080/api/fileDownload/2</a></p>&#xA;&#xA;<p>In the Angular part when I call the URL in my app I see in the console :</p>&#xA;&#xA;<pre><code>Request URL:http://localhost:8080/api/fileDownload/2&#xA;Request Method:GET&#xA;Status Code:200 &#xA;</code></pre>&#xA;&#xA;<p>In the preview and the response of the console, I also have the content of my file. So it seems everything looks good but the problem is that my browser doesn't download the file automatically.</p>&#xA;&#xA;<p>My controller : </p>&#xA;&#xA;<pre><code>vm.downloadFunction=function(){&#xA;    FileDownload.download.query({id:2},function(data){&#xA;    });&#xA;};&#xA;</code></pre>&#xA;&#xA;<p>My view : </p>&#xA;&#xA;<pre><code> &lt;label data-ng-click=""addModule.downloadFunction()"" class=""btn btn-link btn-file""&gt;&#xA;                    Download &lt;input type=""button"" class=""hidden""&gt;&#xA;                &lt;/label&gt;&#xA;</code></pre>&#xA;&#xA;<p>And the service : </p>&#xA;&#xA;<pre><code>voltApp.factory('FileDownload', function ($resource) {&#xA;return{&#xA;    download:  $resource('/api/fileDownload/:id', {}, {&#xA;        query: {method: 'GET', params: {id:'@id'},isArray:false},&#xA;        update:{method: 'PUT'}&#xA;    })&#xA;};&#xA;</code></pre>&#xA;&#xA;<p>});</p>&#xA;&#xA;<p>What am I doing wrong?</p>&#xA;"
41776814,Accessing Large files stored in AWS s3 using AWS Lambda functions,2017-01-21 07:29:07,<amazon-web-services><amazon-s3><aws-lambda><microservices>,1,1992,1,0.0,1,"<p>I have more than 30GB file stored in s3,and I want to write an Lambda function which will access that file, parse it and then run some algorithm on the same.&#xA;I am not sure if my lambda function can take that big file and work on it as Max execution time for Lambda function is 300 sec(5 min).&#xA;I found AWS S3 feature regarding faster acceleration, but will it help?</p>&#xA;&#xA;<p>Considering the scenario other than lambda function can any one suggest any other service to host my code as micro service and parse the file?</p>&#xA;&#xA;<p>Thanks in Advance</p>&#xA;"
41832273,Kuberenets Web UI (Dashboard) missing graphs,2017-01-24 15:41:14,<docker><kubernetes><microservices>,1,607,2,0.0,1,<p>I have installed Docker v1.13 and Kubernetes with Kubeadm v1.6. Then I installed Web UI (Dashboard). I can access it but its missing CPU/Memory usage graphs... Why could this happen? </p>&#xA;
41739975,What are the reason to decouple databases on microservices?,2017-01-19 10:51:46,<database><microservices><nosql>,1,435,3,0.0,1,"<p>Here I my current findings on this subject, are these correct or is there an aspect missing?</p>&#xA;&#xA;<p>There are two major principles for microservices: </p>&#xA;&#xA;<ul>&#xA;<li><strong>strong cohesion</strong> -> related code is gouped together, e.g. a class does on well defined job this is strong/hingh cohesion. </li>&#xA;<li><strong>loose coupling</strong> -> interconnect components in a system so that those  components, depend on each other as less as practicable. Coupling refers to the degree of direct knowledge that one element has of another. So a change to one service should not require a change to another.</li>&#xA;</ul>&#xA;&#xA;<p>With a shared database (as in not decoupled) architecture both these principles are not covered. This due to the following facts:</p>&#xA;&#xA;<ul>&#xA;<li>There is a fixed link between the users and the specific technology&#xA;choice as well as to the actual database implementation.</li>&#xA;<li>Businiess/application logic might be spread among multiple users.</li>&#xA;<li>Shared information which needs to be edited can trigger a change of&#xA;the behavior in multiple places.</li>&#xA;<li>Due to the more monolithic architecture which goes with shared&#xA;databases a failure can effect many serveries since they are all tied&#xA;together, even a compelte system failure can happen due to the&#xA;coupeling.</li>&#xA;</ul>&#xA;&#xA;<p>To avoid the above mentioned issues: decoupled databases can be used with microservices instead of shared databases. So each microservice should have its own database. This will also ease scaling of the system, provide much much more system availability, since ""only"" the one, really effected service will fail. </p>&#xA;&#xA;<p><strong>UPDATE</strong>: &#xA;One other benefit of microservices would be that it can improve the flexibility and speed of development. Since correctly decomposed microservices, can be developed and deployed e independently and in parallel with the other services.</p>&#xA;"
35684313,Run all microservices in a multi-project gradle build,2016-02-28 15:22:47,<gradle><microservices>,1,616,1,0.0,1,"<p>I have a multi-project gradle build that's roughly set up like this:</p>&#xA;&#xA;<pre><code>RootProject&#xA;- ServiceA&#xA;- ServiceB&#xA;- ServiceC&#xA;- UI&#xA;</code></pre>&#xA;&#xA;<p>Each of these subprojects is using the Spark framework and runs an embedded web server.  It's basically a microservices setup, so they all need to be up and running for the system as a whole to work.</p>&#xA;&#xA;<p>They each have a task defined like this:</p>&#xA;&#xA;<pre><code>task runApp(type: JavaExec) {&#xA;    main = 'App'&#xA;    classpath = sourceSets.main.runtimeClasspath&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I know I can manually start each service either through my IDE or by opening a different terminal for each sub-project and running <code>gradlew ServiceA:runApp</code>, but what I'd like to do is create a <code>runSystem</code> task at the root level that will fire up everything to make it easy to run the whole system during development.</p>&#xA;&#xA;<p>How can I do this with Gradle?</p>&#xA;"
51512075,SpringBoot Junit testing for filters in Zuul,2018-07-25 06:20:37,<microservices><zuul-testing>,1,41,0,0.0,1,"<p>I'm new to Zuul J-unit testing. I have a couple of filters which is ChangeRequestEntityFilter and SessionFilter, Where I pasted my filtercode below. Can someone tell me how to write a Junit for the filter. I've searched and trying to use MockWire for the unit testing(Also I pasted my empty methods with basic annotations and WireMock port). I need at-least one proper example how this J-unit for Zuul works. I've referred the <a href=""http://wiremock.org/docs/getting-started/"" rel=""nofollow noreferrer"">http://wiremock.org/docs/getting-started/</a> doc. Where I got what to do, but not how to do.</p>&#xA;&#xA;<pre><code>public class ChangeRequestEntityFilter extends ZuulFilter {&#xA;&#xA;    @Autowired&#xA;    private UtilityHelperBean utilityHelperBean;&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        // //avoid http GET request since it does'nt have any request body&#xA;        return utilityHelperBean.isValidContentBody();&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;        //given priority&#xA;    }&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        // Pre&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;&#xA;        RequestContext context = getCurrentContext();&#xA;&#xA;        try {&#xA;            /** get values profile details from session */&#xA;            Map&lt;String, Object&gt; profileMap = utilityHelperBean.getValuesFromSession(context,&#xA;                    CommonConstant.PROFILE.value());&#xA;&#xA;            if (profileMap != null) {&#xA;                /** get new attributes need to add to the actual origin microservice request payload */&#xA;                Map&lt;String, Object&gt; profileAttributeMap = utilityHelperBean.getProfileForRequest(context, profileMap);&#xA;                /** add the new attributes in to the current request payload */&#xA;                context.setRequest(new CustomHttpServletRequestWrapper(context.getRequest(), profileAttributeMap));&#xA;            }&#xA;&#xA;        } catch (Exception ex) {&#xA;            ReflectionUtils.rethrowRuntimeException(new IllegalStateException(""ChangeRequestEntityFilter : "", ex));&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I know ,I'm asking more. But give me any simple working complete example, I'm fine with it.</p>&#xA;&#xA;<p>My current code with basic annotations and WireMock port.</p>&#xA;&#xA;<pre><code>@RunWith(SpringRunner.class)&#xA;@SpringBootTest&#xA;@DirtiesContext&#xA;@EnableZuulProxy&#xA;public class ChangeRequestEntityFilterTest {&#xA;&#xA;    @Rule&#xA;    public WireMockRule wireMockRule = new WireMockRule(8080);&#xA;&#xA;    @Mock&#xA;    ChangeRequestEntityFilter requestEntityFilter;&#xA;&#xA;    int port = wireMockRule.port();&#xA;&#xA;    @Test&#xA;    public void changeRequestTest() {&#xA;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
51524648,Decoding OAuth2 JWT at API Gateway level vs at individual microservice level,2018-07-25 17:30:27,<spring-boot><microservices><spring-security-oauth2>,2,44,0,0.0,1,"<p>I have developed a set of microservices (resource servers) using Spring Boot 1.5.x + OAuth2 with JWT. Right now each microservice is protected using Spring Security i.e. JWT access token is verified at individual resource server level. API Gateway does not have spring security in place, so it just routes the requests to appropriate  server and propagates the authentication headers to downstream services.</p>&#xA;&#xA;<p>I wanted to know if there are any disadvantages of this setup compared to the one where AccessToken is verified at API gateway level only. Or is it just a matter of opinion? Doesn't keeping security at API Gateway level breaks principle of loose coupling, because each microservice may better understand the role of a given user in its own context?</p>&#xA;"
51463528,Microservices (Application-Level joins) more API calls - leads to more latency?,2018-07-22 09:04:20,<join><architecture><microservices><decoupling>,2,45,0,0.0,1,"<p>I have 2 Micro Services one for <code>Orders</code> and one for <code>Customers</code><br>&#xA;Exactly like below example<br>&#xA;<a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/data/database-per-service.html</a><br>&#xA;<a href=""https://i.stack.imgur.com/KdarR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KdarR.png"" alt=""enter image description here""></a> </p>&#xA;&#xA;<p>Which works without any problem.<br>&#xA;I can list <code>Customers</code> data and <code>Orders</code> data based on input <code>CustomerId</code></p>&#xA;&#xA;<p>But now there is new requirement to develop a new screen<br>&#xA;Which shows <code>Orders</code> of input Date <em>and show <code>CustomerName</code> beside each <code>Order</code> information</em>  </p>&#xA;&#xA;<p>When going to implementation<br>&#xA;I can fetch the list of <code>Orders</code>of input Date<br>&#xA;But to show the corresponding <code>CustomerNames</code> based on a list of <code>CustomerIds</code><br>&#xA;I make a multiple API calls to <code>Customer</code> microservice , each call send <code>CustomerId</code> to get <code>CustomerName</code><br>&#xA;Which lead us to more latency</p>&#xA;&#xA;<p>I know above solution is a bad one<br>&#xA;So any ideas please?</p>&#xA;"
51481780,jhipster microservices running mixed in docker and locally. Gateway cannot access UAA,2018-07-23 14:55:07,<docker><microservices><jhipster>,1,45,0,0.0,1,"<p>I have a question about jhipster working combined with docker and localhost. I have started the registry and the uaa apps using docker compose, everything is fine. Then i started locallly one microservice and the gateway. Both of them are sucessfully seen in the registry instances view. The problem is, that when the gateway tries to connect to the uaa (<code>uaa/oauth/token</code>) it fails (<code>I/O error on POST request for http://uaa/oauth/token</code>). I have tried to set in /etc/hosts uaa localhost but it did not help. Does anybody have an idea how to deal with this issue? Thanks in advance</p>&#xA;"
51469118,What are some methods to document contracts between microservices?,2018-07-22 20:46:16,<rest><microservices><distributed><api-design>,1,49,0,0.0,1,"<p>In an HTTP-driven microservices architecture, each service might have a number of public endpoints that return JSON, for example, to a client or an API gateway intermediary. These services could also accept POSTs with JSON bodies of a certain shape, or query strings of a certain shape, etc.</p>&#xA;&#xA;<p>What are some good options for documenting or programmatically keeping track of these ""contracts"" between services? I.e, if service A's <code>/getThing</code> endpoint has been refactored to return different data, is there a documentation tool or methodology that would facilitate updating the API gateway to adapt to this change?</p>&#xA;"
51477318,"How to stich (merge, join, ...) multiple OData microservices together",2018-07-23 11:05:07,<c#><odata><microservices><api-gateway>,1,53,0,0.0,1,"<p>we want to publish multiple datasources in our company via separate <strong>OData microservices</strong>. All these microservices shall be presented by <strong>one API Gateway</strong>. The gateway shall also stich the metadata together in order to look like <strong>ONE</strong> service.</p>&#xA;&#xA;<p>I found the <a href=""https://github.com/Netflix/falcor"" rel=""nofollow noreferrer"">FALCOR-project</a> which looks like the way to go. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/yfL17.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yfL17.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>But it has one drawback: It must be OData-schema conform!&#xA;These microservices (or the API gateway) shall be used by third party applications like Power BI.</p>&#xA;&#xA;<p>A ""nice-to-have"" is to maintain the links (nav properties) between these services in the gateway.</p>&#xA;"
51520654,Distributed transactions in microservices,2018-07-25 13:52:15,<microservices><distributed-transactions><saga>,3,55,0,0.0,1,"<p>I have 2 microservices <code>S1</code> and <code>S2</code>. <code>S1</code> invokes <code>S2</code> to update a data and then <code>S1</code> inserts another data,But let's consider <code>S1</code> fails,Then we need to rollback the data updated by <code>S2</code> or else we'll be in inconsistent state.</p>&#xA;&#xA;<p>I also gone through Saga patterns.will it satisfy this inconsistency</p>&#xA;&#xA;<p>Can anyone suggest any better solutions for this?</p>&#xA;"
51532187,Access machine learning models via REST API,2018-07-26 06:20:11,<java><rest><machine-learning><microservices><conv-neural-network>,1,58,0,0.0,1,"<p>I have made a Convolutional Neural Network to classify cats and dogs images. The dataset, as well as the code, was available online. I used <strong>Python</strong> as my programming language. But now I need to deploy this model on a server and need to access it using REST API. </p>&#xA;&#xA;<p>I have saved my model using HDF5 format. example ""model.h5""&#xA;For reference: <strong><a href=""https://machinelearningmastery.com/save-load-keras-deep-learning-models/"" rel=""nofollow noreferrer"">https://machinelearningmastery.com/save-load-keras-deep-learning-models/</a></strong></p>&#xA;&#xA;<p>We can convert it into PMML file as well but CNN is not supported yet by PMML file.</p>&#xA;&#xA;<p>We can use flask library to convert the model into restful web service like this: ""<strong><a href=""https://www.linode.com/docs/applications/big-data/how-to-move-machine-learning-model-to-production/"" rel=""nofollow noreferrer"">https://www.linode.com/docs/applications/big-data/how-to-move-machine-learning-model-to-production/</a></strong>""</p>&#xA;&#xA;<p>But <strong>I would prefer java.</strong></p>&#xA;&#xA;<p>I prefer making a microservice using Spring Boot. But I didn't get any step by step article on how to do it. </p>&#xA;&#xA;<p>Can anyone help me out, how can we achieve accessing model via REST API using Java. Or any other method to deploy and access using REST API.</p>&#xA;&#xA;<p>Any help would be appreciated.</p>&#xA;"
51428155,Elasticsearch in microservices architecture,2018-07-19 16:55:44,<elasticsearch><design-patterns><microservices>,1,75,0,0.0,1,"<p>I'm designing a system in which we have two different microservices to manage two different data types. Common approach is to have database per microservice, but what are your thoughts about if Elasticsearch takes place of a database? Should I have Elasticsearch instance (cluster) per microservice to claim my architecture nice and shiny, or one instance (cluster) with many indexes is ok? &#xA;I expect answers like ""it depends"", but still I would love to know your thoughts about this.</p>&#xA;"
51392666,Could not locate PropertySource because of java.net.ConnectException: Connection refused,2018-07-18 02:22:30,<spring><docker><spring-boot><docker-compose><microservices>,2,116,0,0.0,1,"<p>I created a docker image and pushed it to docker hub. Now, I am trying to run it on a remote machine by using <code>docker-compose</code> and I get the following error.</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;my-test_1  |    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:132)&#xA;my-test_1  |    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:93)&#xA;my-test_1  |    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:567)&#xA;my-test_1  |    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:338)&#xA;my-test_1  |    at org.springframework.boot.SpringApplication.run(SpringApplication.java:301)&#xA;my-test_1  |    at net.ptidej.seodin.SeodinApp.main(SeodinApp.java:68)&#xA;my-test_1  |    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;my-test_1  |    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;my-test_1  |    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;my-test_1  |    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;my-test_1  |    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)&#xA;my-test_1  |    at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)&#xA;my-test_1  |    at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)&#xA;my-test_1  |    at org.springframework.boot.loader.WarLauncher.main(WarLauncher.java:59)&#xA;my-test_1  | Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8761/config/seodin/prod/master"": Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)&#xA;my-test_1  |    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:674)&#xA;my-test_1  |    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:621)&#xA;my-test_1  |    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:539)&#xA;my-test_1  |    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:172)&#xA;my-test_1  |    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:93)&#xA;my-test_1  |    ... 13 common frames omitted&#xA;my-test_1  | Caused by: java.net.ConnectException: Connection refused (Connection refused)&#xA;my-test_1  |    at java.net.PlainSocketImpl.socketConnect(Native Method)&#xA;my-test_1  |    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)&#xA;my-test_1  |    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)&#xA;my-test_1  |    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)&#xA;my-test_1  |    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)&#xA;my-test_1  |    at java.net.Socket.connect(Socket.java:589)&#xA;my-test_1  |    at java.net.Socket.connect(Socket.java:538)&#xA;my-test_1  |    at sun.net.NetworkClient.doConnect(NetworkClient.java:180)&#xA;my-test_1  |    at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)&#xA;my-test_1  |    at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)&#xA;my-test_1  |    at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java:242)&#xA;my-test_1  |    at sun.net.www.http.HttpClient.New(HttpClient.java:339)&#xA;my-test_1  |    at sun.net.www.http.HttpClient.New(HttpClient.java:357)&#xA;my-test_1  |    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220)&#xA;my-test_1  |    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156)&#xA;my-test_1  |    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050)&#xA;my-test_1  |    at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984)&#xA;my-test_1  |    at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:78)&#xA;my-test_1  |    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)&#xA;my-test_1  |    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53)&#xA;my-test_1  |    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)&#xA;my-test_1  |    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$GenericRequestHeaderInterceptor.intercept(ConfigServicePropertySourceLocator.java:237)&#xA;my-test_1  |    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)&#xA;my-test_1  |    at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)&#xA;my-test_1  |    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)&#xA;my-test_1  |    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53)&#xA;my-test_1  |    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:660)&#xA;my-test_1  |    ... 17 common frames omitted&#xA;my-test_1  | &#xA;</code></pre>&#xA;&#xA;<p>I am guessing it has something to do with ports in one of the config files, but I don't know which one. What is the meaning of this error and where should I look to resolve it? I would appreciate any lead/hint to the problem in the source code/config files. Thank you.</p>&#xA;"
51368809,Eureka client exception com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server,2018-07-16 19:23:02,<spring-boot><microservices><spring-cloud><netflix-eureka><eureka>,2,118,0,0.0,1,"<p>I am new to microservices. I'm trying to create one small application for learning purpose. Here is my code:&#xA;EurekaServer - application.yml</p>&#xA;&#xA;<pre><code>    spring:&#xA;     application:&#xA;      name: EurekaServer&#xA;&#xA;    server:&#xA;     port: 8080&#xA;     servlet:&#xA;      context-path: /EurekaServer&#xA;&#xA;    eureka:&#xA;     client:&#xA;      fetch-registry: false&#xA;      register-with-eureka: false &#xA;</code></pre>&#xA;&#xA;<p>Eureka Server is working fine and I am able to see the dashboard at <a href=""http://localhost:8080/EurekaServer/"" rel=""nofollow noreferrer"">http://localhost:8080/EurekaServer</a></p>&#xA;&#xA;<p>EmployeeClient: application.yml is below:</p>&#xA;&#xA;<pre><code>    spring:&#xA;     application:&#xA;      name: EmployeeClient&#xA;&#xA;    server:&#xA;     port: 8586&#xA;&#xA;    eureka:&#xA;     client: &#xA;      serviceUrl:&#xA;       defaultZone: http://localhost:8080/EurekaServer&#xA;</code></pre>&#xA;&#xA;<p>In last line I need to write serviceUrl explicitly as on pressing ctrl+space in sts it doesnot show option serviceUrl but it shows service-url, hyphen sign. And same with defaultZone. Am I missing some jar or specific version?</p>&#xA;&#xA;<p>My EmployeeClientApplication.java</p>&#xA;&#xA;<pre><code>    @EnableEurekaClient&#xA;    @SpringBootApplication&#xA;    public class EmployeeClientApplication {&#xA;&#xA;       public static void main(String[] args) {&#xA;          SpringApplication.run(EmployeeClientApplication.class, args);&#xA;       }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>when I try to run EmployeeClientApplication.java it gives me below exception:</p>&#xA;&#xA;<pre><code>    com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server&#xA;</code></pre>&#xA;&#xA;<p>I also tried using @EnableDiscoveryClient in place of @EnableEurekaClient, but with no luck.</p>&#xA;&#xA;<p>A part of EmployeeClient pom.xml is below:</p>&#xA;&#xA;<pre><code>    &lt;parent&gt;&#xA;       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;       &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;       &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&#xA;       &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;      &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;      &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;      &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;      &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;   &lt;dependencies&gt;&#xA;     &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&#xA;    &lt;dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>Where I'm making a mistake?</p>&#xA;"
44928556,Monolith to microservice,2017-07-05 14:08:05,<design><microservices><system-design>,1,132,0,1.0,1,"<p>We are planning to migrate from monolith to micro-services based architecture. Now i own the responsibility of talking a module out of monolith. </p>&#xA;&#xA;<p><strong>Existing Monolith:</strong></p>&#xA;&#xA;<p>1) Code is very tightly coupled.</p>&#xA;&#xA;<p>2) APIs are called recursively with different parameters. </p>&#xA;&#xA;<p>3) Some of the calls with-in the module which i am planning to extract out contains calls to a system which takes approx 9 minutes to complete. &#xA;Unfortunately that's a synchronous.</p>&#xA;&#xA;<p><strong>Points to note:</strong></p>&#xA;&#xA;<p>1) I am starting with a single api migration which is a very important one and is not performing well.&#xA;2) This api consists of parallel calls to another system for performing &#xA;   bunch of tasks. All the calls are blocking and time-consuming (consider &#xA;   avg response time to be 5-6 min) </p>&#xA;&#xA;<p><strong>Moving to microservice based architecture :</strong> There are 2 approaches that comes to my mind while moving the aforementioned api from monolith to a separate microservice, along with solving the problem of blocking threads due to time taking blocking calls. </p>&#xA;&#xA;<p><strong>a) moving in phases</strong> : </p>&#xA;&#xA;<pre><code> - Create a separate module &#xA; - In this module provide an api to push events to kafka, another &#xA;   module will in-turn process the request and push the response back &#xA;   to kafka&#xA; - monolith for now will call above mentioned api to push events to &#xA;   kafka&#xA; - New module will inturn call back the monolith when the task &#xA;   complete (received response on a separate topic in kafka)&#xA; - Monolith once get response for all the tasks will trigger some post &#xA;   processing activity.&#xA;&#xA; Advantage:&#xA; 1) It will solve the problem of sync- blocking call.&#xA;&#xA; Disadvantage:&#xA; 1) Changes are required in the monolith, which could introduce some &#xA;    bugs.&#xA; 2) No fallbacks are available for the case if bug gets introduced.&#xA;</code></pre>&#xA;&#xA;<p><strong>b) Move the API at once to the microservice :</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>Initially which will share common &#xA; data source with the monolith and solve the problem of blocking calls &#xA; via introduction of kafka between new microservice and the module which &#xA;takes time to process the request. </p>&#xA;&#xA;<p>Advantage:</p>&#xA;&#xA;<p>1) Fallback is available in monolith</p>&#xA;&#xA;<p>Disadvantage:</p>&#xA;&#xA;<p>1) Initially data source is shared between the systems.      </p></li>&#xA;</ul>&#xA;&#xA;<p>What should be the best approach to do these kinds of complex tasks ?</p>&#xA;"
45052239,How to expose REST api microservices to the client?,2017-07-12 08:23:21,<iis><soa><microservices><aws-api-gateway><api-design>,1,496,0,1.0,1,"<p>We are splitting rest api monolith into microservices and we encountered following issue</p>&#xA;&#xA;<p>Let us assume the following</p>&#xA;&#xA;<blockquote>&#xA;  <ul>&#xA;  <li>project is asp.net mvc, hosted on iis</li>&#xA;  <li>project is hosted on dedicated server (not a cloud)</li>&#xA;  <li>monolith rest api had urls defined such as www.domain.com/orders/  www.domain.com/tickets/ etc</li>&#xA;  </ul>&#xA;</blockquote>&#xA;&#xA;<p>When splitting monolith to microservice, ideal situation would be that we end up with </p>&#xA;&#xA;<pre><code>ms1 -&gt; www.domain.com/orders/&#xA;ms2 -&gt; www.domain.com/tickets/&#xA;</code></pre>&#xA;&#xA;<p>Since microservices do not usually correlate with resources this could get messy, for example one microservice could serve more then one resource, or on resource could be served by more then one microservice. </p>&#xA;&#xA;<pre><code>fe.&#xA;www.domain.com/tickets/ (ms1)&#xA;www.domain.com/tickets/reports (ms2)&#xA;&#xA;or&#xA;www.domain.com/tickets (ms1)&#xA;www.domain.com/orders (ms1)&#xA;</code></pre>&#xA;&#xA;<p>What would be solution for this? </p>&#xA;&#xA;<ul>&#xA;<li>Use IIS rewrite to match resource with microservice &#xA;fe. GET www.domain.com/tickets/5 via iis rewrite to call -> ticketsms.domain.com/tickets/5</li>&#xA;<li>Use API gateway to route request to proper microservice endpoint&#xA;fe. &#xA;GET www.domain.com/tickets/5 via API gateway to call -> ticketsms.domain.com/tickets/5</li>&#xA;</ul>&#xA;&#xA;<p>So basically the primary goal is to have full rest api apear like</p>&#xA;&#xA;<pre><code>GET www.domain.com/tickets/5&#xA;GET www.domain.com/orders/5&#xA;POST www.domain.com/orders/&#xA;GET www.domain.com/invoices/100&#xA;</code></pre>&#xA;&#xA;<p>etc</p>&#xA;&#xA;<p>So are iis rewrite and api gateway are the only two options here? &#xA;Should microservices be exposed directly to the clients, or should they go trought API gateway. Is API gateway overkill in this scenario? </p>&#xA;"
45047011,Microservice architecture for ETL,2017-07-12 01:48:20,<web-services><architecture><etl><microservices><restful-architecture>,3,1201,2,2.0,1,"<p>I am redesigning a small monolith ETL software written in Python. I find a microservice architecture suitable as it will give us the flexibility to use different technologies if needed (Python is not the nicest language for enterprise software in my opinion). So if we had three microservices (call them Extract, Transform, Load), we could use Java for Transform microservice in the future.</p>&#xA;&#xA;<p>The problem is, it is not feasible here to pass the result of a service call in an API response (say HTTP). The output from Extract is going to be gigabytes of data.</p>&#xA;&#xA;<p>One idea is to call Extract and have it store the results in a database (which is really what that module is doing in the monolith, so easy to implement). In this case, the service will return only a yes/no response (was the process successful or not).</p>&#xA;&#xA;<p>I was wondering if there were a better way to approach this. What would be a better architecture? Is what I'm proposing reasonable?</p>&#xA;"
45095183,Low Level Protocol for Microservice Orchestration,2017-07-14 05:18:57,<rest><redis><network-programming><apache-zookeeper><microservices>,1,109,3,2.0,1,"<p>Recently I started working with Microservices, I wrote a library for service discovery using Redis to store every service's url and port number, along with a TTL value for the entry. It turned out to be an expensive approach since for every cross service call to any other service required one call to Redis. Caching didn't seem to be a good idea, since the services won't be up all the times, there can be possible downtimes as well.</p>&#xA;&#xA;<p>So I wanted to write a separate microservice which could take care of the orchestration part. For this I need to figure out a really low level network protocol to take care of the exchange of heartbeats(which would help me figure out if any of the service instance goes unavailable). How do applications like zookeeperClient, redisClient take care of heartbeats?</p>&#xA;&#xA;<p>Moreover what is the industry's preferred protocol for cross service calls? &#xA;I have been calling REST Api's over HTTP and eliminated every possibility of Joins across different collections.</p>&#xA;&#xA;<p>Is there a better way to do this?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44927532,How to get newly created resource to client with CQRS and event sourcing based microservices,2017-07-05 13:23:43,<microservices><cqrs><event-sourcing>,1,275,4,0.0,1,"<p>I'm experimenting with microservices, event sourcing and CQRS. However, I'm a little bit confused about how I go from issuing a command to performing a query to return the new state, specifically with regard to interactions with a web API gateway.</p>&#xA;&#xA;<p>As an example, the simple application I am attempting to write (which probably doesn't actually need any of these; it is just something to aid my learning) creates a random-graph and then performs some long-running calculations on the graph. I've modelled this as two separate services: the <code>GraphService</code> and the <code>ComputationService</code>. The imagined process flow is as follows:</p>&#xA;&#xA;<ol>&#xA;<li>User requests new random graph.</li>&#xA;<li>API gateway constructs <code>CreateGraph</code> command and sends it to the&#xA;<code>graph service</code>.</li>&#xA;<li><code>GraphService command handler</code> creates a graph and publishes a&#xA;<code>GraphCreated</code> event.</li>&#xA;<li><code>GraphService event handler</code> subscribes to topic for graph events,&#xA;processes <code>GraphCreated</code> event and stores graph in persistent read&#xA;storage.</li>&#xA;<li><strong>Client somehow gets the newly created graph.</strong></li>&#xA;<li><code>ComputationService event handler</code> subscribes to topic for graph&#xA;events, processes <code>GraphCreated</code> event and begins potentially&#xA;long-running computation, e.g. calculate diameter.</li>&#xA;<li><code>ComputationService</code> publishes <code>DiameterComputed</code> event.</li>&#xA;<li><code>GraphService</code> event handler subscribes to topic for computation&#xA;events, processed <code>DiameterComputed</code> event and updates the graph in&#xA;persistent read storage.</li>&#xA;<li>Client somehow gets updated - easier than getting the new graph, since already have an ID and can poll for changes / websockets / SSE, etc.</li>&#xA;</ol>&#xA;&#xA;<p>That seems relatively simple. However, my confusion lies in how to go about informing the API gateway, and thus the web client, of the new graph (as highlighted in bold above). In a typical CRUD process, the result of the <code>POST request</code> to create a new graph would be to return the URL of the new resource, for instance. However, with CQRS, commands should return nothing or an exception.</p>&#xA;&#xA;<p>How do I pass information back to the client of the service (in this case the API gateway) about the ID of the new graph so that it can perform a query to get the representation of the new resource and send it to the user? Or at least get an ID so that the web client can ask the API gateway, etc?</p>&#xA;&#xA;<p>As I see it at the moment, after sending a command, everyone is just left hanging. There needs to be some sort of subscription model that can be interrogated for the status of the graph creation. I considered having the API gateway generate a request ID which gets embedded with the <code>CreateGraph</code> command, but this then couples the service to the API.</p>&#xA;&#xA;<p>I'm obviously missing something, but have no idea what. None of the examples I've looked at or discussions I've read address this issue and assume that the ID of whatever resource is already known. I couldn't find any discussions here addressing this issue, but if I've just missed them, please point me there rather than duplicating questions. Any pointers would be hugely welcomed.</p>&#xA;"
42394690,Service fabric communication by RPC with metadata,2017-02-22 14:46:23,<c#><azure><rpc><microservices><azure-service-fabric>,1,290,0,0.0,1,"<p>In the <code>API Gateway</code> app I set to request traceId. Then over <code>HTTP</code> pass it to my stateless service. But service should call another service by <code>RPC</code> (using <code>IServiceRemotingListener</code>). How can I pass that traceId to other service?</p>&#xA;&#xA;<p>I've done so far (according to <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-communication-remoting"" rel=""nofollow noreferrer"">this</a>):</p>&#xA;&#xA;<pre><code>public interface ICommunicationService : IService&#xA;{&#xA;    Task&lt;string&gt; FooAsync();&#xA;}&#xA;&#xA;public class Stateless1 : StatelessService, ICommunicationService &#xA;{&#xA;    protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners() &#xA;    {&#xA;        return new[] { new ServiceInstanceListener(c =&gt; this.CreateServiceRemotingListener(c)) };&#xA;    }       &#xA;&#xA;    public Task&lt;string&gt; FooAsync()&#xA;    {&#xA;        return Task.FromResult(""TraceId: "" + TraceId);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and trying to use it:</p>&#xA;&#xA;<pre><code>ICommunicationService service = ServiceProxy.Create&lt;ICommunicationService&gt;(new Uri(""fabric:/App/Stateless1""));&#xA;&#xA;string message = await service.FooAsync();&#xA;</code></pre>&#xA;&#xA;<p>How can I pass that TraceId to other service b RPC?</p>&#xA;"
42392789,Query syntax for nanoscale.io Store,2017-02-22 13:26:04,<javascript><store><microservices>,1,51,0,0.0,1,"<p>Does anyone know how to use the query strings for accessing Store (collection) data in Nanoscale.io? I've tried to read their documentation but the only example is given below:</p>&#xA;&#xA;<pre><code>local.request = new AP.Store.Request();&#xA;local.request.select(""Tasks"", ""priority &gt;= $1 order numeric(priority) asc"", parseInt(request.params.priority));&#xA;</code></pre>&#xA;&#xA;<p>I don't know where the syntax in ""priority >= $1 order numeric(priority) asc"" is from...</p>&#xA;&#xA;<p>In their docs:</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>select(collection, query)</strong></p>&#xA;  &#xA;  <p>Selects matching objects from a collection based off of the query&#xA;  string.</p>&#xA;  &#xA;  <p>collection [string] - Collection name.</p>&#xA;  &#xA;  <p>query [string | number] - This can be either a query or a number. If a&#xA;  number, the operation will return the object that has a matching ID.&#xA;  To return all, use the string ""true"".</p>&#xA;</blockquote>&#xA;&#xA;<p>Apart from ""true"" I don't know how I can form my own queries.</p>&#xA;"
42607458,What would be the correct way to unit test an app engine application with a microservice architecture?,2017-03-05 10:52:59,<python><unit-testing><google-app-engine><microservices>,2,382,0,0.0,1,"<p><strong>Directory structure</strong></p>&#xA;&#xA;<pre><code>/service-session&#xA;    - app.yaml&#xA;/service-dashboard&#xA;    - app.yaml&#xA;    /handlers&#xA;        - login.py&#xA;    /tests&#xA;        - login_test.py&#xA;</code></pre>&#xA;&#xA;<p>service-dashboard uses webapp2 to respond to the user. service-session manages the session. </p>&#xA;&#xA;<p>What the unittest has to do:</p>&#xA;&#xA;<ol>&#xA;<li>Insert valid session into datastore</li>&#xA;<li>Set session cookie</li>&#xA;<li>Request login page to perform an auto-login based on session cookie</li>&#xA;</ol>&#xA;&#xA;<p><strong>Unit Test</strong></p>&#xA;&#xA;<pre><code>class TestHandlers(unittest.TestCase):&#xA;    def setUp(self):&#xA;        self.testbed = testbed.Testbed()&#xA;        self.testbed.activate()&#xA;        self.testbed.init_datastore_v3_stub()&#xA;        self.testbed.init_memcache_stub()&#xA;        self.testbed.init_modules_stub()&#xA;        self.testbed.init_urlfetch_stub()&#xA;&#xA;        self.app = main.app&#xA;&#xA;        self.customer = service_customer.Customer(password='test', salt='', email='test@test.com')&#xA;        self.customer.put()&#xA;&#xA;        self.session = service_session.Session(customer=self.customer.key, session_id=""test_session"")&#xA;        self.session.put()&#xA;&#xA;&#xA;    def test_list(self):&#xA;        request = webapp2.Request.blank('/login', headers={'Cookie': 'session_id=%s' % 'test_session'})&#xA;        response = request.get_response(self.app)&#xA;        self.assertEqual(response.status_int, 200)&#xA;</code></pre>&#xA;&#xA;<p><strong>The issue</strong></p>&#xA;&#xA;<p>Dashboard makes a request to service-session, this fails because the session cannot be located. This is because the session has not been dispatched.</p>&#xA;&#xA;<p>In search for answers I came across <a href=""https://stackoverflow.com/questions/28166558/invalidmoduleerror-when-using-testbed-to-unit-test-google-app-engine"">this</a> post where they use a <code>_LocalFakeDispatcher</code> to bind the services to a certain location. However, this requires to dispatch the services with the devserver because it does not actually dispatch the services. Doing so causes the services to not use the datastore_v3_stub which is initialized in the unit test preventing me to insert a valid session into the datastore.</p>&#xA;&#xA;<p>How does one work around this issue? Is it possible to dispatch the services with the datastore stub? What tactics do you use when testing a microservice architecture on app engine?</p>&#xA;&#xA;<p><strong>NoseGAE + WebTest</strong></p>&#xA;&#xA;<pre><code>nosetests --logging-level=ERROR --gae-lib-root ""C:\google_appengine"" --with-gae --gae-application=""C:\service-session\app.yaml,C:\service-dashboard\app.yaml""&#xA;</code></pre>&#xA;&#xA;<p>Unittest remains about the same except the webtest.TestApp is used to perform requests to dashboard service.</p>&#xA;&#xA;<p>When the dashboard service attempts to locate the session service the application terminates with an InvalidModuleError. Trace:</p>&#xA;&#xA;<pre><code>Traceback (most recent call last):&#xA;  File ""C:\google_appengine\lib\webapp2-2.5.2\webapp2.py"", line 1535, in __call__&#xA;    rv = self.handle_exception(request, response, e)&#xA;  File ""C:\google_appengine\lib\webapp2-2.5.2\webapp2.py"", line 1529, in __call__&#xA;    rv = self.router.dispatch(request, response)&#xA;  File ""C:\google_appengine\lib\webapp2-2.5.2\webapp2.py"", line 1278, in default_dispatcher&#xA;    return route.handler_adapter(request, response)&#xA;  File ""C:\google_appengine\lib\webapp2-2.5.2\webapp2.py"", line 1102, in __call__&#xA;    return handler.dispatch()&#xA;  File ""C:\service-dashboard\core.py"", line 40, in dispatch&#xA;    url = 'http://' + modules.get_hostname('service-session') + '/session.get'&#xA;  File ""C:\google_appengine\google\appengine\api\modules\modules.py"", line 458, in get_hostname&#xA;    _ResultHook).get_result()&#xA;  File ""C:\google_appengine\google\appengine\api\apiproxy_stub_map.py"", line 613, in get_result&#xA;    return self.__get_result_hook(self)&#xA;  File ""C:\google_appengine\google\appengine\api\modules\modules.py"", line 441, in _ResultHook&#xA;    _CheckAsyncResult(rpc, mapped_errors, [])&#xA;  File ""C:\google_appengine\google\appengine\api\modules\modules.py"", line 146, in _CheckAsyncResult&#xA;    raise mapped_error()&#xA;InvalidModuleError&#xA;</code></pre>&#xA;"
42499778,spring-cloud-config in docker-compose https certificate not found,2017-02-28 03:40:37,<docker><spring-boot><docker-compose><microservices>,1,127,0,0.0,1,"<p>I am writing spring cloud application my config service point to my repository. In my development machine everything is working properly but when I create the docker with the help of docker-compose, my virtual machines give the following errors:</p>&#xA;&#xA;<pre><code>2017-02-28T03:14:10.847459300Z &#xA;sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target&#xA;at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141) ~[na:1.8.0_91]&#xA;at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126) ~[na:1.8.0_91]&#xA;at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280) ~[na:1.8.0_91]&#xA;at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:382) ~[na:1.8.0_91]&#xA;at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292) ~[na:1.8.0_91]&#xA;at sun.security.validator.Validator.validate(Validator.java:260) ~[na:1.8.0_91]&#xA;at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324) ~[na:1.8.0_91]&#xA;at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229) ~[na:1.8.0_91]&#xA;at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:124) ~[na:1.8.0_91]&#xA;at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1491) ~[na:1.8.0_91]&#xA;at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:216) ~[na:1.8.0_91]&#xA;at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) ~[na:1.8.0_91]&#xA;at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) ~[na:1.8.0_91]&#xA;at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_91]&#xA;at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_91]&#xA;at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_91]&#xA;at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_91]&#xA;at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) ~[na:1.8.0_91]&#xA;at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.8.0_91]&#xA;at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1513) ~[na:1.8.0_91]&#xA;at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_91]&#xA;at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_91]&#xA;at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_91]&#xA;at org.eclipse.jgit.transport.http.JDKHttpConnection.getResponseCode(JDKHttpConnection.java:98) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.util.HttpSupport.response(HttpSupport.java:196) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.transport.TransportHttp.connect(TransportHttp.java:489) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.transport.TransportHttp.openFetch(TransportHttp.java:311) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.transport.FetchProcess.executeImp(FetchProcess.java:136) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.transport.FetchProcess.execute(FetchProcess.java:122) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.transport.Transport.fetch(Transport.java:1201) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.api.FetchCommand.call(FetchCommand.java:128) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.api.CloneCommand.fetch(CloneCommand.java:203) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.eclipse.jgit.api.CloneCommand.call(CloneCommand.java:136) ~[org.eclipse.jgit-4.6.0.201612231935-r.jar!/:4.6.0.201612231935-r]&#xA;at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.cloneToBasedir(JGitEnvironmentRepository.java:399) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.copyRepository(JGitEnvironmentRepository.java:373) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.createGitClient(JGitEnvironmentRepository.java:358) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.refresh(JGitEnvironmentRepository.java:177) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.getLocations(JGitEnvironmentRepository.java:155) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.MultipleJGitEnvironmentRepository.getLocations(MultipleJGitEnvironmentRepository.java:132) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.AbstractScmEnvironmentRepository.findOne(AbstractScmEnvironmentRepository.java:42) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.MultipleJGitEnvironmentRepository.findOne(MultipleJGitEnvironmentRepository.java:170) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.CompositeEnvironmentRepository.findOne(CompositeEnvironmentRepository.java:45) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;&#xA;at org.springframework.cloud.config.server.environment.EnvironmentEncryptorEnvironmentRepository.findOne(EnvironmentEncryptorEnvironmentRepository.java:53) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at org.springframework.cloud.config.server.environment.EnvironmentController.labelled(EnvironmentController.java:112) ~[spring-cloud-config-server-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_91]&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_91]&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_91]&#xA;at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_91]&#xA;at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.1.RELEASE.jar!/:1.5.1.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:108) ~[spring-boot-actuator-1.5.1.RELEASE.jar!/:1.5.1.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:145) ~[spring-cloud-sleuth-core-1.2.0.BUILD-SNAPSHOT.jar!/:1.2.0.BUILD-SNAPSHOT]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.1.RELEASE.jar!/:1.5.1.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar!/:4.3.6.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_91]&#xA;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_91]&#xA;at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.11.jar!/:8.5.11]&#xA;at java.lang.Thread.run(Thread.java:745) [na:1.8.0_91]&#xA;</code></pre>&#xA;&#xA;<p>I assume that I my config cannot access the https certificates. How to compose the image with yaml to tell the docker about the ssl certificates?</p>&#xA;"
42439626,RESTful API design: token auth,2017-02-24 13:17:36,<node.js><laravel><rest><api><microservices>,1,128,0,0.0,1,<p>I'm designing a standard compliant RESTful API. Each resource has its own end points. There are no verbs in my resources etc...</p>&#xA;&#xA;<p>We use JWT for stateless client authentication.</p>&#xA;&#xA;<p>How can I still utilise a semantic design with auth routes? </p>&#xA;&#xA;<p>E.g. </p>&#xA;&#xA;<pre><code>/auth/login&#xA;/auth/logout&#xA;/auth/reset&#xA;/auth/forgot &#xA;</code></pre>&#xA;&#xA;<p>These endpoint contain verbs... I can't workout how to best name the auth resource.</p>&#xA;
42549749,"Micro-services, client-side discovery",2017-03-02 08:00:04,<microservices>,2,689,0,0.0,1,"<p>I am new to microservices, so while reading about it,I can't understand the below paragraph when talking about the load balancing, how the client will do something like this?</p>&#xA;&#xA;<p>""When using clientâ€‘side discovery, the client is responsible for determining the network locations of available service instances <strong>and load balancing requests across them.</strong>""</p>&#xA;"
42528718,CQRS + Microservices: How to handle relations / validation?,2017-03-01 10:06:11,<validation><relationship><one-to-many><microservices><cqrs>,3,462,0,0.0,1,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<ul>&#xA;<li>I have 2 Microservices (which both use CQRS + Event Sourcing internally)</li>&#xA;<li>Microservice 1 manages Contacts (= Aggregate Root)</li>&#xA;<li>Microservice 2 manages Invoices (= Aggregate Root)</li>&#xA;</ul>&#xA;&#xA;<p>The recipient of an invoice must be a valid contact. </p>&#xA;&#xA;<p><strong>CreateInvoiceCommand:</strong></p>&#xA;&#xA;<pre><code>{&#xA;  ""content"": ""my invoice content"",&#xA;  ""recipient"": ""42""&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>I now read lot's of times, that the write side (= the command handler) shouldn't call the read side.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Taking this into account, the Invoices Microservice must listen to all <code>ContactCreated</code> and <code>ContactDeleted</code> events in order to know if the given recipient id is valid.</p>&#xA;&#xA;<p>Then I'd have thousands of Contacts within the Invoices Microservice, even if I know that only a few of them will ever receive an Invoice.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Is there any best practice to handle those scenarios?</p>&#xA;"
42457900,Microservices: how to handle scenario when data is needed between bounded contexts,2017-02-25 15:27:22,<node.js><microservices><bounded-contexts>,2,130,2,0.0,1,"<p>I am beginning to move a node.js project to a microservices approach and am not getting how data should be shared.  Here is an example, suppose I have the following bounded contexts: </p>&#xA;&#xA;<ul>&#xA;<li>account (used for managing user accounts, permission, login/logout, profiles, etc.)</li>&#xA;<li>image (used for managing file uploading such as profile pics, image gallery, etc. associated with a given account)</li>&#xA;<li>video (used for managing video uploading and transcoding to various formats associated with a given user)</li>&#xA;</ul>&#xA;&#xA;<p>In this example, the image and video seem to have a natural dependency on the accounts bounded context or microservice.  I assume that I could copy the accounts table over to the image and video databases and only store the accounts data that is needed but this seems like a nightmare in terms of maintaining consistency, etc. as account information is updated frequently, not to mention if other microservices need this same dependency.  I could have all three microservices to use the same database, but that would violate the recommendation that each microservices being tied to its own database.  </p>&#xA;&#xA;<p>What is the recommended approach for handling this scenario? I am still in the planning phase and want to make sure I did this the right way.</p>&#xA;"
42478361,How to login to Microservices ui app using jhipster,2017-02-27 05:24:39,<jhipster><microservices>,1,383,4,0.0,1,"<p>I am creating a <code>jhipster</code> application using microservices. I have created JHipster Registry, UAAserver, 2 microservices calling 2 Ui apps on 2 different url. Have added entities in 2 UI apps, using Mongodb for database. Have run all the above JHipster Registry, UAAserver, 2 microservices, 2 Uiapp's and i am able to see all running in Jhipster registry and tables being created in Mongodb but when i try to login to Uiapp1 or UiApp2 its throwing </p>&#xA;&#xA;<blockquote>&#xA;  <p>XMLHttpRequest cannot load <a href=""http://192.168.0.10:9999/login"" rel=""nofollow noreferrer"">http://192.168.0.10:9999/login</a>. No 'Access-Control-Allow-Origin' header is present on the requested resource. &#xA;  Origin '<a href=""http://192.168.0.10:8084"" rel=""nofollow noreferrer"">http://192.168.0.10:8084</a>' is therefore not allowed access.</p>&#xA;</blockquote>&#xA;"
42539505,How to get sorted data from one service to another over http,2017-03-01 18:42:22,<microservices><api-design>,2,313,6,1.0,1,"<p>I have service oriented architecture with couple services.</p>&#xA;&#xA;<ul>&#xA;<li><p>Product  - store list of products</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   price: number&#xA;}</code></p></li>&#xA;<li><p>Categories   - store category information + the list of product ids</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   parentCategory: number,&#xA;   productIds: number[]&#xA; }</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Lets assume that I have such category instance</p>&#xA;&#xA;<pre><code>{&#xA;   id: 1,&#xA;   parentCategory: null,&#xA;   productIds: [1, 3, 4, 5, ....]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I need to get 10 products from the category above sorted by product price. </p>&#xA;&#xA;<p>Category service processes that request and because it doesn't know anything about the price it has to make the request to Product service like that: </p>&#xA;&#xA;<pre><code>/api/products?&#xA;   ids=&lt;list of all product ids&gt;&#xA;   limit=10&#xA;   sortBy=price&#xA;</code></pre>&#xA;&#xA;<p>which won't work well when the category has a lot of products.</p>&#xA;&#xA;<p>What is the recipe in such case? &#xA;Thanks.</p>&#xA;"
47162798,Decomposition into microservices,2017-11-07 16:25:12,<design><architecture><microservices><bounded-contexts>,3,86,0,2.0,1,"<p>I have a question regarding decomposition into microservices. Suppose we have 2 microservices: <strong>User</strong> and <strong>Product</strong>. Suppose we now have a requirement to add categories to the system. More specifically, a product has one or more categories (e.g the product red miniature ferrari belongs to categories toys and cars) and a user can have categories which she likes (e.g. toys and shoes). Now when we retrieve the full list of products we want them to be sorted such that the products that fall in the preferred user categories are at the top. </p>&#xA;&#xA;<p>Basically be have a concept that is shared between microservices (in this case category). How to best model this in a microarchitecture environment? I see two solutions:</p>&#xA;&#xA;<p><strong>Solution 1:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Make a separate â€œcategories"" microservice which manages CRUD of categories</li>&#xA;<li>In the product service have an API call to link category ids to a product</li>&#xA;<li>In the user service have an API call to link category ids to a user</li>&#xA;<li>In the product service we have an API call to fetch products ordered on preference. To make this work the product service needs to call the user service to get the user categories (or listen to events emitted by user services)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong> </p>&#xA;&#xA;<ul>&#xA;<li><p>Make a separate â€œcategoriesâ€ microservice which manages CRUD of categories</p></li>&#xA;<li><p>The categories service also has an API call to link product ids to categories</p></li>&#xA;<li><p>The categories service also has an API call to link user ids to categories</p></li>&#xA;<li><p>In the product service we have an API call to fetch products ordered on preference (to make this work product service needs to call the categories service to get user and product categories (or listen to events)</p></li>&#xA;</ul>&#xA;&#xA;<p>What are the advantages/disadvantage to both solutions? </p>&#xA;"
47324935,Registering Spring Cloud Microservice with Eureka server,2017-11-16 08:32:51,<microservices><spring-cloud><eureka>,1,100,0,0.0,1,"<p>I am trying to create spring cloud microservices and also need to include eureka server and zuul as spring cloud tools. Now I created one module in my one spring boot project. I registered that service with eureka server. And also I created one spring boot project for adding zuul service discovery and also registered with eureka project. </p>&#xA;&#xA;<ul>&#xA;<li>Here my doubt is that When I am adding another module as another spring boot project, Can I register that application also with my current eureka server as client? What type of relation that eureka server project and microservice having? one-To-One or One-To-Many? Can I register 3 or 4 microservices with one eureka server as client?</li>&#xA;</ul>&#xA;"
47265946,Microservice Project Structure Using Spring boot and Spring Cloud,2017-11-13 13:53:05,<spring-boot><microservices>,3,1693,0,1.0,1,"<p>I am trying to convert a normal monolithic web application into microservices structure using spring boot and spring cloud. I am actually trying to create Angular 2 front-end application and calls these my developed microservices in the cloud. And I am already started to break the modules into independent process's structure for microservice architecture.</p>&#xA;&#xA;<ul>&#xA;<li>Here my doubt is that , When designing the flow of control and microservice structure architecture, Can I use only one single spring boot project using different controller for this entire web application back end process.? Somewhere I found that when I am reading develop all microservices using 2 different spring boot project. Actually I am new to spring and spring cloud. I have lot of confusions in my task. Can any one help to clarify that is possible to create all services in single project by using different modules ???</li>&#xA;</ul>&#xA;"
47181503,Response Status HTTP SpringBoot Kotlin Api,2017-11-08 13:53:29,<api><spring-boot><kotlin><microservices>,2,433,0,0.0,1,"<p>I'm starting in kotlin and if anyone can help me, I've had a question about how I can return the http status, when my true if it returns 200 Ok and when it's any other way, return 404 NotFound.</p>&#xA;&#xA;<p>I tried to do according to the code below, but it is only returning status 200 Ok, in all situations</p>&#xA;&#xA;<pre><code>@DeleteMapping(""{id}"")&#xA;fun delete(@PathVariable id: Long): ResponseEntity&lt;Unit&gt; {&#xA;    try {&#xA;        if (dogRepository.exists(id)) {&#xA;            dogRepository.delete(id)&#xA;        }&#xA;        return ResponseEntity.ok().build()&#xA;    } catch (e: Exception) {&#xA;        return ResponseEntity.notFound().build()&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
47287743,Microservice of commercetools cart API,2017-11-14 14:01:57,<api><e-commerce><microservices><commercetools>,1,195,0,1.0,1,"<p>As per documentations of commercetools, all the microservices(carts, order, shipping method etc) are independent of each other. </p>&#xA;&#xA;<p><strong>Calling the below API in POSTMAN :</strong>&#xA;<a href=""https://api.sphere.io/"" rel=""nofollow noreferrer"">https://api.sphere.io/</a>{{myproject-key}}/carts/{{cartId}}</p>&#xA;&#xA;<p><strong>Body part:</strong>&#xA;{&#xA;  ""version"": 5,&#xA;  ""actions"": [{&#xA;    ""action"": ""addLineItem"",&#xA;    ""productId"": ""6d22957d-7c42-4663-95c3-099c11016999"",&#xA;    ""variantId"": 1&#xA;  }]&#xA;}</p>&#xA;&#xA;<p>The above yields me the correct response whenever I provide the productID from the commercetools platform catalog.&#xA;But if I try to give my own product ID(from DB hosted at Localhost) why can't I add items to the cart.</p>&#xA;&#xA;<p>Instead it gives me the following error:&#xA;Error Log: ""The referenced object of type 'product' with identifier '6d22957d-7c42-4663-95c3-099c11016999' not found.""</p>&#xA;&#xA;<p><em>This means both the services i.e product catalog and cart are tightly coupled.&#xA;Does this mean that the microservices cannot be used individually?</em></p>&#xA;&#xA;<p>Basically my end question is :<strong>Can I use commercetools individual services such as Cart, Shipping method, Order alone in my existing e-commerce site?</strong></p>&#xA;"
47304927,Microservice Architecture design,2017-11-15 10:26:12,<mysql><microservices>,2,252,0,0.0,1,"<p>I have few doubts on Microservice architecture.</p>&#xA;&#xA;<p>Lets say there are microservices A, B and C.&#xA;<strong>A</strong> maintains the context of a job apart from other things it does and <strong>B,C</strong> work to fulfill that job by doing respective tasks for that job.</p>&#xA;&#xA;<p>Here I have questions.</p>&#xA;&#xA;<p><strong>1. DB design</strong></p>&#xA;&#xA;<p>I am talking about SQL here.&#xA;Usage of foreign keys simplifies lot of things. &#xA;But as I understand microservice architecture, every microservice maintaines its own data and data has to be queried from that service if required.</p>&#xA;&#xA;<p>Does it mean no foreign keys referring to tables in another microservices?</p>&#xA;&#xA;<p><strong>2. Data Flow</strong></p>&#xA;&#xA;<p>As I see here are two ways.</p>&#xA;&#xA;<p>All the queries are done using <strong>jobId</strong> maintained uniquely in all microservices for a job.</p>&#xA;&#xA;<ul>&#xA;<li>Client requests go directly to individual service for a task.  To get summary of the job, client queries individual microservices collects the data and passes to user.</li>&#xA;<li>Do everything through coordinating microservice. Client requests go to service A and in tern service A will gather info from all other microservices for that <strong>jobId</strong> and passed that to user.</li>&#xA;</ul>&#xA;&#xA;<p>Which of the above two has to be followed and why?</p>&#xA;"
47282162,API Gateway with microservices and presentation layer,2017-11-14 09:35:37,<cloud><microservices><soa><pivotal-cloud-foundry><api-gateway>,1,112,1,0.0,1,<p>I am working on microservices architecture and using API gateway pattern to secure the services and everything looks good so far.&#xA;We have presentation layer/orchestration layer(a monolith RoR application) that is supposed to orchestrate the microservices for a user functionality.&#xA;We are deploying everything to our company's enterprise PAAS platform. My question is should i make the presentation layer fall beneath the API gateway(or not)? &#xA;What could be the PROS/CONS of the approach?  </p>&#xA;
47146939,Managing test ssl certificates on dev environments,2017-11-06 22:30:40,<java><spring-boot><https><ssl-certificate><microservices>,1,194,1,1.0,1,"<p>I have a Spring Boot web service, and I want to make it use https instead of http.</p>&#xA;&#xA;<p>To this end, I have already created a keystore containing a self-signed certificate, and configured the server using spring boot properties.&#xA;The certificate has name localhost, to match the local environment.</p>&#xA;&#xA;<p>Now I want to test it on a proper dev environment, but the certificate doesn't work any more, because the name needs to be the name of the environment.</p>&#xA;&#xA;<p>What is the preferred way of dealing with this? Should I create a separate keystore/certificate per environment as well as a separate yml file with their respective properties? </p>&#xA;"
47228231,Spring Cloud Eureka with Non-JVM Language (PHP) / Discovering Services Using Eureka REST Endpoints,2017-11-10 17:31:52,<java><php><microservices><spring-cloud><spring-cloud-netflix>,1,458,2,1.0,1,"<p>I'm using Spring Eureka as discovery server in my application which is implemented using microservices architecture. The services are mostly created with PHP, and they register themselves on start-up using Eureka REST endpoints and each one of them sends a heartbeat every 30 seconds and everything works well.</p>&#xA;&#xA;<p>Now, imagine service A wants to talk to service B. How does the discovery happen?&#xA;Currently I think service A should send a GET request to <code>http://localhost:8761/eureka/apps/service-B</code> endpoint, retrieve the list of current instances of service B and choose between them. Is it the right approach?&#xA;What about load-balancing? Should I implement that in my services to ask for a different instance every time? Or choose between them randomly?</p>&#xA;&#xA;<p>Any help would be greatly appreciated.</p>&#xA;&#xA;<p><strong>Update</strong>: Take a look at <a href=""https://github.com/piwvh/php-eureka"" rel=""nofollow noreferrer"">this library</a>.</p>&#xA;"
47184194,common POM based plugins across multiple microservice projects,2017-11-08 15:58:41,<maven><pom.xml><maven-plugin><microservices>,1,42,3,0.0,1,"<p>I am trying to figure out a way to import a set of common Maven plugins, across multiple microservice projects?</p>&#xA;&#xA;<p>Idea is to maintain a single place to manage all the common plugins - like jacoco, javadocs etc.</p>&#xA;&#xA;<p>We totally want to avoid the parent POM way of handling it.</p>&#xA;"
47309649,MicroService path /api/v1/ or /v1/api/,2017-11-15 14:12:46,<java><microservices><grizzly>,1,51,4,0.0,1,"<p>I'm building a MicroSerive and I was planning to publish services using this URI naming convention:</p>&#xA;&#xA;<pre><code>https://host:port/api/v1/service1&#xA;https://host:port/api/v1/service2&#xA;https://host:port/api/v2/service1&#xA;https://host:port/api/v2/service2&#xA;</code></pre>&#xA;&#xA;<p>But I've also seen URIs named like this (ie vx and api 'swapped'):</p>&#xA;&#xA;<pre><code>https://host:port/v1/api/service1&#xA;https://host:port/v1/api/service2&#xA;https://host:port/v2/api/service1&#xA;https://host:port/v2/api/service2&#xA;</code></pre>&#xA;&#xA;<p>In my opinion, the first approach is better. Are there any reasons to go for the second approach?</p>&#xA;"
49534740,Communication between two microservices by Docker hostname,2018-03-28 12:36:59,<docker><docker-compose><microservices>,1,316,0,0.0,1,"<p><strong>How it works now:</strong></p>&#xA;&#xA;<p>Microservice X makes REST API request to Microservice Y with static ip</p>&#xA;&#xA;<pre><code>http://{ip-address}:{port}/doSomething&#xA;</code></pre>&#xA;&#xA;<p><strong>The problem:</strong></p>&#xA;&#xA;<p>The problem is that I can no long guarantee that static ip.&#xA;I wan't to solve this by using the docker hostname instead:</p>&#xA;&#xA;<pre><code>http://hostname:{port}/doSomething&#xA;</code></pre>&#xA;&#xA;<p>I tried achieving this by creating a used defined network in docker-compose:</p>&#xA;&#xA;<pre><code>    #part of docker-compose file&#xA;    streamapp:&#xA;      hostname: twitterstreamapp&#xA;      image: twitterstreamapp&#xA;      container_name: twitterstreamapp&#xA;      restart: always&#xA;      ports:&#xA;        - '8090:8080'&#xA;      build:&#xA;        context: ./TwitterStream&#xA;        dockerfile: Dockerfile&#xA;&#xA;    storeapp:&#xA;      hostname: twitterstoreapp&#xA;      image: twitterstoreapp&#xA;      container_name: twitterstoreapp&#xA;      restart: always&#xA;      ports:&#xA;        - '8095:8080'&#xA;      build:&#xA;        context: ./TwitterStore&#xA;        dockerfile: Dockerfile&#xA;      depends_on:&#xA;        - 'mysql-db'&#xA;      networks:&#xA;        - backend&#xA;&#xA;  volumes:&#xA;    MyDataVolume:&#xA;&#xA;  networks:&#xA;    backend:&#xA;      driver: bridge&#xA;</code></pre>&#xA;&#xA;<p>I can ping from Container X to Container Y. But not Curl for example.&#xA;How can I fix this, or is this not the best way to achieve what I want.</p>&#xA;"
49476498,"In microservices, endpoint overloading vs. separate endpoints",2018-03-25 13:39:01,<java><jax-rs><microservices><publish-subscribe><endpoint>,1,74,0,0.0,1,"<p>This question is similar to <a href=""https://stackoverflow.com/questions/3316402/method-overloading-vs-optional-parameter-in-c-sharp-4-0"">method overloading vs optional parameter</a>&#xA;but 1) it relates to a service endpoints, and 2) optional parameter may indicate different semantic meaning:</p>&#xA;&#xA;<p>Suppose I provide an endpoint in my service, say ""/messaging/subscribe"" which basically allows the client to subscribe to some topics. So the subscribe request object may contain a list of topic names and information sufficient  enough for the service to send notifications to the subscribing client when a message is published to one of the subscribed topics.   </p>&#xA;&#xA;<p>It's also important to note that the service is agnostic to the content of these messages, and that is separately commnuicated between publishers and subscribers. The service just needs to pass some encoding of a published message to all subscribers and they know how to decode it.<br>&#xA;Suppose also that clients who wish to subscribe via this endpoint require a SUBSCRIBER role.</p>&#xA;&#xA;<p>Now let's say that I want the service to provide a new, topic monitoring functionality: a client of this new functionality still needs to specify a list of topic names and the means to notify it, but this kind of service:<br>&#xA;1) would send meta-data notifications about the topics of interest. These notifications would convey meta-data information about topics such as: ""subscriber x has been disconnected from topic y"", or ""subscriber v subscribed to topic q"", or ""the number of subscribers on topic z just dropped below 3"", or ""there have been less than 5 notifications sent to topic w in the last hour""<br>&#xA;2) clients of this service require a MONITOR role.<br>&#xA;3) Note that the messages in these notifications would be system-defined messages. So their susbcribers could receive a service-defined object representing the message data (e.g. event type, subscriber id, topic name, etc').</p>&#xA;&#xA;<p>There are two ways of handing this:<br>&#xA;A new endpoint may be created for the monitoring service, e.g. ""/messaging/monitor"", with same request object information as the existing subscribe endpoint, and perhaps additional parameters.</p>&#xA;&#xA;<p>Alternatively, the existing endpoint may be overloaded to handle both subscribe and monitor requests, where the difference is conveyed in additional parameters. For example, the client could specify a boolean attribute, named ""monitor"", in the request object. So if the request does not include this ""optional"" request attribute or it's value is false, the request is a normal subscibe to the topics. Alternatively if the parameter specifies monitor==true it means the client is only interested in meta-data events related to the specified topics.&#xA;Role authorization may be checked by the code based on the value of this 'monitor' request attribute.</p>&#xA;&#xA;<p>What are the considerations one should examine in order to decide which of the two alternatives is preferrrable? </p>&#xA;&#xA;<p>Not that it matters, but the implementation uses Vertx in Java...</p>&#xA;"
49638004,UI microservice - No security are there any implications?,2018-04-03 19:44:23,<java><spring-security><microservices><spring-cloud>,2,74,0,0.0,1,"<p>This is probably super dumb.</p>&#xA;&#xA;<p><strong>Are their any implications</strong> of having a Microservice that simply serves a UI with no security?</p>&#xA;&#xA;<p>I have security at the gateway level, the UI microservice simply serves the web app, there's nothing in the app that i would like to protect. I could go as far as ensuring that only the gateway can call it directly no other origin is allowed access.</p>&#xA;&#xA;<p>I have Spring-Security on my class path but i've disabled it using:</p>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<pre><code>security:&#xA;  basic:&#xA;    enabled: false&#xA;&#xA;management:&#xA;  security:&#xA;    enabled: false&#xA;</code></pre>&#xA;&#xA;<p>I haven't made any configuration changes to the security config for example this service has no class that extends <code>WebSecurityConfigurerAdapter</code>.</p>&#xA;&#xA;<p>This service doesn't call anything else it just serves an Angular application contained in <code>/resource/public</code> with:</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class AngularApplicationController {&#xA;&#xA;      // serve UI&#xA;      @GetMapping(value = ""/{path:[^\\.]*}"")&#xA;      public String redirect() {&#xA;        return ""forward:/"";&#xA;      }&#xA;&#xA;}&#xA;</code></pre>&#xA;"
49573552,Rest communication between two microservices without static ip in Amazon ECS,2018-03-30 11:27:28,<rest><amazon-web-services><microservices><amazon-ecs>,1,147,0,0.0,1,"<p><a href=""https://stackoverflow.com/questions/49534740/communication-between-two-microservices-by-docker-hostname"">In this question, I managed to set-up REST communication between two microservices using a user-defined bridge network in docker-compose</a></p>&#xA;&#xA;<p>Now, I'm trying to do the same when hosting my microservices on AWS.&#xA;I could really use some pointers as to how to achieve this, because I'm terribly lost.</p>&#xA;&#xA;<p>I've tried following numerous tutorials, both written and on pluralsight, but none seem to be close enough to my use case.</p>&#xA;&#xA;<p>My project architecture is as follows:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/vc6TX.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/vc6TX.png</a></p>&#xA;&#xA;<p>And my project infrastructure should probably look like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/X73HA.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/X73HA.png</a></p>&#xA;&#xA;<p>Thanks</p>&#xA;"
49606124,Neo4J In Microservices Architecture,2018-04-02 06:05:19,<java><spring><neo4j><microservices><spring-data-neo4j-5>,4,176,0,0.0,1,"<p>To keep in line with DDD and Bounded Contexts, its well known that when you create your microservices you should keep separation of concerns.</p>&#xA;&#xA;<p>One of the main benefits of Neo4J is keeping your ""connected"" data in Neo4J so relationships between them are efficiently queried.</p>&#xA;&#xA;<p>These two opposing forces seem to make an microservice architecture decision difficult when choosing to use Neo4J.</p>&#xA;&#xA;<p>Do you have multiple microservices connect to Neo4J db and persist their own domain accordingly?</p>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<p>Do you have one microservice with a db connection to Neo4J that controls persistance and querying?</p>&#xA;&#xA;<p>Both dont seem quite right...</p>&#xA;"
49559239,How to subscribe to a specific routing key using RabbitMQ,2018-03-29 14:56:07,<spring><rabbitmq><microservices><spring-amqp>,1,99,1,0.0,1,"<p>We are designing a microservices architecture, we would like to use RabbitMQ as message broker.</p>&#xA;&#xA;<p>We wanted each service to have one specific queue, lets say <code>applicationQueue</code>.</p>&#xA;&#xA;<p>We also defined that our messages would be of two kinds: </p>&#xA;&#xA;<p><strong>Events</strong>: Messages that are routed to every service. If a service is interested in some specific event, it will intercept it and create a <strong>task</strong> from it.</p>&#xA;&#xA;<p><strong>Tasks</strong>: Messages representing jobs created from the service to himself, they should be publish only to the queue of the service itself</p>&#xA;&#xA;<p>We are struggling to implement that so far using Spring AMQP.</p>&#xA;&#xA;<p>We designed a message producer, so after a given http request, it would create a task for the service itself:</p>&#xA;&#xA;<p>RestController:</p>&#xA;&#xA;<pre><code>@PostMapping&#xA;public void saveProduct(@RequestBody Product product) {&#xA;    messageProducer.message(""subscriptions.product.create"", product)&#xA;            .fromHttpRequest(requestContext)&#xA;            .send();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>our send method of the message producer:</p>&#xA;&#xA;<pre><code>public void send() {&#xA;        template.convertAndSend(exchange, routingKey, payload, message -&gt; {&#xA;            if (requestContext != null) {&#xA;                extractHttpRequestInfo(message);&#xA;                message.getMessageProperties().getHeaders()&#xA;                        .put(MessageDictionary.TRANSACTION_ID, generateTransactionId());&#xA;            } else if (originalMessage != null) {&#xA;                extractMessageInfo(message);&#xA;            }&#xA;            return message;&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>RabbitMQ Configuration:</p>&#xA;&#xA;<pre><code>@Bean&#xA;List&lt;Binding&gt; binding(Queue queue, TopicExchange exchange) {&#xA;    return Arrays.asList(&#xA;            BindingBuilder.bind(queue).to(exchange).with(""*.*""),&#xA;            BindingBuilder.bind(queue).to(exchange).with(""${condohub.rabbitmq.queue.name}.#"")&#xA;    );&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and then subscribe elsewhere (The <code>@Digest</code> annotation is a custom annotation):</p>&#xA;&#xA;<pre><code>@Digest(""${condohub.rabbitmq.queue.name}.product.create"")&#xA;public void createProduct(Product product) {&#xA;    service.save(product);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any help is welcome.</p>&#xA;"
49469599,Authentication and authorisation in microservice architecture,2018-03-24 20:28:44,<authentication><jwt><graphql><microservices><go-micro>,1,322,2,2.0,1,"<p>I have multiple services:</p>&#xA;&#xA;<ul>&#xA;<li>User</li>&#xA;<li>Post</li>&#xA;<li>Comment</li>&#xA;<li>Authentication</li>&#xA;<li>GraphQL endpoint</li>&#xA;</ul>&#xA;&#xA;<p>And lets say they are connected together like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GAyiV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GAyiV.png"" alt=""example 1""></a></p>&#xA;&#xA;<p>All services are communicating through gRPC on a closed nettwork and the Authorization is done using jwt tokens</p>&#xA;&#xA;<p>Approach 1:&#xA;The graphql service is responsible for user authentication and making sure that the user is authorised to run the specified procedure. There is no user authentication between the services, but there is TLS authentication. There is no authorisation checks done by the services.</p>&#xA;&#xA;<p>Approach 2:&#xA;Each individual service makes sure that the user is authorised to run a specific procedure. An example could be voting on a post where you wold need to be signed in and have over 15 in reputation. Here it would be the Post service responsibility to check whether the user is signed in or not (authenticated) and whether it's authorised to vote. This will result in large overhead since every procedure call needs to check user authentication and authorisation through the Auth service. </p>&#xA;&#xA;<p>Is there a better approach that still preserves the security of approach 2, but creates a small overhead like approach 1?</p>&#xA;&#xA;<p><strong>-----Update-----</strong></p>&#xA;&#xA;<p>Approach 3:&#xA;Same as approach 2, but user authentication is only done in the GraphQL service using the Auth service. Authorisation is done by checking metadata passed arround. And there is TLS authentication between the services. </p>&#xA;"
49580394,sending millions of short messages over tcp socket in golang,2018-03-30 19:37:25,<go><tcp><microservices>,1,324,2,2.0,1,"<p>I'm writing two services in golang that need to send to each other about 2 million messages per second. Each message is about 50 bytes, so throughput should only be about 100MB/s. I want to use tcp for this. However, results are very slow. I configured SetNoDelay(false) to make sure that data is buffered before sending, but that didn't make any difference. </p>&#xA;&#xA;<p>I can only send about 50k messages per second, and message size doesn't matter too much, so I assume the code is blocking somewhere. Here's my test code:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import ""net""&#xA;import ""fmt""&#xA;import ""bufio""&#xA;import (&#xA;    //""strings""&#xA;    ""time""&#xA;)&#xA;&#xA;func startserver() {&#xA;    fmt.Println(""Launching server..."")&#xA;    ln, _ := net.Listen(""tcp"", "":8081"")&#xA;    conn, _ := ln.Accept()&#xA;&#xA;    for {&#xA;        bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Println(message)&#xA;        //newmessage := strings.ToUpper(message)&#xA;        //conn.Write([]byte(newmessage + ""\n""))&#xA;    }&#xA;}&#xA;&#xA;func startclient() {&#xA;    time.Sleep(time.Second) // so that server has time to start&#xA;    servAddr := ""127.0.0.1:8081""&#xA;    tcpAddr, _ := net.ResolveTCPAddr(""tcp"", servAddr)&#xA;    conn, _ := net.DialTCP(""tcp"", nil, tcpAddr)&#xA;    conn.SetNoDelay(false)&#xA;    conn.SetWriteBuffer(10000)&#xA;    msg := ""abc\n""&#xA;    start := time.Now()&#xA;    for i := 0; i &lt; 1000000; i++ {&#xA;        conn.Write([]byte(msg))&#xA;        //bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Print(""Message from server: "", response)&#xA;    }&#xA;    fmt.Println(""took:"", time.Since(start))&#xA;}&#xA;&#xA;func main() {&#xA;    go startserver()&#xA;    startclient()&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestion?</p>&#xA;"
49488573,Communication between microservices / responsibilities,2018-03-26 09:52:27,<design-patterns><microservices>,2,93,2,0.0,1,"<p>I'm new with microservices, and after reading many documentation, I'm still having some doubts about many things. I'm putting an example of what I want to achieve now:</p>&#xA;&#xA;<p><strong>Scenario:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice architecture.  </li>&#xA;<li>The FileServer will store files from several sources.  </li>&#xA;<li>Each microservice has its own database.</li>&#xA;</ul>&#xA;&#xA;<p>TemplateService database:</p>&#xA;&#xA;<ul>&#xA;<li>TemplateId (PK): guid</li>&#xA;<li>FileId (~FK): guid</li>&#xA;<li>TemplateName</li>&#xA;</ul>&#xA;&#xA;<p>FileService database:</p>&#xA;&#xA;<ul>&#xA;<li>FileId (PK): guid</li>&#xA;<li>FileName</li>&#xA;<li>Path</li>&#xA;</ul>&#xA;&#xA;<p><strong>Use case:</strong> &#xA;A user wants to upload a template to the application.</p>&#xA;&#xA;<p><strong>Questions:</strong> (and my ideas)</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/bTlRJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bTlRJ.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Who creates the GUID (FileId)?</p>&#xA;&#xA;<ol>&#xA;<li>UI creates the GUID, and calls both, Template Service and File Service.</li>&#xA;<li>UI calls Template Service and this service creates the GUID, and then call the File Service</li>&#xA;</ol>&#xA;&#xA;<p>Who deals with the File Server?</p>&#xA;&#xA;<ol>&#xA;<li>UI sends the File directly to the FileServer (or maybe to another service such as FileManager?)</li>&#xA;<li>UI sends the File to FileService, and this service store it in the FileServer.</li>&#xA;</ol>&#xA;&#xA;<p><strong>UPDATED: 2018/03/27</strong> </p>&#xA;&#xA;<p>So, my new design looks like this for a UserInput SaveTemplate().</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/enHNM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/enHNM.png"" alt=""enter image description here""></a></p>&#xA;"
49637598,"Getting an error ""Cause: AMQ119031: Unable to validate user"" in Spring-Boot app",2018-04-03 19:16:24,<spring-boot><microservices><spring-jms><jboss-eap-7><activemq-artemis>,1,167,3,0.0,1,"<p>I'm getting the following error when trying to connect to ActiveMQ Artemis Queue deployed on JBoss EAP 7.1. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: DefaultMessageListenerContainer: Could not refresh JMS&#xA;  Connection for destination 'jms/queue/QueueA' - retrying using&#xA;  FixedBackOff{interval=5000, currentAttempts=139,&#xA;  maxAttempts=unlimited}. Cause: AMQ119031: Unable to validate user</p>&#xA;</blockquote>&#xA;&#xA;<p>Here is the code I'm using:</p>&#xA;&#xA;<pre><code>@Bean public DefaultMessageListenerContainer myFactory() throws NamingException { &#xA;   DefaultMessageListenerContainer listenerContainer = new DefaultMessageListenerContainer();&#xA;   listenerContainer.setConnectionFactory(getConnectionFactory());&#xA;   listenerContainer.setDestinationName(""jms/queue/QueueA"");&#xA;   listenerContainer.setMessageListener(new MessageReceiver());&#xA;   return listenerContainer; &#xA;}&#xA;&#xA;private ConnectionFactory getConnectionFactory() throws NamingException { &#xA;   final Properties env = new Properties();&#xA;   env.put(Context.INITIAL_CONTEXT_FACTORY, org.wildfly.naming.client.WildFlyInitialContextFactory); &#xA;   env.put(Context.PROVIDER_URL, ""http-remoting://localhost:8080""); &#xA;   env.put(Context.SECURITY_PRINCIPAL, ""Username""); &#xA;   env.put(Context.SECURITY_CREDENTIALS, ""Password""); &#xA;   InitialContext ic = new InitialContext(env); &#xA;   return (ConnectionFactory) ic.lookup(""jms/RemoteConnectionFactory"");&#xA;}&#xA;</code></pre>&#xA;"
49610008,Swagger with spring boot microservice,2018-04-02 11:01:07,<spring-boot><filter><swagger><microservices><swagger-ui>,1,98,5,0.0,1,<p>I have a <strong>microservice-A</strong> which gets the token as a header from another <strong>microservice-B</strong>. Now I want to implement <strong>swagger2 in microservice-A</strong>. The problem is every request <strong>flows through microservice-B</strong>. So <strong>swagger-ui throws error</strong> in local as </p>&#xA;&#xA;<blockquote>&#xA;  <p>it is not able to get those header parameter which microservice-B is&#xA;  trying to fetch.</p>&#xA;</blockquote>&#xA;
49659871,Java circuit breaker running in request thread,2018-04-04 20:28:50,<java><microservices><hystrix><circuit-breaker>,1,110,7,1.0,1,"<p>I have been considering Netflix OSS circuit breaker solution - Hystrix.</p>&#xA;&#xA;<p>Everything sounds good but I think that having the command run in a different thread does not make sense in my use case scenario. </p>&#xA;&#xA;<p>That is because the work done by my request handler requires very little computation before calling the remote service. Also, there is nothing I can do while waiting for the response.</p>&#xA;&#xA;<p>Example in Pseudo code:</p>&#xA;&#xA;<p>@post(""/token"")&#xA;token(@body authResult){&#xA;  Validate authResult&#xA;  Get id from authResult &#xA;  Call a remote service to get authz token&#xA;  Return authz token&#xA;}</p>&#xA;&#xA;<p>I would like to do the remote call using hystrix but I do not think it makes sense to execute the command in a separate thread since I would be blocked anyway. </p>&#xA;&#xA;<p>Any suggestions? Is it possible to run hystrix command in the same thread as the caller?</p>&#xA;"
48327939,Does WCF(Windows Communication Foundation) have a Micro Web Service feature?And does it only supported by REST?,2018-01-18 18:24:08,<rest><web-services><wcf><soap><microservices>,2,17,0,0.0,1,<p>my question is this:</p>&#xA;&#xA;<p>Does WCF(Windows Communication Foundation) have a Micro Web Service feature?And does it only supported by REST?</p>&#xA;
48308464,Transfering multiple files and meta data in POST request,2018-01-17 19:19:04,<rest><post><networking><microservices><transfer>,1,44,0,0.0,1,"<p>I've got a Python Django Backend running, and want to design a microservice. This microservices has a rest POST endpoint open. Now I want to transfer multiple binary files and some meta data (as json?) in a single POST request from Django to the microservice. What would be the besteht way to accomplish this.&#xA;I thought about transfering the data as multipart, but I think it's Mord for HTML forms. Also thought about protobuf. Would appreciate if you could help me, what's the most common way for such problems? What's the most efficient way?&#xA;It shouldn't be important, that I am using Django or Python for the answer.</p>&#xA;"
48341375,Where to add my registration logic when using microservice architecture?,2018-01-19 12:40:56,<spring-boot><spring-security><microservices><spring-cloud>,2,73,0,0.0,1,"<p>In my microservice architecture project ,it would have oauth service to authenticate the user and the gateway work as the front end api. </p>&#xA;&#xA;<p>My question is where to write the register logic ? </p>&#xA;&#xA;<p>In the oauth service or in the gateway?</p>&#xA;&#xA;<p><strong>Finally solution:</strong>&#xA;I do that in the user service and call from the gateway. Everything seems to work fineï¼</p>&#xA;"
48344922,Unable save data into JHipster Micro Service using Gateway UI,2018-01-19 15:55:56,<java><spring><spring-boot><jhipster><microservices>,1,78,0,0.0,1,"<p>I set up my micro-services application with one microservice and one gateway. I generated micro service entities using $jhipster import-jdl books.jh command and entities UI in gateway. JDL file in the gateway is slightly different with options like skipServer. I used below file to generate UI for entities in gateway, and those entities generated in microservices. I was looking at all docs and issues raised by other people, but I couldn't find proper to documentation to generate Entities using Micro Service and UI for those entities in the gateway (need to specify the path of micro service in JDL file). Correct me if my syntax is incorrect. Everything went well, when open I entity page and try to save the object, it did not save it. I got following error on console.</p>&#xA;&#xA;<pre><code>POST http://localhost:8080/api/addresses 404 error (not found)&#xA;</code></pre>&#xA;&#xA;<p>Books Micro Service JDL file:</p>&#xA;&#xA;<pre><code>entity Address&#xA;{&#xA;    streetName  String required,&#xA;    apartmentOrHouseNumber  String,&#xA;    city    String  required,&#xA;    zipcode Long    required,&#xA;    state   String,&#xA;    country String&#xA;}&#xA;&#xA;entity BookCoverType&#xA;{&#xA;    coverType   String  required&#xA;}&#xA;&#xA;&#xA;entity Author&#xA;{&#xA;    firstName   String  required,&#xA;    lastName    String  required,&#xA;    middleName  String,&#xA;}&#xA;&#xA;entity Book &#xA;{&#xA;    bookName String required,&#xA;    bookTitle String    required,&#xA;    numberOfPages Integer   required,&#xA;}&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;relationship OneToOne &#xA;{&#xA;    //Book{bookCoverType(coverType)} to BookCoverType&#xA;    Author{address(streetName)} to Address&#xA;}&#xA;&#xA;relationship OneToMany &#xA;{&#xA;    BookCoverType{book(bookTitle)} to Book&#xA;    Book{author(firstName)} to Author&#xA;    Author{book(bookTitle)} to Book&#xA;&#xA;}&#xA;&#xA;&#xA;paginate Book with pagination&#xA;paginate Author with pagination&#xA;</code></pre>&#xA;&#xA;<p>BookStore gateway JDL file:</p>&#xA;&#xA;<pre><code>entity Address&#xA;{&#xA;    streetName  String required,&#xA;    apartmentOrHouseNumber  String,&#xA;    city    String  required,&#xA;    zipcode Long    required,&#xA;    state   String,&#xA;    country String&#xA;}&#xA;&#xA;entity BookCoverType&#xA;{&#xA;    coverType   String  required&#xA;}&#xA;&#xA;&#xA;entity Author&#xA;{&#xA;    firstName   String  required,&#xA;    lastName    String  required,&#xA;    middleName  String,&#xA;}&#xA;&#xA;entity Book &#xA;{&#xA;    bookName String required,&#xA;    bookTitle String    required,&#xA;    numberOfPages Integer   required,&#xA;}&#xA;&#xA;&#xA;&#xA;&#xA;relationship OneToOne &#xA;{&#xA;    //Book{bookCoverType(coverType)} to BookCoverType&#xA;    Author{address(streetName)} to Address&#xA;}&#xA;&#xA;relationship OneToMany &#xA;{&#xA;    BookCoverType{book(bookTitle)} to Book&#xA;    Book{author(firstName)} to Author&#xA;    Author{book(bookTitle)} to Book&#xA;&#xA;}&#xA;&#xA;skipServer *&#xA;microservice * with books&#xA;&#xA;paginate Book with pagination&#xA;paginate Author with pagination&#xA;</code></pre>&#xA;&#xA;<p>JHipster version: 4.13.3</p>&#xA;&#xA;<p>JHipster info:</p>&#xA;&#xA;<pre><code>Using JHipster version installed globally&#xA;Executing jhipster:info&#xA;Options: &#xA;&#xA;Just found a `.yo-rc.json` in a parent directory.&#xA;Setting the project root at: /Users/pjadda/kubernetesapps/bookstore&#xA;Welcome to the JHipster Information Sub-Generator&#xA;&#xA;##### **JHipster Version(s)**&#xA;&#xA;bookstore@0.0.0 /Users/pjadda/kubernetesapps/bookstore&#xA;â””â”€â”€ generator-jhipster@4.13.3&#xA;&#xA;&#xA;&#xA;##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**&#xA;&#xA;&#xA;&lt;details&gt;&#xA;&lt;summary&gt;.yo-rc.json file&lt;/summary&gt;&#xA;&lt;pre&gt;&#xA;{&#xA;  ""generator-jhipster"": {&#xA;    ""promptValues"": {&#xA;      ""packageName"": ""com.bookstore""&#xA;    },&#xA;    ""jhipsterVersion"": ""4.13.3"",&#xA;    ""baseName"": ""bookstore"",&#xA;    ""packageName"": ""com.bookstore"",&#xA;    ""packageFolder"": ""com/bookstore"",&#xA;    ""serverPort"": ""8080"",&#xA;    ""authenticationType"": ""jwt"",&#xA;    ""cacheProvider"": ""hazelcast"",&#xA;    ""enableHibernateCache"": false,&#xA;    ""websocket"": false,&#xA;    ""databaseType"": ""sql"",&#xA;    ""devDatabaseType"": ""mysql"",&#xA;    ""prodDatabaseType"": ""mysql"",&#xA;    ""searchEngine"": ""elasticsearch"",&#xA;    ""messageBroker"": false,&#xA;    ""serviceDiscoveryType"": ""eureka"",&#xA;    ""buildTool"": ""maven"",&#xA;    ""enableSocialSignIn"": false,&#xA;    ""enableSwaggerCodegen"": true,&#xA;    ""jwtSecretKey"": ""replaced-by-jhipster-info"",&#xA;    ""clientFramework"": ""angularX"",&#xA;    ""useSass"": true,&#xA;    ""clientPackageManager"": ""yarn"",&#xA;    ""applicationType"": ""gateway"",&#xA;    ""testFrameworks"": [],&#xA;    ""jhiPrefix"": ""jhi"",&#xA;    ""enableTranslation"": false&#xA;  }&#xA;}&#xA;&lt;/pre&gt;&#xA;&lt;/details&gt;&#xA;&#xA;&#xA;##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**&#xA;&#xA;&lt;details&gt;&#xA;&lt;summary&gt;JDL entity definitions&lt;/summary&gt;&#xA;&#xA;&lt;pre&gt;&#xA;entity Address (address) {&#xA;  streetName String required,&#xA;  apartmentOrHouseNumber String,&#xA;  city String required,&#xA;  zipcode Long required,&#xA;  state String,&#xA;  country String&#xA;}&#xA;entity BookCoverType (book_cover_type) {&#xA;  coverType String required&#xA;}&#xA;entity Author (author) {&#xA;  firstName String required,&#xA;  lastName String required,&#xA;  middleName String&#xA;}&#xA;entity Book (book) {&#xA;  bookName String required,&#xA;  bookTitle String required,&#xA;  numberOfPages Integer required&#xA;}&#xA;&#xA;relationship OneToOne {&#xA;  Author{address(streetName)} to Address&#xA;}&#xA;relationship OneToMany {&#xA;  Book{author} to Author{book},&#xA;  BookCoverType{book} to Book{bookCoverType},&#xA;  Author{book} to Book{author}&#xA;}&#xA;&#xA;paginate Author, Book with pagination&#xA;&#xA;&lt;/pre&gt;&#xA;&lt;/details&gt;&#xA;&#xA;&#xA;##### **Environment and Tools**&#xA;&#xA;java version ""1.8.0_144""&#xA;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)&#xA;Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)&#xA;&#xA;git version 2.13.1&#xA;&#xA;node: v8.9.3&#xA;&#xA;npm: 5.6.0&#xA;&#xA;bower: 1.8.2&#xA;&#xA;yarn: 1.3.2&#xA;&#xA;Docker version 17.12.0-ce, build c97c6d6&#xA;&#xA;docker-compose version 1.18.0, build 8dd22a9&#xA;&#xA;Congratulations, JHipster execution is complete!&#xA;Address.json&#xA;&#xA;{&#xA;    ""fluentMethods"": true,&#xA;    ""relationships"": [],&#xA;    ""fields"": [&#xA;        {&#xA;            ""fieldName"": ""streetName"",&#xA;            ""fieldType"": ""String"",&#xA;            ""fieldValidateRules"": [&#xA;                ""required""&#xA;            ]&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""apartmentOrHouseNumber"",&#xA;            ""fieldType"": ""String""&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""city"",&#xA;            ""fieldType"": ""String"",&#xA;            ""fieldValidateRules"": [&#xA;                ""required""&#xA;            ]&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""zipcode"",&#xA;            ""fieldType"": ""Long"",&#xA;            ""fieldValidateRules"": [&#xA;                ""required""&#xA;            ]&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""state"",&#xA;            ""fieldType"": ""String""&#xA;        },&#xA;        {&#xA;            ""fieldName"": ""country"",&#xA;            ""fieldType"": ""String""&#xA;        }&#xA;    ],&#xA;    ""changelogDate"": ""20180119060434"",&#xA;    ""entityTableName"": ""address"",&#xA;    ""dto"": ""no"",&#xA;    ""pagination"": ""no"",&#xA;    ""service"": ""no"",&#xA;    ""jpaMetamodelFiltering"": false,&#xA;    ""skipServer"": true&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Browsers and Operating System</p>&#xA;&#xA;<pre><code>macOS High Sierra, Chrome browser&#xA;</code></pre>&#xA;"
48251083,Deploying Spring boot application in AWS lambda,2018-01-14 15:24:55,<java><spring-boot><aws-lambda><microservices>,2,2243,0,0.0,1,"<p>I have an existing web application built in Javascript, Spring Boot and MySQL. I want to deploy the application (frontend + backend) in AWS Lambda. Please advise how can this be achieved, as I am not sure how each restful API call should be mapped to API gateway, that will in turn invoke the lambda functions (which should be the existing java methods from RestConroller).</p>&#xA;&#xA;<p>Thanks and appreciate your advise.</p>&#xA;"
48347363,Dependency Injection of Value Types,2018-01-19 18:24:11,<c#><azure><dependency-injection><microservices><azure-service-fabric>,1,66,1,1.0,1,"<p>I am creating an Azure Service Fabric service and relying on the native .NET framework for dependency injection through constructors. The problem is: one of the constructors has as parameter a value type (specifically System.TimeSpan). How should/can I register such type with the dependency injection framework?</p>&#xA;&#xA;<p>To clarify: I am trying to follow the examples shown here: <a href=""https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection#service-lifetimes-and-registration-options"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection#service-lifetimes-and-registration-options</a></p>&#xA;"
48313647,Event Sourcing Microservices in Node,2018-01-18 04:02:02,<node.js><microservices><event-sourcing>,1,295,2,1.0,1,"<p>I am trying to build a microservices POC and trying to incorporate concepts of ES/DDD/CQRS, so I had a couple of questions for practitioners out there who have actually implemented this:</p>&#xA;&#xA;<p>1) Is it possible to build microservices without using ES, since it seems that this adds a major amount of complexity ? </p>&#xA;&#xA;<p>2) Has anyone actually built production microservices using ES/DDD/CQRS with Nodejs, did you use any framework ? I ask this because it seems like if you want to go down this route, you have to build all of the infrastructure yourself, as no full framework such as axon, or akka, exists in the node community, and you basically have to roll your own.</p>&#xA;&#xA;<p>3) What would be the best technology stack to use for building microservices which has a decent framework available to let you concentrate on business logic ?</p>&#xA;&#xA;<p>4) In an EDA architecture with microservices, when you have multiple instances of the same service available, because CQRS requires a separate read/write model, where they can be implemented as two completely separate services, does this imply that for a service A there will be multiple read model services which all need to keep their projections up to date based on the events being received ?</p>&#xA;&#xA;<p>For people who have actually implemented this, can you provide your guidance/experience with this ? </p>&#xA;"
48271493,Relation of Microservices and DDD CQRS and ES,2018-01-15 22:21:43,<domain-driven-design><microservices>,3,206,2,0.0,1,"<p>For the last couple of weeks I've been starting and trying to understand DDD CQRS, ES and Microservices. &#xA;I think I've understood them individually but not as a single unit so this is why I have some misunderstandings that I hope to clarify.</p>&#xA;&#xA;<p>So first what is the relation between Microservices and DDD, can you do one without the other?&#xA;And secondly, does Bounded Contexts translate in the end into a microservice ?</p>&#xA;"
49308482,Is there a way to configure the generate method name for grpc-node client?,2018-03-15 20:19:13,<node.js><microservices><grpc>,1,172,0,0.0,1,"<p>I am hoping to use a <code>grpc-node</code> client to talk to a microservice built in <code>Go</code> using the <code>go-micro</code> framework. I am running into an issue where <code>go-micro</code> defines method names using periods (<code>.</code>) to separate namespaces and method names, whereas <code>grpc-node</code> slashes (<code>/</code>). Is there anyway to configure this pattern to have these two processes talk to each other?</p>&#xA;"
49260669,Should HTTP Based Micro Services always be Rest,2018-03-13 16:01:39,<rest><microservices>,1,39,1,0.0,1,"<p>I'm currently developing a micro service that basically provides calculation services to other micro services. It does not store data or have any resources like a sales order. It only calls other micro services and then calculates metrics and prices to return a result.</p>&#xA;&#xA;<p>I'm kind of struggling  trying to make a rest API with resources names that are nouns when all I do is calculate stuff and return results (more like an action).</p>&#xA;&#xA;<p>So can we have a micro services that behaves more like an HTTP API than a Restful service (is it a bad practice, an anti pattern , an architecture smell, ....)</p>&#xA;&#xA;<p>Regards</p>&#xA;"
49344182,Should I use pact based stub service or Wiremock.net?,2018-03-18 03:22:24,<testing><automated-tests><microservices><wiremock><pact-net>,1,232,2,0.0,1,"<p>I am researching tools for <a href=""https://martinfowler.com/articles/microservice-testing/#testing-component-introduction/"" rel=""nofollow noreferrer"">Component Testing</a> for Microservices in the dotnetcore world. </p>&#xA;&#xA;<p>Along with Component Testing I am planning to do <a href=""https://martinfowler.com/articles/microservice-testing/#testing-contract-introduction"" rel=""nofollow noreferrer"">Contract Testing</a> as well using Pact.net. </p>&#xA;&#xA;<p>While reading Pact.net here:&#xA;<a href=""https://github.com/pact-foundation/pact-net"" rel=""nofollow noreferrer"">https://github.com/pact-foundation/pact-net</a></p>&#xA;&#xA;<p>I found link to:&#xA;<a href=""https://github.com/seek-oss/seek.automation.stub"" rel=""nofollow noreferrer"">https://github.com/seek-oss/seek.automation.stub</a>&#xA;which says its a Pact based stubbing library for .NET.&#xA;This makes lot of sense to use since I am going to use Pact and my Pacts can be used for stubbing.</p>&#xA;&#xA;<p>But before this I was considering WireMock.net <a href=""https://github.com/WireMock-Net/WireMock.Net"" rel=""nofollow noreferrer"">https://github.com/WireMock-Net/WireMock.Net</a>. Has anyone tried each and share their feedback which one I should pick? WireMock seems to be very popular in community compared to this Seek Automation stub.</p>&#xA;&#xA;<p>Thanks for your help in advance!</p>&#xA;"
49252691,Microservice relationship/dependency strategy,2018-03-13 09:37:06,<architecture><microservices>,2,60,3,0.0,1,"<p>I'd like some feedback on couple different solutions to handling data dependencies and relations across micro services.</p>&#xA;&#xA;<p>Consider these services:&#xA;<a href=""https://i.stack.imgur.com/Y7Qx8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y7Qx8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Briefly explained, there is a bank service and an account service. The account service holds the accounts and are always connected to a bank using a bankId.</p>&#xA;&#xA;<p>The dilemma is how to handle and validate this relationship and bankId and the pros and cons that comes with each decision.</p>&#xA;&#xA;<p><strong>Option 1:</strong></p>&#xA;&#xA;<p>Ignore validating completely. POST/PATCH against Accounts will never validate if the given BankId is an existing ID.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>Services don't know about each other and there are no hard dependencies between them, if one service goes down, the other doesn't stop working. (Which is a BIG one)</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>If the BankId is incorrect, accounts are ""lost"" and can't be accessed.</li>&#xA;<li>The reporting service and/or any reader has to account for missing or incorrect banks and present whatever data it has without crashing.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>The services are completely decoupled which will benefit performance, up time and complexity. All readers and applications need to be ""reactive"" and able to handle when cross service relationships are ""broken"".</p>&#xA;&#xA;<p><strong>Option 2:</strong></p>&#xA;&#xA;<p>Always validate using synchronous REST-call. POST/PATCH against Accounts will fail if BankId does not exist or if in anyway BankService can't respond or is broken.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Services are tightly dependent, you could argue that they are no longer proper micro services and might as well be a single service.</li>&#xA;<li>Performance impacted negatively</li>&#xA;<li>AccountService POST/PATCH won't work if BankService is down, GET will still work.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>Services are tightly dependent which is really bad, this is more like the ""old ways"" and generally I feel like it's the wrong way to do it. Merging the services in this case is even worse, if you start fixing problems by merging you'd probably keep doing it and soon end up with massive services and you've failed with the whole micro service principle. Sure, reads will still work but that's a far fetched excuse.</p>&#xA;&#xA;<p><strong>Option 3:</strong></p>&#xA;&#xA;<p>Keep a readonly copy of BankEntity in AccountService. AccountService keeps this updated via the event bus. Validate against this on POST/PATCH.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;<li>No measurable negative performance impact</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Complexity increased</li>&#xA;<li>Due to the asynchronous nature of events we cannot assume that the readonly copy of Banks are 100% updated. POST/PATCH on Account in rapid succession after creating a BankEntity might fail.</li>&#xA;<li>AccountService gets more knowledge of other services, even though it's a loose dependency</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>This is the most complex way, readers won't need to handle broken relationships and the performance / up time-issues are resolved, however, instead you would have to handle the fact that the readonly copy of Banks might not be updated yet and try again later. Comparing this to Option 1 means you'd still have to deal with it in some way, and since this will be more complex across the board I'd say its not the most favourable one.</p>&#xA;&#xA;<p><strong>End Thoughts</strong></p>&#xA;&#xA;<p>The general goal that would be nice to achieve is that the services do not synchronously talk to each other and that data integrity is a good as possible.</p>&#xA;&#xA;<p>However, in a micro service architecture I'm under the impression that relationship integrity simply might be one of those things you accept to lose going to this way.</p>&#xA;&#xA;<p>Our decision is leaning towards Option 1, actually just ignoring it, and anytime where you need to use it, you have to expect and handle that it might not be correct. This seems like it is the most ""micro services"" solution, the services don't really know about each other, the only ones that do are applications and reporting services that need to do cross-service operations.</p>&#xA;&#xA;<p>Any of the services need to take full responsibility that they, at any given time, has all the data they need to fully function themselves. Let's say for arguments sake that AccountEntity NEEDED a location for whatever reason to be a usable and complete domain entity, you can't expect to rely on BankId, you'd have to store Location on AccountEntity and maybe if it changes, you'd get an event and you can update it.</p>&#xA;&#xA;<p><strong>TL;DR</strong>&#xA;What are your experiences, opinions and thoughts on this? What would you do? Which strategy would you go for?</p>&#xA;"
49302010,What are the benefits of splitting a big monolithic application into 2 applications?,2018-03-15 14:24:18,<java><web-services><java-ee><weblogic><microservices>,3,113,3,1.0,1,<p>We currently have a big monolithic J2EE application (weblogic / DB2).  It is a typical OLTP application.  We are considering to split this application into 2 applications where each application has its own database which is not directly accessible by the other application.  This also means that each application need to expose an interface for the functionality that is needed by the other application.</p>&#xA;&#xA;<p>So what are potentially the major benefits of splitting such an existing application into 2 applications ?</p>&#xA;
49393058,RabbitMQ asynchronously,2018-03-20 19:55:23,<c#><rabbitmq><.net-core><microservices>,1,372,3,0.0,1,"<p>I want to process RabbitMQ queue in a consumer service. When I try to follow tutorials, i can see that it processes message by message. But what if processing of some message takes longer (e.g. longer DB response)? Then it won't process anything else.</p>&#xA;&#xA;<p>I would like to have it asynchronous. So it can process another messages during waiting time. I tried this piece of code, it works, but it doesn't seem to me that it is correct (not awaited task followed by ContinueWith):</p>&#xA;&#xA;<pre><code>private async Task ExecuteAsync(CancellationToken cancelationToken)&#xA;{&#xA;    Random random = new Random();&#xA;    var factory = new ConnectionFactory() { HostName = ""localhost"", DispatchConsumersAsync = true };&#xA;    using (var connection = factory.CreateConnection())&#xA;    using (var channel = connection.CreateModel())&#xA;    {&#xA;        channel.QueueDeclare(queue: ""task_queue"",&#xA;                                durable: true,&#xA;                                exclusive: false,&#xA;                                autoDelete: false,&#xA;                                arguments: null);&#xA;&#xA;        channel.BasicQos(prefetchSize: 0, prefetchCount: 30, global: false);&#xA;&#xA;        Console.WriteLine("" [*] Waiting for messages."");&#xA;&#xA;        var consumer = new AsyncEventingBasicConsumer(channel);&#xA;        consumer.Received += async (model, ea) =&gt;&#xA;        {&#xA;            var body = ea.Body;&#xA;            var message = Encoding.UTF8.GetString(body);&#xA;&#xA;            // Is it possible to write following part somehow,&#xA;            // 1) so that following task can be awaited ?&#xA;            // 2) so I doesn't have to use .ContinueWith ?&#xA;            #pragma warning disable CS4014 // Because this call is not awaited, execution of the current method continues before the call is completed&#xA;            Task.Run(async () =&gt;&#xA;            {&#xA;                await Task.Delay(random.Next(100, 5000), cancelationToken);&#xA;&#xA;                Console.WriteLine("" [x] Received {0}"", message);&#xA;            }).ContinueWith((prevTask) =&gt;&#xA;            {&#xA;                if (!prevTask.IsFaulted)&#xA;                {&#xA;                    channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false);&#xA;                }&#xA;&#xA;            });&#xA;            #pragma warning restore CS4014 // Because this call is not awaited, execution of the current method continues before the call is completed&#xA;&#xA;&#xA;        };&#xA;&#xA;        channel.BasicConsume(queue: ""task_queue"",&#xA;                                autoAck: false,&#xA;                                consumer: consumer);&#xA;&#xA;        while (!cancelationToken.IsCancellationRequested)&#xA;        {&#xA;            await Task.Delay(100, cancelationToken);&#xA;        }&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I await that Task.Run, then it won't process any other message until that</p>&#xA;&#xA;<pre><code>consumer.Received += async (model, ea) =&gt;&#xA;{&#xA;...&#xA;};&#xA;</code></pre>&#xA;&#xA;<p>is over.</p>&#xA;"
49292843,Swagger Gateway MicroService Aggregation,2018-03-15 06:27:21,<java><spring-boot><swagger><microservices>,1,403,5,1.0,1,"<p>I am developing a microservice application using SpringBoot. There is Gateway Microservice which is public facing, it redirects requests to particular microservice (which are running on different hosts).</p>&#xA;&#xA;<p>Now, I've multiple microservices, each microservice has exposed their APIs using Swagger. We would like to aggregate all these API Swagger docs for public clients. </p>&#xA;&#xA;<p>Temporary solution we've incorporated is, just copied the Swagger Annotated classes for each microservice in Gateway Service. What is <strong><em>the right way</em></strong> to do it?</p>&#xA;"
50000445,Saving a previous authentication in Spring,2018-04-24 11:22:49,<spring-boot><gradle><microservices><spring-security-oauth2><netflix-zuul>,1,23,0,0.0,1,"<p>As an authentication, the application (Service-X) uses a third-party internal service (Service-Y), in which all the information about the employees is stored. All internal services of the company use SSO.</p>&#xA;&#xA;<p>How to implement the ability to log in to Service-X if Service-Y is unavailable? (If I have already been authenticated in Service-X before this).</p>&#xA;"
49990620,DDD design+ Immutability when using event sourcing good idea?,2018-04-23 22:06:57,<java><domain-driven-design><immutability><microservices><event-sourcing>,1,41,0,0.0,1,<p>This is my third question on DDD and event sourcing.I was looking into some best practices and unrelated to DDD a good concept is to make your classes immutable if possible. </p>&#xA;&#xA;<p>I however see a problem in my head trying to marry Event sourcing pattern + immutable Domain Model. Since</p>&#xA;&#xA;<p><strong>DomainModel-1.0 + e1  = DomainModel-2.0</strong>&#xA;[rinse and repeat for all events]</p>&#xA;&#xA;<p>My concern is if I implement my domain model as immutable will I not be creating a lot of domain objects just for my domain model to be up to date and that is wasted resources.</p>&#xA;&#xA;<p>I want to know what if there is any upside to make my Domain model immutable if I am planning to use in with event sourcing. </p>&#xA;
49901574,Docker mvn plugin make {}->unix://localhost:80: Broken pipe,2018-04-18 13:55:29,<maven><docker><spring-boot><microservices><maven-docker-plugin>,1,57,0,0.0,1,"<p>I implement application using spring-boot and try to build docker image using this mvn plugin. </p>&#xA;&#xA;<pre><code>&lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;com.spotify&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.3.6&lt;/version&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;id&gt;default&lt;/id&gt;&#xA;                        &lt;phase&gt;install&lt;/phase&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;build&lt;/goal&gt;&#xA;                            &lt;!-- &lt;goal&gt;push&lt;/goal&gt; --&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt;&#xA;&#xA;                    &lt;buildArgs&gt;&#xA;                        &lt;JAR_FILE&gt;target/${project.build.finalName}.jar&lt;/JAR_FILE&gt;&#xA;                    &lt;/buildArgs&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;</code></pre>&#xA;&#xA;<p>If i try to build this using mvn clean install and it make below error. </p>&#xA;&#xA;<pre><code>    Caused by: java.io.IOException: Broken pipe&#xA;    at jnr.enxio.channels.NativeSocketChannel.write(NativeSocketChannel.java:93)&#xA;    at java.nio.channels.Channels.writeFullyImpl(Channels.java:78)&#xA;    at java.nio.channels.Channels.writeFully(Channels.java:98)&#xA;    at java.nio.channels.Channels.access$000(Channels.java:61)&#xA;    at java.nio.channels.Channels$1.write(Channels.java:174)&#xA;    at org.apache.http.impl.io.SessionOutputBufferImpl.streamWrite(SessionOutputBufferImpl.java:124)&#xA;    at org.apache.http.impl.io.SessionOutputBufferImpl.flushBuffer(SessionOutputBufferImpl.java:136)&#xA;    at org.apache.http.impl.io.SessionOutputBufferImpl.write(SessionOutputBufferImpl.java:167)&#xA;    at â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦..&#xA;org.apache.http.impl.io.SessionOutputBufferImpl.write(SessionOutputBufferImpl.java:179)&#xA;        at &#xA;    [INFO] Building Docker context /Users/thamira/ProjectFolder/finalresearch/cloud-microservice-projet-eureka&#xA;    [INFO] &#xA;    [INFO] Image will be built as springio/cloud-microservice-projet-Eureka:latest&#xA;    [INFO] &#xA;    Apr 18, 2018 6:56:20 PM org.apache.http.impl.execchain.RetryExec execute&#xA;    INFO: I/O exception (java.io.IOException) caught when processing request to {}-&gt;unix://localhost:80: Broken pipe&#xA;</code></pre>&#xA;&#xA;<p>how can i solve this problem. </p>&#xA;"
49992237,"If there are multiple microservices, how should I integration test them?",2018-04-24 01:42:04,<docker><go><microservices>,3,110,0,0.0,1,"<p>I am learning microservice architecture, but now there is some confusion.</p>&#xA;&#xA;<h3>situation</h3>&#xA;&#xA;<ul>&#xA;<li>there are 4 projects written in <code>golang</code>&#xA;&#xA;<ol>&#xA;<li><strong>orderService</strong></li>&#xA;<li><strong>userService</strong></li>&#xA;<li><strong>tools</strong></li>&#xA;<li><strong>web</strong> ( forward <code>HTTP</code> request )</li>&#xA;</ol></li>&#xA;<li><code>orderService</code> , <code>userService</code>, <code>web</code> communicate via <code>grpc</code></li>&#xA;<li>all api requests through <code>web</code> forwarding to <code>orderService</code> or <code>userService</code></li>&#xA;<li><code>orderService</code> and <code>userService</code> have their own independent database</li>&#xA;<li>they are all in <code>docker</code> containers</li>&#xA;</ul>&#xA;&#xA;<h3>confusion</h3>&#xA;&#xA;<p>when I want to test a request, I have to do the following steps:</p>&#xA;&#xA;<pre><code>cd orderService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd userService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd web&#xA;govender update +vendor&#xA;go build&#xA;&#xA;docker-compose build&#xA;docker-compose up&#xA;</code></pre>&#xA;&#xA;<p>when I changed some code, I have to do this steps again.<br>&#xA;I think this is unscientific and abnormal.  I want to know whether all of these steps are necessary to integration test four microservices in docker.</p>&#xA;"
50010287,Why Event Stream in event sourcing pattern?,2018-04-24 20:29:37,<java><domain-driven-design><microservices><event-sourcing>,1,47,1,0.0,1,"<p>Wanted to ensure I had clarity on just stripping out things randomly.</p>&#xA;&#xA;<p><strong>EVENT STORE Database</strong></p>&#xA;&#xA;<pre><code>| p_key | invoice_id | Event type        | Version | Data |&#xA;|-------|------------|-------------------|---------|------|&#xA;| 1     | 41234      | Invoice_Generated | 1       | JSON |&#xA;| 2     | 34241      | Invoice_Generated | 1       | JSON |&#xA;| 3     | 12345      | Invoice_Generated | 1       | JSON |&#xA;| 4     | 12345      | Invoice_Reviewed  | 2       | JSON |&#xA;| 5     | 12345      | Invoice_Paid      | 3       | JSON |&#xA;</code></pre>&#xA;&#xA;<p>JAVA side components</p>&#xA;&#xA;<ol>&#xA;<li>Event Store: </li>&#xA;<li>Event Stream</li>&#xA;<li>Event</li>&#xA;</ol>&#xA;&#xA;<p>Event store is responsible to both retrieve list of events and save the events to database when everything is done.</p>&#xA;&#xA;<pre><code>public interface EventStore {&#xA;    EventStream loadEventStream(AggregateId aggregateId);&#xA;    void store(AggregateId aggregateId, long version, List&lt;Event&gt; events);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Event is essentially one of rows retrieved from the database.</p>&#xA;&#xA;<pre><code>public interface Event&lt;T&gt; {&#xA;    AggregateId getAggregateId();&#xA;&#xA;    int getVersion();&#xA;&#xA;    String getEventType();&#xA;&#xA;    void applyOn(T account);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>what I do not get is the use of event stream. It makes no sense to me as to why would I need an event stream</p>&#xA;&#xA;<pre><code>public interface EventStream extends Iterable&lt;Event&gt; {&#xA;    long version();&#xA;&#xA;    void addAll(List&lt;Event&gt; changes);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Is the sole purpose of event stream to give ability to iterate over list of events that does not sound so useful maybe I am missing something but why can't I just get rid of event stream and call it a day?</p>&#xA;&#xA;<p>Source: <a href=""https://github.com/Pragmatists/eventsourcing-java-example/tree/excercise_1_solution/eventsourcing/src/main/java/com/pragmatists/eventsourcing"" rel=""nofollow noreferrer"">https://github.com/Pragmatists/eventsourcing-java-example/tree/excercise_1_solution/eventsourcing/src/main/java/com/pragmatists/eventsourcing</a></p>&#xA;"
49999709,Getting error details from JHipster UAA microservice through gateway,2018-04-24 10:44:25,<spring><jhipster><microservices>,1,79,1,0.0,1,"<p>Context: our app uses a JHipster generated gateway and UAA service (microservice architecture).&#xA;We're implementing blocking a user account after too many failed attempts. </p>&#xA;&#xA;<p>The UAA service returns a 400 Bad Request when a blocked user tries to login, with a custom i18n code in the <code>error_description</code> field that can be used by the frontend to display the correct user error :</p>&#xA;&#xA;<pre><code>{&#xA;  ""error"" : ""invalid_grant"",&#xA;  ""error_description"" : ""error.login.locked""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So far so good.</p>&#xA;&#xA;<p>The issue happens when the login request is made <strong>through the gateway</strong>, because the answer is:   </p>&#xA;&#xA;<pre><code>{&#xA;  ""type"" : ""http://www.jhipster.tech/problem/problem-with-message"",&#xA;  ""title"" : ""Internal Server Error"",&#xA;  ""status"" : 500,&#xA;  ""detail"" : ""400 Bad Request"",&#xA;  ""path"" : ""/auth/login"",&#xA;  ""message"" : ""error.http.500""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There are <strong>2 issues</strong> here :</p>&#xA;&#xA;<ol>&#xA;<li><p>The HTTP status is 500. It's also the case when login fails because of a wrong password... &#xA;Is that the normal, expected behavior for the generated gateway ?</p></li>&#xA;<li><p>The <code>error</code> and <code>error_description</code> fields that are necessary for the frontend were lost passing through the gateway.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is there a better way than to edit the gateway <code>authenticate</code> method, checking the <code>HttpClientErrorExceptionfor</code> and parsing an <code>OAuth2Exception</code> to get the details, raising a custom exception which is then handled by the <code>Exceptiontranslator</code> in order to conserve the needed fields? That seems a bit much, just to be able to preserve data sent by the service.</p>&#xA;"
49985156,Aggregates in Event Sourcing Pattern,2018-04-23 15:50:51,<java><aggregate><microservices><event-sourcing>,1,128,4,0.0,1,"<p>I am dipping my feet into event sourcing pattern and trying to make sense of aggregates.I have read a few blogs and now I am more confused than ever before.</p>&#xA;&#xA;<p>From what I inferred aggregates should somehow enable user to run different queries on the event store to retrieve different stream of events.</p>&#xA;&#xA;<p>Use case :</p>&#xA;&#xA;<ol>&#xA;<li><p>I want to <strong>replay</strong> events on an invoice where the I want to see all actions done by  a specific employee on the balance.</p></li>&#xA;<li><p>I want to <strong>replay all</strong> events on an invoice </p></li>&#xA;</ol>&#xA;&#xA;<p>I hope these are valid use cases.</p>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | EmployeeId | Event            | Payload |&#xA;|----------|------------|------------|------------------|---------|&#xA;| 1        | 12345      | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | 45567      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | 77341      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | 98421      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status of invoice&#xA;Status is(Review,Billed,Paid)</p>&#xA;&#xA;<p>So from my understanding there needs to be 5 components . </p>&#xA;&#xA;<ol>&#xA;<li>Event- A specific event.</li>&#xA;<li>Event Source - The service that calls repo to get related events</li>&#xA;<li>Event Stream - A list of events</li>&#xA;<li>Command - A request operation on invoice</li>&#xA;<li>Aggregate -  An api to decide on inputs to load events </li>&#xA;</ol>&#xA;&#xA;<p>I understand how other things play but having a hard time wrapping my head around Aggregate. What is it ?</p>&#xA;&#xA;<p>Will I have two aggregate classes </p>&#xA;&#xA;<ul>&#xA;<li>AggregateEventsByInvoice</li>&#xA;<li>AggregateEventsByInvoiceEmployee</li>&#xA;</ul>&#xA;&#xA;<p>I really am having a hard time figuring out the need and use of aggregate . All the examples I have seen use UUID which does not make sense to me at all? Any help will be greatly appreciated.</p>&#xA;"
50041559,How to share common Data over several Microservices,2018-04-26 11:15:02,<domain-driven-design><microservices>,2,87,5,1.0,1,"<p>I'm writing a Bachelors-Thesis about Microservices.</p>&#xA;&#xA;<p>I'm trying to split a monolith into Microservices and now I ran into a problem that there are some tables in a Database, that are relevant for more than one Microservice.&#xA;There is no chance to split this data into domain specific views.</p>&#xA;&#xA;<p>My approach is that I will create a new Database Schema with that specific tables and let all Microservices read from it.&#xA;That would be a shared kernel approach which is not recommended by the experts of Microservices.</p>&#xA;&#xA;<p>Do you have any experience or recommendations about this problem?</p>&#xA;&#xA;<p>Do you have any recommendations about books which are about similar problems?</p>&#xA;"
44769245,Running and accessing multiple angular applications,2017-06-26 21:53:39,<angularjs><typescript><webpack><microservices>,1,49,0,0.0,1,"<p>I am a newbie to Angular and was trying to see if we can access another application(hosted on different port, has a completely different repository and Angular version). &#xA;Lets say I have two Angular Typescript projects , A and B.</p>&#xA;&#xA;<pre><code>=======================================&#xA;Project A configuration: &#xA;Angular 1.5&#xA;Typescript 2&#xA;Grunt for build purposes.&#xA;runs on localhost:8080 &#xA;&#xA;=======================================&#xA;Project B configuration: &#xA;Angular 2&#xA;Typescript 2&#xA;Webpack for build purposes.&#xA;runs on localhost:9000&#xA;=======================================&#xA;</code></pre>&#xA;&#xA;<p>Each of theses apps, A and B are hosted on different repositories. &#xA;Now, lets say project A is master and has a tab(button) in it which on click should call the index page hosted on project B.</p>&#xA;&#xA;<p>The button label is 'microapp; and below is the src : </p>&#xA;&#xA;<pre><code>$scope.showMicroApp = function showMicroAppView(isMessagePanelOpen) {&#xA;           // $scope.isEnvelopeOpen = !!isMessagePanelOpen;&#xA;            $scope.changeRoute('/microapp');&#xA;            $location.path('/microapp'); // HOW DO I REDIRECT?&#xA;        };&#xA;</code></pre>&#xA;&#xA;<p>Why am I doing this ? </p>&#xA;&#xA;<p>I am doing this to achieve independence in the front end part of my project. &#xA;Such that if I change a particular screen/module, I don't have to build the entire project. I can simply build the changed module and see the changes reflected. &#xA;Is this achievable ? Do I need to change the existing implementation of the project B?</p>&#xA;&#xA;<p>Kindly help if you have any leads. </p>&#xA;"
44765491,how to deploy shared library in google app engine flex environment,2017-06-26 17:41:32,<python><google-app-engine><pip><google-cloud-endpoints><microservices>,1,81,0,0.0,1,"<blockquote>&#xA;  <p>I'm using app engine with cloud endpoints to deploy APIs. All service in the following description is about APIs. </p>&#xA;</blockquote>&#xA;&#xA;<p>I know in app engine flex env, I could deploy several independent <code>service</code> which talk to each other only through REST.</p>&#xA;&#xA;<p>It's a great idea to make services as independent as possible, but there are some opportunities for code reuse I don't know how to achieve.</p>&#xA;&#xA;<p>For example, there are same procedures I will need to use regardless which API under which service. Usually I'll write a helper library so all these small helper functions would be in one place and I could reuse them across various APIs. </p>&#xA;&#xA;<p>The purpose is to write once and use at many places.<br>&#xA;So my questions:</p>&#xA;&#xA;<ol>&#xA;<li>Is this shared library still good idea under the context of app engine? If not, wouldn't it has too much overhead to make all those small function as api?  </li>&#xA;<li>If shared helper library still make sense, how to achieve it in app engine flex environment? I know in standard env you could use <a href=""https://cloud.google.com/appengine/docs/standard/python/config/appref"" rel=""nofollow noreferrer""><code>includes</code> directive</a> to include files, I don't see how in flex environment.   </li>&#xA;<li>I know we could use 3rd party library by declaring them in the requirement and pip support install from github repo, but my helper library would be a private repo, how to allow app engine to pip install private repo?</li>&#xA;</ol>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
44882977,Is this correct way to deploy springboot cloud netflix in production on multi host network?,2017-07-03 10:12:55,<docker><spring-boot><microservices><spring-cloud-netflix><docker-networking>,1,107,0,1.0,1,"<p>I am developing a spring boot application with netflix cloud stack. and deploying each module(microservice) in separate docker container. Structure is as follows:</p>&#xA;&#xA;<ol>&#xA;<li>Eureka</li>&#xA;<li>Zuul</li>&#xA;<li>Business logic in Microservices</li>&#xA;<li>MySQL</li>&#xA;<li>Angular4 UI</li>&#xA;<li>Keycloak - User management and Authentication</li>&#xA;<li>ELK - for log maintenance </li>&#xA;<li>Hystrix </li>&#xA;<li>Zipkin</li>&#xA;</ol>&#xA;&#xA;<p>Okay so after facing lot of problems and spending whole lot of network bandwidth on googling on the matter I have deployed in following way, What I need to know is, if it is correct way to do it ?</p>&#xA;&#xA;<p>The limitation here is that I have been provided with 2 hosts to test this configuration and further action plan is not there yet.</p>&#xA;&#xA;<p>So here is what I have done: I have not yet used full stack which I mentioned.</p>&#xA;&#xA;<p><strong>Server 1</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Eureka</p></li>&#xA;<li><p>Zuul</p></li>&#xA;<li><p>ELK</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>Server2</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Keycloak</p></li>&#xA;<li><p>Business Logic microservices</p></li>&#xA;<li><p>MySQL</p></li>&#xA;<li><p>Anguar4 UI</p></li>&#xA;</ol>&#xA;&#xA;<p>Haven't configured and used Hystrix and Zipkin yet. &#xA;So I have given the IP:PORT of the Server1 in the Eureka configuration of all the microservices which needs to register on Eureka. Same goes for Zuul(given the IP:PORT of Eureka). </p>&#xA;&#xA;<p>In the Angular4 UI I have given the URL:PORT of Zuul deployment, because all the services will be called through Zuul.</p>&#xA;&#xA;<p>This I understand is correct because Services needs to know where Eureka is located and rest can be managed through Eureka.</p>&#xA;&#xA;<p>Now my key question is, because MySQL, ELK can't be registered on Eureka, so is it correct to give IP:PORT of MySQL and ELK wherever required ? </p>&#xA;&#xA;<p>Same goes with the configuration of ELK, with ELK my requirement is also that all the logs are located at common place for this I have used docker, volume mounting but I don't know how to accomplish this on multi host environment, I can only make dockers out put logs on external volume which can then probably be accessed by ELK over URL, haven't tested this configuration yet.</p>&#xA;&#xA;<p>If so then isn't this configuration not so Independent if we think it will be able to manage itself ?</p>&#xA;&#xA;<p>I have configured my docker compose to use ""network_mode"": host so host to host docker communication can be done.</p>&#xA;&#xA;<p>Again All I need to know is, is my configuration/architecture correct for multi-host environment and in future for Cloud environments ? &#xA;If Not, then please kindly guide me to correct path.</p>&#xA;&#xA;<p>Thank you!&#xA;p.s. excuse me for my English and Grammar, I have tried best to my knowledge to make it understandable, please point out and ask questions if you need more input from my side.</p>&#xA;"
44687892,What Oauth2 grant type to use in a distributed application without any third party client?,2017-06-21 23:45:43,<java><security><oauth-2.0><microservices><spring-cloud-netflix>,1,179,0,0.0,1,"<p>After reading for the last two days about <code>Oauth2</code> protocol I still need some help to figure out what's the best grant to use for our system where the <code>Authorization Service</code> is deployed by us.</p>&#xA;&#xA;<p>The app uses <code>Spring Cloud, Spring Boot and Spring Security</code>. It has a <code>service discovery</code> that uses <code>Eureka</code> and all users' requests go through an <code>API gateway</code> to reach the different microservices in an internal network. All these microservices, included the gateway, use the <code>Zuul</code> proxy. The <code>Authorization Service</code> will be another microservice storing the users in its own database. There is a frontend that at the moment is deployed in the gateway and is developed in <code>Angular 4</code>. There isn't any external apps that make requests to our system and there will be a bunch of users with a small set of possible roles that will make use of it and that will have to log in using a username and password. </p>&#xA;&#xA;<p>In this situation, should we go for the <code>Authentication Code grant</code> or the <code>Password grant</code> would be ok? Or maybe not <code>Oauth2</code> at all? All the examples I've seen and read about that use the <code>Authentication Code grant</code> require the user to allow the client to get access to the resource after log in. In our case, the client will be the gateway so the user shouldn't have to grant it anything. The <code>Password grant</code> seems to remove this situation as the user's credentials serve to tell the <code>Authorization Service</code> to provide a token. Am I missing something?</p>&#xA;&#xA;<p>Apart from that, examples of <code>Authorization Services</code> include <code>Facebook</code> or <code>Google</code>. When using these, once the user grants the client application access to the resource after log in, subsequent requests don't show this screen and they only need to log in with their credentials. Where is this access granted information stored? How does <code>Facebook</code> know that, once the user has granted access to a resource to an application, next time he logs in he doesn't need to do it again?</p>&#xA;"
44785105,Swagger datatype not generating docs,2017-06-27 16:10:35,<java><swagger><microservices><spark-java>,1,256,2,0.0,1,"<p>I have the below code in Swagger,</p>&#xA;&#xA;<pre><code>@Path(""/v1"")&#xA;    @ApiOperation(value = ""POST - Some Value"", nickname = ""post-funtion"", consumes = ""application/json"", produces = ""text/html; charset=UTF-8"", tags = {&#xA;            ""Some Controller"" })&#xA;    @ApiImplicitParams({&#xA;            @ApiImplicitParam(name = ""Authorization"", paramType = ""header"", dataType = ""string"", format = ""JWT"", required = false, value = ""A User Service JWT""),&#xA;            @ApiImplicitParam(name = ""Request"", value = ""Request Object"", paramType = ""body"", dataType = ""org.pkg.SomeRequest"", required = true) })&#xA;    @ApiResponses({&#xA;            @ApiResponse(code = 200, message = ""Value Added"", response = SomeResponse.class) })&#xA;private Object retrieveByName(Request request, Response response)&#xA;{&#xA;    return new RetrieveByNameRqstHandler(catalogService, request, response).handle();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The code is supposed to automatically generate default json request depending upon the datatype which in this case is <code>""org.pkg.SomeRequest""</code> but there is nothing generated. On the contrary if I change the ""org.pkg.SomeRequest"" with <code>""org.pkg.SomeResponse""</code> there is a default JSON generated for this. Can anybody help me please?</p>&#xA;&#xA;<p>Consider both classes SomeRequest,SomeResponse have the same code.&#xA;This is the image where I use <code>""org.pkg.SomeRequest""</code> in the dataType&#xA;<a href=""https://i.stack.imgur.com/4hHCi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4hHCi.png"" alt=""This is the image where I use &lt;code&gt;&quot;org.pkg.SomeRequest&quot;&lt;/code&gt; in the dataType""></a>&#xA;<a href=""https://i.stack.imgur.com/BGpCE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BGpCE.png"" alt=""This is the image where I use &lt;code&gt;&quot;org.pkg.SomeResponse&quot;&lt;/code&gt; in the dataType""></a></p>&#xA;&#xA;<p>This is the image where I use <code>""org.pkg.SomeResponse""</code> in the dataType</p>&#xA;"
44797253,Reducing unnecessary work for a multiple-instance service,2017-06-28 08:23:47,<architecture><message-queue><microservices><distributed-system>,1,71,2,1.0,1,"<p>I have a little service which connects to a third party web-service, obtains some information and saves it into a mongo collection. The data this service is interested in is pretty static, but it it can change under exceptional circumstances (it is football schedules, btw). To get notified about changes, the service checks back every 3-6 hours to see if any matches have been cancelled or rescheduled. New entries end up in the database, old ones are discarded (since they are already in the collection).</p>&#xA;&#xA;<p>The service also exposes a GET endpoint, to which users connect.</p>&#xA;&#xA;<p>Now, this is fine when I run a single instance of the service, but not so nice when I have multiple instances (probably it does not make sense for all instances to query the data service every three hours and discard most of the result). </p>&#xA;&#xA;<p>I have the following ideas how to solve this:</p>&#xA;&#xA;<ul>&#xA;<li>Use some kind of leader election algorithm, only the leader should query the third party service</li>&#xA;<li>Separate the service into two: one smaller service would query the data (still problematic with several instances), put the result on a message queue so it's guaranteed that only one consumer takes and processes that result</li>&#xA;<li>Combine the first two ideas: leader election for the querying service, message queues for consuming data</li>&#xA;<li>Use some kind of distributed lock (I am aware of a solution with Redis/Jedis) so only one service does the querying. This, however feels a bit of an overkill; adding Redis just for locking is like...meh...</li>&#xA;<li>A much better, other idea, commonly used in such cases :-)</li>&#xA;</ul>&#xA;&#xA;<p>Could you please let me know if there is a preferred solution to such problems?</p>&#xA;"
50310975,Microservices and duplicating database tables,2018-05-12 21:53:39,<microservices>,2,31,0,1.0,1,"<p>I have been working on splitting up a monolithic system (.NET) into smaller bounded contexts and thus multiple class libraries. Address records are central to the system, so its important for the unrelated entities to reach back to a MASTER address record. Each microservice has its own database with tables related to that bounded context. I've run across a challenge with regard to Address records or the Address Entity. Both of these bounded contexts or libraries need the use of an Address table and the related lookup tables, such as State, Country, etc. Should I duplicate the Address related tables in each database and also duplicate the Address related domain classes? If I duplicate, I will have a ton of duplicate address records in both databases and this has me stuck. If I put the Address tables in something like a ""Location Service"", it will be difficult to display address fields in search results. Maybe this isn't the proper scenario for microservices?</p>&#xA;&#xA;<p>EXAMPLE:&#xA;Microservice-1 (product A)&#xA;Incident -> one to one -> Address</p>&#xA;&#xA;<p>Microservice-2 (product B)&#xA;Fire Hydrant -> one to one -> Address</p>&#xA;&#xA;<p>Microservice-3 (product C)&#xA;Inspection -> many to one -> Address</p>&#xA;"
50484157,Use case for Zuul and Netflix Ribbon,2018-05-23 09:04:30,<spring-boot><microservices><netflix-zuul><netflix-ribbon>,2,167,0,0.0,1,<p>Both Zuul and Ribbon can be used for load balancing. But in which case should we prefer Zuul over Ribbon and vice versa?</p>&#xA;
45441593,Microservices With CosmosDB on Azure,2017-08-01 15:14:03,<azure><microservices><azure-cosmosdb>,1,280,0,0.0,1,"<p>I've read a bit about microservices and the favored approach appears to be a separate database for each microservice.  With regards to Azure's CosmosDB, would that mean a separate Table for each service?  What's the best way to architect this?</p>&#xA;"
45468971,How to reorganize microservices when they all share data and concepts?,2017-08-02 18:58:56,<design-patterns><architecture><microservices>,2,70,0,0.0,1,"<p>At our company we use the microservices approach because we like to keep services small, understandable and maintainable. Besides that, we use a load balancer which enables us to duplicate heavy used services.</p>&#xA;&#xA;<p>We understand that microservices should be loosely coupled if coupling is needed at all. Also, the coupling should not happen on the database, but preferably by API's (REST).</p>&#xA;&#xA;<p>Well, we use the microservice idea. We don't apply everthing that is recommended. In our case we use loosely coupled Tomcat War's that communicate via REST and JMS messaging. All webapps use the same database server, but they all have their own scheme (so no integration).</p>&#xA;&#xA;<p>We have two issues with this approach:</p>&#xA;&#xA;<ol>&#xA;<li>75% of the services generate report data. There is a report service that is responsible for persistence and serving of that data. So all services that generate report data send their findings to the report-service. In fact, each &#xA;service has it's own responsibility, but still we need all this communication. This seems to conflict with the microservices idea. It is like a horizontal layer that binds all vertical microservices together.</li>&#xA;<li>Due to the 'horizontal' coupling above, we also share interface objects. Report data is structured in a certain way. And every service needs to follow that structure. We have a strong feeling that shared libraries of domain / interface objects is against some principles. But as you will understand, duplicating all interface objects seems dumb and still a lot of work when interfaces change.</li>&#xA;</ol>&#xA;&#xA;<p>An alternative to the current architecture is that every service persists it's own report data. Then you only need the communication when the report is rendered. In that case we don't have the regular communication between services and the report-service. Disadvantages are now that every service needs it's database layer (there was no), and that you still need to share report structures among all services.</p>&#xA;&#xA;<p>The high-level question is: is there a pattern for dividing services when behaviour can be separated horizontally and vertically?</p>&#xA;&#xA;<p>The same issue may occur in a sales application where the 'product' plays a central role through the entire set of services.</p>&#xA;&#xA;<p>Should we redesign the architecture? Is there a pattern we can use? or is this an already known anti-pattern?</p>&#xA;"
45489456,connect docker container on local and other containers remotely,2017-08-03 16:07:48,<docker><docker-compose><microservices><docker-machine>,2,70,0,2.0,1,"<p>For our development debugging easiness and few issues over deployment we planned to containerize the services we have. For example.</p>&#xA;&#xA;<p>I have services such as <code>A</code>, <code>B</code>, <code>C</code> and <code>D</code>. where <code>A</code> is my development code(which changes frequently) , and B,C and D are the dependent services. </p>&#xA;&#xA;<p>Currently the <code>B</code>,<code>C</code> and <code>D</code> are planned to deploy remotely because they are just a dependency (Docker Container)&#xA;I would want a way  to debug/deploy so that </p>&#xA;&#xA;<ul>&#xA;<li><p>My service <code>A</code> could be on local and it could easily connect with the remote Docker Service <code>B</code>,<code>C</code>,<code>D</code></p></li>&#xA;<li><p>Or <code>A</code> could be somehow deployed to the remote cluster and it could be tested.</p></li>&#xA;</ul>&#xA;&#xA;<p>I thought of going with the push to registry but each developer with his own snapshot being pushed could not co-relate others images.</p>&#xA;&#xA;<p><strong>Note:</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I do not want Swarm kind of thing but want to keep it simple.</p></li>&#xA;<li><p>The Cluster is managed via Docker Machine. Can it be replaced?</p></li>&#xA;<li><p>The services are woven by Docker Compose.</p></li>&#xA;</ul>&#xA;&#xA;<p>Any suggestions on how I could drive this? Also preferred way is via Docker.</p>&#xA;"
45431599,Handling Data for UI in a Microservice Architecture?,2017-08-01 07:32:34,<database><api><architecture><microservices><gateway>,2,72,0,0.0,1,"<p>WeÂ´re planning to use the Microservice Architecture in our next application. I wanted to know if itÂ´s a common practise to have a same domain entity for every related microservice. For example, there is a customer. A customer consists of multiple users and one company. They are existing in a customer service. Then there is a warehouse service. A warehouse can have different customers in different roles. So the warehosue entities holds keys to the customers.</p>&#xA;&#xA;<p>In front of those two microservices there is an API gateway. Now when showing a screen with warehouses we need also the information about the customers from the customer service. So the API gateway could handle this, meaning fetch the warehouses and then the related customers. But then we connect two services via the API gateway. Is it a better way to hold the customers with specific attributes also in the warehouse service? But this is just necessary for view/UI specific use cases? Is this a correct way to bring ""view logic"" to the services?</p>&#xA;"
45420766,Should a micro-service wrap a message queue exposed to a third party vendor?,2017-07-31 16:15:34,<architecture><message-queue><microservices>,2,97,0,0.0,1,<p>I have a third party vendor that will need to push messages to us. I am considering having them put these messages onto a messaging queue. Because I do not want the micro-service that will need to take action on the queue to be overwhelmed by traffic.  </p>&#xA;&#xA;<p>Is it considered good practice to give the third party access to put messages on the queue or should I wrap like RESTful micro-service in around the queue? </p>&#xA;
45363163,what is the difference between netflix zuul server and netflix eureka server?,2017-07-28 00:46:18,<spring-boot><microservices><spring-cloud><spring-cloud-netflix>,2,2209,0,0.0,1,<p>i have created two java spring-boot micro services they are &#xA;1) producer &#xA;2) consumer &#xA;and i have used spring eureka server for service registration and discovery . it worked fine . then what is the use of Netflix Zuul.</p>&#xA;
45484451,Spring Cloud shared configuration for group of microservices,2017-08-03 12:38:16,<java><configuration><yaml><microservices><spring-cloud>,1,199,1,0.0,1,"<p>Is it possible to share some properties for limited group of microservices? I mean I just want to declare common datasourse in one place for several microservices, which will use the same database</p>&#xA;&#xA;<p>I try to implement it using gradle variables, which should consist all data related to db connection with profiles, but probably easier way to do it exists.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45534252,Express-Gateway response error after setting authorization,2017-08-06 16:40:36,<node.js><express><microservices><express-gateway>,2,286,2,0.0,1,"<p>I'm getting an Error 404 when trying to set my authorization key (key-auth) in the request header. I'm sure that there isn't any problem with my key because if I don't set it a Forbidden status will return.</p>&#xA;&#xA;<p><strong>before setting any credentials:</strong></p>&#xA;&#xA;<pre><code>$ curl http://localhost:8080/ip&#xA;</code></pre>&#xA;&#xA;<p>will return:</p>&#xA;&#xA;<pre><code>{&#xA;  ""origin"": ""5.116.28.133""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>after creating a key-auth credential:</strong></p>&#xA;&#xA;<pre><code>$ curl -H ""Authorization: apiKey ${keyId}:${keySecret}"" http://localhost:8080/ip&#xA;</code></pre>&#xA;&#xA;<p>will return:</p>&#xA;&#xA;<pre><code>&lt;!DOCTYPE html&gt;&#xA;&lt;html lang=""en""&gt;&#xA;&lt;head&gt;&#xA;&lt;meta charset=""utf-8""&gt;&#xA;&lt;title&gt;Error&lt;/title&gt;&#xA;&lt;/head&gt;&#xA;&lt;body&gt;&#xA;&lt;pre&gt;Cannot GET /ip&lt;/pre&gt;&#xA;&lt;/body&gt;&#xA;&lt;/html&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>and it's my gateway config:</strong></p>&#xA;&#xA;<pre><code>http:&#xA;  port: 8080&#xA;admin:&#xA;  port: 9876&#xA;  hostname: localhost&#xA;apiEndpoints:&#xA;  api:&#xA;    host: localhost&#xA;    paths: '/ip'&#xA;serviceEndpoints:&#xA;  httpbin:&#xA;    url: 'https://httpbin.org'&#xA;policies:&#xA;  - basic-auth&#xA;  - cors&#xA;  - expression&#xA;  - key-auth&#xA;  - log&#xA;  - oauth2&#xA;  - proxy&#xA;  - rate-limit&#xA;pipelines:&#xA;  - name: default&#xA;    apiEndpoints:&#xA;      - api&#xA;    policies:&#xA;    - key-auth:&#xA;      - proxy:&#xA;          - action:&#xA;              serviceEndpoint: httpbin &#xA;              changeOrigin: true&#xA;</code></pre>&#xA;&#xA;<p>Does anyone know why this issue happens?</p>&#xA;&#xA;<p>find more information about express-gateway from <a href=""http://www.express-gateway.io/"" rel=""nofollow noreferrer"">http://www.express-gateway.io/</a></p>&#xA;"
45474338,Event Sourcing Choregraphy that Relate to Multiple Records,2017-08-03 03:34:52,<domain-driven-design><microservices><event-sourcing>,1,53,2,0.0,1,"<p>I am trying to develop microservices for order / transaction process using event sourcing concept. The staff could place an order / transaction for a customer by phone. The system also record the number of order that grouped by customer. It is using AWS Kinesis to send the customer id in orderCreated event to the service of customer data so we could increment the number of created order. We separate the order processing and customer based on DDD concept. But, we should anticipate human error when staff select wrong customer id for the order. So, there is a feature to change the customer for related order. </p>&#xA;&#xA;<p>The problem is the orderUpdated event just contains the latest data of the order. It means that the event only has the new customer id. We could increment the number of order for new customer. But, we should decrement the number of order for previous customer id. </p>&#xA;&#xA;<p>How to solve this problem? Could you give me some suggestions?</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
45390260,What things should I consider to split my Monolithic nodeJs app to Microservice architecture?,2017-07-29 14:16:27,<node.js><microservices>,1,461,3,1.0,1,"<p>I'm trying to build Restful API's using NodeJs for a e-commerce application with a minimal functionality like User Accounts, Products, Inventory System, Cart/ Orders, Payments, Wallet/Credit, Delivery Management, Notifications etc.</p>&#xA;&#xA;<p>I wanted to implement this using a microservice architecture.</p>&#xA;&#xA;<p>I do not want to use a any framework, I want to explore and learn myself. </p>&#xA;&#xA;<p>How should I start?</p>&#xA;&#xA;<p>1) On what parameters should I choose a microservice architecture.</p>&#xA;&#xA;<p>2) How should I use the common ""terms"" like user model, or (products, inventory and orders).</p>&#xA;&#xA;<p>3) Should I build full monolithic App first and then take out the heavy parts out of it, one by one?</p>&#xA;&#xA;<p>A basic guideline that can put me in direction will be very helpful. I'll really appreciate and thank for helping on this subject.</p>&#xA;"
45486658,Is it bad practice to produce and consume messages from the same topic?,2017-08-03 14:09:23,<apache-kafka><activemq><messaging><microservices><tibco-ems>,1,363,4,1.0,1,"<p>Say you have a micro-service architecture where multiple services produce and consume <em>unit</em> statusses. </p>&#xA;&#xA;<p>There are multiple ways to design this, which one would you recommend?</p>&#xA;&#xA;<p>These are some options that come to mind:</p>&#xA;&#xA;<ol>&#xA;<li>Create a generic topic <code>unit-status</code> and make services consume and produce messages on this topic. This has the consequence that you consume your own messages and have to filter them. I would consider this a dirty solution, but easy for new new consumers to get all unit status events.</li>&#xA;<li>Create a specific topic for each status, for example <code>unit-status-created</code>, <code>unit-status-packaged</code>, <code>unit-status-loaded</code>, <code>unit-status-deleted</code>, etc. Each service produces only on it's own topic, but can consume from a list of topics, excluding it's own. For example the loading service would consume from list(<code>unit-status-created</code>, <code>unit-status-deleted</code>, <code>unit-status-packaged</code>). This allows services to show interest in only specific events, but it requires a code or config change in potentially all service when a new status topic is added. </li>&#xA;<li>Give each status it's own partition and consume from all partitions except the one you produce in. This design makes things more complicated (bookkeeping which partition contains a specific status), does not auto balance when partitions are added, adding partitions while live makes things a bit more risky, therefore does not have my preference. </li>&#xA;</ol>&#xA;"
45567201,User docker-compose to pull images from private repository,2017-08-08 11:32:44,<docker><docker-compose><microservices>,1,4064,6,0.0,1,<p>I'm using docker-compose command to run multiple containers. The problem is my docker-compose has to pull some images from the public repository and some from a private repository. What I'm planning to do is push all required images to the private repository but how can I make docker-compose pull the images from the private repository.</p>&#xA;&#xA;<p>In short -> How to point to a private repository when the images are only available there</p>&#xA;
48743105,Parse CSV file from API request in go-kit golang,2018-02-12 09:27:26,<csv><go><service><microservices>,1,270,0,0.0,1,"<p>I am trying to build a service that takes user input of file from <code>POST</code> request and then iterates the CSV and passes it into my database. I am having problem to pass the file and read it. Below are my codes.</p>&#xA;&#xA;<p><strong>Endpoint.go</strong></p>&#xA;&#xA;<pre><code>  type CSVRequest struct {&#xA;    File  io.Reader&#xA;&#xA;}&#xA;&#xA;&#xA;func MakeCSVEndpoint(svc Service) endpoint.Endpoint {&#xA;    return func(ctx context.Context, request interface{}) (interface{}, error) {&#xA;        req := request.(CSVRequest)&#xA;&#xA;        data, err := svc.ReadCSV(req.File)&#xA;&#xA;        if err != nil {&#xA;            return GetErrorResponse{err}, nil&#xA;        }&#xA;&#xA;        return CreateProductResponse{data}, nil&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>transport.go</strong></p>&#xA;&#xA;<pre><code>    func decodeCreateProductsCSV(_ context.Context, r *http.Request) (interface{}, error) {&#xA;    file, _, err := r.FormFile(""file"")&#xA;&#xA;    return CSVRequest{File: file}, nil&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>so how can I pass the csv file to the service.go and then read and iterate the csv file and get the values of the csv file.</p>&#xA;"
48677693,Is Microservice design pattern or architecture?,2018-02-08 04:42:44,<microservices>,1,337,0,0.0,1,"<p>After doing rigorous research and analysis I finally arrived to a point which is confusing me ""Is Microservice a design pattern or architecture"".&#xA;Some say it's a pattern evolved as a solution to monolithic applications and hence design pattern&#xA;And some confirms no doubt it's an architecture which speaks about their development, management, scalability, autonomous &amp; full stack.&#xA;Any thoughts or suggestions I welcome to get myself clarified.</p>&#xA;"
48671754,How can I return an error from a gRPC service?,2018-02-07 19:24:35,<ruby><error-handling><microservices><grpc>,1,150,0,0.0,1,"<p>I have a simple gRPC service running in Ruby. Under some conditions, I want to return an error to the client in a controlled fashion, something like an HTTP status code with an error message. I don't see any clear way to do this from the documentation; what is the correct way to do so?</p>&#xA;"
48660912,How to secure my micro service which should be accessible only from Amazon's api gateway or any authenticated app,2018-02-07 10:02:51,<tomcat><grails><microservices><aws-api-gateway>,2,208,0,0.0,1,"<p>I am managing the users and their authentication/authorization process on the AWS server( using Cognito, API gateway and IAM features) and I've written the micro services in a grails app which is / will be hosted on the different server, but the services are public now as I'm using the AWS Cognito for the authentication and authorization, I want here to access all my micro services from AWS's API gateway only. I read about client certificate but no appropriate doc is found.</p>&#xA;&#xA;<p>Any help would be appreciated! Thanks!</p>&#xA;"
48763985,Feasibility of Choosing EC2 + Docker As a Production Deployment Option,2018-02-13 09:59:48,<docker><amazon-ec2><microservices>,3,139,1,1.0,1,"<p>I am trying to deploy my microservice in EC2 machine. I already launched my Ec2 machine with Ubuntu 16.04 LTS AMI. And also I found that we can install docker and run containers through docker installation. Also I tried sample service deployment using docker in my ubuntu.I successfully run commands using -d option for running image in background also.</p>&#xA;&#xA;<ol>&#xA;<li>Here My confusion is that Can I choose this EC2 + Docker for deployment of my microservice for actual production environment? , Then I can deploy all my spring boot microservice in these option.</li>&#xA;</ol>&#xA;&#xA;<p>I know that ECS is another option for me.To be frank trying to avoid ECR, ECS optimized AMI and its burdens, Looking for machine with full control that only belongs to me. &#xA;                              But still I need to know about the feasibility of choosing EC2 + Docker through my Ubuntu machine.Also I am planning to deploy my angular 2. I don't need to install , deploy and manage any application server for both spring boot and angular.Since It will gives me about a serverless production environment to me.</p>&#xA;&#xA;<p>Can anyone help to clarify my doubts on choosing EC2 + Docker in production version for deploying my microservice? </p>&#xA;"
48801894,How to make a dll as a Microservice and make it reside outside the system,2018-02-15 07:25:00,<c#><.net><dll><microservices>,1,109,2,1.0,1,"<p>My requirement is simple.</p>&#xA;&#xA;<p>We have a system with so many components interacting with each other. All the components are built as DLLs and interact via object.</p>&#xA;&#xA;<p>So lets say I have a component XXX. Now I want to remove the component XXX outside the system and want the user to install the component XXX only when he needs.</p>&#xA;&#xA;<p>I want to make XXX as an ""Extensible"" and a ""Pluggable"" component and develop and build it independently and whenever the user needs the functionality that is provided by the XXX dll, he will install XXX dll as a standalone component.</p>&#xA;&#xA;<p>Also, XXX dll interacts with other components in the system,say YYY, using objects. Components are binded by objects.</p>&#xA;&#xA;<p>If i want to make XXX dll as a outside component, how does the communication XXX and YYY component happen now? I was thinking components can communicate over a Web Service interface.</p>&#xA;&#xA;<p>Any leads or pointers on how I can proceed with this idea? I am searching for it all regarding Micro-services and others but I am not able to come up with a good feasible approach.</p>&#xA;"
48743223,Sharing domain model classes (Aggregates) across two microservices,2018-02-12 09:34:50,<domain-driven-design><microservices>,1,138,3,0.0,1,"<p>Based on my limited knowledge, microservice can be designed at bounded context level or Aggregate level.</p>&#xA;&#xA;<p>If microservices are created at aggregate level, they might need to refer to an aggregate created in other microservices (as they share the same bounded context).</p>&#xA;&#xA;<p>Should we create the same aggregate multiple times in each microservice (if required)? Or there can never be a case, where we need to use one aggregate into other?</p>&#xA;"
48792602,Persistence layer as microservices?,2018-02-14 17:04:40,<spring-boot><microservices><netflix-eureka>,3,251,3,0.0,1,"<p>I'm a beginner in microservice architecture and I have read in a lot of blog that in a microservice architecture, it is mandatory that each micro service has its own database. In my case it may cost very expensive. </p>&#xA;&#xA;<p>My question is, is it possible to make the persistence layer as micro service in itself ? Which would have the function of allowing other microservices to have read/write access to the database.&#xA;Thanks</p>&#xA;"
37936588,Using existing microservices,2016-06-21 05:57:38,<microservices>,2,47,0,0.0,1,"<p>In the microservice architecture, the main idea is that, every service is a small program, that does one thing and does it well (like unix philosophy)</p>&#xA;&#xA;<p>Some things are common to a variety of projects, eg. user management, contacts, companies, clients, products, payments, etc.</p>&#xA;&#xA;<p>I want to know if there is some kind of repository for microservices that solve there common tasks, so that I don't must reinvent the wheel again.</p>&#xA;&#xA;<p>On <a href=""http://github.com"" rel=""nofollow"">github</a> it is hard to find something like this and on <a href=""http://hub.docker.com"" rel=""nofollow"">docker hub</a> are most repos not documented.</p>&#xA;&#xA;<p>So you use some 3th party microservices? Or you create everything yourself? </p>&#xA;"
37897876,Vert.x how to pass/get messages from REST to message bus?,2016-06-18 14:09:34,<java><rest><microservices><vert.x>,2,1175,0,0.0,1,"<p>I want to pass messages to bus via REST, and get it back. But I cant correctly setup the message bus receiver, it throws <code>java.lang.IllegalStateException</code>: Response has already been written. In real life message bus should receive messages from different sources and pass a message to another target. Therefore we just need to publish the message to the bus. But how to correctly read messages and handle all of them? For example from a REST interface: read that messages!&#xA;My simple app start:</p>&#xA;&#xA;<pre><code> public static void main(String[] args) {&#xA;        Vertx vertx = Vertx.vertx();&#xA;        vertx.deployVerticle(new RESTVerticle());&#xA;        vertx.deployVerticle(new Receiver());&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.registerDefaultCodec(MessageDTO.class, new CustomMessageCodec());&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>REST part</p>&#xA;&#xA;<pre><code>public class RESTVerticle extends AbstractVerticle {&#xA;&#xA;    private EventBus eventBus = null;&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        Router router = Router.router(vertx);&#xA;        eventBus = vertx.eventBus();&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.post(""/api/message"").handler(this::publishToEventBus);&#xA;       // router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9999);&#xA;        System.out.println(""Service running at 0.0.0.0:9999"");&#xA;&#xA;    }&#xA;&#xA;private void publishToEventBus(RoutingContext routingContext) {&#xA;        System.out.println(""routingContext.getBodyAsString() "" + routingContext.getBodyAsString());&#xA;        final MessageDTO message = Json.decodeValue(routingContext.getBodyAsString(),&#xA;                MessageDTO.class);&#xA;&#xA;        HttpServerResponse response = routingContext.response();&#xA;        response.setStatusCode(201)&#xA;                .putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                .end(Json.encodePrettily(message));&#xA;&#xA;        eventBus.publish(""messagesBus"", message);&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>And the Receiver: I move it to a different class, but it does not help</p>&#xA;&#xA;<pre><code>public class Receiver extends AbstractVerticle {&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        Router router = Router.router(vertx);&#xA;&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9998);&#xA;        System.out.println(""Service Receiver running at 0.0.0.0:9998"");&#xA;&#xA;private void getMessagesFromBus(RoutingContext routingContext) {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.consumer(""messagesBus"", message -&gt; {&#xA;            MessageDTO customMessage = (MessageDTO) message.body();&#xA;            HttpServerResponse response = routingContext.response();&#xA;            System.out.println(""Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "" + customMessage);&#xA;            if (customMessage != null) {&#xA;                response.putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                        .end(Json.encodePrettily(customMessage));&#xA;            }&#xA;            response.closed();&#xA;&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So if i post message to REST and handler publish it to the bus, when I am runtime get <a href=""http://localhost:9998/api/messagelist"" rel=""nofollow"">http://localhost:9998/api/messagelist</a>  it is return json, but second time it trow exception</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Response has already been written&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.checkWritten(HttpServerResponseImpl.java:561)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:154)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:52)&#xA;    at com.project.backend.Receiver.lambda$getMessagesFromBus$0(Receiver.java:55)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handleMessage(HandlerRegistration.java:207)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handle(HandlerRegistration.java:201)&#xA;    at io.vertx.core.eventbus.impl.EventBusImpl.lambda$deliverToHandler$127(EventBusImpl.java:498)&#xA;    at io.vertx.core.impl.ContextImpl.lambda$wrapTask$18(ContextImpl.java:335)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:358)&#xA;    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;&#xA;Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Message{username=Aaaewfewf2d, message=41414wefwef2d2}&#xA;</code></pre>&#xA;&#xA;<p>How to correctly get all messages from the receiver? Or if the bus received messages, should I immediately store them to the db? Can a message bus keep messages and not lost them?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37806128,docker-compose per microservice in local and production enironments?,2016-06-14 07:54:47,<docker><docker-compose><microservices><docker-swarm><docker-container>,1,157,0,0.0,1,"<p>I want to be able to develop microservices locally, but also to 'push' them into production with minimal configurational changes. I used to put all microservices into one <code>docker-compose</code> locally; but I start to see this might no be the practical.</p>&#xA;&#xA;<p>The new idea is to have single docker-compose <em>per service</em>. This does not means it will run with only one container; it might have more inside (like some datastore behind etc).</p>&#xA;&#xA;<p>From that new point of view, let's take a look at the well-known <a href=""https://github.com/docker/example-voting-app"" rel=""nofollow"">docker voting app example</a>, that consist of 5 components:</p>&#xA;&#xA;<ul>&#xA;<li>(<strong>P</strong>) Python webapp which lets you vote between two options</li>&#xA;<li>(<strong>R</strong>) Redis queue which collects new votes</li>&#xA;<li>(<strong>J</strong>) Java worker which consumes votes and stores them inâ€¦</li>&#xA;<li>(<strong>S</strong>) Postgres database backed by a Docker volume</li>&#xA;<li>(<strong>N</strong>) Node.js webapp which shows the results of the voting in real time</li>&#xA;</ul>&#xA;&#xA;<p>Let's say you want to push this example into production (so having just one <code>docker-compose</code> is not an option:). Not forget that more infrastructure-related components may be added on top of it (like kibana, prometheus...). And we want to be able to scale what we need; and we use e.g. swarm.</p>&#xA;&#xA;<p>The question is:</p>&#xA;&#xA;<ul>&#xA;<li>How to organize this example: in single <code>docker-composes</code> or many?</li>&#xA;<li>What microservices do we have here? In other words, which components would you combine into single <code>docker-compose</code>? Example: <strong>J</strong> and <strong>S</strong>?</li>&#xA;<li>If services are not in single docker-compose, do we add them to same overlay network to use swarm dns feature?</li>&#xA;<li>and so on...</li>&#xA;</ul>&#xA;&#xA;<p>(I don't need details on how to install stuff, this question is about top-level organization)</p>&#xA;"
37864491,"In a microservices architecture, how do you handle composite requests which must do minor data processing and call other services?",2016-06-16 16:19:04,<architecture><restful-architecture><microservices>,3,966,0,0.0,1,"<p>For example once the user gets to the payment step in our workflow a lot of different services need to be called (such as payment, email generation, content generation). Should the front-end handle that or should a service be designed to handle this type of request? If so, how should that service be designed so that it can handle doing composite requests without specifically hardcoding what those requests are composed of?</p>&#xA;"
37946486,Need help on docker scaling of micro-services,2016-06-21 13:56:49,<linux><docker><docker-compose><microservices><docker-machine>,1,74,1,0.0,1,"<p>I have installed docker on an AWS linux AMI instance and built apache image from docker file. Apache image is running as a container in my instance. I would want to monitor my docker micro service and also scale them, i.e if one goes down then how to spin up other. Please help me on how to proceed with this. I am bit confused with micro-instance scaling. I tried to use cadvisor but it didnt work. <strong>Please suggest me the other alternate to monitor and scale the docker containers</strong></p>&#xA;"
37985551,Alternative to iframe for microservices ui composition,2016-06-23 08:01:54,<iframe><microservices>,2,1405,2,0.0,1,"<p>I'm currently integrating multiple microservices ui into a web portal. I have a navigation sidebar with link to microservices which will be loaded into an iframe in the central area.</p>&#xA;&#xA;<p>I have lot of issue with iframe (security with frame option header, window sizing, etc...)</p>&#xA;&#xA;<p>Do you know about a better alternative to an iframe?</p>&#xA;"
37889067,Reactive Microservices Example - Generic & REAL (Not Abstract),2016-06-17 19:30:04,<microservices>,1,216,2,1.0,1,"<p>Every business is in the process of finding customers, making products, selling them to customers, etc.  </p>&#xA;&#xA;<p>I've been to a lecture on reactive microservices and know what they are in abstract form, but NOBODY (and I mean NOBODY) seems to be able to give me a good real life example in regards to how the software being created today would be better designed by utilizing reactive microservices.</p>&#xA;&#xA;<p>For example, a webservice that does Thing1 for a customer.  It has three major components, SubThing1, SubThing2, SubThing3.  SubThing2 can be much more memory and resource intensive at times, so it would be good to break it into reactive microservices so that SubThing2 can be scaled up and down when needed.</p>&#xA;&#xA;<p>Can You give me a real time live working practical example of Thing1, SubThing1, SubThing2, and SubThing3.</p>&#xA;"
37801454,Is there a way to implement SSO in front of the microservices?,2016-06-14 01:10:36,<go><single-sign-on><cas><microservices><beego>,1,1127,5,1.0,1,"<p>Recently I have a project to implement <a href=""https://en.wikipedia.org/wiki/Single_sign-on"" rel=""nofollow noreferrer"">SSO(Single-Sign-On)</a> for multiple web applications based on <a href=""http://beego.me/"" rel=""nofollow noreferrer"">Beego Framework</a>. The most popular SSO project is <a href=""https://en.wikipedia.org/wiki/Central_Authentication_Service"" rel=""nofollow noreferrer"">CAS</a>, which needs a CAS Server in the center, and a CAS Client before each web application. Unfortunately, it seems that there's not any offical CAS clients written in Golang, except <a href=""https://github.com/go-cas/cas"" rel=""nofollow noreferrer"">go-cas/cas</a>, and <a href=""https://github.com/adanteng/cas"" rel=""nofollow noreferrer"">adanteng/cas</a>, which supports Beego.</p>&#xA;&#xA;<p>But the workflow of CAS is a little bit complicated: too many redirections, too many tickets transmitted among the CAS, web apps, and the user browser. I can't figure out why people deploy the Authentication Services in the center of all the web apps, rather than the front, like the following diagram:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/aqOmDm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aqOmDm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In this diagram, all the requests are forced to be processed in the Authenticate Service first, if authenticated successfully, then generate a session ID, saved in the cookies and Redis which is shared by other microservices. There's not any redirections or tickets at all, only requests transmittion.</p>&#xA;&#xA;<p>So is this diagram possible, or some critical problems I ignored?</p>&#xA;&#xA;<h1>Update 0</h1>&#xA;&#xA;<p>The session-sharing way is indeed not scalable and modular as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> counsels. How about transmitting user information, like name, email, etc., in the headers of requests between the auth service and downstream services, like the creative work of Heipei at <a href=""https://heipei.github.io/2015/09/23/nginx-sso-Simple-offline-SSO-for-nginx/"" rel=""nofollow noreferrer"">nginx-sso</a>? Is it possible to make it work as an SSO Gateway as Sam Newman sharing in the book <a href=""http://samnewman.io/books/building_microservices/"" rel=""nofollow noreferrer"">Building Microservices</a>?</p>&#xA;&#xA;<h1>Update 1</h1>&#xA;&#xA;<p>A more detailed diagram is shown as follows, in order to describe my childish idea a little bit clearly, hoping that there is not much misunderstanding from Heipei and Sam Newman. </p>&#xA;&#xA;<p>Rather than handling so many redirections and handshakes, all the requests are processed in the authentication service firstly, which writes user info from MySQL, into the Redis as the session provider, and the HTTP header to transmit to the downstream services, if the request is authenticated successfully.</p>&#xA;&#xA;<p>In this way, the user info is transmitted via HTTP header instead of the above shared-Redis as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> warning, and Redis can be depolyed with the auth service, or shared among auth instances only.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BeMFF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BeMFF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<h1>Update 2</h1>&#xA;&#xA;<p>It seems that Cookie and Session are old-school techs. The cross-domain problem of cookie, and the sharing problem of session are the primary barrier to the scalability and flexibility of the modern web applications. Fortunately, JSON Web Token comes to be the best Single Sign-on solution for multiple lightweight services nowadays, by moving the user info(maybe id is enough) storage from the server side to the client side, and transmitted only if necessary.</p>&#xA;"
37389481,Connecting internal APIs,2016-05-23 11:13:18,<api><microservices><devops><infrastructure>,1,45,0,0.0,1,"<p>I am looking for a software that can within defined timeframe request one endpoint in the system and provide its output to another one. I am dealing with internal endpoints, that is why 3rd party SaaS are not an option.</p>&#xA;&#xA;<p>Things that I need it to do is</p>&#xA;&#xA;<ul>&#xA;<li>It should be configurable on the run (preferably through HTTP API)</li>&#xA;<li>It should request one endpoint and feed the output to another one</li>&#xA;<li>It should let to configure time frame</li>&#xA;<li>It should accept various authentication methods (for both sides)</li>&#xA;<li>Preferably support by community and opensource</li>&#xA;<li>Preferably free to use</li>&#xA;</ul>&#xA;&#xA;<p>I made quite extensive research on the internet withing last two days but was able to find only SaaS that provides that. I also asked my collegues at work but they could not suggest me anything useful. I am sure there is already something exists, it just me who could not find it.</p>&#xA;"
37427976,How do micro services in Cloud Foundry communicate?,2016-05-25 04:41:47,<rest><communication><cloudfoundry><microservices><predix>,2,1076,0,0.0,1,"<p>I'm a newbie in Cloud Foundry. In following the reference application provided by Predix (<a href=""https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600"" rel=""nofollow"">https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600</a>), the application consisted of several modules and each module is implemented as micro service.</p>&#xA;&#xA;<p>My question is, how do these micro services talk to each other? I understand they must be using some sort of REST calls but the problem is:</p>&#xA;&#xA;<ol>&#xA;<li><p>service registry: Say I have services A, B, C. How do these components 'discover' the REST URLs of other components? As the component URL is only known after the service is pushed to cloud foundry.</p></li>&#xA;<li><p>How does cloud foundry controls the components dependency during service startup and service shutdown? Say A cannot start until B is started. B needs to be shutdown if A is shutdown.</p></li>&#xA;</ol>&#xA;"
37439039,microservices messaging - cancel request,2016-05-25 13:42:52,<messaging><microservices>,1,56,0,0.0,1,"<p>I am trying to get my head around micro services messaging instead of pure REST and see a lot of benefits in decoupling and using RabbitMQ or similar as dispatcher.&#xA;One thing I don't quite understand is how you would cancel a request.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>Request X is composed of 4 calls to multiple micro services but micro service number 3 takes more time than expected and the whole request reaches the time out (for example 30 seconds).&#xA;I guess in the case the user will get a time out error.&#xA;But how would we cancel that request that is already in flight? I mean, say after 40 seconds micro service number 3 responds and the flow continues... the user would have received by now an error to his request.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37528335,Splitting monolith into microservices,2016-05-30 14:39:57,<spring><rest><spring-boot><microservices>,1,691,1,1.0,1,"<p>I have an existing web service that supports ordering and it has multiple operations (approximately 20). This is a single webservice that support the ordering function. It interacts with multiple other services to provide ordering capability. </p>&#xA;&#xA;<p>Since there is a lot of business functionality within this app and it is supported by a 10 member team , I believe it is a monolith (though I assume there is no hard and fast rule to define what a monolith is). </p>&#xA;&#xA;<p>We are planning to get the application deployed in cloud foundry environment and we are planning to split the app into 2-3 microservices , primarily to enable them scale independently. </p>&#xA;&#xA;<p>The first few apis which enable searching for a product typically have more number of hits whereas the api that support actual order submission receives less that 5% of the hits. So the product search api should have significantly larger number of instances as compared to order submission api. </p>&#xA;&#xA;<p>Though I am not sure if we could split is based on sub-domains (which I have read should be the basis) , we are thinking of splitting them based on the call sequence as explained earlier. </p>&#xA;&#xA;<p>I have also read that microservices should be choreographed and not orchestrated. However in order to ensure our existing consumers are not impacted , I believe we should expose a api layer which would orchestrate the calls to these microservices. Is providing an api gateway , the normal approach that is followed to ensure consumers do not end up calling multiple microservices and also provides a layer of abstraction? </p>&#xA;&#xA;<p>This seems to be orchestration more than choreography - though I am not hung up on the theoretical aspects , I would like to understand the different solutions that are pursued for this problem statement in an enterprise world.</p>&#xA;"
37509121,Listening on multiple events,2016-05-29 11:07:15,<microservices><event-driven-design>,2,161,2,0.0,1,"<p>How to deal with correlated events in an Event Driven Architecture? Concretely, what if multiple events must be triggered in order for some action to be performed. For example, I have a microservice that listens to two events <code>foo</code> and <code>bar</code> and only performs an action when both of the events arrive and have the same correlation id. </p>&#xA;&#xA;<p>One way would be to keep an internal data structure inside the microservice that does the book keeping and when everything is satisfied an appropriate action is triggered. However, the problem with this approach is that the microservice is not immutable anymore.</p>&#xA;&#xA;<p>Is there a better approach?</p>&#xA;"
43476908,How to implement microservices [Node.js]?,2017-04-18 15:55:46,<docker><docker-compose><microservices><seneca>,2,262,0,0.0,1,"<p>I am new to this, what is a best approach to implement microservices? </p>&#xA;&#xA;<p>I found fw like <code>seneca</code> but it is little bit confusing...</p>&#xA;&#xA;<p>Is there any tut how to create jwt auth, mongodb and other staff in  microservices?</p>&#xA;"
43378165,Microservice Architecture dependency,2017-04-12 19:34:55,<design-patterns><architecture><message-queue><microservices>,2,313,0,1.0,1,<p>I have read a lot about microservice architecture but there is one thing that I dont understand how to achieve and hope you can help me with this...</p>&#xA;&#xA;<p>Lets say I have a web-api-endpoint that recieves orders that an OrderMicroservice is responsible to handle. When order is put Inventory must be updated so OrderMS publish an event to subscribers (pub/sub using for example Nats) and InventoryMS will update the inventory due to it is subscribing to current event/message....I want to have a loose coupled architecture and use asynch calls to modules/MSs thats are interested in given info. </p>&#xA;&#xA;<p>Given scenario will work perfectly fine if you have 1 instance of InventoryMS but what happens if you have scaled the InventoryMS horizontally i.e there are 5 instances of InventoryMS and all of them subscribes to inventory.change.event and will try to update the inventory?</p>&#xA;&#xA;<p>What kind of architecture or message pattern should I use for a scenario like this with horizonatally scalled MS's so I can have a loose coupled architecture when MSs are dependent of each other? &#xA;One way is that communication internally is made by REST-calls using circuit breaker pattern but then I feel that I build a monolite of MSs with some smartness (the circuit breaker)...</p>&#xA;&#xA;<p>Thanks for your help!</p>&#xA;
43440170,ReflectionTestUtils.setfield is not overriding the local project property attribute,2017-04-16 17:44:38,<java><spring><microservices>,3,438,0,0.0,1,"<p>I am struggling with how to override a property file inside a .yml file</p>&#xA;&#xA;<p>We use the Spring framework and use annotations (eg. @InjectMocks).</p>&#xA;&#xA;<p>I have a an attribute declared in a configuration project YML file called ""one-platform-properties"" called paysafe-ss-fx-service.yml.  It sets a variable called <code>maxRecoveryAge=0</code>.  It is essentially a time to live buffer.</p>&#xA;&#xA;<pre><code>  oneplatform:&#xA;  environment: local&#xA;publisher:&#xA;  rates:&#xA;    maxRecoveryAge: 0&#xA;    interPublishDelay: 500&#xA;</code></pre>&#xA;&#xA;<p>The problem is that I want to be able to adjust this at run time in my tests.  Make the buffer to 1 hour, 5 hours and 24 hours.</p>&#xA;&#xA;<p>I am using the <code>ReflectionTestUtils.setfield(PublisherClass, ""maxDocumentAge"", 1, int.class)</code> call in my tests to adjust the timing, but the value is not being overridden.  When I do a watch on the variable it is working in my test harness, but once the test run penetrates into the micro service code, the overridden value is lost.  Any ideas on how to have the overridden value persist throughout all the tests?</p>&#xA;&#xA;<p>My goal is to use different variations on my test run:</p>&#xA;&#xA;<pre><code>ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",1,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",5,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",24,int.class);&#xA;</code></pre>&#xA;&#xA;<p>and essentially override the value as defined in the project defined properties file.</p>&#xA;"
43374386,What is the correct way to handle multiple levels of network requests?,2017-04-12 15:58:25,<web-services><http><asynchronous><microservices>,1,21,1,0.0,1,"<p>I have a service which accepts HTTP requests from a customer site. The service then sends an HTTP request to a transactional email provider with information provided in the initial request to the service. The workflow looks like this:</p>&#xA;&#xA;<p>CustomerSite <strong>âŸ·</strong> EmailService <strong>âŸ·</strong> TransactionEmailProvider</p>&#xA;&#xA;<p>I can think of two possibilities for handling requests so that errors from the TransactionalEmailProvider can be reported to the CustomerSite.</p>&#xA;&#xA;<ol>&#xA;<li>The <code>EmailService</code> immediately sends an asynchronous request to&#xA;<code>TransactionalEmailProvider</code> when it receives a request from a&#xA;<code>CustomerSite</code>. The <code>EmailService</code> immediately responds to the&#xA;<code>CustomerSite</code> with a success code if the request was properly&#xA;formed. If a failure happened when sending a request to the&#xA;<code>TransactionalEmailProvider</code>, the <code>EmailService</code> sends a failure&#xA;notification using a POST request back to the <code>EmailService</code> using a&#xA;webhook implementation.  </li>&#xA;<li>The EmailService sends a request to the TransactionalEmailProvider, and awaits a response before responding to the CustomerSite request with either a success or a failure.</li>&#xA;</ol>&#xA;&#xA;<p>Right now I'm implementing the first version because I don't want the responsiveness of the <code>EmailService</code> to be dependent on the responsiveness of the <code>TransactionalEmailProvider</code>.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Is this a reasonable way to process HTTP requests that are dependent upon a second level of HTTP requests? Are there situations in which one would be preferred over the other?</p>&#xA;</blockquote>&#xA;"
43350278,SemVer and Microservices,2017-04-11 15:29:38,<architecture><microservices><semantic-versioning>,2,289,3,0.0,1,"<p>Are there any best practices/patterns for applying SemVer in a microservice'd product? Should there be SemVer for each microservice, and SemVer for the overall product?</p>&#xA;&#xA;<p>Example- I have a product called <code>SuperDatabase</code> with 3 microservices called <code>SuperDatabaseCore</code>, <code>SuperDatabaseReports</code>, and <code>SuperDatabaseSearch</code>.</p>&#xA;&#xA;<p>Initial Release:&#xA;<code>SuperDatabase v1.0.0</code>&#xA;<code>SuperDatabaseCore v1.0.0</code>&#xA;<code>SuperDatabaseReports v1.0.0</code>&#xA;<code>SuperDatabaseSearch v1.0.0</code></p>&#xA;&#xA;<p>Minor Update to Report:&#xA;<code>SuperDatabaseReport v1.1.0</code></p>&#xA;&#xA;<p>Should the product be <code>SuperDatabase v1.1.0</code> now?</p>&#xA;&#xA;<p>What if later there is a patch to Search:&#xA;<code>SuperDatabaseSearch v1.0.1</code></p>&#xA;&#xA;<p>Should the product versioning be changed again? Should the product version be completely independent of the microservice? Should it use SemVer at all? Or should it not have any versioning?</p>&#xA;"
43424176,How to send various command type by MassTransit and RabbitMQ?,2017-04-15 09:01:03,<c#><rabbitmq><microservices><masstransit>,1,1238,4,0.0,1,"<p>Iâ€™m a beginner in using message brokers.<br/>&#xA;We have a ticketing service which has multiple sub service. A supervisor service gets requests with help of a web API and sends them to sub services.<br/>&#xA;Any request has a header which is used to detect command type (such as Reserve, Refund, Availability or etc.). We use json for serializing objects.<br/>&#xA;Now, How to send various message types(different objects) by MassTransit from a publisher such as our supervisor system, in a way that consumer can use it easily?<br/>&#xA;In general, is it possible to send various message type in MassTransit and rabbitMQ?<br/>&#xA;Every consumer has only one queue for processing received messages.</p>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<blockquote>&#xA;  <h1>Update</h1>&#xA;</blockquote>&#xA;&#xA;<p><code>https://dotnetcodr.com/2016/08/02/messaging-with-rabbitmq-and-net-review-part-1-foundations-and-terminology/</code> <br/></p>&#xA;&#xA;<p>I read This posts suit to start in messaging with MassTransit and didn't see any example to using various message types on these and another resources:</p>&#xA;&#xA;<p>I have multiple commands and need various message types to send with them, but in examples only use a message type such as below:</p>&#xA;&#xA;<p><strong>Sender</strong></p>&#xA;&#xA;<pre><code>    private static void RunMassTransitPublisherWithRabbit()&#xA;    {&#xA;        string rabbitMqAddress = ""rabbitmq://localhost:5672/Ticket"";&#xA;        string rabbitMqQueue = ""mycompany.domains.queues"";&#xA;        Uri rabbitMqRootUri = new Uri(rabbitMqAddress);&#xA;&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            rabbit.Host(rabbitMqRootUri, settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;        });&#xA;&#xA;        Task&lt;ISendEndpoint&gt; sendEndpointTask = rabbitBusControl.GetSendEndpoint(new Uri(string.Concat(rabbitMqAddress, ""/"", rabbitMqQueue)));&#xA;        ISendEndpoint sendEndpoint = sendEndpointTask.Result;&#xA;&#xA;        Task sendTask = sendEndpoint.Send&lt;IRegisterCustomer&gt;(new&#xA;        {&#xA;            Address = ""New Street"",&#xA;            Id = Guid.NewGuid(),&#xA;            Preferred = true,&#xA;            RegisteredUtc = DateTime.UtcNow,&#xA;            Name = ""Nice people LTD"",&#xA;            Type = 1,&#xA;            DefaultDiscount = 0&#xA;        });&#xA;        Console.ReadKey();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><strong>Receiver</strong></p>&#xA;&#xA;<pre><code>        private static void RunMassTransitReceiverWithRabbit()&#xA;    {&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            IRabbitMqHost rabbitMqHost = rabbit.Host(new Uri(""rabbitmq://localhost:5672/Ticket""), settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;&#xA;            rabbit.ReceiveEndpoint(rabbitMqHost, ""mycompany.domains.queues"", conf =&gt;&#xA;            {&#xA;                conf.Consumer&lt;RegisterCustomerConsumer&gt;();&#xA;            });&#xA;        });&#xA;&#xA;        rabbitBusControl.Start();&#xA;        Console.ReadKey();&#xA;&#xA;        rabbitBusControl.Stop();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><code>IRegisterCustomer</code> is an interface and I can only get message content in  <code>rabbit.ReceiveEndpoint</code> and convert to usable object.</p>&#xA;&#xA;<p>Now, How to use various message types such as <code>IReserveTicket</code>, <code>IRefundTicket</code> and <code>IGetAvailability</code> to sending and receiving messages?</p>&#xA;&#xA;<p>Thanks again</p>&#xA;"
47630168,Inter-service communication with Spring Boot and OAuth2,2017-12-04 09:30:19,<spring><oauth-2.0><microservices>,2,691,0,1.0,1,"<p>I am working on a micro-service architecture using Spring Boot. We have implemented OAuth2 in a Auth Server. </p>&#xA;&#xA;<p>My question is - If two microservices want to communicate what should be the best way?</p>&#xA;&#xA;<p>As of now, I have discovered below options:</p>&#xA;&#xA;<ol>&#xA;<li><p>If each microservice is verifying the token then we can pass the same token. But the problem is - in between same token can be expired.</p></li>&#xA;<li><p>If we use client_credentials grant then there we are having two issues: one is, we need to send the username in next microservice. Another one is, we need to request two times - first for getting the access token, next for actual call.</p></li>&#xA;<li><p>If we do the token verification in API gateway only (not in microservices) then from the API gateway we need to send the username in every microservices. And microservices implementation needs to be changed to accept that param/header.</p></li>&#xA;</ol>&#xA;&#xA;<p>Please suggest which option should I pick and if there is any better option please let me know.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47730089,eclipse-microprofiles config throws No ConfigProviderResolver implementation found,2017-12-09 15:26:43,<java><eclipse><java-ee><glassfish><microservices>,1,181,0,0.0,1,"<p>I am using <a href=""https://github.com/eclipse/microprofile-config"" rel=""nofollow noreferrer"">eclipse-microprofiles-config</a> v1.1 in my jersey 2.26.</p>&#xA;&#xA;<p>My complete build.gradle is as follows.</p>&#xA;&#xA;<pre><code>apply plugin: 'java'&#xA;apply plugin: 'war'&#xA;&#xA;repositories {&#xA;    mavenCentral()&#xA;}&#xA;&#xA;war{&#xA;    archiveName = 'pqr.war'&#xA;}&#xA;&#xA;dependencies {&#xA;    compile 'javax:javaee-api:7.0'&#xA;    compile 'javax.ws.rs:javax.ws.rs-api:2.0'&#xA;    compile 'org.glassfish.jersey.core:jersey-common:2.26'&#xA;    compile 'org.glassfish.jersey.core:jersey-client:2.26-b03'&#xA;    compile 'org.glassfish.jersey.core:jersey-server:2.26'&#xA;    compile 'org.glassfish.jersey.containers:jersey-container-servlet-core:2.26'&#xA;    compile 'org.glassfish.jersey.containers:jersey-container-servlet:2.26'&#xA;    compile 'org.glassfish.jersey.media:jersey-media-moxy:2.26'&#xA;    compile 'org.glassfish.jersey.inject:jersey-hk2:2.26'&#xA;    compile 'org.eclipse.microprofile.config:microprofile-config-api:1.1'&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have the required properties file located at <code>{PROJECT_ROOT}/src/main/webapp/META-INF/microprofile-config.properties</code>&#xA;in whichs content is </p>&#xA;&#xA;<pre><code>// Higher ordinal value so that this configuration source will take precedense&#xA;config_ordinal = 599999999 &#xA;foo.bar = abcdefghijklmnopqrstuvwxyz&#xA;</code></pre>&#xA;&#xA;<p>Whenever I try to get this configuration as </p>&#xA;&#xA;<pre><code>import javax.ws.rs.GET;&#xA;import javax.ws.rs.Path;&#xA;&#xA;import org.eclipse.microprofile.config.Config;&#xA;import org.eclipse.microprofile.config.ConfigProvider;&#xA;&#xA;@Path(value = ""awesomeService"")&#xA;public class AwesomeService {&#xA;&#xA;    @GET&#xA;    @Path(value = ""test"")&#xA;    public String someOperation() {&#xA;&#xA;        Config config = ConfigProvider.getConfig(); // fails here&#xA;        String value = config.getValue(""foo.bar"", String.class);&#xA;&#xA;        return value;&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>it throws ""No ConfigProviderResolver implementation found"" although ConfigProviderResolver.class is in the classpath. Im using glassfish 4 for my deployment. Where have I got it wrong. Following is the server log from glassfish. </p>&#xA;&#xA;<pre><code>[2017-12-09T20:34:17.296+0530] [glassfish 4.1] [WARNING] [] [javax.enterprise.web] [tid: _ThreadID=27 _ThreadName=http-listener-1(1)] [timeMillis: 1512831857296] [levelV$&#xA;lue: 900] [[&#xA;  StandardWrapperValve[org.pqr.rest.AppConfig]: Servlet.service() for servlet org.pqr.rest.AppConfig threw exception&#xA;java.lang.IllegalStateException: No ConfigProviderResolver implementation found!&#xA;        at org.eclipse.microprofile.config.spi.ConfigProviderResolver.instance(ConfigProviderResolver.java:122)&#xA;        at org.eclipse.microprofile.config.ConfigProvider.&lt;clinit&gt;(ConfigProvider.java:74)&#xA;        at org.pqr.rest.AwesomeService.someOperation(AwesomeService.java:16)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:498)&#xA;        at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81)&#xA;        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144)&#xA;        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161)&#xA;        at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:205)&#xA;        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99)&#xA;        at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389)&#xA;        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347)&#xA;        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102)&#xA;</code></pre>&#xA;&#xA;<p>A sample project which causes this problem can be downloaded here.&#xA;<a href=""https://github.com/kalpacg/eclipse-microprofile-config"" rel=""nofollow noreferrer"">https://github.com/kalpacg/eclipse-microprofile-config</a></p>&#xA;"
47633268,"Filtering errors, which errors we can show to end users",2017-12-04 12:20:36,<go><microservices><grpc>,1,57,2,0.0,1,"<p>I am developing platform with multiple microservices and I need to filter  errors: What kind of errors can be returned to end users and what are not.</p>&#xA;&#xA;<p>For example database errors are internal and they are not returned back to users. Instead, we send internal server error with status code. But validation errors can be send back to users. </p>&#xA;&#xA;<p>I have an idea how to do it manually. But I am searching the best practices to design this in a right way.</p>&#xA;&#xA;<p>P.S. I am using Go language and GRPC framework.</p>&#xA;"
47656406,"Are all the classes containing business logic, domain objects?",2017-12-05 14:49:15,<domain-driven-design><microservices><business-logic>,3,116,2,0.0,1,"<p>So I have few doubts regarding calling something as domain object (and eventually placing the class under domain package) or not.</p>&#xA;&#xA;<p>I have a micro-service whose responsibility is to do some calculations (without getting into actual business requirements, all it does is calculate some return of intereset based on given request). Now to achieve the calculations there are certain sub-calculations which need to take place and hence are composed in different classes respectively. But yes, these calculation do not need to be persisted in DB , and neither they have an ID (so definitely not an Entity or Aggregate). However these individual calculator classes (for the lack of terminology) do contain some complex business logic. Now, my question is, do these individual classes still qualify/classify as domain objects or should they be referred to as services ?</p>&#xA;&#xA;<p>Feel free to ask for more clarifications around use case if need be. </p>&#xA;&#xA;<p>Cheers ! </p>&#xA;"
40876048,Similar Endpoints on multiple API's,2016-11-29 21:28:05,<rest><microservices><api-design>,1,77,0,0.0,1,"<p>Say I have a few API's set up as micro-services. One API is to manage users (user API) and looks like:</p>&#xA;&#xA;<pre><code>/users                 GET, POST&#xA;    /{id}              GET, PUT, DELETE&#xA;</code></pre>&#xA;&#xA;<p>Then there is another API that is used to manage security information (access roles, permissions, etc.), and a <code>user</code> created in the user API can be assigned a <code>group</code> that is defined in the security API. Should that association be made in the security micro-service, or in the user micro-service? </p>&#xA;&#xA;<p>My initial thought is in the security micro-service since that is where all applications will request the security information from. With that, and that a <code>user</code> can only be assigned to one <code>group</code>, I then come up with the endpoint of:</p>&#xA;&#xA;<pre><code>/users/{id}/group      GET, POST, DELETE&#xA;</code></pre>&#xA;&#xA;<p>But that endpoint feels like it belongs more in the user micro-service. The other endpoints that are an option are:</p>&#xA;&#xA;<pre><code>/groups/{id}/users     GET, POST, DELETE&#xA;                /{id}  GET, DELETE&#xA;</code></pre>&#xA;&#xA;<p>But that then makes it seem that a <code>user</code> could be assigned to multiple groups. However, I could design it so that when a <code>user</code> is associated to a <code>group</code>, it disassociates it from a <code>group</code> that it was previously associated with.</p>&#xA;&#xA;<p>What is the best option, or is there a better way to handle these types of api calls that I am not aware of?</p>&#xA;"
40988204,Scaling: Server-Side vs Client-Side Rendering,2016-12-06 05:06:52,<architecture><microservices>,2,441,0,0.0,1,"<p>I've seen a lot of posts about SSR vs CSR but none of them touch on how this speed changes from a small application to a large one serving millions of users.</p>&#xA;&#xA;<p>Also, speed might not be the only concern. How do the two compare when you factor in:</p>&#xA;&#xA;<ol>&#xA;<li>Enterprise integration</li>&#xA;<li>Multiple client types e.g. Native mobile and desktop apps</li>&#xA;<li>When changing the API (updating or adding new end points) you will have to take the server down and that also takes down your SSR rendering webapp</li>&#xA;</ol>&#xA;&#xA;<p>Could someone please shed some light on this situation?</p>&#xA;&#xA;<p>Many Thanks,&#xA;Clement</p>&#xA;"
40832097,MockMvc returns null instead of object,2016-11-27 18:00:32,<spring><spring-mvc><junit><mockito><microservices>,1,2210,2,1.0,1,"<p>I am developing a microservice application and I need to test a post request &#xA;to a controller. Testing manually works but the test case always returns null.</p>&#xA;&#xA;<p>I've read many similar questions here in Stackoverflow and documentation but haven't figured out yet what I am missing.</p>&#xA;&#xA;<p>Here is what I currently have and what I tried in order to make it work:</p>&#xA;&#xA;<pre><code>//Profile controller method need to be tested&#xA;@RequestMapping(path = ""/"", method = RequestMethod.POST)&#xA;public ResponseEntity&lt;Profile&gt; createProfile(@Valid @RequestBody User user, UriComponentsBuilder ucBuilder) {&#xA;    Profile createdProfile = profileService.create(user); // line that returns null in the test&#xA;    if (createdProfile == null) {&#xA;        System.out.println(""Profile already exist"");&#xA;        return new ResponseEntity&lt;&gt;(HttpStatus.CONFLICT);&#xA;    }&#xA;    HttpHeaders headers = new HttpHeaders();&#xA;    headers.setLocation(ucBuilder.path(""/{name}"").buildAndExpand(createdProfile.getName()).toUri());&#xA;    return new ResponseEntity&lt;&gt;(createdProfile , headers, HttpStatus.CREATED);&#xA;}&#xA;&#xA;//ProfileService create function that returns null in the test case&#xA;public Profile create(User user) {&#xA;    Profile existing = repository.findByName(user.getUsername());&#xA;    Assert.isNull(existing, ""profile already exists: "" + user.getUsername());&#xA;&#xA;    authClient.createUser(user); //Feign client request&#xA;&#xA;    Profile profile = new Profile();&#xA;    profile.setName(user.getUsername());&#xA;    repository.save(profile);&#xA;&#xA;    return profile;&#xA;}&#xA;&#xA;// The test case&#xA;@RunWith(SpringRunner.class)&#xA;@SpringBootTest(classes = ProfileApplication.class)&#xA;@WebAppConfiguration&#xA;public class ProfileControllerTest {&#xA;&#xA;    @InjectMocks&#xA;    private ProfileController profileController;&#xA;&#xA;    @Mock&#xA;    private ProfileService profileService;&#xA;&#xA;    private MockMvc mockMvc;&#xA;&#xA;    private static final ObjectMapper mapper = new ObjectMapper();&#xA;&#xA;    private MediaType contentType = MediaType.APPLICATION_JSON;&#xA;&#xA;    @Before&#xA;    public void setup() {&#xA;        initMocks(this);&#xA;        this.mockMvc = MockMvcBuilders.standaloneSetup(profileController).build();&#xA;    }&#xA;    @Test&#xA;    public void shouldCreateNewProfile() throws Exception {&#xA;&#xA;        final User user = new User();&#xA;        user.setUsername(""testuser"");&#xA;        user.setPassword(""password"");&#xA;&#xA;        String userJson = mapper.writeValueAsString(user);&#xA;&#xA;        mockMvc.perform(post(""/"").contentType(contentType).content(userJson))&#xA;                .andExpect(jsonPath(""$.username"").value(user.getUsername()))&#xA;                .andExpect(status().isCreated());&#xA;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Tried to add <code>when</code>/<code>thenReturn</code> before post but still returns 409 response with null object.</p>&#xA;&#xA;<pre><code>when(profileService.create(user)).thenReturn(profile);&#xA;</code></pre>&#xA;"
40840470,MYSQL primary key strategy for microservices architecture,2016-11-28 09:02:37,<mysql><microservices>,2,169,5,0.0,1,"<p>We are currently using auto-generated primary keys and we would like to switch to an approach which is more suitable for microservices-based applications: either we are going to use business defined primary key (a tax code for persons) or global unique identifiers.</p>&#xA;&#xA;<ul>&#xA;<li>In the past, MySQL had performance issues when using alphanumeric primary keys instead of autoincrement, is it still the case? </li>&#xA;<li>Is it possible, if we go for the UUID approach, to use a strong uuid generator which will guarantee the uuid will be unique even across different servers?</li>&#xA;</ul>&#xA;"
50225125,Mutiple-language microservice approach,2018-05-08 02:57:20,<node.js><python-3.x><docker><microservices>,1,34,0,0.0,1,"<p>this is rather a straightforward question, i've tried to find something about it but either im totally out of my mind or it is not so easy to find out, Is there a way to have say: Microservice 1 (in Nodejs) and Microservice 2 (in Python) under the same ApiGateWay (Nodejs Express) ... i made it work using Nodejs (express) as gateWay and 2 Microservices in Nodejs (Cote.js) with no problem at all, but now i need part of the logic in python (Flask) .. what is the best approach to use a second language? i read something about an internal restApi but i could not find any clear example.</p>&#xA;&#xA;<p>btw: If Docker helps i can totally use it, dont hesitate about it.</p>&#xA;&#xA;<p>Thank you in advanse.</p>&#xA;"
50217813,Disable Microservice initial exposed port after configuring it in a gateway,2018-05-07 15:35:30,<security><microservices><firewall><kong><api-gateway>,3,41,0,0.0,1,"<p>Hello I've been searching everywhere and did not found a solution to my problem, which is how can I access my API through the gateway configured endpoint only, currently I can access to my api using localhost:9000, and localhost:8000 which is the Kong gateway port, that I secured and configured, but what's the point of using this gateway if the initial port is still accessible.&#xA;Thus I am wondering is there a way to disable the 9000 port and only access to my API with KONG.</p>&#xA;"
50159354,Microservices - Does HTML belong inside API Gateways?,2018-05-03 15:59:31,<html><microservices><soa><api-gateway>,1,49,0,0.0,1,"<p>When designing microservices with the API Gateway pattern, do HTML templates belong inside the API Gateway service, or as a standalone service?</p>&#xA;&#xA;<p>For example, if some website (like Stack Overflow) wants to change their features at will (question layout, messaging, search, etc...), then they can inject features into their HTML templates.</p>&#xA;&#xA;<p>If the templates are coupled with the Gateway:</p>&#xA;&#xA;<ul>&#xA;<li>Latency is decreased</li>&#xA;<li>Any changes to the templates affects the entire Gateway service.</li>&#xA;</ul>&#xA;&#xA;<p>If the templates exist as their own Templating Service:</p>&#xA;&#xA;<ul>&#xA;<li>Latency increases</li>&#xA;<li>Updating templates doesn't necessitate editing the Gateway.</li>&#xA;</ul>&#xA;&#xA;<p>I'm wondering which method is preferable for designing a web application using the API Gateway pattern.  What are the pros and cons of each approach?</p>&#xA;"
50139640,Architecture of microservices from a business approach or technical?,2018-05-02 16:43:36,<rest><docker><cloud><microservices>,3,50,0,1.0,1,"<p>Our team is trying to decouple a <strong>monolithic</strong> spring mvc administrative application <em>(create, update, delete)</em> and we want to adopt an architecture based on <strong>microservices</strong>. </p>&#xA;&#xA;<p>After a bit of research, it seems the best is create microservices <strong><em>according to the problem</em></strong> that a specific part of the software solves, for example, Managing Clients. </p>&#xA;&#xA;<p>The problem comes when we read some definitions, like the following from <strong><a href=""https://en.wikipedia.org/wiki/Monolithic_application"" rel=""nofollow noreferrer"">Wikipedia</a></strong>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In software engineering, a monolithic application describes a&#xA;  single-tiered software application in which the user interface and&#xA;  data access code are combined into a single program from a single&#xA;  platform.</p>&#xA;</blockquote>&#xA;&#xA;<p>Based on that definition, <em>my application is not monolithic</em>, because it is perfectly separated in layers, but it is not found in a micro-services architecture either, which is confusing to me since in the web everything is about <strong>Monolithic vs. Microservices</strong>.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/EIfHO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EIfHO.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>So, should the microservices architecture be designed based on the business problem it solves?</strong> </p>&#xA;&#xA;<p><strong>Should the microservices architecture be designed based on to the way in which the application is organized in layers?</strong></p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
50284055,Using Google Cloud ecosystem vs building your own microservice architecture,2018-05-11 02:16:12,<google-bigquery><google-cloud-storage><microservices><google-cloud-dataflow>,2,77,0,1.0,1,"<p>Building in the Google Cloud ecosystem is really powerful. I really like how you can ingest files to Cloud Storage then Data Flow enriches, transforms and aggregates the data, and then finally stored in BigQuery or Cloud SQL.</p>&#xA;&#xA;<p>I have a couple of questions to help me have a better understanding. &#xA;If you are to build a big data product using the Google services.</p>&#xA;&#xA;<ol>&#xA;<li><p>When a front-end web application (might be built in React) submits a file to Cloud storage it may take some time before it completely processes. The client might want to view the status the file in the pipeline. They then might want to do something with the result on completion. How are front-end clients expected know when a file has completed processed and ready? Do they need to poll data from somewhere?</p></li>&#xA;<li><p>If you currently have a microservice architecture in which each service does a different kind of processing. For example one might parse a file, another might processes messages. The services communicate using Kafka or RabbitMQ and store data in Postgres or S3. &#xA;If you adopt the Google services ecosystem could you replace that microservice architecture with Cloud storage, dataflow, Cloud SQL/Store?</p></li>&#xA;</ol>&#xA;"
50154865,What does it mean by Heartbeat in terms of micro-services?,2018-05-03 12:14:30,<microservices><netflix-eureka>,2,132,0,0.0,1,"<p>I was reading an article about eureka and it said :</p>&#xA;&#xA;<blockquote>&#xA;  <p>if there are two clients registered to a Eureka instance, each one sending a heartbeat every 30s</p>&#xA;</blockquote>&#xA;&#xA;<p>What is a heartbeat? what information is sent in a heartbeat?</p>&#xA;"
50122851,Client side load balancing (Ribbon) and Service Discovery (Eureka) on PaaS cloud (PCF),2018-05-01 19:48:09,<cloud><microservices><netflix-eureka><pivotal-cloud-foundry><netflix-ribbon>,1,240,0,0.0,1,"<p>Currently we deploy our application to Pivotal Cloud Foundry (PCF), which operates in a Platform as a Service (PaaS) model. </p>&#xA;&#xA;<p>It means whenever we deploy an app to PCF, PCF automatically (apart from the other actions it does) sets up a load balancer forwarding requests to the desired number of the instances it automatically provisioned. </p>&#xA;&#xA;<p>Having that in mind, is it possible to use a client side load balancer such as Ribbon in a PaaS cloud, so that the clients of your app will reach out directly to the instances running your app, not to the load balancer? If yes, what are the benefits?</p>&#xA;&#xA;<p>One more related question, if all my services follow the same naming convention e.g. <code>myapp-service</code> and therefore are available under <code>https://myapp-service.cfapps.io</code> is there any benefit of setting up a Service Discovery service (e.g. Eureka) in a PaaS cloud?</p>&#xA;"
50265973,domain object sharing microservices,2018-05-10 05:19:15,<java><database-design><architecture><microservices><spring-cloud>,2,145,2,0.0,1,"<p>I am trying to understand Microservices. I would like to know how to tackle the problem of one to many/ many to many relationship in microservices architecture and what's the best practice. Assume I want to convert student-course app to student service and course service and student service talks to Student table and course service talks Course table in the same database.</p>&#xA;&#xA;<p>Example:&#xA;Students can enroll to many courses and also many courses can have many students( Many to Many relationship). I have 2 microservices&#xA;Microservices 1: Student-service&#xA;Microservices 2: Course-service</p>&#xA;&#xA;<p><strong>Student Service has Student object</strong></p>&#xA;&#xA;<pre><code>@Entity&#xA;@Table(name = ""STUDENT"")&#xA;public class Student {&#xA;&#xA;@Id&#xA;@GeneratedValue(strategy = GenerationType.AUTO)&#xA;private long id;&#xA;&#xA;@Column(name = ""NAME"")&#xA;private String name;&#xA;&#xA;&#xA;//@ManyToMany(fetch = FetchType.LAZY)&#xA;//@JoinTable(name = ""STUDENT_COURSE"", joinColumns = @JoinColumn(name = //""STUDENT_ID""), inverseJoinColumns = @JoinColumn(name = ""COURSE_ID""))&#xA;//  private List&lt;Course&gt; courses = new ArrayList&lt;Course&gt;();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Course Service has Course object</strong></p>&#xA;&#xA;<pre><code>@Entity&#xA;@Table(name = ""COURSE"")&#xA;public class Course {&#xA;&#xA;@Id&#xA;@Column(name = ""ID"")&#xA;private long id;&#xA;&#xA;@Column(name = ""COURSE_NAME"")&#xA;private String name;&#xA;&#xA;//@ManyToMany(mappedBy = ""courses"", fetch = FetchType.LAZY)&#xA;//private List&lt;Student&gt; students = new ArrayList&lt;Student&gt;();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I understand student services has to make call to course service to get the courses but how do I map course to a student?( like student A has enrolled to Course X,Y,Z)</p>&#xA;&#xA;<ul>&#xA;<li>How do I get list of courses for a student or list of students for a&#xA;course? </li>&#xA;<li>Do I need to duplicate <strong>Course</strong> class in <strong>Student&#xA;Service</strong> and <strong>Student</strong> class in <strong>Course service</strong>? </li>&#xA;<li>Do I need to&#xA;move the domain classes to common project and then share between&#xA;microservices to avoid duplicating?</li>&#xA;</ul>&#xA;&#xA;<p>Can you please help me by answering the best practice to solve many to many relationship problem in microservice?</p>&#xA;"
50248560,spring-boot:run for multi module maven project,2018-05-09 08:14:42,<java><maven><spring-boot><microservices><netflix-eureka>,1,239,3,0.0,1,<p>I have a micro services setup of Eureka Server and multiple spring-boot applications as Eureka Clients. This is setup as maven multi module project at the parent (root) level. Below is the hierarchy:</p>&#xA;&#xA;<pre><code>parent (multi-module parent pom.xml)&#xA;  |_ eureka-server-spring-boot-app (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-1 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-2 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-3 (individual pom.xml)&#xA;  .&#xA;  .&#xA;</code></pre>&#xA;&#xA;<p>I was trying to run all the modules in the order defined in parent pom.xml. But when I run <code>mvn spring-boot:run</code> at parent level it only runs the first module (Eureka Server). Other modules are not deployed. I tried reading through SO but no relevant answers found.</p>&#xA;&#xA;<p>I want maven to run all the modules in order from parent directory. Is there any way this can be achieved?</p>&#xA;
51923607,What design pattern should be used for a workflow like this?,2018-08-20 02:54:48,<design-patterns><architecture><workflow><microservices><soa>,2,37,0,0.0,1,"<p>Let's say I have a workflow like this</p>&#xA;&#xA;<pre><code>          (1) Check for latest commit in a GitHub repo&#xA;                             |&#xA;                             |&#xA;                    (2) Is new commit?&#xA;                            / \&#xA;                        No /   \ Yes&#xA;                          /     \&#xA;                         /       \&#xA;                      End         \&#xA;                                   \&#xA;                                    \&#xA;                                  (3) Download all files&#xA;                                  /       |       \&#xA;                                 /        |        \&#xA;                     (4i) Process file i  .      Process file N&#xA;                                \         .         /&#xA;                                 \        .        /&#xA;                                  \       .       /&#xA;                                   \      .      /&#xA;                                    \     .     /&#xA;                                        End&#xA;</code></pre>&#xA;&#xA;<p>and I want to have the following microservices:</p>&#xA;&#xA;<ul>&#xA;<li>(A) Commit Checker</li>&#xA;<li>(B) File Downloader</li>&#xA;<li>(C) File Processer</li>&#xA;</ul>&#xA;&#xA;<p><strong>My question is whether each of these microservices should be a link in a sequential workflow, or whether these microservices should just contain functionalities and a separate ""omniscient"" microservice conducts the workflow.</strong></p>&#xA;&#xA;<p>In the first case it might look like</p>&#xA;&#xA;<pre><code>A: (1),(2) ====&gt; B:(3) ====&gt; C:(4i),(4ii),...,(4N)&#xA;</code></pre>&#xA;&#xA;<p>where each link is writing a message in a queue that gets picked up by the next link.</p>&#xA;&#xA;<p>Because (2) is in A, that means that A is making a decision about whether to invoke B. I guess you could then say that the services are tightly coupled. </p>&#xA;&#xA;<p>In other implementation I've suggesting, there would be a separate service X that performs the control flow and simply plugs in data to A, B, C, which would perform single tasks like</p>&#xA;&#xA;<pre><code>A: Get latest commit&#xA;B: Download all files by commit&#xA;C: Process single file&#xA;</code></pre>&#xA;&#xA;<p>and then X would own/execute the logic of</p>&#xA;&#xA;<ul>&#xA;<li>(2), i.e. deciding whether to terminate the workflow or do the next step</li>&#xA;<li>Deciding to have the downloaded files processed in parallel</li>&#xA;</ul>&#xA;&#xA;<p>Which is better implementation?</p>&#xA;&#xA;<p>Another question I have is about storage. The <code>Is new commit?</code> part means that I keep a record of commits so I can tell whether what I checked is one that I haven't checked before. <strong>Who should keep the record of commits? Should it be considered in A's storage or a separate ""workflow storage""?</strong> </p>&#xA;"
51798009,Not able to access service on minikube cluster| Istio,2018-08-11 08:43:30,<docker><kubernetes><microservices><minikube><istio>,1,45,0,0.0,1,"<p><a href=""https://i.stack.imgur.com/EKOoX.png"" rel=""nofollow noreferrer"">Startup Logs of Pod</a>  I am not able to access a spring boot service on my minikube cluster.&#xA;On my local machine,I configured minikube cluster and built the docker image of my service. My service contains some simple REST endpoints.</p>&#xA;&#xA;<p>I configured minikube to take my local docker image or should I say pull my docker image. But now when I do     </p>&#xA;&#xA;<pre><code>kubectl get services -n istio-system&#xA;</code></pre>&#xA;&#xA;<p>I get the below services&#xA;<a href=""https://i.stack.imgur.com/BiBia.png"" rel=""nofollow noreferrer"">kubectl get services|Services list in minkube cluster</a> | &#xA;<a href=""https://i.stack.imgur.com/yxHwn.png"" rel=""nofollow noreferrer"">Kubectl get pods all namespaces</a> | <a href=""https://i.stack.imgur.com/96QUs.png"" rel=""nofollow noreferrer"">Kubectl describe service</a></p>&#xA;&#xA;<p>I am trying to access my service through below command</p>&#xA;&#xA;<p><code>minikube service producer-service --url&#xA;</code>&#xA;which gives <a href=""http://192.168.99.100:30696"" rel=""nofollow noreferrer"">http://192.168.99.100:30696</a></p>&#xA;&#xA;<p>I have a ping URL in my service so ideally I should be getting response by hitting <a href=""http://192.168.99.100:30696/ping"" rel=""nofollow noreferrer"">http://192.168.99.100:30696/ping</a></p>&#xA;&#xA;<p>I am not getting any response here. Can you guys please let me know what I am missing here?</p>&#xA;"
51924926,Communication between user-service and auth-service in microservice architecture,2018-08-20 06:07:06,<spring><security><spring-security><microservices><restful-authentication>,1,49,0,0.0,1,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<p>This is my login scenario for my microservice application:</p>&#xA;&#xA;<ol>&#xA;<li>The user enters his phone number</li>&#xA;<li>A verification code will be sent  </li>&#xA;<li>The user must send the received code to verify it  </li>&#xA;<li>The user must enter his password </li>&#xA;<li>A JWT Token will be received</li>&#xA;</ol>&#xA;&#xA;<p><strong>REST Implementation</strong></p>&#xA;&#xA;<p>For implementing the given scenario, I've created three services: auth, sms, and user. From my point of view, I think it's better to handle requests for sending verification code and generating JWT token from user-service. Here is the detail of my implementation:</p>&#xA;&#xA;<ul>&#xA;<li><p>User calls <code>POST /user/sms</code> to send his phone number to the <strong>user-service</strong>. Inside that, a request will be made to the <strong>sms-service</strong> to send the verification code.</p></li>&#xA;<li><p>Then user calls <code>POST /user/verify</code> to verify the code, again this request will be handled inside the <strong>user-service</strong>. If the code is valid, user-service will generate a temporary token and pass it to the header response (assume that the user is already registered into the system)</p></li>&#xA;<li><p>Now the user passes his password with the temporary token via <code>POST /user/password</code>. If the credentials are valid, <strong>user-service</strong> will call <strong>auth-service</strong> to get a JWT token and append it to the response header of <code>POST /user/password</code>.</p></li>&#xA;</ul>&#xA;&#xA;<p><strong>Question</strong></p>&#xA;&#xA;<p>Are there right communications between user&lt;->auth and user&lt;->sms services? </p>&#xA;"
51842770,monolithic webapi to micro service design,2018-08-14 13:33:43,<microservices><azure-service-fabric>,1,72,0,0.0,1,"<p>We have a monolithic webAPI layer in our application with hundred end pints and I am trying to break it to Micro-services using Azure Service Fabric. &#xA;When we break them into multiple services we may end up having duplicate code. &#xA;Example: Let's say we have an Account Services to create account. And there is a payment service to apply payments to transactions.&#xA;In this case both the services need Customer class/domain. Probably the Account Services need an exhaustive customer with full details, but the payment might need a light weight one.</p>&#xA;&#xA;<p>The question is do we need to copy several domain entities, and other layers like this. Doesn't that create more maintenance issues.</p>&#xA;&#xA;<p>If we don't we end up copying the code and creating different services one monolithic service same is the existing webapi.</p>&#xA;&#xA;<p>Any thoughts on this.</p>&#xA;&#xA;<p>2ndly, we have some cases where transactions are mentioned today and if we separate them any good design to record failures and rollback, without trying too much to maintain transactions.</p>&#xA;"
51863914,Load balancing in Spring boot micro services hosted on Kubernetis,2018-08-15 17:51:11,<spring-boot><load-balancing><microservices><netflix-zuul><google-kubernetes-engine>,1,44,2,0.0,1,"<p><strong>Context</strong>: </p>&#xA;&#xA;<p>Building Micro services based architecture using SpringBoot and REST APIs/micro-services. The application will be Containerized using Docker and then will be deployed on Google Cloud Platform Kubernetes service. Thinking of using Nextflix ZUUL for API Gateway for Cross cutting concerns like Authentication / Authorization (OAuth2), Service discovery (Eureka) &amp; Compose, etc..</p>&#xA;&#xA;<p><strong>Query</strong>:</p>&#xA;&#xA;<p>As the application will be hosted on Kubernetes, the question is around which Load balancing should be used? &#xA;As per my limited knowledge there are 2 options:&#xA;1) Ribbon&#xA;2) Kubernetes Service&#xA;3) Combination of both of the above</p>&#xA;&#xA;<p>It would be great help if will get some pointers, best practices etc. to come up with optimum solution. Kindly let know if additional information is required from my side.</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
51863731,Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository,2018-08-15 17:38:33,<spring><microservices><spring-cloud>,1,87,3,1.0,1,"<p>I am developing <code>Microservices with Spring Boot 2.0, Eureka and Spring Cloud</code> taking a ref from : <a href=""https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/"" rel=""nofollow noreferrer"">https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/</a>. In this example, I am developing <code>config-service</code> with <code>spring-boot-starter-parent</code> version <code>2.0.4.RELEASE</code>. </p>&#xA;&#xA;<p>When I simply run this code I got the below error. No where steps mentioned to setup the local git or use remote git. Could anyone please guide me on this?</p>&#xA;&#xA;<p><strong>Error:</strong></p>&#xA;&#xA;<pre><code>Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.&#xA;23:04:07.774 [main] ERROR o.s.boot.SpringApplication - Application run failed&#xA;org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155)&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:544)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:398)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246)&#xA;    at com.prateek.ConfigServiceApplication.main(ConfigServiceApplication.java:12)&#xA;Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:126)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:413)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:174)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152)&#xA;    ... 8 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'servletEndpointRegistrar' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:226)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:214)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:91)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:80)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:250)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:237)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:54)&#xA;    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)&#xA;    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1421)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1411)&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)&#xA;    at java.lang.Thread.run(Unknown Source)&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 23 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1089)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBean(EndpointDiscoverer.java:143)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBeans(EndpointDiscoverer.java:132)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.discoverEndpoints(EndpointDiscoverer.java:122)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.getEndpoints(EndpointDiscoverer.java:116)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.servletEndpointRegistrar(ServletEndpointManagementContextConfiguration.java:75)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.CGLIB$servletEndpointRegistrar$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c$$FastClassBySpringCGLIB$$5ed0fb30.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.servletEndpointRegistrar(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 24 common frames omitted&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 48 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:732)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:474)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:514)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:502)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1198)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthIndicatorBeansComposite.get(HealthIndicatorBeansComposite.java:46)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration.healthEndpoint(HealthEndpointConfiguration.java:38)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.CGLIB$healthEndpoint$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444$$FastClassBySpringCGLIB$$c5cb8397.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.healthEndpoint(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 49 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:666)&#xA;    at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:91)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1341)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:572)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:818)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:724)&#xA;    ... 73 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1699)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:573)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1322)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1288)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1190)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1093)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:658)&#xA;    ... 96 common frames omitted&#xA;Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.util.Assert.state(Assert.java:73)&#xA;    at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.afterPropertiesSet(JGitEnvironmentRepository.java:245)&#xA;    at org.springframework.cloud.config.server.environment.MultipleJGitEnvironmentRepository.afterPropertiesSet(MultipleJGitEnvironmentRepository.java:69)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1758)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1695)&#xA;    ... 109 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;</code></pre>&#xA;"
51926575,Linking data in java microservices in a database per service implementation,2018-08-20 08:13:36,<java><spring><spring-boot><microservices><cqrs>,3,47,4,1.0,1,"<p>I am building a java / spring microservices where each service has it own database . Let's say i have a user service that stores user information in one of the table and a orders service that stores only the username of the person who orders as described below :-</p>&#xA;&#xA;<pre><code>User Service (UserService Database - User Table )&#xA;id     firstName    lastName     username     age &#xA;1       Chris        Brown       c.brown      20&#xA;2       John         Doe         j.doe        25&#xA;</code></pre>&#xA;&#xA;<p>And orders service as below</p>&#xA;&#xA;<pre><code> Order Service (OrderService Database - Order Table )&#xA;    id     username    productName     productPrice     OrderDate &#xA;    1      c.brown       Sony Mic       100$            20-08-2018&#xA;    2       j.doe       Television      j.doe           11-07-2018&#xA;</code></pre>&#xA;&#xA;<p>Question is what is the best approach to get firstName and lastName from user service while listing the orders . I am aware that microservices should communicate via Rest API , but if i have 1000 users with orders , i will have to loop 1000 times to get the firstName and lastName or take usernames as array , activity which might be expensive . </p>&#xA;&#xA;<p>I have read on using CQRS and event sourcing , but not sure how to best apply it in this scenario . </p>&#xA;"
40737349,Right place to do the service composition in API world?,2016-11-22 08:49:46,<microservices><aws-api-gateway><apigee><kong>,3,515,0,0.0,1,"<p>I am working in an environment where API is becoming a by default standard and we have a lot of micro services available... but still not able to meet the requirement of my customers...</p>&#xA;&#xA;<p>My customer demands a mix and match of data which I need to offer by writing new compositions and further host them as services.... </p>&#xA;&#xA;<p>1) What is the right platform to do this composition, gateways or host them on a dedicated paas instances?</p>&#xA;&#xA;<p>2) The moment I start going for composition, I end up paying for http overhead compared to get data directly from database</p>&#xA;&#xA;<p>Any help will be helpful</p>&#xA;"
40688160,"Kubernetes - Creating a specific namespace for ""services""",2016-11-19 01:07:02,<docker><kubernetes><microservices><devops><environments>,1,55,0,0.0,1,"<p>In our micro-service architecture we have a number of stateful services:</p>&#xA;&#xA;<ul>&#xA;<li>MongoDB</li>&#xA;<li>MySQL</li>&#xA;<li>Redis</li>&#xA;<li>ElasicSearch</li>&#xA;</ul>&#xA;&#xA;<p>We also have two Kubernetes <code>namespaces</code> we use for our different environments:</p>&#xA;&#xA;<ul>&#xA;<li>Staging</li>&#xA;<li>Production</li>&#xA;</ul>&#xA;&#xA;<p>We run each of the above stateful services in both environments / namespaces. I have been wondering as we are limited for resources in our cluster due to a limited budget. Should we create a third namespace for a these services and use them for both production and staging environments? e.g. create a </p>&#xA;&#xA;<p>""Services"" namespace?</p>&#xA;&#xA;<p><strong>Whats the best practice in this case? Are there any disadvantages?</strong></p>&#xA;"
40719381,Service request/response: would you use routing keys and store messages in the same RabbitMQ queue?,2016-11-21 11:45:31,<rabbitmq><messaging><soa><microservices>,2,65,0,0.0,1,"<p>For example, I've implemented a search indexing service, which receives search requests and produces responses using messages.</p>&#xA;&#xA;<p>Currently I've defined a queue to enqueue <em>search requests</em> and other one to enqueue <em>search results</em>.</p>&#xA;&#xA;<p>Would you refactor this to just enqueue to an unique queue where messages have a <em>request</em> and <em>response</em> <strong>routing keys</strong>? Or is this overusing <em>RabbitMQ</em> on this particular case?</p>&#xA;"
40564595,Docker - run two processes in single container,2016-11-12 15:48:29,<ruby-on-rails><nginx><docker><docker-compose><microservices>,1,612,0,0.0,1,"<p>I've created Ruby on Rails project with Nginx. Rails app and Nginx runs in separate and linked containers. This configuration works fine. However...</p>&#xA;&#xA;<p><strong>1) Is it possible to run both together (Rails / Puma server + Nginx) in a single container?</strong> </p>&#xA;&#xA;<p><strong>2) How should the CMD command in Dockerfile look like?</strong></p>&#xA;&#xA;<p><strong>3) What command should I use as the ""command:"" attribute in docker-compose.yml?</strong></p>&#xA;&#xA;<p>I think that configuration to run them in separate containers is better solution, but I would like to get to know all possibilites.</p>&#xA;&#xA;<p><em>I use Puma as a Rails' app server and to run it I use command: bundle exec puma -C config/puma.rb</em></p>&#xA;"
40735590,How to switch request traffic from old server instance to a new one dynamically with jhipster-registry?,2016-11-22 06:57:48,<jhipster><microservices><netflix-eureka>,2,135,0,1.0,1,"<p>I use jhipster-registry for registry and manage microservice .And it based on Spring Cloud Netflix Eureka and Spring Cloud Config. </p>&#xA;&#xA;<p>when I add new api and publish next version of a micro service , I need</p>&#xA;&#xA;<ol>&#xA;<li>start a new service instance </li>&#xA;<li>switch request traffic from old instance to the new one </li>&#xA;<li>remove / shut down old one  </li>&#xA;</ol>&#xA;&#xA;<p>And I don't want to restart my gateway during these steps. Actually, I'm look a runtime dynamic routing method .</p>&#xA;"
40564979,Host WepAPI on Service Fabric,2016-11-12 16:25:29,<c#><asp.net-web-api><microservices><azure-service-fabric><devops>,3,755,0,1.0,1,"<p>We just stood up an on-premise MS Service Fabric cluster.  I have some WebAPI's i'd like to host in it.  I'm looking for resources on how to take our standard 4.5 WebAPI's and host them in Service Fabric without have to create a Service Fabric project and migrate it; that just seems too complex.</p>&#xA;&#xA;<p>I looked at some of the Service Fabric sample projects, and it seems all the projects are tightly coupled with Service Fabric.  My goal is keep these apps unaware of Service Fabric.</p>&#xA;&#xA;<p>Any links of information is greatly appreciated, thanks!</p>&#xA;"
50796780,Ensure consistence for foreignkeys/ownerships in microservices,2018-06-11 11:34:55,<rest><reference><foreign-keys><microservices>,2,14,0,0.0,1,"<p>I have two bounded contexts which lead into two micro services</p>&#xA;&#xA;<ul>&#xA;<li>PersonalManagement</li>&#xA;<li>DocumentStorage</li>&#xA;</ul>&#xA;&#xA;<p>I keep the entity model simple here.</p>&#xA;&#xA;<p>PersonalManagement:</p>&#xA;&#xA;<pre><code>Entity/Table Person:&#xA;@id - int&#xA;tenantId - int&#xA;name - string&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>DocumentStorage</p>&#xA;&#xA;<pre><code>Entity/Table Document:&#xA;@id - int&#xA;tenantId - int&#xA;personId - int&#xA;dateIssued - string&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>You need to know that before the application is started - a company (tenant) is choosen to define the company context.</p>&#xA;&#xA;<p>I want to store a new document by using REST/JSON.</p>&#xA;&#xA;<p>This is a POST to /tenants/1/persons/5/documents</p>&#xA;&#xA;<pre><code>with the body&#xA;{&#xA;    ""dateIssued"" : ""2018-06-11""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>On the backend side - I validate the input body.</p>&#xA;&#xA;<p>One validation might be ""if the person specified exists and really belongs to given tenant"".</p>&#xA;&#xA;<p>Since this info is stored in the PersonalManagement-MicroService, I need to provide an operation like this:</p>&#xA;&#xA;<pre><code>""Does exists (personId=5,tenantId=1)""&#xA;</code></pre>&#xA;&#xA;<p>in PersonalManagement to ensure consistence since caller might be evil.</p>&#xA;&#xA;<p>Or in general:</p>&#xA;&#xA;<p>What is best practise to check ""ownership"" of entities cross database in micro services</p>&#xA;&#xA;<p>It might also be an option that if a new person is created (tenantId,personId) this information is stored additionally(!) in DocumentStorage but wanna avoid this redundancy.</p>&#xA;"
50830715,REST-based services running as pods on Kubernetes in Azure with intermittent timeouts,2018-06-13 06:48:18,<azure><docker><kubernetes><microservices>,3,36,0,0.0,1,"<p>We have a number of different REST-based services running in Azure within a Kubernetes (version 1.9.6) cluster.  </p>&#xA;&#xA;<p>Two of the services, let's say A and B needs to communicate with each other using REST-calls.  Typically, something like the following:</p>&#xA;&#xA;<pre><code>Client calls A (original request)&#xA;A calls B (request 1)&#xA;B calls A (request 2)&#xA;A responds to B (request 2)&#xA;B responds to A (request 1)&#xA;A responds to the original request&#xA;</code></pre>&#xA;&#xA;<p>The above being a typical intertwined micro-services architecture.  Manually running the docker instances works perfectly on our local test servers.</p>&#xA;&#xA;<p>The moment we run this in Kubernetes on Azure we get intermittent timeouts (60+ seconds) on the micro-services calling each other through Kubernetes' networking services.  After a timeout, repeating the request would then often give correct responses in a few micro-seconds.</p>&#xA;&#xA;<p>I am stuck at this point as I have no idea what could be causing this.  Could it be the dynamic routing?  The virtualised network? Kubernetes configuration? </p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
50889657,Microservice synchronous communication - service to service or message broker,2018-06-16 16:26:32,<spring><spring-boot><apache-kafka><microservices>,2,53,0,2.0,1,"<p>I am developing a series of microservices using Spring Boot and Kafka. For asynchronous communication, I am using Kafka which is working well. </p>&#xA;&#xA;<p>I have a use case where I require synchronous communication between two microservices (a user registers a profile via the user profile service which needs to create an auth account in the auth microservice). </p>&#xA;&#xA;<p>Should I just call the auth service directly (service to service communication) or should I use Kafka?</p>&#xA;&#xA;<p>Any examples or best practise advice would be appreciated. </p>&#xA;"
50820762,Vertx is not binding Routers,2018-06-12 15:26:34,<java><microservices><vert.x>,2,63,0,0.0,1,"<p>Well, i felt myself really lost with Vertx structure due to everything is a lambda expression. &#xA;i followed <a href=""https://www.devcon5.ch/en/blog/2017/09/15/vertx-modular-router-design/"" rel=""nofollow noreferrer"">this</a> tutorial exactly in order to well structure my application,&#xA;unfortunately it doesn't register any router i have no idea why. pleasefind bellow what i did</p>&#xA;&#xA;<p>serviceEndPoint same with the above tutorial </p>&#xA;&#xA;<pre><code>import io.vertx.core.Vertx;&#xA;import io.vertx.ext.web.Router;&#xA;&#xA;public interface ServiceEndPoint {&#xA;    String mountPoint();&#xA;&#xA;    Router router(Vertx vertx);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and here is the subscriptionService </p>&#xA;&#xA;<pre><code>import com.poc.poc.repositories.SubscriptionRepository;&#xA;import com.poc.poc.services.ServiceEndPoint;&#xA;import io.vertx.core.Vertx;&#xA;import io.vertx.ext.web.Router;&#xA;&#xA;public class SubscriptionService implements ServiceEndPoint {&#xA;    private SubscriptionRepository subscriptionRepository;&#xA;&#xA;    public SubscriptionService() {&#xA;        subscriptionRepository = new SubscriptionRepository();&#xA;&#xA;    }&#xA;&#xA;    @Override&#xA;    public String mountPoint() {&#xA;        return ""/test"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public Router router(Vertx vertx) {&#xA;        Router router = Router.router(vertx);&#xA;        router.get(""/test"").handler(rc -&gt; rc.response().end(subscriptionRepository.getSubscriptionInfo(rc, vertx).toString()));&#xA;        return router;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And finally here is the server vertical </p>&#xA;&#xA;<pre><code>import com.poc.poc.services.ServiceEndPoint;&#xA;import io.vertx.core.AbstractVerticle;&#xA;import io.vertx.core.Future;&#xA;&#xA;import java.util.ServiceLoader;&#xA;import java.util.stream.StreamSupport;&#xA;&#xA;import io.vertx.ext.web.Router;&#xA;&#xA;public class ServerVertical extends AbstractVerticle {&#xA;&#xA;    @Override&#xA;    public void start(final Future&lt;Void&gt; startFuture) throws Exception {&#xA;&#xA;        ServiceLoader&lt;ServiceEndPoint&gt; loader = ServiceLoader.load(ServiceEndPoint.class);&#xA;&#xA;        Router main = StreamSupport.stream(loader.spliterator(), false)&#xA;            .collect(() -&gt; Router.router(vertx), //the main router&#xA;                (r, s) -&gt; r.mountSubRouter(s.mountPoint(), s.router(vertx)),&#xA;                (r1, r2) -&gt; {&#xA;                });&#xA;&#xA;        vertx.createHttpServer().requestHandler(main::accept).listen(8080, res -&gt; {&#xA;            if (res.succeeded()) {&#xA;                startFuture.complete();&#xA;            } else {&#xA;                startFuture.fail(res.cause());&#xA;            }&#xA;        });&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please be noted once i run the application, im getting those warnings</p>&#xA;&#xA;<pre><code>Jun 12, 2018 6:16:45 PM io.vertx.core.impl.BlockedThreadChecker&#xA;WARNING: Thread Thread[vert.x-eventloop-thread-0,5,main] has been blocked for 2486 ms, time limit is 2000&#xA;Jun 12, 2018 6:16:46 PM io.vertx.core.impl.BlockedThreadChecker&#xA;WARNING: Thread Thread[vert.x-eventloop-thread-0,5,main] has been blocked for 3485 ms, time limit is 2000&#xA;</code></pre>&#xA;&#xA;<p>by the way  <code>Router main = StreamSupport.stream(loader.spliterator(), false)</code> size is 0.</p>&#xA;&#xA;<p>any help ?</p>&#xA;"
50734807,How to share mongoose models with multiple microservices,2018-06-07 07:00:10,<node.js><express><mongoose><microservices>,1,70,0,0.0,1,"<p>I've a User model which looks like:</p>&#xA;&#xA;<pre><code>import mongoose from 'mongoose';&#xA;&#xA;const UserSchema = new mongoose.Schema({&#xA;    name: String,&#xA;    email: {&#xA;        type: String,&#xA;        required: true,&#xA;        unique: true,&#xA;    },&#xA;    password: {&#xA;        type: String,&#xA;        required: true,&#xA;    },&#xA;});&#xA;&#xA;export default mongoose.model('User', UserSchema);&#xA;</code></pre>&#xA;&#xA;<p>I'm trying to share this model with multiple microservices, but how do i share this? Should i make a database service exposed over http or should i manually make models in each server and use it that way, or is there any other way to do the same?</p>&#xA;"
50887887,APIs authentication and JWT token validation with KONG,2018-06-16 12:24:49,<api><jwt><microservices><kong><api-gateway>,1,108,0,0.0,1,"<p>I plan to use Kong in our project. I'm currently working on a POC to see how we can integrate it in our platform as the main API gateway. I also want to use the <strong>JWT</strong> plugin for authentication and authorisation. I know that all the API calls should go through the Kong gateway to be authenticated. Then, if the authentication is validated they can go to the API. </p>&#xA;&#xA;<p><strong>Clients  ---> Kong gateway ----> Apis</strong></p>&#xA;&#xA;<p>The part that is not very clear in my mind is how the APIs and Kong fit together. </p>&#xA;&#xA;<ol>&#xA;<li><p>Imagine a scenario where a client try to call directly an API with a token (bypassing the Gateway). How can the API use Kong to validate this token ? </p></li>&#xA;<li><p>How does Kong authenticates the APIs (not the Client) ? In the examples I have seen so far, only the authentication of the clients is documented, not the authentication of the APIs that are ""protected"" by Kong. </p></li>&#xA;</ol>&#xA;"
50779254,How do you determine what should be a microservice?,2018-06-09 23:05:39,<design-patterns><microservices><scalability>,2,51,1,0.0,1,"<p>If I'm building a scalable application that follows the microservice architecture, how do you decide what components of the application should be a service on their own? For example a website like facebook, it can be split into very broad services, newsfeed, messenger, search, etc, or it can be split into smaller services for each of those. What is the correct way to split an application into services to ensure scalability and efficiency? </p>&#xA;"
50856401,Reach Service Fabric from internet,2018-06-14 11:24:25,<azure><microservices><azure-service-fabric>,2,54,1,0.0,1,"<p>Iâ€™m playing with Microsoft Azure Service Fabric, but I'm having some problems reaching the services from internet.</p>&#xA;&#xA;<h1>My situation:</h1>&#xA;&#xA;<ul>&#xA;<li>I Created the Service Fabric cluster:&#xA;&#xA;<ul>&#xA;<li>Windows Server 2016 Datacenter.</li>&#xA;<li>Node type count: 1.</li>&#xA;<li>Custom Endpoint: empty.</li>&#xA;<li>â€œEnable reverse proxyâ€ flagged.</li>&#xA;</ul></li>&#xA;<li>All my services are developed base on .NET Core 2.1, REST API.</li>&#xA;</ul>&#xA;&#xA;<p>Using a web browser, all the services work fine locally (with Service Fabric Local Cluster and Azure Storage Emulator or Azure Storage). Then I published the application to the Azure cluster but I can not reach any of the service from internet.</p>&#xA;&#xA;<h1>Question</h1>&#xA;&#xA;<p>How can I setup the environment so to reach the services from internet?</p>&#xA;&#xA;<p>I read some docs:</p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-connect-and-communicate-with-services"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-connect-and-communicate-with-services</a></li>&#xA;<li><a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reverseproxy"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reverseproxy</a></li>&#xA;</ul>&#xA;&#xA;<p>One of the service in the ServiceMnifest.xml file has the following configuration:</p>&#xA;&#xA;<pre><code>&lt;Endpoint Protocol=""http"" Name=""ServiceEndpoint"" Type=""Input"" Port=""8939"" /&gt;&#xA;</code></pre>&#xA;&#xA;<p>So, I added the following configurations in the load balancer:</p>&#xA;&#xA;<ul>&#xA;<li>Health probes: added a configuration for the 8939 port.</li>&#xA;<li>Load balancing rules: added a configuration for an 8939 => 8939 TCP passthrough using the previous health probes configuration. </li>&#xA;</ul>&#xA;&#xA;<p>But when I try to reach it from browser I get a timeout.</p>&#xA;&#xA;<p>Any suggestion is appreciated.</p>&#xA;&#xA;<p>Regards,</p>&#xA;&#xA;<p>Attilio</p>&#xA;"
50903364,orchestration vs choreography in Micro service architecture,2018-06-18 05:57:41,<domain-driven-design><microservices><orchestration><choregraphe>,1,178,1,0.0,1,"<p>In the Micro service architecture ,  I was reading the concepts the orchestration and choreography. Is any guidelines/suggestions for choosing the  Choreography and Orchestration?</p>&#xA;"
50849415,What is the best way to do microservice REST API versioning?,2018-06-14 04:00:55,<spring><rest><microservices><aws-api-gateway><api-versioning>,1,233,3,0.0,1,"<p>I'm developing this project using Spring and hosting in AWS EC2 instances. As few new requirements coming up, I have to change  my API contracts. But I don't want to break the current clients. So, I'm trying to implement some REST APIs with versioning. So that whenever I update the endpoints the consumer applications won't crash. But I'm confused on how to do the API versioning. I thought of two ways. </p>&#xA;&#xA;<ol>&#xA;<li><p>Create a next version endpoint in the same server,(in spring using RequestMaping(""/v1/api1""),RequestMaping(""/v2/api1"") something like this.)</p></li>&#xA;<li><p>Other wise completely run the v2 APIs in new server instance but keep the same API endpoint footprint and use AWS APIGateway as a proxy and configure the versioning there, then route to old server and new server depending on the version number in the request.</p></li>&#xA;</ol>&#xA;&#xA;<p>But the first approach will lead to lot of code duplication and code management messy I believe. Because we are keeping the same functionality with variations.</p>&#xA;&#xA;<p>In the second approach I have to keep two set of instances for bot versions if me Version increases then It's hard to manage those instances, specially, when I will have around 15 micro-service instances. And it'll not be cost effective also. Because my company is a startup , so I need to consider this fact also.</p>&#xA;&#xA;<p>Is there any best practices regarding API versioning and managing multiple version of endpoints? I'm open for any suggestions and guidelines. If multiple server is the solution also, I'm open to reconsider the cost limitations. I need the best solution for this problem. </p>&#xA;"
50759872,Should I ignore the guidance and avoid putting validation in the command objects?,2018-06-08 11:41:08,<c#><domain-driven-design><microservices>,1,95,12,0.0,1,"<p>I am using CQRS.  Everywhere I read tells me to put validation logic in the command objects.  For example, see this link: <a href=""https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/"" rel=""nofollow noreferrer"">https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/</a></p>&#xA;&#xA;<p>Please see the command below (taken from the link):</p>&#xA;&#xA;<pre><code>public class ChangeNameCommand { &#xA;   [Required] &#xA;   public string FirstName { get; set; } &#xA;   [Required] &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and the Business Object below (also taken from the link - note that I have changed the the parameter passed to the Customer constructor from a class to an interface):</p>&#xA;&#xA;<pre><code>public class Customer &#xA;{ &#xA;   public string FirstName { get; private set; } &#xA;   public string LastName { get; private set; } &#xA;&#xA;   public void ChangeName(IChangeNameCommand command) { &#xA;     FirstName = command.FirstName; &#xA;     LastName = command.LastName; &#xA;   } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>In my case the commands are stored in one class library and the business objects in others (because the commands are shared by multiple microservice type projects).  If I follow the guidance (and put the validation in the commands) then I believe there is nothing to stop a developer doing this:</p>&#xA;&#xA;<pre><code>public class ChangeNameCommandWithoutValidation : IChangeNameCommand { &#xA;   public string FirstName { get; set; } &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and then passing the command (without the validation) to the domain object.  In this case I believe the Domain Object has no control what is passed to it?</p>&#xA;&#xA;<p>Therefore should I be going against all of the guidance I can find and do the validation in the domain object? I believe I should do this because the commands are in a separate class library to the domain objects.  Have I understood this correctly?</p>&#xA;&#xA;<p>I believe this question is also relevant when passing an event to the customer domain object (when using event sourcing).</p>&#xA;"
48571805,"Zeit's ""micro"" never resolves the promise",2018-02-01 21:12:40,<javascript><node.js><promise><microservices>,1,64,0,0.0,1,"<p>I'm scratching my head over little piece of code, that never resolves the <code>promise</code>. It doesn't even tell me that the <code>promise</code> is probably rejected.</p>&#xA;&#xA;<pre><code>const https = require('https'),&#xA;    {&#xA;        json&#xA;    } = require('micro')&#xA;&#xA;module.exports = async () =&gt; {&#xA;    let response = https.get('https://jsonplaceholder.typicode.com/posts/1')&#xA;    const jsonData = await json(response, {&#xA;        encoding: 'utf8'&#xA;    })&#xA;    console.log(jsonData)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Reading the <a href=""https://github.com/zeit/micro#body-parsing"" rel=""nofollow noreferrer"">documentation</a>, the code is correct, it's just I don't understand why doesn't the promise log the response, instead the terminal is just blinking the cursor.</p>&#xA;&#xA;<p>Any kind of help is appreciated.</p>&#xA;"
48460986,Microservices and isolated persistence - how should the data be stored/fetched?,2018-01-26 12:01:03,<microservices>,2,87,0,0.0,1,"<p>At my company, we're about to move to the micro services architecture. I read a lot about it, and there are tons of obscure areas where it's specific to the project built, but one area seems to get everyone to agree, microservices need to have isolated persistence or another way to say it, they need to have they own database.</p>&#xA;&#xA;<p>Now I love the idea, that means every microservice has its own database schema, its own domain objects and is 100% independent of any other microservice data structure.</p>&#xA;&#xA;<p>There are things I don't quite understand though.</p>&#xA;&#xA;<p>The ""Customer Service"" is obviously central to the application, and we can see that basically any other microservice will need some data about the user at some point. Whether it'd be the user's credit amount, its ID, or its name.</p>&#xA;&#xA;<p>But since other microservices can't directly read into the Customer Service database, they'll need to query this service over and over again. This is fine (I guess) for simple stuff like getting the name of current logged user, but when we need to display 60 users on a page and we can't do any SQL join, it feels like we're missing something. This is even worse when microservices depend upon tons of microservices.</p>&#xA;&#xA;<p>So I found out that some people actually queried microservices X times a day to get data into their own microservices.</p>&#xA;&#xA;<p>So if microservice ""Search"" needs data from ""Product"", ""Customer"", it'll actually query these microservices and will persist the data with its own data structure.</p>&#xA;&#xA;<p>The question I have is should it be ""Search"" that queries ""Product"" and ""Customer"", or should ""Product"" and ""Customer"" send data to ""Search"" ?</p>&#xA;&#xA;<p>The first option looks a bit easier to do, we only need to have this logic on one side, and that's where the data is needed. But we'll only get static freshness of data which is not very smart, but could definitely work.&#xA;The second option looks a bit more difficult but more scalable too, because we could have very fresh data when we need it, since the data changed where it's sent, it could also be more granular.</p>&#xA;"
48483491,How to automatically scale up and scale down of micro services instances built using Spring Boot and Spring cloud?,2018-01-28 05:32:23,<spring-boot><microservices><spring-cloud><distributed-system><scalable>,1,215,1,0.0,1,<p>How to automatically scale up and scale down of micro services instances built using Spring Boot and Spring cloud?</p>&#xA;&#xA;<p>I didn't find much info about this on web.</p>&#xA;&#xA;<p>please help in understanding the possible approaches</p>&#xA;
48487098,Saga Choreography implementation problems,2018-01-28 13:54:26,<events><microservices><saga>,1,126,2,0.0,1,"<p>I am designing and developing a microservice platform based on the specifications of <a href=""http://microservices.io/"" rel=""nofollow noreferrer"">http://microservices.io/</a></p>&#xA;&#xA;<p>The entire framework integrates through socket thus removing the overhead of multiple HTTP requests (like most REST APIs).</p>&#xA;&#xA;<p>A service registry host receives the registry of multiple microservice hosts, each microservice is responsible for a domain of the business. Another host we call a router (or API gateway) is responsible for exposing the microservices for consumption by third parties.</p>&#xA;&#xA;<p>We will use the structure of Sagas (in choreography style) to distribute the requisitions, so we have some doubts:</p>&#xA;&#xA;<ul>&#xA;<li>Should a microservice issue the event in any process manager or should it be passed directly to the next microservice responsible for the chain of events? (the same logic applies to rollback)</li>&#xA;<li>Who should know how to build the Saga chain of events? The first microservice that receives a certain work or the router?</li>&#xA;<li>If an event needs to pass a very large volume of data to the next Saga event, how is this done in terms of the request structure? Is it divided into multiple Sagas for example (as a result pagination type)?</li>&#xA;</ul>&#xA;&#xA;<p>I think the main point is that in this router and microservice structure, who is responsible for building the Sagas and propagating their events.</p>&#xA;"
48482639,Node.js REST API wrapper for async messaging,2018-01-28 02:33:09,<node.js><rest><express><asynchronous><microservices>,3,130,3,1.0,1,"<p>Given an event driven micro service architecture with asynchronous messaging, what solutions are there to implementing a 'synchronous' REST API wrapper such that requests to the REST interface wait for a response event to be published before sending a response to the client?</p>&#xA;&#xA;<p>Example: POST /api/articles</p>&#xA;&#xA;<p>Internally this would send a CreateArticleEvent in the services layer, eventually expecting an ArticleCreatedEvent in response containing the ID of the persisted article.</p>&#xA;&#xA;<p>Only then would the REST interface response to the end client with this ID.</p>&#xA;&#xA;<p>Dealing with multiple simultaneous requests - is keeping an in-memory map of inflight requests in the REST api layer keyed by some correlating identifier conceptually a workable approach?</p>&#xA;&#xA;<p>How can we deal with timing out requests after a certain period?</p>&#xA;"
48438747,Jhipster microservices : How to create dynamic instances on microservices in production?,2018-01-25 08:40:53,<java><jhipster><microservices><production-environment>,2,210,5,0.0,1,"<p>I am using JHipster with 3 microservices (microservice1, microservice2, microservice3) applications, 1 JHipster registry application, and the API gateway. All applications are working as needed. I can  run my 5 applications in production without problem in mode one instance by application :</p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One instance</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>I want to have the following instance dynamically or with some automation : </p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One, two or more instances</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>But I wonder how to instance dynamically or manually more instance of microservice2. If I want to create a new instance of service what is the best practices? :&#xA; - In Jhipster configuration are set in application-prod.yml. The port is set are the creation of the application. I just avec one server.  So if I cannot create a new instance on the same server!  There is be a conflict IP/port because the port is configured in the application-prod.yml. How to solve it? I think it's not a good idea to create multiple configuration files with different ports in case I have to run others instances of my microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Is there another way to solve my problem?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading and for your ideas.</p>&#xA;"
37537605,Application B is used by many client so which (Tools) will scale the B?,2016-05-31 05:39:41,<docker><microservices>,1,31,0,1.0,1,"<p>So I have three micro-services (images A,B &amp; C) in docker.<br>&#xA;The only advantage of micro-service is scale it if required, In my case I would like to scale B.</p>&#xA;&#xA;<p>So how to do the scaling (+ or -) of services when we have more demands.</p>&#xA;"
37555434,locating the service registery in a standalone LAN (in service discovery pattern),2016-05-31 20:53:55,<web-services><architecture><microservices><service-discovery><etcd>,1,50,0,1.0,1,"<p><strong>Some background</strong>&#xA;I'm working on a project that involves a standalone LAN network with number of linux PC's and 1 central windows PC. I need to write web services (right now I got some examples work with jersey in java) for both the linux PC's and the central window PC. I'm wishing to publish an API Gateway in the central PC, which will need to know the addresses and ports of the other PC's so he can address their REST services. </p>&#xA;&#xA;<p><strong>The question at hand</strong></p>&#xA;&#xA;<p>My question can be seperated into 2 parts:</p>&#xA;&#xA;<p>1) How will I make service discovery work? The option I know about from my research till now is:&#xA;Using <a href=""https://github.com/coreos/etcd"" rel=""nofollow"">etcd</a>. Seems easy and simple, but I don't see the benefit of it over managing a database in the API Gateway and publishing on it routes for registering and deregistering services.</p>&#xA;&#xA;<p>2) How will the other linux PC's services will know the address of the central windows PC? I read many articles about the service discovery pattern, and failed to find a single one that address the part about how exactly the services know the address of the <strong>service registery</strong>. Lets assume that the address is fixed in the LAN and doesn't change while my system should be working, but I don't know it when deploying (My clients need to deploy it in several different LANs where the address of central station can be different, and I can't trust them to define it in a config before deploying)</p>&#xA;&#xA;<p>Thanks a lot in advance for any assistance :)</p>&#xA;"
37706697,Microservices out of sync,2016-06-08 15:22:35,<ruby-on-rails><microservices>,1,57,0,0.0,1,"<p>Application architecture has three microservices; let's call them A, B, and C.</p>&#xA;&#xA;<p>A is the authority for holding user permissions (including permissions for sending SMS) and when permissions update it publishes an Event for services interested in this data. </p>&#xA;&#xA;<p>B and C listen for permissions changes, to control sending SMS.</p>&#xA;&#xA;<p>Main Rails App is integrating with A, B, C. </p>&#xA;&#xA;<p>App updated A with permissions to prevent student A from receiving any SMS, &#xA;and then A published the event which gets delayed in Queueworker;&#xA;App started to send SMS through B, which is not updated yet because of Queueworker delay.</p>&#xA;&#xA;<p>How can we ensure (or what is need to be changed in design to ensure) users will not receive SMS once permissions changed to false?</p>&#xA;"
37632735,Spring session + Redis + Infinispan caching in session scope fail,2016-06-04 16:50:53,<spring-security><spring-boot><redis><microservices><infinispan>,2,465,0,0.0,1,"<p>I am using Infinispan caching as session scoped bean to cache user related data objects in a Spring MVC application.</p>&#xA;&#xA;<p>Now we migrate to spring boot and we want to use @enableRedisHttpSession&#xA;but we face the problem that the Infinispan CacheManager attached to the session is not Serializable, producing the following exception:</p>&#xA;&#xA;<pre><code>java.lang.IllegalArgumentException: DefaultSerializer requires a Serializable payload but received an object of type [org.infinispan.spring.provider.SpringEmbeddedCacheManagerFactoryBean]&#xA;    org.springframework.core.serializer.DefaultSerializer.serialize(DefaultSerializer.java:43)&#xA;    org.springframework.core.serializer.support.SerializingConverter.convert(SerializingConverter.java:63)&#xA;    org.springframework.core.serializer.support.SerializingConverter.convert(SerializingConverter.java:35)&#xA;    org.springframework.data.redis.serializer.JdkSerializationRedisSerializer.serialize(JdkSerializationRedisSerializer.java:50)&#xA;    org.springframework.data.redis.core.AbstractOperations.rawHashValue(AbstractOperations.java:166)&#xA;    org.springframework.data.redis.core.DefaultHashOperations.putAll(DefaultHashOperations.java:128)&#xA;    org.springframework.data.redis.core.DefaultBoundHashOperations.putAll(DefaultBoundHashOperations.java:85)&#xA;    org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.saveDelta(RedisOperationsSessionRepository.java:409)&#xA;    org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.access$000(RedisOperationsSessionRepository.java:331)&#xA;    org.springframework.session.data.redis.RedisOperationsSessionRepository.save(RedisOperationsSessionRepository.java:211)&#xA;    org.springframework.session.data.redis.RedisOperationsSessionRepository.save(RedisOperationsSessionRepository.java:141)&#xA;    org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.commitSession(SessionRepositoryFilter.java:193)&#xA;    org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.access$100(SessionRepositoryFilter.java:169)&#xA;    org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:127)&#xA;    org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:65)&#xA;    org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121)&#xA;    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)&#xA;    org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103)&#xA;    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)&#xA;</code></pre>&#xA;&#xA;<p>Typically we will balance user requests to multiple nodes so we need to make the cache shared between the nodes (using Redis store).</p>&#xA;&#xA;<p>can any one help.</p>&#xA;"
37699062,API vs Event in Microservice approach,2016-06-08 09:50:34,<soa><cqrs><microservices><event-sourcing><eda>,1,721,0,1.0,1,"<p>What about <a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""nofollow"">Smart endpoints and dumb pipes</a> in terms of different type of requests?</p>&#xA;&#xA;<p>After reading that I was thinking that it's enough to subscribe for some events and deal with that. But now I've realised that sometimes you should have opened API (maybe not for the end customers, but for the API Gateway etc). Is this ok? Or you should ""eventize"" (transform into event) any request which coming to Microservices cloud?</p>&#xA;&#xA;<p>So, for instance, you have Invoice and Order services.&#xA;It's clear that when order created you might use an event which might be consumed by Invoice service to create an invoice. It's clear that for receiving list of last user's orders you may use CQRS on Order service side or even just make new service LastOrders which will keep just projection of required data. But should this request transformed into event or LastOrders should provide API for that and listen for events to update it's own DB? </p>&#xA;"
37727820,Consumer driven contracts,2016-06-09 13:47:28,<microservices><pact>,1,355,1,0.0,1,<p>Is there a way to check consumer contracts in unit tests for micro services?&#xA;I know we can use Pact library in java while doing integration testing via JUnit. But i wonder if there is a way to do the same with unit tests?</p>&#xA;
37693542,How to implement Https on web facing nginx and several microservices behind it,2016-06-08 04:54:18,<ssl><nginx><cross-domain><dropwizard><microservices>,1,187,1,0.0,1,"<p>I'm just starting to develop a SPA, with java(dropwizard) REST backend. I'm kinda new to 'web' development, but I did internal web apps before, so security was not a big concern before.&#xA;Right now I'm using nginx as my public facing web server, and I just discovered whole slew of complications that arise as we're splitting actual servers: static web server serving my SPA's files, and java microservices behind it. </p>&#xA;&#xA;<p>I'm used to apache talking to tomcat with mod_jk, but now I had to implement CORS in dev because my SPA is deployed on a lite-server serving at different port than the REST Api served by dropwizard.</p>&#xA;&#xA;<p>Now I got to my minimum viable product and wanted to deploy it on prod, &#xA;but I have no idea how do I do it. </p>&#xA;&#xA;<ol>&#xA;<li>Do I still need the CORS header? Dropwizard will be run separately on a different port only available to local processes, then I configure nginx to route incoming request from, e.g. /api/ to that port. Does that counts as cross-origin?</li>&#xA;<li>I'd like to serve full https. Dropwizard can serve to https, but I don't want to update SSL cert on multiple microservices. I read about nginx ssl termination, will this enable me to use plain http in local and https on nginx?</li>&#xA;<li>Any other caveats to watch out on deploying with this architecture?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you!</p>&#xA;"
37711051,Example open source microservices applications,2016-06-08 19:16:46,<microservices>,3,729,1,1.0,1,"<p>I'm looking for open source applications that demonstrate the <a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow"">microservices</a> pattern. In particular, I'd like to find one or more applications that can be spun up on real cloud environment up (but with fake data and requests) to demonstrate real-world deployment mechanics.</p>&#xA;&#xA;<p>Unfortunately, I haven't found any good options yet. I'll note that <a href=""https://www.discourse.org/"" rel=""nofollow"">Discourse</a> is a modern 3-tier application, using Rails API, Ember.js, Postgres, and Redis, but it still is much closer to a monolith than an example of microservices. The closest I've found so far is <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">https://github.com/kbastani/spring-cloud-microservice-example</a> but that is more of a framework than an actual application that delivers data.</p>&#xA;"
37679132,Load Balancing in Spring Cloud / Netflix OSS,2016-06-07 12:15:56,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-ribbon>,2,767,1,0.0,1,"<p>I am looking  at Spring Boot / Cloud and Netflix FWs (Eureka, Ribbon). I am working through this example:</p>&#xA;&#xA;<p><a href=""https://spring.io/blog/2015/07/14/microservices-with-spring"" rel=""nofollow"">https://spring.io/blog/2015/07/14/microservices-with-spring</a>&#xA;Basically it is about some small Spring Boot microservices that use the Eureka Service Registry. </p>&#xA;&#xA;<p>I now want to start several instances of the same service (in this example the AccountService, on different ports). Everything I read (above article, <a href=""http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/"" rel=""nofollow"">http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/</a> etc) suggests that if I do this, all instances get registered with Eureka redundantly and when I call the service, client-side load balancing is applied and the service to call is dynamically chosen.</p>&#xA;&#xA;<p>However, this is NOT what happens. When I start the first service instance, it gets registered and shows up in the Eureka Dashboard. When I start the same service on a different port, it also registers, but it seems to REPLACE the previous service instance: The Eureka Dashboard still only shows one instance with Availability Zones = 1 (should be 2?) and ALL calls to this service are handled by the second instance. When I query the registry, only this instance is applied.</p>&#xA;&#xA;<p>When I stop the second instance, after some time Eureka switches back to the first one and it still works. So it seems to keep all instances, but only ever uses the instance that was registered latest.</p>&#xA;&#xA;<p>Do I miss anything important? I thought all instances should be used simultaneously?</p>&#xA;&#xA;<p>==========&#xA;Application Properties are (those are practically unchanged to the example from the Spring Site):</p>&#xA;&#xA;<p><strong>EurekaServer</strong>  </p>&#xA;&#xA;<pre><code>eureka:  &#xA;  instance:  &#xA;    hostname: localhost  &#xA;  client:    &#xA;    registerWithEureka: false  &#xA;    fetchRegistry: false  &#xA;&#xA;server:  &#xA;  port: 1111     &#xA;&#xA;spring:  &#xA;  thymeleaf:  &#xA;    enabled: false  &#xA;</code></pre>&#xA;&#xA;<p><strong>AccountsServer</strong>  </p>&#xA;&#xA;<pre><code>spring:  &#xA;  application:  &#xA;    name: accounts-service  &#xA;  freemarker:  &#xA;    enabled: false           &#xA;  thymeleaf:  &#xA;    cache: false             &#xA;    prefix: classpath:/accounts-server/templates/      &#xA;&#xA;eureka:  &#xA;  client:  &#xA;    serviceUrl:  &#xA;      defaultZone: http://localhost:1111/eureka/  &#xA;&#xA;server:  &#xA;  port: 4444   # HTTP (Tomcat) port, for the second instance this is changed to a different port&#xA;</code></pre>&#xA;"
46615008,Microservices: Service discovery/ circuit breaker for Event-driven architecture,2017-10-06 22:58:45,<spring-boot><microservices><event-driven><event-driven-design><circuit-breaker>,4,274,0,1.0,1,"<p>I'm fairly new to Microservices...</p>&#xA;&#xA;<p>I've taken an interest in learning more about two main patterns like <em><a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">service discovery</a></em> and <em><a href=""https://martinfowler.com/bliki/CircuitBreaker.html"" rel=""nofollow noreferrer"">circuit breaker</a></em> and I have conducted research on how these could be implemented. </p>&#xA;&#xA;<p>As a Java Developer, I'm using Spring Boot. From what I understand, these patterns are useful if microservices communicate via HTTP.</p>&#xA;&#xA;<p>One of the topics I've recently seen is the importance of event-driven architecture, which makes use of an event message bus that services would use to send messages to for other services, which subscribe to the bus&#xA;and process the message.</p>&#xA;&#xA;<p>Given this event-driven nature, how can service-discovery and circuit breakers be achieved/implemented, given that these are commonly applicable for services communicating via HTTP?</p>&#xA;"
46677030,Domain based Microservice Authorization and reusable services,2017-10-10 22:33:44,<api><permissions><authorization><microservices>,1,51,0,0.0,1,"<p>I am running a microservice based server-less architecture and had built this around the principal of a central authorization service that is called by all other microservices. For info Authentication is handled by interceptors before the services are called.</p>&#xA;&#xA;<p>For the sake of this question I have following microservices</p>&#xA;&#xA;<pre><code>/boats&#xA;/cars&#xA;/comments&#xA;/authorization&#xA;</code></pre>&#xA;&#xA;<p>If a user called the the Car service and looked up car 123. The Car Microservice would first call the authorization service to check if the user was allowed to see car 123 and if so, the car microservice would return the car to the user. &#xA;Similarly if the user asked for any comments about car 123, it would call the comments service, which in turn would first call the authorization service to check the users access to car 123 before returning the appropriate comments for that car.</p>&#xA;&#xA;<p>Based on some reading I have been doing (<a href=""https://groups.google.com/forum/#!topic/microservices/n_jL3atxPhQ"" rel=""nofollow noreferrer"">https://groups.google.com/forum/#!topic/microservices/n_jL3atxPhQ</a>) I believe for object level permissions, it may be more useful to embed authorization within the respective api, thus keeping all object &amp; permission information for a domain within that service. </p>&#xA;&#xA;<p>I am not sure what to do when there are reusable microservices providing functionality across all domains e.g. comments, files activities</p>&#xA;&#xA;<h2>Approach 1:</h2>&#xA;&#xA;<p>Boats and Cars services handle their own authorization. The comments service needs to call out to the boat or car service to handle authorization</p>&#xA;&#xA;<pre><code>/boats&#xA;/cars&#xA;/comments&#xA;</code></pre>&#xA;&#xA;<h2>Approach 2:</h2>&#xA;&#xA;<p>Boats and Cars services handle their own authorization, and proxy requests (with appropriate claim headers) to an internal only comments micro-service. Comments then does not need to handle authorization other than to check claims in the header.</p>&#xA;&#xA;<pre><code>/boats/{123}/comments&#xA;/cars/{123}/comments&#xA;</code></pre>&#xA;&#xA;<p>Are these common or even valid approaches? &#xA;If so what is a better pattern to use given a number of other reusable services like comments?</p>&#xA;"
46643268,Microservices master/slave pattern,2017-10-09 09:37:43,<apache-zookeeper><microservices>,1,151,0,0.0,1,"<p>There are scenario where you want to run a cluster of microservices in High-Availability but you would like just one of them to execute a specific operation (consuming from a queue, polling a database)</p>&#xA;&#xA;<p>What are the best practices with relation to this use case? Should one use Zookeeper as a registry, or are there other suitable technologies?</p>&#xA;"
46689798,How to access from one micro service to another via zuul proxy,2017-10-11 13:42:56,<docker><spring-boot><microservices><netflix-eureka><netflix-zuul>,1,165,0,0.0,1,"<p>I'm developing micro services project using spring boot. Here, UI pages are in separate micro service and zuul proxy in separate micro service. I want to access UI page via zuul micro service. I have added my project structure below.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/T57sh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/T57sh.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>UiService Application.properties:</p>&#xA;&#xA;<pre><code>server.port=8090&#xA;spring.mvc.view.prefix: /WEB-INF/views/&#xA;spring.mvc.view.suffix: .jsp&#xA;spring.application.name=ui&#xA;eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/&#xA;eureka.instance.preferIpAddress=true&#xA;eureka.instance.leaseRenewalIntervalInSeconds=5&#xA;</code></pre>&#xA;&#xA;<p>zuulService application.yml:</p>&#xA;&#xA;<pre><code>server:&#xA;port: 8080&#xA;eureka:&#xA; instance:&#xA;  leaseRenewalIntervalInSeconds: 10&#xA;  statusPageUrlPath: /info&#xA;  healthCheckUrlPath: /health    &#xA;&#xA;logging:&#xA; level:&#xA;  ROOT: INFO&#xA;  org.springframework.web: DEBUG&#xA;zuul:&#xA;  routes:&#xA;    ui: &#xA;      url: http://localhost:8090&#xA;ribbon:&#xA;  eager-load:&#xA;    enabled: false&#xA;</code></pre>&#xA;&#xA;<p>My docker compose file:</p>&#xA;&#xA;<pre><code>version: '3'&#xA;services:&#xA;  eureka:&#xA;    build: eurekaService&#xA;    ports:&#xA;      - ""8761:8761""&#xA;  zuul:&#xA;    build: zuulService&#xA;    links:&#xA;     - eureka&#xA;    ports:&#xA;      - ""8080:8080""&#xA;  turbine:&#xA;     build: turbineService&#xA;    links:&#xA;     - eureka&#xA;    ports:&#xA;     - ""8989:8989""&#xA;  ui: &#xA;   build: uiService&#xA;   links:&#xA;     - eureka&#xA;    ports:&#xA;     - ""8090:8090""&#xA;</code></pre>&#xA;&#xA;<p>uiService Structure:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Xr1Tk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Xr1Tk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>My eureka service page:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/yd5of.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yd5of.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>After run this project in docker(docker-compose up -d), When I'm trying to access the login screen(Which is available inside uiService) getting following exception. How to solve this?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/fFGq8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fFGq8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>UIService Main Method:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;@EnableCircuitBreaker&#xA;public class UIApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(UIApplication.class, args);&#xA;     }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>uiService pom.xml:</p>&#xA;&#xA;<pre><code> &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;        &lt;parent&gt;&#xA;            &lt;groupId&gt;com.scm&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;demo&lt;/artifactId&gt;&#xA;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;        &lt;/parent&gt;&#xA;        &lt;artifactId&gt;uiService&lt;/artifactId&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;            &lt;/dependency&gt;&#xA;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&#xA;            &lt;/dependency&gt;&#xA;&#xA;           &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&#xA;           &lt;/dependency&gt;&#xA;&#xA;           &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-starter-data-rest&lt;/artifactId&gt;&#xA;           &lt;/dependency&gt;&#xA;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;            &lt;/dependency&gt;&#xA;&#xA;             &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;                &lt;scope&gt;test&lt;/scope&gt;&#xA;             &lt;/dependency&gt;&#xA;             &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&#xA;                &lt;scope&gt;provided&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;&#xA;            &lt;/dependencies&gt;&#xA;        &lt;/project&gt;&#xA;</code></pre>&#xA;"
46668418,Microservice return response first and then process the request,2017-10-10 13:46:12,<spring-boot><java-8><microservices>,2,582,5,1.0,1,<p>I am working on a solution for which i am trying to create a microservice which returns response immediately and then processes the request.</p>&#xA;&#xA;<p>I am trying to use Java 8 and Spring for this.</p>&#xA;
47917777,Is putting a ElastiCache behind a microservice worth it in the following scenario?,2017-12-21 04:04:46,<amazon-web-services><microservices><amazon-elasticache>,1,38,0,1.0,1,"<p>I have a bunch of EC2 processing an object (let's assume the objects are unique URLs of images that needs to be downloaded from the web). I have 3 Elasticache dbs: all three dbs track different thing about images. I need to consult the 3 databases before deciding whether to process the image or discard it.</p>&#xA;&#xA;<p>I need to decide whether each EC2 instance should consult with the 3 dbs on their own, or whether I should encapsulate the 3 dbs behind a microservice such that each EC2 does not communicate directly with dbs. </p>&#xA;&#xA;<p>Having a microservice and using API to communicate obviously adds processing time overhead but generally while scaling it is worth it. But ElastiCache is a fast in-memory db service, and I cannot decide whether the overhead is worth it. What should I do? Or, what should I look into before deciding?</p>&#xA;"
47766808,Response Encoding in spring boot micro services for Front-end angular application,2017-12-12 06:51:42,<spring-boot><http-status-code-404><microservices>,1,123,0,0.0,1,"<p>I am creating my web application using microservices architecture. Here front-end application , angular 2 will communicate with back end microservices developing using spring MVC , spring boot and spring Data JPA.</p>&#xA;&#xA;<ul>&#xA;<li>Here my confusion is that , I added methods in my repository, like findbyusername, findbylastname etc. And here I need to give back this results with HTTP status codes. Means 200 Ok, 400 Bad request , 401 Unauthorized etc. How I can encode these status code with my results?. When I returning findbyusername result, I need to add 200 ok with that result.</li>&#xA;<li>Also I need to transfer the result as JSON format,since angular is parsing data as JSON format.</li>&#xA;</ul>&#xA;&#xA;<p>Here My sample controller action only like this,</p>&#xA;&#xA;<pre><code>@CrossOrigin(origins = ""http://localhost:4200"")&#xA;@RequestMapping(value = ""/checkAuthentication"", method = RequestMethod.POST)&#xA;public String checkLoginByName(@RequestBody Users user) throws Exception{&#xA;&#xA;    ObjectMapper mapper = new ObjectMapper();&#xA;    Users useObj1 = userRepo.findByUsernameAndPassword(user.username,user.password);&#xA;    return(mapper.writeValueAsString(useObj1));&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Here I need to add status also.Can anyone help me to clarify this status adding problem?</p>&#xA;"
47889886,"In microservices, does it make sense to have separate code repositories for database migration scripts and API code?",2017-12-19 15:09:11,<github><database-design><relational-database><microservices><continuous-delivery>,1,226,0,0.0,1,"<p>In accordance with <a href=""https://martinfowler.com/bliki/BoundedContext.html"" rel=""nofollow noreferrer"">bounded context</a>, we have identified two microservices implementations, lets call them <code>Service A</code> and <code>Service B</code> respectively. Each of these microservices have different repositories (due to the benefits of Single Responsibility and better ownership). Now, each of these repositories use their own database schema (choice made for better separation of persistence and reduced maintenance of DB instances).</p>&#xA;&#xA;<p>Earlier, we extracted the database migrations scripts (for continuous delivery) into a separate single repository (contains scripts for both <code>Service A</code> and <code>Service B</code> 's schemas) and run them under a single job under CI. Now as we tackle more stories, we have started facing some challenges, some of which are listed below:</p>&#xA;&#xA;<ul>&#xA;<li>A change to a single schema triggers the build for the whole database and hence the downstream triggering of all the microservices, hence increasing our feedback time</li>&#xA;<li>We are in general failing to achieve <code>true</code> continuous delivery, because a schema change also requires a respective change in the <code>Service</code> code and hence cautious efforts are taken to deploy both the <a href=""https://help.github.com/articles/about-pull-requests/"" rel=""nofollow noreferrer"">PRs</a></li>&#xA;<li>Moreover, there are some common tables like <code>Users</code> which needs to be used by both the schemas, which currently are being duplicated across both the schemas.</li>&#xA;</ul>&#xA;&#xA;<p>So my question/doubt is :</p>&#xA;&#xA;<ul>&#xA;<li>Should we even separate the DB migrations repository according to the schemas, just like the Services.</li>&#xA;<li>Should we even have separate repository for DB migrations scripts ? Should we club them within their respective <code>Service</code> repository code ?</li>&#xA;<li>Should we extract the common tables further <code>a level up</code> and raise <code>Domain Events</code> for <a href=""https://en.wikipedia.org/wiki/Eventual_consistency"" rel=""nofollow noreferrer""><code>Eventual Consistency</code></a></li>&#xA;</ul>&#xA;&#xA;<p>Any pointers/advice would greatly help.Thanks.</p>&#xA;"
47860278,Best practice to share domain model between two microservices,2017-12-17 22:59:00,<microservices>,1,376,3,0.0,1,"<p>Are there any best practices or guidelines on how to share the domain model between two micro-services?</p>&#xA;&#xA;<p>I have a micro-service (1) which provides end points to interact with a resource (e.g, Order) all CRUD and the other micro-service (2) which performs a specific non CRUD task on the resource (Order). The micro-service (2) almost needs all the order attributes to perform its operation. In this case, does it make sense to create a common shared lib of the domain model and share between the two services? I could technically combine 1 and 2 together but the micro-service (2) needs to support scalability as it is quite memory and CPU intensive.</p>&#xA;"
47456945,Microservice consuming Kafka events through Zuul,2017-11-23 13:41:45,<apache-kafka><microservices><netflix-zuul>,1,169,0,0.0,1,"<p>I am new to Microservices architecture.&#xA;I want to create a microservice using Netflix OSS.&#xA;I want my architecture to look some thing like the one described here.</p>&#xA;&#xA;<p><a href=""http://callistaenterprise.se/blogg/teknik/2017/09/13/building-microservices-part-8-logging-with-ELK/"" rel=""nofollow noreferrer"">http://callistaenterprise.se/blogg/teknik/2017/09/13/building-microservices-part-8-logging-with-ELK/</a></p>&#xA;&#xA;<p>However I want one of my microservice, (which is behind the Zuul Reverse proxy) to consume events from a Kafka events(which is from some other team).&#xA;I am not sure If this is a good idea, since this will expose my microservices, which is supposed to be abstracted from outside world behind my Zuul wall.</p>&#xA;&#xA;<p>Is there any other way. Can I use my Zuul to consume event streams from kafka and push to my microservice. If yes, how do I stream from my Zuul to microservice?</p>&#xA;"
47366889,Sync Google Cloud Datastore with ElasticSearch,2017-11-18 13:57:40,<elasticsearch><google-cloud-datastore><microservices>,1,217,0,0.0,1,"<p>I have Google Cloud Datastore as Single Point of Truth and I want to index data from it in dedicated service for reading, filtering a searching. For this purpose I am creating an ElasticSearch-based service.</p>&#xA;&#xA;<p>And I am wondering if there is some simple way/library to keep ES synced with the Datastore or if I simply have to write a bridge and handle it on my own?</p>&#xA;&#xA;<p>I will be using events so I only need a way of fetching the data from DS to ES. I will handle the deleting, creating and updating specific records via events but I want to avoid doing the complete syncing(when service instance comes up) on my own.</p>&#xA;"
47343439,microservice not able to locate zipkin service using discovery-server,2017-11-17 04:44:23,<spring-boot><microservices><spring-cloud><zipkin><eureka>,1,770,2,0.0,1,"<p>I have mircroservice environment based on spring-boot, where i am using zipkin server and discovery-server(eureka) and config-server. Now i have a rest-microservice which sends logs to zipkin server and this microservice is required to resolve where is zipkin server using discovery-server.</p>&#xA;&#xA;<p>following is zipkin configuration i have in my rest-microservice's application.properties(pulled from config-server).</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://MTD-ZIPKIN-SERVER/&#xA;spring.zipkin.locator.discovery.enabled=true&#xA;spring.zipkin.enabled=true&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>here MTD-ZIPKIN-SERVER is zipkin-server name in discovery-server.</p>&#xA;&#xA;<p>discovery-server dashboard.&#xA;<a href=""https://i.stack.imgur.com/SNliR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SNliR.png"" alt=""enter image description here""></a>&#xA;but it does not try to resolve zipkin from discovery-server, instead it tries to connect directly using spring.zipkin.baseUrl, and i get below exception.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Dropped 1 spans due to ResourceAccessException(I/O error on POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER)</p>&#xA;  &#xA;  <p>org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER     at&#xA;  org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:666)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.execute(RestTemplate.java:628)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:590)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.post(RestTemplateSender.java:73)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.sendSpans(RestTemplateSender.java:46)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$BoundedAsyncReporter.flush(AsyncReporter.java:245)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$Builder.lambda$build$0(AsyncReporter.java:166)&#xA;    at zipkin.reporter.AsyncReporter$Builder$$Lambda$1.run(Unknown&#xA;  Source)   at java.lang.Thread.run(Thread.java:745) Caused by:&#xA;  java.net.UnknownHostException: MTD-ZIPKIN-SERVER  at&#xA;  java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)&#xA;    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</p>&#xA;</blockquote>&#xA;&#xA;<p>if i provide exact zipkin url in property spring.zipkin.baseUrl like below</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://localhost:5555/&#xA;</code></pre>&#xA;&#xA;<p>then my rest-microservice is able to connect to zipkin-server.</p>&#xA;&#xA;<p>My goal here is to read zipkin-server location from discovery-srever. What am i doing wrong? Do i need to add some zipkin enabling annotation on my spring-boot rest-microservice?</p>&#xA;"
45215621,Grpc microservice architecture implementation,2017-07-20 13:05:10,<node.js><architecture><protocol-buffers><microservices><grpc>,1,285,0,0.0,1,"<p>In a microservice architecture, is it advisable to have a centralized collection of proto files and have them as dependency for clients and servers? or have only 1 proto file per client and server?</p>&#xA;"
45270983,How volumes are shared across Docker Swarm nodes?,2017-07-24 00:01:28,<docker><docker-compose><microservices><docker-swarm>,1,425,0,0.0,1,"<p>So I'm starting to play with docker and docker swarm, and now I wonder how volumes are shared across docker swarm nodes.</p>&#xA;&#xA;<p>Lets pick a Postgres database for instance, and I have a volume declared for the data:</p>&#xA;&#xA;<p>docker-compose.yml:</p>&#xA;&#xA;<pre><code>...&#xA;  db:&#xA;    image: postgres:9.4-alpine&#xA;    volumes:&#xA;      - db-data:/var/lib/postgresql/data&#xA;    deploy:&#xA;      placement:&#xA;        constraints: [node.role == manager]&#xA; ...&#xA;</code></pre>&#xA;&#xA;<p>What If I have managers that are very far away, in different regions of the world, and occurs that they need to share data between them?</p>&#xA;&#xA;<p>How does Docker operate on that?</p>&#xA;"
45301310,JMS/REST clients as a centralized library vs one per microservice?,2017-07-25 10:59:09,<java><jms><microservices>,1,216,0,1.0,1,<p>Why does the microservices architecture mindset see benefit in duplicating all REST/JMS clients so each service has its independent code? </p>&#xA;&#xA;<p>Does the trade-off really work out - given the comfortability and maintainability of a single library/adapter towards a server-spec so everybody uses it as an abstraction?</p>&#xA;&#xA;<p>What are the the benefits in practice?</p>&#xA;
45236389,"Apache Kafka consumer groups and microservices running on Kubernetes, are they compatible?",2017-07-21 11:22:41,<apache-kafka><kubernetes><openshift><microservices><spring-cloud-stream>,2,248,0,0.0,1,"<p>So far, I have been using Spring Boot apps (with Spring Cloud Stream) and Kafka running without any supporting infrastructure (PaaS).</p>&#xA;&#xA;<p>Since our corporate platform is running on Kubernetes we need to move those Spring Boot apps into K8s to allow the apps to scale and so on. Obviously there will be more than one instance of every application so we will define a consumer group per application to ensure the unique delivery and processing of every message.</p>&#xA;&#xA;<p><strong>Kafka will be running outside Kubernetes.</strong></p>&#xA;&#xA;<p>Now my doubt is: since the apps deployed on k8s are accessed through the k8s service that abstracts the underlying pods, and individual application pods can't be access directly outside of the k8s cluster, Kafka won't know how to call individual instances of the consumer group to deliver the messages, will it? </p>&#xA;&#xA;<p>How can I make them work together?</p>&#xA;"
45311236,How can microservice can talk to other microservice in JHipster,2017-07-25 18:41:32,<jhipster><microservices>,2,529,2,0.0,1,<p>I am planning to create a microservice aplication with a dedicated service for dealing with data (mostly a Mongodb based service). I am wondering if there is a way using which my other microservices will be able to communicate with this service to make use of the shared data. Is it possible with JHipster API Gateway ?&#xA;If not how can I achieve this. I dont want to keep multiple copies of the same data within each microservice.</p>&#xA;
45302887,Alternative to synchronous REST communication betweeen microservices,2017-07-25 12:10:16,<architecture><microservices><api-design>,1,73,2,1.0,1,"<p>I know synchronous communication between services is an anti-pattern, so I'm searching for a good solution for my use-case.</p>&#xA;&#xA;<p>I have this two services:</p>&#xA;&#xA;<ul>&#xA;<li><code>Location Service</code> that manages users location</li>&#xA;<li><code>Score Service</code> that manages users score</li>&#xA;</ul>&#xA;&#xA;<p>Now, I have to build another service: <code>Users Feed Service</code> (UFS). It has to return users near to a given location, ordered by score (descending).</p>&#xA;&#xA;<p><strong>Synchronous solution</strong></p>&#xA;&#xA;<ol>&#xA;<li>Given a location, UFS fetch nearby users from the location service (REST)</li>&#xA;<li>For each one of them, it gets her score from the Score Service (REST) </li>&#xA;<li>Finally, it sorts the users in memory and return them</li>&#xA;</ol>&#xA;&#xA;<p>What is the alternative? I have been thinking about something like this:</p>&#xA;&#xA;<p><strong>Event queue solution</strong></p>&#xA;&#xA;<ul>&#xA;<li>UFS stores users locations and scores in a database, or memory cache or something</li>&#xA;<li>It listens to changes in a queue to update its data when the score service and location service publish in it</li>&#xA;</ul>&#xA;&#xA;<p>This way, when client request the users feed, the users feed service don't have to perform any network request (it owns the necessary data)</p>&#xA;&#xA;<p>Is this a good solution? How can I improve it? Will it scale in a large amount of users?</p>&#xA;"
45212459,Is it a good practice to share constants/enums between microservices,2017-07-20 10:43:41,<microservices>,1,421,2,1.0,1,"<p>In my application there are 9 micro-services, lets say two of them uses an enum for a operation. Is it a good practice to place the enum in common place and add commons jar as a dependency to both the microservices ?</p>&#xA;"
45321939,Host a service with 2 endpoints in the same or separate processes?,2017-07-26 08:50:29,<web-services><iis><asp.net-web-api><nservicebus><microservices>,2,123,3,0.0,1,"<p>I'm building a microservice with both a synchronous REST endpoint (using WebAPI) and an asynchronous publish/subscribe endpoint (using NServiceBus on top of MSMQ) that will be processing data that is stored in a database shared by these endpoints.</p>&#xA;&#xA;<p>I'm trying to decide if I should host both endpoints in the same process, or if I should simply host them in separate processes and have them use the database as common ground to pass data between these processes. My gut feeling says the same process would be 'better', although it would also be more complex:</p>&#xA;&#xA;<ol>&#xA;<li><p>Hosting the endpoints in separate processes is simple: Host the WebAPI endpoint in IIS and host the NServiceBus endpoint as a Windows Service.</p></li>&#xA;<li><p>When hosting them in the same process, it's possible to self-host the NServiceBus endpoint in the WebAPI code but this is not recommended as IIS will shut down the worker process after a period of inactivity,&#xA;thereby also killing the NServiceBus part of the service and leaving it unable to handle incoming messages.<br>&#xA;So I figured I would have to host both the NServiceBus and the WebAPI endpoints in a Windows service, which appears to be possible when <a href=""https://docs.microsoft.com/en-us/aspnet/web-api/overview/hosting-aspnet-web-api/use-owin-to-self-host-web-api"" rel=""nofollow noreferrer"">using OWIN to self-host the WebAPI endpoint</a>.</p></li>&#xA;</ol>&#xA;&#xA;<p>Does anyone have experience with hosting a service with 2 endpoints in the same or different processes, and can tell me the problems/benefits associated with this choice?</p>&#xA;&#xA;<p><em>(<a href=""https://stackoverflow.com/questions/21202411/host-web-api-in-self-hosted-nservicebus"">This question</a> seemed to ask the same, but it never got a satisfactory answer)</em></p>&#xA;&#xA;<p><strong>Edit</strong> In response to @HadiEskandari, I'm not looking for a WebAPI facade for an NServiceBus endpoint. I'm planning to have the WebAPI endpoint to handle simple queries for information which it stores in the database that is shared between these endpoints.&#xA;Thse REST calls will be invoked AJAX-style from a web application, so I need this to execute quickly - forwarding each REST call through an MSMQ queue &#xA;to the NServiceBus endpoint and waiting for a response seems slow and wasteful in this case.</p>&#xA;&#xA;<p>Rather, I'm looking for a way to keep the data access code and business logic not just in the same assembly, but also in the same AppDomain so that both endpoints may share say, the same configuration or cached data.</p>&#xA;"
45300410,Django - How to implement authentication service in microservices architecture,2017-07-25 10:19:57,<django><jwt><microservices>,1,481,3,0.0,1,"<p>Basically, I have several independent services. I want to build a service for authentication. When client get a token from authentication service. Client use it for further request to others services. Client need to attach that token in header of request. The services receiving token need to verify the token by sending it to authentication server. So all requests that clients make to protected routes need to be verified by authentication service. The thing is I do not know the best place to put the code that automatically sends token to authentication service and receive the result. &#xA;Here is what i tried so far:&#xA;I implemented a middleware like that:</p>&#xA;&#xA;<pre><code>class VerifyTokenMiddleware(object):&#xA;&#xA;def process_request(self, request):&#xA;    if not request.META.get('HTTP_AUTHORIZATION'):&#xA;        return HttpResponse(status=404)&#xA;    auth_header = request.META.get('HTTP_AUTHORIZATION')&#xA;    token = auth_header[4:]&#xA;    response = requests.post(AUTH_URL, {""token"": token})&#xA;    if response.status_code == 400:&#xA;        return HttpResponse(status=403)&#xA;    return None&#xA;</code></pre>&#xA;&#xA;<p>However, the problem of my solution is every requests to services(not auth service) have to pass through that middleware. Therefore, client cannot access unprotected routes like before. &#xA;Any help is extremely appreciated. :D</p>&#xA;&#xA;<p>I used django restframework jwt <a href=""https://github.com/GetBlimp/django-rest-framework-jwt"" rel=""nofollow noreferrer"">https://github.com/GetBlimp/django-rest-framework-jwt</a>. </p>&#xA;"
45293123,How to design a multi-file processor using Golang?,2017-07-25 02:53:46,<go><design><microservices>,1,53,4,0.0,1,"<p>I'm trying to figure out how to design a service that can handle multiples files format, using micro-services for example:</p>&#xA;&#xA;<p>I have a customer using a file format A, another using format B and other using format C.</p>&#xA;&#xA;<p>After processing a specific format for each customer, I need to transform this format into an common format, and insert into database.</p>&#xA;&#xA;<p>The first thing I tried is to design one service per customer but all of them need to know the base format and if an update is needed in this base format, I need to update all of there services.</p>&#xA;&#xA;<p>I'm trying to decouple the service processor and have a single place to translate to base format.</p>&#xA;&#xA;<p>If my customer services know about the base format, if this format changes,  I need to update all of them. If I have a service that translate the format, this service needs to know all customer formats.</p>&#xA;&#xA;<p>How to design this solution?</p>&#xA;"
45168622,How to share constans between Rails microservices?,2017-07-18 13:45:07,<ruby-on-rails><ruby><microservices>,2,88,4,0.0,1,"<p>I have my main app and admin app built as a microservice, they are communicating via api. I want to share some constants between those two apps.</p>&#xA;&#xA;<p>For example I have User model that can have role Owner or Regular. In admin app I can search Users and in this search I have dropdown with hardcoded user type (Owner, Regular). This is okay, but when I change naming (e.g. Regular -> Standard) I have to update my Admin app also.</p>&#xA;&#xA;<p>To avoid changing admin app every time I change some core naming in my main app I want to somehow share those constants, so every change in main app will change Admin at the same time.</p>&#xA;&#xA;<p>For now I found 2 solutions, both with pros and cons:</p>&#xA;&#xA;<p>First is sending constants from main app to admin via json api. I have build a class that will fetch and store all constants in class variable, so it's available from every part of the the app. The good thing about this solution is performance (thanks to memoization it's only one api request) and it's easy to use later. The bad thing is I have no idea how to handle tests in this case. Of course I cannot let my tests make request to main app and stubbing this request makes the whole idea pointless, because after every change of constants in main app I will need to change tests in admin app. </p>&#xA;&#xA;<p>Second approach I thought of is building a gem that will store all constants. It's very easy to implement, but this means I will need to make changes to this repo every time I want to change constants in main app. Also I work with big team and they won't be happy that they have to work on 2 repos at the same time.</p>&#xA;&#xA;<p>What do you think about those solutions? First one seems to be perfect for me except tests, so maybe you have some ideas how to stub those constants without real values? I haven't tried gem solution yet so if you see some obstacles please let me know.&#xA;Maybe there is another better solution to this problem?</p>&#xA;"
45275679,Sharing code in Microservices,2017-07-24 08:28:19,<java-ee><architecture><jax-rs><microservices>,1,301,8,0.0,1,"<p>We have two services. However, in the past, these two services were one service, but have been split due to differing traffic requirements.</p>&#xA;&#xA;<p>The services are consumed by two kinds of clients; other services and UI clients (web, desktop and mobile).</p>&#xA;&#xA;<p>Consumers of service 1: Services, </p>&#xA;&#xA;<ol>&#xA;<li>Use a very limited number of exposed endpoints (<code>addInput</code>, <code>removeInput</code>).</li>&#xA;<li>Generates high traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Consumers of service 2: UI clients,</p>&#xA;&#xA;<ol>&#xA;<li>Using a large number of exposed endpoints</li>&#xA;<li>Generating less traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Currently, they are sharing code but as far as I can figure out micro-services should not share base code. Therefore we believe something is wrong using this approach.</p>&#xA;&#xA;<p>what are the key issues to understand in order to solve this kind of micro-services architecture issues?</p>&#xA;"
40447582,API Gateway handling Webservices in a Microservice Architecture,2016-11-06 08:58:30,<web-services><rest><architecture><microservices>,2,257,0,2.0,1,"<p>I have an architectural question. We are transforming an old Monolith to a Microservice Architecture. Therefore we have in plan to identify the bounded contexts and make Microservices out of these. </p>&#xA;&#xA;<p>To keep up with our public API we will have an API Gateway which routes the stuff properly. The internal communication will be done via REST (at the first shot). Unfortunatelly our existing public API is about WebServices most of the time.</p>&#xA;&#xA;<p>If we do transformation from Webservices to REST communication we already need to know stuff of the Domain Objects. Isn't that already a violation of the Microservice Design. In the end that means adding a field in the Microservice A implies also touching the API Gateway. Which I do not like.</p>&#xA;&#xA;<p>Am I wrong here? What is your opinion on this?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/9ZGGo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9ZGGo.png"" alt=""enter image description here""></a></p>&#xA;"
40446036,API design - splitting into different sub-domains (micro-services),2016-11-06 04:38:37,<node.js><api><docker><kubernetes><microservices>,1,381,0,1.0,1,<p>Our application is based on an API first architecture and is currently based on a single domain / service:</p>&#xA;&#xA;<p><code>api.todos.com</code></p>&#xA;&#xA;<p>Consumers of the API are :</p>&#xA;&#xA;<ul>&#xA;<li>Our web-frontend</li>&#xA;<li>Our mobile-apps</li>&#xA;<li>Other business / public</li>&#xA;</ul>&#xA;&#xA;<p>We will be building new <em>micro-services</em> written in different languages for the same application. For example we might develop API services for:</p>&#xA;&#xA;<ul>&#xA;<li>Statistics</li>&#xA;<li>Blog / Content</li>&#xA;<li>RSS Feed</li>&#xA;<li>Search</li>&#xA;</ul>&#xA;&#xA;<p>My question is around dealing with domains. Would it be best to split each service into a different subdomain e.g.</p>&#xA;&#xA;<ul>&#xA;<li><code>api.todos.com</code></li>&#xA;<li><code>stats.todos.com</code></li>&#xA;<li><code>content.todos.com</code></li>&#xA;<li><code>rss.todos.com</code></li>&#xA;<li><code>search.todos.com</code></li>&#xA;</ul>&#xA;&#xA;<p>Or is it better to have a single unified API domain where we do HTTP (layer 7) routing to reach our endpoints. e.g.</p>&#xA;&#xA;<ul>&#xA;<li><code>api.todos.com/todos</code></li>&#xA;<li><code>api.todos.com/stats</code></li>&#xA;<li><code>api.todos.com/content</code></li>&#xA;<li><code>api.todos.com/rss</code></li>&#xA;<li><code>api.todos.com/search</code></li>&#xA;</ul>&#xA;&#xA;<p>Not sure which is preferable for a public API? It would be easier to have multiple sub-domains and not have to deal with an intermediate routing layer / proxy.</p>&#xA;
40479926,Mapping entity having dependency with two different schema's on microservice architecture,2016-11-08 05:54:39,<c#><nhibernate><fluent-nhibernate><microservices>,1,94,1,0.0,1,"<p>Based on Microservice architecture I have separated the two schemes into two different db's see below,</p>&#xA;&#xA;<ul>&#xA;<li>(VS2015 Solution1, BusinessEntity project) db1 -> schema1 -> customer, supplier</li>&#xA;<li>(VS2015 Solution2, BusinessEntity project) db2 -> schema2 -> product, order, orderdetails</li>&#xA;</ul>&#xA;&#xA;<p><strong>C#</strong>&#xA;Now I am having the issue when creating the mapping entity how and where should I create the mapping entity.</p>&#xA;&#xA;<blockquote>&#xA;  <p>I am using ""PostgreSQL"" as my DB and ""Fluent nHibernate""</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>public class CustomerOrderMap&#xA;{&#xA;[DatabaseGenerated(DatabaseGeneratedOption.Identity)]&#xA;// (pkey property)&#xA;public virtual int Id  { get; set; } &#xA;&#xA;// (fk property, this is in db1, schema1)&#xA;public virtual int CustomerId     { get; set; } &#xA;public virtual Customer Customer  { get; set; }&#xA;&#xA;// (fk property, this is in db2, schema2)&#xA;public virtual int OrderId    { get; set; }&#xA;public virtual Order Order    { get; set; }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ol>&#xA;<li>Where should I have this entity?</li>&#xA;<li>Since I am following Microservice architecture I am having the ""Order"" entity separately in schema2. Hence how can I have that entity type in the mapping entity if I am going to have the mapping entity in schema1 or am I missing something in architecture wise?</li>&#xA;</ol>&#xA;&#xA;<p><em>any examples would be appreciated!!</em></p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
40542220,Exposing services deployed on Service Fabric Cluster (with traffic distribution handled by an Internal Load Balancer),2016-11-11 06:18:48,<.net><azure><microservices><azure-service-fabric>,1,209,1,0.0,1,"<p>I have a Secure Service Fabric Cluster (I'm using self signed certificates for the moment) with a Internal Load Balancer deployed on azure which has all the rules and probes configured. Right now I do not have an internet facing load balancer or an equivalent resource that has a public IP which means I cannot access it from anywhere outside my VNet.</p>&#xA;&#xA;<p>I need to expose the services deployed in my cluster without exposing the Service Fabric management URL (like westus.cloudapp.azure.com:19080).</p>&#xA;&#xA;<p>From what I have found, my options are:</p>&#xA;&#xA;<ol>&#xA;<li>To use a Public Load Balancer</li>&#xA;<li>To configure my VPN Gateway</li>&#xA;<li>To use an Application Gateway</li>&#xA;</ol>&#xA;&#xA;<p>Option 1 would mean that I would have to replace my existing internal load balancer with an internet facing one (if that is possible) but that exposes my management url as well. Or I would have to go with a multi-tier app with a web tier and back end - <a href=""https://azure.microsoft.com/en-in/documentation/articles/load-balancer-internal-overview/"" rel=""nofollow noreferrer"">https://azure.microsoft.com/en-in/documentation/articles/load-balancer-internal-overview/</a> </p>&#xA;&#xA;<p>Option 2 would require me to configure access to my private IPs through the VPN gateway which I do not have access to.</p>&#xA;&#xA;<p>Option 3 again seems to undermine the existing internal load balancer </p>&#xA;&#xA;<p>Is there any way to custom-route my requests to the services using something that can be built on top of my existing architecture? </p>&#xA;"
40413453,Aggregated Notification Microservice,2016-11-04 00:26:00,<microservices>,1,728,1,0.0,1,"<p><strong>The Problem</strong></p>&#xA;&#xA;<p>We are currently architecting our new Notification Microservice but having trouble with how to handle aggregated emails. What we need to do is instead of sending one email every action performed (could be 20+ in a few minutes), we would send an email after an hour summarising all the actions that were completed.</p>&#xA;&#xA;<p><strong>What We Have So Far</strong></p>&#xA;&#xA;<p>We so far propose that we have this type of messaging pattern, where Client Service is any service in our cluster and Messagebot is our Notification Microservice.</p>&#xA;&#xA;<ol>&#xA;<li>Client Service sends a notification to Messagebot that it will need to send something in the future</li>&#xA;<li>Messagebot stores the details in its database</li>&#xA;<li>Messagebot periodically checks its database for what needs to be sent</li>&#xA;<li>Messagebot gets the required data from another service (could be Client Service) via API</li>&#xA;<li>Messagebot sends email using the data from #3 and an HTML template</li>&#xA;</ol>&#xA;&#xA;<p><strong>The Debate</strong></p>&#xA;&#xA;<p>For the data that needs to be sent, we are less sure and it is what we need help with. So far we think this should be the structure of the JSON from Client Service to Notification Service (step #1):</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    objectid: SOME_OBJECT_ID&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>or</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    required_objects: { task_id: SOME_TASK_ID, document_id: SOME_DOCUMENT_ID }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Where task_id and document_id are just examples and it would change based on the template. It could just as easily be <code>{product_id: SOME_PRODUCT_ID}</code> for a different template.</p>&#xA;&#xA;<p><strong>Why The Debate</strong></p>&#xA;&#xA;<p>Our thoughts so far are that:</p>&#xA;&#xA;<ol>&#xA;<li>We only need template_id because the source of the data would be implied in the objects (like an ENV var). For example, the Task object would be at <a href=""http://taskservice/:id"" rel=""nofollow noreferrer"">http://taskservice/:id</a>. Otherwise, we can have problems with failing APIs or switching URLs in the future.</li>&#xA;<li>We should use userid instead of email and name because we prevent the issue of email/ name pairs not matching up over multiple messages</li>&#xA;<li>For the objects, we're still sceptical because it means that the client app service would need knowledge of the inner workings in Messagebot but a single objectid might not be very extensible. We could easily imagine many of our messages needing more than one object.</li>&#xA;</ol>&#xA;&#xA;<p><strong>In Conclusion</strong></p>&#xA;&#xA;<p>Thank you for reading. The design of this service is important because it will be central to our entire organisation. </p>&#xA;&#xA;<p>Which debated JSON structure is most appropriate in our situation? Also, knowing our requirements, what would be the proper setup for this type of service? (aka. Are we correct in our other assumptions?)</p>&#xA;"
43542042,Forwarding docker GELF logs to Logstash with Filebeat (or alternative?),2017-04-21 11:52:07,<logging><docker><microservices><elastic-stack><filebeat>,1,317,0,0.0,1,"<p>Gelf messages are a subset of all Json Strings. How can I use filebeat (or an alternative) as a lightweight solution to forward docker gelf logs reliably to logstash?</p>&#xA;&#xA;<p>Further info:</p>&#xA;&#xA;<p>I have a cluster (docker swarm for now) of machines in the same network running docker containers. I want to use --log-driver=gelf because I like the gelf format and want the fields that docker adds to each GELF log entry.</p>&#xA;&#xA;<p>Unfortunately docker sends GELF logs with UDP and I fear loosing log entries. Either because packages are lost, logstash is down, or there is too much load for logstash. I don't want to run logstash on each host because it is a heavyweight.</p>&#xA;"
43617787,What is the difference between workflow and dataflow?,2017-04-25 17:54:44,<spring><workflow><microservices><dataflow><spring-cloud-dataflow>,1,586,0,0.0,1,"<p>I'm looking at Spring Cloud Date Flow, before that I watched Activiti and Camunda(this is workflow engine). And I can't understand what is the difference between these concepts as workflow and dataflow? and Ñan we call Spring Cloud Data Flow the workflow engine?</p>&#xA;&#xA;<p>Sorry, I'm newer in this topic.</p>&#xA;&#xA;<p>I will be glad to any answer!</p>&#xA;"
43545080,Getting the different Content Type in the response of REST call done by REST client and Jersey Java Code,2017-04-21 14:19:51,<java><rest><jersey><microservices>,3,595,0,0.0,1,"<p>While working on a Micro-Service, I have to hit the REST api of the 3rd party. I am using the Spring Boot Application with Jersey library. &#xA;Now the problem is that I am getting the content type of the response as ""text/html; charset=utf-8"".</p>&#xA;&#xA;<p>If I hit the same call using the REST client, I get the right content type as application/json;charset=UTF-8. Why so ?</p>&#xA;&#xA;<p>Below is the Java source code for the same -</p>&#xA;&#xA;<pre><code>@Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;@POST&#xA;@Path(""/endPoint"")&#xA;@Consumes(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;public JSONObject getAccessToken(@FormParam(""item1"") String item1,@FormParam(""item2"") String item2,@FormParam(""item3"") String item3,@FormParam(""item4"") String item4) throws Exception {&#xA;  System.out.println(""Enter to test"");&#xA;&#xA;&#xA;    String extendedUrl = ""?item1=""+item1+""&amp;item2=""+item2+""&amp;item3=""+item3+""&amp;item4=""+item4;&#xA;&#xA;    JSONObject jObject = null;&#xA;    try {&#xA;      jObject = postCall(extendedUrl);&#xA;    }&#xA;    catch (Exception e) {&#xA;      // TODO Auto-generated catch block&#xA;      e.printStackTrace();&#xA;    }&#xA;&#xA;    System.out.println(""Box Auth Response :: ""+jObject.toJSONString());&#xA;&#xA;    return jObject;&#xA;}&#xA;// Short description of the logic to execute the request&#xA;public void postCall(String extendedUrl)&#xA;{ &#xA;String url = ""baseurl"";&#xA;url+=extendedUrl;&#xA;HttpsURLConnection conn = openConnection(apiUrl);&#xA;conn.connect();&#xA;status = conn.getResponseCode();&#xA;String responseContentType = conn.getContentType();&#xA;System.out.println(""responseContentType ::""+responseContentType);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So when I debug the code, responseContentType comes out as text/html; charset=utf-8. Is there any reason for the same ? How will get this as application/json;charset=UTF-8?</p>&#xA;&#xA;<p>Help would be appreciated. </p>&#xA;"
43655652,how to use AWS instance's IP address dynamically in an ansible playbook without saving it in an external file using ansible playbook,2017-04-27 10:50:37,<amazon-web-services><jenkins><ansible><microservices>,1,91,0,0.0,1,"<p>I have 2 clusters, 1 of Cassandra(4 node cluster) and other of Kafka(3 node cluster) on EC2. I have a playbook which deploys my microservices on AWS instances, for that microservice playbook i have maintained an inventory file which stores my cassandra/kafka host's IP adresses in a variable as follows:</p>&#xA;&#xA;<pre><code>cassandra_hosts = 'X.X.X.X:9042,X.X.X.X:9042,X.X.X.X:9042,X.X.X.X:9042'&#xA;kafka_host = 'X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092'&#xA;</code></pre>&#xA;&#xA;<p>The microservice playbook is somewhat as follows:</p>&#xA;&#xA;<pre><code>- hosts: dynamic_hosts&#xA;  become: yes&#xA;  become_user: xxxxxx&#xA;  become_method: sudo &#xA;&#xA;  vars:&#xA;   ansible_connection: ""{{ connection_type }}""&#xA;   ansible_ssh_user: ""{{ ssh_user_name }}""&#xA;   ansible_ssh_private_key_file: ""{{ ssh_private_key_file }}""&#xA;&#xA;  tasks:&#xA;&#xA;    - name: Register Service as an Upstart&#xA;      shell: chdir=""{{dest_location}}"" ""./{{upstartscript}}.sh"" "" -p  {{service_port}}  -u  {{service_uri}}  -v  {{service_version}}  -c  {{cassandra_hosts}}  -k  {{kafka_host}}  -l  {{log_level}}""&#xA;      register: escript&#xA;&#xA;    - name: Register Service as an Upstart Output&#xA;      debug: &#xA;       msg : ""{{ escript.stdout }}""&#xA;</code></pre>&#xA;&#xA;<p>The code above is the way in which I retrieve the IP Address which i have hardcoded in the inventory file(mentioned in the first part of the code).</p>&#xA;&#xA;<p>What I am trying to achieve is, how can I store the IP addresses of my AWS instances dynamically in my playbook and use it in my microservices playbook without storing the IP addresses in the inventory file, any suggestions</p>&#xA;&#xA;<p>P.S. I request you to ask any question if needed, this is my first question here, Thanks in advance</p>&#xA;&#xA;<p>Hi,&#xA;I also need to get the output of the kafka cluster, but kafka cluster outputs it in the AWS console in a different way as follows:</p>&#xA;&#xA;<pre><code>|||                                                           Outputs                                                           &#xA;|||&#xA;||+---------------------------+-----------------+---------------------------&#xA;----------------------------------------------------+||&#xA;|||        Description        |    OutputKey    |                                  &#xA;OutputValue                                  |||&#xA;||+---------------------------+-----------------+---------------------------&#xA;----------------------------------------------------+||&#xA;|||  IP of Primary Seed Node  |  ZookeeperLink  |  &#xA;X.X.X.X:2181,X.X.X.X:2181,X.X.X.X:2181,X.X.X.X:2181     &#xA;|||&#xA;|||  IP of Primary Seed Node  |  Node2DNSName   |  ip-X-X-X-&#xA;X.ec2.internal                                                 |||&#xA;|||  IP of Primary Seed Node  |  KafkaLink      |  &#xA;X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092     &#xA;|||&#xA;|||  IP of Primary Seed Node  |  Node3DNSName   |  ip-X-X-X-&#xA;X.ec2.internal                                                |||&#xA;|||  IP of Primary Seed Node  |  Node4DNSName   |  ip-X-X-X-&#xA;X.ec2.internal                                                |||&#xA;|||  IP of Primary Seed Node  |  Node1DNSName   |  ip-X-X-X-&#xA;X.ec2.internal  &#xA;</code></pre>&#xA;&#xA;<p>I just want to ouput the IPs of the part KafkaLink, any help on this:</p>&#xA;&#xA;<pre><code>    X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092&#xA;</code></pre>&#xA;&#xA;<p>I tried the following command but it is not working:</p>&#xA;&#xA;<pre><code> aws cloudformation describe-stacks --stack-name IngKafkaCluster --query 'Stacks[].Outputs[].OutputValue' --output text&#xA;</code></pre>&#xA;&#xA;<p>I get the following ouput on the above command , which is not wrong but not exactly what i want:</p>&#xA;&#xA;<pre><code>X.X.X.X:2181,X.X.X.X:2181,X.X.X.X:2181,X.X.X.X:2181        ip-X-X-X-X.ec2.internal    X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092,X.X.X.X:9092        ip-X-X-X-X.ec2.internal   ip-X-X-X-X.ec2.internal   ip-X-X-X-X.ec2.internal&#xA;</code></pre>&#xA;"
43665011,Microservice registration with Eureka replicas in docker swarm cluster,2017-04-27 18:05:23,<docker><microservices><netflix-eureka>,1,988,0,0.0,1,"<p>If I have a microservice for Eureka service discovery and I have 5 replicas for it in docker-compose.yml then, these 5 eureka containers would be spread across multiple swarm nodes available in swarm cluster.</p>&#xA;&#xA;<p>My question is, when a microservice wants to register itself with eureka,</p>&#xA;&#xA;<ol>&#xA;<li><p>Would it specify the ip address of the master node in the swarm cluster in its config for eureka server ?</p></li>&#xA;<li><p>When a microservice registers itself with eureka whichever way, does this registry get replicated across all the eureka containers in swarm cluster as who know which eureka node in swarm cluster would service a particular microservice.</p></li>&#xA;</ol>&#xA;"
43639036,using both api gateway and message broker in microservice,2017-04-26 15:51:22,<microservices>,1,548,1,0.0,1,<p>I have a question about microservice implementation. right now I am using an api gateway to process all get request to my individual services and using kafka to handle asynchronous post put and delete request. Is this a good way of handling of handling request in a microservice architecture?</p>&#xA;
43584079,How to split an existing webApi project?,2017-04-24 09:13:47,<.net><asp.net-web-api><architecture><microservices>,1,68,4,0.0,1,"<p>I have an existing legacy .Net webApi project with ~20 controllers and ~10 methods each.&#xA;The traffic is 15 requests per sec.&#xA;I'm wondering if it's a smart thing to do to take microServices approach and split it into few hosted projects.</p>&#xA;&#xA;<p>Since i don't have access to the clients (android, ios, WebSite and third parties) i will have to keep the existing API URL working (<a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a>).</p>&#xA;&#xA;<p>My quick and dirty architecture is:&#xA;1) Build new hosted API process <a href=""http://domainName/API1"" rel=""nofollow noreferrer"">http://domainName/API1</a>, <a href=""http://domainName/API2"" rel=""nofollow noreferrer"">http://domainName/API2</a>, <a href=""http://domainName/API3"" rel=""nofollow noreferrer"">http://domainName/API3</a>...&#xA;2) Ask kindly from the clients to use the new URLs&#xA;3) <a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a> will act as router to the new processes for background competitively </p>&#xA;&#xA;<p>Ideas ? Is there any existing pattern for that?  </p>&#xA;"
43559197,Shared signature key for JWT in various Microservices,2017-04-22 12:27:52,<security><spring-security><jwt><spring-cloud><microservices>,1,372,4,0.0,1,<p>I have various microservices. I have implemented security using JWT. Each service validates the JWT token by the key which is being shared across all the services.</p>&#xA;&#xA;<p><strong>Is it fine to share same signature key for JWT across all the microservices?</strong> </p>&#xA;&#xA;<p>I can't implement this at the API gateway as I have to use certain libraries which requires spring security to be triggered in every microservice.</p>&#xA;
43661844,Microservice - What does changing service without changing code really mean?,2017-04-27 15:21:00,<java><spring-boot><cloudfoundry><microservices>,2,113,7,0.0,1,"<p>I am trying to understand ""changing database without changing code"". Currently working with micro services using springboot, java, thymeleaf and cloud foundry.</p>&#xA;&#xA;<p>I have a spring boot application and attached a database as a service using cloud foundry.</p>&#xA;&#xA;<p>My problem is I am seeing that the purpose of micro service is allowing the ease to change services without changing code.</p>&#xA;&#xA;<p><strong>Here is where I got stuck</strong></p>&#xA;&#xA;<p>In java I have a sql script, ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>Images <a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">source</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/WDQmC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WDQmC.png"" alt=""Table sample""></a></p>&#xA;&#xA;<p>My database would be attached as a service on cloud foundry using CUPS &#xA;""jdbc:oracle:thin:username/password//host:port/servicename""</p>&#xA;&#xA;<p>So let say I want to change this database to CUSTOMER table(take it as a different database). This will throw an error because CUSTOMER table will not have ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>I've changed database, but wouldn't I still have to go back to my code and change the sql script?</p>&#xA;&#xA;<p><strong>My Attempt to resolve this issue</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>So instead of hard coding my sql script in java ""select * from ORDER where Status = 'ACCEPTED';""</p></li>&#xA;<li><p>I created a system environment variable and set it as sqlScript with value of select * from ORDER where Status = 'ACCEPTED'</p></li>&#xA;<li><p>Then in java I called the env variable String sqlScript= System.getenv(""sqlScript"");  </p></li>&#xA;<li><p>So now instead of going back into java to change sql script, user can change it through environment variables.</p></li>&#xA;</ol>&#xA;&#xA;<p>this is a very dirty method to go around my issue, what would be a better alternative?</p>&#xA;&#xA;<p>I know my logic of understanding is really wrong. Please guide me to the right path.</p>&#xA;"
41194679,Have only one micro service perform a background task in an auto scaling group,2016-12-17 01:57:38,<architecture><microservices>,1,67,0,0.0,1,"<p>I have a fairly simple micro service that reads data from a MongoDB cluster, does some data transformation, and exposes the data through a REST API. I need to update the independent persistence datastore using a cron job. I could create a separate application to update the dataset but it is easier to deploy just the one application that exists in an AWS auto scaling group (this is for a large enterprise with a lot of red tape for releasing new applications), and have one of the instances update the dataset through a background job. </p>&#xA;&#xA;<p>Locking writes to the DB through a field in the DB is a workable solution but seems like an antipattern. Is there a better way to do this without creating a separate application to do the DB writes?</p>&#xA;"
41094112,Should each microservice run in its own process?,2016-12-12 04:12:21,<deployment><soa><microservices>,1,173,0,0.0,1,<p>Assume I have separated my monolithic application into 5 microservices.</p>&#xA;&#xA;<p>Now do I need to run these 5 microservices in 5 processes or is it OK to have all 5 of them run in a single process? Why?</p>&#xA;
41086281,MICROSERVICES - communication between them,2016-12-11 12:41:57,<java><rest><microservices>,2,712,4,0.0,1,"<p>I've got one question concerning microservices architecture. I am designing a system based on microservices. I've read few articles and I think I understand the idea. However, I don't how microservices should communicate with each other while they have separate business responsibilities....&#xA;What I mean is that if I have a system for booking train tickets, I would divide backend application into modules: </p>&#xA;&#xA;<ul>&#xA;<li>Client (login,logout,registration) </li>&#xA;<li>Reservations (booking a train seat for user,getting all reservations for user) </li>&#xA;<li>ConnectionsDetails&#xA;(searching for connections,getting connection details) </li>&#xA;<li>Trains&#xA;(information about trains- seats number,class etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Now, I can only think that if user search for connections module ConnectionsDetails communicate with Trains module and ask about particular train details. But how could other microservices communicate? If user wants to login - she/he asks directly Client module, if she/he wants to get all her reservations - asks Reservation module DIRECTLY etc... </p>&#xA;&#xA;<p>So my question is, how should modules communicate if they do different things? I'm sorry if my question is trivial or stupid, I'm just starting with microservices.</p>&#xA;&#xA;<p>EDIT:&#xA;I didn't mean what tools could I use for communication. My question is about logic. In the example I showed, why one microservice could ask another microservice about sth if client can directly ask the another one? As I said earlier, how they should communicate(about what should they ask each other exactly) if they do separate things?</p>&#xA;"
45998405,Oracle SOA and MSA,2017-09-01 10:38:32,<soa><esb><microservices>,1,78,0,1.0,1,"<p>Is it advicible to build the MSA based services on Oracle SOA or any other ESB suite for that matter? Is there any advantage or disadvantage? </p>&#xA;&#xA;<p>If I am using Java, Spring and JPA over a message queue - say - RabbitMQ, I can achieve it in a more controlled environment with less recurring expenses. Of course will end up mixing tools like Drools or JBPM or similar to achieve things that may be OOTB (Out of the box) in the SOA Or ESB Suite. But scaling a specific service without paying licence fee for an additional environment should certainly be a good catch right?</p>&#xA;"
46022865,nginx with .net core kestrel - multiple vs single instance,2017-09-03 11:13:27,<docker><nginx><.net-core><microservices>,1,358,0,0.0,1,"<p>I have 4 .net core web applications running (3 'micro' services and one web site). I'm trying to decide on a deployment strategy using docker. As I understand, my options are as follows:</p>&#xA;&#xA;<ol>&#xA;<li>Total 4 containers - each container with a core app and a nginx instance</li>&#xA;<li>Total 8 containers - 4 .net core containers and 4 nginx containers</li>&#xA;<li>Total 5 Containers - 4 .net core containers and shared nginx container</li>&#xA;</ol>&#xA;&#xA;<p>Some Notes:</p>&#xA;&#xA;<ol>&#xA;<li>More services will also be added as time goes by.</li>&#xA;<li>This setup will be running on a linux</li>&#xA;<li>In the future, when the site load gets high I will want to do load balancing and to run each of the four websites on their own (multiple) servers. I would also want to fire up multiple instances of each service as they are stateless.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Question is</strong>; Is there a good reason to use separate nginx instances or should all .net apps use the same nginx container? </p>&#xA;"
45929864,Tracking of who created or changed an entity in microservices,2017-08-29 02:33:28,<java><spring><spring-boot><microservices><auditing>,1,61,1,0.0,1,"<p>Usually in spring boot applications, we can use jpa audit to do the tracking. &#xA;<a href=""https://docs.spring.io/spring-data/data-jpa/docs/1.7.0.DATAJPA-580-SNAPSHOT/reference/html/auditing.html"" rel=""nofollow noreferrer"">Spring Boot Jpa Auditing</a></p>&#xA;&#xA;<p>While in microservices architecture, I'd try to avoid involving security in core microservice. Instead, we can do authentication/authorization at api gateway. </p>&#xA;&#xA;<p>While, if the core service didn't get the current login user, we have to find an way to pass the current operator to core services. It could be an user identifier header on the request. Or Maybe we can pass token to core services to let it fetch the login user from auth server.</p>&#xA;&#xA;<p>I am wondering if anyone has handled such case and give out some suggestion. </p>&#xA;"
45866422,CQRS + ES: Splitting monolith to microservices database issue,2017-08-24 16:08:56,<subquery><microservices><cqrs>,1,71,1,0.0,1,"<p>When we use the relational database to do multi-table subquery, e.g.</p>&#xA;&#xA;<p><code>&#xA;select * from `t_a` a where exist (select pid from` t_b` b where b.pid = a.pid group by pid)&#xA;</code></p>&#xA;&#xA;<p>if table t_a, t_b are in the same database, then it is easy to achieve the subquery, if we split these two tables (more than millions of rows) into two microservices A and B, service A has database db_a, it has table t_a, service B has database db_b, it has table t_b.</p>&#xA;&#xA;<p>My question is: how does CQRS &amp; ES implement data aggregation?</p>&#xA;&#xA;<p>I'm struggling this issue for a long time, searched so many articles, but I didn't find any useful answer, any suggestion would be appreciated.</p>&#xA;"
45848118,Spring Boot Authorization Server send request to external service to get user details,2017-08-23 19:42:47,<java><spring><spring-security><authorization><microservices>,1,525,2,0.0,1,"<p>I got a lot of services and I want to centralize my authentication with an authentication-service. Now I am a noobie at Spring boot and I have no clue how do I make this possible.</p>&#xA;&#xA;<p>I just implement the normal security from Spring and it works perfectly and I only find some tutorials about <code>jdbcAuthentication</code>, <code>inMemoryAuthentication</code>, etc but not an authentication where the authentication-service send a request to another service. Does anyone get a clue about this?</p>&#xA;&#xA;<p>My security based on tokens -> <code>JWT</code></p>&#xA;&#xA;<p>I think I need to manipulate the <code>AuthenticationManagerBuilder</code> because it decides whether a username is valid or not. </p>&#xA;&#xA;<pre><code>protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and I make my request with Feign - maybe the wrong location for this code</p>&#xA;&#xA;<pre><code>@Override&#xA;public Authentication attemptAuthentication(HttpServletRequest req, HttpServletResponse res) throws AuthenticationException, IOException, ServletException {&#xA;    AccountCredentials credentials = new ObjectMapper()&#xA;            .readValue(req.getInputStream(), AccountCredentials.class);&#xA;&#xA;    UserRequest userRequest = Feign.builder()&#xA;            .decoder(new GsonDecoder())&#xA;            .target(UserRequest.class,""http://localhost:7998/api/user-service/user/"" + credentials.getUsername());&#xA;&#xA;    return getAuthenticationManager().authenticate(new UsernamePasswordAuthenticationToken(credentials.getUsername(),credentials.getPassword(),emptyList()));&#xA;}&#xA;</code></pre>&#xA;"
45771237,How to limit rate of out going http calls in scaled microservice?,2017-08-19 11:56:17,<spring><http><microservices><rate-limiting>,2,69,0,1.0,1,"<p>I have a scenario in which my microservice is scaled to 3 instances. Each service makes http calls to third party service. However, the third party service has a rate limit i.e. it cannot accept more than 1000 requests per second. Now that I have 3 instances of same service running its hard to keep track of count. Any solutions that could help me implement this?</p>&#xA;"
45661006,What is the difference between Monolith and n Layer?,2017-08-13 13:44:07,<architecture><microservices>,1,972,0,1.0,1,"<p>i have a few questions regarding <strong>monolith</strong> and <strong>n layer architecture</strong>.</p>&#xA;&#xA;<p>First, whats the difference between Monolith and n Layer architecture?</p>&#xA;&#xA;<p>Second, let's say I have a single Visual Studio solutions that consist of multiple projects such as:</p>&#xA;&#xA;<ol>&#xA;<li>Presentation Layer</li>&#xA;<li>Service Layer</li>&#xA;<li>Business Layer</li>&#xA;<li>Cross Layer</li>&#xA;<li>Data Layer</li>&#xA;<li>Unit Test</li>&#xA;</ol>&#xA;&#xA;<p>Is that considered as Monolith or n layer architecture?</p>&#xA;&#xA;<p>If I have microservices that consist (let's say) 3 Web API and I build each service in single separate Visual Studio solutions, <strong><em>it is ok</em></strong> to implement my previous project structure (service layer, business layer, data layer, etc)?</p>&#xA;&#xA;<p>Thank you very much and sorry for my bad english.</p>&#xA;"
45776238,Golang microservice project structure,2017-08-19 21:00:10,<go><microservices><directory-structure>,3,2271,0,2.0,1,"<p>I'm at an initial stage of creating a microservice application in Go, but due to the way that the import paths and directories are handled I'm not quite sure what's best way to structure the project files.</p>&#xA;&#xA;<p>Normally, the project would look something like this in Java:</p>&#xA;&#xA;<pre><code>|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>Now if I do it the same way in Go, the import paths become somewhat cumbersome:</p>&#xA;&#xA;<pre><code>import (&#xA;       ""fmt"" &#xA;       ""github.com/user/myproject/gateway_microservice/src/package1""&#xA;       ""github.com/user/myproject/gateway_microservice/src/package2""&#xA;)&#xA;</code></pre>&#xA;&#xA;<p>Additionally, I hear that the idiomatic way is to put all <code>main.go</code> files in a separate <code>cmd</code> directory, which adds to the confusion. Would it look something like this:</p>&#xA;&#xA;<pre><code>|-- cmd&#xA;   |-- gateway_microservice&#xA;      |-- main.go&#xA;   |-- config_microservice&#xA;      |-- main.go&#xA;   |-- recommendation_microservice&#xA;      |-- main.go&#xA;   |-- users_microservice&#xA;      |-- main.go&#xA;|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>What is the 'correct' or idiomatic way of structuring a project like this in Go?</p>&#xA;"
45597395,How to decide on picking new micro service or add to existing micro service when new business feature is requested,2017-08-09 17:44:10,<web-services><amazon-web-services><microservices><spring-ws><go-restful>,1,25,1,1.0,1,<p>I like to understand better on Micro services. Is there checklist which help me to decide particular new feature can be build as new micro service or combine with existing micro services available in my application?</p>&#xA;
45755580,differentiate between maven multi module and Spring micro services?,2017-08-18 11:29:16,<microservices>,1,417,2,0.0,1,"<p>I am reading spring micro services for next project. Tut said that ""The architecture style the main application divided in a set of sub applications called microservices. One large Application divided into multiple collaborating processes."". So already we have a framework maven multi module There I separated the project in my experience. even though it is. why do we need micro services to separate a project?. please differentiate it. thanks in advance..</p>&#xA;"
45751211,Automated tests on contracts between microservices?,2017-08-18 07:45:16,<c#><api><integration-testing><microservices><contract>,2,258,4,0.0,1,"<p>Say we have a CreditCardService microservice that depends on a ThreeDSecureService microservice, communicating using JSON.</p>&#xA;&#xA;<p>Minor changes in the API (or even implementation) of the ThreeDSecureService could silently break the CreditCardService (and other potential clients). So, we would like automated tests.</p>&#xA;&#xA;<p>I see two flawed approaches, and am wondering how to improve.</p>&#xA;&#xA;<ol>&#xA;<li>Integration testing in ThreeDSecureService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The accompanying test project of ThreeDSecureService could have an integration test with a fixed JSON input. Faking out any dependencies, it could run an otherwise complete call for that input, confirming that the service swallows the input.</p>&#xA;&#xA;<p>The problem here is that if someone fails to realize how their changes could break clients, they are almost as likely to 'fix' the tests to match their changes.</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Integration testing in CreditCardService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The <em>client</em> is the one that actually wants to test assertions about ThreeDSecureService's expected input. However, that would require the client solution to include the ThreeDSecureService project, as well as any projects it depends on. This would negate many of the advantages we get from using microservices!</p>&#xA;&#xA;<p><strong>How do we make assertions from the client (safeguarding the dependency) without breaking the loose coupling we get from using microservices?</strong></p>&#xA;"
45673863,Communication between Spring microservices,2017-08-14 11:49:01,<java><spring><api><spring-mvc><microservices>,2,664,4,0.0,1,"<p>I am still learning microservices and I am asking myself, how do we secure our rest-points? I use the famous framework Spring Boot which extends from Spring. What is the best or most used pattern to secure the endpoints of a rest API?</p>&#xA;&#xA;<p>When I use Spring Security with oAuth2, I always need to send the credentials in the body of the request. Is there an approach without the credentials and which is easier to implement? Like API-Tokens?</p>&#xA;&#xA;<p>I always prefer practical tutorials.</p>&#xA;"
45642575,microservices or SOA: how to respond one specific request,2017-08-11 19:32:36,<architecture><soa><microservices>,2,137,5,0.0,1,"<p>I am interested in microservices and SOA. I read some tutorials. This is my understanding SOA. The API gateway receives lots of requests (requestA, requestB, ...) and put requests in messaging queues. Micro-services will consume the events in the messaging queues and do some processing. My question is after processing, how the response can be returned to requests (responseA to requestA, responseB to requestB).</p>&#xA;&#xA;<p>I am not sure whether my understanding is right or wrong and whether messaging is used in every architecture. </p>&#xA;&#xA;<p>Anyone can give me more details/examples how to decouple/connect the API gateways and the microservices. How to respond to requests? should the connection between API gateways and clients kept alive?</p>&#xA;&#xA;<p>Sorry if my question is not clear. I am confused and have no idea how to understand each concept.</p>&#xA;&#xA;<p>Any comment welcomed. Thanks</p>&#xA;"
45791262,How to orchestrate multiple microservices on local env?,2017-08-21 07:14:59,<docker><development-environment><microservices><orchestration>,1,584,6,0.0,1,"<p>at the moment of speaking I have a bunch of services running each one on its own container&#xA;Every repo of code has its own Docker file and docker compose file in order to bring up the service on my local dev-machine</p>&#xA;&#xA;<p>Everything is fine and I'm able o access each service at</p>&#xA;&#xA;<p><a href=""http://localhost:[service"" rel=""nofollow noreferrer"">http://localhost:[service</a> mapped/exposed port]</p>&#xA;&#xA;<p>Problem is that services are augmenting and I'm thinking that could be a better idea to have everything in a local private network, where each service 's container has its own IP address.</p>&#xA;&#xA;<p>Is this a better approach to orchestrate containers locally?</p>&#xA;&#xA;<p>Where should I start from to make up my mind?</p>&#xA;"
26706240,Why does 12factor recommend not to daemonize processes?,2014-11-03 00:41:11,<12factor><microservices>,3,244,0,0.0,2,"<p><a href=""http://12factor.net/concurrency"" rel=""nofollow"">12factor recommends not to daemonize processes</a>. What are the disadvantages of doing so?</p>&#xA;"
28114758,Microservices with spring integration and spring boot,2015-01-23 16:51:43,<spring-boot><spring-integration><microservices>,2,2113,0,1.0,2,<p>I'm a bit new with microservices (and SI) and want to make a POC following a microservices architecture style. I've seen that I can use Spring Boot for deployment and SI for the development but found little docs about how to combine them (just an example in Spring Boot home page). Do you know about best practices or recommendations on how to combine this two technologies? </p>&#xA;
25812816,How to shutdown dropwizard application?,2014-09-12 16:30:05,<java><dropwizard><microservices>,5,6562,2,0.0,2,"<p>I am trying to come up with a microservice using dropwizard. &#xA;The documentation tells how to start the application, but says nothing about terminating it gracefully. Fir example, apache tomcat has both startup <em>and</em> shutdown scripts. </p>&#xA;&#xA;<p>So does anyone know how to terminate a dropwizard application other than pressing <code>Ctrl+C</code> of <code>kill</code> ? </p>&#xA;"
50651256,microservices - is it one service per CRUD,2018-06-01 21:34:29,<node.js><amazon-web-services><aws-lambda><microservices>,4,76,0,1.0,2,"<p>Very new to microservices...  </p>&#xA;&#xA;<p>If I have an API that deals with CRUD for customers and orders, does this translate to 2 microservices one for customers and one for orders?</p>&#xA;&#xA;<p><strong>Customer API</strong></p>&#xA;&#xA;<pre><code>CreateCustomer&#xA;ReadCustomer&#xA;UpdateCustomer&#xA;DeleteCustomer&#xA;</code></pre>&#xA;&#xA;<p><strong>Order API</strong></p>&#xA;&#xA;<pre><code>CreateOrder&#xA;ReadOrder&#xA;UpdateOrder&#xA;DeleteOrder&#xA;</code></pre>&#xA;"
50672490,What's the right way to gather data from different microservices?,2018-06-04 01:37:39,<node.js><design><architecture><microservices>,2,64,1,2.0,2,"<p>I'm having a problem understanding how basic communication between microservices should be made and I haven't been able to find a good solution or standard way to do this in the other questions. Let's use this basic example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pOCGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pOCGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I have an invoice service that return <strong>invoices</strong>, every invoice will contain information(ids) about the user and the products. If I have a view in which I need to render the invoices for a specific user, I just make a simple request.</p>&#xA;&#xA;<pre><code>let url = ""http://my-domain.com/api/v2/invoices""&#xA;let params = {userId:1}&#xA;request(url,params,(e,r)=&gt;{&#xA;  const results = r // An array of 1000 invoices for the user 1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>Now, for this specific <strong>view</strong> I will need to make another request to get all the details for each product on each invoice.</p>&#xA;&#xA;<pre><code>results.map((invoice)=&gt;{&#xA;   invoice.items.map((itemId)=&gt;{&#xA;      const url=`http://my-domain.com/api/v2/products/${itemId}`&#xA;      request(url,(e,r)=&gt;{&#xA;       const product = r&#xA;       //Do something else.....&#xA;      });&#xA;   });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>I know the code example is not perfect but you can see that this will generate a huge number of requests(at least 1000) to the product service and just for 1 user, now imagine if I have 1000 users making this kind of requests.</p>&#xA;&#xA;<p>What is the right way to get the information off all the products without having to make this number of requests in order to avoid performance issues?.</p>&#xA;&#xA;<p>I found some workarounds for this kind of scenarios such as:</p>&#xA;&#xA;<ol>&#xA;<li>Create an API endpoint that accepts a list of IDs in order to make a single request.</li>&#xA;<li>Duplicate the information from the Product service within the invoice service and find a way to keep them in sync.</li>&#xA;</ol>&#xA;&#xA;<p>In a microservices architecture are these the right ways to deal with this kind of issues? For me, they look like simple workarounds.</p>&#xA;&#xA;<p><strong><em>Edit #1: Based on Remus Rusanu response.</em></strong></p>&#xA;&#xA;<p>As per Remus recommendation, I decided to isolate my services and describe them a little bit better.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BHosb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BHosb.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>As shown in the image above the microservices are now isolated(in specific the Billing-service) and they now are the owners of the data. By using this structure I ensure that Billing-service is able to work even if there are async jobs or even if the other two services are down.</p>&#xA;&#xA;<p>If I need to create a new invoice, I can call the other two microservices(Users, Inventory) synchronously and then update the data on the ""cache"" tables(Users, Inventory) in my billing service.</p>&#xA;&#xA;<p>Is it also good to assume these ""cache"" tables are read-only? I assume they are since only the user/inventory services should be able to modify this information to preserve isolation and authority over the information.</p>&#xA;"
50702676,How to solve two generals issue between event store and persistence layer?,2018-06-05 14:31:34,<microservices><distributed-system><event-store>,3,50,2,0.0,2,"<p><strong>Two General Problems - EventStore and persistence layer?</strong></p>&#xA;&#xA;<p>I would like to understand how industry is actually dealing with this problems! </p>&#xA;&#xA;<p>If a microservice 1 persists object X into Database A. In the same time, for micro-service 2 to feed on the data from micro-service 1, micro-service 1 writes the same object X to an event store B. </p>&#xA;&#xA;<p>Now, the question I have is, where do I write object X first? </p>&#xA;&#xA;<ol>&#xA;<li><p>Database A first and then to event store B, is it fair to roll back the thread at the app level if Database A is down? Also, what should be the ideal error handle if Database A is online and persisted object X but event store B is down?</p></li>&#xA;<li><p>What should be the error handle look like if we go vice-versa of point 1?</p></li>&#xA;</ol>&#xA;&#xA;<p>I do understand that in today's world of distributed high-available systems, systems going down is questionable thing. But, it can happen. I want to understand what needs to be done when either database or event store system/cluster is down?</p>&#xA;"
30000824,How to use kubernetes replication controllers to replicate message-based services,2015-05-02 09:50:02,<rabbitmq><kubernetes><microservices>,1,1121,0,0.0,2,"<p>We usually use message passing to send messages to decoupled services. This makes service discovery a non-issue, because (with AMQP in RabbitMQ for instance) you can use the broker's routing capability to dispatch messages to the right queues that feed the correct services. Load balancing is also handled by the message broker.</p>&#xA;&#xA;<p>Enter kubernetes.</p>&#xA;&#xA;<p>The use case that is usually laid out when talking about service replication and re-spawning failing services, is when your clients use some active protocol like http to contact a service, even if this service handles requests asynchronously. In this context, it is a natural fit to have replication controllers, that manage a group of services and a single entry point to load balance between them.</p>&#xA;&#xA;<p>I like kubernetes' intuitive concepts, like rolling deployments, but how to you control this beasts that don't have an http interface ?</p>&#xA;&#xA;<p><strong>UPDATE:</strong>&#xA;I am not trying to set up a cluster of message brokers. I am looking at message consumers as services. Service clients don't connect directly to the services, they send messages to the message broker. The message broker acts as a load balancer in a way, and dispatches the messages to the subscribed queue consumers. These consumers implement the service.</p>&#xA;&#xA;<p>My question gravitates around the fact that most usage patterns in demos handle services that are called via http, and kubernetes does a good job here to create a service proxy for these services, and a replication controller. Is it possible to create replication controllers for my kind of service, which does not have a http interface per se, and have all the benefits of rolling updates, and minimum instances?</p>&#xA;"
30053782,"Microservice architecture, authentication and other services",2015-05-05 13:02:18,<java><web-services><api><amqp><microservices>,1,648,0,0.0,2,"<p>I m studying the micro-services architecture, and I m have a question.</p>&#xA;&#xA;<p>Admitting that I have multiple services on different host like following :</p>&#xA;&#xA;<ul>&#xA;<li>Authentication service on <a href=""http://80.80.80.80:9000/"" rel=""nofollow"">http://80.80.80.80:9000/</a></li>&#xA;<li>Billing service on <a href=""http://90.90.90.90:1234/"" rel=""nofollow"">http://90.90.90.90:1234/</a></li>&#xA;<li>Planning service on <a href=""http://70.70.70.70:7412/"" rel=""nofollow"">http://70.70.70.70:7412/</a></li>&#xA;</ul>&#xA;&#xA;<p>My question is, when a user request on the gateway, he sends an access token (stateless, oauth2.0, whatever), then the gateway asks the authentication service, and if the user exists and has permissions, he access the ressources on another service.</p>&#xA;&#xA;<p>That's okay, but what if I try to call directly the BillingService from his host ? You can tell me that the port is closed, and I agree with that.</p>&#xA;&#xA;<p>But does it mean that they are port allowed only from a certain host to another ? Meaning that the billing service on port 1234 is allowed only from the gateway machine ?</p>&#xA;&#xA;<p>Am I missing something ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
27723156,How to handle self-created artifacts in micro service architecture when several services depend on it?,2014-12-31 15:36:03,<java><jpa><spring-boot><microservices>,2,140,0,0.0,2,"<p>I'm testing micro service architecture using Spring Boot and RabbitMQ.</p>&#xA;&#xA;<p>I now have two small services:&#xA;UserRegistrationService (Registers the user in a db)&#xA;GetUserInfo (Returns the user from the same db)</p>&#xA;&#xA;<p>I choose to have all the user-specific services use the same db.</p>&#xA;&#xA;<p>Both the services are using the entity ""User""(JPA). (This may not be the smartest way of going about)</p>&#xA;&#xA;<p>Is there a smart way of handling this dependency? (two services depend on the same entity)&#xA;Should I make the entity (user) to a separate project and use a artifact repository?</p>&#xA;"
27839789,How do I change these producer-consumer microservices to allow parallel processing?,2015-01-08 12:06:52,<ruby-on-rails><ruby><multithreading><parallel-processing><microservices>,3,429,2,0.0,2,"<p>I've got a couple microservices (implemented in ruby, although I doubt that is important for my question). One of them provides items, and the other one processes them, and then marks them as processed (via a DELETE call)</p>&#xA;&#xA;<p>The provider has an <code>/items</code> endpoint which lists a bunch of items identified with an id, in JSON format. It also has a <code>DELETE /items/id</code> endpoint which removes one item from the list (presumably because it is processed)</p>&#xA;&#xA;<p>The code (very simplified) in the ""processor"" looks like this:</p>&#xA;&#xA;<pre><code>items = &lt;GET provider/items&gt;&#xA;items.each do |item|&#xA;  process item&#xA;  &lt;DELETE provider/items/#{item.id}&gt;&#xA;end&#xA;</code></pre>&#xA;&#xA;<p>This has several problems, but the one I would like to solve is that it is not thread-safe, and thus I can't run it in parallel. If two workers start processing items simultaneously, they will ""step onto each other's toes"": they will get the same list of items, and then (try to) process and delete each item twice.</p>&#xA;&#xA;<p>What is the simplest way I can change this setup to allow for parallel processing?</p>&#xA;&#xA;<p>You can assume that I have ruby available. I would prefer keeping changes to a minimum, and would rather not install other gems if possible. <a href=""http://sidekiq.org/"" rel=""nofollow"">Sidekiq</a> is available as a queuing system on the consumer.</p>&#xA;"
31973473,Message Bus versus Quasar/HTTP for internal Microservice Calls,2015-08-12 19:08:08,<java><microservices><message-bus><backpressure><quasar>,1,981,0,0.0,2,"<p>I am looking to optimize a microservice architecture that currently uses HTTP/REST for internal node-to-node communication.</p>&#xA;&#xA;<p>One option is implementing backpressure capability into the services, (eg) by integrating something like Quasar into the stack.  This would no doubt improve things.  But I see a couple challenges.  One is, the async client threads are transient (in memory) and on client failure (crash), these retry threads will be lost.  The second, in theory, if a target server is down for some time, the client could eventually reach OOM attempting retry because threads are ultimately limited, even Quasar Fibers.</p>&#xA;&#xA;<p>I know it's a little paranoid, but I'm wondering if a queue-based alternative would be more advantageous at very large scale.</p>&#xA;&#xA;<p>It would still work asynchronously like Quasar/fibers, except a) the queue is centrally managed and off the client JVM, and b) the queue can be durable, so that in the event client and or target servers go down, no in flight messages are lost.</p>&#xA;&#xA;<p>The downside to queue of course is that there are more hops and it slows down the system.  But I'm thinking there is probably a sweet spot where Quasar ROI peaks and a centralized and durable queue becomes more critical to scale and HA.</p>&#xA;&#xA;<p><strong>My question is:</strong>  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Has this tradeoff been discussed?  Are there any papers on using a&#xA;  centralized external queue / router approach for intraservice&#xA;  communication.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>TL;DR;</strong>  I just realized I could probably phrase this question as:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""When is it appropriate to use Message Bus based intraservice&#xA;  communication as opposed to direct HTTP within a microservice&#xA;  architecture.""</p>&#xA;</blockquote>&#xA;"
30449278,Automation of releases of microservices-based application,2015-05-26 04:04:42,<git><automation><release-management><salt-stack><microservices>,4,894,0,0.0,2,"<p>We are working on the application that consists of many standalone services. It has advantages over the single monolithic application, but not when we do releases.</p>&#xA;&#xA;<p>We do weekly release cycles. Each service/component located in the separate git repository. 'A release' - is several features that we put into wild. Usually only several components should be updated. We manage servers using saltstack. To make a release salt scripts update component's versions using git.latest state. The problem is to specify right versions.</p>&#xA;&#xA;<p>This is where the manual work that I'd like to automate. To update versions I have to manually check each component's repository, merge development branch into master and tag according to symantec versioning rules. Then I write new version in salt scripts. We have over 10 components so this is rather boring and error prone process.</p>&#xA;&#xA;<p>Probably we doing it wrong, I'll be glad to hear any advices how to do it better, thanks.</p>&#xA;"
49861169,Best approach to send updates to other micro services which are running(multiple instances) in different data centers,2018-04-16 15:37:01,<microservices><production-environment><multiple-instances>,1,33,0,0.0,2,"<p>I have 3 different micro services(ex: A,B,C. these are REST, and springboot based). These 3 different services generally runs on 3 different data centers locations, so i.e different instances for each service. </p>&#xA;&#xA;<p>The problem trying to solve:&#xA;I need to send updates(its kind of polling, checking if there are any updated records) in service A, then send updated information to services B and C, through REST call. Based on these updates service B and C does it's own processing. Once after deployment(mostly into cloud). How does A knows which B, C instances are up and running. SO that it can send updates to running instances.</p>&#xA;&#xA;<p>Do we need to keep track of running instances into some DB table and lookup for active instances before sending updates from A?. (OR) just create some indicator or sequence number based approach to find out there are some updates at A, So we need to send out.But in this does it A knows what all are active instances running? Or else, we just need to send updates from A, so that some router or load balancer or some other thing will takes care of sending to available active instances running regardless of storing and looking up for active instances</p>&#xA;&#xA;<p>I am not much familiar with network and prod systems behavior and its communication in cloud systems.</p>&#xA;"
31845342,How does Spring Cloud Config download remote configurations for a service?,2015-08-06 01:24:32,<spring-boot><spring-cloud><microservices>,1,866,3,0.0,2,"<p>I have found this <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">example</a> about spring-cloud on GitHub a few days ago.</p>&#xA;&#xA;<p>I am having some problems getting the config service example working. I don't know how to use <code>config-microservice</code> correctly.</p>&#xA;&#xA;<p><a href=""http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html?mkt_tok=3RkMMJWWfF9wsRonuqTMZKXonjHpfsX57ukoWaC0lMI%2F0ER3fOvrPUfGjI4ATcdqI%2BSLDwEYGJlv6SgFQ7LMMaZq1rgMXBk%3D"" rel=""nofollow"">in this blog</a>,it said configurations for your microservice applications should be stored in the environment and not in the project.</p>&#xA;&#xA;<p>But I'm not sure how to do this. I don't know how one of the microservices, for instance a <code>movie-microservice</code> Spring Boot application gets a config file from <code>config-service</code>.</p>&#xA;"
48882829,Backends For Frontends BFFs or API Gateway,2018-02-20 10:16:42,<microservices>,1,448,0,0.0,2,"<p>In a micro-services architecture we can have:</p>&#xA;&#xA;<ol>&#xA;<li><p>A single API gateway providing a single API for all clients.</p></li>&#xA;<li><p>A single API gateway provider an API for each kind of client. </p></li>&#xA;<li><p>A per-client API gateway providing each client with an API. which is the BFF pattern.</p></li>&#xA;</ol>&#xA;&#xA;<p>Netflix uses the second style <a href=""https://medium.com/netflix-techblog/embracing-the-differences-inside-the-netflix-api-redesign-15fd8b3dc49d"" rel=""nofollow noreferrer"">Inside the Netflix API Redesign</a>. we can surely say that they have created a smart-piece of middleware in their architecture that takes on multiple responsibilities.&#xA;But how much work this single API back-end can handle, it seems that it can become a bottleneck so easily.</p>&#xA;&#xA;<p>So my question is what are the benefits of choosing the single API to handle  requests for more than 1000 clients instead of creating an API Gateway specifically designed to one type of clients? Aren't they facing many challenges to manage and maintain this complex piece? </p>&#xA;"
48961000,Why shared libraries between microservices are bad?,2018-02-24 08:43:10,<interface><architecture><shared-libraries><microservices><distributed-computing>,1,967,0,0.0,2,"<p>Sam Newman states in his book <em>Building Microservices</em></p>&#xA;&#xA;<blockquote>&#xA;  <p>The evils of too much coupling between services are far worse than the problems caused by code duplication</p>&#xA;</blockquote>&#xA;&#xA;<p>I just don't understand how the shared code between the services is evil. Does the author mean the <em>service boundaries themselves</em> are poorly designed if a need for a shared library emerges, or does he really mean I should duplicate the code in the case of common business logic dependency? I don't see what that solves.</p>&#xA;&#xA;<p>Let's say I have a shared library of entities common to two services. The common domain objects for two services may smell, but another service is the GUI to tweak the state of those entities, another is an interface for other services to poll the state for their purpose. Same domain, different function.</p>&#xA;&#xA;<p>Now, if the shared knowledge changes, I would have to rebuild and deploy both services regardless of the common code being an external dependency or duplicated across the services. Generally, same concerns all the cases for two services depending of the same article of the business logic. In this case, I see only harm of duplication of the code, reducing the cohesion of the system.</p>&#xA;&#xA;<p>Of course, <em>diverging</em> from the shared knowledge may cause headaches in the case of shared library, but even this could be solved with inheritance, composition and clever use of abstractions.</p>&#xA;&#xA;<p>So, what does Sam mean by saying code duplication is better than too much coupling via shared libraries? </p>&#xA;"
48861926,How to keep state consistent across distributed systems,2018-02-19 08:17:01,<rest><web-services><architecture><microservices><distributed-computing>,1,53,5,0.0,2,"<p>When building distributed systems, it must be ensured the client and the server eventually ends up with consistent view of the data they are operating on, i.e they never get out of sync. Extra care is needed, because network can not be considered reliable. In other words, in the case of network failure, client never knows if the operation was successful, and may decide to retry the call.</p>&#xA;&#xA;<p>Consider a microservice, which exposes simple CRUD API, and unbounded set of clients, maintained in-house by the same team, by different teams and by different companies also.</p>&#xA;&#xA;<p>In the example, client request a creation of new entity, which the microservice successfully creates and persists, but the network fails and client connection times out. The client will most probably retry, unknowingly persisting the same entity second time. Here is one possible solution to this I came up with:</p>&#xA;&#xA;<ul>&#xA;<li>Use client-generated identifier to prevent duplicate post</li>&#xA;</ul>&#xA;&#xA;<p>This could mean the primary key as it is, the half of the client and server -generated composite key, or the token issued by the service. A service would either persist the entity, or reply with OK message in the case the entity with that identifier is already present.</p>&#xA;&#xA;<p>But there is more to this: What if the client gives up after network failure (but entity got persisted), mutates it's internal view of the entity, and later decides to persist it in the service with the same id. At this point and generally, would it be reasonable for the service just silently:</p>&#xA;&#xA;<ul>&#xA;<li><em>Update</em> the existing entity with the state that client posted</li>&#xA;</ul>&#xA;&#xA;<p>Or should the service answer with some more specific status code about what happened? The point is, developer of the service couldn't really influence the client design solutions.</p>&#xA;&#xA;<p>So, what are some sensible practices to keep the state consistent across distributed systems and avoid most common pitfalls in the case of network and system failure?</p>&#xA;"
30648139,What information should be sent on body?,2015-06-04 15:32:45,<rest><microservices><trust>,1,30,0,0.0,2,"<p>I've been reading about microservices and I have some doubts about what's the data that should be sent on the body, and what's the data that should be populated in the server (by means of an id).</p>&#xA;&#xA;<p>For example, imagine that we have a real estate agency, and the domain models are agent, client and house. Imagine that for an agent to submit a deal he has to:</p>&#xA;&#xA;<ul>&#xA;<li>log in into the agency's system with his account</li>&#xA;<li>create client's profile in system</li>&#xA;<li>fill transaction form with&#xA;<ul>&#xA;<li>client data</li>&#xA;<li>house to be sold</li>&#xA;</ul></li>&#xA;<li>click on submit (this submits the data to the sales service)</li>&#xA;</ul>&#xA;&#xA;<p>Now my question is, if the sales service requires fields like client's first and last name, client's contacts, house's address and so on, should we:</p>&#xA;&#xA;<ul>&#xA;<li>send all the required data from the browser, or just the id of the house and client and the service will handle the rest?</li>&#xA;<li>if we have a restriction in the system that says that ""you can only sell houses to your clients"", how do we guarantee in the sales service that this agent is selling a house to his client (how can I trust the data that comes from the browser)?</li>&#xA;</ul>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
30739851,How can microservices be truly independent when using an ESB (i.e. MassTransit)?,2015-06-09 18:20:33,<c#><esb><servicebus><masstransit><microservices>,1,611,0,0.0,2,"<p>I'm doing some initial investigation into decomposing a current monolithic system by using MassTransit.  My main reason for going with a queue-based ESB is that the set of features I'm tackling first are using a shared database as, essentially, a queue.</p>&#xA;&#xA;<p>I've also been reading ""Building Microservices"" and while I haven't yet finished it, one of the core tenets appears to be that microservices should essentially be standalone.</p>&#xA;&#xA;<p>How can I reconcile using MassTransit which by necessity shares a message library (or at least contracts) and the fact that these services shouldn't have to ""know"" anything about each other?</p>&#xA;"
30772774,Microservices and cloud resource limitations,2015-06-11 06:01:25,<amazon-web-services><amazon-ec2><spring-cloud><microservices><amazon-elastic-beanstalk>,1,338,2,0.0,2,"<p>I am at the beginning of a large migration from a single monolithic web service to a collection of microservices using Spring Cloud/Spring Cloud Netflix. Through my research of microservices I understand that the lines of demarcation between services should mirror the separations of concerns between them. An additional factor affecting separation is which services are required to scale individually.</p>&#xA;&#xA;<p>As a concrete example, depending on the level of granularity desired, a microservice environment could end up like this:</p>&#xA;&#xA;<ul>&#xA;<li>Accounts (containing Signup, Login, Profiles, etc.)</li>&#xA;<li>Store (containing Products, Payments, Reporting, Inventories, etc.)</li>&#xA;<li>Chat/Social (containing chat rooms, user statuses, etc.)</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Or it could end up with each of the areas of concern in brackets represented by their own microservice, e.g:</p>&#xA;&#xA;<ul>&#xA;<li>Accounts</li>&#xA;<li>Signup</li>&#xA;<li>Login</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>I believe there is a preference in the microservices community for the second approach, and I tend to agree. However, the issue I have is one of hosting and resource limitations.</p>&#xA;&#xA;<p>In the migration I would like to streamline the provisioning of resources and the installation of updated services. Since we use the AWS stack, Elastic Beanstalk seemed like the perfect choice. While researching Elastic Beanstalk though I was rather disheartened to discover that there was a limit of 25 applications per account. Not only that, but EC2 has a limit of 20 instances per region per account. It seems like a microservice architecture will hit that limit very quickly, especially when you add multiple environments (staging and production) for each service into the mix, let alone websites and internal tooling.</p>&#xA;&#xA;<p>With all of the amazing content that I've seen around the web regarding microservices, I'm surprised and somewhat disappointed at the lack of information regarding the actual hosting of microservices beyond the development of them. Have I missed something? Is there any information about deploying more than a couple of microservices on AWS?</p>&#xA;&#xA;<p>It is my understanding that Netflix use AWS for their own microservice hosting, beyond requesting additional resources from Amazon and throwing money at it, are there other solutions? Would their Asgard tool help with this issue (possibly by handling the sharing of instances between services) or would it result in the same outcome?</p>&#xA;"
30649582,Normalized or Denormalized Data in Microservices and Service Composition,2015-06-04 16:43:12,<domain-driven-design><soa><composition><microservices>,3,660,2,1.0,2,"<p>So our development team has been working towards Microservices for the past 6-8 months and have picked up a lot of steam. </p>&#xA;&#xA;<p>We have experienced several <code>gotcha</code> moments in that time, and are humble enough to know that we are in for many more as we move closer to moving our platform to production.</p>&#xA;&#xA;<p>One area that I can't quite put my finger on is how we are to treat our data between our service boundaries. I hear a lot of statements form large companies that have successfully implemented Microservices, but I can never seem to get straight advice and reasoning.</p>&#xA;&#xA;<p><strong>Specifically, given two service domains  <code>User</code> and <code>Contacts</code>,and assuming that a <code>User</code> has a <code>Contact</code> object associated with it, what are the options for each of these two service domains in regards to managing their own data?</strong></p>&#xA;&#xA;<p><strong>Should the <code>User</code> have a <code>ContactID</code> stored with it, or should it store the entire <code>Contact</code> object?</strong></p>&#xA;&#xA;<p>I have seen many reliable service oriented development teams (Netflix,Amazon,Nike,etc) make statements such as the following:</p>&#xA;&#xA;<p><strong>""Normalization is the root of all evil...""</strong></p>&#xA;&#xA;<p><strong>""Break all that is shared...""</strong></p>&#xA;&#xA;<p><strong>""Share nothing...""</strong></p>&#xA;"
30732982,What's the correct way to embed a remote AngularJS application into a webpage?,2015-06-09 13:10:16,<javascript><php><angularjs><html5><microservices>,1,695,2,0.0,2,"<p>I'm trying to work out the correct way to embed an AngularJS application into another web page (served by another app). I have two apps, running on different servers:</p>&#xA;&#xA;<p>App 1 - PHP app</p>&#xA;&#xA;<p>App 2 - AngularJS app (calendar widget of sorts)</p>&#xA;&#xA;<p>The PHP app is the primary app, into which I want to embed the calendar, which is served from a remote server. I have full access to both servers, and to both apps. The idea is that I want to be able to re-use the Angular app elsewhere, so it needs to be as loosely coupled as possible to the PHP app, preferably embedded in a single line of code. </p>&#xA;&#xA;<p>I am currently using a HTML5  tag, which seems to work well, but I was wondering if there's anything wrong with this approach, or if there's a better means of doing what I'm after.</p>&#xA;&#xA;<p>I should mention that I'm happy to use a HTML5-only solution, I'm no worried about backwards compatibility with older browsers.</p>&#xA;&#xA;<p>No iFrame solutions, unless there's a REALLY valid solution. My ultimate goal is to head towards a microservice-style architecture.</p>&#xA;&#xA;<p>Thanks in advance for your help.</p>&#xA;"
29387250,RESTful Microservice failover & load balancing,2015-04-01 09:30:10,<spring-boot><load-balancing><failover><microservices>,1,1748,0,2.0,2,<p>At the moment we have some monolithic Web Applications and try to transfer the projects to an microservices infrastructure. </p>&#xA;&#xA;<p>For the monolithic application is an HAProxy and Session Replication to have failover and load balancing. </p>&#xA;&#xA;<p>Now we build some RESTful microservices with spring boot but it's not clear for me what is the best way to build the production environment. &#xA;Of course we can run all applications as unix services and still have a reverse proxy for load balancing and failover. This solution seems very heavy for me and have a lot of configuration and maintenance. Resource Management and scaling up or down servers will be always a manually process. </p>&#xA;&#xA;<p>What are the best possibilities to setup production environment with 2-3 Servers and easy resource management? &#xA;Is there some solution the also support continuous deployment?</p>&#xA;
29434226,Generating JPA entities in microservices design,2015-04-03 14:36:27,<java-ee><jpa><microservices>,1,343,5,0.0,2,"<p>I am thinking of design and bit confused with generating entities in a microservices architecture (though I am new to microservices design, but I am fascinated with multiple lean war's). I have DB and multiple war's in mind. Should I generate the entities from DB and place them in a jar, and include the jar in every war i create, OR there is another option. Secondly where I place persistence.xml. And if i plan to use cache later to cache entity instances, will above approach pose any issues. Thanks</p>&#xA;"
28387907,Push Data onto Queue vs Pull Data by Workers,2015-02-07 21:57:31,<message-queue><soa><microservices>,2,801,0,0.0,2,"<p>I am building a web site backend that involves a client submitting a request to perform some expensive (in time) operation. The expensive operation also involves gathering some set of information for it to complete.</p>&#xA;&#xA;<p>The work that the client submits can be fully described by a <code>uuid</code>. I am hoping to use a service oriented architecture (SOA) (i.e. multiple micro-services).</p>&#xA;&#xA;<p>The client communicates with the backend using RESTful communication over HTTP. I plan to use a queue that the workers performing the expensive operation can poll for work. The queue has persistence and offers decent reliability semantics.</p>&#xA;&#xA;<p>One consideration is whether I gather all of the data needed for the expensive operation upstream and then enqueue all of that data or whether I just enqueue the <code>uuid</code> and let the worker fetch the data.</p>&#xA;&#xA;<p>Here are diagrams of the two architectures under consideration:</p>&#xA;&#xA;<p><strong>Push-based (i.e. gather data upstream):</strong>&#xA;<img src=""https://i.stack.imgur.com/rxZQe.png"" alt=""Push-based (i.e. gather data upstream)""></p>&#xA;&#xA;<p><strong>Pull-based (i.e. worker gathers the data):</strong>&#xA;<img src=""https://i.stack.imgur.com/R9aJN.png"" alt=""Pull-based (i.e. worker gathers the data)""></p>&#xA;&#xA;<p>Some things that I have thought of:</p>&#xA;&#xA;<ol>&#xA;<li>In the push-based case, I would be likely be blocking while I gathered the needed data so the client's HTTP request would not be responded to until the data is gathered and then enqueued. From a UI standpoint, the request would be pending until the response comes back.</li>&#xA;<li>In the pull based scenario, only the worker needs to know what data is required for the work. That means I can have multiple types of clients talking to various backends. If the data needs change I update just the workers and not each of the upstream services.</li>&#xA;</ol>&#xA;&#xA;<p>Any thing else that I am missing here?</p>&#xA;"
28572202,Gradle + Dropwizard + Shadow -> Could not find or load main class,2015-02-17 22:18:56,<java><gradle><dropwizard><microservices>,2,1931,0,0.0,2,"<p>I'm trying to create a simple microservice using Dropwizard and Gradle as a build system. &#xA;No database, only REST endpoint to expose.</p>&#xA;&#xA;<p>So I have a controller: </p>&#xA;&#xA;<pre><code>@Path(""/domainurl/"")&#xA;@Produces(MediaType.APPLICATION_JSON)&#xA;public class SimpleController {&#xA;&#xA;    @GET&#xA;    public Example resourceExample() {&#xA;        return new Example(""something"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My application main class:</p>&#xA;&#xA;<pre><code>public class Application extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration configuration, Environment environment) throws Exception {&#xA;        final SimpleCOntroller controller = new SimpleController();&#xA;        environment.jersey().register(controller);&#xA;    }&#xA;&#xA;    public static void main(String[] args) throws Exception {&#xA;        new Application().run(args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Example is a simple value object with one string property, MyConfiguration is an empty class at this moment.</p>&#xA;&#xA;<p>And build.gradle:</p>&#xA;&#xA;<pre><code>buildscript {&#xA;    repositories {&#xA;        jcenter()&#xA;    }&#xA;&#xA;    dependencies {&#xA;        classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.0'&#xA;    }&#xA;}&#xA;&#xA;apply plugin: 'java'&#xA;apply plugin: 'groovy'&#xA;apply plugin: 'application'&#xA;apply plugin: 'com.github.johnrengelman.shadow'&#xA;&#xA;mainClassName = ""com.example.Application""&#xA;&#xA;//&#xA;dependencies&#xA;//&#xA;&#xA;run {&#xA;    args 'server', './src/config/microservice.yml'&#xA;}&#xA;&#xA;task wrapper(type: Wrapper) {&#xA;    gradleVersion = '2.1'&#xA;}&#xA;&#xA;jar {&#xA;    manifest {&#xA;        attributes 'Main-Class': mainClassName&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But after build, when I type:</p>&#xA;&#xA;<pre><code>java -jar MyApp.jar&#xA;</code></pre>&#xA;&#xA;<p>I'm still getting:</p>&#xA;&#xA;<pre><code>Error: Could not find or load main class com.example.Application&#xA;</code></pre>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
41408847,How to handle private files in a microservice,2016-12-31 13:48:21,<service><backend><microservices><data-storage>,1,219,0,0.0,2,"<p>We're working on a backend project and we've started a move to microservices development. We already have a few services in place, one of which is a FileService which stores and fetches files (using underlying Amazon S3 storage). The FileService also provides file checksum, authentication and retry mechanism and is used to share files across services and with the clients.</p>&#xA;&#xA;<p>We are now building a new service and part of this service's private data are files that the service stores and uses for its business logic, and we have a dilemma of whether we should use the FileService to store and fetch the files or handle the storage and fetching of the files internally in the service.</p>&#xA;&#xA;<p>The reason to use the FileService is we're getting all the features implemented in the service for free (retry, checksum etc).&#xA;The reason not to use it is we want the new service to be able to work autonomously and using the FileService ties the new service to it (it must handle OAuth2 authentication to fetch/upload files, it must deploy the FileService and the AuthService whenever this services is deployed etc).</p>&#xA;&#xA;<p>I wanted to know if someone has best practices for storing private files in a microservices environment, and what is the best approach to it with the pros and cons.</p>&#xA;"
41400158,Bitnami and Docker,2016-12-30 17:26:04,<docker><cloud><microservices><bitnami>,1,1792,1,0.0,2,"<p>How Bitnami and Docker are different from each other when it comes to container based deployments.</p>&#xA;&#xA;<p>I have been learning about microservices recently. I used Docker images to run my apps as containers. And, I noticed that Bitnami does something similar when it creates a virtual image on a cloud form its launchpad.</p>&#xA;&#xA;<p>From whatever links I could see on Internet, I could not visualize how these two - Docker and Bitnami - are different from each other.</p>&#xA;"
41285879,Microservice and RabbitMQ,2016-12-22 14:53:49,<asp.net-web-api><architecture><rabbitmq><microservices><easynetq>,3,711,2,2.0,2,"<p>I am new to Microservices and have a question with RabbitMQ / EasyNetQ. &#xA;I am sending messages from one microservice to another microservice.</p>&#xA;&#xA;<p> Each Microservice are Web API's. I am using CQRS where my Command Handler would consume message off the Queue and do some business logic. In order to call the handler, it will need to make a request to the API method. </p>&#xA;&#xA;<p>I would like to know without having to explicit call the API endpoint to hit the code for consuming messages. Is there an automated way of doing it without having to call the API endpoint ? &#xA;<p> Suggestion could be creating a separate solution which would be a Console App that will execute the RabbitMQ in order to start listening. Create a while loop to read messages, then call the web api endpoint to handle business logic every time a new message is sent to the queue. </p>&#xA;&#xA;<p>My aim is to create a listener or a startup task where once messages are in the queue it will automatically pick it up from the Queue and continue with command handler but not sure how to do the ""Automatic"" way as i describe it. I was thinking to utilise Azure Webjob that will continuously be running and it will act as the Consumer.&#xA;<br>Looking for a good architectural way of doing it. &#xA;<p> Programming language being used is C#  </p>&#xA;&#xA;<p>Much Appreciated</p>&#xA;"
49051663,How to authenticate and authorize different profiles in a microservices and API Gateway architecture,2018-03-01 14:18:59,<architecture><oauth-2.0><asp.net-identity><microservices><api-gateway>,1,89,0,0.0,2,"<p>I want to build a microservices architecture. It's supposed to have 13 microservices and 3 clients (2 web and 1 mobile).</p>&#xA;&#xA;<p>In our scenario we have:</p>&#xA;&#xA;<ul>&#xA;<li>Employees: Access to specific and shared services and their credentials are stored in Active Directory;</li>&#xA;<li>Administrators: They are employees with full access. They have specific and shared services and their credentials are stored in Active Directory;</li>&#xA;<li>Customers: Access to specific and shared services and their credentials are stored in the Identity microservice.</li>&#xA;</ul>&#xA;&#xA;<p>We're going to have an API Gateway.</p>&#xA;&#xA;<p>Every request is handled by API Gateway which should (or invoke the responsible for) check if the token of the request is valid, identify if it is a customer, employee or admin and check if this user has permission to access request API/microservice.</p>&#xA;&#xA;<p>I have some misconceptions about this solution, so I'd appreciate some help for:</p>&#xA;&#xA;<ul>&#xA;<li>What are API Gateway responsibilities?</li>&#xA;<li>What are Identity microservice responsibilities?</li>&#xA;<li>How to manage to define which APIs/microservices can an employee, a customer and an admin can access or not?</li>&#xA;<li>How to identify if given user is a customer, an employee or an admin?</li>&#xA;</ul>&#xA;"
30237292,Is the Microservices architectural Pattern similar to EJB 1.0?,2015-05-14 12:22:28,<ejb><components><microservices>,2,1834,0,0.0,2,"<p>What we see with microservices is an isolated component, communicating over a protocol over the wire to a parent consumer of that component. </p>&#xA;&#xA;<p>We see a very similar pattern with EJB 1.0. </p>&#xA;&#xA;<p>My question is: <strong>Is the Microservices architectural Pattern similar to EJB 1.0?</strong></p>&#xA;"
33763271,Consul/Registrator architecture - do I need a separate Consul agent on each VM?,2015-11-17 17:26:21,<docker><vagrant><microservices><consul>,1,344,0,1.0,2,"<p>I'm trying to use Consul and Registrator to pick up microservices in various VMs but I think I'm not quite getting something.  I understand that Registrator auto-registers containers with Consul.  So I was thinking that I'd have one VM that runs Consul, and then for each microservice I'd have a VM with Registrator + the microservice.</p>&#xA;&#xA;<p>However, I'm unable to get Registrator to talk to the Consul agent in a separate VM.  Looking more closely at suggested architecture, it seems that I need a separate Consul agent on each VM.  Am I understanding that right?  If so, why?  Shouldn't Registrator just be able to forward the container info to a Consul agent on any VM?</p>&#xA;&#xA;<p>Also, do I need to run Registrator on the VM with the Consul agent and servers?</p>&#xA;"
33814080,Microservices with many repositories out of date,2015-11-19 20:47:51,<github><teamcity><microservices><octopus-deploy><devops>,2,220,3,1.0,2,<p>In a microservices architecture what is the best strategy for keeping many developer environments up-to-date across multiple source code repositories?</p>&#xA;&#xA;<p>Suppose there were 10 teams of 10 developers working on 200 microservices in git. Every developer would need to pull regularly from every repository. This could be done with scripts but is there a better way? Are we doing this wrong because it seems like a heavy overhead.</p>&#xA;
33712470,Api naming in microservices design,2015-11-14 19:34:07,<rest><design><microservices>,2,1342,4,0.0,2,"<p>Let's say that there are two microservices representing the resources orders(/orders) and customers(/customers). My requirement is to get all the orders made by a customer. &#xA;Had it been a monolithic application, I would have modeled my uri as /customers/{id}/orders. This would have hit the customers resource and made an in-memory service call to get the corresponding orders. &#xA;Now, in case of microservices, this isn't possible. So, is the only way to get the orders is to make a remote service call or is there a better way of doing it?&#xA;Can we create another resource with the representation /ordersByCustomers/{customerid}?</p>&#xA;"
52051459,"Jhipster - unable to Use a Gateway app when deploying everything on docker host except the Gateway itself, Mixed Docker and locally deployment",2018-08-28 06:30:31,<docker><microservices><jhipster><keycloak><gateway>,1,31,0,2.0,2,"<p>I have some JHipster Spring Microservice and gateway projects. I deployed all of them on a host using docker except the gateway. I started the gateway on another host.</p>&#xA;&#xA;<p>I use Keycloak for OAuth authentication.</p>&#xA;&#xA;<p>Everything works fine when i deploy all of the microservices and databases and Gateways as docker containers on a docker network using docker-compose.</p>&#xA;&#xA;<p>But it doesn't work when i just deploy everything on docker except the gateway.i mean if the gateway resides outside of docker-created network. the motivation for this action is that I just want my UI programmer to up and run the gateway on his own PC, and use microservices which are deployed on server host. Just for ease of UI development in need to up and run this sole gateway using <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>I used a technique to assign a separate IP to each container on my docker network. This technique is called Docker MacVLan networking. so that every container in the host have a separate IP address in physical network and each of these containers are visible on other hosts in the network.</p>&#xA;&#xA;<p>the problem is that in normal docker deployment (when gateway is deployed in a docker network in same host) everything works fine. but in my scenario after successful login, every microservice return <code>error 401</code>.</p>&#xA;&#xA;<p>in microservice it says this error:</p>&#xA;&#xA;<pre><code>o.s.s.oauth2.client.OAuth2RestTemplate   : Setting request Accept header to [application/json, application/x-jackson-smile, application/cbor, application/*+json]&#xA;o.s.s.oauth2.client.OAuth2RestTemplate   : GET request for ""http://keycloak:9080/auth/realms/jhipster/protocol/openid-connect/userinfo"" resulted in 401 (Unauthorized); invoking error handler&#xA;n.m.b.s.o.CachedUserInfoTokenServices    : Could not fetch user details: class org.springframework.security.oauth2.client.resource.OAuth2AccessDeniedException, Unable to obtain a new access token for resource 'null'. The provider manager is not configured to support it.&#xA;p.a.OAuth2AuthenticationProcessingFilter : Authentication request failed: error=""invalid_token"", error_description=""token string here""&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/C7MwY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/C7MwY.png"" alt=""SSO 401 is Happening""></a></p>&#xA;&#xA;<p>it says that your token is invalid. the same mechanism just works when everything is deployed in same host in docker. is it for the Keycloak that prevents the token to validate for external hosts? i personally doubt that , because it didn't prevent me from logging into gateway successfully. and i just checked keycloak. its up by the command <code>-b 0.0.0.0</code></p>&#xA;&#xA;<p>Please help me up and run a gateway just by <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>In summary I could rephrase my question to: <strong><em>i just want the UI Developer be able to test his angular/spring-gateway project in it's own PC while other services are deployed in powerful server using docker</em></strong> (authentication using <strong><em>Keycloak</em></strong>). and it is not possible to deploy those other services on UI developers own PC. how to do it in JHipster?</p>&#xA;"
51946603,What is the best approach or design pattern to call multiple microservices several times from a single service?,2018-08-21 10:24:54,<java><spring-mvc><spring-boot><microservices>,1,77,1,0.0,2,"<p>Microservice A has dependency on Microservice B &amp;C. When client calls a certain endpoint on service A, that will cause multiple HTTP requests to services B &amp; C from A to get the dependent details. What would be the optimal, performance effective design pattern or approach to handle this scenario simultaneously?</p>&#xA;&#xA;<p>NB : We are not using API gateway in this case.</p>&#xA;"
51976057,Microservices architecture and MySQL database pagination,2018-08-22 22:32:57,<javascript><mysql><node.js><amazon-web-services><microservices>,2,103,2,2.0,2,"<p>So imagine, I want to retrieve all orders for an array of customers.&#xA;The <code>arrayList</code> in the example below will have an array of customer IDs.</p>&#xA;&#xA;<p>This array will be passed into the <code>get</code> method below and processed asynchronously retrieving orders for each customer ID in the array.</p>&#xA;&#xA;<p>Here's where I get lost. How can you paginate the database result set and pull only a small set of records at a time from the database without bring having to pull all the records across the network.</p>&#xA;&#xA;<p>What's confusing me is the asynchronous nature as well as we won't know how many orders per customer there are? So how can you efficiently return a set page size at a time?</p>&#xA;&#xA;<p><strong>service.js</strong></p>&#xA;&#xA;<pre><code>function callToAnotherService(id) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        //calls service passing id&#xA;    }&#xA;}&#xA;&#xA;exports.get = arrayList =&gt; Promise.all(arrayList.map(callToAnotherService))&#xA;    .then((result) =&gt; result);&#xA;</code></pre>&#xA;"
36876367,Cloud Service to Service Fabric authentication?,2016-04-26 21:47:08,<c#><azure><microservices><azure-service-fabric>,1,1084,0,1.0,2,<p>What's the recommended way to authorize service-to-service traffic in Service Fabric?</p>&#xA;&#xA;<p>I have a Classic Cloud Service that I'd like to have call a Web API endpoint in a service fabric service. Is there a way to open up specific ports to specific IPs in a service fabric cluster? Or is there a better way to make sure my service fabric endpoints can not be called from the outside internet?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
36877722,Microservices per DB table?,2016-04-26 23:41:28,<microservices>,1,631,4,0.0,2,"<ul>&#xA;<li>Person</li>&#xA;<li>NativeCountry</li>&#xA;<li>SpokenLanguages</li>&#xA;</ul>&#xA;&#xA;<p>Had a query about MIcroservice granularity. Will try to explain my query with an example.</p>&#xA;&#xA;<p>Assume I have above 3 tables in database, with Many to one relationship between Person -> NativeCountry table. One to Many relationship between person -> LanguagesSpoken in database.</p>&#xA;&#xA;<p>Front end Application is suppose do CRUD operation on person entity and will also have capability to retrieve people based on nativecountry or spokenlanguage.</p>&#xA;&#xA;<p>Does it makes sense to develop 3 independent microservices for each of the entities and then use Aggregator Microservice at upper layer to build combined data for UX layer or I should think of combining those to build just single microservice?</p>&#xA;"
35135884,Transaction when inter-communicate microservices,2016-02-01 16:50:41,<java><hibernate><transactions><akka><microservices>,2,191,0,1.0,2,"<p>I'm looking for best approach to keep data consistent while inter-communicate between microservices in my project.</p>&#xA;&#xA;<p>Project built with Jersey + Guice and uses Akka to glue services in whole system. I use separate transaction across call to another service to avoid long-running transactions. I use Hibernate as ORM and Postgres as DB.&#xA;Process looks like:</p>&#xA;&#xA;<ol>&#xA;<li>Begin transaction</li>&#xA;<li>Do some work</li>&#xA;<li>Commit transaction</li>&#xA;<li>Call to another service using Akka, receive or send some data</li>&#xA;<li>Begin transaction</li>&#xA;<li>Do remaining work</li>&#xA;<li>Commit transaction</li>&#xA;</ol>&#xA;&#xA;<p>So if step 4 failed my data becomes in non consistent state. I spent some hours to find solution to avoid it but I was failed. Is there some right way to keep it in consistent state?</p>&#xA;"
35140042,Django or Flask or Falcon for Microservices,2016-02-01 20:49:21,<django><flask><architecture><microservices><falconframework>,1,3874,2,1.0,2,"<p>Why is Microservice Architecture better than monolithic architecture? I know the answer will be because the microservice architecture is more scalable and each service is independent of each other etc.</p>&#xA;&#xA;<p>My following question is: should we build using Flask or Django REST Framework?</p>&#xA;&#xA;<p>I have also heard of a framework know as <a href=""http://falconframework.org"" rel=""nofollow"">Falcon</a> as per there documentation seems good enough.</p>&#xA;"
32996097,Single Sign On + Microservices,2015-10-07 15:17:12,<java><spring><oauth-2.0><microservices>,1,654,0,2.0,2,"<p>I have a couple web apps which I will try to convert in microservices (In the future maybe I will have more). Before this, I would like to create a microservice for authentication and authorization which permits SSO.</p>&#xA;&#xA;<p>I read a lot about <a href=""http://jasig.github.io/cas/4.1.x/index.html"" rel=""nofollow"">CAS</a> but I have the feeling that seems an old solution and I don't know if it is a good idea for microservices' architecture.</p>&#xA;&#xA;<p>On the other hand I have been researching about Oauth2, I know it is only for authorizations (but you need to be authenticated for that) so.. maybe it could be a good option. Also I have found a good guide for implement <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow"">Oauth2 SSO with Spring</a>. However Oauth2 is for third-party so.. neither know if it is the best solution.</p>&#xA;&#xA;<p>As you see, I'm a bit confused . Other terms and tecnologies are in my head like SAML, OpenId... But I don't know which choose.</p>&#xA;"
34676168,Geo mapping with stateful actors,2016-01-08 11:36:16,<azure><events><geolocation><microservices><azure-service-fabric>,1,99,0,0.0,2,"<p>Can I use Azure Service Fabric reliable stateful actors for geo mapping issues? Let's say I have an actor representing an event. This event is created by a user, who set such an event on a map. A lot of users can create a lot of events. Each event representing actor stores a geo coordinate and one another state. That will cause I can have millions of events distributed over a map.</p>&#xA;&#xA;<p>So now I want have a grouping actor representing event actors based on an area of the map, or based on a rectangle of coordinates. The grouping actor stores a list of all event actors in this map area. In view of performance issues, is it possible and recommended to create dynamically such a grouping actor? The area will be determined by user input.</p>&#xA;"
34578641,Is there a real need to adopt ssl transport layer in a microservice architecture for internal lan-only Service to Service communication?,2016-01-03 16:13:29,<ssl><https><microservices>,1,1355,1,0.0,2,<p>In a scenario where there are thousands of webservices are there reasons to use also a signed cert for each microservice or it's just going to add overhead? Services communicate via VPC sitting behind a firewall while Public endpoints are behind a nginx public facing a valid CA cert.</p>&#xA;&#xA;<p>Services are on multiple servers on aws.</p>&#xA;
35928639,Clojure name binding to REST JSON data,2016-03-10 22:29:44,<json><rest><clojure><microservices>,1,193,0,0.0,2,"<p>I'm a Frontend Engineer, our team is switching many of our old services to micro services written in clojure.  The main issue I'm seeing is that clojure naming conventions prefer hyphens to-separate-words in variable names. This means if you straight map variables into JSON any JS consumer would need to access this data using bracket notation e.g. response['to-separate-words']. This is obviously not ideal.  I thought this would be a easy best practice to lookup but I've been looking for an hour and it seems like all the docs I read avoid this issue but using single words.  Has anyone else dealt with this. </p>&#xA;"
32889746,Erlang intra clusters communication,2015-10-01 14:10:48,<erlang><cluster-computing><elixir><riak><microservices>,1,236,1,0.0,2,"<p>In Erlang, a cluster of connected machines has some soft limitations on how many machines you can have without suffering from too many messages being sent for the gossip protocol to work properly. </p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/13212007/erlang-clusters"">This question</a> has similar statements. I have also seen some benchmarks of Riak running ok with 200 nodes (can't find the link but I think it was a Basho test).</p>&#xA;&#xA;<p>I understand that a 200 Erlang node cluster is capable of <strong>REALLY</strong> heavy loads. I am just wondering on alternatives if that limit becomes a bottleneck.</p>&#xA;&#xA;<p>It seems the answer to a bigger scale than that (which would be huge) is to isolate your system in smaller isolated clusters, much like a micro services approach. </p>&#xA;&#xA;<p>My question is: <em>which is the recommended way of making this communication?</em> </p>&#xA;&#xA;<p>I don't want to come up with a REST service because of the unnecessary weight of marshling/unmarshiling JSON, HTTPS handshakes and other protocol bound operations (load balancers and etc).</p>&#xA;&#xA;<p><a href=""http://bert-rpc.org/"" rel=""nofollow noreferrer"">BERT-RPC</a> seemed like the best fit but its development seems stale. <a href=""https://github.com/Nekso/nkcluster"" rel=""nofollow noreferrer"">NkCluster</a> seems to have implemented something similar but is there an Erlang/Elixir/Joxa/LFE way of doing this?</p>&#xA;"
32863771,SpringBoot RestController generic POST type,2015-09-30 10:27:41,<java><spring><rest><spring-boot><microservices>,2,1908,2,1.0,2,"<p>I'm experimenting with building microservices using Spring Boot.</p>&#xA;&#xA;<p>I have a back-end API that receives ResponseEntity POST requests and processes it (saving to database etc). Where Data is an Object of a self-created class.</p>&#xA;&#xA;<p>Now I have a top-level API (that handles authentication,..). The end-users will communicate with the back-end services through this top-level API. So this API basically just has to forward all the requests to the right back-end api's.</p>&#xA;&#xA;<p>In this top API I don't want to need to include all my classes (e.g. the Data class in this case) and I would rather just send it as String json data or something. So I tried this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;    ResponseEntity&lt;String&gt; createUnit(@RequestBody String data) {&#xA;        URI uri = util.getServiceUrl(""dataservice"");&#xA;        String url = uri.toString() + ""/data"";&#xA;&#xA;        ResponseEntity&lt;String&gt; result = restTemplate.postForEntity(url, data, String.class);&#xA;        return new ResponseEntity&lt;String&gt;(result.getBody(), HttpStatus.OK);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>But this results in an <code>org.springframework.web.client.HttpClientErrorException: 415 Unsupported Media Type</code>. </p>&#xA;&#xA;<p>So my question is, is there a way to forward these requests to my back-end without the need to include all my Object classes in my API? I figured this should be able since this is the same as when a web-browser sends requests in json format without knowing what kind of Object the data actually is.</p>&#xA;&#xA;<p>The back-end handling looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;ResponseEntity&lt;Data&gt; saveData(@RequestBody Data data) {&#xA;    //Some code that processes the data&#xA;    return new ResponseEntity&lt;Data&gt;(dataProcessed, HttpStatus.OK);&#xA;}&#xA;</code></pre>&#xA;"
32887039,How to implement HATEOAS in a Spring-Boot microservices project,2015-10-01 11:56:39,<java><spring><rest><microservices><spring-hateoas>,1,488,5,0.0,2,"<p>Lately I've been experimenting with building <strong>microservices</strong> using the Java <strong>Spring Boot</strong> framework. I currently have a working Microservices systeem with several resources (which all have its own independent service), e.g.: A Book service and a Review service.&#xA;Each service has its own <strong>RestController</strong> and uses a <strong>MongoRepository</strong> to interact with its database.</p>&#xA;&#xA;<p>The end-users of the application (web-clients) will not communicate with these independent services itself but with an API above them.</p>&#xA;&#xA;<p>This API calls the book and review services, merges the data and returns it back to the client. Note that all the communication is using <code>ResponseEntity&lt;T&gt;</code> (<code>T</code> can be <code>Book</code>, <code>Review</code>, <code>Iterable&lt;Book&gt;</code>, etc, ..)</p>&#xA;&#xA;<p>But after reading a while I learnt about <strong>HATEOAS</strong> and I would like to use it in my microservices set-up. Now my question is, what is the best way to implement this?</p>&#xA;&#xA;<p>Some examples I've found extend the entity classes (which in my case would be the Book entity or the Review entity with Spring's <code>ResourceSupport</code> class). But this causes errors since my entity's have an ID parameter and the <code>getId()</code> method clashes with the <code>getId()</code> method of the ResourceSupport class. </p>&#xA;&#xA;<p>Other examples contain a <code>MongoRepository</code> annotated with <code>@RestResource</code> instead of using a <strong>Controller</strong>.</p>&#xA;&#xA;<p>So my question is, what would in this case be the best way to implement HATEOAS? And e.g. when the Book service adds links (the HATEOAS way), how can the API above change these links? Since the end-users will only do calls to this API and the API just processes these requests and delegates it to the necesarry sub-services.</p>&#xA;"
34316241,Realtime connection (SockJS/Socket.io) and Microservice application,2015-12-16 15:44:51,<session><socket.io><real-time><microservices><sockjs>,1,340,2,0.0,2,"<p>Currently I'm building an application in a micro service architecture.</p>&#xA;&#xA;<p>The first application is an <strong>API</strong> that does the user authentication, receive requests to initiate/keep a realtime connection with the user (via Socket.io or SockJS) and the system store the socket id into the User object.</p>&#xA;&#xA;<p>The second application is a <strong>WORKER</strong> doing some stuff and sometime he has to send realtime data to the user.</p>&#xA;&#xA;<p>The question is: How should the second application (the <strong>WORKER</strong>) send realtime data to the user? </p>&#xA;&#xA;<p>Should the <strong>WORKER</strong> send a message to the API then the <strong>API</strong> forward this message to the user? &#xA;Or the <strong>WORKER</strong> can directly send the message to the user? </p>&#xA;&#xA;<p>Thank you</p>&#xA;"
34498033,"What does ""There are no namespaces currently available."" on the fabric8 console mean?",2015-12-28 17:35:18,<kubernetes><microservices><fabric8>,1,354,0,0.0,2,"<p>I just completed the instructions given <a href=""http://fabric8.io/guide/getStarted/gke.html"" rel=""nofollow noreferrer"">here</a> on how to install fabric8 on Google Compute Engine.</p>&#xA;&#xA;<p>Here's what connecting to the console gets me:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/wyWGb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wyWGb.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What does it mean? Where do I go from here?</p>&#xA;"
34450732,microservices bounded context in distributed analytics,2015-12-24 09:49:05,<architecture><microservices>,1,121,0,1.0,2,"<p>In our current system, we are slicing several services that in the past were a single monolith application into a independent services.</p>&#xA;&#xA;<p>We have a pretty standard architecture in the analytics side (similar to lambda):</p>&#xA;&#xA;<ul>&#xA;<li>A front-end service that parses the HTTP requests and pushes them to the stream.</li>&#xA;<li>A consumer service that build the roll-ups for each kind of event and calling to the database directly (for performance reasons, mostly).</li>&#xA;<li>A reporting service that reads each rolled-up table and returns meaningful data</li>&#xA;<li>A data curation service that every N hours runs batch jobs that reads the data and samples it, deletes non useful rows and short-lived data/reports, etc.</li>&#xA;</ul>&#xA;&#xA;<p>The architecture is something like the following diagram:&#xA;<a href=""https://i.stack.imgur.com/84aQQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/84aQQ.png"" alt=""http://i.stack.imgur.com/84aQQ.png""></a></p>&#xA;&#xA;<p>Since the consumer and the reporting service are using the same tables we are breaking the bounded context and we are following an anti-pattern here, because each time we need to do a schema change we need to deploy the consumer (the service that creates the data) and the reporting (the service that reads the data) at the ""same time"". And then we may have to deploy the curation service too.</p>&#xA;&#xA;<p>The only way I'm able to come up with to follow the bounded context rule is expose a method on the reporting service to build the roll-ups based on the consumer calls parameters. And the same for the curation service, exposing the curation methods in the reporting service. Transforming this ""reporting service"" in some kind of god service.</p>&#xA;&#xA;<p>The huge downside of this solution is that it makes impossible to predict latencies for reporting, since the same box could be performing a batch job, creating tons of roll-ups and calculating the reports because the service will have multiple responsibilities.</p>&#xA;&#xA;<p>Is there a way to architect this three services (consumer, reporting, curation) to be loosely coupled and don't depend directly on the database integration between them?</p>&#xA;"
34439201,Java Spring will not talk to Consul when run as a Docker container,2015-12-23 15:46:51,<java><docker><spring-cloud><microservices><consul>,2,1970,1,1.0,2,"<p>I am trying to solve what I believe is a common use case for running micro services.  In this case I am testing consul with a spring cloud application. I am trying to test consul in two different ways.  The first of which is running in a docker container and the other is running on the docker host machine.  I am then attempting to start a spring cloud container that will talk with either consul example.</p>&#xA;&#xA;<p>I have been unable to make the spring cloud application talk to consul when the spring cloud application is run as a docker container.  When the spring cloud application is run with the host networking mode it works as it can resolve the localhost ports, but this is not an acceptable solution if I wish to run multiple instances of the image.  </p>&#xA;&#xA;<p>An example of my docker compose file when running both services as containers is shown below. Here I am attempting to set the consul uri in spring cloud through the environment variables, but have been unable to get it to work using a variety of configurations.  If anyone could point to an example of these functions working together that would be immensely helpful.</p>&#xA;&#xA;<pre><code> consul1:&#xA;  image: progrium/consul&#xA;  ports:&#xA;    - ""8400:8400""&#xA;    - ""8500:8500""&#xA;    - ""8600:53/udp""&#xA;    - ""8600:53/tcp""&#xA;  environment:&#xA;      GOMAXPROCS: 100&#xA;      entrypoint: ""/bin/consul""&#xA;      hostname: consul&#xA;      command: agent -log-level=debug -server -config-dir=/config -bootstrap -ui-dir /ui&#xA;&#xA;simpletest:&#xA;    build: simpletest&#xA;    hostname: simpletest&#xA;    environment:  &#xA;      JAVA_OPTS: ""-Xdebug -Xrunjdwp:server=y,transport=dt_socket,suspend=n -Dspring.cloud.consul.host=consul1""&#xA;    ports:&#xA;     - 39041:7051&#xA;     - 39052:7055&#xA;#     d2fdockerroot_consul1_1 consul&#xA;#    links:&#xA;#     - consul1&#xA;</code></pre>&#xA;"
34357893,Netflix hystrix shared request caching,2015-12-18 14:31:46,<caching><spring-cloud><microservices><netflix><hystrix>,1,469,0,0.0,2,"<p>I'm using spring cloud based on Netflix OSS architecture. I need to cache results of one of my methods which is using Get-Set-Get pattern.</p>&#xA;&#xA;<pre><code> public class UserService {    &#xA;    @CacheResult&#xA;    @HystrixCommand&#xA;    public User getUserById(@CacheKey String id) { // GET&#xA;        return storage.get(id);&#xA;    }&#xA;&#xA;    @CacheRemove(commandKey = ""getUserById"")&#xA;    @HystrixCommand&#xA;    public void update(@CacheKey(""id"") User user) { // SET&#xA;        storage.put(user.getId(), user);&#xA;    }&#xA;}    &#xA;</code></pre>&#xA;&#xA;<p>Now my question is pretty simple. I need to know can I have a distributed cache if I've multiple instances of this service running? If yes, can I use something like Redis if the size grows?</p>&#xA;"
34406896,How to share code between micro services?,2015-12-22 00:57:07,<architecture><microservices>,2,1258,3,1.0,2,"<p>For example, I have a project which has 4 micro services: client-web, admin-web, client-api, admin-api.</p>&#xA;&#xA;<p>These four micro services should share one DB code,  should I make the DB code as a submodule of git and use it in each micro service?</p>&#xA;&#xA;<p>does it against micro service principle? </p>&#xA;"
39428356,jHipster fails to generate Gateway Docker Images,2016-09-10 16:47:06,<docker><jhipster><microservices>,1,278,0,0.0,2,"<p>jHipster fails to generate Gateway Docker Images.</p>&#xA;&#xA;<p>I have successfully built the micorservice application, but while making the microservice gateway, I encounter an ERROR [karma] in Running 'gulp.js test --no-notification'. I have tried many hours to resolve but failed to find out the source of two errors:</p>&#xA;&#xA;<ol>&#xA;<li>[Error: spawn EACCES] code: 'EACCES', errno: 'EACCES', syscall: 'spawn'. </li>&#xA;<li>at formatError (/Users/Emac/microservices/gateway/node_modules/gulp/bin/gulp.js:169:10)</li>&#xA;</ol>&#xA;&#xA;<p>Please anyone can help?</p>&#xA;&#xA;<p>On Mac OSX 10.11.6, using jHipster 3.6.1, the the micorservice gateway is also done (JWT, SQL, MySQL, H2, HazelCast, ElasticSearch, International, Gatling and Protractor).</p>&#xA;&#xA;<p>.........&#xA;AFter having done npm install and bower install, proceed to build docker images:</p>&#xA;&#xA;<p>Emacs-MacBook-Pro:gateway Emac$ ./mvnw -Pprod package docker:build</p>&#xA;&#xA;<pre><code>[INFO] Scanning for projects...&#xA;[INFO]                                                                         &#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building Gateway 0.0.1-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] &#xA;[INFO] --- maven-resources-plugin:3.0.1:copy-resources (default-resources) @ gateway ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 8 resources&#xA;[INFO] Copying 17 resources&#xA;[INFO] &#xA;[INFO] --- maven-resources-plugin:3.0.1:resources (default-resources) @ gateway ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 8 resources&#xA;[INFO] Copying 17 resources&#xA;[INFO] &#xA;[INFO] --- maven-enforcer-plugin:1.4.1:enforce (enforce-versions) @ gateway ---&#xA;[INFO] &#xA;[INFO] --- jacoco-maven-plugin:0.7.7.201606060606:prepare-agent (pre-unit-tests) @ gateway ---&#xA;[INFO] surefireArgLine set to -javaagent:/Users/Emac/.m2/repository/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606-runtime.jar=destfile=/Users/Emac/microservices/gateway/target/test-results/coverage/jacoco/jacoco.exec&#xA;[INFO] &#xA;[INFO] --- maven-processor-plugin:2.2.4:process (process) @ gateway ---&#xA;[INFO] &#xA;[INFO] --- frontend-maven-plugin:1.0:install-node-and-npm (install node and npm) @ gateway ---&#xA;[INFO] Installing node version v4.4.7&#xA;[INFO] Unpacking /Users/Emac/.m2/repository/com/github/eirslett/node/4.4.7/node-4.4.7-darwin-x64.tar.gz into /Users/Emac/microservices/gateway/node/tmp&#xA;[INFO] Copying node binary from /Users/Emac/microservices/gateway/node/tmp/node-v4.4.7-darwin-x64/bin/node to /Users/Emac/microservices/gateway/node/node&#xA;[INFO] Installed node locally.&#xA;[INFO] Installing npm version 3.10.5&#xA;[INFO] Unpacking /Users/Emac/.m2/repository/com/github/eirslett/npm/3.10.5/npm-3.10.5.tar.gz into /Users/Emac/microservices/gateway/node/node_modules&#xA;[INFO] Installed npm locally.&#xA;[INFO] &#xA;[INFO] --- frontend-maven-plugin:1.0:npm (npm install) @ gateway ---&#xA;[INFO] Running 'npm install' in /Users/Emac/microservices/gateway&#xA;[INFO] &#xA;[INFO] &gt; gateway@0.0.0 postinstall /Users/Emac/microservices/gateway&#xA;[INFO] &gt; webdriver-manager update&#xA;[INFO] &#xA;[INFO] [22:37:12] I/update - selenium standalone: file exists /Users/Emac/microservices/gateway/node_modules/protractor/node_modules/webdriver-manager/selenium/selenium-server-standalone-2.53.1.jar&#xA;[INFO] [22:37:12] I/update - selenium standalone: v2.53.1 up to date&#xA;[INFO] [22:37:12] I/update - chromedriver: file exists /Users/Emac/microservices/gateway/node_modules/protractor/node_modules/webdriver-manager/selenium/chromedriver_2.22mac32.zip&#xA;[INFO] [22:37:13] I/update - chromedriver: unzipping chromedriver_2.22mac32.zip&#xA;[INFO] [22:37:14] I/update - chromedriver: setting permissions to 0755 for /Users/Emac/microservices/gateway/node_modules/protractor/node_modules/webdriver-manager/selenium/chromedriver_2.22&#xA;[INFO] [22:37:14] I/update - chromedriver: v2.22 up to date&#xA;[INFO] &#xA;[INFO] --- frontend-maven-plugin:1.0:bower (bower install) @ gateway ---&#xA;[INFO] Running 'bower install --no-color' in /Users/Emac/microservices/gateway&#xA;[INFO] &#xA;[INFO] --- frontend-maven-plugin:1.0:gulp (gulp build) @ gateway ---&#xA;[INFO] Running 'gulp.js build --no-notification' in /Users/Emac/microservices/gateway&#xA;[INFO] [22:38:18] Using gulpfile ~/microservices/gateway/gulpfile.js&#xA;[INFO] [22:38:18] Starting 'clean'...&#xA;[INFO] [22:38:18] Finished 'clean' after 7.82 ms&#xA;[INFO] [22:38:18] Starting 'build'...&#xA;[INFO] [22:38:18] Starting 'copy:i18n'...&#xA;[INFO] [22:38:18] Starting 'copy:fonts'...&#xA;[INFO] [22:38:18] Starting 'copy:common'...&#xA;[INFO] [22:38:18] Starting 'inject:vendor'...&#xA;[INFO] [22:38:19] Starting 'ngconstant:prod'...&#xA;[INFO] [22:38:19] Starting 'copy:languages'...&#xA;[INFO] [22:38:19] Finished 'ngconstant:prod' after 320 ms&#xA;[INFO] [22:38:19] Finished 'copy:languages' after 196 ms&#xA;[INFO] [22:38:19] Finished 'copy:common' after 415 ms&#xA;[INFO] [22:38:19] gulp-inject 23 files into index.html.&#xA;[INFO] [22:38:19] Finished 'inject:vendor' after 438 ms&#xA;[INFO] [22:38:19] Finished 'copy:fonts' after 516 ms&#xA;[INFO] [22:38:19] Finished 'copy:i18n' after 594 ms&#xA;[INFO] [22:38:19] Starting 'copy'...&#xA;[INFO] [22:38:19] Finished 'copy' after 19 Î¼s&#xA;[INFO] [22:38:19] Starting 'inject:app'...&#xA;[INFO] [22:38:20] gulp-inject 103 files into index.html.&#xA;[INFO] [22:38:20] Finished 'inject:app' after 564 ms&#xA;[INFO] [22:38:20] Starting 'inject:troubleshoot'...&#xA;[INFO] [22:38:20] gulp-inject 1 files into index.html.&#xA;[INFO] [22:38:20] Finished 'inject:troubleshoot' after 51 ms&#xA;[INFO] [22:38:20] Starting 'images'...&#xA;[INFO] [22:38:20] Starting 'styles'...&#xA;[INFO] [22:38:20] Starting 'html'...&#xA;[INFO] [22:38:20] Starting 'copy:swagger'...&#xA;[INFO] [22:38:20] Starting 'copy:images'...&#xA;[INFO] [22:38:20] Finished 'copy:images' after 28 ms&#xA;[INFO] [22:38:20] Finished 'styles' after 70 ms&#xA;[INFO] [22:38:20] Finished 'html' after 726 ms&#xA;[INFO] [22:38:20] Finished 'copy:swagger' after 754 ms&#xA;[INFO] [22:38:21] gulp-imagemin: Minified 3 images (saved 0 B - 0%)&#xA;[INFO] [22:38:21] Finished 'images' after 1.49 s&#xA;[INFO] [22:38:21] Starting 'assets:prod'...&#xA;[INFO] [22:38:44] Finished 'assets:prod' after 23 s&#xA;[INFO] [22:38:44] Finished 'build' after 26 s&#xA;[INFO] &#xA;[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ gateway ---&#xA;[INFO] Changes detected - recompiling the module!&#xA;[INFO] Compiling 104 source files to /Users/Emac/microservices/gateway/target/classes&#xA;[WARNING] /Users/Emac/microservices/gateway/src/main/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilter.java: /Users/Emac/microservices/gateway/src/main/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilter.java uses or overrides a deprecated API.&#xA;[WARNING] /Users/Emac/microservices/gateway/src/main/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilter.java: Recompile with -Xlint:deprecation for details.&#xA;[WARNING] /Users/Emac/microservices/gateway/src/main/java/com/emodak/buji/gateway/TokenRelayFilter.java: Some input files use unchecked or unsafe operations.&#xA;[WARNING] /Users/Emac/microservices/gateway/src/main/java/com/emodak/buji/gateway/TokenRelayFilter.java: Recompile with -Xlint:unchecked for details.&#xA;[INFO] &#xA;[INFO] --- maven-resources-plugin:3.0.1:testResources (default-testResources) @ gateway ---&#xA;[INFO] Using 'UTF-8' encoding to copy filtered resources.&#xA;[INFO] Copying 2 resources&#xA;[INFO] &#xA;[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ gateway ---&#xA;[INFO] Changes detected - recompiling the module!&#xA;[INFO] Compiling 8 source files to /Users/Emac/microservices/gateway/target/test-classes&#xA;[WARNING] /Users/Emac/microservices/gateway/src/test/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilterTest.java: /Users/Emac/microservices/gateway/src/test/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilterTest.java uses or overrides a deprecated API.&#xA;[WARNING] /Users/Emac/microservices/gateway/src/test/java/com/emodak/buji/gateway/responserewriting/SwaggerBasePathRewritingFilterTest.java: Recompile with -Xlint:deprecation for details.&#xA;[INFO] &#xA;[INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ gateway ---&#xA;[INFO] Surefire report directory: /Users/Emac/microservices/gateway/target/surefire-reports&#xA;&#xA;-------------------------------------------------------&#xA; T E S T S&#xA;-------------------------------------------------------&#xA;objc[46612]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.8.0_73.jdk/Contents/Home/jre/bin/java and /Library/Java/JavaVirtualMachines/jdk1.8.0_73.jdk/Contents/Home/jre/lib/libinstrument.dylib. One of the two will be used. Which one is undefined.&#xA;Running com.emodak.buji.gateway.responserewriting.SwaggerBasePathRewritingFilterTest&#xA;2016-09-10 22:39:07.302  WARN   --- [           main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.&#xA;2016-09-10 22:39:08.537 DEBUG   --- [           main] c.e.b.g.r.SwaggerBasePathRewritingFilter : Swagger-docs: rewritten Base URL with correct micro-service route: /service1&#xA;Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.437 sec - in com.emodak.buji.gateway.responserewriting.SwaggerBasePathRewritingFilterTest&#xA;Running com.emodak.buji.security.SecurityUtilsUnitTest&#xA;Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.269 sec - in com.emodak.buji.security.SecurityUtilsUnitTest&#xA;Running com.emodak.buji.service.UserServiceIntTest&#xA;&#xA;        â–ˆâ–ˆ  â–ˆâ–ˆ    â–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ&#xA;        â–ˆâ–ˆ  â–ˆâ–ˆ    â–ˆâ–ˆ     â–ˆâ–ˆ     â–ˆâ–ˆ    â–ˆâ–ˆ  â–ˆâ–ˆ          â–ˆâ–ˆ     â–ˆâ–ˆ        â–ˆâ–ˆ    â–ˆâ–ˆ&#xA;        â–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     â–ˆâ–ˆ     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      â–ˆâ–ˆ     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ&#xA;  â–ˆâ–ˆ    â–ˆâ–ˆ  â–ˆâ–ˆ    â–ˆâ–ˆ     â–ˆâ–ˆ     â–ˆâ–ˆ             â–ˆâ–ˆ     â–ˆâ–ˆ     â–ˆâ–ˆ        â–ˆâ–ˆ   â–ˆâ–ˆ&#xA;   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆ    â–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆ        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      â–ˆâ–ˆ     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆ    â–ˆâ–ˆ&#xA;&#xA;:: JHipster   :: Running Spring Boot 1.4.0.RELEASE ::&#xA;:: http://jhipster.github.io ::&#xA;&#xA;2016-09-10 22:39:18.809  WARN 46612 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""http://localhost:8888/gateway/default"": Connection refused; nested exception is java.net.ConnectException: Connection refused&#xA;2016-09-10 22:39:18.853  INFO 46612 --- [           main] c.e.buji.service.UserServiceIntTest      : No active profile set, falling back to default profiles: default&#xA;2016-09-10 22:39:24.098  WARN 46612 --- [           main] o.s.c.a.ConfigurationClassPostProcessor  : Cannot enhance @Configuration bean definition 'refreshScope' since its singleton instance has been created too early. The typical cause is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor return type: Consider declaring such methods as 'static'.&#xA;2016-09-10 22:39:25.121 DEBUG 46612 --- [           main] c.emodak.buji.config.AsyncConfiguration  : Creating Async Task Executor&#xA;2016-09-10 22:39:27.595 DEBUG 46612 --- [           main] c.e.buji.config.MetricsConfiguration     : Registering JVM gauges&#xA;2016-09-10 22:39:27.650 DEBUG 46612 --- [           main] c.e.buji.config.MetricsConfiguration     : Monitoring the datasource&#xA;2016-09-10 22:39:27.651 DEBUG 46612 --- [           main] c.e.buji.config.MetricsConfiguration     : Initializing Metrics JMX reporting&#xA;2016-09-10 22:39:28.834 DEBUG 46612 --- [           main] c.e.buji.config.DatabaseConfiguration    : Configuring Liquibase&#xA;2016-09-10 22:39:28.861 DEBUG 46612 --- [           main] c.e.b.c.liquibase.AsyncSpringLiquibase   : Starting Liquibase synchronously&#xA;2016-09-10 22:39:33.557 DEBUG 46612 --- [           main] c.e.b.c.liquibase.AsyncSpringLiquibase   : Started Liquibase in 4695 ms&#xA;2016-09-10 22:39:33.952 DEBUG 46612 --- [           main] c.emodak.buji.config.CacheConfiguration  : Configuring Hazelcast&#xA;2016-09-10 22:39:34.110 DEBUG 46612 --- [           main] c.emodak.buji.config.CacheConfiguration  : Configuring Hazelcast clustering for instanceId: gateway&#xA;2016-09-10 22:39:34.347  WARN 46612 --- [           main] c.h.instance.DefaultAddressPicker        : [LOCAL] [dev] [3.6.1] Could not find a matching address to start with! Picking one of non-loopback addresses.&#xA;2016-09-10 22:39:45.031  INFO 46612 --- [           main] com.emodak.buji.GatewayApp               : Running with Spring profile(s) : []&#xA;2016-09-10 22:39:48.315  WARN 46612 --- [           main] org.elasticsearch.env                    : [Cardiac] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]&#xA;2016-09-10 22:40:00.397 DEBUG 46612 --- [           main] c.e.b.c.e.IndexReinitializer             : ElasticSearch indexes reset in 12 ms&#xA;2016-09-10 22:40:11.100 DEBUG 46612 --- [           main] c.emodak.buji.config.CacheConfiguration  : Starting HazelcastCacheManager&#xA;2016-09-10 22:40:20.884  WARN 46612 --- [           main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.&#xA;2016-09-10 22:40:21.974  INFO 46612 --- [           main] c.e.buji.service.UserServiceIntTest      : Started UserServiceIntTest in 72.623 seconds (JVM running for 79.635)&#xA;Hibernate: select authority0_.name as name1_0_0_ from jhi_authority authority0_ where authority0_.name=?&#xA;Hibernate: insert into jhi_user (id, created_by, created_date, last_modified_by, last_modified_date, activated, activation_key, email, first_name, lang_key, last_name, login, password_hash, reset_date, reset_key) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&#xA;2016-09-10 22:40:23.482 DEBUG 46612 --- [           main] com.emodak.buji.service.UserService      : Created Information for User: User{login='johndoe', firstName='John', lastName='Doe', email='john.doe@localhost', activated='false', langKey='en-US', activationKey='80060923054997847003'}&#xA;......&#xA;Hibernate: select authoritie0_.user_id as user_id1_3_0_, authoritie0_.authority_name as authorit2_4_0_, authority1_.name as name1_0_1_ from jhi_user_authority authoritie0_ inner join jhi_authority authority1_ on authoritie0_.authority_name=authority1_.name where authoritie0_.user_id=?&#xA;Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.317 sec - in com.emodak.buji.web.rest.UserResourceIntTest&#xA;2016-09-10 22:40:29.743  WARN 46612 --- [.ShutdownThread] com.hazelcast.instance.Node              : [192.168.11.5]:5701 [dev] [3.6.1] Terminating forcefully...&#xA;2016-09-10 22:40:30.287  WARN 46612 --- [       Thread-6] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.&#xA;2016-09-10 22:40:30.537  INFO 46612 --- [       Thread-6] c.emodak.buji.config.CacheConfiguration  : Closing Cache Manager&#xA;&#xA;Results :&#xA;&#xA;Tests run: 32, Failures: 0, Errors: 0, Skipped: 0&#xA;&#xA;[INFO] &#xA;[INFO] --- jacoco-maven-plugin:0.7.7.201606060606:report (post-unit-test) @ gateway ---&#xA;[INFO] Loading execution data file /Users/Emac/microservices/gateway/target/test-results/coverage/jacoco/jacoco.exec&#xA;[INFO] Analyzed bundle 'Gateway' with 120 classes&#xA;[INFO] &#xA;[INFO] --- frontend-maven-plugin:1.0:gulp (gulp test) @ gateway ---&#xA;[INFO] Running 'gulp.js test --no-notification' in /Users/Emac/microservices/gateway&#xA;[INFO] [22:41:35] Using gulpfile ~/microservices/gateway/gulpfile.js&#xA;[INFO] [22:41:35] Starting 'inject:test'...&#xA;[INFO] [22:41:35] Starting 'ngconstant:dev'...&#xA;[INFO] [22:41:35] Finished 'ngconstant:dev' after 142 ms&#xA;[INFO] [22:41:35] gulp-inject 22 files into karma.conf.js.&#xA;[INFO] [22:41:35] Finished 'inject:test' after 655 ms&#xA;[INFO] [22:41:35] Starting 'test'...&#xA;[INFO] 10 09 2016 22:41:47.224:INFO [karma]: Karma v1.1.2 server started at http://localhost:9876/&#xA;[INFO] 10 09 2016 22:41:47.287:INFO [launcher]: Launching browser PhantomJS with unlimited concurrency&#xA;[INFO] 10 09 2016 22:41:47.402:INFO [launcher]: Starting browser PhantomJS&#xA;&#xA;&#xA;&#xA;[INFO] 10 09 2016 22:41:47.500:ERROR [karma]: { [Error: spawn EACCES] code: 'EACCES', errno: 'EACCES', syscall: 'spawn' }&#xA;[INFO] Error: spawn EACCES&#xA;[INFO]     at exports._errnoException (util.js:873:11)&#xA;&#xA;&#xA;&#xA;[INFO]     at ChildProcess.spawn (internal/child_process.js:298:11)&#xA;[INFO]     at exports.spawn (child_process.js:362:9)&#xA;[INFO]     at Object._execCommand (/Users/Emac/microservices/gateway/node_modules/karma/lib/launchers/process.js:63:21)&#xA;[INFO]     at Object._start (/Users/Emac/microservices/gateway/node_modules/karma-phantomjs-launcher/index.js:76:10)&#xA;[INFO]     at Object.&lt;anonymous&gt; (/Users/Emac/microservices/gateway/node_modules/karma/lib/launchers/process.js:14:10)&#xA;[INFO]     at emitOne (events.js:82:20)&#xA;[INFO]     at Object.emit (events.js:169:7)&#xA;[INFO]     at Object.start (/Users/Emac/microservices/gateway/node_modules/karma/lib/launchers/base.js:42:10)&#xA;[INFO]     at Object.j (/Users/Emac/microservices/gateway/node_modules/karma/lib/launcher.js:108:17)&#xA;[INFO]     at Object.setTimeout.bind.j (/Users/Emac/microservices/gateway/node_modules/karma/node_modules/qjobs/qjobs.js:143:18)&#xA;[INFO]     at Timer.listOnTimeout (timers.js:92:15)&#xA;&#xA;&#xA;&#xA;[INFO] [22:41:47] 'test' errored after 12 s&#xA;[INFO] [22:41:47] Error: 1&#xA;[INFO]     at formatError (/Users/Emac/microservices/gateway/node_modules/gulp/bin/gulp.js:169:10)&#xA;&#xA;&#xA;&#xA;[INFO]     at Gulp.&lt;anonymous&gt; (/Users/Emac/microservices/gateway/node_modules/gulp/bin/gulp.js:195:15)&#xA;[INFO]     at emitOne (events.js:77:13)&#xA;[INFO]     at Gulp.emit (events.js:169:7)&#xA;[INFO]     at Gulp.Orchestrator._emitTaskDone (/Users/Emac/microservices/gateway/node_modules/gulp/node_modules/orchestrator/index.js:264:8)&#xA;[INFO]     at /Users/Emac/microservices/gateway/node_modules/gulp/node_modules/orchestrator/index.js:275:23&#xA;[INFO]     at finish (/Users/Emac/microservices/gateway/node_modules/gulp/node_modules/orchestrator/lib/runTask.js:21:8)&#xA;[INFO]     at cb (/Users/Emac/microservices/gateway/node_modules/gulp/node_modules/orchestrator/lib/runTask.js:29:3)&#xA;[INFO]     at removeAllListeners (/Users/Emac/microservices/gateway/node_modules/karma/lib/server.js:379:7)&#xA;[INFO]     at Server.&lt;anonymous&gt; (/Users/Emac/microservices/gateway/node_modules/karma/lib/server.js:390:9)&#xA;[INFO]     at Server.g (events.js:260:16)&#xA;[INFO]     at emitNone (events.js:72:20)&#xA;[INFO]     at Server.emit (events.js:166:7)&#xA;[INFO]     at emitCloseNT (net.js:1537:8)&#xA;[INFO]     at nextTickCallbackWith1Arg (node.js:431:9)&#xA;[INFO]     at process._tickCallback (node.js:353:17)&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD FAILURE&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 08:53 min&#xA;[INFO] Finished at: 2016-09-10T22:42:47+08:00&#xA;[INFO] Final Memory: 67M/314M&#xA;[INFO] ------------------------------------------------------------------------&#xA;[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.0:gulp (gulp test) on project gateway: Failed to run task: 'gulp.js test --no-notification' failed. (error code 1) -&gt; [Help 1]&#xA;[ERROR] &#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR] &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException&#xA;</code></pre>&#xA;&#xA;<p>Emacs-MacBook-Pro:gateway Emac$ </p>&#xA;&#xA;<p>Thanks in advance, Sam8881</p>&#xA;"
39457873,How to include CorrelationId in microservice architecture?,2016-09-12 19:57:35,<microservices><asp.net-core-webapi>,1,777,4,1.0,2,"<p>I am creating a microservices architecture using ASP.NET Core web api. All the services are decoupled from each other, and may be deployed in different environments. Every service has its own logging. When requests flows through these services it could fail in any of the service, We need a way of tracing a series of events back to the source, even if it means traversing multiple services.<br>&#xA;So to handle this issue, the service that originates the request creates a CorrelationId and pass it to the next service. The 2nd service pass it to 3rd service and so on. If exception occurs the corresponding service will log the exception message along with CorrelationId.</p>&#xA;&#xA;<p>I wanted to know what would be a best place for the caller of the service to pass the correlationid? </p>&#xA;&#xA;<p>Should the caller pass correlationid in HttpHeader or should it pass it as a part method parameter something like below</p>&#xA;&#xA;<p><em>This is the service that is getting called</em></p>&#xA;&#xA;<pre><code> public class RequestDTO&#xA; {&#xA;    public string CorrelationId {get;set;}&#xA;    public string SomeOtherData {get;set;}&#xA; }&#xA;&#xA; public Service2Controller:Controller&#xA; {&#xA;    public Task&lt;in&gt; DoSomething(RequestDTO request)&#xA;    {&#xA;         // add the correlationid in current request Items collection&#xA;         // So global exception handling can access it and log it &#xA;         // along with the exception&#xA;&#xA;         HttpContext.Items.Add(""CorrelationId"", request.CorrelationId);&#xA;    }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>in the approach above if there is an exception before this method is invoked, the CorrelationId will not be available for global exception handler for logging.</p>&#xA;&#xA;<p>Any suggestions? or alternate approach</p>&#xA;"
39561186,Best practice for loading multiple dynamic services and them dependencies services,2016-09-18 18:28:43,<c#><multithreading><reflection><microservices>,2,58,5,0.0,2,"<p>I want to devlop a custom system for my self.</p>&#xA;&#xA;<p>I want to loading custom services by configuratin with dependency services - for example:</p>&#xA;&#xA;<pre><code>&lt;Services&gt;&#xA;    &lt;Service name=""ServiceA"" args="""" type=""CommonLib.IServiceA"" dependencies=""""/&gt;&#xA;    &lt;Service name=""ServiceB"" args="""" type=""CommonLib.IServiceB"" dependencies=""ServiceA""/&gt;&#xA;    &lt;Service name=""ServiceC"" args="""" type=""CommonLib.IServiceC"" dependencies=""ServiceA,ServiceB""/&gt;&#xA;    &lt;Service name=""ServiceD"" args="""" type=""CommonLib.IServiceD"" dependencies=""ServiceA,ServiceB,ServiceC""/&gt;&#xA;    &lt;Service name=""ServiceE"" args="""" type=""CommonLib.IServiceE"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD""/&gt;&#xA;    &lt;Service name=""ServiceF"" args="""" type=""CommonLib.IServiceF"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD,ServiceE""/&gt;&#xA;&lt;/Services&gt;&#xA;</code></pre>&#xA;&#xA;<p>All those services are implement custom interface:</p>&#xA;&#xA;<pre><code>public interface IService&#xA;{&#xA;    bool Start();&#xA;    bool Stop();&#xA;    bool IsReady {get;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What the best practice for loading dynamic services toghether but depends on those dependencies?</p>&#xA;&#xA;<p>Loop every service and postpone till those dependencies are loaded and ready?</p>&#xA;&#xA;<p>Have any tutorial for that?</p>&#xA;"
32392202,MicroServices with Play and JSON Serialization,2015-09-04 07:14:09,<scala><playframework-2.2><microservices>,2,295,0,1.0,2,"<p>Let's assume that I have a couple of MicroServices with each exposing a set of REST end points. Assume that MicroService A is communicating with MicroService B and they exchange JSON data. </p>&#xA;&#xA;<p>This JSON data needs to be Serialized and De-Serialized on both the MicroService A and B. This Serialization logic and the models are going to be the same on both the MicroService code base. </p>&#xA;&#xA;<p>I can reduce this duplication by just moving the model classes into a small dependency and use it on both the MicroServices. Not a problem! This might go against the goal of a MicroService architecture, which is ""share nothing"". But I feel even more potential problem to address is code duplication. What do you guys think?</p>&#xA;"
39742117,Jhipster : Proper architecture to authenticate using an existing database,2016-09-28 08:35:55,<authentication><jwt><jhipster><microservices>,2,515,0,1.0,2,"<p>I'm currently working on a Jhipster prototype application. The application is a simple gateway with a microservice to access data.</p>&#xA;&#xA;<p>Right now, I would like to use an existing database from my company to authenticate users, but Jhispter doesn't seems to supports multiple datasources (and I don't want my whole gateway to switch to another database)</p>&#xA;&#xA;<p>My first idea was to use a microservices to authenticate user. This microservice would run on the other database, but this creates another problem : to call this service from the gateway, I need a JWT token... and this starts to look like I need to be authenticated to authenticate a user.</p>&#xA;&#xA;<p>The other solution, as said before, would be to have two datasources on my gateway : one for user authentication (pointing to the existing database), and the other for Jhipster-related data (audits, etc..)</p>&#xA;&#xA;<p>Do you know what would be the best practice in this case?&#xA;And can you point me in the right direction for this choice ?</p>&#xA;"
39686227,Handling database schema creation and migrations when launching multiple instances of a containerized microservice,2016-09-25 11:18:52,<docker><kubernetes><database-migration><microservices>,2,814,0,0.0,2,"<p>I want to deploy my microservices in docker containers. I want these microservices to be as stateless as possible, only persisting state to a database.</p>&#xA;&#xA;<p>This means that there are these requirements:</p>&#xA;&#xA;<ul>&#xA;<li>These services are deployed as docker containers and orchestrated using kubernetes.</li>&#xA;<li>Each service can be deployed and scaled to multiple instances.</li>&#xA;<li>Each instance of a service will be identical. This means that they must all have the same environment variables and configurations passed to it.</li>&#xA;<li>Each instances should not care or know about another instance.</li>&#xA;<li>The instances should be stateless and should not elect a leader or have a quorum.</li>&#xA;</ul>&#xA;&#xA;<p>That leads to my problem with handling schema creation and migrations:</p>&#xA;&#xA;<ol>&#xA;<li><p>If I have a service that uses MySQL or Postgres as the data store, how do I create the tables/schemas on first launch? Should I just use <code>CREATE IF NOT EXIST</code> statements and let the instances ""fight it out"" during boot? I am not able to set an environment variable to ask for table/schema creation for just 1 of the instances.</p></li>&#xA;<li><p>How do I handle schema migrations with the above constraints? There are numerous actions like dropping/adding columns that cannot be encapsulated in a transaction.</p></li>&#xA;</ol>&#xA;"
40296598,Micro-services approach: Isolation and decoupling,2016-10-28 01:27:44,<design><architecture><microservices>,1,163,3,0.0,2,"<p>I've to add a service to my Micro-services architecture and&#xA;my new services needs to compute data he's responsable of. These computations occurs at a relatively high frequency.</p>&#xA;&#xA;<p>In order to compute things, my new service needs to retrieve additional infos from another service (lets say from the same bounded context)</p>&#xA;&#xA;<p>The issue here is that all these calls on every computation might cause some performance issues.</p>&#xA;&#xA;<p>What do you think is the best approach to take here?&#xA;Is it a good idea to let my new service save a kind of snapshot of the additional infos it needs (asynchronous synchronisation with the other service) so that it doesn't have to perform all those calls every time it needs to compute. </p>&#xA;"
35632607,Is the HTTP method PURGE idempotent in Varnish?,2016-02-25 16:14:18,<rabbitmq><varnish><microservices><http-method><purge>,2,614,0,0.0,2,<p>Is the HTTP verb PURGE idempotent? &#xA;If I send the same PURGE request twice will I receive 200 the second time?</p>&#xA;&#xA;<p>I have a microservice that invalidates a Varnish cache before publishing a message into a rabbit queue. In case of purge failure our need is to just log and continue the execution.</p>&#xA;&#xA;<p>The queue consumer has to get the latest status of the resource from the Varnish cache.&#xA;Will a new purge request (before actually requesting the resource from varnish) from the second microservice return success in case the first purge from the first microservice succeeded?</p>&#xA;
35617996,Eureka registration of Https micro services,2016-02-25 03:57:15,<spring-boot><microservices><netflix-eureka>,2,1894,0,0.0,2,<p>Eureka does not recognized HTTPS endpoints like '/info' and '/health' and always points to HTTP endpoints after enabling HTTPS. How to enable HTTPS micro-service url registration at Eureka ? </p>&#xA;
35441660,Micro services with JBOSS,2016-02-16 19:42:39,<jboss><microservices>,3,1732,0,0.0,2,"<p>I am new to Jboss, want to know if micro services architecture is a right choice on JBOSS. I cannot change the application server as it is decided by client architect and I have no choice.&#xA;Want to know whether we can develop micro services with underlying JBOSS application server.</p>&#xA;&#xA;<p>I understand Spring boot comes with embedded tomcat container, which makes it flexible to stop and start, deploy individual service with no impact to other services.&#xA;However will that architecture works with JBoss too.</p>&#xA;&#xA;<p>Please suggest.</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
35589045,How to aggregate logs from a large number of (micro)services,2016-02-23 21:57:02,<logging><service><spring-boot><microservices>,1,530,1,1.0,2,"<p>We will be building a large number of (micro)services with Spring Boot. These will ofcourse generate a large number of disseparate logs. What would be the options and best practices to manage these logs, and make sense of them? Thanks for any help!</p>&#xA;"
35585519,"Cross origin issue with ajax, angular and Zuul",2016-02-23 18:38:01,<angularjs><ajax><spring-cloud><microservices><netflix-zuul>,1,1313,4,0.0,2,"<p>I have zuul server implemented which does the routing to all my microservices. I have a seperate UI project which is in angular. I am trying to make an AJAX call from the UI app to a specific microservices which routes through Zuul but I am getting this error.</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load http://localhost:8006/user/v1/userassociations. Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:63342' is therefore not allowed access. The response had HTTP status code 403. &#xA;</code></pre>&#xA;&#xA;<p>But When I directly try to hit the api in local host which is hosted at <a href=""http://localhost:4444/user/v1/userassociations"" rel=""nofollow"">http://localhost:4444/user/v1/userassociations</a> it works perfectly fine. I have the below CORS configuration added to the actual api.</p>&#xA;&#xA;<pre><code>@Override&#xA;public void addCorsMappings(final CorsRegistry registry) {&#xA;    registry.addMapping(""/**"").allowedMethods(""PUT"", ""GET"", ""DELETE"", ""OPTIONS"", ""PATCH"", ""POST"");&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is only happening when i try to hit the api via zuul I tried to add the same configuration to Zuul  but it is not working.</p>&#xA;&#xA;<p>I know it is the same origin issue but there must be a solution our microservices are suppose to go public so anyone can make the request from any domain.</p>&#xA;&#xA;<p>Below is the Working AJAX call:- if i change the url to <a href=""http://localhost:8006/user/v1/userassociations"" rel=""nofollow"">http://localhost:8006/user/v1/userassociations</a> which is via zuul i get the cross origin.</p>&#xA;&#xA;<pre><code>var service = {};&#xA;  service.userContextCall = function()&#xA;  {&#xA;    return $http({&#xA;      url:'http://localhost:4444/user/v1/userassociations',&#xA;      method: 'GET',&#xA;      headers: {'Content-Type':'application/json',&#xA;        'userContextId':'1234567890123456'}&#xA;    }).success(function(response){&#xA;&#xA;      return response;&#xA;    }).error(function(error){&#xA;&#xA;      return error;&#xA;    });&#xA;&#xA;  };&#xA;&#xA;  return service;&#xA;</code></pre>&#xA;&#xA;<p>Header that Iam receiving for when i hit the api via Zuul.</p>&#xA;&#xA;<pre><code>Request URL:http://localhost:8006/user/v1/userassociations&#xA;Request Method:OPTIONS&#xA;Status Code:403 Forbidden&#xA;Remote Address:[::1]:8006&#xA;Response Headers&#xA;view source&#xA;Allow:GET, HEAD, POST, PUT, DELETE, TRACE, OPTIONS, PATCH&#xA;Content-Length:20&#xA;Date:Tue, 23 Feb 2016 18:51:15 GMT&#xA;Server:Apache-Coyote/1.1&#xA;X-Application-Context:apigateway:8006&#xA;Request Headers&#xA;view source&#xA;Accept:*/*&#xA;Accept-Encoding:gzip, deflate, sdch&#xA;Accept-Language:en-US,en;q=0.8&#xA;Access-Control-Request-Headers:accept, usercontextid&#xA;Access-Control-Request-Method:GET&#xA;Connection:keep-alive&#xA;Host:localhost:8006&#xA;Origin:http://localhost:63342&#xA;Referer:http://localhost:63342/icpAccountHolder/app/index.html&#xA;User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36&#xA;</code></pre>&#xA;&#xA;<p>Header when i direclty hit the api the working one.</p>&#xA;&#xA;<pre><code>Request URL:http://localhost:4444/user/v1/userassociations&#xA;Request Method:GET&#xA;Status Code:200 OK&#xA;Remote Address:[::1]:4444&#xA;Response Headers&#xA;view source&#xA;Access-Control-Allow-Credentials:true&#xA;Access-Control-Allow-Origin:http://localhost:63342&#xA;Content-Type:application/json;charset=utf-8&#xA;Date:Tue, 23 Feb 2016 18:54:19 GMT&#xA;Server:Apache-Coyote/1.1&#xA;Transfer-Encoding:chunked&#xA;Vary:Origin&#xA;X-Application-Context:userassociations-v1&#xA;Request Headers&#xA;view source&#xA;Accept:application/json, text/plain, */*&#xA;Accept-Encoding:gzip, deflate, sdch&#xA;Accept-Language:en-US,en;q=0.8&#xA;Connection:keep-alive&#xA;Host:localhost:4444&#xA;Origin:http://localhost:63342&#xA;Referer:http://localhost:63342/icpAccountHolder/app/index.html&#xA;User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36&#xA;userContextId:1234567890123456&#xA;</code></pre>&#xA;&#xA;<p>Can anyone help me with this. </p>&#xA;"
51149979,Microservicess with Serverless (Lambda or Function),2018-07-03 08:30:31,<azure><lambda><microservices><azure-functions>,2,61,0,2.0,2,"<p>I have some concern on getting an idea of migrating current microservices system into serverless.</p>&#xA;&#xA;<p>Right now, between services are communicating with HTTP or API based.&#xA;Serverless like lambda or function can talk to each other with function call or lambda call. This way can be done by changing all HTTP code into lambda call within all services.</p>&#xA;&#xA;<p>Another way is still using HTTP request to call another service that on lambda through API Gateway. This method of calling is not good because the service request gone to Internet and go back again into API Gateway then neighbor service get the request. Too long and does not make sense for me.</p>&#xA;&#xA;<p>I will be glad if lambda app call another lambda app with local network HTTP request, this is still on my research on how to do it.</p>&#xA;&#xA;<p>I would like to know from all of you about your experience on migrating microservices based on HTTP communication between services into serverless like Lambda or Functions ?</p>&#xA;&#xA;<p>Do you change all your code into specific lambda function call ?&#xA;Do you use HTTP over internet and API Gateway again to call neighbor service ?&#xA;Have you guys figured it out on Local / Private network lambda call ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;"
51189616,How can I proceed a delete operation in Lagom Framework?,2018-07-05 10:59:14,<java><scala><akka><microservices><lagom>,2,79,4,0.0,2,"<p>I am a little newbie on the Lagom framework and I need to know what the right way to do a delete operation in this framework. I develop with Java and I tested two approaches:</p>&#xA;&#xA;<ol>&#xA;<li>when I handle the delete event I set the state to Optional.empty () but it returns nullPointerException crashes and the line in my readSide (Cassandra DataBase) is not deleted</li>&#xA;<li>I add a Status field to my entity and when I handle the delete event I pass it to -1. When I refer to my entity I test on State.present and status! = -1 to make sure the entity and deleted. For the readSide, the line is deleted properly</li>&#xA;</ol>&#xA;&#xA;<p>In terms of logic, I think the second approach is the most logical but I want to know if there is a good practice that the Lagom framework offers developers to do delete operations</p>&#xA;&#xA;<p><strong>EDIT 1</strong>&#xA;This is my ReadSideHandler code, how can I proceed to handle properly the empty option</p>&#xA;&#xA;<pre><code>@Override&#xA;public ReadSideHandler&lt;AuthenticationEvent&gt; buildHandler() {&#xA;    return readSide.&lt;AuthenticationEvent&gt;builder(""authenticationEventOffset"")&#xA;            .setGlobalPrepare(this::createTables)&#xA;            .setPrepare(tag -&gt; prepareStatements())&#xA;            .setEventHandler(AuthenticationLoginEvent.class,&#xA;                    e -&gt; insertAuthentication(e.getAuthentication()))&#xA;            .setEventHandler(AuthenticationLogoutEvent.class, e -&gt; deleteAuthentication(e.getAccessToken()))&#xA;            .build();&#xA;}&#xA;</code></pre>&#xA;"
51227737,How to implement OpenID Connect authentication with 3rd party IDPs in a microservices architecture,2018-07-07 23:37:39,<oauth-2.0><jwt><microservices><openid-connect>,3,192,4,0.0,2,"<p>For the past 10+ days I've read an watched ALL the content I could find on understanding OAuth2 and OpenID Connect, only to find that many people disagree on the implementation, which really confuses me.</p>&#xA;&#xA;<p>To my understanding, all the articles and examples I found assume you want access to eg. google calendar, profile info or emails if you eg. login with google, but I do NOT need to access other than my own API's - I only want to use Google, Facebook etc for logging in, and getting an id which I can link to my user in my own database - nothing more than that.</p>&#xA;&#xA;<p>I'll try illustrate my use case and use that as an example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/H4VwP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H4VwP.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>A note on the diagram: the Authentication service could probably be built into the API Gateway - not that i matters for this example, since this is not about ""where to do it"", but ""how to do it the best way"" possible, for an architecture such as mine, where it's used for my own API's / Microservices, and not accessing Google, Facebook etc. external API's</em></p>&#xA;&#xA;<p>If you can understand what I'm trying to illustrate with this diagram above, please tell me if I've misunderstood this.</p>&#xA;&#xA;<p>The most basic requirements for this architecture you see here are:</p>&#xA;&#xA;<ul>&#xA;<li>Users can login with Google, Facebook, etc.</li>&#xA;<li>The same login will be used for all micro-services</li>&#xA;<li>OpenId user will have a linked account in the database</li>&#xA;<li>User access is defined in my own db, based on groups, roles and permissions</li>&#xA;</ul>&#xA;&#xA;<p>I do not intend to use external API's after the user is authenticated and logged in. No need for ever accessing a users calendar, email etc. so I really just need the authentication part and nothing else (proof of successful login). All user access is defined in my own database.</p>&#xA;&#xA;<p>So a few fundamental questions comes to mind.</p>&#xA;&#xA;<ul>&#xA;<li>First of all, is OpenID Connect even the right tool for the job for authentication only (I'll have no use for authorization, since I will not need read/write access to google / facebook API's other than getting the ID from authenticating)?</li>&#xA;<li>People generally do not agree on whether to use the ID or Access token for accessing your own API's. As far as I understand the ID token is for the client (user-agent) only, and the access token is for eg. accessing google calendar, emails etc.... External API's of the OpenID Provider... but since I'll only be accessing my own API's, do I event need the access token or the ID token - what is the correct way to protect your own API's?</li>&#xA;</ul>&#xA;&#xA;<p>If the ID token is really just for the client, so it can show eg. currently logged in user, without going to the DB, I have 0 use for it, since I'll probably query the user from from the db and store it in redux for my react frontend app.</p>&#xA;&#xA;<p><strong>Dilemma: To store user details, groups, roles and permission inside JWT or not for API authorization?</strong></p>&#xA;&#xA;<ul>&#xA;<li>By only storing the user identifier in the token, it means that I always allow authenticated users that has a valid token, to call endpoints BEFORE authorization and first then determine access based on the db query result and the permissions in my own database.</li>&#xA;<li>By storing more data about the user inside the JWT, it means that in some cases, I'd be able to do the authorization / access (group, role, permission) check before hitting the API - only possible with user info, groups, roles and permission stored inside a JWT issued upon login. In some cases it would not be possible due to eg. the CMS content access permissions being on a per-node level. But still it would mean a little better performance. </li>&#xA;</ul>&#xA;&#xA;<p>As you can see on the diagram I'm sending all API requests through the gateway, which will (in itself or with an authentication service) translate the opaque access token into some JWT with an identifier, so I can identify the user in the graph database - and then verify if the user has the required groups, roles and permissions - not from an external API, but from my own database like you see on the diagram.</p>&#xA;&#xA;<p>This seems like a lot of work on every request, even if the services can share the JWT in case multiple services should need to cross call each other.</p>&#xA;&#xA;<p>The advantage of always looking up the user, and his permissions in the db, is naturally that the moment the user access levels change, he is denied/granted access immediately and it will always be in sync. If I store the user details, groups, roles and permission inside a JWT and persist that in the client localstorage, I guess it could pose a security issue right, and it would be pretty hard to update the user info, groups, roles and permissions inside that JWT?</p>&#xA;&#xA;<p>One big advantage of storing user access levels and info inside the JWT is of course that in many cases I'd be able to block the user from calling certain API's, instead of having to determine access after a db lookup.</p>&#xA;&#xA;<p>So the whole token translation thing means increased security at the cost of performance, but is is generally recommended and worth it? Or is it safe enough to store user info and groups, roles, permissions inside the JWT? </p>&#xA;&#xA;<p>If yes, do I store all that information from my own DB in the ID Token, Access token or a 3rd token - what token is sent to the API and determines if the user should be granted access to a given resource based on his permissions in the db? Do I really need an access token if I don't need to interact with the ID providers API? Or do I store and append all my groups, roles, permissions inside the ID token (that doesn't seem clean to me) issued by OpenID connect, and call the API and authorize my own API endpoints using that, even if some say you should never use the ID token to access an API? Or do I create a new JWT to store all the info fetched from my database, which is to be used for deciding if the user can access a given resource / API endpoint?</p>&#xA;&#xA;<p>Please do not just link to general specs or general info, since I've already read it all - I just failed to understand how to apply all that info to my actual use case (the diagram above). Try to please be as concrete as possible.</p>&#xA;&#xA;<p>Made another attempt to try and simply the flow:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/1d1Tn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1d1Tn.png"" alt=""enter image description here""></a></p>&#xA;"
36582126,How Lagom services consume other services?,2016-04-12 19:15:41,<microservices><service-discovery><lagom>,1,1048,2,1.0,2,"<p>I cant think in three cases.</p>&#xA;&#xA;<ol>&#xA;<li>Lagom service consumes another Lagom service in the same cluster</li>&#xA;<li>Lagom service consumes another Lagom service in a different cluster</li>&#xA;<li>Lagom service consumes an external non-Lagom service</li>&#xA;<li>An external non-Lagom service consumes a Lagom service</li>&#xA;</ol>&#xA;&#xA;<p><strong>1. Lagom service consumes another Lagom service in the same cluster</strong></p>&#xA;&#xA;<p>For this case the approach is that ServiceAImpl depends on the ServiceB API, wich is binded to a concrete implementation that will be injected to ServiceAImpl.</p>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Binding-a-service-client"" rel=""nofollow"">ServiceB binding:</a></p>&#xA;&#xA;<pre><code>import com.google.inject.AbstractModule;&#xA;import com.lightbend.lagom.javadsl.server.ServiceGuiceSupport;&#xA;import docs.services.HelloService;&#xA;&#xA;public class Module extends AbstractModule implements ServiceGuiceSupport {&#xA;&#xA;    protected void configure() {&#xA;        bindClient(HelloService.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Using-a-service-client"" rel=""nofollow"">ServiceA implementation:</a></p>&#xA;&#xA;<pre><code>public class MyServiceImpl implements MyService {&#xA;  private final HelloService helloService;&#xA;&#xA;  @Inject&#xA;  public MyServiceImpl(HelloService helloService) {&#xA;    this.helloService = helloService;&#xA;  }&#xA;&#xA;  @Override&#xA;  public ServiceCall&lt;NotUsed, NotUsed, String&gt; sayHelloLagom() {&#xA;    return (id, msg) -&gt; {&#xA;      CompletionStage&lt;String&gt; response = helloService.sayHello().invoke(""Lagom"");&#xA;      return response.thenApply(answer -&gt;&#xA;          ""Hello service said: "" + answer&#xA;      );&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I understand it correctly, in order to consume the service API in this way, both clients must be in the same cluster.&#xA;However Lagom <a href=""http://www.lagomframework.com/documentation/1.0.x/Cluster.html#Cluster-composition"" rel=""nofollow"">says</a> that</p>&#xA;&#xA;<blockquote>&#xA;  <p>A cluster should only span nodes that are running the same service.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this case we have two different types of services. </p>&#xA;&#xA;<ul>&#xA;<li>""The same service"" means a top level service whose API is exposed to external services?</li>&#xA;<li>In Lagom 1 Microservice = 1 service with external API + n internal services?</li>&#xA;</ul>&#xA;&#xA;<p><strong>2. Lagom service consumes another Lagom service in a different cluster</strong></p>&#xA;&#xA;<p>The documentation <a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceLocator.html#Integrating-with-external-Lagom-projects"" rel=""nofollow"">says</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Note that if the service you want to communicate with is actually a Lagom service, you may want to read the documentation for <a href=""http://www.lagomframework.com/documentation/1.0.x/MultipleBuilds.html"" rel=""nofollow"">integrating with an external Lagom projects</a>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Why is only configured the dependency to the service API and not the IP and port of the external Lagom service also?</p>&#xA;&#xA;<p><strong>3. Lagom service consumes an external non-Lagom service</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>The first thing you will have to do is to register each external&#xA;  service in the Service Locator. Assume we want to register an external&#xA;  service named weather that is running on <a href=""http://localhost:3333"" rel=""nofollow"">http://localhost:3333</a>, here&#xA;  is what we would add to the build:</p>&#xA;&#xA;<pre><code> lagomUnmanagedServices in ThisBuild := Map(""weather"" -&gt; ""http://localhost:3333"")&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>What is the contract with that IP? What should be behind it?</p>&#xA;&#xA;<p><strong>4. An external non-Lagom service consumes a Lagom service</strong></p>&#xA;&#xA;<p>I have to use the <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow"">Third-Party Registration Pattern</a> until Lagom support the <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow"">self registration pattern</a>?</p>&#xA;"
33228178,Does anyone know of a way to mock a web service while specifying latency and throughput?,2015-10-20 04:43:45,<performance><http><testing><microservices>,1,99,0,0.0,2,"<p>In order to to experiment with error handling and back-off strategies in a typical ""micro-services"" architecture, I would like to have a simple ""mock"" web service that </p>&#xA;&#xA;<ul>&#xA;<li>has configurable latency and throughput, changeable at runtime</li>&#xA;<li>can handle some thousands of requests per second on cheap hardware</li>&#xA;</ul>&#xA;&#xA;<p>Does anyone know of such a thing?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
33308154,Blue green deployment on microservices - how to route 10% of traffic to one one instance and remaining 90% of traffic to other instance,2015-10-23 17:25:00,<cloud><ibm-cloud><cloudfoundry><microservices>,3,188,0,0.0,2,<p>I have two instances of the same microservice in Bluemix(cloud Foundry). I want to route 90% of the traffic to one service and remaining 10% of the traffic to other service. Can you tell me how to do this in Bluemix</p>&#xA;
38377156,How to stop a spring boot service from command line?,2016-07-14 14:38:40,<java><windows><spring><spring-boot><microservices>,1,4534,0,0.0,2,"<p>Iâ€™m a spring-boot newbie, so please go easy on me.</p>&#xA;&#xA;<p>I need to offer a way for an administrator to start and stop my spring-boot microservice from a job scheduler. If I can create <code>start.bat</code> and <code>stop.bat</code> files for the service, then the scheduler could call them.</p>&#xA;&#xA;<p>How do I stop a spring-boot microservice from command line without killing the process? I'd like a graceful exit, if possible.</p>&#xA;&#xA;<p>The host will be a Windows server.</p>&#xA;"
38453830,How defensive to be when interacting with another internal microservice?,2016-07-19 08:57:26,<microservices><defensive-programming>,2,54,3,0.0,2,"<p>In this scenario there are two HTTP microservices:</p>&#xA;&#xA;<ol>&#xA;<li>The public service that provides the client with data</li>&#xA;<li>The internal microservice that authenticates calls to the public service</li>&#xA;</ol>&#xA;&#xA;<p>Service 1 makes a call to Service 2 to ask it to authenticate the token provided to it by the client.</p>&#xA;&#xA;<p>The agreement (""contract"") is that Service 2 should reply with <code>200 OK</code> and JSON content about the authenticated user.</p>&#xA;&#xA;<p>In Service 1, if it receives the response <code>200 OK</code>, is it worth going any further to validate the response further?</p>&#xA;&#xA;<p>For example, the JSON body of the response is parsed into an object. Is there value in checking if that object was correctly instantiated instead of being set to null? Or alternatively should that be left to integration tests?</p>&#xA;"
38230495,Zuul spring security and adding Additional Params in Request,2016-07-06 17:48:01,<spring><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1545,7,0.0,2,"<p>I am building Microservices using Spring Microservices, I have 2 questions related to that.<br><br>1. I have spring security in the Api Gateway i.e <strong>Zuul server</strong>, now Zuul is not forwarding any request if I have already read the request from the stream once to Authenticate(to get username/pass from POST Request) <br>&#xA;<code>new ObjectMapper().readValue(request.getInputStream(), UserDto.class);</code> &#xA;<br><strong>How can I read the request and then again forward the same request to Downstream services?</strong><br><br>&#xA;2. Zuul is not forwarding <strong>request.setAttribute()</strong> to Downstream services, so a workaround is to use <strong>ctx.addZuulRequestHeader</strong>, which is making <code>Request Header</code> too huge, How can I acheive <strong>request.setAttribute</strong> and get in downstream services.</p>&#xA;&#xA;<pre><code> public Authentication getAuthentication(HttpServletRequest request) {&#xA;    final String token = request.getHeader(AUTH_HEADER_NAME);&#xA;    logger.info(""token=""+token);&#xA;    if (token != null) {&#xA;        logger.info(""Entering getAuthentication"");&#xA;        final UserToken userInfo = tokenHandler.validateToken(token);&#xA;        if (userInfo != null&#xA;                &amp;&amp; token.equals(String.valueOf(redisUtility.getValue(userInfo.getUsername()+""_""+userInfo.getUniqueId())))) {&#xA;            logger.info(""Validating token key=""+userInfo.getUsername()+""_""+userInfo.getUniqueId());&#xA;            User user=userDetailsService.loadUserByUsername(userInfo.getUsername());&#xA;            if(user!=null &amp;&amp; user.getUsername().equals(userInfo.getUsername())&#xA;                &amp;&amp; user.getLastPasswordResetTime()&lt;userInfo.getCreatedTime()){&#xA;                request.setAttribute(""username"",user.getUsername());//**Not able to fetch this in Downstream services**&#xA;                logger.info(""Token Authenticated for User ""+user.getUsername());&#xA;                return new UserAuthentication(user);&#xA;            }&#xA;        } &#xA;    }&#xA;    return null;&#xA;}&#xA;&#xA;&#xA;  public class SimpleFilter extends ZuulFilter {&#xA;&#xA;      private static Logger log = LoggerFactory.getLogger(SimpleFilter.class);&#xA;&#xA;      @Override&#xA;      public String filterType() {&#xA;        return ""pre"";&#xA;      }&#xA;&#xA;      @Override&#xA;      public int filterOrder() {&#xA;        return 1;&#xA;      }&#xA;&#xA;      @Override&#xA;      public boolean shouldFilter() {&#xA;        return true;&#xA;      }&#xA;&#xA;      @Override&#xA;      public Object run() {&#xA;        RequestContext ctx = RequestContext.getCurrentContext();&#xA;        HttpServletRequest request = ctx.getRequest();&#xA;        request.setAttribute(""test"", ""test"");// Not able to get this in services&#xA;        log.info(String.format(""%s request to %s"", request.getMethod(), request.getRequestURL().toString()));&#xA;&#xA;        return null;&#xA;      }&#xA;&#xA; @Bean&#xA;  public SimpleFilter simpleFilter() {&#xA;    return new SimpleFilter();&#xA;  }&#xA;&#xA;@RequestMapping(value = ""/test/avl"",method=RequestMethod.POST)&#xA;  public String test(HttpServletRequest request) {&#xA;    System.out.println(request.getAttribute(""test"")+"""");&#xA;    return ""Spring in Action"";&#xA;  }&#xA;</code></pre>&#xA;"
39888480,Where to get the vertx dashboard monitor?,2016-10-06 05:53:38,<java><microservices><vert.x>,1,553,0,0.0,2,"<p>I have seen a couple of times on vertx website a vertx dashboard monitor, that looks like:    </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FrR9F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FrR9F.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>How to setup the dashboard or how to get it?  </p>&#xA;"
40068318,Ribbon client not able to discover microservices registered with eureka,2016-10-16 08:18:22,<java><spring-boot><microservices><netflix-eureka><netflix-ribbon>,1,423,0,0.0,2,"<p>Hi I have created two microservices 1. spotparkin and 2. spotparking2 and they have successfully registered with eureka server then I created ribbon client and tried making a rest call using the application name spotpaking , which is application name that I have given in application.yml file in both microservices but I am getting below error :</p>&#xA;&#xA;<blockquote>&#xA;  <p>2016-10-16 13:28:35.177 ERROR 11304 --- [nio-7213-exec-1]&#xA;  o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for&#xA;  servlet [dispatcherServlet] in c ontext with path [] threw exception&#xA;  [Request processing failed; nested exception is&#xA;  org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  GE T request for ""<a href=""http://spotparking/spotparking/pincode"" rel=""nofollow"">http://spotparking/spotparking/pincode</a>"":&#xA;  spotparking; nested exception is java.net.UnknownHostException:&#xA;  spotparking] with root cause</p>&#xA;  &#xA;  <p>java.net.UnknownHostException: spotparking&#xA;          at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_101]</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>ParkingSpot parkingSpot = restTemplate.exchange(""http://spotparking/spotparking/{pincode}"",HttpMethod.GET,null,new ParameterizedTypeReference&lt;ParkingSpot&gt;() {}, pincode).getBody();&#xA;        return new MessageWrapper&lt;&gt;(parkingSpot, ""server called using eureka with rest template"");&#xA;&#xA;This is how it is comming up in eureka:  &#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jfDVt.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/jfDVt.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>source code is available on <a href=""https://github.com/focode/microservices2/"" rel=""nofollow"">https://github.com/focode/microservices2/</a></p>&#xA;"
40081965,Where lookup tables should be placed in a microservices architecture?,2016-10-17 08:45:02,<microservices><lookup-tables>,1,268,3,1.0,2,"<p>In a microservices architecture, each microservice has its own database and tables should not be duplicated in different databases.&#xA;But there are tables, like lookup tables (called also reference tables), that are needed by multiple microservices.&#xA;Should we put lookup tables in each microservice database, or is it better to create a new microservice with a database holding all the lookup tables ?</p>&#xA;"
39891218,Setting up development environment in micro-services architecture,2016-10-06 08:30:12,<microservices><gateway>,1,365,4,0.0,2,<p>We are moving towards developing a web app in a micro-services architecture.<br>&#xA;We thought about running the services behind a API gateway that will handle authentication and will proxy the requests to the appropriate services.<br>&#xA;We have encountered a problem while setting up the development environment. How can we develop a service in a local machine (laptop) and test and run it in a way that is similar to the production (behind the gateway)?</p>&#xA;&#xA;<p>Consider the following requirements:</p>&#xA;&#xA;<ul>&#xA;<li>Inter process communication (B2B)</li>&#xA;<li>Manage and sync different versions</li>&#xA;<li>Access the service with authentication token (produced by the gateway)</li>&#xA;</ul>&#xA;
29825744,How to decide between using messaging (e.g. RabbitMQ) versus a web service for backend component interactions/communication?,2015-04-23 13:58:41,<web-services><rest><messaging><spring-rabbit><microservices>,2,1338,0,1.0,2,"<p>In developing backend components, I need to decide how these components will interact and communicate with each other. In particular, I need to decide whether it is better to use (RESTful, micro) web services versus a message broker (e.g. RabbitMQ).  Are there certain criteria to help decide between using web services for each component versus messaging?</p>&#xA;"
29775643,Microservice Event driven Design with multiple Instances,2015-04-21 14:49:06,<spring><jms><spring-jms><microservices><event-driven-design>,1,740,0,1.0,2,<p>At the Moment we design and plan to transform our system to a microservice architecture pattern. </p>&#xA;&#xA;<p>To loose coupling we think about an event driven design with an JMS Topic. This looks great. But i don't now how we can solve the problem with multiple instances of a microservice. &#xA;For failover and load balancing we have <em>n</em> instances of each service. If an event is published to the topic each instance will receive and process that event. </p>&#xA;&#xA;<p>It's possible to handle this with locks and processed states in the data storage. But this solution looks very expensive and every instance has the same work. This is not a load balaning for me. </p>&#xA;&#xA;<p>Is there some good Solution or best practice for this pattern?</p>&#xA;
44392569,Will istio add support for docker swarm?,2017-06-06 14:19:18,<docker><microservices><docker-swarm>,2,650,0,1.0,2,"<p><a href=""https://github.com/istio/istio"" rel=""nofollow noreferrer"">istio</a> An open platform to connect, manage, and secure micro-services looks very interesting, but supports only Kubernetes. I couldn't find a roadmap or mention of future support for other container management platforms, specifically Docker Swarm</p>&#xA;"
44433488,micro service architecture database backup and restore,2017-06-08 10:40:29,<docker><database-design><microservices><database-backups><database-restore>,1,402,0,0.0,2,"<p>I'm working on a big project, which is based on micro service architecture , so consider I have 10 service which some of them have their own database,&#xA;these databases are in different technologies (mysql, mongodb , elastic, ... )</p>&#xA;&#xA;<p>so what is the best practice for backup and restore collection of services?</p>&#xA;&#xA;<p>the real problem is these databases are related to each other, for example in my logic backend server I keep oauhId of each user which comes from oauth server,</p>&#xA;&#xA;<p>now consider restore these two databases separately and now my users db in logic server contains some users which there aren't any related records to them on oauth server,</p>&#xA;&#xA;<p>just for your information, I'm using docker , docker-compose, docker swarm for my service orchestration.</p>&#xA;"
44305351,Send data in Request body using HttpURLConnection,2017-06-01 10:41:06,<java><web-services><httpurlconnection><microservices><spark-java>,2,6350,0,1.0,2,"<p>I am using <code>HttpURLConnection</code> to make a POST request to a local service deployed in my local created using JAVA Spark.<strong>I want to send some data in request body when I make the POST call using the HttpURLConnection but every time the request body in JAVA Spark is null</strong>. Below is the code I am using for this</p>&#xA;&#xA;<h3>Java Spark POST Service Handler</h3>&#xA;&#xA;<p><code>post(""/"", (req, res) -&gt; {&#xA;        System.out.println(""Request Body: "" + req.body());&#xA;        return ""Hello!!!!"";&#xA;  });</code></p>&#xA;&#xA;<h3>HTTPClass Making the post call</h3>&#xA;&#xA;<pre><code>`public class HTTPClassExample{&#xA;   public static void main(String[] args) {&#xA;        try{&#xA;            URL url = new URL(""http://localhost:4567/"");&#xA;            HttpURLConnection httpCon = (HttpURLConnection) url.openConnection();&#xA;            httpCon.setDoOutput(true);&#xA;            httpCon.setRequestMethod(""POST"");&#xA;            httpCon.connect();&#xA;            OutputStream os = httpCon.getOutputStream();&#xA;            OutputStreamWriter osw = new OutputStreamWriter(os, ""UTF-8"");    &#xA;            osw.write(""Just Some Text"");&#xA;            System.out.println(httpCon.getResponseCode());&#xA;            System.out.println(httpCon.getResponseMessage());&#xA;            osw.flush();&#xA;            osw.close();  &#xA;        }catch(Exception ex){&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}`&#xA;</code></pre>&#xA;"
44274982,Spring Boot Application - what is default timeout for any rest API endpoint or a easy config to control all endpoint timeout,2017-05-31 03:08:28,<java><spring><rest><spring-boot><microservices>,4,10949,2,1.0,2,"<p>I am using current Spring boot version (1.4.x) and wondering if it has any default timeout for api calls. I have tested it by putting breakpoints but it was keep waiting and didn't time-out. &#xA;I was also trying to configure default timeout for all my spring-boot apps by using some annotation or yml settings. </p>&#xA;&#xA;<p>I found couple of alternatives (one of them <a href=""https://stackoverflow.com/questions/34852236/spring-boot-rest-api-request-timeout"">here</a>) but using callable actually adding extra non-business logic code where setting something in xml bean is out of fashion in latest spring boot applications.</p>&#xA;"
38922420,Microservices configuration server,2016-08-12 16:15:18,<microservices>,1,605,0,1.0,2,"<p>It's well understood that in a microservices architecture, configuration must be externalized. </p>&#xA;&#xA;<p>Tools like zookeeper, etcd or consul are excellent options to store that configuration. However a new layer on top of those services is required in order to provide new functionalities that are fundamental in a configuration server. Ex. versioning; change history; ""draft"" / published configuration, etc...</p>&#xA;&#xA;<p>I've found <a href=""https://github.com/spring-cloud/spring-cloud-config"" rel=""nofollow"">spring config server</a>, which is an interesting project and addresses all these concerns using git for handling the above mentioned requirements. However, I'd like avoid using git due to additional required setup. ex. replication, etc...</p>&#xA;&#xA;<p>Do you know any other options other then spring config server?</p>&#xA;"
46333040,Using docker-compose vs codeship-services in my CI pipeline,2017-09-20 23:11:02,<docker><docker-compose><microservices><codeship>,2,124,0,0.0,2,"<p>I am building an app that has a couple of <code>microservices</code> and trying to prototype a <code>CI/CD</code> pipeline using <code>Codeship</code> and <code>Docker</code>.</p>&#xA;&#xA;<p>I am a bit confused with the difference between using <code>codeship-services.yml</code> and <code>docker-compose.yml</code>. Codeship docs say - </p>&#xA;&#xA;<blockquote>&#xA;  <p>By default, we look for the filename codeship-services.yml. In its&#xA;  absence, Codeship will automatically search for a docker-compose.yml&#xA;  file to use in its place.</p>&#xA;</blockquote>&#xA;&#xA;<p>Per my understanding, <code>docker-compose</code> could be more appropriate in my case as I'd like to spin up containers for all the <code>microservices</code> at the same time for integration testing. <code>codeship-services.yml</code> would have helped if I wanted to build my services serially rather than in parallel. </p>&#xA;&#xA;<p>Is my understanding correct?</p>&#xA;"
46263443,Ehcache of spring doesn't work correctly between microservices,2017-09-17 11:12:26,<java><spring-boot><ehcache><microservices>,1,137,0,0.0,2,"<p>I have a monolithic application.According to microservices appearance and It that needs to adapt with this appearance splited into small APPs.You assume after splinting each Microservice has a model that has one object that is same in all microservices.The following example for clearing.</p>&#xA;&#xA;<p>Into Micro1:</p>&#xA;&#xA;<pre><code>Class A {&#xA;private Object obj;&#xA;&#xA;//getter and setter&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Into Micro2:</p>&#xA;&#xA;<pre><code>Class B {&#xA;private Object obj;&#xA;&#xA;//getter and setter&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and <code>Object obj</code> has its own repository and service and controller layer.<br />&#xA;There is the config of ehcash of spring at save method into service layer of this model. like this:</p>&#xA;&#xA;<pre><code>@Transactional&#xA;@Override&#xA;@Caching(evict = { @CacheEvict(value = ""obj"", key = ""#obj.id"" ) })&#xA;public Integer save(Object obj) {&#xA;    //Code here&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>It was working when the application was a monolithic but after spliting because of this <code>obj</code> as a dependency is into all Microservices and this method(save method) is repeated into each microservice,the ehcash doesn't work correctly.<br />&#xA;How do I do that when each microservice affects the Object obj other microservices aware to.</p>&#xA;"
46425554,Exposed domain model in Java microservice architecture,2017-09-26 11:40:30,<jpa><entity><microservices><dto>,2,284,2,1.0,2,"<p>I'm aware that copying entity classes and properties into DTOs is considered anti-pattern, so by <code>Exposed domain model</code> pattern the same <code>@Entity</code> can be used as both database entity class, and DTO for service and MVC layer. (see here <a href=""https://codereview.stackexchange.com/questions/93511/data-transfer-objects-vs-entities-in-java-rest-server-application"">https://codereview.stackexchange.com/questions/93511/data-transfer-objects-vs-entities-in-java-rest-server-application</a>)</p>&#xA;&#xA;<p>But suppose we have microservice architecture where the same set of properties is used as entity in one project with persistence, and as DTO in another project which uses the first one as a service. What's the proposed pattern in such a situation?&#xA;Because the second project doesn't need <code>@Entity</code> related functionality, and if we put that class in shared library, it will be tied unnecessary to JPA specific APIs and libraries. And the alternative is to again use separate DTO classes anti-pattern.  </p>&#xA;"
46291406,How to design a database idempotent microservice (POST),2017-09-19 03:40:46,<rest><http-post><microservices>,1,209,2,0.0,2,"<p>This is a very general and basic question regarding how to design a POST database service (new to implementing microservice). Say you have a SaveCustomer microservice. You so a POST to pass the customer data, and the SaveCustomer service receives the data (JSON) and inserts it into the database.</p>&#xA;&#xA;<p>Due to network congestion etc, the client might retry and send duplicate requests, so how do you ensure that you dont insert duplicate records in the database?</p>&#xA;&#xA;<p>Thanks&#xA;Obaid</p>&#xA;"
44540545,Microservices. What is difference between Service registry and service discovery,2017-06-14 09:18:44,<microservices><service-discovery>,1,2488,0,0.0,2,"<p>I am new to Microservice. I cam e across term  Service registry and service discovery. &#xA;What I understood is when a new service(or service instance comes up) then it will register itself with ""service registry"". It is also mentioned that client can contact service registry and get the list of IP-port where that service is available.  </p>&#xA;&#xA;<p>In that case what is the role of ""service discovery"". </p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>Accepted answer. Also more theoretical details were found <a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/</a></p>&#xA;"
44619634,What is the best way to run multiple services that use Socket.io,2017-06-18 21:19:51,<node.js><sockets><websocket><socket.io><microservices>,2,604,1,1.0,2,"<p>I am developing a website where I will use microservices.</p>&#xA;&#xA;<p>I will have a couple or more Node.js application that will use Socket.io.</p>&#xA;&#xA;<p>I was trying to figure out how I will architecture this.</p>&#xA;&#xA;<p>Can I use multiple Node.js with Socket.io connecting to a user or will I run into conflicts? I can use NGiNX as a proxy a an UUID to identify which microservice to send the request to. Does that make sens? Is there a better way?</p>&#xA;&#xA;<p>Or I was also thinking of using a Node.js has a proxy that receives all the Socket.io connection and then it creates a connection with the user. But this seems to be adding to the network load because I am adding a another microservice.</p>&#xA;&#xA;<p>Anyways, I would love your views on this.</p>&#xA;"
44597832,Managing a multi-tenant connection pool with separate schema/DB approach,2017-06-16 20:53:37,<architecture><multi-tenant><microservices>,1,428,2,1.0,2,"<p>Say that I have a multi-tenant monolithic application, which uses a separate schema (or DB) approach to isolate the tenants' data. A single running instance of the application is used by multiple tenants to access their data. The diagram below sums up the idea:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ymalt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ymalt.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>So far, so good. Now, I have to scale the application up. To do so, I increase the number of running instances, and the load balancer routes each request to one of the instances. By doing so, each instance keeps a connection pool for each tenant's database, since it can serve requests from any tenant. The result is something like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/uyosV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uyosV.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The problem is that it grows up exponentially as the number of tenants increases -- higher number of tenants demands more running instances, both of them demands a higher number of connections which demands an increasing number of resources just to keep track of the connection pool. It gets worse if I have a microservices application.</p>&#xA;&#xA;<p><strong>My question is</strong>: Is this approach maintainable? What are the possible alternatives and how can one implement them?</p>&#xA;"
44460206,microservice deployment in firebase hosting for an app,2017-06-09 14:20:55,<firebase><microservices><google-cloud-functions><firebase-hosting>,1,216,2,0.0,2,"<p>I've built an app with polymer 2.0 and polymerfire and deployed it into firebase hosting. This part is smooth. </p>&#xA;&#xA;<p>But I wanted to maintain all my cloud functions as separate modules / separate projects and deploy them independently into firebase hosting. As per the Google IO 2017 talks, it is advised to go microservice style for the cloud functions. </p>&#xA;&#xA;<p>The problem I am facing: </p>&#xA;&#xA;<p>Whenever I deploy an individual module, it erases all the previously deployed cloud functions. Meaning <code>firebase deploy</code> from a project with only firebase functions enabled, will erase all the other cloud functions and deploy the ones declared in this project.</p>&#xA;&#xA;<p>In a nutshell, it looks like I need to create a single monolith with the complete web application, all the cloud functions all in one single fat project and deploy the whole thing. This defeats the point of being microservice style! </p>&#xA;&#xA;<p>Please advise if I am missing something important in the whole setup procedure?</p>&#xA;"
31525237,how to get scope associated with access token in Spring OAuth while building microservices?,2015-07-20 19:56:35,<spring><spring-security><oauth-2.0><microservices>,1,733,0,0.0,2,"<p>I am in the process of spinning up a <code>microservices</code> system with a central <code>Authorization Server</code> that grants <code>tokens</code> with different scopes for accessing individual micro-service.</p>&#xA;&#xA;<p>Here is the picture explaining the various service calls.&#xA;The numbers marked are requests made in the chronological order.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/8R9CP.png"" alt=""enter image description here""></p>&#xA;&#xA;<p><strong>1)</strong> In a nut-shell, I want the auth Server to return <code>access-token</code> with a User identifer (id) and scope when controller makes a login call. just like the following example taken from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow noreferrer"">spring tutorial</a> (but this is missing id). how can I have the id retured with the token returned?. I prefer not to make another REST call as proposed in the tutorial.</p>&#xA;&#xA;<pre><code>$ curl acme:acmesecret@localhost:9999/uaa/oauth/token  \&#xA;-d grant_type=authorization_code -d client_id=acme     \&#xA;-d redirect_uri=http://example.com -d code=jYWioI&#xA;{""access_token"":""2219199c-966e-4466-8b7e-12bb9038c9bb"",""token_type"":""bearer"",""refresh_token"":""d193caf4-5643-4988-9a4a-1c03c9d657aa"",""expires_in"":43199,""scope"":""openid""}&#xA;</code></pre>&#xA;&#xA;<p><strong>2)</strong> How does the photo Service which receives the access token in the ""Authorization bearer"" header checks with Auth Server to see the token is valid and it has the scope required to access the photo. (for example, if Auth Server responds back with list of scopes this token is eligible for, Post service can check among the list of scopes, if it can provide access).</p>&#xA;&#xA;<p><strong>3)</strong> on a side note, I see the <code>-d code=jYWioI</code> is passed in above the request, but not sure why it is passed and whats the purpose of it?</p>&#xA;"
51613104,How to create Spring Cloud Config Client with env specific configuration?,2018-07-31 12:11:19,<spring-boot><microservices><spring-cloud-config>,1,47,0,1.0,2,"<p>I have facing an issue with Spring Cloud Config Server and Eureka Server Profiling.<br>&#xA;Let's say I have 3 services with their name (""spring.application.name"") as :</p>&#xA;&#xA;<pre><code>myapp-svc&#xA;myapp-spring-cloud-config-svc&#xA;myapp-spring-eureka-svc&#xA;</code></pre>&#xA;&#xA;<p>I want to deploy each service in 2 regions ( dev and prod ). In Dev region, each service will run on localhost and in prod it will have some different url.    'myapp-spring-cloud-config-svc' in dev region will point to local git repo, while in prod region it will point to remote git repo.I can have 2 configurations:</p>&#xA;&#xA;<p>1)  When I start 'myapp-svc' service in local, it should connect to 'myapp-spring-cloud-config-svc' in dev. &#xA;      I can do this by setting spring.cloud.config.uri = .&#xA;      But the issue with this set up is that the property needs to be defined in bootstrap.properties. &#xA;      So, If deploy 'myapp-svc'  to prod, I will have to change config uri there to point it to prod config service which in turn would need another build creation.&#xA;      This doesn't seem like a good solution, what if I have 50 app related services, I can't change this property in each one of them before prod deployment.&#xA;      I tried setting spring.cloud.config.uri in application-dev.properties of 'myapp-svc' but it doesn't work. As per docs, it must be changed in bootstrap.</p>&#xA;&#xA;<pre><code>  So, how do I implement this without having to create new build for prod ?&#xA;</code></pre>&#xA;&#xA;<p>2) I can first call eureka and then using eureka I can call config service here.&#xA;       The problem here is also same.&#xA;       If I use eureka to look up config then ""eureka.client.serviceUrl.defaultZone"" must be defined in ""bootstrap.yml"".&#xA;       See this:<a href=""https://cloud.spring.io/spring-cloud-config/multi/multi__spring_cloud_config_client.html"" rel=""nofollow noreferrer"">https://cloud.spring.io/spring-cloud-config/multi/multi__spring_cloud_config_client.html</a>&#xA;So, in this case too, I need to change eureka url before deploying this service to prod.&#xA;Please help me on this...!!&#xA;  Here is how, the properties, yml looks like for each of the above mentioned services:</p>&#xA;&#xA;<pre><code>1) myapp-svc:&#xA;   1.1)bootstrap.yml  &#xA;        spring:&#xA;         application:&#xA;           name: myapp-svc &#xA;         cloud:&#xA;           config:&#xA;             discovery:&#xA;               enabled: true&#xA;               serviceId: myapp-spring-cloud-config-svc&#xA;        eureka:&#xA;           client:&#xA;              serviceUrl:&#xA;                defaultZone: http://localhost:8762/eureka/&#xA;        server:&#xA;           port: 8082&#xA;&#xA;&#xA;    2) myapp-spring-cloud-config-svc:&#xA;&#xA;      2.1)application-dev.properties:&#xA;           spring.cloud.config.server.git.uri=file:///C:/config-repo&#xA;           eureka.client.serviceUrl.defaultZone=http://localhost:8762/eureka&#xA;&#xA;      2.2)application-prod.properties:&#xA;           spring.cloud.config.server.git.uri=https://github.com/&lt;mygit Repo&gt;&#xA;&#xA;      2.3)bootstrap.proerties:&#xA;           spring.application.name=myapp-spring-cloud-config-svc&#xA;           server.port=8888&#xA;&#xA;&#xA;    3) myapp-spring-eureka-svc&#xA;       3.1)bootstrap.proerties&#xA;        spring.application.name=myapp-spring-eureka-svc&#xA;        server.port=8762&#xA;</code></pre>&#xA;"
51641688,Asynchronously build Hibernate Search index to ensure no downtime.,2018-08-01 20:20:59,<java><hibernate><lucene><microservices><hibernate-search>,1,29,2,0.0,2,"<p>We are using Hibernate Search (Lucene Engine) to enable fuzzy search for text some data we are storing in SQL Server database and consumed by a search service written in Java 8. The data source for the search is a table with moderate edit/update frequency. What we need is that for any change made while the index is rebuilt, we want to ensure that search function is still running and accessible instead of getting locked by process of index being built.</p>&#xA;&#xA;<p>In short, how to temporarily use existing index while a new is being built and replace it on completion.</p>&#xA;"
42134186,How to use same DB for two ddp connected applications,2017-02-09 10:28:47,<javascript><mongodb><meteor><microservices>,1,28,0,0.0,2,"<p>I have connected two meteor applications via DDP. I expected to get the DB data also on the second service application, but I don't get any data.&#xA;As both is running on server side I didn't do any subscription - which I think I don't have to in this example.</p>&#xA;&#xA;<p>What am I doing wrong?</p>&#xA;&#xA;<ol>&#xA;<li>Starting main web application: <code>meteor</code> (which should load mongodb on port 3001)</li>&#xA;<li>Starting service application: <code>MONGO_URL=mongodb://localhost:3001/mydb meteor --port 3100</code></li>&#xA;</ol>&#xA;&#xA;<p><em>Web (main)</em>&#xA;<strong>/server/main.js</strong></p>&#xA;&#xA;<pre><code>Examples = new Mongo.Collection('examples');&#xA;var serviceConn = DDP.connect(""http://localhost:3100"");&#xA;console.log(Examples.find().count()); // Returns 21&#xA;</code></pre>&#xA;&#xA;<p><em>Service 1</em>&#xA;<strong>/server/main.js</strong></p>&#xA;&#xA;<pre><code>Examples = new Mongo.Collection('examples');&#xA;console.log(Examples.find().count()); // Returns 0 !&#xA;</code></pre>&#xA;&#xA;<p>So why can't I get the collection data on the service application as it gives me 0 results?</p>&#xA;"
36698706,Service Fabric: Consistency when updating state between stateful services,2016-04-18 15:47:20,<architecture><microservices><azure-service-fabric>,1,155,0,0.0,2,"<p>Let's imagine there was some code like this in a stateful service:</p>&#xA;&#xA;<pre><code>public async Task&lt;bool&gt; UpdateTheThing()&#xA;{&#xA;    using (var tx = StateManager.CreateTransaction())&#xA;    {&#xA;        await UpdateLocalState(tx);&#xA;        // point a&#xA;        bool isOK = await otherServiceProxy.UpdateServiceState();&#xA;        // point b&#xA;        if(isOK)&#xA;        {   &#xA;            await tx.CommitAsync();&#xA;        }&#xA;        return isOK;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If something bad happens anywhere up to point a we're safe - the transaction will deal with &#xA;ensuring the data is consistent. If something happens between point a and point b we may&#xA;or may not have updated the state on the other service.</p>&#xA;&#xA;<p>If the bad thing that happened was that an exception was thrown, it's feasable we could&#xA;recover the state on the other service, but if our node was shut down at that point, we'd&#xA;never recover the state.</p>&#xA;&#xA;<p>One way I know to fix a problem like this would be to do the following:</p>&#xA;&#xA;<ol>&#xA;<li>Make UpdateTheThing do nothing other than adding a command to a queue</li>&#xA;<li>Implement some logic to process the queue</li>&#xA;<li>Invent some way to get the result (isOk) back to the caller</li>&#xA;<li>Make UpdateServiceState idempotent</li>&#xA;<li>Make the queue keep retrying the command if there's a problem</li>&#xA;<li>Invent some way to remove the command from the queue if the problem keeps happening and somehow inform someone that there's been a problem.</li>&#xA;</ol>&#xA;&#xA;<p>This is quite a lot of infrastructure to put into place. I'm looking for suggestions of a simpler approach.</p>&#xA;&#xA;<p>I notice that none of the Service Fabric samples seem to deal with this problem.</p>&#xA;"
51071363,Microservices Concurrent Payments on The Same Account,2018-06-27 21:02:51,<concurrency><locking><microservices>,1,44,0,0.0,2,"<p>Let us say that we have a transaction microservice that transfers money from one account to another account using mysql as the data store.</p>&#xA;&#xA;<p>Let us say that there is a request called K to transfer money from account A to account B. There is also another request Z from Account A to Account C concurrently to transfer money. My question is what strategy should a transaction microservice use when Account B is locked during processing? Should request Z time out and return an error, should request Z try multiple times?</p>&#xA;"
50932766,Client application not registering on SBA server,2018-06-19 16:11:59,<java><spring-boot><microservices><spring-boot-admin>,1,88,0,0.0,2,"<p>I have an application running as a Spring boot admin server and a couple of client microservices which register successfully on the server - even on Docker.</p>&#xA;&#xA;<p>However, I have one client application which does not register on the SBA server. I have followed the same steps that I did for the other client applications (added dependencies and changed the application.properties file) as is mentioned in the documentation; but this service does not register. </p>&#xA;&#xA;<p>Surprisingly there is nothing in the logs of both the server and the client. I also tried throwing an <code>UnknownHostException</code> on purpose by specifying an incorrect <code>spring.boot.admin.url</code> and an incorrect <code>spring.boot.admin.client.url</code> in the .properties file of the client, but there are still no logs. I've tried restarting docker, restarting intellij, cleared .m2 folder. Nothing seems to help.</p>&#xA;"
51099034,Map JPA Embedded entity class id to Embeddable entity class id,2018-06-29 09:53:58,<java><hibernate><spring-data-jpa><microservices><hibernate-mapping>,2,119,5,0.0,2,"<p>I have a class:</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class A {&#xA;    @Embedded&#xA;    @AttributeOverride(name = ""id"", column = @Column(name = ""b_id""))&#xA;    private B b;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There is column b_id BIGINT NOT NULL in table A</p>&#xA;&#xA;<pre><code>@Embeddable&#xA;@Entity&#xA;public class B {&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>we are getting error: Caused by: org.hibernate.MappingException: component property not found: id</p>&#xA;&#xA;<p>Basically, we need to map B in A using id</p>&#xA;&#xA;<p>Kindly help</p>&#xA;"
38178535,How to share the web API controllers with microservice,2016-07-04 06:55:40,<c#><asp.net-web-api><microservices><asp.net5>,1,1301,0,0.0,2,<p>We have an existing Web API that is built using ASP.Net 5 framework. We plan to develop new micro services now. We are trying to re-use the code of existing API as far as possible. Our old API (monolithic) or our new micro services will be deployed based on customer need.</p>&#xA;&#xA;<p>We are finding it tough to share the Controllers between monolithic API and micro services. Thought of using 'add as link file' but that is not working in case of controller files. Any other ways to share the controllers?</p>&#xA;
38049334,Manage multiple dependencies between microservices using Maven,2016-06-27 08:39:27,<maven><dependencies><release><microservices>,1,760,0,0.0,2,<p>We are using Maven to define and manage our dependencies between our microservices. Here is an example:</p>&#xA;&#xA;<p><strong>Microservice 1</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-1&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.04-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice 2</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-3&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.28.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>The problem is that the release phase is taking a lot of time and is fully manual:</p>&#xA;&#xA;<ol>&#xA;<li>perform <code>mvn:release</code> for the first microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>change the version in <code>pom.xml</code> of the dependency</li>&#xA;<li>perform <code>mvn:release</code> for the second microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>and so on (actually on 15 microservices...)</li>&#xA;</ol>&#xA;&#xA;<p>I'm wondering if there is any automatized way to perform this release (in cascade)? </p>&#xA;&#xA;<p>Thanks</p>&#xA;
38045423,What is the concept of Ambassador in distributed systems?,2016-06-27 03:21:58,<docker><architecture><cluster-computing><microservices><docker-swarm>,1,199,1,0.0,2,"<p>Can someone explain to me in simple terms what is the architectural concept of an Ambassador in cluster computing? What are the benefits of implementing it in a microservice architecture patterns? </p>&#xA;&#xA;<p>I've been studying docker and docker-swarm lately and I've been seen this term mentioned repeatedly across articles or repos. For example in <a href=""https://github.com/openstf/stf"" rel=""nofollow"">this amazing project</a>, they have a repository called <a href=""https://github.com/openstf/docker-ambassador"" rel=""nofollow"">docker-ambasssador</a>. Or this other project called <a href=""https://github.com/CenturyLinkLabs/ctlc-docker-ambassador"" rel=""nofollow"">ctlc-docker-ambassador</a>.</p>&#xA;"
38197629,Azure service fabric : not accepting normal or portable class libraries,2016-07-05 07:29:25,<c#><azure><service><microservices><appfabric>,1,238,2,0.0,2,"<p>I am trying to deploy a service(asp.net core template. Stateless web API) to local cluster. I need to refer some existing class libraries. Some of these class libraries are portable type and others are normal class libraries. The solution is compiling fine but while deploying I am getting following error.</p>&#xA;&#xA;<p><strong><em>The OutputPath property is not set for project.  Please check to make sure that you have specified a valid combination of Configuration and Platform for this project.  Configuration='Debug'  Platform='x64'.</em></strong></p>&#xA;&#xA;<p>Is there a way to refer portable and normal class libraries with service fabric?&#xA;Any help appreciated.</p>&#xA;&#xA;<p>Thanks, Jojo</p>&#xA;"
38049329,"DDD, Microservices and data direction",2016-06-27 08:39:06,<domain-driven-design><microservices>,2,170,3,1.0,2,"<p>Let's assume I have Identity Management bounded context and discussion bounded context. Each of those is a separate micro service.</p>&#xA;&#xA;<p>Identity has Users, Discussion has Moderators.</p>&#xA;&#xA;<p>If I update first and last name in the Identity bounded context, my plan is to publish a message to Amazon SQS, and have discussion bounded context to listen that queue for any changes, and update first and last name in discussion context via Anti-Corruption layer.</p>&#xA;&#xA;<p>My question is, what if I decide to change first name and last name in the Discussion BC? Should my Identity BS listen for that changes too, or having bi-directional communication is not considered a good practice, and I should always update that information inside Identity BC?</p>&#xA;"
38006427,Building a microservices application on. Net?,2016-06-24 05:53:13,<.net><f#><microservices>,1,1024,5,0.0,2,"<p>I plan to build an internal application for my company and want to implement it in micro services. All the servers in my company is Windows servers. </p>&#xA;&#xA;<p>I'm thinking build it using asp.net core, etc. Is there a good example available? What kind of tech stack it will need?</p>&#xA;"
36291878,Microservices - IPC authentication/authorization,2016-03-29 18:06:34,<authentication><microservices>,2,297,0,0.0,2,"<p>We're trying to figure out a best practice for IPC authentication and authorization. I'll explain.&#xA;We have a micro-services based architecture SaaS with a dedicated service for authentication. This service is responsible for doing the authentication and managing auth tokens (JWTs).</p>&#xA;&#xA;<p>Everything works perfectly good with users that login and start to consume resources from the different services.</p>&#xA;&#xA;<p>The question now is how to authentication and authorize requests which being initiated by other services (without the context of a specific user)?</p>&#xA;&#xA;<ol>&#xA;<li>Should we generate a dedicated user per service and treat it like&#xA;any other user in the system (with appropriate permissions)? </li>&#xA;<li>Should&#xA;we have a ""hard coded""/dynamic token deployed among the services?</li>&#xA;<li>Any other ideas?</li>&#xA;</ol>&#xA;&#xA;<p>Our biggest concern is such tokens/passwords will be compromised at some point since requests from one service to another is treated with high level of permissions.</p>&#xA;&#xA;<p>Cheers,</p>&#xA;"
36152538,Kubernetes can not get its own cluster IP,2016-03-22 10:56:50,<docker><kubernetes><microservices>,1,47,0,0.0,2,"<p>I have 3 kubernetes services which are:</p>&#xA;&#xA;<pre><code>service 1:&#xA;&#xA;name: abc&#xA;&#xA;service 2:&#xA;&#xA;name: def&#xA;&#xA;service 3:&#xA;&#xA;name: hgk&#xA;</code></pre>&#xA;&#xA;<p>In application running on service 1, I successfully use environment variables to get cluster IP of other services. </p>&#xA;&#xA;<pre><code>System.getenv(DEF_SERVICE_HOST); --&gt; success&#xA;System.getenv(HGK_SERVICE_HOST); --&gt; success&#xA;</code></pre>&#xA;&#xA;<p>However, when I call the service 1 's environemnet, it return null</p>&#xA;&#xA;<pre><code>System.get(ABC_SERVICE_HOST); ---&gt; null &#xA;</code></pre>&#xA;&#xA;<p>Looks like it can not get its own cluster IP. </p>&#xA;&#xA;<p>Do you guys have any ideas?&#xA;Thank you very much!</p>&#xA;"
36307211,How to override url suffix for hystrix metrics stream endpoint?,2016-03-30 11:17:08,<spring-boot><dropwizard><metrics><microservices>,1,320,0,0.0,2,"<p>In our setup we have lots of dropwizard services which are streaming their metrics to a hystrix dashboard.</p>&#xA;&#xA;<p>We are writing a new service in Spring Boot and would like the metrics stream to be on the same url as the dropwizard one but I can't find out how to override the stream servlet's url pattern.</p>&#xA;&#xA;<p>I'm sure this is configurable somehow, any ideas?  </p>&#xA;"
36272482,Write out Spring Boot metrics to Stdout or aggregator?,2016-03-28 22:45:25,<spring-boot><spring-integration><metrics><microservices>,1,416,2,1.0,2,"<p>I have a java application written on top of Spring Boot and I can see the metrics being generated through the <code>/metrics</code> management API. I would like to filter the metrics that are being generated (based on metric prefix) and print to stdout OR send the selected metrics to a 3rd party aggregator (not the ones referenced <a href=""http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html#production-ready-metric-writers"" rel=""nofollow noreferrer"">here</a>) </p>&#xA;&#xA;<p>I tried the code suggested by this <a href=""https://stackoverflow.com/questions/29627061/subscribe-to-spring-metrics-channel"">answer</a> but it didn't result in any metrics being written to the stdout. This is what I added to my <code>Application.java</code> class:</p>&#xA;&#xA;<pre><code>@Bean&#xA;@ServiceActivator(inputChannel = ""metricsChannel"")&#xA;    public MessageHandler metricsHandler()Â {&#xA;        return System.out::println;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What is the best way to intercept the metrics on a preconfigured cadence so I can process and write them to stdout or publish them to an aggregator? </p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
39388560,OpenID Connect ID Token: What's the purpose of audience [aud] field validation,2016-09-08 10:28:45,<security><microservices><openid-connect>,1,573,0,0.0,2,"<p>I'm trying to implement <a href=""http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth"" rel=""nofollow"">OpenID Connect Implicit Flow</a>. The frontend Single Page App passes the ID Token down to the backend server (using Authorization header) where I need to validate it.</p>&#xA;&#xA;<p>The documentation requires me <a href=""http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation"" rel=""nofollow"">to check</a> that I trust the audience of the token (aud &amp; azp fields). I'm struggling to understand the significance of this validation step and what are the security implications of not doing so. Why should I distrust the token if I'm not the intended recipient?</p>&#xA;&#xA;<p>My reasoning is that if I trust the issuer it doesn't matter who was the token issued for. I would expect the claims to be the same for any clientId (is this wrong?). Ideally when I pass the ID Token around my microservices all they should know is what issuers to trust (and use <a href=""https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig"" rel=""nofollow"">discovery protocol</a> for figuring out the keys).</p>&#xA;&#xA;<p>What is the attack vector if I skip this validation step?</p>&#xA;"
39224930,jhipster 3 Migrate from monolithic to microservices,2016-08-30 10:24:52,<migration><jhipster><microservices>,2,635,0,2.0,2,"<p>Currently I've a JHipster 3.3 monolithic application and I would like to migrate to microservices architecture. I've already created the registry, the gateway and the uaa service. Now I need to migrate the core business of my application into a microservice. Is there a facility to perform it? Can I make it automatically?</p>&#xA;"
39364466,How to dockerized java microservices efficiently,2016-09-07 08:06:47,<java><docker><jvm><microservices><application-server>,1,383,1,2.0,2,"<p>While a java application server will extend a unique JVM to run several (micro)services, a dockerized java microservices architecture will run a JVM for each dockerized microservice.&#xA;Considering 20+ java microservices and a limited number of host it seems that the amount of resources consumed by the JVMs on each host is huge.</p>&#xA;&#xA;<p>Is there an efficient way to manage this problem ? Is it possible to tune each JVM to limit resources consumption ?&#xA;The aim is to limit the overhead of using docker in a java microservices architecture.</p>&#xA;"
39358842,Recommended approach to deal with JSON in microservices,2016-09-06 22:42:17,<json.net><asp.net-web-api2><microservices>,1,389,2,0.0,2,"<p>I have RESTful API that only deals with underneath SQL Server database. The API method accepts a JSON string. This string is exact representation of EF Entity. Idea is to convert the string to Entity and Save it. Something along the line of code below</p>&#xA;&#xA;<pre><code>[HttpPost]&#xA;public void ApiMethod([FromBody] string request)&#xA;{&#xA;    var doc = JsonConverter.DeserializeObject&lt;Document&gt;(request);&#xA;    _dbContext.Documents.Add(doc);&#xA;    _dbContext.SaveChanges();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I wanted to know is okay to expose Entity structure to external clients?</p>&#xA;&#xA;<p>An Alternate approaches would be  </p>&#xA;&#xA;<p>Approach 1: Convert json string to dynamic and the build the required entity by mapping properties.</p>&#xA;&#xA;<pre><code>[HttpPost]&#xA;public void ApiMethod([FromBody] string request)&#xA;{&#xA;     dynamic anonymousDoc = JsonConverter.DeserializeObject(request);&#xA;     var doc = new Document()&#xA;     {&#xA;        Property1 = anonymousDoc.Property1,&#xA;        Property2 = anonymousDoc.Property2&#xA;     }&#xA;    _dbContext.Documents.Add(doc);&#xA;    _dbContext.SaveChanges();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Approach 2: Create strongly type DTO</p>&#xA;&#xA;<pre><code>[HttpPost]&#xA;public void ApiMethod([FromBody] string request)&#xA;{&#xA;     var dto = JsonConverter.DeserializeObject&lt;DocumentDTO&gt;(request);&#xA;     var doc = new Document()&#xA;     {&#xA;        Property1 = dto.Property1,&#xA;        Property2 = dto.Property2&#xA;     }&#xA;    _dbContext.Documents.Add(doc);&#xA;    _dbContext.SaveChanges();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However I have to create lots of DTOs here with almost same properties.</p>&#xA;&#xA;<p><strong>Question 1 :</strong> What would be a recommended approach here?</p>&#xA;&#xA;<p><strong>Question 2 :</strong> (<em>This question is kind of related to question 1 so I'm posting it here instead of creating new post.)</em> The API I mentioned above is a part of microservices architecture. I have bunch of microservices that communicate with each other over HTTP. Since all the services are decoupled from each other there is no strongly typed data contract. So I though passing JSON would be a good approach. I am using <code>Newtonsoft.json</code> for serialization/de-serialization since it has better performance than microsoft's native DataContractJsonSerializer.&#xA;again is this correct approach to communicate between microservices.</p>&#xA;"
38931315,Is it possible to add a favicon to sefl-hosted web api service?,2016-08-13 09:32:50,<asp.net-web-api><owin><favicon><microservices><self-host-webapi>,1,263,0,0.0,2,"<p>I have many services that I'm moving from ordinary Web API to Owin/Katana as self-hosted web api services. Because we were somehow using Microservices, we have many small services that would run and all of them had the same favicon.ico that showed our branding across our services to developers. Is it possible to add a favicon to self-hosted web api? How?</p>&#xA;"
38964840,Text search for microservice architectures,2016-08-16 00:17:58,<elasticsearch><architecture><microservices>,1,1133,0,1.0,2,"<p>I am investigating into implementing text search on a microservice based system. We will have to search for data that span across more than one microservice. </p>&#xA;&#xA;<p>E.g. say we have two services for managing Organisations and managing Contacts. We should be able to search for organisations by contact details in one search operation.</p>&#xA;&#xA;<p>Our preferred search solution is Elasticsearch. We already have a working solution based on embedded objects (and/or parent-child) where when a parent domain is updated the indexing payload is enriched with the dependent object data, which is held in a cache (we avoid making calls to the service managing child directly for this purpose). </p>&#xA;&#xA;<p>I am wondering if there is a better solution. Is there a microservice pattern applicable to such scenarios?</p>&#xA;"
39134238,Client authentication in microservices using JWT and OpenID Connect,2016-08-24 22:57:09,<api><authentication><jwt><microservices>,1,994,0,1.0,2,"<p>I've some questions regarding authentication in a microservices architecture. I've right now a monolithic application and my goal is to split the application in small microservices.</p>&#xA;&#xA;<p>My bigest problem is for authentication (for now). After reading a LOT a documentation, It seems that the best solution is to use OpenID Connect to authenticate an user to retrieve a JWT that can by passed with the request to the microservices. </p>&#xA;&#xA;<p>Also, to avoid having multiple endpoints, you can deploy and API Gateway to have only one endpoint for the end user. Ok, so now I've two questions with this architecture.</p>&#xA;&#xA;<p>The standard flow for authentication will be :</p>&#xA;&#xA;<p>An user contact my identity server in OpenID Connect with the implicit flow and get the id_token (JWT) and also the access_token. The user can now contact my API with this access_token. The API Gateway will valide the access_token with the identity server and also retrieve the JWT to add it to the sub request to the microservice API. </p>&#xA;&#xA;<p>1/ How the API Gateway can get the JWT from the access_token? From what I red from the documentation (<a href=""http://openid.net/specs/openid-connect-core-1_0.html"" rel=""nofollow"">http://openid.net/specs/openid-connect-core-1_0.html</a>), It can contact the ""/userinfo"" endpoint but It will get just the JSON format not the JWT...</p>&#xA;&#xA;<p>2/ I want to allow authenticated calls between my microservices. So each microservice needs to be able to generate a JWT to contact other microservices directly. My first thought was to contact the identity server. But with the OAuth2 Client Credentials flow, I don't retrieve a id_token or a JWT. Just a classic OAuth2 access token without JWT. My second thought was that the microservice can directly sign its own JWT with a certificate issued by the same PKI as the one used by the identity server. That mean that a JWT can be sign by several certificats but from the same private PKI. When a microservice receives a JWT, It needs to be able to identify witch certificat was used to sign the JWT. I don't find anything on the RFC regarding this problem. I can add my own private claim in the token to have the certificate but after several days of browsing the web without seeing this kind of solution, I'm wondering if I'm not on the wrong path... To sum up, how can i perfom ""User to service"" authentication AND alors ""service to service"" authentication in JWT?</p>&#xA;&#xA;<p>Thank you very much!</p>&#xA;"
38966184,Should business logic be contained in individual services in a micro service ecosystem?,2016-08-16 03:26:29,<architecture><microservices>,2,1341,2,0.0,2,<p>Let's say I just have 2 services <strong>Billing</strong> and <strong>Orders</strong> and one API gateway which may fan out requests to these services for billing or creating orders. </p>&#xA;&#xA;<p>Given this new order scenario:</p>&#xA;&#xA;<ol>&#xA;<li>user creates an order (request -> Rest API)</li>&#xA;<li>User validation has to be done</li>&#xA;<li>Order entity has to be created</li>&#xA;<li>Billing entity has to be created </li>&#xA;<li>Notification has to be done to notify the user</li>&#xA;</ol>&#xA;&#xA;<p>Where should my application logic sit ? and should the calls to these services be done synchronously (within the rest api) ? or each service should be responsible for calling another ? eg:</p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> (if successful) Rest API -> (if successful) calls the billing service</p>&#xA;&#xA;<p><strong>Or</strong></p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> returns the response. Then order service takes of things from there on asynchronously ?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
39071178,SOA versus NuGet Packages,2016-08-22 03:54:20,<architecture><nuget><soa><nuget-package><microservices>,1,370,2,0.0,2,"<p>I'm interested in a services-based architecture, loosely based on the concept of microservices. Our management is of the view that this is in place, as we are building Nuget Packages. I feel there is a different, but can't quite articulate... What is a ""microservice"" or ""SOA"" giving that is different from re-use of Nuget packages?</p>&#xA;"
37143689,JHipster Registry rejects gateways and microservices,2016-05-10 16:03:40,<jwt><jhipster><microservices><spring-cloud-config>,2,2306,0,1.0,2,"<p>I'm trying to use JHipster for a project using microservices, but the latest JHipster Registry won't let my gateway or microservices access the config server and rejects them.</p>&#xA;&#xA;<p>I installed the JHipster Vagrant DevBox, then used <code>docker run -p 8761:8761 jhipster/jhipster-registry</code> to run the JHipster registry.&#xA;Then, I generated a gateway and 2 microservices following <a href=""http://www.ipponusa.com/blog/jhipster-3-0-introducing-microservices/"" rel=""nofollow"">this</a>, and it worked.</p>&#xA;&#xA;<p>But then I wanted to use the JHipster Registry from GitHub, so I cloned it and runned it (apparently it had been updated to 2.0.0 in the meantime). Sadly, the gateway and the microservices weren't able to access this registry. They were still able to access the Docker image registry though (I suppose Docker didn't update it). But since it was fancier, and probably more up-to-date, I wanted to use the latest version of the registry, the same as the one from GitHub. So I tried to update the Docker image Jhipster Registry with <code>docker pull</code>. And now it won't work with either registry - Docker image or GitHub clone. </p>&#xA;&#xA;<p>When a registry is running and I run a gateway or microservice, I get 6 times this:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.511 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@86ba8f5 pairs: {GET /config/gateway/dev/master HTTP/1.1: null}{Accept: application/json, application/*+json}{User-Agent: Java/1.8.0_91}{Host: localhost:8761}{Connection: keep-alive}&#xA;2016-05-10 15:39:07.522 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@43c7802510 pairs: {null: HTTP/1.1 401 Unauthorized}{Server: Apache-Coyote/1.1}{X-Content-Type-Options: nosniff}{X-XSS-Protection: 1; mode=block}{Cache-Control: no-cache, no-store, max-age=0, must-revalidate}{Pragma: no-cache}{Expires: 0}{Content-Type: application/json;charset=UTF-8}{Transfer-Encoding: chunked}{Date: Tue, 10 May 2016 15:39:07 GMT}&#xA;</code></pre>&#xA;&#xA;<p>Then I get an error:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:13.781 ERROR 20706 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Then I get Java exceptions:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 common frames omitted&#xA;&#xA;[WARNING] &#xA;java.lang.reflect.InvocationTargetException&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;... 6 more&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 more&#xA;</code></pre>&#xA;&#xA;<p>And finally a <code>BUILD FAILURE</code> and a Maven error:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project gateway: An exception occurred while running. null: InvocationTargetException: Could not locate PropertySource and the fail fast property is set, failing: 401 Unauthorized -&gt; [Help 1]&#xA;[ERROR] &#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR] &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>In the registry's shell I get this line 6 times too:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.519 DEBUG 17958 --- [io-8761-exec-10] i.g.j.r.s.Http401UnauthorizedEntryPoint  : Pre-authenticated entry point called. Rejecting access&#xA;</code></pre>&#xA;&#xA;<p>I tried updating everything, and I am currently trying to downgrade things (since the doc says ""we recommend you use the same version tag as the one you use for your JHipster generator"", but I don't think it'll work since JHipster Registry's latest version is 2.0.0 and the JHipster generator introduced microservices with the 3.0 version), and I also tried copying directly the secret from the central-server-config to the config of the applications, but apparently to no avail.</p>&#xA;&#xA;<p>Could you help me with this ?</p>&#xA;&#xA;<p>Thank you very much in advance.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>I tried updating JHipster to 3.2.1 using <code>npm install -g generator-jhipster</code>, which apparently worked, but when I run <code>yo jhipster</code>, Yeoman still uses JHipster 3.1.0. Actually, even if I uninstall JHipster with <code>npm uninstall -g generator-jhipster</code>, Yeoman can still use JHipster 3.1.0...</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>It works fine if I reinstall everything locally (in the directory where I use <code>yo jhipster</code>).&#xA;However, I still can't update JHipster globally in Yeoman. When I try using <code>npm install -g generator-jhipster</code>, it updates JHipster globally to 3.2.1 but Yeoman still uses 3.1.0. If I try to update JHipster using <code>yo</code>/""Update your generators""/generator-jhipster, I get an error:</p>&#xA;&#xA;<pre><code>npm WARN deprecated npmconf@2.1.2: this package has been reintegrated into npm and is now out of date with respect to npm&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules/generator-jhipster&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules&#xA;/usr/local/lib&#xA;â””â”€â”€ generator-jhipster@3.2.1 &#xA;&#xA;npm ERR! Linux 3.13.0-85-generic&#xA;npm ERR! argv ""/usr/local/bin/node"" ""/usr/local/bin/npm"" ""install"" ""-g"" ""generator-jhipster""&#xA;npm ERR! node v4.4.4&#xA;npm ERR! npm  v3.8.9&#xA;npm ERR! path /usr/local/lib/node_modules/generator-jhipster&#xA;npm ERR! code EACCES&#xA;npm ERR! errno -13&#xA;npm ERR! syscall access&#xA;&#xA;npm ERR! Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster'&#xA;npm ERR!     at Error (native)&#xA;npm ERR!  { [Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster']&#xA;npm ERR!   errno: -13,&#xA;npm ERR!   code: 'EACCES',&#xA;npm ERR!   syscall: 'access',&#xA;npm ERR!   path: '/usr/local/lib/node_modules/generator-jhipster' }&#xA;npm ERR! &#xA;npm ERR! Please try running this command again as root/Administrator.&#xA;&#xA;npm ERR! Please include the following file with any support request:&#xA;npm ERR!     /home/vagrant/npm-debug.log&#xA;&#xA;I've just updated your generators. Remember, you can update&#xA;a specific generator with npm by running:&#xA;&#xA;    npm install -g generator-_______&#xA;</code></pre>&#xA;&#xA;<p>Using <code>sudo</code> will do the same and <code>sudo su</code> give me this when I try to run <code>yo</code>:</p>&#xA;&#xA;<pre><code>/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:53&#xA;                throw err;&#xA;                ^&#xA;&#xA;Error: EACCES: permission denied, open '/root/.config/configstore/insight-yo.json'&#xA;You don't have access to this file.&#xA;&#xA;    at Error (native)&#xA;    at Object.fs.openSync (fs.js:549:18)&#xA;    at Object.fs.readFileSync (fs.js:397:15)&#xA;    at Object.create.all.get (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:34:26)&#xA;    at Object.Configstore (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:27:44)&#xA;    at new Insight (/usr/local/lib/node_modules/yo/node_modules/insight/lib/index.js:37:34)&#xA;    at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/yo/lib/cli.js:163:11)&#xA;    at Module._compile (module.js:409:26)&#xA;    at Object.Module._extensions..js (module.js:416:10)&#xA;    at Module.load (module.js:343:32)&#xA;</code></pre>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Ok it does <strong>not</strong> work even with a local installation...&#xA;Well the gateway does access to the registry, but it displays a debug page when I try to access to localhost:8080.&#xA;Actually, during the generation, I get a <code>permission denied</code> again, and missing dependencies (<code>gulp-rev</code>).</p>&#xA;&#xA;<p>I just saw this: ""It is wise to use a tag to have a stable version: the JHipster DevBox tags are the same as the JHipster Generator tags, so using the DevBox v3.2.0 also means using the generator v3.2.0"" on the DevBox GitHub page, so maybe I'll just delete and download the DevBox again...</p>&#xA;"
37246989,how to organize outgoing api request urls in rails,2016-05-16 05:02:07,<ruby-on-rails><microservices><httparty>,1,167,0,1.0,2,"<p>I have an application in rails that make request to other microservices using httparty. Other microservices are also written in Rails. Right now, i hard coded all the api urls used in httparty, what will be a more elegant way to organize them?</p>&#xA;"
37254914,"I renamed my microservice, what do I do with the semantic version?",2016-05-16 13:18:13,<rename><microservices><semantic-versioning>,1,74,3,0.0,2,"<p>I have a number of microservices in a distributed system - one of which I have recently renamed to better reflect its bounded context and disambiguate with another similarly named service.</p>&#xA;&#xA;<p>The service was on version 3.1.0 at the point of renaming. My question is, what do I do with the version now? Is it 4.0.0? Or is this conceptually now a new service, replacing the old one and starting again from 1.0.0?</p>&#xA;&#xA;<p>I would lean towards the latter option, but I'm also versioning the db schema to match the service, and I don't want to end up in the position where the service is 1.0.0 but the db schema is 3.1.0...</p>&#xA;"
37159662,Microservices - RestTemplate UnknownHostException,2016-05-11 10:18:16,<java><spring-boot><spring-cloud><microservices><netflix-eureka>,1,5840,5,1.0,2,"<p>I have a simple setup with a Eureka service registration server, a service for the public API and a service that gets called from the public API using RestTemplate. Eureka tells me that the services are successfully registered, but when I call the service </p>&#xA;&#xA;<pre><code>@Service&#xA;public class MyServiceService {&#xA;&#xA;    @Autowired&#xA;    private RestTemplate restTemplate;&#xA;&#xA;    private final String serviceUrl;&#xA;&#xA;    public MyServiceService() {&#xA;        this.serviceUrl = ""http://MY-SERVICE"";&#xA;    }&#xA;&#xA;    public Map&lt;String, String&gt; getTest() {&#xA;&#xA;        Map&lt;String, String&gt; vars = new HashMap&lt;&gt;();&#xA;        vars.put(""id"", ""1"");&#xA;&#xA;        restTemplate.setRequestFactory(new HttpComponentsClientHttpRequestFactory());&#xA;&#xA;        return restTemplate.postForObject(serviceUrl+""/test"", """", Map.class, vars);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I get the following exception</p>&#xA;&#xA;<pre><code>Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed;&#xA;  nested exception is org.springframework.web.client.ResourceAccessException: I/O error on POST request for ""http://MY-SERVICE/test"": MY-SERVICE;&#xA;  nested exception is java.net.UnknownHostException: MY-SERVICE] with root cause java.net.UnknownHostException: MY-SERVICE&#xA;</code></pre>&#xA;&#xA;<p>I created a sample project to illustrate my setup, maybe someone could take a look at it and tell me what's wrong with my setup.</p>&#xA;&#xA;<p><a href=""https://github.com/KenavR/spring-boot-microservices-example"" rel=""nofollow"">https://github.com/KenavR/spring-boot-microservices-example</a></p>&#xA;&#xA;<p>thanks</p>&#xA;"
44115310,SessionId lost when I make a request between backend of microservices,2017-05-22 14:20:30,<java><spring><rest><security><microservices>,3,271,2,1.0,2,"<p>I am trying to make request between microservices in order to retrieve a list of users with the same roles. For this, first I make a request between FrontEnd and Backend inside the microservice 1. Following, I call an endpoint in the microservice 2 from Microservice 1 backend, but the session Id is lost in it, and I can retrieve the context. &#xA;I am using spring security and Redis for the session Control. &#xA;Manually, I retrieve the session Id from the microservice 1 and I add it as an attribute of the header of the second call, to the microservice 2. But it does not work.</p>&#xA;&#xA;<pre><code>String sessionID= RequestContextHolder.currentRequestAttributes().getSessionId();&#xA;RestTemplate rest = new RestTemplate();&#xA;HttpHeaders headers= new HttpHeaders();            &#xA;headers.set(""Session"",sessionID);&#xA;HttpEntity&lt;ResponseData&gt; entity = new HttpEntity&lt;ResponseData&gt;(headers);&#xA;ResponseEntity&lt;ResponseData&gt; responseEntity =rest.exchange(targetApi,  HttpMethod.GET, entity,ResponseData.class);&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qFEXf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qFEXf.jpg"" alt=""enter image description here""></a></p>&#xA;"
44181863,Difference between Microservices and load balancer?,2017-05-25 13:30:39,<load-balancing><microservices>,2,636,2,0.0,2,"<p>I'm fairly new to the realm of microservices but know basics about load balancing. I recently read an article about the microservices: <a href=""https://aadrake.com/posts/2017-05-20-enough-with-the-microservices.html"" rel=""nofollow noreferrer"">Enough with the microservices</a>.    </p>&#xA;&#xA;<p>There it's mentioned that both the microservices and load balancers have clusters/different VM's for deploying many copies of application but in the case of microservices, we have a <strong>separate database</strong> in contrast to load balancers which backs a single database. Is it the only difference between them?</p>&#xA;&#xA;<p>Here's the quoted text:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""multiple copies of the same microservice can be deployed in order to&#xA;  achieve a form of scalability. However, most companies that adopt&#xA;  microservices too early will use the same storage subsystem (most&#xA;  often a database) to back all of their microservices. What that means&#xA;  is that you donâ€™t really have horizontal scalability for your&#xA;  application, only for your service. If this is the scalability method&#xA;  you plan to use, why not just deploy more copies of your monolith&#xA;  behind a load balancer? Youâ€™ll accomplish the same goal with less&#xA;  complexity.""</p>&#xA;</blockquote>&#xA;"
38471362,Couchbase Microservice Architecture,2016-07-20 02:31:01,<couchbase><microservices><couchbase-sync-gateway>,1,276,0,1.0,2,"<p>I've read a lot of articles about having a datastore per microservice. I'm going to use this approach but want to know the best way to go about it using Couchbase Sync Gateway since I want to use Sync Gateway REST API calls both from mobile AND backend server apps. I am thinking that the simplest way to go about this is to have one Couchbase cluster (3-n Couchbase Server instances) with maybe 2-3 buckets. A bucket for sessions maybe, another for all of my data, and maybe some others later. For each microservice's ""database"", instead of having different physical clusters for each, I'm thinking I should just put all of the data in one bucket and differentiate the databases and tables by document fields. So maybe I would have something like:</p>&#xA;&#xA;<pre><code>{&#xA;  database: 'person-api'&#xA;  doc_type: 'Person'&#xA;&#xA;  ...&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I would also have multiple database entries for each service all pointing to the same bucket in my sync-gateway config file. Then I would need to set up ACLs or some kind of controls that would only allow the backend server applications to access their own databases (so the 'election-api' server could only read/write docs with the corresponding <code>database</code> property). This would all have to be through Sync Gateway, for writes at least (I might do most reads using the sdks instead). </p>&#xA;&#xA;<p>Sync Gateway is still a bit confusing to me and I'm not sure if this is the best approach. Would I just use channels as a sort of ACL? Is this just a bad approach to begin with? Any suggestions? thanks!</p>&#xA;"
38504315,Monolith to Separate Services Help and Guidance,2016-07-21 12:28:09,<restful-architecture><microservices>,1,38,0,0.0,2,"<p>I'm in the process of breaking a monolith into separate microservices. I already have a contact service - it stores Names, Email Addresses, Phone Numbers etc.</p>&#xA;&#xA;<p>I want to create another service for organisations/businesses. These organisations have contacts so I'd like to use my existing Contact Service for this rather than recreating it all.</p>&#xA;&#xA;<p>Can anyone advise on how I should structure this? I've thought of the following two ways.</p>&#xA;&#xA;<p>1) Implement the Contact Service within the Org Service. So a user of the Org service is unaware the contact service is separate. This has the drawback that I need to recreate a load of endpoints in the Org service that simply (more or less) pass through to the contact service.</p>&#xA;&#xA;<p>2) Let the user of these services create a contact through the contact service and then just create a way to 'attach' this contact to the organisation.</p>&#xA;&#xA;<p>Is one of these preferable? Or is there another way I've not thought of?</p>&#xA;"
38511443,AWS Pub/Sub Message Pattern,2016-07-21 18:09:32,<amazon-web-services><aws-lambda><amazon-sqs><microservices>,2,1848,0,0.0,2,"<p>Can someone explain to me the advantage or disadvantage of using SNS -> Lambda  vs. SNS -> SQS -> Lambda.</p>&#xA;&#xA;<p>I'm looking to setup an architecture for pub/sub micro-service messaging, but having a queue in front of every Lambda seems excessive.</p>&#xA;"
38508387,"What is SOA, Microservices, REST and Web Services ""in plain English""?",2016-07-21 15:30:49,<web-services><rest><soa><microservices>,2,1920,0,1.0,2,"<p>Could somebody explain SOA, Microservices, REST and Web Services in simple terms. It is really fascinating and confusing me. Any help would be appreciated.</p>&#xA;"
38629740,How to implement security for my Microservices with Spring?,2016-07-28 07:28:20,<spring-security><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,221,0,2.0,2,"<p>We have one monolithic application having more than 10 services like user management, fleet booking, feedback and etc developed on spring rest.</p>&#xA;&#xA;<p>We want to migrate to Microservices(Spring Boot + Cloud + Netflix OSS).</p>&#xA;&#xA;<p>Below are my questions :&#xA;How can we implement security for all our rest services (with own user database)?&#xA;How to implement api gateway from security stand point ?</p>&#xA;"
38492388,Adding dependencies to microservices,2016-07-20 23:16:50,<java><spring><spring-boot><microservices><spring-cloud-netflix>,1,302,2,1.0,2,"<p>I have built few microservices that consume a number of external services. Few of these external services are consumed by more than 1 microservice that I have built. I have built the connectors to these microservices as a library project and have included it as a dependency in all my microservice projects. However I read that all logic for microservices should be self contained and duplication of logic is ok. If that's the case , is it recommended for me to define these connectors within each every microservice instead of having a shared library?</p>&#xA;"
38629237,How to create a Transaction 'Wrapper' for multiple Services?,2016-07-28 07:03:34,<c#><web-services><wcf><transactions><microservices>,2,434,3,0.0,2,"<p>Currently, I'm working on a project that using MicroServices as the main concept.</p>&#xA;&#xA;<p>For a clearer picture, I'll give you the example:</p>&#xA;&#xA;<p>I got <em>Service A</em> that has its own model and controller. </p>&#xA;&#xA;<p>Basically, Service A only contains basic CRUD operations for <em>Database A</em>. </p>&#xA;&#xA;<p>Second, I got <em>Service B</em>, same like Service A but different database (<em>Database B</em>). </p>&#xA;&#xA;<p>Now, I created 1 Services to consume both Service A and Service B. Currently I'm using TransactionScope for 'wrap' the transaction, but it didn't work.</p>&#xA;&#xA;<p>Here's the code :</p>&#xA;&#xA;<pre><code>//This is the service to call Service A and Service B&#xA;using (TransactionScope ts = new TransactionScope())&#xA;{&#xA;     callServiceAMethod(); // works good&#xA;     callServiceBMethod(); // something happened, and failed&#xA;&#xA;     //from here I don't know what should I do&#xA;     //What I'm expecting is : if one of the service i just called didn't work as expected, &#xA;     //the transaction will be rolled back else will committed     &#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Any help will be appreciated :)</p>&#xA;"
38480000,Service Fabric Nested Applications,2016-07-20 11:26:37,<deployment><configuration><microservices><azure-service-fabric>,1,195,6,0.0,2,"<p>I am trying to re-architect our current monolithic web application into a more modular (micro-service) style design.</p>&#xA;&#xA;<p>I have a good idea of the boundaries and a plan on how to build it...</p>&#xA;&#xA;<p>Each part of the app will have it's own domain package, a backing rest api, and a web front-end for managing the data. Plus other stuff like unit tests and possibly a connection helper library, etc.</p>&#xA;&#xA;<p>For argument's sake, say my monolithic app has 3 main components (modules):</p>&#xA;&#xA;<ol>&#xA;<li>An accounts module for creating and managing users</li>&#xA;<li>A Products module for administering and managing the product&#xA;catalog</li>&#xA;<li>An Orders module for creating, viewing and amending orders.</li>&#xA;</ol>&#xA;&#xA;<p>In the monolithic app these are all part of the same application (and VS solution and project) and usually have distinct controllers configured using MVC / WebApi Etc:</p>&#xA;&#xA;<pre><code>// MyApp.Web Project (base url ~/)&#xA;myapp.com/...&#xA;myapp.com/accounts/...&#xA;myapp.com/products/...&#xA;myapp.com/orders/...&#xA;&#xA;// MyApp.Api Project (base url ~/api)&#xA;myapp.com/api/...&#xA;myapp.com/api/accounts/...&#xA;myapp.com/api/products/...&#xA;myapp.com/api/orders/...&#xA;</code></pre>&#xA;&#xA;<p>Currently we host this in IIS using nested applications and virtual folders but I want to replicate this sort of idea or structure using a service fabric cluster. But each isolated area (accounts, products, orders) will be developed and deployed independently of one another.</p>&#xA;&#xA;<p><strong>How do I configure service fabric cluster to enable this type of situation?</strong></p>&#xA;&#xA;<p>For instance if I have a cluster of 50 nodes and on those 50 nodes I have instances spread out of each service and the service's api. How do I say:</p>&#xA;&#xA;<pre><code>v2.myapp.com/accounts --&gt; any available accounts web UI instance?&#xA;v2.myapp.com/products --&gt; any available products web UI instance?&#xA;v2.myapp.com/api/products --&gt; any available products api instance?&#xA;</code></pre>&#xA;&#xA;<p>Should I have VM Scale Sets for web and api or one for each component too, like VM Scale Sets for just products api and another for orders web UI, etc?</p>&#xA;&#xA;<p>Also please note that our system is BIG so there are lots of components, hence the reason for splitting out the monolithic style, so I need a consistent structure to enable all this.</p>&#xA;&#xA;<p>We have major scaleability issues and very slow (manual) virtual server provisioning. Plus a single monolithic SQl Server database. The features of SF I want is modular design, easy provisioning and deployment and a drastic increase in response times and throughput of our system. And of course good failover.</p>&#xA;&#xA;<p>At the end of the day I want customers to see a consistent url structure but under the covers I want to be able to have it all separate and working together over many nodes.</p>&#xA;&#xA;<p>Thanks in advance.<br>&#xA;Any help on how to configure this is very much appreciated.</p>&#xA;&#xA;<p>G.</p>&#xA;"
42344020,Hiding multiple web services behind one?,2017-02-20 11:59:15,<rest><asp.net-web-api><asp.net-core><microservices><asp.net-core-webapi>,1,59,0,1.0,2,"<p>There is a system with a rather big amount of different small services.&#xA;The idea is to hide them behind one, which is going to be an entry point to the system.<br>&#xA;Is that considered a good practice?<br>&#xA;Are there any common approaches/solutions for such case in asp.net core?</p>&#xA;"
42281634,Application-side join ORM for Node?,2017-02-16 18:11:38,<node.js><amazon-web-services><orm><microservices><loopback>,1,167,0,0.0,2,"<p>To start: I've tried Loopback. Loopback is nice but does not allow for relations across multiple REST data services, but rather makes a call to the initial data service and passes query parameters that ask it to perform the joined query.</p>&#xA;&#xA;<p>Before I go reinventing the wheel and writing a massive wrapper around Loopback's loopback-rest-connector, I need to find out if there are any existing libraries or frameworks that already tackle this. My extensive Googling has turned up nothing so far.</p>&#xA;&#xA;<p>In a true microservice environment, there is a service per database.</p>&#xA;&#xA;<p><a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/data/database-per-service.html</a></p>&#xA;&#xA;<p>From this article:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Implementing queries that join data that is now in multiple databases&#xA;  is challenging. There are various solutions:</p>&#xA;  &#xA;  <ul>&#xA;  <li><p>Application-side joins - the application performs the join rather than&#xA;  the database. For example, a service (or the API gateway) could&#xA;  retrieve a customer and their orders by first retrieving the customer&#xA;  from the customer service and then querying the order service to&#xA;  return the customerâ€™s most recent orders.</p></li>&#xA;  <li><p>Command Query Responsibility Segregation (CQRS) - maintain one or more&#xA;  materialized views that contain data from multiple services. The views&#xA;  are kept by services that subscribe to events that each services&#xA;  publishes when it updates its data. For example, the online store&#xA;  could implement a query that finds customers in a particular region&#xA;  and their recent orders by maintaining a view that joins customers and&#xA;  orders. The view is updated by a service that subscribes to customer&#xA;  and order events.</p></li>&#xA;  </ul>&#xA;</blockquote>&#xA;&#xA;<p>EXAMPLE:</p>&#xA;&#xA;<p>I have 2 data microservices: </p>&#xA;&#xA;<p>GET /pets - Returns an object like</p>&#xA;&#xA;<pre><code>{&#xA;   ""name"":""ugly"",&#xA;   ""type"":""dog"",&#xA;   ""owner"":""chris""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and on a completely different microservice....</p>&#xA;&#xA;<p>GET /owners/{OWNER_NAME} - Returns the owner info</p>&#xA;&#xA;<pre><code> {&#xA;    ""owner"":""chris"",&#xA;    ""address"":""under a bridge"",&#xA;    ""phone"":""123-456-7890""&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>And I have an API-level microservice that is going to call these two data services. This is the microservice that I will be applying this at.</p>&#xA;&#xA;<p>I'd like to be able to establish a model for Pet such that, when I query pet, upon a successful response from GET /pets, it will ""join"" with owners (send a GET /owners/{OWNERS_NAME} for all responses), and to the user, simply return a list of pets that includes their owner's data.</p>&#xA;&#xA;<p>So GET /pets (maybe something like Pets.find()) would return</p>&#xA;&#xA;<pre><code>{&#xA;  ""name"":""ugly"",&#xA;  ""type"":""dog"",&#xA;  ""owner"": ""chris"",&#xA;  ""address"": ""under a bridge"",&#xA;  ""phone"": ""123-456-7890""&#xA;}&#xA;</code></pre>&#xA;"
42204181,Spring Cloud Stream Kafka - How to implement idempotency to support distributed transaction management (eventual consistency),2017-02-13 12:34:23,<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,2,1234,6,0.0,2,"<p>I have the following typical scenario: </p>&#xA;&#xA;<ul>&#xA;<li>An order service used to purchase products. Acts as the commander of the distributed transaction.</li>&#xA;<li>A product service with the list of products and its stock.</li>&#xA;<li><p>A payment service.</p>&#xA;&#xA;<pre><code>    Orders DB               Products DB&#xA;       |                       |&#xA;---------------         ----------------          ----------------&#xA;| OrderService  |       | ProductService |        | PaymentService |&#xA; ---------------         ----------------          ----------------&#xA;       |                       |                         |&#xA;       |                --------------------             |&#xA;       --------------- | Kafka orders topic |-------------&#xA;                       ---------------------&#xA;</code></pre></li>&#xA;</ul>&#xA;&#xA;<p>The normal flow would be:</p>&#xA;&#xA;<ol>&#xA;<li>The user orders a product.</li>&#xA;<li>Order service creates an order in DB and publishes a message in Kafka topic ""orders"" to reserve a product (PRODUCT_RESERVE_REQUEST).</li>&#xA;<li>Product service decreases the product stock one unit in its DB and publishes a message in ""orders"" saying PRODUCT_RESERVED</li>&#xA;<li>Order service gets the PRODUCT_RESERVED message and orders the payment publishing a message PAYMENT_REQUESTED</li>&#xA;<li>Payment service orders the payment and answers with a message PAYED</li>&#xA;<li>Order service reads the PAYED message and marks the order as COMPLETED, finishing the transaction.</li>&#xA;</ol>&#xA;&#xA;<p>I am having trouble to deal with error cases, e.g: let's assume this:</p>&#xA;&#xA;<ol start=""5"">&#xA;<li>Payment service fails to charge for the product, so it publishes a message PAYMENT_FAILED</li>&#xA;<li>Order service reacts publishing a message UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service increases the stock in the DB to cancel the reservation and publishes PRODUCT_UNRESERVATION_COMPLETED</li>&#xA;<li>Order service finishes the transaction saving the final state of the order as CANCELLED_PAYMENT_FAILED.</li>&#xA;</ol>&#xA;&#xA;<p>In this scenario imagine that for whatever reason, order service publishes a UNDO_PRODUCT_RESERVATION message but doesn't receive the PRODUCT_UNRESERVATION_COMPLETED message, so it retries publishing another UNDO_PRODUCT_RESERVATION message.</p>&#xA;&#xA;<p>Now, imagine that those two UNDO_PRODUCT_RESERVATION messages for the same order end up arriving to ProductService. If I process both of them I could end up setting an invalid stock for the product. </p>&#xA;&#xA;<p>In this scenario how can I implement idempotency? </p>&#xA;&#xA;<p><strong>UPDATE:</strong></p>&#xA;&#xA;<p>Following Artem's instructions I can now detect duplicated messages (by checking the message header) and ignore them but there may still be situations like the following where I shouldn't ignore the duplicated messages:</p>&#xA;&#xA;<ol>&#xA;<li>Order Service sends UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service gets the message and starts processing it but crashes before updating the stock.</li>&#xA;<li>Order Service doesn't get a response so it retries sending UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service knows this is a duplicated message BUT, in this case it should repeat the processing again. </li>&#xA;</ol>&#xA;&#xA;<p>Can you help me come up with a way to support this scenario as well? How could I distinguish when I should discard the message or reprocess it?</p>&#xA;"
43208872,How to communicate user ID between Spring Boot microservice applications,2017-04-04 13:37:07,<java><spring><authentication><oauth-2.0><microservices>,1,320,0,0.0,2,"<p>I have three services:</p>&#xA;&#xA;<ol>&#xA;<li>Auth (OAuth2 token provision and username + passwords, nothing else)</li>&#xA;<li>User-related resources (linked devices, date of birth etc.)</li>&#xA;<li>Domain data</li>&#xA;</ol>&#xA;&#xA;<p>All three of them are Spring Boot applications. Authentication is done via OAuth2 token provision, using JDBC Token Store. Logging in, obtaining the token works well, requesting data from either of the other two resource servers works well too. However I am not happy with how I'm doing it, as it seems a bit clunky:</p>&#xA;&#xA;<p>All of the data on resource servers is linked to the user via server-side generated user ID. I believe linking it to the username is a bad idea should the user ever want to change his/her username. Right now, the way I'm getting the user ID is in short:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.GET)&#xA;public ResponseEntity&lt;SampleData&gt; getData(OAuth2Authentication authentication) {&#xA;    Authentication auth = authentication.getUserAuthentication();&#xA;    final Map&lt;String, Object&gt; map = (Map) auth.getDetails();&#xA;&#xA;    // parse user data from the map ...&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The method <code>getDetails</code> returns the whole User object on the Auth server as a map - because that's the way I linked it in <strong>application.properties</strong> file:</p>&#xA;&#xA;<pre><code>security.oauth2.resource.userInfoUri=http://localhost:9000/api-auth/user&#xA;</code></pre>&#xA;&#xA;<p>But I can't bring myself to be OK with this solution, because:</p>&#xA;&#xA;<ol>&#xA;<li>All user-facing methods would have to start with this parsing and even after I made it into a separate class, it's still the same two lines for every method.</li>&#xA;<li>I feel like the methods shouldn't even have the object <code>OAuth2Authentication authentication</code> as the input - it should be in a layer above and not here (could be my wrong feeling, though).</li>&#xA;</ol>&#xA;&#xA;<p>My question is - can I do it more efficiently? In a more clean and sustainable way?</p>&#xA;&#xA;<p>I'd like to have:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.GET)&#xA;public ResponseEntity&lt;SampleData&gt; getData(String userId) {&#xA;    // interact with data with the userId&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And definitely <strong>not</strong> depend on the client sending this data - this has to come from the Auth server.</p>&#xA;&#xA;<p>My (so far failed) thoughts:</p>&#xA;&#xA;<ol>&#xA;<li>JWT token usage - failed on the fact that I'm using JDBC Token Store and that seems to be not compatible with JWT. Also JWT tokens cannot be revoked as they're not stored and have to be dealt with through short-lived access/refresh tokens. But if nothing else works, I am open to this approach.</li>&#xA;<li>Filters - my favorite, I thought this would be it, but I couldn't make it work - I receive the request in a e.g. <code>OncePerRequestFilter</code> and parse the data. But then I was unable to distribute the parsed object straight into the controller. This seemed like the solution, but I guess it's not meant for this, perhaps.</li>&#xA;</ol>&#xA;&#xA;<p>Am I approaching this completely wrong or am I missing some Spring Boot detail that solves this automatically?</p>&#xA;"
43264727,Call Python tasks from Golang,2017-04-06 19:59:13,<python><go><concurrency><server><microservices>,1,451,0,0.0,2,"<p>I have been building big data application for stock market analysis. About 5TB of records per day. I use Golang for data transformation/calculation and saving in Cassandra/MySQL. But Python has very good libraries for data analysis Pandas, Spark and etc., but there is no easy way for multicore processing and takes a lot of time. </p>&#xA;&#xA;<p>So, I want to call python data analysis tasks concurrently in Golang. One way is to execute command line task directly, but I think there should be more scalable solution. Maybe there is library for communication between Golang and Python. I thought maybe I should create multiple servers of Python Flask and give tasks to them. Speed is important, but I can sacrifice some of it for concise solution. Any ideas?  </p>&#xA;"
43252404,REST API Java microservice available inside same application server,2017-04-06 10:22:35,<java><rest><microservices>,2,214,2,0.0,2,"<p>I have small Java (Java EE) microservice, that do some calculations. This microservice is running on the same application server as other application, also written in Java EE. First question - should these apps communicate each other by REST API or different way? Second question - if so, is there a way to save some time, by not serializing/deserializing transfer objects? I understand that communication between two apps on different servers (languages) requires serialization/deserialization, but what about mentioned situation? </p>&#xA;"
43100199,zuul API Gateway Filter,2017-03-29 17:24:47,<spring><microservices><spring-cloud><netflix-zuul>,2,545,3,0.0,2,"<p>I am facing problem when i trying to access another REST API(registered in ZUUL route) from zuul pre-filter, the call is becoming recursive i.e its running my pre-filter code again and again. My Usecase is as follows-</p>&#xA;&#xA;<ol>&#xA;<li><p>In Zuul <code>PreFilter</code> <code>run()</code> method, I am validating the token passed in the header.</p></li>&#xA;<li><p>After validating the token, I am calling one rest service(User Location Service) to fetch the user details. My User Location Service is itself registered in ZUUL as below:</p>&#xA;&#xA;<pre><code>user-location-service:&#xA;  path: /userLocationService/**&#xA;  url: http://localhost:9002&#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>The problem is that the JWT token validation code is running again and again, Can you please suggest some solution where I can apply the call Userlocation service so that the <code>PreFilter</code> code would not run again and again?</p>&#xA;"
43212533,Eventual Consistency in microservice-based architecture temporarily limits functionality,2017-04-04 16:15:01,<microservices><application-design><eventual-consistency><event-based-programming>,1,629,3,0.0,2,"<p>I'll illustrate my question with Twitter. For example, Twitter has microservice-based architecture which means that different processes are in different servers and have different databases.</p>&#xA;&#xA;<p>A new tweet appears, server A stored in its own database some data, generated new events and fired them. Server B and C didn't get these events at this point and didn't store anything in their databases nor processed anything.</p>&#xA;&#xA;<p>The user that created the tweet wants to edit that tweet. To achieve that, all three services A, B, C should have processed all events and stored to db all required data, but service B and C aren't consistent yet. <strong>That means that we are not able to provide edit functionality</strong> at the moment.</p>&#xA;&#xA;<p>As I can see, a possible workaround could be in switching to immediate consistency, but that will take away all microservice-based architecture benefits and probably could cause problems with tight coupling.    </p>&#xA;&#xA;<p>Another workaround is to restrict user's actions for some time till data aren't consistent across all necessary services. Probably a solution, depends on customer and his business requirements.    </p>&#xA;&#xA;<p>And another workaround is to add additional logic or probably service D that will store edits as user's actions and apply them to data only when they will be consistent. Drawback is very increased complexity of the system.</p>&#xA;&#xA;<p>And there are two-phase commits, but that's 1) not really reliable 2) slow.<br>&#xA;I think slowness is a huge drawback in case of such loads as Twitter has. But probably it could be solved, whereas lack of reliability cannot, again, without increased complexity of a solution.</p>&#xA;&#xA;<p>So, the questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Are there any nice solutions to the illustrated situation or only things that I mentioned as workarounds? Maybe some programming platforms or databases?</li>&#xA;<li>Do I misunderstood something and some of workarounds aren't correct?</li>&#xA;<li>Is there any other approach except Eventual Consistency that will guarantee that all data will be stored and all necessary actions will be executed by other services?</li>&#xA;</ol>&#xA;&#xA;<p><em>Why Eventual Consistency has been picked for this use case</em>? As I can see, right now it is the only way to guarantee that some data will be stored or some action will be performed if we are talking about event-driven approach when some of services will start their work when some event is fired, and following my example, that event would be â€œtweet is createdâ€. So, in case if services B and C go down, I need to be able to perform action successfully when they will be up again.</p>&#xA;&#xA;<p>Things I would like to achieve are: reliability, ability to bear high loads, adequate complexity of solution. Any links on any related subjects will be very much appreciated.</p>&#xA;&#xA;<p>If there are natural limitations of this approach and what I want cannot be achieved using this paradigm, it is okay too. I just need to know that this problem really isn't solved yet.</p>&#xA;"
47089196,How to ensure that the variable was modified from only one side,2017-11-03 05:45:18,<hash><microservices><stateless><revision-history>,2,23,0,1.0,2,"<p>I've got an application with a lot of stateless microservices, which passes their variable context one to another. I've got a case when I'm starting few chains of services with the same context in parallel and then waiting for them to finish. Each service can modify its variable context, but after all of chains is finished I have to merge their variable contexts and ensure there is no conflicts.</p>&#xA;&#xA;<p>It's illustrated in the examples below:&#xA;<a href=""https://i.stack.imgur.com/HEzBC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HEzBC.png"" alt=""incorrect example""></a>&#xA;<a href=""https://i.stack.imgur.com/56UDh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/56UDh.png"" alt=""correct example""></a></p>&#xA;&#xA;<p>It's possible to solve this problem by storing the whole history of variable modifications, but it's a huge data overhead which I'd like to avoid.</p>&#xA;&#xA;<p>Another solution I see is to find some hashing function, which lets to calculate the hash of modification history by the existing hash and new data, and also lets to check if one history data is prefix of another history data by knowing their hashes only. But I'm unable to find such a function.</p>&#xA;&#xA;<p>I'm looking for any applicable algorithm with has as less data overhead as possible.</p>&#xA;"
46975781,Converting my Node app to Docker/Kubernetes?,2017-10-27 13:06:20,<node.js><docker><continuous-integration><kubernetes><microservices>,2,150,0,0.0,2,"<p>I have a Node app that's composed of several independent modules, talking to each other over AMQP. This app is started by an index.js file that instatiates every other index.js in the different folders of my project, which in turn instantiate the actual modules.</p>&#xA;&#xA;<p>I've been reading about microservices and I'd like to convert my application to Docker containers. I've found examples of how to convert a simple Node app to Docker, but I want to separate my app so that every module is in an independent Node container (this is because each module is independent and doesn't depend on other modules to work. They receive work from the message queue, and put results on the message queue).</p>&#xA;&#xA;<p>What I can't find is information on how I should organize and deploy my code. Should I have a different Node project (with separate packages.json) for each of my modules? Or should I have a single Node project for all my modules and deploy each of them individually?</p>&#xA;&#xA;<p>After I have my project organized, is there a script tool that will generate (build* and deploy) each of my modules to its own container? All examples I've found so far are ""hello world"" level samples that just pack one app.</p>&#xA;&#xA;<p>During development, will I have to deploy new containers for each change I test?</p>&#xA;&#xA;<p>*: build because I use ES6 and I have to use Babel.</p>&#xA;"
47017657,How to have lombok to create constructor for non null fields since @RequiredArgsConstructor seems not to work?,2017-10-30 14:25:32,<java><spring><microservices><lombok>,1,665,2,1.0,2,"<p>I am playing with the <strong>Lombok</strong> and already went through many link but none of them worked for me.</p>&#xA;&#xA;<p><strong>Person.java</strong></p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>PersonController.java</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/people"")&#xA;public class PersonController {&#xA;    @Autowired&#xA;    private PersonRepository personRepository;&#xA;&#xA;    @RequestMapping(value = """", method = RequestMethod.POST)&#xA;    @ResponseStatus(HttpStatus.CREATED)&#xA;    public void createPerson(@RequestBody Person person) {&#xA;        personRepository.save(new Person(person.getFirstName(), person.getLastName()));  //line-34&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But its not allowing me to create the two argument constructor</p>&#xA;&#xA;<pre><code>Multiple markers at this line&#xA;    - The constructor Person(String, String) is undefined&#xA;    - The method save(S) in the type CrudRepository&lt;Person,Long&gt; is not applicable for the arguments &#xA;     (Person)&#xA;</code></pre>&#xA;&#xA;<p><strong>On line No-34 its breaking...</strong></p>&#xA;&#xA;<p><strong>EDIT-1:</strong></p>&#xA;&#xA;<pre><code> @RequestMapping(value = ""/{id}"", method = RequestMethod.PUT)&#xA;    @ResponseStatus(HttpStatus.NO_CONTENT)&#xA;    public void updatePerson(@PathVariable(""id"") Long id, @RequestBody Person person) {&#xA;        Person existingPerson = personRepository.findOne(id);&#xA;        existingPerson.setFirstName(person.getFirstName());&#xA;        existingPerson.setLastName(person.getLastName());&#xA;        personRepository.save(existingPerson);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Here is the error</p>&#xA;&#xA;<pre><code>The method setFirstName(String) is undefined for the type Person&#xA;</code></pre>&#xA;&#xA;<p>The changes I made</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor()&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private final String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private final String lastName;&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>-===================</p>&#xA;&#xA;<p><strong>Edit-2</strong></p>&#xA;&#xA;<p>Here is the final result:</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;&#xA;    public Person(String firstName, String lastName){&#xA;        this.firstName = firstName;&#xA;        this.lastName = lastName;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
43941794,Could GraphQL be useful for a system without a frontend client?,2017-05-12 15:49:28,<api><reactjs><architecture><microservices><graphql>,1,63,1,0.0,2,"<p>So far all the guides i have looked at involve communicating with a frontend client via Graphql, I wonder does it have any usage for something purely backend, such as communicating among microservices?</p>&#xA;"
43927492,Microservices - Stubbing/Mocking,2017-05-12 00:15:48,<java><cloudfoundry><microservices>,5,926,2,0.0,2,"<p>I am developing a product using microservices and am running into a bit of an issue. In order to do any work, I need to have all 9 services running on my local development environment. I am using Cloud Foundry to run the applications, but when running locally I am just running the Spring Boot Jars themselves. Is there anyway to setup a more lightweight environment so that I don't need everything running? Ideally, I would only like to have the service I am currently working on to have to be real.</p>&#xA;"
43792085,How to check service-to-service authentication in Google Cloud Endpoints?,2017-05-04 20:17:14,<google-app-engine><oauth-2.0><google-cloud-endpoints><microservices><google-oauth2>,1,171,3,2.0,2,"<p>I'm trying to split a monolith Google App Engine application (using Python &amp; standard environment) into several services within one application. Default service is calling API implemented using the Endpoints framework in another service.</p>&#xA;&#xA;<p>Everything works nicely except that I don't understand how to correctly check authentication of the default service (and make it work both in local development server and in production).</p>&#xA;&#xA;<p>To call the service I'm using <code>google-api-python-client</code> and default application credentials.</p>&#xA;&#xA;<pre><code>from googleapiclient.discovery import build&#xA;from oauth2client.client import GoogleCredentials&#xA;service = build(&#xA;    name, version,&#xA;    credentials=GoogleCredentials.get_application_default(),&#xA;    discoveryServiceUrl=discovery_url)&#xA;service.client_token().execute()&#xA;</code></pre>&#xA;&#xA;<p>My service API code looks like the following</p>&#xA;&#xA;<pre><code>@endpoints.api(&#xA;    name='test',&#xA;    version='v1',&#xA;)&#xA;class TestApi(remote.Service):&#xA;&#xA;    @endpoints.method(&#xA;        message_types.VoidMessage,&#xA;        TestResponse,&#xA;        path='test',&#xA;        http_method='GET',&#xA;        name='test')&#xA;    def get_test(self, request):&#xA;        # user = endpoints.get_current_user()&#xA;        # if not user:&#xA;        #     raise endpoints.UnauthorizedException&#xA;        return TestResponse(test='test')&#xA;</code></pre>&#xA;&#xA;<p>In production <code>endpoints.get_current_user()</code> seems to return a correct application user, but I don't know how to correctly validate that it's the same application. In local development environment <code>endpoints.get_current_user()</code> returns <code>None</code>.</p>&#xA;"
43850359,Microservice Coupling,2017-05-08 14:32:40,<spring><architecture><cloud><microservices><coupling>,5,280,9,1.0,2,"<p>I'm building a new application with microservice concepts, but I don't know how to communicate with another microservice without coupling. Here is my scenario.</p>&#xA;&#xA;<p>I want to show a graphic bar about my sales but I have two microservices, the first one is the <strong>sales-service</strong> and the another one <strong>product-service</strong>. In this case I have to select the period I want to filter and then select the sales and after select the products from these sales, but I'm calling the product-service directly with REST and if my product-service going down fails every thing. What is the correct way to work in this scenario?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/faHqp.jpg"" rel=""nofollow noreferrer"">Diagram of Architecture</a></p>&#xA;&#xA;<p>This is the architecture with some services. The problem is that sale-service has to communicate with others services to get some informations.</p>&#xA;&#xA;<p>We have a sales software in hundreds of client and this application recieves this data and we have a front-end that shows this informations. In this scenario, microservice is the best approatch?</p>&#xA;&#xA;<p>I'm using Spring Cloud.</p>&#xA;"
46746885,In a DDD oriented microservice the Infrastructure and Entities can be reused?,2017-10-14 16:37:11,<domain-driven-design><microservices><data-access-layer><entities>,2,77,0,0.0,2,"<p>I'm thinking in a DDD oriented microservice architecture as described in this article (<a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/microservice-ddd-cqrs-patterns/ddd-oriented-microservice"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/microservice-ddd-cqrs-patterns/ddd-oriented-microservice</a>). But I'm in doubt about the data access and the entities. </p>&#xA;&#xA;<p>Would it make sense for me to put domain entities and data access into a common project or even into a nugget? Because I think I would be rewriting the same data access multiple times for each service.</p>&#xA;"
46807757,Service discovery on aws ECS with Application Load Balancer,2017-10-18 10:11:46,<amazon-web-services><microservices>,2,1616,0,1.0,2,"<p>I would like to ask you if you have an microservice architecture (based on Spring Boot) involving Amazon Elastic Container Service (ECS) with Application Load Balancer(ALB), service discovery is performed automatically by the platform, or do you need a special mechanism (such as Eureka or Consul)?</p>&#xA;&#xA;<p>From the documentation (ECS and ALB) is not clear you have this feature provided.</p>&#xA;"
46759745,one event triggering another command in CQRS,2017-10-15 20:37:21,<asp.net-core-mvc><microservices><cqrs><event-sourcing><get-event-store>,1,87,0,0.0,2,"<p>I need some opinions/suggestions/recommendation on this one.</p>&#xA;&#xA;<p>I have this use case where 1 event can trigger another command in a CQRS.</p>&#xA;&#xA;<p>The scenario is, there is 1 command service and 2 subscriber/query services and 1 of the subscribers need to perform some search and based on the result of the search can issue another command.</p>&#xA;&#xA;<p>Now, the question is should the query service issue a command (direct to eventstore: I guess this defeat the purpose of cqrs) or make a normal api call to the command service (perhaps via api gateway) which will issue the command?</p>&#xA;"
46824730,How should be project structure using microservices with gradle or maven?,2017-10-19 07:31:19,<maven><gradle><microservices><multi-module><multi-project>,2,697,0,2.0,2,"<p>I want to be sure what is the best practice for project structure while using microservice architecture.</p>&#xA;&#xA;<p>All microservices can be created as a new maven/gradle project or as a subproject/module.</p>&#xA;&#xA;<p>I think dependency inheritance, project repository should be taken into account.</p>&#xA;&#xA;<p>Due to the nature of the microservices, any service can has a different technology but still most of the services can have same dependencies(e.g. spring-boot)).</p>&#xA;&#xA;<p>Another issue is that should  team  fetch all services or just a service which will be worked on? so repository structure also will be affected by the structure.</p>&#xA;"
46803321,Is it wrong to use sessions in Microservices?,2017-10-18 05:23:31,<java><spring-boot><spring-security><microservices><spring-session>,1,1139,1,1.0,2,"<p>I have read that, session is against the concept of RESTfulness.</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/q/6068113/1358676"">Do sessions really violate RESTfulness?</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/32741333/session-management-in-microservices/32743085#32743085"">Session Management in microservices</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/319530/restful-authentication"">RESTful Authentication</a></p>&#xA;&#xA;<p>Since Microservices inevitably use <code>REST</code>, does the same apply here as well? If so, then why do we have Spring session? It even lists 'Spring Session allows providing session ids in headers to work with <code>RESTful</code> APIs' as one of its features.</p>&#xA;"
34973165,How to share communication models between Akka microservices?,2016-01-24 07:12:41,<scala><akka><microservices>,1,327,0,2.0,2,"<p>We are using Akka as our microservice platform. We are not going to support non-JVM platforms for now, so we use direct messaging between Akka actors as communication platform.</p>&#xA;&#xA;<p>This way, our communication units are just <strong>case classes</strong>. Do we have to repeat ourselves and define the case classes for each microservice or we can put all message classes into a single project and share it between microservice projects?</p>&#xA;&#xA;<p>I know that sharing models between microservices is not recommended but as we use Akka communication protocol, I'm not sure if creating the same communication case class in multiple projects is correct. What if a microservice change it's model and the others don't? How can we handle versioning and upgrade to new versions of the communication models without breaking the whole system.</p>&#xA;"
34841789,microservices & service discovery with random ports,2016-01-17 18:09:16,<docker><microservices><service-discovery><consul>,3,598,0,3.0,2,"<p>My question is related to microservices &amp; service discovery of a service which is spread between several hosts.</p>&#xA;&#xA;<p>The setup is as follows:</p>&#xA;&#xA;<ul>&#xA;<li>2 docker hosts (host A &amp; host B)</li>&#xA;<li>a Consul server (service discovery)</li>&#xA;</ul>&#xA;&#xA;<p>Letâ€™s say that I have 2 services: </p>&#xA;&#xA;<ul>&#xA;<li>service A</li>&#xA;<li>service B</li>&#xA;</ul>&#xA;&#xA;<p>Service B is deployed 10 times (with random ports): 5 times on host A and 5 times on host B.</p>&#xA;&#xA;<p>When service A communicates with service B, for example,  it sends a request to serviceB.example.com (hard coded).</p>&#xA;&#xA;<p>In order to get an IP and a port, service A should query the Consul server for an SRV record.</p>&#xA;&#xA;<p>It will get 10 ip:port pairs, for which the client should apply some load-balancing logic.</p>&#xA;&#xA;<ul>&#xA;<li>Is there a simpler way to handle this without me developing a client resolver (+LB) library for that matter ? </li>&#xA;<li>Is there anything like that already implemented somewhere ?</li>&#xA;<li>Am I doing it all wrong ?</li>&#xA;</ul>&#xA;"
34973135,Service Fabric Service vs. Service Fabric Actors for user representation,2016-01-24 07:06:53,<c#><.net><microservices><azure-service-fabric>,1,1445,0,0.0,2,"<p>In my application users can post events on a map. The entry point of the application is a stateless web api service. For representing the users internally, I want to have an user service. When should I use Reliable Stateful Actors and when Reliable Stateful Services to store the profile data and the posted events of each user? </p>&#xA;&#xA;<p>When a client creates a new user at the frontend, the actor or service should create a new user internally. And every time the user is logged in, the web api service should forward all user interactions to the internally representation of the user (Actor or Service). E.g. the user post a new event, the web api service find the user and forward the posted event to him. Because the posted event is public, I also want to have an reliable stateful event service. After storing the posted event inside the user, the user service should forward the event to the event service. </p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<pre><code>Client/User --&gt; WebApiService --&gt; UserService/UserActor --&gt; EventService&#xA;</code></pre>&#xA;&#xA;<p>And when a user want to see all the public events on a map the should be something like this: </p>&#xA;&#xA;<pre><code>Client/User &lt;-- WebApiService &lt;-- EventService&#xA;</code></pre>&#xA;&#xA;<p>Because the events have a geo reference, I want to partition the EventService based on geocodes or something like that. </p>&#xA;&#xA;<p>Which programming model (actor and/or service) should I prefer for such an application and why?</p>&#xA;"
34774290,Implications of implementing a microservice architecture,2016-01-13 18:26:26,<amazon-web-services><architecture><spring-boot><licensing><microservices>,2,598,1,1.0,2,"<p>I'm starting out on the journey of learning/implementing microservice architecture for the first time and I have some questions related to the implications that has.</p>&#xA;&#xA;<p>For some background, the techstack I intend on using is in a very over-arching sense is dockerized spring-boot microservices running on AWS. </p>&#xA;&#xA;<p>So what I want to know is...</p>&#xA;&#xA;<p>Firstly, given that each microservice is supposed to be full stack including separate databases does this mean I need 3 separate instances of whatever database I choose runnning? I'm guessing the answer is yes. So, I guess my real question is, isn't this consuming a lot more hardware resources than a monolithic application with a single database? Databases are pretty memory hungry...</p>&#xA;&#xA;<p>Not only that but the full amount of ram required for running a single spring-boot application will be required 5 times over if I'm running 5 microservices right? It seems to me this would require far, far more ram than the monolithic application, correct?</p>&#xA;&#xA;<p>What about if you are using Oracle as a database? What implications does it have for licencing? Wouldn't it get crazy expensive if you need a separate database for each microservice?</p>&#xA;&#xA;<p>Are there any other licencing pitfalls to consider? Or any other pitfalls of MSA in general that one should consider/be aware of before starting out on this journey?</p>&#xA;&#xA;<p>Edit:&#xA;Also, given each microservice is full-stack, what if I want a consist looking front-end for each of them (where a microservice requires a front-end)? I haven't seen any good advice around this. Especially given (if they are so called '12 factor') the codebase is supposed to be in separate repository for each microservice. How is this best managed/achieved?</p>&#xA;"
34790550,Threading configuration for microservices written in java/jersey/grizzly,2016-01-14 13:12:12,<java><multithreading><jersey><grizzly><microservices>,1,574,7,1.0,2,"<p>I am designing a micro-services based system. Most of the services are deployed as standalone Jersey processes with an embedded Grizzly web server.</p>&#xA;&#xA;<p>Assuming that many of those services will execute on the same machine, shall I change any threading configuration in Grizzly to prevent a situation of too many threads machine-wide?</p>&#xA;&#xA;<p>What is the default threading model for Grizzly? Is there a limit for number of threads that a single web server can create?</p>&#xA;"
48071720,org.axonframework.eventsourcing.IncompatibleAggregateException (Axon framework: Aggregate identifier must be non-null after applying an event),2018-01-03 05:35:13,<spring-boot><microservices><cqrs><event-sourcing><axon>,1,290,0,0.0,2,"<p>I try to config <strong>cqrs</strong> and <strong>event sourcing</strong> with axon.&#xA;<strong>SeatReseveCreateCommand</strong> is work properly. but <strong>SeatReserveUpadateCommand</strong> is not work correct.</p>&#xA;&#xA;<p>this is my SeatReserve <strong>aggregate</strong> </p>&#xA;&#xA;<pre><code>@Aggregate&#xA;public class SeatReserve {&#xA;    @AggregateIdentifier&#xA;    private String id;&#xA;    private String seatid;&#xA;    private Date date;&#xA;&#xA;    @SuppressWarnings(""unused"")&#xA;    private SeatReserve() {&#xA;    }&#xA;&#xA;    @CommandHandler&#xA;    public SeatReserve(SeatReseveCreateCommand seatReseveCreateCommand) {&#xA;        apply(new SeatReseveCreateEvent(seatReseveCreateCommand.getMyid(), seatReseveCreateCommand.getSeatId(),&#xA;                seatReseveCreateCommand.getDate()));&#xA;    }&#xA;&#xA;    @CommandHandler&#xA;    public SeatReserve(SeatReserveUpadateCommand upadateCommand) {&#xA;        apply(new SeatReserveUpadateEvent(id, upadateCommand.getSeatId()));&#xA;    }&#xA;&#xA;    @EventSourcingHandler&#xA;    public void on(SeatReseveCreateEvent seatReseveCreateEvent) {&#xA;        this.id = seatReseveCreateEvent.getId();&#xA;        this.seatid = seatReseveCreateEvent.getSeatId();&#xA;        this.date = seatReseveCreateEvent.getDate();&#xA;    }&#xA;&#xA;    @EventSourcingHandler&#xA;    public void on(SeatReserveChangeEvent upadateEvent) {&#xA;        seatid = upadateEvent.getSeatId();&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>this is my controller</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class TestController {&#xA;&#xA;    private final CommandGateway commandGateway;&#xA;&#xA;    public TestController(CommandGateway commandGateway) {&#xA;        this.commandGateway=commandGateway;&#xA;    }&#xA;&#xA;    @PostMapping&#xA;    public String fileComplaint(@RequestBody Map&lt;String, String&gt; request) {&#xA;        String id = UUID.randomUUID().toString();&#xA;        SeatReseveCreateCommand command=new SeatReseveCreateCommand(id,request.get(""seatid""),new Date(request.get(""date"")));&#xA;        commandGateway.send(command);&#xA;        return id;   &#xA;    }&#xA;    @PatchMapping&#xA;    public String fileComplaintUpdate(@RequestBody Map&lt;String, String&gt; request) {&#xA;        SeatReserveUpadateCommand command= new SeatReserveUpadateCommand(request.get(""id""),request.get(""seatid""));&#xA;        commandGateway.send(command);&#xA;        return request.get(""id"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I try to send request using postman </p>&#xA;&#xA;<p>this is my create request </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/d2nf6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d2nf6.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>this is my update request</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/il0tF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/il0tF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>update make this error </p>&#xA;&#xA;<pre><code>2018-01-03 10:44:53.608  WARN 11138 --- [nio-8085-exec-1] o.a.c.gateway.DefaultCommandGateway      : Command 'com.thamira.research.api.bankaccount.SeatReserveUpadateCommand' resulted in org.axonframework.eventsourcing.IncompatibleAggregateException(Aggregate identifier must be non-null after applying an event. Make sure the aggregate identifier is initialized at the latest when handling the creation event.)&#xA;</code></pre>&#xA;&#xA;<p>how can I solve this.</p>&#xA;"
48181477,Event Consumers in Event Sourcing and duplicate code,2018-01-10 06:27:20,<events><architecture><microservices><cqrs><event-sourcing>,1,175,0,0.0,2,"<p>I am pretty new to event sourcing, and we have a domain which we consider applying Event Sourcing on.</p>&#xA;&#xA;<p>We have an app which will be storing domain events to an <code>Oracle DB</code> and the consumers of the events which would use them to generate read models (all read models will be generated in memory), those consumers will mostly use a poll model to fetch the events. </p>&#xA;&#xA;<p>Which means that they will get a request and based on that request they will consume a stream of events and generate their read model then return it to the caller.</p>&#xA;&#xA;<p>So for example</p>&#xA;&#xA;<p><code>Event Generation API</code> --> Generates events for aggregates of type A and stores them in an Oracle DB.</p>&#xA;&#xA;<p><code>Consumer 1</code> --> gets a request for a certain type A aggregate, then it fetches the events and replays them to prepare it's read model.</p>&#xA;&#xA;<p><code>Consumer 2</code> --> does exactly the same thing but presents a different read model</p>&#xA;&#xA;<p><strong>Why are we using ES</strong></p>&#xA;&#xA;<ol>&#xA;<li>We need to provide historical representations of data with each change and the state of the aggregate at that change.</li>&#xA;<li>We need to be able to get a snapshot of an aggregate at any point in time per event basis, for example, when changing a name, then we need the state of the aggregate at that name changed event time</li>&#xA;<li>We need to represent the diff of the state of the aggregate between points in time</li>&#xA;</ol>&#xA;&#xA;<p>But all those requirements need to be done in a poll manner, which means the consumers will request the view at a certain point in time (could be the latest or a previous one)</p>&#xA;&#xA;<p><strong>Question 1</strong></p>&#xA;&#xA;<p>Since both <code>consumer 1</code> and <code>consumer 2</code> are going to execute basically the same logic to replay the events, then where should the code for replaying the events be? Will we implement a common library code? Does this mean that we will have duplicate replay code across consumers?</p>&#xA;&#xA;<p>I am worried that when we update an event schema we need to update multiple consumers</p>&#xA;&#xA;<p><strong>Question 2</strong></p>&#xA;&#xA;<p>Is this a good case of event sourcing?</p>&#xA;"
48160266,Canonical data model in Microservice architecture,2018-01-09 01:23:28,<design-patterns><integration><microservices><soa><canonical-schema>,1,434,0,1.0,2,"<p>Lets say i have 2 microservices (Service A, Service B) which can call each other both ways, lets say if A calls B then some parameters of response json of A will be consumed as some other parameter of request paramater of B</p>&#xA;&#xA;<p>now i realized, this problem can be better addressed by using Canonical data model, so that each service consume/produce a canonical data model,</p>&#xA;&#xA;<p>My question is how should a canonical model in this case(json) should look like</p>&#xA;&#xA;<p>suppose response of A looks like </p>&#xA;&#xA;<pre><code>{&#xA;  ""A1"": false,&#xA;  ""A2"": {&#xA;    ""width"": 5,&#xA;    ""height"": 10&#xA;  },&#xA;  ""A3"": ""A green door""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and there would be corresponding json schema, which i am not including here</p>&#xA;&#xA;<p>Similarly request of B looks like </p>&#xA;&#xA;<pre><code>{&#xA;      ""B1"": false,&#xA;      ""B2"": {&#xA;        ""width"": 5,&#xA;        ""height"": 10&#xA;      },&#xA;      ""B3"": ""A green door"",&#xA;      ""B4"": """"&#xA;       .&#xA;       .&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Attribute A1 is mapped to B1, should my canonical data model only include this first attribute with some name (business name: eg -->A1 is score B1 -->Report then buisness name might be --> Points) that commonly relates to both the microservice or should it be more of a aggregation of both json with each attribute replaced with corresponding business name?</p>&#xA;"
48144298,What does bounded context mean in Microservices World?,2018-01-08 04:38:29,<java><domain-driven-design><microservices>,2,326,2,1.0,2,"<p>I have been learning to implement Microservices but I could not understand the term ""bounded context""?</p>&#xA;&#xA;<p>I could understand that it is concept which arises out of Domain Driven Design. But I could not understand the technical implementation of it.</p>&#xA;&#xA;<p>I have looked at below links:</p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/38858550/microservices-and-bounded-contexts"">microservices and bounded contexts</a></li>&#xA;<li><a href=""https://martinfowler.com/bliki/BoundedContext.html"" rel=""nofollow noreferrer"">https://martinfowler.com/bliki/BoundedContext.html</a></li>&#xA;<li><a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/microservice-ddd-cqrs-patterns/microservice-domain-model"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/microservice-ddd-cqrs-patterns/microservice-domain-model</a></li>&#xA;</ol>&#xA;"
31095177,Data replication in Micro Services: restoring database backup,2015-06-28 01:07:07,<microservices>,1,1124,0,0.0,2,"<p>I am currently working with a legacy system that consists of several services which (among others) communicate through some kind of Enterprise Service Bus (ESB) to synchronize data.</p>&#xA;&#xA;<p>I would like to gradually work this system towards the direction of micro services architecture. I am planning to reduce the dependency on ESB and use more of message broker like RabbitMQ or Kafka. Due to some resource/existing technology limitation, I don't think I will be able to completely avoid data replication between services even though I should be able to clearly define a single service as the data owner.</p>&#xA;&#xA;<p>What I am wondering now, how can I safely do a database backup restore for a single service when necessary? Doing so will cause the service to be out of sync with other services that hold the replicated data. Any experience/suggestion regarding this?</p>&#xA;"
31165181,How to set up connection between Docker containers using AWS Beanstalk and Spring Cloud Netflix,2015-07-01 15:09:58,<amazon-web-services><docker><elastic-beanstalk><microservices><netflix-eureka>,1,648,4,1.0,2,"<p>My app consists of several microservices. &#xA;I want to use NetFlix Eureka as discovery server and I want to deploy my apps as Docker containers. I want to set up communication between my services, but there are few problems:</p>&#xA;&#xA;<ol>&#xA;<li>Beanstalk always using nginx as reverse-proxy for container and by default routes all requests to port 80. Ok, I've beaten that using some tricky script.</li>&#xA;<li>I have several network interfaces on my EC2 Beanstalk instance - docker0 which is bridge for docker and eth0 which is host IP. The problem is, that I cannot dynamically determine host IP address inside the container so I cannot pass it to the Eureka discovery server (which is also running as a Docker image) without hardcoding. Using code or configuration I can only expose internal Docker interface and not bridged.</li>&#xA;</ol>&#xA;&#xA;<p>So, bottom line - I want to build microservices-enabled application using Docker, Beanstalk and Eureka. Solution should be scalable and there shouldn't be any hardcoded values except of Eureka host IP's.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46094734,what is the best way to do versioning in service stack microservices,2017-09-07 11:03:45,<asp.net-core><servicestack><versioning><microservices>,1,99,0,0.0,2,"<p>I am using service stack with .net core, the service stack docs <a href=""http://docs.servicestack.net/versioning"" rel=""nofollow noreferrer"">here</a> say to implement IHasVersion but how we can route request coming for two different versions. Does that mean we need to have two different instances for the same service?</p>&#xA;"
46154092,Is it a good practice to wrap Masstransit for CQRS implementation?,2017-09-11 10:59:31,<c#><message-queue><microservices><cqrs><masstransit>,1,405,0,1.0,2,"<p>I would rather have a separate <code>CommandBus</code> and <code>EventBus</code> and also <code>ICommandHandler&lt;TCommand&gt;</code> and <code>IEventHandler&lt;TCommand&gt;</code>  so that an <code>OrderEventHandler</code> class looks like:</p>&#xA;&#xA;<pre><code>public class OrderEventHandler :&#xA;    IEventHandler&lt;OrderPlaced&gt;,&#xA;    IEventHandler&lt;OrderRegistrantAssigned&gt;,&#xA;    IEventHandler&lt;OrderTotalsCalculated&gt;,&#xA;    IEventHandler&lt;OrderConfirmed&gt;,&#xA;    IEventHandler&lt;OrderExpired&gt;,&#xA;    IEventHandler&lt;SeatAssignmentsCreated&gt;,&#xA;    IEventHandler&lt;SeatAssigned&gt;,&#xA;    IEventHandler&lt;SeatAssignmentUpdated&gt;,&#xA;    IEventHandler&lt;SeatUnassigned&gt;&#xA;{ &#xA;    public void Handle(OrderPlaced @event){...}&#xA;    .&#xA;    .&#xA;    .&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>A possible solution can be providing an adopter between <code>Masstransit</code> infrastructure and my <code>CQRS</code>(like <code>ConsumerToHandlerAdopter&lt;T&gt;</code>which only exposes the context details I generally need ).</p>&#xA;&#xA;<p>But since I'm new to <code>Masstransit</code>, I can't get my head around the issues I might have to deal with later.</p>&#xA;&#xA;<p><strong>So my question is:</strong>&#xA;Does it generally worth to wrap Masstransit so that I deal with my own Infrastructure?</p>&#xA;"
46061589,What kind of specification is required for NodeType.Certificates?,2017-09-05 18:53:57,<c#><.net><azure><microservices><azure-service-fabric>,1,81,1,0.0,2,"<p>When attempting to install a cluster, I am getting this error:</p>&#xA;&#xA;<pre><code>Cluster manifest validation failed with exception System.ArgumentException: NodeType.Certificates is req&#xA;uired if section Security parameter ServerAuthCredentialType is  set to X509&#xA;</code></pre>&#xA;&#xA;<p>I am attempting to install this configuration:</p>&#xA;&#xA;<pre><code>.\CreateServiceFabricCluster.ps1 -ClusterConfigFilePath .\ClusterConfig.X509.DevCluster.json&#xA;</code></pre>&#xA;&#xA;<p>Getting the following error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Running Best Practices Analyzer... Best Practices Analyzer completed&#xA;  successfully. Creating Service Fabric Cluster... Processing and&#xA;  validating cluster config. Configuring nodes. Default installation&#xA;  directory chosen based on system drive of machine 'localhost'. Copying&#xA;  installer to all machines. Configuring machine 'localhost'.&#xA;  System.Fabric.FabricDeployer.ClusterManifestValidationException:&#xA;  Cluster manifest validation failed with exception&#xA;  System.ArgumentException: NodeType.Certificates is req uired if&#xA;  section Security parameter ServerAuthCredentialType is  set to X509<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyCertificates(String[]&#xA;  source, String[] destination, ClusterManifestTypeNodeType nodeT ype)<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyDependencies()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.ValidateSettings()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricValidator.Validate()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.ConfigureOperation.OnExecuteOperation(DeploymentParameters&#xA;  parameters, ClusterManifestType clusterManifest, Infrastructure&#xA;  infrastruct ure)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperationPrivate(DeploymentParameters&#xA;  parameters)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperation(DeploymentParameters&#xA;  parameters, Boolean disableFileTrace)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfigurationInner(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfi gPath, String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boo lean removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)&#xA;  System.Fabric.FabricDeployer.ClusterManifestValidationException:&#xA;  Cluster manifest validation failed with exception&#xA;  System.ArgumentException: NodeType.Certificates is req uired if&#xA;  section Security parameter ServerAuthCredentialType is  set to X509<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyCertificates(String[]&#xA;  source, String[] destination, ClusterManifestTypeNodeType nodeT ype)<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyDependencies()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.ValidateSettings()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricValidator.Validate()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.ConfigureOperation.OnExecuteOperation(DeploymentParameters&#xA;  parameters, ClusterManifestType clusterManifest, Infrastructure&#xA;  infrastruct ure)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperationPrivate(DeploymentParameters&#xA;  parameters)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperation(DeploymentParameters&#xA;  parameters, Boolean disableFileTrace)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfigurationInner(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfi gPath, String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boo lean removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfiguration(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfigPath , String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boolean  removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath) CreateCluster Error:&#xA;  System.AggregateException: One or more errors occurred. --->&#xA;  System.Fabric.FabricDeployer.ClusterManifestValidationException:&#xA;  Cluster manifest valid ation failed with exception&#xA;  System.ArgumentException: NodeType.Certificates is required if section&#xA;  Security parameter ServerAuthCredentialType is  set to X509    at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyCertificates(String[]&#xA;  source, String[] destination, ClusterManifestTypeNodeType nodeT ype)<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyDependencies()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.ValidateSettings()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricValidator.Validate()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.ConfigureOperation.OnExecuteOperation(DeploymentParameters&#xA;  parameters, ClusterManifestType clusterManifest, Infrastructure&#xA;  infrastruct ure)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperationPrivate(DeploymentParameters&#xA;  parameters)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperation(DeploymentParameters&#xA;  parameters, Boolean disableFileTrace)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfigurationInner(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfi gPath, String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boo lean removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfiguration(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfigPath , String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boolean  removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.&lt;>c__DisplayClass14_0.b__1(String&#xA;  machineName)    at&#xA;  System.Threading.Tasks.Parallel.&lt;>c__DisplayClass17_0<code>1.&lt;ForWorker&gt;b__1()&#xA;  at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)<br>&#xA;  at&#xA;  System.Threading.Tasks.Task.&lt;&gt;c__DisplayClass176_0.&lt;ExecuteSelfReplicating&gt;b__0(Object&#xA;  )    --- End of inner exception stack trace ---    at&#xA;  System.Threading.Tasks.Task.ThrowIfExceptional(Boolean&#xA;  includeTaskCanceledExceptions)    at&#xA;  System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout,&#xA;  CancellationToken cancellationToken)    at&#xA;  System.Threading.Tasks.Parallel.ForWorker[TLocal](Int32 fromInclusive,&#xA;  Int32 toExclusive, ParallelOptions parallelOptions, Action</code>1 body,&#xA;  Action<code>2 bodyWithState, F unc</code>4 bodyWithLocal, Func<code>1 localInit,&#xA;  Action</code>1 localFinally)    at&#xA;  System.Threading.Tasks.Parallel.ForEachWorker[TSource,TLocal](IEnumerable<code>1&#xA;  source, ParallelOptions parallelOptions, Action</code>1 body, Action<code>2&#xA;  bodyWithState, Action</code> 3 bodyWithStateAndIndex, Func<code>4&#xA;  bodyWithStateAndLocal, Func</code>5 bodyWithEverything, Func<code>1 localInit,&#xA;  Action</code>1 localFinally)    at&#xA;  System.Threading.Tasks.Parallel.ForEach[TSource](IEnumerable<code>1 source,&#xA;  Action</code>1 body)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.&lt;>c__DisplayClass14_0.b__0()&#xA;  at System.Threading.Tasks.Task.Execute()&#xA;  --- End of stack trace from previous location where exception was thrown ---    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task&#xA;  task)    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task&#xA;  task)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.d__1.MoveNext()&#xA;  ---> (Inner Exception #0) System.Fabric.FabricDeployer.ClusterManifestValidationException:&#xA;  Cluster manifest validation failed with exception&#xA;  System.ArgumentException: No deType.Certificates is required if&#xA;  section Security parameter ServerAuthCredentialType is  set to X509<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyCertificates(String[]&#xA;  source, String[] destination, ClusterManifestTypeNodeType nodeT ype)<br>&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.VerifyDependencies()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricSettingsValidator.ValidateSettings()&#xA;  at&#xA;  System.Fabric.Management.WindowsFabricValidator.FabricValidator.Validate()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.FabricValidatorWrapper.ValidateAndEnsureDefaultImageStore()&#xA;  at&#xA;  System.Fabric.FabricDeployer.ConfigureOperation.OnExecuteOperation(DeploymentParameters&#xA;  parameters, ClusterManifestType clusterManifest, Infrastructure&#xA;  infrastruct ure)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperationPrivate(DeploymentParameters&#xA;  parameters)    at&#xA;  System.Fabric.FabricDeployer.DeploymentOperation.ExecuteOperation(DeploymentParameters&#xA;  parameters, Boolean disableFileTrace)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfigurationInner(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfi gPath, String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boo lean removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)    at&#xA;  System.Fabric.FabricDeployer.ConfigurationDeployer.NewNodeConfiguration(String&#xA;  clusterManifestPath, String infrastructureManifestPath, String&#xA;  jsonClusterConfigPath , String fabricDataRoot, String fabricLogRoot,&#xA;  String fabricHostCredentialUser, SecureString&#xA;  fabricHostCredentialPassword, Boolean runFabricHostServiceAsManual,&#xA;  Boolean  removeExistingConfiguration, FabricPackageType&#xA;  fabricPackageType, String fabricPackageRoot, String machineName,&#xA;  String bootstrapPackagePath)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.&lt;>c__DisplayClass14_0.b__1(String&#xA;  machineName)    at&#xA;  System.Threading.Tasks.Parallel.&lt;>c__DisplayClass17_0`1.b__1()&#xA;  at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)<br>&#xA;  at&#xA;  System.Threading.Tasks.Task.&lt;>c__DisplayClass176_0.b__0(Object&#xA;  )&lt;---</p>&#xA;  &#xA;  <p>Trace folder already exists. Traces will be written to existing trace&#xA;  folder: C:\ooo360\5.7.220\DeploymentTraces Cleaning up faulted&#xA;  installation. FabricRoot not found in registry of target machine&#xA;  localhost. Create Cluster failed. For more information please look at&#xA;  traces in FabricLogRoot. Create Cluster failed with exception:&#xA;  System.AggregateException: One or more errors occurred. --->&#xA;  System.AggregateException: One or more errors occurred.    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.d__1.MoveNext()&#xA;  --- End of stack trace from previous location where exception was thrown ---    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task&#xA;  task)    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task&#xA;  task)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManager.d__2.MoveNext()&#xA;  --- End of inner exception stack trace ---    at System.Threading.Tasks.Task.ThrowIfExceptional(Boolean&#xA;  includeTaskCanceledExceptions)    at&#xA;  System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout,&#xA;  CancellationToken cancellationToken)    at&#xA;  Microsoft.ServiceFabric.Powershell.ClusterCmdletBase.NewCluster(String&#xA;  clusterConfigurationFilePath, String fabricPackageSourcePath, Boolean&#xA;  noCleanupOnFailure, Bo olean force)&#xA;  ---> (Inner Exception #0) System.AggregateException: One or more errors occurred.    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.d__1.MoveNext()&#xA;  --- End of stack trace from previous location where exception was thrown ---    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task&#xA;  task)    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task&#xA;  task)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManager.d__2.MoveNext()&lt;---</p>&#xA;  &#xA;  <p>Create Cluster failed with exception: System.AggregateException: One&#xA;  or more errors occurred. ---> System.AggregateException: One or more&#xA;  errors occurred.    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.d__1.MoveNext()&#xA;  --- End of stack trace from previous location where exception was thrown ---    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task&#xA;  task)    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task&#xA;  task)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManager.d__2.MoveNext()&#xA;  --- End of inner exception stack trace ---    at System.Threading.Tasks.Task.ThrowIfExceptional(Boolean&#xA;  includeTaskCanceledExceptions)    at&#xA;  System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout,&#xA;  CancellationToken cancellationToken)    at&#xA;  Microsoft.ServiceFabric.Powershell.ClusterCmdletBase.NewCluster(String&#xA;  clusterConfigurationFilePath, String fabricPackageSourcePath, Boolean&#xA;  noCleanupOnFailure, Boo lean force)&#xA;  ---> (Inner Exception #0) System.AggregateException: One or more errors occurred.    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManagerInternal.d__1.MoveNext()&#xA;  --- End of stack trace from previous location where exception was thrown ---    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task&#xA;  task)    at&#xA;  System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task&#xA;  task)    at&#xA;  Microsoft.ServiceFabric.DeploymentManager.DeploymentManager.d__2.MoveNext()&lt;---</p>&#xA;</blockquote>&#xA;&#xA;<p>Here's my configuration file:</p>&#xA;&#xA;<pre><code>{&#xA;""name"": ""SampleCluster"",&#xA;""clusterConfigurationVersion"": ""1.0.0"",&#xA;""apiVersion"": ""04-2017"",&#xA;""nodes"": [&#xA;    {&#xA;        ""nodeName"": ""vm0"",&#xA;        ""iPAddress"": ""localhost"",&#xA;        ""nodeTypeRef"": ""NodeType0"",&#xA;        ""faultDomain"": ""fd:/dc1/r0"",&#xA;        ""upgradeDomain"": ""UD0""&#xA;    },&#xA;    {&#xA;        ""nodeName"": ""vm1"",&#xA;        ""iPAddress"": ""localhost"",&#xA;        ""nodeTypeRef"": ""NodeType1"",&#xA;        ""faultDomain"": ""fd:/dc1/r1"",&#xA;        ""upgradeDomain"": ""UD1""&#xA;    },&#xA;    {&#xA;        ""nodeName"": ""vm2"",&#xA;        ""iPAddress"": ""localhost"",&#xA;        ""nodeTypeRef"": ""NodeType2"",&#xA;        ""faultDomain"": ""fd:/dc1/r2"",&#xA;        ""upgradeDomain"": ""UD2""&#xA;    }&#xA;],&#xA;""properties"": {&#xA;    ""diagnosticsStore"": &#xA;    {&#xA;        ""metadata"":  ""Please replace the diagnostics file share with an actual file share accessible from all cluster machines."",&#xA;        ""dataDeletionAgeInDays"": ""7"",&#xA;        ""storeType"": ""FileShare"",&#xA;        ""connectionstring"": ""c:\\ProgramData\\SF\\DiagnosticsStore""&#xA;    },&#xA;    ""security"": {&#xA;        ""metadata"": ""The Credential type X509 indicates this is cluster is secured using X509 Certificates. The thumbprint format is - d5 ec 42 3b 79 cb e5 07 fd 83 59 3c 56 b9 d5 31 24 25 42 64."",&#xA;       ""ClusterCredentialType"": ""X509"",&#xA;       ""ServerCredentialType"": ""X509"",&#xA;       ""CertificateInformation"": {&#xA;           ""ClusterCertificateCommonNames"": {&#xA;             ""CommonNames"": [&#xA;               {&#xA;                 ""CertificateCommonName"": ""ooo-WS-Ashort.ccc.int""&#xA;               }&#xA;             ],&#xA;             ""X509StoreName"": ""My""&#xA;           },&#xA;            ""ServerCertificate"": {&#xA;                ""Thumbprint"": ""719ECFD3F5xxxxxxxxx21C69CC36514126"",&#xA;                ""X509StoreName"": ""My""&#xA;            },&#xA;           ""ServerCertificateCommonNames"": {&#xA;             ""CommonNames"": [&#xA;               {&#xA;                 ""CertificateCommonName"": ""ooo-WS-Ashort.ccc.int""&#xA;               }&#xA;             ],&#xA;             ""X509StoreName"": ""My""&#xA;           },&#xA;           ""ClientCertificateThumbprints"": [{&#xA;               ""CertificateThumbprint"": ""719ECFD3F55xxxxxxx69CC36514126"",&#xA;               ""IsAdmin"": false&#xA;           }, {&#xA;               ""CertificateThumbprint"": ""39C52B527B6xxxxxxxxxxDD115274CBE9A"",&#xA;               ""IsAdmin"": true&#xA;           }]&#xA;        }&#xA;    },&#xA;    ""nodeTypes"": [&#xA;        {&#xA;            ""name"": ""NodeType0"",&#xA;            ""clientConnectionEndpointPort"": ""19000"",&#xA;            ""clusterConnectionEndpointPort"": ""19001"",&#xA;            ""leaseDriverEndpointPort"": ""19002"",&#xA;            ""serviceConnectionEndpointPort"": ""19003"",&#xA;            ""httpGatewayEndpointPort"": ""19080"",&#xA;            ""reverseProxyEndpointPort"": ""19081"",&#xA;            ""applicationPorts"": {&#xA;                ""startPort"": ""20001"",&#xA;                ""endPort"": ""20031""&#xA;            },&#xA;            ""isPrimary"": true&#xA;        },&#xA;        {&#xA;            ""name"": ""NodeType1"",&#xA;            ""clientConnectionEndpointPort"": ""19004"",&#xA;            ""clusterConnectionEndpointPort"": ""19005"",&#xA;            ""leaseDriverEndpointPort"": ""19006"",&#xA;            ""serviceConnectionEndpointPort"": ""19007"",&#xA;            ""httpGatewayEndpointPort"": ""19082"",&#xA;            ""reverseProxyEndpointPort"": ""19083"",&#xA;            ""applicationPorts"": {&#xA;                ""startPort"": ""20288"",&#xA;                ""endPort"": ""20318""&#xA;            },&#xA;            ""isPrimary"": true&#xA;        },&#xA;        {&#xA;            ""name"": ""NodeType2"",&#xA;            ""clientConnectionEndpointPort"": ""19008"",&#xA;            ""clusterConnectionEndpointPort"": ""19009"",&#xA;            ""leaseDriverEndpointPort"": ""19010"",&#xA;            ""serviceConnectionEndpointPort"": ""19011"",&#xA;            ""httpGatewayEndpointPort"": ""19084"",&#xA;            ""reverseProxyEndpointPort"": ""19085"",&#xA;            ""applicationPorts"": {&#xA;                ""startPort"": ""20575"",&#xA;                ""endPort"": ""20605""&#xA;            },&#xA;            ""isPrimary"": false&#xA;        }&#xA;    ],&#xA;    ""fabricSettings"": [&#xA;        {&#xA;            ""name"": ""Setup"",&#xA;            ""parameters"": [&#xA;                {&#xA;                    ""name"": ""FabricDataRoot"",&#xA;                    ""value"": ""C:\\ProgramData\\SF""&#xA;                },&#xA;                {&#xA;                    ""name"": ""FabricLogRoot"",&#xA;                    ""value"": ""C:\\ProgramData\\SF\\Log""&#xA;                }&#xA;            ]&#xA;        }&#xA;    ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p><strong>What am I doing wrong? How do I specify the NodeTypes.Certificates value?</strong></p>&#xA;"
46067333,Deploying micro services to Pivotal Cloud Foundry and establish communication between the micro services,2017-09-06 05:20:55,<microservices><pivotal-cloud-foundry>,1,103,1,0.0,2,<p>I have multiple .Net core micro services where some of the micro services will talk/communicate with the other micro services. I want to deploy these services to Pivotal Cloud Foundry(PCF) each to a different container and need to establish the communication between them.</p>&#xA;&#xA;<p>I have tried using Registry service in PCF which didn't work out.</p>&#xA;&#xA;<p>I wanted to know the steps which are used to establish the communication between the micro services.</p>&#xA;&#xA;<p>Any existing example with code would help out.</p>&#xA;&#xA;<p>Could anybody help on this?</p>&#xA;&#xA;<p>Thanks</p>&#xA;
46199874,CQRS without Event Sourcing: handle event log failure,2017-09-13 14:14:04,<events><domain-driven-design><microservices><cqrs><distributed-system>,1,325,2,0.0,2,"<p>As I do not use Event Sourcing in my CQRS Application, I introduced a simple event log which enables me to update the read-store.</p>&#xA;&#xA;<p>This implies that a state change to my application consists of two actions:</p>&#xA;&#xA;<ul>&#xA;<li>Updating the write-model state, e.g. SQL INSERT</li>&#xA;<li>Insert the event into the event log</li>&#xA;</ul>&#xA;&#xA;<p>Both write operations have to happen as one atomic operation. Unfortunately, the event log resides within another database so I have to think about a distributed transaction.</p>&#xA;&#xA;<p>Most CQRS samples deal with the saga pattern and they all seem to utilize event sourcing, which makes things much simpler.</p>&#xA;&#xA;<p>My problem is a ""half-finished"" state change, e.g.</p>&#xA;&#xA;<ul>&#xA;<li>SQL Insert succeeds</li>&#xA;<li>Event Log Insert fails</li>&#xA;</ul>&#xA;&#xA;<p>I could come up with a compensating SQL operation (pseudo code):</p>&#xA;&#xA;<pre><code>SQLTransaction.Commit(); // if this fails, all is fine. Nothing to revert&#xA;try &#xA;{&#xA;    EventLog.Insert(event);&#xA;}&#xA;catch(Exception ex) &#xA;{&#xA;    // Try to undo the SQL stuff.&#xA;    CompensatingSQLTransaction().Commit(); &#xA;    // uh-oh! The commit fails!!&#xA;&#xA;    // What now? Do a Retry?&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Are there any concepts that could help me out?&#xA;I thought about the following scenario to prevent an out-of-sync read-database: </p>&#xA;&#xA;<ul>&#xA;<li>Each event has a sequence number</li>&#xA;<li>If the read-side replication detects an unprocessed event (e.g. receives 40, then 42), it queries the event log for event 41.</li>&#xA;<li>If event 41 is not available, the system will stop replicating any events until someone took a closer look.</li>&#xA;</ul>&#xA;&#xA;<p>This requires manual maintenance, but prevents the read-db from getting out-of-sync.</p>&#xA;&#xA;<p>Any real life experiences?</p>&#xA;"
41745964,Microservices using Asp.Net,2017-01-19 15:42:23,<asp.net><angular><asp.net-web-api><architecture><microservices>,1,381,0,0.0,2,"<p>After reading <a href=""https://martinfowler.com/articles/microservices.html"" rel=""nofollow noreferrer"">this great article</a> I thought about migrating our platform to micro-services architecture.</p>&#xA;&#xA;<p>Our stack is Asp.Net Web API (Rest...) on the server.&#xA;Angular 2 in the front.</p>&#xA;&#xA;<p>I wanted to make a little proof of concept to check if we should continue down this road.</p>&#xA;&#xA;<p>As for my understanding, I need to take some chunks from our web app and slice it into micro services. As for the beginning, I want to take 2 screens I have, ""Users"" And ""Purchase History"" (each of them is too big to be micro service but this is just for the POC) and create each one of them as micro service.</p>&#xA;&#xA;<p>I read that the UI should be part of the microservice, so should I create a new angular two app for each one of them?</p>&#xA;&#xA;<p>If so, should I use rest to call for the rendered HTML?</p>&#xA;"
41756234,Consul key value pair use for configuration in Spring-boot,2017-01-20 04:40:47,<spring-boot><configuration><microservices><consul><spring-cloud-consul>,1,2256,0,1.0,2,"<p>I tried to change my registration server from ""Eureka"" to ""Consul"" and also Consul as my config server. Service discovery with Consul is a success.But I can't understand how to get key/value pair option to bootstrap my application. Is there any possible way I can do that?</p>&#xA;&#xA;<p>I use spring boot with below dependancies </p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&#xA;&lt;/dependency&gt;&#xA;&lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&#xA;&lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>and this is my spring boot app ConsuleDemoApplication.class</p>&#xA;&#xA;<pre><code>@EnableDiscoveryClient&#xA;@SpringBootApplication&#xA;@RestController&#xA;public class ConsuleDemoApplication {&#xA;&#xA;    @RequestMapping(""/"")&#xA;    public String home() {&#xA;        return ""Hello world"";&#xA;    }&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(ConsuleDemoApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and my bootstrap.yml is </p>&#xA;&#xA;<pre><code>spring:&#xA;  cloud:&#xA;    consul:&#xA;      discovery:&#xA;        healthCheckInterval: 15s&#xA;        instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}&#xA;&#xA;  application:&#xA;    name: consul_demo&#xA;</code></pre>&#xA;"
41762928,How to do client side load balancing for discovered microservices in nodejs,2017-01-20 11:45:09,<node.js><microservices><netflix-ribbon>,2,1286,1,0.0,2,"<p>We are trying to build a microservice with nodejs in an environment with other microservices written in java/spring boot.</p>&#xA;&#xA;<p>The other microservices are using consul.io for service discovery and ribbon for client side load balancing. (that would be: spring-boot, spring-cloud-starter-consul-discovery, spring-cloud-starter-feign and spring-cloud-starter-ribbon projects)</p>&#xA;&#xA;<p>Now in this mix, we have a <a href=""https://www.npmjs.com/package/consul"" rel=""nofollow noreferrer"">consul node module</a> to register or discover services, but what of rest of the things? How do I do a discovery-aware rest call with a load balancing handled on the client, similar to that of ribbon.</p>&#xA;&#xA;<p>How can I achieve this in node's stack?</p>&#xA;"
41747165,Service Fabric for Development Environment on Windows Server,2017-01-19 16:42:28,<azure><microservices><azure-service-fabric>,1,144,1,0.0,2,"<p>We are developing Microservices with .NET Core on top of Service Fabric.</p>&#xA;&#xA;<p>We have two development environments that is part of our release process, Automated Test Environment and Functional Test Environment. Using two full instances of SF on Azure is costy given that we can tolerate availability and performance for our dev environment and given that our production environment is on Azure. We already have a VM that we can use.</p>&#xA;&#xA;<ul>&#xA;<li>Does SF work under Windows Server 2016 Core? (I couldn't find any affirmation online).</li>&#xA;<li>Is it possible to have two instances of our application running on one VM?</li>&#xA;</ul>&#xA;"
41850142,Microservices centralized database model,2017-01-25 11:13:51,<mysql><database><go><microservices>,2,1030,3,1.0,2,"<p>Currently we have some <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">microservice</a>, they have their own database model and migration what provided by GORM Golang package. We have a big old MySQL database which is against the microservices laws, but we can't replace it. Im afraid when the microservices numbers start to growing, we will be lost in the many database model. When I add a new column in a microservice I just type <code>service migrate</code> to the terminal (because there is a cli for run and migrate commands), and it is refresh the database.</p>&#xA;&#xA;<p>What is the best practice to manage it. For example I have 1000 microservice, noone will type the <code>service migrate</code> when someone refresh the models. I thinking about a centralized database service, where we just add a new column and it is store the all model with all migration. The only problem, how will the services get know about database model changes. This is how we store for example a user in a service:</p>&#xA;&#xA;<pre><code>type User struct {&#xA;    ID        uint           `gorm:""column:id;not null"" sql:""AUTO_INCREMENT""`&#xA;    Name      string         `gorm:""column:name;not null"" sql:""type:varchar(100)""`&#xA;    Username  sql.NullString `gorm:""column:username;not null"" sql:""type:varchar(255)""`&#xA;}&#xA;&#xA;func (u *User) TableName() string {&#xA;    return ""users""&#xA;}&#xA;</code></pre>&#xA;"
35751630,Spring-cloud Zuul retry when instance is down,2016-03-02 15:36:12,<spring><spring-cloud><microservices><netflix-eureka><netflix-zuul>,2,1841,10,2.0,2,"<p>Using Spring-cloud Angel.SR6:</p>&#xA;&#xA;<p>Here is the configuration of my Spring-boot app with @EnableZuulProxy:</p>&#xA;&#xA;<pre><code>server.port=8765&#xA;&#xA;ribbon.ConnectTimeout=500&#xA;ribbon.ReadTimeout=5000&#xA;ribbon.MaxAutoRetries=1&#xA;ribbon.MaxAutoRetriesNextServer=1&#xA;ribbon.OkToRetryOnAllOperations=true&#xA;&#xA;zuul.routes.service-id.retryable=true&#xA;</code></pre>&#xA;&#xA;<p>I have 2 instances of <code>service-id</code> running on random ports.  These instances, as well as the Zuul instance, successfully register with Eureka, and I can access RESTful endpoints on the 2 <code>service-id</code> instances by accessing <a href=""http://localhost:8765/service-id/"" rel=""nofollow"">http://localhost:8765/service-id/</a>.... and find that they are balanced in a round-robin manner.</p>&#xA;&#xA;<p>I would like to kill one of the <code>service-id</code> instances and, when that defunct instance is next in line for forwarding, have Zuul attempt to contact it, fail, and retry with the other instance.  </p>&#xA;&#xA;<p>Is this possible, or am I misreading the documentation?  When I try the above config, the request 'destined' for the defunct instance fails with a 500 Forwarding error.  From the Zuul stacktrace: </p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:140)&#xA;&#xA;....&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-idRibbonCommand timed-out and no fallback available&#xA;</code></pre>&#xA;&#xA;<p>The subsequent request succeeds as expected.  This behavior continues until the defunct instance is removed from Zuul's registry.</p>&#xA;&#xA;<p><strong>EDIT:</strong> Updated to Brixton.M5.  No change in behavior.  Here's the Hystrix exception in more detail:</p>&#xA;&#xA;<pre><code>Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-id timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$DeprecatedOnFallbackHookApplication$1.onError(AbstractCommand.java:1521) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$FallbackHookApplication$1.onError(AbstractCommand.java:1411) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:314) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:306) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:7710) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:100) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$1.run(AbstractCommand.java:958) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$2.tick(AbstractCommand.java:978) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.util.HystrixTimer$1.run(HystrixTimer.java:100) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    ... 1 common frames omitted&#xA;&#xA;Caused by: java.util.concurrent.TimeoutException: null&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:601) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:581) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    ... 15 common frames omitted&#xA;</code></pre>&#xA;"
51371678,"Only call Lambda function when Aurora transaction commits, but guarantee call (ACID)",2018-07-17 00:37:21,<amazon-web-services><microservices><amazon-rds-aurora>,1,48,0,0.0,2,"<p>For a micro service in new project I am currently considering whether to use DynamoDB or Aurora MySQL as the underlying data store. The micro service offers a REST API to a user interface, and there will be several other micro services. Those other micro services are supposed to listen to an event stream (event sourcing) generated by the UI-connected service to keep additional read models in sync.</p>&#xA;&#xA;<p>I am trying to figure out a way to guarantee that the events published to the change event stream exactly match the changes to the data in the underlying data store.  Generally, the concern is that if the REST API handler e.g. is interrupted half-way through its execution, it may have changed the data but not created the event yet (assuming that the change event is published after the data change). I am now looking for mechanisms that will alleviate this concern. </p>&#xA;&#xA;<p>For DynamoDB there are DynamoDB streams and AWS Lambda Triggers to react to data changes at data store level. The triggered Lambda could transformation the low-level data change into a meaningful change event and then publish the event to SNS, SQS or Kinesis.</p>&#xA;&#xA;<p>For Aurora MySQL I have yet to come up with such a mechanism. I have seen articles that describe two mechanisms:</p>&#xA;&#xA;<ol>&#xA;<li>Enable the binary log for Aurora and use an additional EC2 instance to process the change stream. Publish events for other services from this stream.</li>&#xA;<li>Use the native lambda_sync or lambda_async function to call a Lambda from MySQL triggers. Publish events for other services from within this Lambda.</li>&#xA;</ol>&#xA;&#xA;<p>One, I am not too happy with either approach: 1) I would prefer not to manage additional EC2 instances and process raw SQL changes. 2) I am planning to use constraints, optimistic concurrency and transactions for Aurora, which means that transactions can and will fail and rollback. However, the lambda_(a)sync calls will have been executed regardless of the transaction outcome.</p>&#xA;&#xA;<p>Any better ideas for Aurora? Or am I looking at this problem from the wrong angle?</p>&#xA;&#xA;<p>I would like to keep this question and discussion focused to the question of how to guarantee consistency between changes an the underlying data store and an outgoing stream with change events, not on Aurora vs. DynamoDB.</p>&#xA;"
51386591,How and if test syntactic (bad request) validation with Pact?,2018-07-17 16:47:55,<java><testing><tdd><microservices><pact>,2,59,0,1.0,2,"<p>I'm starting to use Pact (on Java) for Contract Tests.</p>&#xA;&#xA;<p>I've read <a href=""https://docs.pact.io/best-practices/consumer/contract-tests-vs-functional-tests"" rel=""nofollow noreferrer"">Contract Tests vs Functional Tests</a> on Pact best practices but I'm a little confused.</p>&#xA;&#xA;<p><strong>Example</strong>: a simple REST endpoint that creates a resource (POST), returning a 201 Created on success and 400 Bad Request for syntactic validation errors.&#xA;The request body is something like:</p>&#xA;&#xA;<pre><code>{&#xA;    ""firstname"" : ""Foo"",&#xA;    ""lastname"" : ""Bar""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Both <code>firstname</code> and <code>lastname</code> must not be blank. So far as I understand I could write 3 scenarios here, in which the provider should return 400 Bad Request:</p>&#xA;&#xA;<ol>&#xA;<li><code>firstname</code> is <strong>blank</strong>, <code>lastname</code> is not blank</li>&#xA;<li><code>firstname</code> is not blank, <code>lastname</code> is <strong>blank</strong></li>&#xA;<li><code>firstname</code> and <code>lastname</code> are <strong>both</strong> blank</li>&#xA;</ol>&#xA;&#xA;<p>The thing is that the mock server returns a 500 Internal Server Error if only the ""happy path pact"" is defined, and if I want to make it return 400 Bad Request I have to write all possible pacts. Moreover, if I add another fields with the same validation rule the number of pacts explodes.</p>&#xA;&#xA;<ul>&#xA;<li>First of all, should I test that scenarios on my consumer?</li>&#xA;<li>If yes, do exists any smart way to implement it with Pact DSL?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you.</p>&#xA;"
44939302,"*** process.env.ENV is not defined, assuming 'prod' env",2017-07-06 03:28:00,<angularjs><environment-variables><jhipster><microservices><gateway>,1,632,0,0.0,2,"<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in <code>application-dev.yml</code>) and&#xA;Getting following exception in console</p>&#xA;&#xA;<pre><code>*** process.env.ENV is not defined, assuming 'prod' env&#xA;</code></pre>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is given by yarn) and giving exception like below in console.</p>&#xA;&#xA;<pre><code>process.env.ENV is not defined, assuming 'prod' env&#xA;chrome-extension://kbfnbcaeplbcioakkpcpgfkobkghlhen/src/js/bundle.js:4776 *** &#xA;</code></pre>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other microservices applications.</p>&#xA;&#xA;<p>Why am I getting the above exception?</p>&#xA;"
45072041,Correct Micro Service JWT flow,2017-07-13 05:26:18,<security><jwt><microservices>,2,213,0,1.0,2,"<p>I am currently building out a micro service architecture and started with the auth server and client. I also wanted to confirm the best flow of authenticating a user with a token.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/8zUc9.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8zUc9.jpg"" alt=""flow""></a></p>&#xA;&#xA;<p>In the above image. Step 3 is were I start getting confused.&#xA;I thought of 2 solutions to the problem. </p>&#xA;&#xA;<p>One every api passes the token to the auth server and waits to get approval that the token stored inside matches the db and it is still valid. </p>&#xA;&#xA;<p>Two is to include a secret phrase in the JWT token and just have the API service parse and check for itself if the token is valid.(The secret phrase would be so that if a hacker tried to fake a token and it parsed to a valid id somehow the phrase would be off without the secret code used to encrypt the token. Which I don't even know if it is possible. If not then I guess 2 would be the best course of action)</p>&#xA;"
45111662,Microservices with common users table,2017-07-14 21:11:33,<architecture><soa><microservices>,3,244,0,1.0,2,<p>Is it possible to design a microservice based  architecture on which each microservice have separate independent database and a common users table?</p>&#xA;
45099677,Zuul - Single point of Failure,2017-07-14 09:41:04,<microservices><netflix-zuul><api-gateway>,1,296,2,0.0,2,<p><code>Zuul</code> being used to work with <code>Eureka</code>/<code>Edge Services</code> stands out to be a single point of failure? Is there any way around it to make this scalable and resilient? </p>&#xA;
45007694,Microservices - Database compatibility in between old and new versions,2017-07-10 08:56:19,<database><rest><architecture><microservices>,1,175,3,1.0,2,"<p>I am trying to dive into Microservice architecture to start coding some of small pieces of logic for my company.</p>&#xA;&#xA;<p>I know one of microservices concerns is about the database handling (each microservice must have its separated db schmema). So I am looking for pieces of advice or experiences about to move out from an old to new microservice version.</p>&#xA;&#xA;<p>So lets say I have a REST API endpoint <code>ms/v1/whatEver</code> which is running today on prod. After a week we decide to go live with the next version of it. So that we create a <code>ms/v2/whatEver</code> which has some new columns and data types in the entities envolved in this service. Thus in order to not force all clients to migrate immediately we want to keep both versions up and running till users move in progressively to <code>v2</code>.</p>&#xA;&#xA;<p>A couple of scenarios come up in to my mind if we have both version up and running (which actually is my main doubt and the reason of this post):</p>&#xA;&#xA;<ol>&#xA;<li><p>Should they read/write in the same DB instance, hence <code>v1</code> implementation must be adapted to match with the new schema structure of <code>v2</code>?</p></li>&#xA;<li><p>Should they read/write in a separate DB instance. So in any manner both DBs have to be synchronised till the day we decide to turn off <code>v1</code> to guarantee we do not miss any data (eventual consistency)? So my question here is how to accomplish that (throughout framework, queue messaging, or something..)</p></li>&#xA;<li><p>Or, code forwarding every <code>v1</code> request (inside of it) to <code>v2</code> which is going to be the owner of the already migrated new schema (unique DB instance)?</p></li>&#xA;</ol>&#xA;&#xA;<p>I have been reading a couple of books like <a href=""https://developers.redhat.com/promotions/migrating-to-microservice-databases/"" rel=""nofollow noreferrer"">Migrating to Microservices Databases - Red Hat</a> but they are written in concept terms but nothing specific with technologies or best things to do whit this. So that my post. </p>&#xA;&#xA;<p>I really appreciate your opinions.&#xA;Thanks</p>&#xA;"
42393102,Spring Actuator - metrics aggregation from docker containers,2017-02-22 13:39:44,<spring><docker><monitoring><microservices><spring-boot-actuator>,1,386,0,0.0,2,<p>I have a Spring Boot REST service application. This application uses Spring Actuator to display metrics and health information. How can I aggregate this information from two or more containers running the same application?</p>&#xA;
42490380,Handling JWT and Refresh token flow,2017-02-27 16:06:38,<security><jwt><microservices>,1,1223,0,1.0,2,<p>I am building a front end built in react that accesses multiple microservice apis that I am also building. For auth I have built a jwt login system but was wondering what is the process of handling refresh tokens. </p>&#xA;&#xA;<ol>&#xA;<li><p>Is the refresh token inside the jwt with the user info or is it in its own token with a different encryption for extra protection?</p></li>&#xA;<li><p>If it is in its own token what should the other micro services respond with to the react app if the jwt is invalid and needs to be refreshed. Is there a common http status code used?</p></li>&#xA;<li><p>I have read that a refresh token should be more secure then your jwt cause it can be used to issue jwts and will have a longer active time. Is there any extra security past encryption that can be done server side or client side that isnt already done for jwts?</p></li>&#xA;<li><p>When should you refresh the refresh token with a new token and timestamp that it becomes invalid?</p></li>&#xA;</ol>&#xA;
42608033,How to create a public key store for microservices?,2017-03-05 11:49:55,<security><docker><microservices><pki><ca>,2,492,0,0.0,2,"<p>I implemented a set of microservices in a docker enviornment. And each of these services communicate with each other using JWT tokens. When service A calls to service B </p>&#xA;&#xA;<ol>&#xA;<li>Service A, sign the token using his private key and pass to service&#xA;B</li>&#xA;<li>service B, gets the public key of ServiceA from a public key store and verify the token</li>&#xA;</ol>&#xA;&#xA;<p>Public/private key generation process is done by microservices itself and then they will pass the public key to the public key store. So the only thing that the public key store has to do,</p>&#xA;&#xA;<ol>&#xA;<li>Store public keys send by services</li>&#xA;<li>Send correct public key to services on request</li>&#xA;</ol>&#xA;&#xA;<p>What I am going to do is similar to what shows in this diagram. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/MhoGe.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MhoGe.jpg"" alt=""I got this image from ""></a></p>&#xA;&#xA;<p>I got above image from: <a href=""https://www.youtube.com/watch?v=dBdZrw2pPvc&amp;t=462s"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=dBdZrw2pPvc&amp;t=462s</a></p>&#xA;&#xA;<p>So my problem is, are there any standard implementation of this kind of public key stores? If so what are they?</p>&#xA;"
42435307,Spring Cloud Netflix vs Kubernetes,2017-02-24 09:42:37,<kubernetes><microservices><docker-swarm><netflix-zuul><spring-cloud-netflix>,1,2244,1,1.0,2,"<p>I am trying to finally choose between Spring Cloud Netflix, Kubernetes and Swarm for building our microservices environment. They are all very cool and do some choice is very hard. &#xA;I'll describe a little which kind of problems I want to solve.&#xA;I couldn't find any best way to design Api Gateway (not a simple load balancer) with Kubernetes or Swarm , that's why I want to use Zuul. But from other side Api Gateway must use service discovery which in case of Kubernetes or Swarm will be embedded inside the orchestra. With Kubernetes I can use it's spring cloud integration, but this way I will have server side discovery and client side discovery inside Kubernetes. Which is overkill I think. &#xA;I am wondering does anyone have some experience with them and any suggestions about that.&#xA;Thanks.</p>&#xA;"
47145930,Microservices versioning best practices,2017-11-06 21:16:16,<architecture><versioning><microservices>,2,885,0,1.0,2,"<p>I read the Susan Fowler's book ""production ready microservices"" and in two places (until now) I found </p>&#xA;&#xA;<ul>&#xA;<li>(page 26) ""Avoid Versioning Microservices and Endpoints"", </li>&#xA;<li>""versioning microservices can easily become an organizational nightmare"" (page 27),</li>&#xA;<li>In microservice ecosystems, the versioning of microservices is discouraged(page 58)</li>&#xA;</ul>&#xA;&#xA;<p>Anyway, I used all types of versioning for all kind of different projects: git tag, deb package versioning, python packages versioning, http api versions and I never had very big problems to manage the project's versions. Beside of this I knew exactly to what version to roll out in case of some failures or bugs from customers.</p>&#xA;&#xA;<p>Anybody have any clue why in this book the microservice versioning is so blamed and what advises would you have regarding the topic?</p>&#xA;"
47224077,Confusion in Spring Cloud microservice architecture,2017-11-10 13:38:16,<microservices><spring-cloud>,1,118,0,1.0,2,"<p>I am trying to create a spring cloud microservice by using spring boot framework.  </p>&#xA;&#xA;<ul>&#xA;<li>I created a REST microservice by using spring boot framework.</li>&#xA;<li>I also created an Eureka server as another spring boot project. And I registered microservice to the Eureka server.</li>&#xA;<li>And I created another spring boot project for Zuul. This project also registered to Eureka server.  </li>&#xA;</ul>&#xA;&#xA;<p>My Eureka server is running with 2 registered spring boot projects. Eureka server UI is properly working.</p>&#xA;&#xA;<p>Here My confusion is that, am I following standard way of developing spring cloud microservice?  </p>&#xA;&#xA;<p>Since all documentations show this type of spring cloud development. And some blog shows spring cloud in another structure. So I am totally confused about whether I am going in proper way of spring cloud microservice development?  </p>&#xA;&#xA;<p>I am new to spring cloud. Can anyone clarify if my current architecture (Creating eureka server and microservice registration as client(Zuul also)) is proper???</p>&#xA;"
47271002,How to update a GemFire Region based on changes in some other Region,2017-11-13 18:21:05,<microservices><gemfire><spring-data-gemfire>,2,128,0,0.0,2,"<p>My retail application has various contexts like receive, transfer etc. The requests to these contexts are handled by RESTful microservices developed using <em>Spring Boot</em>. The persistence layer is Cassandra. This is shared by all services as we couldn't do a vertical scaling for microservices at DB level as the services are tightly coupled conceptually.</p>&#xA;&#xA;<p>We want vertical scaling at GemFire end by creating different Regions for different contexts.</p>&#xA;&#xA;<p>For example, a BOX table in Cassandra will be updated by Region Box-Receive(receive context) and Region Box-Transfer(transfer context) via <code>CacheWriter</code>.</p>&#xA;&#xA;<p><strong>Our problem is how to maintain data sync between these two Regions?&#xA;Please suggest any other approach also for separation at GemFire end.</strong></p>&#xA;&#xA;<p>gemfire version-</p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;        &lt;groupId&gt;com.gemstone.gemfire&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;gemfire&lt;/artifactId&gt;&#xA;        &lt;version&gt;8.2.6&lt;/version&gt;&#xA;&lt;/dependency&gt;&#xA;</code></pre>&#xA;"
47319604,Microservices vs Monolothic Architecture Conversion,2017-11-16 00:28:21,<microservices><soa><separation-of-concerns>,2,145,0,0.0,2,"<p>I was recently reading about Microservices Architecture and how it differs from Monolithic Architecture. I was wondering about its implementation in the form of pure code.</p>&#xA;&#xA;<p>Say you have a monolithic architecture. All your model, i.e. your core system which handles all requests made etc. are in one file. But this contains different function definitions within this file for each different kind of request.</p>&#xA;&#xA;<p>One of the disadvantages of Monolithic architecture is that one faulty functionality will bring the entire system down. If one of these functions stopped working as expected, how will it bring the entire system down? </p>&#xA;&#xA;<p>If it does then how would this problem be solved in a Microservices architecture? The Microservice conversion would mean splitting the single file into multiple files each doing one specific thing. The requests are made to these many different model files. Since the dependencies between that specific service and others would still be there, would it not bring the system down in Microservices architecture as well?</p>&#xA;"
47163923,What are good practices for creating monorepo kubernetes infrastructure?,2017-11-07 17:24:53,<kubernetes><microservices><orchestration>,1,175,0,0.0,2,"<p>Iâ€™m having really hard time trying to construct workflow with k8s that would include:</p>&#xA;&#xA;<ul>&#xA;<li>Having <strong>monorepo</strong> for multiple microservices</li>&#xA;<li>Having <strong>single command to start</strong> all of them and being able to start local development</li>&#xA;<li>Having <code>docker-like</code> experience of installing entire infrastructure on another machine that has no k8s installed on it (for local development) 1. <code>git pull</code> 2. <code>k8s start</code>, 3. wait, 4. <code>ping localhost:3000</code> would be goal here.</li>&#xA;<li>Being able to have <strong>changes in my local files instantly applied</strong> to services without rebuilding images etc (something similar to docker volumes I guess)</li>&#xA;<li>Having <strong>modular config</strong> files where there is one root config file for infrastructure that is referencing to services smaller configs </li>&#xA;</ul>&#xA;&#xA;<p>I was looking hard for some example or guide about constructing such system without luck. </p>&#xA;&#xA;<p>Am I missing something important about k8s design that makes me look for something not really possible witk k8s?</p>&#xA;&#xA;<p><strong>Why I think such question should not be closed</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>There are many developers without dev-ops experience trying their best with microservices and I've found lack of some solid guide about such (and very common) use case</p></li>&#xA;<li><p>There is no clear guide about smooth local development experience with rapid feedback loop when it comes to k8s.</p></li>&#xA;<li><p>While it's opinion based, I find this question being more focused on general directions that would lead to such developer experience, rather than exact steps. </p>&#xA;&#xA;<p>I'm not even sure (and I was trying to find out) if it's considered good practice for professional dev-ops. I have no idea how big infrastructures (tens or hundreds of microservices) are managed. Is it possible to run them all on single machine? Is it desired?</p></li>&#xA;</ul>&#xA;"
47295217,How to start a spring boot tomcat server on a specified port through command prompt,2017-11-14 21:07:54,<java><spring><spring-mvc><spring-boot><microservices>,1,415,1,2.0,2,"<p>I have a very simple ""Hello World"" kind of REST api created using Spring Boot that is accessible through <a href=""http://localhost:8080/greeting/world"" rel=""nofollow noreferrer"">http://localhost:8080/greeting/world</a> without any problem.</p>&#xA;&#xA;<p>I would like to start two more instances of this API on ports 8081 and 8082 but not able to do so. It says <code>java.net.BindException: Address already in use: bind</code></p>&#xA;&#xA;<p><strong>Command Used:</strong></p>&#xA;&#xA;<pre><code>mvn spring-boot:run -Dserver.port=8081&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: world-greeting-service&#xA;</code></pre>&#xA;&#xA;<p><strong>WorldGreetingServiceApplication.java</strong></p>&#xA;&#xA;<pre><code>@RestController&#xA;@SpringBootApplication&#xA;public class WorldGreetingServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(WorldGreetingServiceApplication.class, args);&#xA;    }&#xA;&#xA;    @RequestMapping(""/greeting/world"")&#xA;    public String greetWorld() {&#xA;        return ""Hello World!"";&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Am I missing anything?</p>&#xA;"
47329630,How to host MassTransit and RabbitMq,2017-11-16 12:25:13,<rabbitmq><cloud><microservices><masstransit><queuing>,2,325,3,0.0,2,"<p>We are working towards an architecture like one below but we will have micro services on cloud and some on premises which will talk to each other using queue(s) and bus(es), </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qfFOh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qfFOh.png"" alt=""RabbitMQ implementation of an event bus""></a></p>&#xA;&#xA;<p>Now I am confused with where we should host MassTransit and RabbitMq, also should it be a ASP.NET Core project on its own ? if yes what I will be doing in it ? starting a bus ? creating queues ? I am not able to move forward with this</p>&#xA;"
49531349,Request Caching with Circuit-Breaker(Opossum) in nodejs,2018-03-28 09:50:53,<javascript><node.js><microservices><hystrix><circuit-breaker>,1,149,3,0.0,2,"<p>Based on the Netflix Hystrix circuit-breaker design pattern i was trying to do the following:</p>&#xA;&#xA;<pre><code>const circuitBreaker = require('opossum');&#xA;import * as request from 'request-promise';&#xA;&#xA;const circuit = circuitBreaker(request.get);&#xA;&#xA;circuit.fallback(() =&gt; Promise.resolve({result:[]}));&#xA;</code></pre>&#xA;&#xA;<p>I have 3 node js services deployed . They use a circuit-breaker(opossum) to make REST Calls in between them. I have a fallback method which handles the scenario when a service goes down. I was wondering if something like request-caching can be used alongside the circuit breaker to return cached response  whenever the fallback is invoked. If yes, how can i achieve this ?</p>&#xA;&#xA;<p>P.S : <strong>request is my client to make REST calls</strong></p>&#xA;"
49490466,Global variables And Application Variables Defining in Spring boot project,2018-03-26 11:33:22,<java><spring><spring-boot><microservices><configuration-files>,1,1421,5,3.0,2,"<p>I am trying to develop micro service by using spring and spring boot. In my project , I am converting monolithic to service oriented architecture. Project contain 20 Micro services.I these I need to set application variables and global variables. I have confusions related to this , And I am adding those confusions here,</p>&#xA;&#xA;<ol>&#xA;<li>Is possible to declare my global variables in application.properties file? ,If not possible where I can define my global variables?</li>&#xA;<li>If I am using spring config server for global configuration, How I can import those properties conditionally to client project?</li>&#xA;<li><p>Can I set different property files for different profiles in config server , and conditionally import into client project for different profiles? , Here each profile representing different regions in my case.</p>&#xA;&#xA;<p>Can anyone help me to clarify my confusions please? </p></li>&#xA;</ol>&#xA;"
48338676,Microservice deployed - initial data migration,2018-01-19 10:13:43,<microservices>,2,26,0,1.0,2,"<p>Let's say that we have microservice A (MS A) and Microservice B (MS B).&#xA;MS B has data about Products. MS A needs the productnames of MS B.</p>&#xA;&#xA;<p>Each time a product is added, updated or deleted, MS B puts a message on a message queue.&#xA;MS A is subscribed to that queue, so it can updated it's own internal state.</p>&#xA;&#xA;<p>Now my question:&#xA;How do we fill the internal state of MS A when we deploy it to production the first time?&#xA;I couldn't find any documentation about the pros and cons of the possible solutions.&#xA;I could think of:</p>&#xA;&#xA;<ol>&#xA;<li><p>Export/import on database level.</p>&#xA;&#xA;<p>Pros: not much work.</p>&#xA;&#xA;<p>Cons: can miss data if during export/import changes to the data of MS A are made.</p></li>&#xA;<li><p>Implement calls for GetData and GetDataChangedSince</p>&#xA;&#xA;<p>Pros: failsafe</p>&#xA;&#xA;<p>Cons: a lot of work</p></li>&#xA;</ol>&#xA;&#xA;<p>Are there any other options? Are there any other pros/cons?</p>&#xA;"
48209566,What to do when the queue is down?,2018-01-11 14:37:13,<architecture><queue><message-queue><microservices><amazon-sqs>,5,142,2,0.0,2,"<p>I have 2 microservices, <code>A</code> and <code>B</code>. When <code>A</code> receives a request from a user, it gets processed (store some things in the database) and a message is sent to a queue that is read by <code>B</code>.</p>&#xA;&#xA;<p>If the queue is down, my initial thought is to make the entire request fall over, rollback, and show an error to the user asking to try again later. Is it a bad practice?</p>&#xA;&#xA;<p>Would it be a better practice to store the messages in <code>A</code>'s database marked as <code>NOT_SENT</code> and have a job to send it later when the queue is up again? Or is it over-engineering?</p>&#xA;&#xA;<p>EDIT: the request to <code>A</code> needs to be synchronous, so the user knows its outcome, but they <strong>don't</strong> need to know yet the results of <code>B</code> processing the message, so it can be asynchronous.</p>&#xA;"
48370641,Microservice internal communication,2018-01-21 19:09:30,<microservices>,4,347,3,1.0,2,"<p>I've been reading up on Microservice Architecture But I still can't understand the inter-microservices communication mechanism.<br>&#xA;In many articles they said that microservices are usually exposed over a RESTful API. But when you search the internet you always see implementations based on messaging and events for the backend communications.<br><br>&#xA;So I'm confused, Is REST API a standard for all the microservices or we can see microservices without a REST endpoints.</p>&#xA;"
48294450,"Microservices, CQRS: Eventual consistency vs Strong consistency(Read after Write consistency)",2018-01-17 05:57:17,<microservices><cqrs><eventual-consistency>,3,910,4,1.0,2,<p>Using CQRS and Event store the choreography between microservices delivers an Eventual consistency where in the changes in one microservice take a bit to propagate to the other downstream systems(essentially other microservices) which are related.&#xA;What are the options if the data is so critical that both the microservices should have a strong consistency for the data? One option that i can think of is a write through Cache like a data grid but that would be very fragile specially in a distributed system.</p>&#xA;
49352887,Microservices - Access & Security understanding,2018-03-18 21:17:10,<security><external><microservices><internal>,1,84,0,1.0,2,"<p>I am coming today because I am getting into the MicroServices architecture logic for a POC. The thing is that I am not sure to totally understand the logic of how to manage the security of these services.</p>&#xA;&#xA;<p>The thing is, I would like to have a part of my app that could be usable without being connected, so some services can be called by anyone, let use A for that case. However, I would like some services to be called only if the user is connected, let use B for that case.</p>&#xA;&#xA;<p>So, it means that I have an API (C) for my client that can access A &amp; B where B can only being accessed through C, unlike A (which can be access by any HTTP request from anywhere).</p>&#xA;&#xA;<p>About that, I am not sure to understand the logic of the security applied between a MicroServices architecture. In fact, I saw a couple of articles and a couple of stack-overflow exchanges about it which are mostly:</p>&#xA;&#xA;<ul>&#xA;<li>DMZ logic</li>&#xA;<li>White List IP access</li>&#xA;<li>Internal services &amp; External services</li>&#xA;</ul>&#xA;&#xA;<p>So, what is finally the best approach? Because using White List IP access, by example, would mean that my Database should be accessed through an API (D.A.L. logic) and I am wondering if it's the best approach. If I understand the ""External"" &amp; ""Internal"" logic, it means that some services are public and the others aren't? If so, how is it organized, how does it works at the bottom? </p>&#xA;&#xA;<p>Thanks for any example or explanation, feel free to ask me any extra details.</p>&#xA;&#xA;<p>Thank in advance !</p>&#xA;"
49925171,Spring Integration or Spring Cloud Data Flow,2018-04-19 15:45:30,<spring-integration><microservices><spring-cloud-dataflow>,2,482,0,0.0,2,"<p>I'm in the process of moving some of my application to microservices. One example service is a RSS crawler which uses Spring Integration to send items to Kafka. I also see there is Spring Cloud Data Flow which uses Spring Integration and Spring Batch under the hood. </p>&#xA;&#xA;<p>If I used Spring Cloud Data Flow, would I use this within each microservice or is it used as orchestration between microservices? </p>&#xA;&#xA;<p>I'm trying understand the benefits of introducing Spring Cloud Data Flow as opposed to keeping the microservices as light as possible using Spring Integration.</p>&#xA;&#xA;<p>Any advice would be appreciated.</p>&#xA;"
49944789,Handle Status Update In Even Sourcing Pattern,2018-04-20 15:13:09,<java><microservices><event-sourcing>,1,61,9,0.0,2,"<p>I was looking at an auditing pattern to save history of my entity and I came across Event Sourcing Pattern. It is an interesting pattern and most of it makes sense to me but I had one question on how to implement a certain use case scenario?</p>&#xA;&#xA;<p>Use Case:</p>&#xA;&#xA;<ol>&#xA;<li>There is an invoice generated with amount of $100 and status as in review.</li>&#xA;<li>Then the invoice status is updated to billed</li>&#xA;<li>Then a payment of $50 is adjustment of $20 is made and status is updated to paid</li>&#xA;<li>We later realized that the amounts were incorrect. So we want to rollback previous transaction and revert bill status to billed again</li>&#xA;<li>We then post a payment of $70 and adjustment of $20 and update invoice status to complete.</li>&#xA;</ol>&#xA;&#xA;<p>From my understanding of event store. It should only contain the actions that were applied on the entity.So the event always has the updated transaction amounts(payment and adjustment) and status.</p>&#xA;&#xA;<p><strong>Database:</strong></p>&#xA;&#xA;<p>Invoice:</p>&#xA;&#xA;<pre><code>| id    | balance | payment | adjustment | status   |&#xA;|-------|---------|---------|------------|----------|&#xA;| 12345 | 10      | 70      | 20         | Paid     |&#xA;</code></pre>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | Event            | Payload |&#xA;|----------|------------|------------------|---------|&#xA;| 1        | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status</p>&#xA;&#xA;<p>So here are my questions</p>&#xA;&#xA;<ol>&#xA;<li>I get how balances can be reversed but I do not see how we can accomplish the same effect for status</li>&#xA;<li>Also how will I handle if api calls(commands) come out of  order for the above events. i.e &#xA;&#xA;<ul>&#xA;<li>Step 3 calls service</li>&#xA;<li>then step 5 </li>&#xA;<li>then step 4.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>from what I understand the balances will be fine but the invoice status will be incorrect.</p>&#xA;&#xA;<p>Please advise me on how to best handle this on event sourcing pattern.</p>&#xA;"
44886715,Should the Auth Server be combined with the User Service in a microservices architecture?,2017-07-03 13:23:23,<spring><authentication><oauth-2.0><microservices>,2,592,0,0.0,2,"<p>I am currently building a microservices based application in spring boot with the following services</p>&#xA;&#xA;<ul>&#xA;<li>Auth server (Distributes access tokens)</li>&#xA;<li>User service (User info like username, password, email, etc.)</li>&#xA;<li>Various other unrelated services</li>&#xA;</ul>&#xA;&#xA;<p>When a user sends their credentials to the auth server, the auth server should verify that they are correct and then return an access token. </p>&#xA;&#xA;<p>My question is, should I combine the auth server with the user service so looking up credentials is a simple database call, or should I keep them as separate applications and have them both point to the same shared database? Is there a better alternative?</p>&#xA;"
44722194,Deploying Independent (Different Maven Project) Rest Service Jar in another standalone/embedded jetty server,2017-06-23 13:04:41,<spring-boot><jersey><jetty><spring-data><microservices>,1,87,0,0.0,2,"<p>I am in very initial stage of our application design. I am trying to decouple application business logic in different (module) Maven projects. All Maven projects will have their own data access layer ( I am using Spring data for this), and independent Rest Service interface. </p>&#xA;&#xA;<p>Now I have tried using spring boot, but spring boot creates standalone executable jar files for each module. But I need to somehow deploy all module jars into single Jetty instance.</p>&#xA;&#xA;<p>I am somewhat trying to implement both micro services and single fat application. Reason being, There may be few clients where user traffic is comparatively very low. So, in such scenarios I feel running independent Jetty for all rest module will be over-kill. But there may be few client where expected user data load is very huge. So, I am trying to implement a flexible solution to meet of requirement.</p>&#xA;&#xA;<p>Can you please suggest if there is anything wrong in my approach.</p>&#xA;"
44802594,Refused connection to RabbitMQ when using docker link,2017-06-28 12:34:43,<asp.net-core><rabbitmq><docker-compose><microservices>,1,800,6,0.0,2,"<p>I have a microservices application which has two services and a rabbit mq used as a message queue for communication between them. Now, I want to deploy them on docker. I have the following code in the <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<p>version: ""3""&#xA;services:</p>&#xA;&#xA;<pre><code>  rabbitmq:&#xA;    build: ./Rabbit&#xA;    hostname: ""rabbitmq""&#xA;    container_name: ""rabbitmq""&#xA;    environment:&#xA;      RABBITMQ_ERLANG_COOKIE: ""cookie""&#xA;      RABBITMQ_DEFAULT_USER: ""user""&#xA;      RABBITMQ_DEFAULT_PASS: ""pass""&#xA;      RABBITMQ_DEFAULT_VHOST: ""/""&#xA;    ports:&#xA;      - ""15672:15672""&#xA;      - ""5672:5672""&#xA;    # labels:&#xA;    #   NAME: ""rabbit1""&#xA;    volumes:&#xA;    - ""/opt/rabbitmq:/var/lib/rabbitmq""&#xA;&#xA;  service1:&#xA;    build: ./service1&#xA;    deploy:&#xA;      replicas: 5&#xA;      restart_policy:&#xA;        condition: on-failure&#xA;      resources:&#xA;        limits:&#xA;          cpus: ""0.1""&#xA;          memory: 50M&#xA;    ports:&#xA;      - ""8181:80""&#xA;    depends_on:&#xA;      - rabbitmq&#xA;    links:&#xA;     - rabbitmq&#xA;    networks:&#xA;      - webnet&#xA;</code></pre>&#xA;&#xA;<p>So, here I build the RabbitMQ image in a container and then link this container to the container of <code>service1</code>. Since <code>service1</code> one is an ASP.NET Core Web API, I use the following setup to connect to the message queue:</p>&#xA;&#xA;<pre><code>//Establish the connection&#xA;            var factory = new ConnectionFactory&#xA;            {&#xA;                HostName = ""rabbitmq"",&#xA;                Port = 5672,&#xA;                UserName = ""user"",&#xA;                Password = ""pass"",&#xA;                VirtualHost = ""/"",&#xA;                AutomaticRecoveryEnabled = true,&#xA;                NetworkRecoveryInterval = TimeSpan.FromSeconds(15)&#xA;            };&#xA;</code></pre>&#xA;&#xA;<p>But when I try to run <code>docker-compose up</code>, I receive the following error message:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Unhandled Exception:&#xA;  RabbitMQ.Client.Exceptions.BrokerUnreachableException: None of the&#xA;  specified endpoints were reachable --->&#xA;  RabbitMQ.Client.Exceptions.ConnectFailureException: Connection failed&#xA;  ---> System.Net.Internals.SocketExceptionFactory+ExtendedSocketException:&#xA;  No such device or address</p>&#xA;</blockquote>&#xA;&#xA;<p>Maybe I have a mistake in the <code>HostName</code> but I am not sure how to correct it.</p>&#xA;"
50406887,Microservices data retrieve,2018-05-18 08:22:44,<architecture><microservices>,1,65,0,0.0,2,"<p>good day&#xA;i read some books about microservices architecture, but i still have question.. One of them is about situation when you need to retrieve data about some entities, which connected with other...&#xA;for example: we have order and user microservices, for example each order have some information about user and customer wants to retrieve user orders&#xA;so i see three ways to achieve this:</p>&#xA;&#xA;<ol>&#xA;<li>Client app makes request to orders microserve and after makes n&#xA;request to users microservice to retrieve user info the order</li>&#xA;<li>Client app makes request to orders mircoservice which make inter-request to users microservices</li>&#xA;<li>Orders microservice db store necessary information about user</li>&#xA;</ol>&#xA;&#xA;<p><strong>For first case</strong> - it is complex for client app to construct and aggregate data together from two sources (orders and users)</p>&#xA;&#xA;<p><strong>For second case</strong> - if we have more than two microservices then total request time will grow</p>&#xA;&#xA;<p><strong>For third case</strong> connected with data consistent problem (user changed data, but order service db does not update yet)</p>&#xA;&#xA;<p>which case is most used?</p>&#xA;&#xA;<p>and small question #2 - in case of microservice and web api application - each microservice contains only one or maybe two controllers?</p>&#xA;"
50344525,High availability in web application with Spring boot,2018-05-15 07:24:57,<spring-boot><web><microservices><high-availability>,1,76,0,0.0,2,"<p>We are developing a web server which allows user to submit spark jobs to run a hadoop cluster, and the web server will help to create a new cluster and keep monitoring the job.</p>&#xA;&#xA;<p>We deployed the web server in 3 nodes and put a loader balancer in front of them.&#xA;The High Availability requirement is that once user has submitted the job, there must be one server keep monitoring it, in case the server is done, then another server should take this task and monitoring the job, so that it has no any impact to user.</p>&#xA;&#xA;<p>Is there any suggested way to do that? What I could think is put all job information to some central storage(a table in a database), and all server keep polling the job info from the table, using distributed lock to ensure there will be only one and always be one server lock each row in the table hence monitoring that job.</p>&#xA;"
50324219,Implementing CQRS in PHP,2018-05-14 06:29:06,<php><microservices><cqrs><event-sourcing>,2,150,0,0.0,2,"<p>I'm researching about CQRS pattern and our team wants to develop a system based on CQRS in PHP. </p>&#xA;&#xA;<p>I know we can simulate event system in PHP, but I found that CQRS implements better/easier if the programming language would be event based (I'm not sure about this). </p>&#xA;&#xA;<p>I have two questions: </p>&#xA;&#xA;<ol>&#xA;<li><p>I want to know that if we develop our system by CQRS pattern in PHP could be reliable or switch to other(event-based) programming language give us more consistency? </p></li>&#xA;<li><p>what kind of benefits CQRS has in micro-services system? is there any other pattern that reliable and easier to implements?</p></li>&#xA;</ol>&#xA;"
50435154,"DDD, CQRS/ES & MicroServices Should Decisions be taken on Microservice's views or aggregates?",2018-05-20 13:07:10,<domain-driven-design><microservices><cqrs><event-sourcing>,2,139,1,1.0,2,"<p>So I'll explain the problem through the use of an example as it makes everything more concrete and hopefully will reduce ambiguity. </p>&#xA;&#xA;<p>The Architecture is pretty simple </p>&#xA;&#xA;<p><strong>1 MicroService &lt;=> 1 Aggregate &lt;=> Transactional Boundry</strong></p>&#xA;&#xA;<p>Each microservice will be using CQRS/ES design pattern which implies</p>&#xA;&#xA;<ul>&#xA;<li>Each microservice will have its own Aggregate mapping the domain of a real-world problem</li>&#xA;<li>The state of the aggregate will be rebuilt from an event store</li>&#xA;<li>Each event will signify a state change within the aggregate and will be transmitted to any service interested in the change via a message broker</li>&#xA;<li>Each microservice will be transactional within its own domain</li>&#xA;<li>Each microservice will be eventually consistent with other domains</li>&#xA;<li>Each microservice will build there own view models, from events being emitted by other microservices</li>&#xA;</ul>&#xA;&#xA;<p>So the example lets say we have a banking system</p>&#xA;&#xA;<ul>&#xA;<li><code>current-account</code> microservice is responsible for mapping the Customer Current Account ... Withdrawal, Deposits</li>&#xA;<li><code>rewards</code> microservice will be responsible for inventory and stock take of any rewards being served by the bank</li>&#xA;<li><code>air-miles</code> microservice will be responsible for monitoring all the transaction coming from the <code>current-account</code> and in doing so award the Customer with rewards, from our reward micro-service</li>&#xA;</ul>&#xA;&#xA;<p>So the problem is this Should the <code>air-miles</code> microservice take decisions based on its own view model which is being updated from events coming from the <code>current-account</code>, and similarly, on picking which reward it should give out to the Customer?</p>&#xA;&#xA;<p>Drawbacks of taking decisions on local view models;</p>&#xA;&#xA;<ul>&#xA;<li>Replicating domain logic on how to maintain these views</li>&#xA;<li>Bugs within the view might propagate the wrong rewards to be given out</li>&#xA;<li>State changes (aka events emitted) on corrupted view models could have consequences in other services which are taking their own decisions on these events</li>&#xA;</ul>&#xA;&#xA;<p>Advantages of taking a decision on local view models;</p>&#xA;&#xA;<ul>&#xA;<li>The system doesn't need to constantly query the microservice owning the domain</li>&#xA;<li><p>The system should be faster and less resource intense</p>&#xA;&#xA;<p>Or should it use the events coming from the service to trigger queries to the Aggregate owning the Domain, in doing so we accept the fact that view models might get corrupt but the final decision should always be consulted with the aggregate owning the domain?</p></li>&#xA;</ul>&#xA;&#xA;<p>Please, not that the above problem is simply my understanding of the architecture, and the aim of this post is to get different views on how one might use this architecture effectively in a microservice environment to keep each service decoupled yet avoid cascading corruption scenario without to much chatter between the service.</p>&#xA;"
50390452,Spring Boot Microservices hitting same microservice multiple time,2018-05-17 11:35:14,<java><microservices><eureka>,1,85,2,0.0,2,"<p>I am using eureka server&#xA;My problem is that &#xA;Microservice X tries to Call Microservice Y but Microservice X call Microservice Y multiple times instead of 1 time , It happens only when implementation service taken more time to respond.</p>&#xA;&#xA;<p>X is hitting using </p>&#xA;&#xA;<pre><code>    @RequestMapping(path=""/catalogs/getCatalogList"",method = RequestMethod.GET)&#xA;public ResponseEntity&lt;RestResponse&gt; getCatalogList() throws RestException;&#xA;</code></pre>&#xA;&#xA;<p>and using @FeignClient(""XYZ"")</p>&#xA;&#xA;<p>And Y is using </p>&#xA;&#xA;<pre><code>@RequestMapping(path=""/getCatalogList"",method = RequestMethod.GET)&#xA;getCatalogList()&#xA;</code></pre>&#xA;&#xA;<p>And getCatalogList is been hit many times if it takes too much to response</p>&#xA;"
50392109,Understanding Cassandra - can it replace RDBMS?,2018-05-17 12:59:06,<cassandra><bigdata><microservices><cql>,2,81,3,1.0,2,"<p>I've spent the last week cramming on Cassandra, trying to understand the basics, as well as if it fits our needs, or not. I think I understand it on a basic level at this point, but if it works like I believe I'm being told...I just can't tell if it's a good fit.</p>&#xA;&#xA;<p>We have a microservices platform which is essentially a large data bus between our customers. They use a set of APIs to push and pull shared data. The filtering, thus far, is pretty simple...but there's no way to know what the future may bring.</p>&#xA;&#xA;<p>On top of this platform is an analytics layer with several visualizations (bar charts, graphs, etc.) based on the data being passed around.</p>&#xA;&#xA;<p>The microservices platform was built atop MySQL with the idea that we could use clustering, which we honestly did not have a lot of luck with. On top of that, changes are painful, as is par for the course in the RDBMS world. Also, we expect extraordinary amounts of data with thousands-upon-thousands of concurrent users - it seems that we'll have an inevitable scaling problem.</p>&#xA;&#xA;<p>So, we began looking at Cassandra as a distributed nosql potential replacement.</p>&#xA;&#xA;<p>I watched the DataStax videos, took a course on another site, and started digging in. What I'm finding is:</p>&#xA;&#xA;<ul>&#xA;<li>Data is stored redundantly across several tables, each of which uses different primary and clustering keys, to enable different types of queries, since rows are scattered across different nodes in the cluster</li>&#xA;<li>Rather than joining, which isn't supported, you'd denormalize and create ""wide"" tables with tons of columns</li>&#xA;<li>Data is eventually consistent, so new writes may not be readily readable in a predictable, reasonable amount of time.</li>&#xA;<li>CQL, while SQL-like, is mostly a lie. How you store and key data determines which types of queries you can use. It seems very limited and inflexible.</li>&#xA;</ul>&#xA;&#xA;<p>While these concepts make sense to me, I'm struggling to see how this would fit most long-term database needs. If data is redundant across several different tables...how is it managed and kept consistent across those many tables? Are materialized views the answer in this case?</p>&#xA;&#xA;<p>I <em>want</em> to like this idea and love the distributed features, but frankly am mostly scared off, at this point. I feel like I've learned a lot and nothing at all, in the last week, and am entirely unsure how to proceed.</p>&#xA;&#xA;<p>I looked into JanusGraph, Elassandra, etc. to see if that would provide a simpler interface on top of Cassandra, relegating it to basically a storage engine, but am not confident many of these things are mature enough or even proper, for what we need.</p>&#xA;&#xA;<p>I suppose I'm looking for direction and insight from those of you who have built things w/ Cassandra, to see if it's a fit for what we're doing. I'm out of R&amp;D time, unfortunately. Thanks!</p>&#xA;"
50455134,Can Software Architects predict of how microservice architectures will mature over time?,2018-05-21 19:05:24,<architecture><microservices><soa><software-design>,1,81,4,1.0,2,"<p>In March 2014 ( just over four years ago at the time of this question ), James Lewis and Martin Fowler wrote: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Many people believe that [decay of modularity over time] is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can't truly assess how microservice architectures mature.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now that many MSAs have been built by a variety of businesses, do we have a general understanding of the maturation of these architectures? What do we know about what works as time goes forward? What do we know about what does not work?</p>&#xA;"
45412334,API gateway and microservice authentication,2017-07-31 09:40:46,<microservices><api-gateway>,1,470,0,3.0,2,"<p>How API Gateway and Micro services works.</p>&#xA;&#xA;<p>Could anyone explain the basic flow of Micro service architecture with Gateway. I couldn't find the proper answer.</p>&#xA;&#xA;<p>Say we have auth server and customer micro service running on separate instances and in front of all the services we have an API gateway.</p>&#xA;&#xA;<p>My question is.</p>&#xA;&#xA;<p>when user try to log in using username and password, the API gateway call <strong>auth server</strong> and return the <strong>access token</strong> to user.</p>&#xA;&#xA;<p>Then user trying to access the specific url (/customers - customer micro service) that is running on separate instance.&#xA;what API Gateway do ?</p>&#xA;&#xA;<ol>&#xA;<li>validate the token with auth server and get the user id and pass the request to <strong>customer service with the user id</strong> ?</li>&#xA;</ol>&#xA;&#xA;<p>OR </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>validate the token and pass the request to customer microservice <strong>with the access token</strong> ? and customer microservice responsible is to the check the user id (Make an HTTP call to auth server) ? </li>&#xA;</ol>&#xA;"
45400096,Migrating multi-module project to microservices?,2017-07-30 13:00:55,<java><microservices>,5,473,1,0.0,2,"<p>I have multi module application. To be more explicit these are maven modules where high level modules depends on low level modules. &#xA;Below are the some of the modules :-</p>&#xA;&#xA;<pre><code>    user-management&#xA;    common-services&#xA;    utils&#xA;    emails&#xA;</code></pre>&#xA;&#xA;<p>For example :- If <code>user management</code> module wants to use any services from <code>utils</code> module, it can call its services as dependency of utils is already injected under user-management.&#xA;To convert/call my project truly following microserives architecture, I believe i need to convert each module as  independently deployable services where each module is a war module&#xA;and provides its services over http(mainly as resful web services) . Is that correct or anything else need to be taken care of as well ? </p>&#xA;&#xA;<p>Probably each modules now has to be secured and authentication layer as well ?</p>&#xA;&#xA;<p>If that's the crux of microservices I really do not understand when someone ask whether you have worked on microservices as to me Its not tool/platform/framework but a simple &#xA;concept to divide you monolithic application in to smaller set of deployable modules whose services is available through HTTP. Is n't it ? May be its another buzz word.</p>&#xA;&#xA;<p><strong>Update:-</strong>&#xA;Obviously there are adavantages going micro services way like independent unit testablemodule, scalable as it can be deployed on separate machine, loose coupling etc but I see I need to handle two complex concerns also </p>&#xA;&#xA;<ol>&#xA;<li>Authentication:- For each module I need to ensure it authenticates the request which is not the case right now</li>&#xA;<li>Transaction:- I can not maintain the transaction atomicity across different services which I could do very easily at present</li>&#xA;</ol>&#xA;"
45547556,Blue Green deployment with multiple Micro Services with internal calls,2017-08-07 13:00:57,<java><amazon-web-services><spring-boot><microservices><blue-green-deployment>,4,693,4,0.0,2,"<p>I have a 8 spring boot micro services which internally call each other. The calling dns's of other micro services, define in the application.properties file of each service.</p>&#xA;&#xA;<p>Suppose,  micro service A represent by A -> a.mydns.com and B-> b.mydns.com etc</p>&#xA;&#xA;<p>So basically each micro service consist of a ELB and two HA Proxies (distribute &#xA; in two zones) and 4 App servers (distribute in two zones).</p>&#xA;&#xA;<p>Currently I am creating the new Green servers (app servers only) and switch the live traffic from HA Proxy level. In this case, while the new version of the micro services are testing, it expose to the live customers also.</p>&#xA;&#xA;<p>Ideally, the approach should be, <strong>creating the entire server structure including ELB's and HA Proxies for each micro service right?</strong></p>&#xA;&#xA;<p>But then how come I face the challenge of testing it with a test dns. I can map the ELB to a test dns. <strong>But then how about the external micro service dns's which hard coded in side the application.properties file?</strong></p>&#xA;&#xA;<p>What would be the approach I should take in such scenario?</p>&#xA;"
45544777,"NodeJS Microservices, combining data",2017-08-07 10:29:38,<javascript><node.js><redis><microservices>,1,147,13,1.0,2,"<p>I'm building a NodeJS platform that consist of several core 'parts' (users, messages and trading signals).</p>&#xA;&#xA;<p>So my idea is to create microservices for each of them, and it works pretty well.. But I can't get my head around how to 'join' data between the microservices (I'm a frontender originally.....)</p>&#xA;&#xA;<p>For example, I have 3 microservices.. Each with its own MongoDB, on its own machine complete isolated.. Imagine the common situation where the messages is retrieved from a single microservice, the message has a 'user_id' and I need to get the username and profilePicture to be combined in the retrieved message object..?</p>&#xA;&#xA;<p>I read a lot about using Redis, but it seems like a 'messaging' service to me, not much of a 'combine' service.. Can anyone help me through the darkness??</p>&#xA;&#xA;<p>Thanks!!</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jQphv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jQphv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I know its a very general question... But I just can't get a grip of what the 'best practice' is when combining data of multiple micro services..</p>&#xA;"
48616949,When we should not to use microservices?,2018-02-05 06:30:32,<architecture><microservices><software-design>,2,524,0,0.0,2,"<p>In which scenario, we should  not use micro services architecture? So far I can see the design for micro services, looks good for many use cases. </p>&#xA;&#xA;<p>One of the basic use case I will not recommend for POC (Proof of concepts) projects.</p>&#xA;"
48803038,Exception Handling with akka.net PipeTo() on Task,2018-02-15 08:41:53,<c#><microservices><akka.net>,1,288,0,0.0,2,"<p>Referring to Akka.Net documentation, using <code>PipeTo()</code> is preferred when dealing with asynchronous jobs.</p>&#xA;&#xA;<p>When dealing with a function that returns <code>Task&lt;T&gt;</code>, I can handle the failure event, no problem.</p>&#xA;&#xA;<p>The problem is, when dealing with a function that does not return any type, but only <code>Task</code>, one still calls the <code>PipeTo</code> function, but instead of having the overload which contains the failure handle, it now says the following: 'As this task has no result, only exceptions will be piped to the recipient.'.</p>&#xA;&#xA;<p>Does this mean, if I have the following code:</p>&#xA;&#xA;<pre><code>public class RepositoryComponent : IRepositoryComponent&#xA;{&#xA;    private SqlSettings _sqlSettings;&#xA;&#xA;    public RepositoryComponent(SqlSettings sqlSettings)&#xA;    {&#xA;        _sqlSettings = sqlSettings;&#xA;    }&#xA;&#xA;    public async Task InsertJobAsync(RetryModel job)&#xA;    {&#xA;        try&#xA;        {&#xA;            await... //some logic&#xA;        }&#xA;        catch { throw; }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My actor: </p>&#xA;&#xA;<pre><code>public class RepositoryActor : ActorBase&#xA;{&#xA;    private IRepositoryComponent _repoComponent;&#xA;    private ActorSelection _retryActor;&#xA;&#xA;    public RepositoryActor(IRepositoryComponent repoComponent) : base()&#xA;    {&#xA;        _repoComponent = repoComponent;&#xA;    }&#xA;&#xA;    public override void Listening()&#xA;    {&#xA;        Receive&lt;RepositoryMessages.GenericRequestNoReturn&gt;(x =&gt; InvokeRequest(x));&#xA;        Receive&lt;RepositoryMessages.GenericRequestWithResponseType&gt;(x =&gt; InvokeRequestAndSendResponse(x));&#xA;    }&#xA;&#xA;    private void InvokeRequest(RepositoryMessages.GenericRequestNoReturn msg)&#xA;    {&#xA;        try&#xA;        {&#xA;            //some logic with msg&#xA;            _repoComponent.InsertJobAsync(new Core.Models.RetryModel()).PipeTo(Context.Self);&#xA;        }&#xA;        catch (Exception ex)&#xA;        {&#xA;            base.ExceptionHandling(ex);&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In order to catch exceptions in the above actor, I need to add another Receive handler to cater for exceptions, as for example, below:</p>&#xA;&#xA;<pre><code>Receive&lt;Exception&gt;(x =&gt; SomeExceptionHandler(x));&#xA;</code></pre>&#xA;&#xA;<p>Is this correct?  If so, no need for the <code>try {} catch {}</code> around my code block?</p>&#xA;"
48687955,Communication among microservices: Apache Kafka vs Hazelcast's Topic,2018-02-08 14:35:09,<apache-kafka><microservices><messaging><hazelcast>,1,400,0,2.0,2,"<p>Disclaimer.&#xA;I have experience with <a href=""https://hazelcast.com/"" rel=""nofollow noreferrer"">Hazelcast</a> and <a href=""http://vertx.io/"" rel=""nofollow noreferrer"">Vert.x</a>. I'm new to <a href=""https://kafka.apache.org/"" rel=""nofollow noreferrer"">Apache Kafka</a>. Sorry if my question look preconceived, it's not.</p>&#xA;&#xA;<p>There are two widespread ways to arrange communication among microservices: REST and messaging. In my region, when someone says they're using messaging for communication among microservices - it de facto means Apache Kafka. </p>&#xA;&#xA;<p><em>Could you please help me to find a clue why Apache Kafka is better fit for communication needs among microservices than Hazelcast's Topic? Is it better? Because of which guarantees, features or architecture decisions?</em></p>&#xA;&#xA;<p>The Hazelcast's example for cluster wide messaging looks as following:</p>&#xA;&#xA;<pre><code>// node #1&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"")&#xA;         .publish(new Date());&#xA;&#xA;// node #2&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"");&#xA;         .addMessageListener(message -&gt; /*Do something here*/);&#xA;</code></pre>&#xA;&#xA;<p>Also there is Vert.x (very roughtly speaking actors framework) written on top of Hazelcast's topics and member discovery.</p>&#xA;&#xA;<p><em>Is Kafka messaging better for communication among microservices?</em></p>&#xA;"
48633781,Kubernetes not resolving node service,2018-02-06 00:43:39,<dns><kubernetes><google-cloud-platform><microservices><google-kubernetes-engine>,1,164,0,1.0,2,"<p>I'm having issues with the internal DNS/service resolution within Kubernetes and I can't seem to track the issue down. I have an api-gateway pod running Kong, which calls other services by their internal service name, i.e <code>srv-name.staging.svc.cluster.local</code>. Which was working fine up until recently. I attempted to deploy 3 more services, into two namespaces, staging and production. </p>&#xA;&#xA;<p>The first service, works as expected when calling <code>booking-service.staging.svc.cluster.local</code>, however the same code doesn't seem to work in the production service. And the other two service don't worth in either namespace. </p>&#xA;&#xA;<p>The behavior I'm getting is a timeout. If I curl these services from my gateway pod, they all timeout, apart from the first service deployed (<code>booking-service.staging.svc.cluster.local</code>). When I call these services from another container within the same pod, they <em>do</em> work as expected. </p>&#xA;&#xA;<p>I have Node services set up for each service I wish to expose to the client side. </p>&#xA;&#xA;<p>Here's an example Kubernetes deployment: </p>&#xA;&#xA;<pre><code>---&#xA;&#xA;# API&#xA;&#xA;apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: {{SRV_NAME}}&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: {{SRV_NAME}}&#xA;    spec:&#xA;        containers:&#xA;        - name: booking-api&#xA;          image: microhq/micro:kubernetes&#xA;          args:&#xA;            - ""api""&#xA;            - ""--handler=rpc""&#xA;          env:&#xA;          - name: PORT&#xA;            value: ""8080""&#xA;          - name: ENV&#xA;            value: {{ENV}}&#xA;          - name: MICRO_REGISTRY&#xA;            value: ""kubernetes""&#xA;          ports:&#xA;          - containerPort: 8080&#xA;        - name: {{SRV_NAME}}&#xA;          image: eu.gcr.io/{{PROJECT_NAME}}/{{SRV_NAME}}:latest&#xA;          imagePullPolicy: Always&#xA;          command: [&#xA;            ""./service"",&#xA;            ""--selector=static""&#xA;          ]&#xA;          env:&#xA;          - name: MICRO_REGISTRY&#xA;            value: ""kubernetes""&#xA;          - name: ENV&#xA;            value: {{ENV}}&#xA;          - name: DB_HOST&#xA;            value: {{DB_HOST}}&#xA;          - name: VERSION&#xA;            value: ""{{VERSION}}""&#xA;          - name: MICRO_SERVER_ADDRESS&#xA;            value: "":50051""&#xA;          ports:&#xA;          - containerPort: 50051&#xA;            name: srv-port&#xA;---&#xA;&#xA;apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: booking-service&#xA;spec:&#xA;  ports:&#xA;  - name: api-http&#xA;    port: 80&#xA;    targetPort: 8080&#xA;    protocol: TCP&#xA;  selector:&#xA;    app: booking-api&#xA;</code></pre>&#xA;&#xA;<p>I'm using go-micro <a href=""https://github.com/micro/go-micro"" rel=""nofollow noreferrer"">https://github.com/micro/go-micro</a> with the Kubernetes pre-configuration. Which again works in one case absolutely fine, but not all the others. Which leads me to believe it's not code related. It also works fine locally. </p>&#xA;&#xA;<p>When I do <code>nslookup</code> from another pod, it resolves the name and finds the cluster IP for the internal Node service as expected. When I attempt to cURL that IP address, I get the same timeout behavior.</p>&#xA;&#xA;<p>I'm using Kubernetes 1.8 on Google Cloud. </p>&#xA;"
48753245,How to expose APIs endpoints from private AWS ALB,2018-02-12 18:35:49,<amazon-web-services><microservices><amazon-vpc><aws-ecs>,3,240,0,0.0,2,"<p>We are having several microservices on AWS ECS. We have single ALB which has different target group for different microservices. We want to expose some endpoints externally while some endpoints just for internal communication. </p>&#xA;&#xA;<p>The problem is that if we put our load balancer in public VPC than it means that we are exposing all register endpoints externally. If we move load balancer to private VPC, we have to use some sort of proxy in public VPC, which required additional infra/cost and custom implementation of all security concerns like D-DOS etc.</p>&#xA;&#xA;<p>What possible approaches we can have or does AWS provide some sort of out of the box solution for this ?</p>&#xA;"
48805353,Can we call Zuul enabled server through RestTemplate,2018-02-15 10:47:22,<java><microservices><netflix-eureka><netflix-zuul>,3,431,2,0.0,2,"<p>I am trying to call a <code>zuul</code> enabled server through <code>RestTemplate</code> by directly giving the URL.&#xA;For example: restTemplate.getForObject(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>"", Employee[].class);</p>&#xA;&#xA;<p>But it is giving an error to me:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: No instances available for localhost&#xA;      at org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.execute(RibbonLoadBalancerClient.java:90) ~[spring-cloud-netflix-core-1.2.3.RELEASE.jar:1.2.3.RELEASE]</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Question in detail</strong> :&#xA;I am having four projects (Github link (branch-master): <a href=""https://github.com/vickygupta0017/microservice-poc"" rel=""nofollow noreferrer"">https://github.com/vickygupta0017/microservice-poc</a>)</p>&#xA;&#xA;<ol>&#xA;<li>microservice-server (eureka-server) port:8080</li>&#xA;<li>microservice-producer (Rest-api)   port:8086</li>&#xA;<li>zuul-gatewayproxy (zuul-server)   port:8090</li>&#xA;<li><p>microservice-consumer (spring-mvc) port:8087</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Gg1hF.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gg1hF.jpg"" alt=""Flow Image""></a></p></li>&#xA;</ol>&#xA;&#xA;<p>If I am calling <code>zuul server</code> directly from browser(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>), then it is redirecting the request to producer successfully.&#xA;But if I am calling this URL from the consumer through <code>RestTemplate</code> then it is giving me this error.</p>&#xA;&#xA;<p><strong>For Information :</strong> If I am not using zuul sever then I am able to call 'microservice-producer' from 'microservice-consumer' using <code>RestTemplate</code> successfully.</p>&#xA;"
48731168,How to apply a microservices architecture to a voting application?,2018-02-11 11:50:05,<node.js><microservices>,2,66,4,2.0,2,"<p>I am developing the FreeCodeCamp full stack voting application and would like to apply a microservices architecture. The user stories of the voting application are as follows:</p>&#xA;&#xA;<ul>&#xA;<li>As an authenticated user, I can keep my polls and come back later to access them.</li>&#xA;<li>As an authenticated user, I can share my polls with my friends.</li>&#xA;<li>As an authenticated user, I can see the aggregate results of my polls.</li>&#xA;<li>As an authenticated user, I can delete polls that I decide I don't want anymore.</li>&#xA;<li>As an authenticated user, I can create a poll with any number of possible items.</li>&#xA;<li>As an unauthenticated or authenticated user, I can see and vote on everyone's polls.</li>&#xA;</ul>&#xA;&#xA;<p>I am conceptualizing an architecture and come up with this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hn6Pe.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hn6Pe.jpg"" alt=""Concept Architecture Voting App""></a></p>&#xA;&#xA;<p>The application is composed of 6 microservices:&#xA;1. UI&#xA;2. Aggregator&#xA;3. Authorization (login, logout)&#xA;4. Social Media (sharing)&#xA;5. Polls (with db)&#xA;6. Users (with db)</p>&#xA;&#xA;<p>Curious how a developer having built microservices would break down these user stories into microservices. Thank you!</p>&#xA;"
48809275,SpringBoot microservice How to set properties in application context using java configuration,2018-02-15 14:11:20,<java><spring><spring-boot><microservices><applicationcontext>,2,455,4,0.0,2,"<p>I have a spring-boot microservice with Java based config. Now there is an auth token container, which I need to call to get the access token. That auth token library has a class like this. Notice that the class <code>AuthServletContextListener</code> comes from a third party  <code>jar</code> file which I can not modify.</p>&#xA;&#xA;<pre><code>public class AuthServletContextListener implements ServletContextListener {&#xA;    public void contextInitialized(ServletContextEvent arg0) {&#xA;        try {&#xA;            ServletContext e = arg0.getServletContext();&#xA;            Properties config = new Properties();&#xA;            this.addProp(config, e, ""auth.token.url"", ""Token Service URL"");&#xA;            this.addProp(config, e, ""auth.system.username"", ""System Username"");&#xA;            this.addProp(config, e, ""cauth.system.password"", ""System Password"");&#xA;            TokenContainer.init(config);&#xA;        } catch (IOException arg3) {&#xA;            arg3.printStackTrace();&#xA;        }&#xA;&#xA;    }&#xA;&#xA;&#xA;    private void addProp(Properties config, ServletContext context, String propName, String descrip) {&#xA;        String propVal = (String) context.getAttribute(propName);&#xA;        if (StringUtils.isEmpty(propVal)) {&#xA;            propVal = context.getInitParameter(propName);&#xA;        }&#xA;&#xA;        if (StringUtils.isNotEmpty(propVal)) {&#xA;            config.put(propName, propVal);&#xA;        } else {&#xA;            throw new RuntimeException(""error: "");&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The AuthContextListener has an annotation that automatically looks for an application startup event. This automatically starts the container correct settings if the above context params are included. I can then grab the token through that container like this:</p>&#xA;&#xA;<pre><code>TokenContainer.getSystemToken() &#xA;</code></pre>&#xA;&#xA;<p>This will initialize successfully if the above context params are included in the web.xml like so:</p>&#xA;&#xA;<pre><code>&lt;context-param&gt;&#xA;   &lt;param-name&gt;auth.system.username&lt;/param-name&gt;&#xA;   &lt;param-value&gt;UserName&lt;/param-value&gt;&#xA;&lt;/context-param&gt; &#xA;</code></pre>&#xA;&#xA;<p>The same Application context configuration as above can be performed by creating a Spring bean with the following information:</p>&#xA;&#xA;<pre><code>&lt;bean&gt;&#xA;    &lt;property name=""attributes""&gt;&#xA;        &lt;map&gt;&#xA;            &lt;entry key=""auth.token.url"" value=""${auth.token.url}""/&gt;&#xA;            &lt;entry key=""auth.system.username"" value=""${auth.system.username}""/&gt;&#xA;            &lt;entry key=""auth.system.password"" value=""${auth.system.password}""/&gt;&#xA;        &lt;/map&gt;&#xA;    &lt;/property&gt;&#xA;&lt;/bean&gt;&#xA;</code></pre>&#xA;&#xA;<p>My question is how can I achieve the same using Java based configuration in a latest spring boot application. All I have is <code>application.yml</code> file with the auth endpoint, username and password values. I tried using <code>@Configuration</code> bean but no luck. How can I set those three props in application context and make that listener start automatically for me.</p>&#xA;"
48762736,What is the best way to send password from app server to authentication micro service?,2018-02-13 08:49:49,<node.js><microservices>,1,53,7,0.0,2,"<p>I am currently in a process to develop micro service architecture in one of my projects. I have one public layer of App Servers which actually routes the user requests to relevant micro services and replies back to client. My mirco services are in private layer.</p>&#xA;&#xA;<p>Currently i am using REST API to send data back and forth. However, I was wondering, what is the best way to send username and password from app server to micro service? Should I use plain text format as micro service is in private layer? Please suggest best way.</p>&#xA;"
37793364,"AWS ECS: How do I get around ""too many containers"" with my microservice architecture API?",2016-06-13 15:13:57,<amazon-web-services><elastic-beanstalk><microservices><amazon-ecs>,2,916,6,0.0,2,"<p>I'm working on an API with microservice architecture. I deploy to ECS via Elastic Beanstalk. Each microservice is a long-running task (which, on ECS equates to a single container). I just passed up 10 tasks, and I can no longer deploy.</p>&#xA;&#xA;<blockquote>&#xA;  <p>ERROR: Service:AmazonECS, Code:ClientException, Message:Too many containers., Class:com.amazonaws.services.ecs.model.ClientException</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""http://docs.aws.amazon.com/AmazonECS/latest/developerguide/service_limits.html"" rel=""nofollow"">According to the documentation</a>, 10 task definition containers is a hard limit on ECS.</p>&#xA;&#xA;<p>Is there any way to get around this? How can I continue adding services to my API on ECS? This limitation suggests to me I am not using the service as intended. What is the best way to deploy a collection of microservices each as a separate Docker container on AWS?</p>&#xA;&#xA;<p><strong>EDIT:</strong> My understanding of the relationship between containers and tasks was completely wrong. Looks like the entire API is a single task and each container in my Dockerrun.aws.json is a container inside the API task. So, the limitation is a limit on containers inside a single task.</p>&#xA;"
37854185,Server to Server communication in microservices,2016-06-16 08:46:04,<java><spring><microservices><spring-cloud-netflix>,2,967,11,1.0,2,"<p>I am working on microservice architecture, but I am facing some challenges in that.</p>&#xA;&#xA;<p>First let me give you a brief about the architecture.</p>&#xA;&#xA;<ol>&#xA;<li><p>User logs in and get a signed token which will be used to call all REST APIS.</p></li>&#xA;<li><p>There will be lot of API server where APIs are secured using Spring security and Authorized as per the user roles.</p></li>&#xA;<li><p>Services have to interact with each other to get/update information.</p></li>&#xA;<li><p>Every service will have the power to validate a token issue by auth server.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem:-</p>&#xA;&#xA;<ol>&#xA;<li><p>Everything works fine if User logs in and the same token is used and passsed to every service which is validated across.So, services dont need to trust each other as the token is passed.</p></li>&#xA;<li><p>Now, the problem is there are some services which needs to be called from server itself without logging in. Lets say a server to server call. How will a service authenticate and authorize the call from other services.</p></li>&#xA;</ol>&#xA;&#xA;<p>I read about spring Microservices but Zuul is also not the saviour here as every API server has spring security embedded and not just the API gateway.</p>&#xA;&#xA;<p>One solution can be that every service has its own default user with certaing roles which is used to Login->Fetch a token->call other server api with token.</p>&#xA;&#xA;<p>Can you please give me some pointers in server to server calls where each server is authenticated and authorized using spring security.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;"
37413626,Perform action on upgrade of a (stateful) microservice in Azure Service Fabric?,2016-05-24 12:29:29,<microservices><azure-service-fabric><stateful>,1,135,0,1.0,2,<p>Is it possible in Azure Service Fabric to run code when a (stateful) microservice is upgraded?</p>&#xA;&#xA;<p>The case I have in mind is state migration. Between one version of a service and the next you may want to update persisted state to a new format. Or maybe delete state that is no longer relevant for the next version of the service.</p>&#xA;
43497790,How to get response of event in publisher?,2017-04-19 13:53:47,<c#><rabbitmq><microservices><masstransit>,2,196,1,0.0,2,"<p>I'm using MassTransit and rabbitMQ in c#.</p>&#xA;&#xA;<p>I send commands to consumer, get them in consumer and execute required tasks and try to send response to publisher.</p>&#xA;&#xA;<pre><code>using MyCompany.Messaging;&#xA;using System;&#xA;using System.Threading.Tasks;&#xA;&#xA;namespace MassTransit.Receiver&#xA;{&#xA;    public class RegisterCustomerConsumer : IConsumer&lt;IRegisterCustomer&gt;&#xA;    {       &#xA;        public Task Consume(ConsumeContext&lt;IRegisterCustomer&gt; context)&#xA;        {           &#xA;            IRegisterCustomer newCustomer = context.Message;&#xA;            Console.WriteLine(""A new customer has signed up, it's time to register it in the command receiver. Details: "");&#xA;            Console.WriteLine(newCustomer.Address);&#xA;            Console.WriteLine(newCustomer.Name);&#xA;            Console.WriteLine(newCustomer.Id);&#xA;            Console.WriteLine(newCustomer.Preferred);&#xA;&#xA;            context.Publish&lt;ICustomerRegistered&gt;(new&#xA;            {&#xA;                Address = newCustomer.Address,&#xA;                Id = newCustomer.Id,                &#xA;                RegisteredUtc = newCustomer.RegisteredUtc,&#xA;                Name = newCustomer.Name             &#xA;            });&#xA;&#xA;            return Task.FromResult(context.Message);&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I find this sample code which properly get message and perform related task.&#xA;Author of topic added this comment:</p>&#xA;&#xA;<p><code>Note that we didnâ€™t have to specify a queue name here as opposed to sending a command to a single queue. Weâ€™ll see that the queue names are only provided in the consumers. MassTransit will create the necessary queues in the background.</code></p>&#xA;&#xA;<p>Now, where will published response message and how to get this response in publisher?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
43498534,"In a NodeJs microservices Architecture, should I use a package.json per service?",2017-04-19 14:24:23,<node.js><microservices>,1,297,2,2.0,2,"<p>I'm currently developing a microservices architecture in NodeJs. My first approach, was a <code>package.json</code> per service. Although, it can be very tricky when accessing to a common area (with logging or database utils), for all microservices. For instance:</p>&#xA;&#xA;<pre><code>common-area &gt;&#xA;    logger.js&#xA;    package.json - install module typeorm&#xA;&#xA;service1 &gt;&#xA;    app.js - use logger.js&#xA;    package.json - also install module typeorm&#xA;</code></pre>&#xA;&#xA;<p>When running <code>node app.js</code> (Service 1) we end up with 2 typeorm modules loaded, once we made two different installations, one in common area (used by logger) and another in service1.</p>&#xA;&#xA;<p>Should I use only one <code>package.json</code>, for all micro-services, resulting in only one <code>node_modules</code> folder?</p>&#xA;"
43383125,How to refactor common EJB code as a Microservice while refactoring a monolith application,2017-04-13 03:37:30,<java-ee><architecture><microservices><weblogic12c><ejb-3.1>,2,376,2,0.0,2,"<p>I am currently working on a strategy to refactor a Monolith Java/J2EE based application which is running with multiple web services and common EJB code on Weblogic 12c Platform as multiple MicroServices.The common EJB code has session beans which are specific to each web service and it also has common code which is accessed by multiple services.What is the best approach to refactor common EJB code ? Some of the options that I came across are</p>&#xA;&#xA;<p>1.Refactor the common EJB beans as a shared library and deploy it as an EAR - The question here how will the web services lookup the beans (CDI will not work as they are outside the context,Local JNDI lookup is a possibility)</p>&#xA;&#xA;<p>2.Package the common EJB beans as a JAR file and include it all the web services APP-INF/lib directory - This option will create multiple copies of code on various services</p>&#xA;&#xA;<p>Please suggest any other options</p>&#xA;"
43418403,Microservices and coupling,2017-04-14 19:57:55,<spring-mvc><microservices><coupling>,2,324,3,0.0,2,"<p>I am trying to use some kind of microservice architecture. I am trying to use HTTP and JSON as a communication medium (I know better than to call it ReST). </p>&#xA;&#xA;<p>So, I'm using spring-mvc and I wanted to use a class as a <code>ResponseBody</code> on the called and as a <code>RequestBody</code> on the callee. So it so happens that I can duplicate and mirror the class on both the projects, or create a jar and include it in both.</p>&#xA;&#xA;<p>I see coupling in both cases, the first one is duplicate coupling and the other is (I'm sure it has a name) coupling. </p>&#xA;&#xA;<p>And the <code>Request</code> and <code>Response</code> models are not what the projects have in common. I am using event-driven architecture for both and the events are somewhat similar (kinda exactly the same). </p>&#xA;&#xA;<p>What should I do?</p>&#xA;"
43369008,Unable to connect with Azure Container Services - Kubernetes,2017-04-12 12:03:27,<azure><kubernetes><credentials><microservices><azure-container-service>,1,588,7,1.0,2,"<p>I am working on setting up environment for deploying microservices.</p>&#xA;&#xA;<p>I have gotten as far as building my code and deploying to a registry but having problem running it in Azure Container Services.</p>&#xA;&#xA;<p>I am following this guide to connect to ACS: <a href=""https://docs.microsoft.com/en-us/azure/container-service/container-service-connect"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/container-service/container-service-connect</a> </p>&#xA;&#xA;<p>But i fail on the step: Download Cluster Credentials&#xA;Using the given command</p>&#xA;&#xA;<pre><code>az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt;&#xA;</code></pre>&#xA;&#xA;<p>Ofc changing the reseource group and clustername to the correct names from my portal. I get an error:</p>&#xA;&#xA;<pre><code>[WinError 10049] The requested address is not valid in its context&#xA;</code></pre>&#xA;&#xA;<p>(if i change resource group or clustername to something else I get other errors so seems it can find those at least)</p>&#xA;&#xA;<p>When i try to search for the error it seems to be some IP adress problem but can't figure out what to do. Tried running same command from other network (from home) to make sure work firewall is not blocking something.. but I get the same error</p>&#xA;&#xA;<p>Any help appriciated!</p>&#xA;"
47566338,Not able to read configuration from Consul in spring-boot application,2017-11-30 05:13:58,<spring-boot><microservices><spring-cloud><consul><spring-cloud-consul>,1,806,3,2.0,2,"<p>I am creating a <code>Spring Boot</code> application, which will read configuration like DB properties from <code>Consul</code>. But I am not able to read the key value from Consul using my application. Following is, what I am trying to do.</p>&#xA;&#xA;<pre><code>**pom.xml**&#xA;&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0""&#xA;         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.tuturself&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-consul&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;spring.retry.version&gt;1.2.1.RELEASE&lt;/spring.retry.version&gt;&#xA;        &lt;consul.version&gt;1.1.2.RELEASE&lt;/consul.version&gt;&#xA;        &lt;consul.discovery.version&gt;1.1.2.RELEASE&lt;/consul.discovery.version&gt;&#xA;        &lt;jackson.version&gt;2.8.1&lt;/jackson.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-consul-all&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-consul-discovery&lt;/artifactId&gt;&#xA;            &lt;version&gt;${consul.discovery.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring.retry.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;3.5.1&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;1.8&lt;/source&gt;&#xA;                    &lt;target&gt;1.8&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;repackage&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-consul-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.2.1.RELEASE&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>And Following is my Main class:</strong></p>&#xA;&#xA;<pre><code>@EnableRetry&#xA;@RefreshScope&#xA;@EnableDiscoveryClient&#xA;@SpringBootApplication&#xA;@ComponentScan(""com.test.*"")&#xA;public class SpringBootConsulApplication {&#xA;&#xA;    private static ConsulConfiguration consulConfiguration;&#xA;&#xA;    public static void main(String[] args) {&#xA;        try {&#xA;            String consulHost = System.getProperty(""spring.cloud.consul.host"");&#xA;            System.out.println(""consulHost ::"" + consulHost);&#xA;            String consulPort = System.getProperty(""spring.cloud.consul.port"");&#xA;            System.out.println(""consulPort ::"" + consulPort);&#xA;            String consulPrefix = System.getProperty(""spring.cloud.consul.config.prefix"");&#xA;            System.out.println(""consulPrefix ::"" + consulPrefix);&#xA;            new SpringApplicationBuilder(SpringBootConsulApplication.class).web(true).run(args);&#xA;        } catch (Exception ex) {&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I am reading the consul properties using the <code>@Value</code> annotation:</p>&#xA;&#xA;<pre><code>@Configuration&#xA;@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)&#xA;public class ConsulConfiguration {&#xA;&#xA;    @Value(""${cassandra.host}"")&#xA;    private String cassandraHost;&#xA;&#xA;    @Value(""${cassandra.user}"")&#xA;    private String userName;&#xA;&#xA;    @Value(""${cassandra.password}"")&#xA;    private String password;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>bootstrap.yml</code> in resources folder:</p>&#xA;&#xA;<pre><code>spring:&#xA;  cloud:&#xA;    consul:&#xA;      host: localhost&#xA;      port: 8500&#xA;      enabled: true&#xA;      config:&#xA;        enabled: true&#xA;        prefix: config/application&#xA;        defaultContext: apps&#xA;        profileSeparator: '::'&#xA;  application:&#xA;    name: spring-boot-consul&#xA;</code></pre>&#xA;&#xA;<p>Consul is up and running in my local system on <code>localhost:8500</code> where I have the file <code>config/application/spring-boot-consul.yml</code> file;</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: spring-boot-consul&#xA;cassandra:&#xA;  host: 127.0.0.1:9042,127.0.0.2:9042&#xA;  user: my_user&#xA;  password: my_pass&#xA;  pooling:&#xA;    maxThread: 10&#xA;    timeout: 50&#xA;  keyspace:&#xA;    name: test_keyspace&#xA;    readConsistency: ONE&#xA;    writeConsistency: ONE&#xA;</code></pre>&#xA;&#xA;<p>When I am strating the application, it is showing not able to bind <code>cassandra.host</code> in my <code>ConsulConfiguration</code>  class. Thus stopping the application. Any hints , What I am doing wrong here?</p>&#xA;"
40815723,Circuit Breaker in a Microservices Architecture,2016-11-26 06:41:15,<microservices><hystrix><netflix><circuit-breaker>,1,293,0,1.0,2,"<p>What is the best way to add a Circuit Breaker pattern in a Microservices Architecture. Should it be on the microservice side (inside each microservice), inside an ELB or insider the Api Gateway? What would be the best design pattern? </p>&#xA;"
40829959,Share microservices between different projects,2016-11-27 14:21:50,<database><design-patterns><microservices>,1,132,2,0.0,2,"<p>I want to make a microservice project including some microservices like: page, order, products and etc.&#xA;I have two questions about that:</p>&#xA;&#xA;<ol>&#xA;<li><p>I want to know if it is a good idea to reuse the same microservice in different projects and store multiple websites data in one microservice and retrieve corresponding data by the project token?  </p>&#xA;&#xA;<p>For example we have website A and website B and share their data in the same microservice database and products microservice holds website A and website B products.</p></li>&#xA;<li><p>If reusing microservice is a good idea, then problems may occur if maybe there are some slight changes between website A and website B products. Should I rewrite another microservice for website B or write a generic product microservice so it can handle different types of products?</p></li>&#xA;</ol>&#xA;"
40960054,"Service Fabric, What Microservices is best intended for continuous polling from Service Bus",2016-12-04 15:12:29,<c#><azure><microservices><azureservicebus><azure-service-fabric>,3,1421,2,1.0,2,"<p>I am new to Service Fabric.</p>&#xA;&#xA;<p>We have a queue on Azure Service Bus. I want to continuously pull from the queue in my Service Fabric, process the message (execute some business logic) and save some data in the DB, then remove the message from the queue.</p>&#xA;&#xA;<p>The Microservice should check the queue every couple of seconds to monitor for a new message.</p>&#xA;&#xA;<p>My question is, <strong>What is the intended Microservice(s) that would pull data, process some business logic, then save to the DB. Is it A Stateless Service or a Reliable Actor</strong></p>&#xA;"
40880443,Can micro services be applied to the front-end with JS?,2016-11-30 04:40:09,<javascript><angularjs><reactjs><frontend><microservices>,1,524,3,0.0,2,"<p>I have a project which requires various developers to build components / modules for an app at any given time.</p>&#xA;&#xA;<p>However, each component can be written in a different framework or library e.g. <code>URI/app1</code> is a search component written in React, and <code>URI/app2</code> is a results component written in AngularJS. </p>&#xA;&#xA;<p>I'm trying to find a way so that given a <code>URI</code> if <code>URI/subdomain</code> is served I can serve a module which is fully encapsulated (technology wise) from other sub paths &amp; the URI.</p>&#xA;&#xA;<p>Does something along these lines exist? Is there a methodology or approach which will allow an app to holistically serve sub-modules (not fragments of a single page, but rather full pages under a unique path) and remain isolated to other front-end code, but still allow data to be passed across the technologies used, so that a developer could essentially come in and create a component / page / module under a subpath using the technology of their choice and have it be accepted cohesively across the existing app written in potentially varying technologies?</p>&#xA;"
40807355,Scheduled messages with RabbitMQ,2016-11-25 14:39:26,<rabbitmq><message-queue><microservices>,2,2663,3,1.0,2,"<p>I'm looking for a solution to have scheduled messages with RabbitMQ, so not only delaying the messages as described in several sources but schedule it to have a message e.g. every day.</p>&#xA;&#xA;<p>If not RabbitMQ, any other solutions out there you can think of and you'd suggest for a microservices environment using a message-bus?&#xA;So it's really about combining the concept of a task-scheduler and a message bus ...</p>&#xA;&#xA;<p>Or is it better to use a job scheduler just to push messages to the message queue, e.g. using rundeck in combination with RabbitMQ?</p>&#xA;"
50180928,.NET Core 2.0 HttpClient Singleton throwing 502,2018-05-04 18:14:15,<azure><httpclient><microservices>,2,53,1,0.0,2,"<p>I have a web application acting as a gateway to a variety of internal services. These services are consumed by using a single instance of <code>HttpClient</code>, instantiated at startup (i.e. <code>Startup.cs</code>)</p>&#xA;&#xA;<p>After a certain period of time, something is causing our <code>HttpClient</code> to stop hitting our APIs and immediately fail with HTTP 502 errors for every call using that client. (Note that I can still hit our APIs using other means, such as Postman)</p>&#xA;&#xA;<p>Also be aware that this is all deployed to a variety of AppServices in Azure. </p>&#xA;&#xA;<p>Any ideas as to what could corrupt HttpClient in this manner?</p>&#xA;&#xA;<p>Thanks,&#xA;-Tim</p>&#xA;"
50275156,Azure Service Bus Topic Architecture,2018-05-10 14:22:20,<c#><azure><microservices><azureservicebus><azure-servicebus-topics>,2,169,2,1.0,2,"<p>I've been working through the <a href=""https://github.com/dotnet-architecture/eShopOnContainers"" rel=""nofollow noreferrer"">eShopOnContainers</a> project provided by Microsoft, honing my microservice skills in general. One of the big concepts is the introduction of an Event Bus. I've opted to try it with Azure Service Bus but my experience with the platform is limited.</p>&#xA;&#xA;<p>I've managed to get the project running after manually creating the Topics, Subscriptions, etc, but this raises a few questions:</p>&#xA;&#xA;<p>Is it not the responsibility of the subscribing application to create it's own Subscription in Azure? e.g. on startup?</p>&#xA;&#xA;<p>Conceptually, Topics represent different event stacks, correct? E.g. Customers, Ordering, etc? Or are they intended to be domain event boundaries? E.g. in this application, 'eShop' would be the topic.</p>&#xA;&#xA;<p>Azure deployments is a whole other topic, but related to the Service Bus configuration, are there any recommended techniques for managing that within source control?</p>&#xA;&#xA;<p>Any insight is greatly appreciated.</p>&#xA;"
40691082,Splitting and naming Microservices,2016-11-19 09:07:16,<soa><microservices>,1,1036,0,1.0,2,"<p>I recently started a side-project. It was supposed to be a virtual recipe-book with the capabilities to store and retrieve recipes (CRUD), rate them and search through them. This is nothing new, but i wanted to build it as a desktop application to learn more about databases, unit testing, UIs and so on. Now that the core domain is pretty much done (i use a DDD approach) and i implemented most of the CRUD Repositories, i want to make this a bit more extensible by hosting the core functionality online, so i am able to write multiple backends (desktop application, web application, web api, etc).</p>&#xA;&#xA;<p>Service Oriented Architecture (or Microservices) sound like a good approach to me to do that. The problem i am facing is how to decide, which parts of my project belong into a separate service and how to name them.</p>&#xA;&#xA;<p>Take the following parts of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Core domain (Aggregates, Entities, Value Objects, Logic) -> <em>Java</em></li>&#xA;<li>Persistence (DAOs, Repositories, multiple Database backend implementations) -> <em>Java</em></li>&#xA;<li>Search (Search Services which use SQL queries on the persistence DB for searching) -> <em>Java</em></li>&#xA;<li>Desktop Application -> <em>JS (Electron) or JavaFX</em></li>&#xA;<li>Web Application -> <em>Flask or Rails</em></li>&#xA;<li>Web API (Manage, Rate, Search for recipes using REST) -> <em>?</em></li>&#xA;</ul>&#xA;&#xA;<p>My initial approach would be to put the core domain, the persistence, the search and the web api into a single sub-project and host that whole stack on Heroku or something similar. That way my clients could consume the web interface. The Desktop and Web apps would be different projects on their own. The Dektop app could share the core domain if they are both written in Java.</p>&#xA;&#xA;<p>Is this a valid approach, or should i split the first service into smaller parts? How do you name these services?</p>&#xA;"
40734086,Implementing API Gateway for ASP.NET API Microservices,2016-11-22 05:01:43,<.net><asp.net-web-api><asp.net-core><microservices><api-gateway>,2,3920,0,0.0,2,"<p>I have developed my micro services using ASP.NET Core WEB API. I am still planning and investigating at this step to add an API Gateway that can acts just as proxy and routes client requests to the designated service (just to isolate and prevent clients from calling the services directly). The gateway will also perform logging and security checks.</p>&#xA;&#xA;<p>I don't need any Discovery Mechanisms for the time being (but if there is a platform I could leverage that would be great).</p>&#xA;&#xA;<p>For constraint purposes let's say that my micro services are hosted on static IPs.</p>&#xA;&#xA;<p>As far as creating my own AP-Gateway, what things do I need to do?&#xA;How would such gateway be implemented?&#xA;How should I host it?  How many?&#xA;I need some patterns that I can translate into an generic implementation.</p>&#xA;&#xA;<p>I was thinking about a simply structured DB that maps every api requested to a micro service API at the other end, then using HttpWebRequest to construct the request and return back the response. Then I can create a message handler that can log all the requests.</p>&#xA;"
40585401,Using routing key to communicate services,2016-11-14 09:26:59,<rabbitmq><message-queue><soa><esb><microservices>,2,103,0,0.0,2,"<p>Take the following sample requirement:</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>Service A</strong> does some work. That work is done periodically and no one asks <strong>Service A</strong> to do it. It's done automatically.</p>&#xA;  &#xA;  <p><strong>Service B</strong> needs to query data produced by <strong>Service A</strong>. <strong>Service A</strong> resides in a different server than <strong>Service B</strong>.</p>&#xA;</blockquote>&#xA;&#xA;<p>That is, <strong>Service B</strong> won't be able to get data if <strong>Service A</strong> doesn't provide some way of asking it for the data.</p>&#xA;&#xA;<p>I want to require <strong>Service A</strong> data <em>the SOA way</em> using <em>RabbitMQ</em>: when <strong>Service B</strong> requires some data, it sends a message to a given exchange and its written to some queue. Then, <strong>Service A</strong> processes the message and publishes the <em>answer</em> to some other exchange. Finally, <strong>Service B</strong> listens the <em>answer message</em> and the cycle ends.</p>&#xA;&#xA;<h2>My question</h2>&#xA;&#xA;<p>I need some way to both publish and consume messages identified by the operation that requested data to <strong>Service A</strong>, and I also need that each started operation could be identified by an <em>unique identifier</em>.</p>&#xA;&#xA;<p>My question is about how to publish a message and be able to receive an answer for a particular invocation of an operation. </p>&#xA;&#xA;<p>I just want to validate that RabbitMQ <em>routing keys</em> are the answer to this requirement. For example, <strong>Service A</strong> sends a message with a routing key <code>072e6ee1-6046-4c3b-bade-9077c863637b</code>. There's a consumer in <strong>Service B</strong> which consumes any message ignoring the routing key, but once it produces a result, it does publishing a message to an exchange with the same routing key . Therefore, <strong>Service A</strong> receives message because it's bound to the whole routing key. </p>&#xA;&#xA;<p>Is it a possible right usage of <em>routing keys</em>?</p>&#xA;"
40586946,gofabric8> Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip,2016-11-14 10:49:35,<maven><openshift><kubernetes><microservices><fabric8>,4,180,0,0.0,2,<p>I'm trying to set up environment for microservices. I'm using fabric8 to do that.</p>&#xA;&#xA;<p>I'm using <code>mvn fabric8:cluster-start -Dfabric8.cluster.kind=openshift</code> command. while executing i'm getting following error...</p>&#xA;&#xA;<pre><code>  [INFO] gofabric8&gt; Downloading https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-mac.zip...&#xA;    [INFO] gofabric8&gt; **Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip fileUnable to download client zip: not a valid zip file**&#xA;    [INFO] gofabric8&gt; using the executable /Users/apple/.fabric8/bin/minishift&#xA;    [INFO] gofabric8&gt; running: /Users/apple/.fabric8/bin/minishift start --vm-driver=xhyve --memory=4096 --cpus=1&#xA;    [INFO] gofabric8&gt; Starting local OpenShift cluster...&#xA;    [INFO] gofabric8&gt; Downloading ISO&#xA;    [INFO] gofabric8&gt; &#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] BUILD FAILURE&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] Total time: 18:50 min&#xA;    [INFO] Finished at: 2016-11-14T16:05:32+05:30&#xA;    [INFO] Final Memory: 21M/224M&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [ERROR] Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = ''' -&gt; [Help 1]&#xA;    org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = '''&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;</code></pre>&#xA;&#xA;<p>Any Idea?</p>&#xA;
40660163,Microservices dependence management - Governance or Domain Driven Design?,2016-11-17 16:30:33,<domain-driven-design><dependency-management><microservices><soa-governance>,1,318,1,0.0,2,"<p><strong>Background</strong>: an international company with a federation model is transforming into Microservices due to chronic Monolithic pain. Autonomous teams with quick deployment is highly desirable. In spite of theory, services are indeed dependent on each other for higher functionality, but are autonomous (independently developed and deployed). Since this is a federation model and decentralized control, we cannot impose strict rules - just like the UN. Without a governance platform that will manage dependencies else due to the multiple versions in production in different countries, we foresee uncontrollable chaos.</p>&#xA;&#xA;<p>Let's call set of Microservices that needs to collaborate a ""Compatibility Set"". A service can be deployed but may not satisfy the higher functionality in its Compatibility Set.  For example MicroService A-4.3 is fully autonomous, deployed and working perfectly. However to satisfy BusinessFunctionality 8.6 it must work together with MicroService B-5.4 and MicroService C-2.9. Together (A-4.3 , B-5.4 and C-2.9) they form a ""Compatibility Set""</p>&#xA;&#xA;<p>There are two approaches to this dilemma. Microservice in real life where the rubber hits the road and the learning from experience begins...</p>&#xA;&#xA;<p><strong>Approach 1) Governance Platform</strong></p>&#xA;&#xA;<p><em>Rationale</em>: Federal model in an International company in 100+ countries. Which means Central IT can lay down the model but individual countries can choose their own destiny - and they frequently do. It frequently devolves to chaos and the Central IT team is on the hook. DDD is the solution for an ideal world where version inconsistencies do not derail functionality like releasing services which do not fit into the Compatibility set, individually blameless but together they fall apart or result in flawed or inconsistent functionality.</p>&#xA;&#xA;<ul>&#xA;<li>There is no homogeneity, there isn't even standardization of terminology</li>&#xA;<li>Developers are mixed skill, many junior, and many learning reactive programming and cloud native technologies</li>&#xA;<li>Bounded Context heavily depends on Shared Vocabulary and it can get subtle, but this is impossible to enforce and naive to assume in an International, mixed skill, fragmented scenario with multiple versions running</li>&#xA;<li>Standardization on a Single Business Model is not realistic in such a heterogeneous system (but ideal)</li>&#xA;</ul>&#xA;&#xA;<p>How what is Central IT to do when they're held responsible for this Chaos?</p>&#xA;&#xA;<p><em>Enforce a Governance Platform</em>&#xA;Create a Microservices governance system or framework to enforce dependency management. It verifies and enforces at design and run time dependencies on a particular Microservice through a manifest and performs some checks and balances to verify the service implementations being offered - the  ""Compatibility Set"". </p>&#xA;&#xA;<p><strong>Approach 2)  Domain Driven Design (DDD)</strong>&#xA;DDD is about modelling domains that are constantly evolving, where domain experts (typically a business stakeholder, or perhaps an analyst) will work alongside developers to design the system. Within each domain, a ubiquitous language is formed, such that within that context, the same word always means the same thing. An important thing to realise is that in one part of your system, â€œOrderâ€ might mean one thing, it might mean for example a list of products. In another part of your system, â€œOrderâ€ might mean something else, it might mean a financial transaction that happened. This is where the model you describe can fall down, if my service needs to get a list of orders, perhaps there is a capability out there that supplies a list of orders, but which orders are they? The list of products or the financial transaction? Trying to coordinate as many developers as you have to all use the same language here is an impossible task that is doomed to fail.</p>&#xA;&#xA;<p>In DDD, rather than trying to manage this at a system level and force every service to use the same definition of Order, DDD embraces the inherent complexity in coordinating very large deployments with huge numbers of developers involved, and allows each team to work independently, coordinating with other teams as needed, not through some centralised dependency management system. The term used in DDD is bounded contexts, where in one context, Order means one thing, and in another bounded context, Order can mean another thing. These contexts can function truly autonomously â€“ you describe your services as being autonomous, but if they have to match their definition of order with the entire system by registering and supplied dependencies to a central registry, then really they are tightly coupled to the rest of the system and what it considers an order to be â€“ you end up with all the painful coupling of a monolith, with all the pain of building a distributed system, and you wonâ€™t realise many of the benefits of microservices if you try to take this approach.</p>&#xA;&#xA;<p>So a DDD based approach doesnâ€™t ever try to take a heavy handed approach of enforcing dependencies or capabilities at the system level, rather, it allows individual teams to work without needing central coordination, if Service A needs to interact with Service B, then the team who manages Service A will work with the team that manages service B, they can build an interface between their bounded contexts, and come to an agreement on language for that interface. It is up to these teams to manage their dependencies with each other, at the system level things can remain quite opaque / unenforced.</p>&#xA;&#xA;<p>Too often we see people implement â€œMicroservicesâ€ but end up with a system that is just as, if not more inflexible, and often more fragile, than a monolith. Also called a ""Minilith"" or ""Monolith 2.0"" Microservices require a complete rethink of architecture and software development processes, and require not just allowing services to be autonomous and independently managed, but also for teams to be independent, not centrally managed. Centralising the management of dependencies and capabilities in a system is likely to be an inhibitor to successfully building a microservice based system.</p>&#xA;&#xA;<p><strong>Intelligent and Pragmatic comments invited...</strong></p>&#xA;&#xA;<p>Approach 1 (Governance) is pragmatic and tactical and intended to solve very real challenges. Question is - will it undermine the long term strategic DDD model of the Enterprise?</p>&#xA;&#xA;<p>Approach 2 (DDD) is ideal and aspirational but doesn't address the very real challenges that we have to deal with right now. </p>&#xA;&#xA;<p>Opinions? Thought? Comments? </p>&#xA;"
40645778,Microservices waiting on responses from other services,2016-11-17 02:33:58,<soa><restful-architecture><microservices>,3,76,1,0.0,2,"<p>I recently encountered a question where a person asked me what would you do in the following scenario:</p>&#xA;&#xA;<p>You have service A, service B, and service C interacting with one another. Service A can only perform its full functionality if it receives response from B and C. However, C has a lot of requests queued and will take a long time to respond. How would service A handle this scenario? Will service A wait and wait until C will respond even after getting the response from B? How will you make this architecture faster?</p>&#xA;"
40574379,SNS + CloudFormation,2016-11-13 13:31:34,<microservices><amazon-sns><amazon-cloudformation>,3,327,3,1.0,2,"<p>I'm using <em>AWS CloudFormation</em> to build a stack for a microservice. My <em>AWS CloudFormation</em> template creates resources like: a Lambda function, an SNS topic and API Gateway.</p>&#xA;&#xA;<p>This microservice does some work and publishes messages to the SNS topic. Other microservices subscribe to this topic.</p>&#xA;&#xA;<p>The problem I'm facing is that when I upgrade my microservice's <em>CloudFormation</em> template (sometimes I need to redeploy it, and recreate all resources), the SNS topic changes its <code>ARN</code>. Hence, all microservices that use this topic need to change as well.</p>&#xA;&#xA;<p>I think I could create a separate <em>CloudFormation</em> template for the SNS topic (I have more than one per microservice).</p>&#xA;&#xA;<ul>&#xA;<li>Will this be a good approach? </li>&#xA;<li>If not, what's the recommended way?</li>&#xA;</ul>&#xA;"
50775206,Debugging nestjs micro-service framework,2018-06-09 14:19:08,<typescript><visual-studio-code><microservices><nestjs>,1,91,0,0.0,2,"<p>How can we debug the nest micro-service framework in vscode,</p>&#xA;&#xA;<p>The framework is a typescript project with springboot conventions</p>&#xA;&#xA;<p><a href=""https://nestjs.com/"" rel=""nofollow noreferrer"">http://nestjs.com</a></p>&#xA;"
50835738,Monolith to Microservices (What tasks are involved?),2018-06-13 11:09:31,<architecture><microservices>,3,100,1,1.0,2,"<p>I am curious of what tasks are involved in the transistion of a monolith site into microservices. What do you have to do to make it work, i.e. redirecting. To put this into practise what tasks are involved in the transistion of the following website? </p>&#xA;&#xA;<p><a href=""http://www.wehkamp.nl/"" rel=""nofollow noreferrer"">http://www.wehkamp.nl/</a></p>&#xA;&#xA;<p>In short, I understand what the transistion does but not what has to be done to make the transistion.</p>&#xA;"
48540114,jhipster - how to master data management and microservices comunications ?,2018-01-31 10:40:24,<mongodb><spring-boot><apache-kafka><jhipster><microservices>,1,100,1,1.0,2,"<p>I'm working on a project using jHipster and microservices architecture , I'm new to this technology but, i'm really concerned about performance and app architecture.</p>&#xA;&#xA;<p>So my use case is having a gateway and one other microservice, &#xA;the gateway is responsible for managing all user related data like favorites restaurants ... , and the other microservice is responsible for restaurants data management, including crud and search operations.</p>&#xA;&#xA;<p>So my question is if i have an endpoint for adding a new favorite restaurant or selecting all favorite restaurant for a specific user, what approche i will follow </p>&#xA;&#xA;<p>PS : i'm using mongoDB for storing data</p>&#xA;&#xA;<p>1 - save only the ids of the restaurants in my user favorite document :</p>&#xA;&#xA;<pre><code>pros : &#xA;     - they will be no master data management if a restaurant is &#xA;      updated.&#xA;cons : &#xA;     - there will be a tied coupling between microservices because&#xA;      requesting favorite restaurant will depend on restaurant microservice &#xA;     - performance impact requesting list of restaurants in every &#xA;       favorite restaurant request&#xA;</code></pre>&#xA;&#xA;<p>2 - save favorite restaurants with embed documents of restaurants</p>&#xA;&#xA;<pre><code>pros: &#xA;     - there will be no tied coupling between microservices&#xA;     - better performance &#xA;cons&#xA;     - we need master data management for updating data &#xA;     - what to do if restaurant microservice is down when inserting a new favorite restaurant ?&#xA;</code></pre>&#xA;&#xA;<p>So what to choose and is there a better solution or better architecture ? &#xA;Another question how can i use the benefits of kafka in my use case ?</p>&#xA;&#xA;<p>Ps: keep in mind that i might face a large trafic . </p>&#xA;&#xA;<p>thank you :)</p>&#xA;"
48557437,API Gateway combine results,2018-02-01 07:28:23,<microservices><api-gateway>,1,116,1,0.0,2,<p>I have separate auth service and products service. &#xA;I need to have an api gateway in front of the services and do this function for protected url:</p>&#xA;&#xA;<ul>&#xA;<li>Call the auth service and validates the user token</li>&#xA;<li>if token is valid attach the user id to the request and make the request to products service.</li>&#xA;</ul>&#xA;&#xA;<p>Is there any API gateway supports this custom logic to handle requests ?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;
48419410,is kafka reliable when used as a message bus in micro services,2018-01-24 09:52:48,<apache-kafka><apache-zookeeper><microservices>,1,192,1,1.0,2,"<p>I am using kafka as a message bus for Micro Service architecture, hence multiple services listen on a topic for a message. Therefore, the services are highly dependent on the topic to be live.</p>&#xA;&#xA;<p>But, there are many instances where I get <code>leader not available</code>, <code>broker not available</code> and <code>leader= - 1</code> on the topics.</p>&#xA;&#xA;<p>Now, I am not sure if I can rely on the kafka topics, as services get interrupted when there are issues on the topics with cause issues in the platform.</p>&#xA;&#xA;<p>Can someone throw some light on the reliability and dependability on the topics and can we recover if we can across the above issues.</p>&#xA;"
48505946,Single Database backed Micro-server architecture?,2018-01-29 16:35:32,<architecture><microservices>,2,121,3,0.0,2,"<p>In an application I am planning to build, I am trying to decide an architecture for our server. One idea I had was to spawn multiple servers at different addresses like <code>orders.example.com</code>, <code>settings.example.com</code> etc, i.e. , one server process per component of the system, which will be backed by a single database cluster.</p>&#xA;&#xA;<p>I am wondering if this is a good idea, and what are the caveats of it, if anyone has ever used it ?</p>&#xA;"
48531937,AWS ALB per ECS Service vs. multiple services per ALB for a microservices architecture,2018-01-30 23:05:32,<amazon-web-services><microservices><amazon-elb><amazon-route53><amazon-alb>,1,272,4,0.0,2,"<p>Initially I thought that multiple services per ALB listener with different path patterns to distribute API calls appropriately was the obvious choice. In terms of health checks though (if one of those services goes down), I don't know of a smart way to divert traffic for just that service to a different region. </p>&#xA;&#xA;<p>If I have an active active setup with weighted route 53 records that will failover on a health check, I don't see any other solution than to either cut off that entire ALBs traffic and divert to another region, or ignore the 1 down service and continue to send traffic to the partially failing ALB.</p>&#xA;&#xA;<p>Having a one to one mapping of ALBs to services fixes this solution, but it adds additional overhead in terms of cost and complexity.</p>&#xA;&#xA;<p>What is the recommended pattern to follow for an active active microservices architecture?</p>&#xA;"
37684053,"Docker, connection refused for every other running services",2016-06-07 15:55:56,<ruby-on-rails><port><docker-compose><microservices>,1,615,0,0.0,2,"<p>My local installation of docker cannot access to other ports.</p>&#xA;&#xA;<p>This is my <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<pre><code>db:&#xA;  image: library/mysql:5.6&#xA;  environment:&#xA;    MYSQL_ALLOW_EMPTY_PASSWORD: ""yes""&#xA;  expose:&#xA;    - ""3306""&#xA;  ports:&#xA;    - ""3306:3306""&#xA;&#xA;mailcatcher:&#xA;  image: yappabe/mailcatcher&#xA;  ports:&#xA;    - ""1025:1025""&#xA;    - ""1080:1080""&#xA;&#xA;rails-app:&#xA;  build: .&#xA;  dockerfile: ""Dockerfile""&#xA;  environment:&#xA;    RAILS_ENV: development&#xA;  links:&#xA;    - mailcatcher&#xA;    - db&#xA;  command: bundle exec rails server -p 3005 -b '0.0.0.0'&#xA;  volumes:&#xA;    - "".:/home/app""&#xA;  volumes_from:&#xA;    - bundle&#xA;  expose:&#xA;    - ""3005""&#xA;  ports:&#xA;    - ""3005:3005""&#xA;</code></pre>&#xA;&#xA;<p>This is the config for mailcatcher <code>config/environments/development.rb</code>:</p>&#xA;&#xA;<pre><code>config.action_mailer.delivery_method = :smtp&#xA;config.action_mailer.smtp_settings = { address: ""localhost"", port: 1025 }&#xA;</code></pre>&#xA;&#xA;<p>This is how I run the rails app:</p>&#xA;&#xA;<pre><code>docker-compose run --service-ports rails-app&#xA;</code></pre>&#xA;&#xA;<p>This is what I see when running <code>docker ps</code>:</p>&#xA;&#xA;<pre><code>&gt; docker ps&#xA;CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                                            NAMES&#xA;1fa8ac2ad8fd        pmt_rails-app          ""bundle exec rails se""   5 seconds ago       Up 3 seconds        0.0.0.0:3005-&gt;3005/tcp                           pmt_rails-app_run_1&#xA;4f65bb2fc9ac        yappabe/mailcatcher    ""/run.sh""                About an hour ago   Up About an hour    0.0.0.0:1025-&gt;1025/tcp, 0.0.0.0:1080-&gt;1080/tcp   pmt_mailcatcher_1&#xA;cfb364ee569f        library/mysql:5.6      ""docker-entrypoint.sh""   About an hour ago   Up About an hour    0.0.0.0:3306-&gt;3306/tcp                           pmt_db_1&#xA;</code></pre>&#xA;&#xA;<p>This is what I get when rails app tries to send an email:</p>&#xA;&#xA;<pre><code>Errno::ECONNREFUSED: Connection refused - connect(2) for ""localhost"" port 1025&#xA;from /usr/local/lib/ruby/2.3.0/net/smtp.rb:542:in `initialize'&#xA;</code></pre>&#xA;&#xA;<p>I get the same error when I try to connect with another <code>rails server</code> that is running in another port.</p>&#xA;&#xA;<p>I am working with Docker-beta in a Mac OSX.</p>&#xA;"
37715875,Testing Java Spark Microservices app that implements SparkApplication interface,2016-06-09 02:26:25,<unit-testing><junit><java-8><microservices><spark-java>,1,561,2,0.0,2,"<p>I am trying to figure out how to test a web/rest services written in <code>Java Spark</code> and there is not many tutorials on how to do that. It is tricky to find answers due to confusion between <code>Apache Spark</code> and <code>Java Spark</code>. </p>&#xA;&#xA;<p>I came across this <a href=""https://github.com/perwendel/spark/tree/master/src/test/java/spark/servlet"" rel=""nofollow"">resource</a> but, I couldn't get it to work the way I had expected. There is also this <a href=""https://github.com/mscharhag/blog-examples/tree/master/sparkdemo"" rel=""nofollow"">resource</a> and examples in <code>Java Spark</code> <a href=""https://github.com/perwendel/spark/tree/master/src/test/java/spark"" rel=""nofollow"">github</a> but they all probably use embedded server. </p>&#xA;&#xA;<p>Anyway, Assuming that I have the following service </p>&#xA;&#xA;<pre><code>public class RestService implements SparkApplication {&#xA;    @Override&#xA;    public void init() {&#xA;        get(""/"", (req, res) -&gt; ""Hello World!""); &#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I would like to test the above to make sure it <code>Hello World!</code> for <code>HTTP GET</code> requests or not. I have the following test: </p>&#xA;&#xA;<pre><code>public class RestServiceTest {&#xA;    //not sure if this is a good practice????&#xA;    final static RestService restService = new RestService(); &#xA;&#xA;    @BeforeClass&#xA;    public static void beforeClass() {&#xA;        //I have seen tests that invoked className.main(null)&#xA;        //but, I don't know if its good idea to do it here?&#xA;        restService.init();&#xA;        Spark.awaitInitialization();&#xA;    }&#xA;&#xA;    @AfterClass&#xA;    public static void afterClass() {&#xA;        Spark.stop();&#xA;    }&#xA;&#xA;    @Test&#xA;    public void testRootRoute() throws IOException {&#xA;        TestResponse res = makeRequest(""GET"", ""/"");&#xA;        assertEquals(200, res.status);&#xA;        assertNotNull(res.body); &#xA;        assertEquals(""Hello World!"", res.body);&#xA;    }&#xA;&#xA;    private TestResponse makeRequest(String method, String path) throws IOException {&#xA;        URL url = new URL(""http://localhost:4567"" + path);&#xA;        HttpURLConnection connection = (HttpURLConnection) url.openConnection();&#xA;        connection.setRequestMethod(method);&#xA;        connection.setDoOutput(true);&#xA;        connection.connect();&#xA;        String body = IOUtils.toString(connection.getInputStream());&#xA;        return new TestResponse(connection.getResponseCode(), body);&#xA;    }&#xA;&#xA;    private static class TestResponse {&#xA;        public final String body;&#xA;        public final int status;&#xA;&#xA;        public TestResponse(int status, String body) {&#xA;            this.status = status;&#xA;            this.body = body;&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Running the above, the test executes successfully aand the output is shown below but, my main concern is whether this is the right method of testing a <code>Java Spark</code> webapp aimed to run not in embedded server (when SparkApplication is implemented and <code>init()</code> is overrided)? </p>&#xA;&#xA;<pre><code>T E S T S&#xA;-------------------------------------------------------&#xA;Running com.company.test.RestServiceTest&#xA;[Thread-0] INFO org.eclipse.jetty.util.log - Logging initialized @238ms&#xA;[Thread-0] INFO spark.embeddedserver.jetty.EmbeddedJettyServer - == Spark has ignited ...&#xA;[Thread-0] INFO spark.embeddedserver.jetty.EmbeddedJettyServer - &gt;&gt; Listening on 0.0.0.0:4567&#xA;[Thread-0] INFO org.eclipse.jetty.server.Server - jetty-9.3.6.v20151106&#xA;[Thread-0] INFO org.eclipse.jetty.server.ServerConnector - Started ServerConnector@4be514e0{HTTP/1.1,[http/1.1]}{0.0.0.0:4567}&#xA;[Thread-0] INFO org.eclipse.jetty.server.Server - Started @330ms&#xA;[main] INFO spark.embeddedserver.jetty.EmbeddedJettyServer - &gt;&gt;&gt; Spark shutting down ...&#xA;[main] INFO org.eclipse.jetty.server.ServerConnector - Stopped ServerConnector@4be514e0{HTTP/1.1,[http/1.1]}{0.0.0.0:4567}&#xA;[main] INFO spark.embeddedserver.jetty.EmbeddedJettyServer - done&#xA;Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.291 sec&#xA;&#xA;Results :&#xA;&#xA;Tests run: 1, Failures: 0, Errors: 0, Skipped: 0&#xA;</code></pre>&#xA;"
37615250,Repository within domain objects,2016-06-03 13:07:27,<domain-driven-design><microservices>,2,285,3,0.0,2,"<p>I have seen lot of discussions regarding this topic but i couldn't get a convincing answer. The general advice is not to have repository inside a domain object.  What about an aggregate root? Isnt it right to give the root the responsibility to manipulate the composed objects? &#xA;For example, i have a microservice which takes care of invoices. Invoice is an aggregate root which has the different products. There is no requirement for this service to give details about individual products. I have 2 tables, one to store invoice details and other to store products of those invoices. I have two repositories corresponding to the tables. I have injected product repository inside the invoice domain object. Is it wrong to do so? </p>&#xA;"
37634349,How can I handle large files processing via messaging queries in Microservices environment?,2016-06-04 19:45:51,<java><jms><ipc><microservices>,1,733,3,0.0,2,"<p>Many people suggest that the good way for organizing IPC (ImicroservicesC) is asynchronous communication via queries like Kafka and JMS. </p>&#xA;&#xA;<p>But what if I need to pass large data files between services?</p>&#xA;&#xA;<p>Suppose I have a Video Microservice and a Publisher Microservice. The first one receives videos from the user, verifies and sends them to Publisher for converting and publishing. It's oblivious video can be a very large file and it can overload messaging system (Kafka is not suitable for big messages at all). Of course, I can share one database for them and send video_id via Kafka, but it couples these services and its not a real microservices architecture anymore.</p>&#xA;&#xA;<p>Do you have similar situations in practice? How do you handle it?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
46682651,Is it possible to create a docker image whitout OS?,2017-10-11 07:47:59,<docker><docker-compose><dockerfile><microservices>,1,107,0,0.0,2,<p>To install my microservice binaries I need a centos. And since I have 20 microservice I'm trying to find a way to optimize the images size so I'm wondering if there's a way to create a docker image without os and at the moment of deployment Docker takes the OS Layer from cache to put it in all the images.. I'm a beginner so I don't know if I'm clear in my statements ? </p>&#xA;
46476437,"Is Google Cloud Endpoints equivalent to an API Gateway, or are Endpoints equivalent to a microservice?",2017-09-28 18:56:39,<node.js><google-app-engine><mean-stack><microservices><google-cloud-endpoints-v2>,2,425,0,0.0,2,"<p>Using the App Engine Flexible Environment, I'm preparing to deploy an Angular 4 client and am looking into Cloud Endpoints to handle my node.js/express microservices as it seems to simplify securing and authenticating endpoint requests, and I wanted to clarify a few things:</p>&#xA;&#xA;<ol>&#xA;<li><p>Do I use cloud-endpoints as an API Gateway which routes requests to the individual microservice backends or are the microservices supposed to be built as individual endpoints-apps themselves?</p></li>&#xA;<li><p>Do I host the Angular 4 app statically (server agnostic), and make endpoint requests directly to the Gateway/microservice from the ng client, or is the app hosted through a server framework (e.g. node.js/express) which then passes on the request along to the Gateway/microservice</p></li>&#xA;</ol>&#xA;"
46564574,Unable to run the docker container using the entrypoint,2017-10-04 12:12:02,<asp.net><docker><.net-core><docker-compose><microservices>,1,97,2,0.0,2,"<p>I am successfully able to build and run this docker container but the asp.net core application/microservice inside fails to run and exits without giving any error.</p>&#xA;&#xA;<p>here are the logs of the docker container.</p>&#xA;&#xA;<pre><code>C:\Work\FloAppCore\Docker-Compose&gt;docker-compose --verbose up -d --build&#xA;compose.config.config.find: Using configuration files: .\docker-compose.yml&#xA;docker.auth.find_config_file: Trying paths: ['C:\\Users\\flo-engineer-7\\.docker\\config.json', 'C:\\Users\\flo-engineer-7\\.dockercfg']&#xA;docker.auth.find_config_file: No config file found&#xA;compose.cli.command.get_client: docker-compose version 1.16.1, build 6d1ac219&#xA;docker-py version: 2.5.1&#xA;CPython version: 2.7.13&#xA;OpenSSL version: OpenSSL 1.0.2j  26 Sep 2016&#xA;compose.cli.command.get_client: Docker base_url: http+docker://localnpipe&#xA;compose.cli.command.get_client: Docker version: KernelVersion=10.0 14393 (14393.1593.amd64fre.rs1_release.170731-1934), Arch=amd64, BuildTime=2017-09-21T23:10:04.946582391+00:00, ApiVersion=1.30, Version=17.06.2-ee-3, MinAPIVersion=1.24, GitCommit=915cbaa, Os=windows, GoVersion=go1.8.3&#xA;compose.cli.verbose_proxy.proxy_callable: docker info &lt;- ()&#xA;compose.cli.verbose_proxy.proxy_callable: docker info -&gt; {u'Architecture': u'x86_64',&#xA; u'BridgeNfIp6tables': True,&#xA; u'BridgeNfIptables': True,&#xA; u'CPUSet': False,&#xA; u'CPUShares': False,&#xA; u'CgroupDriver': u'',&#xA; u'ClusterAdvertise': u'',&#xA; u'ClusterStore': u'',&#xA; u'ContainerdCommit': {u'Expected': u'', u'ID': u''},&#xA; u'Containers': 5,&#xA;...&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_network &lt;- (u'dockercompose_default')&#xA;compose.network.ensure: Creating network ""dockercompose_default"" with the default driver&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_network &lt;- (name=u'dockercompose_default', enable_ipv6=False, ipam=None, labels={u'com.docker.compose.project': u'dockercompose', u'com.docker.compose.network': u'default'}, driver=None, attachable=True, internal=False, options=None)&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_network -&gt; {u'Id': u'6765f470d5c0ad7efb38a122e11e1c8ca4f76ceeefe5ad9d3c4e3463b62e05ee',&#xA; u'Warning': u''}&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers &lt;- (all=False, filters={u'label': [u'com.docker.compose.project=dockercompose', u'com.docker.compose.oneoff=False']})&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers -&gt; (list with 0 items)&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers &lt;- (all=True, filters={u'label': [u'com.docker.compose.project=dockercompose', u'com.docker.compose.service=flousermanagement', u'com.docker.compose.oneoff=False']})&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers -&gt; (list with 0 items)&#xA;compose.service.build: Building flousermanagement&#xA;compose.cli.verbose_proxy.proxy_callable: docker build &lt;- (nocache=False, pull=False, cache_from=None, target=None, stream=True, labels=None, network_mode=None, tag=u'dockercompose_flousermanagement', buildargs={}, forcerm=False, rm=True, path=u'C:\\Work\\FloAppCore\\FloUserManagement\\bin\\Debug\\netcoreapp2.0\\publish', dockerfile='Dockerfile')&#xA;docker.api.build._set_auth_headers: Looking for auth config&#xA;docker.api.build._set_auth_headers: No auth config in memory - loading from filesystem&#xA;docker.auth.find_config_file: Trying paths: ['C:\\Users\\flo-engineer-7\\.docker\\config.json', 'C:\\Users\\flo-engineer-7\\.dockercfg']&#xA;docker.auth.find_config_file: No config file found&#xA;docker.api.build._set_auth_headers: No auth config found&#xA;compose.cli.verbose_proxy.proxy_callable: docker build -&gt; &lt;generator object _stream_helper at 0x0000000003D75318&gt;&#xA;Step 1/8 : FROM microsoft/dotnet:2.0.0-sdk-nanoserver&#xA; ---&gt; b21d0dcac3da&#xA;Step 2/8 : ENTRYPOINT dotnet FloUserManagement.dll&#xA; ---&gt; Using cache&#xA; ---&gt; 045d2ee6931f&#xA;Step 3/8 : ARG source=.&#xA; ---&gt; Using cache&#xA; ---&gt; 730970d5a20d&#xA;Step 4/8 : WORKDIR /floUserManagement&#xA; ---&gt; Using cache&#xA; ---&gt; a49ab14bd6d1&#xA;Step 5/8 : ENV ASPNETCORE_URLS http://+:5001&#xA; ---&gt; Using cache&#xA; ---&gt; 53ac819650c8&#xA;Step 6/8 : EXPOSE 5001&#xA; ---&gt; Using cache&#xA; ---&gt; 1128b8571494&#xA;Step 7/8 : EXPOSE 8080&#xA; ---&gt; Using cache&#xA; ---&gt; bf898070e47c&#xA;Step 8/8 : COPY $source .&#xA; ---&gt; Using cache&#xA; ---&gt; 10dca54677f7&#xA;Successfully built 10dca54677f7&#xA;Successfully tagged dockercompose_flousermanagement:latest&#xA;compose.cli.verbose_proxy.proxy_callable: docker close &lt;- ()&#xA;compose.cli.verbose_proxy.proxy_callable: docker close -&gt; None&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers &lt;- (all=True, filters={u'label': [u'com.docker.compose.project=dockercompose', u'com.docker.compose.service=flousermanagement', u'com.docker.compose.oneoff=False']})&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers -&gt; (list with 0 items)&#xA;compose.parallel.feed_queue: Pending: set([&lt;Service: flousermanagement&gt;])&#xA;compose.parallel.feed_queue: Starting producer thread for &lt;Service: flousermanagement&gt;&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers &lt;- (all=True, filters={u'label': [u'com.docker.compose.project=dockercompose', u'com.docker.compose.service=flousermanagement', u'com.docker.compose.oneoff=False']})&#xA;compose.cli.verbose_proxy.proxy_callable: docker containers -&gt; (list with 0 items)&#xA;Creating dockercompose_flousermanagement_1 ...&#xA;compose.parallel.feed_queue: Pending: set([1])&#xA;compose.parallel.feed_queue: Starting producer thread for 1&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_image &lt;- (u'dockercompose_flousermanagement')&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_image -&gt; {u'Architecture': u'amd64',&#xA; u'Author': u'',&#xA; u'Comment': u'',&#xA; u'Config': {u'AttachStderr': False,&#xA;             u'AttachStdin': False,&#xA;             u'AttachStdout': False,&#xA;             u'Cmd': None,&#xA;             u'Domainname': u'',&#xA;             u'Entrypoint': [u'dotnet', u'FloUserManagement.dll'],&#xA;             u'Env': [u'DOTNET_SDK_VERSION=2.0.0',&#xA;...&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_image &lt;- (u'dockercompose_flousermanagement')&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_image -&gt; {u'Architecture': u'amd64',&#xA; u'Author': u'',&#xA; u'Comment': u'',&#xA; u'Config': {u'AttachStderr': False,&#xA;             u'AttachStdin': False,&#xA;             u'AttachStdout': False,&#xA;             u'Cmd': None,&#xA;             u'Domainname': u'',&#xA;             u'Entrypoint': [u'dotnet', u'FloUserManagement.dll'],&#xA;             u'Env': [u'DOTNET_SDK_VERSION=2.0.0',&#xA;...&#xA;compose.service.build_container_labels: Added config hash: fcbc2b05b3778b56210b9b7eaee882bd94227d1fdebf4936737d580c94631241&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_host_config &lt;- (device_read_iops=None, mem_swappiness=None, links=[], oom_score_adj=None, blkio_weight=None, cpu_count=None, cpuset_cpus=None, dns_search=None, pid_mode=None, init_path=None, log_config={'Type': u'', 'Config': {}}, cpu_quota=None, read_only=None, cpu_percent=None, device_read_bps=None, storage_opt=None, init=None, dns=None, volumes_from=[], ipc_mode=None, mem_reservation=None, security_opt=None, shm_size=None, device_write_iops=None, dns_opt=None, cgroup_parent=None, group_add=None, network_mode=u'dockercompose_default', blkio_weight_device=None, userns_mode=None, tmpfs=None, nano_cpus=None, port_bindings={'8080/tcp': ['8080'], '5001/tcp': ['5001']}, isolation=None, memswap_limit=None, restart_policy=None, volume_driver=None, devices=None, extra_hosts=None, binds=[u'C:\\Work\\FloAppCore\\FloUserManagement\\bin\\Debug\\netcoreapp2.0\\publish\\data:c:\\floUserManagement\\data:rw'], sysctls=None, pids_limit=None, device_write_bps=None, cap_add=None, mem_limit=None, cap_drop=None, privileged=False, ulimits=None, cpu_shares=None)&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_host_config -&gt; {'Binds': [u'C:\\Work\\FloAppCore\\FloUserManagement\\bin\\Debug\\netcoreapp2.0\\publish\\data:c:\\floUserManagement\\data:rw'],&#xA; 'Links': [],&#xA; 'LogConfig': {'Config': {}, 'Type': u''},&#xA; 'NetworkMode': u'dockercompose_default',&#xA; 'PortBindings': {'5001/tcp': [{'HostIp': '', 'HostPort': '5001'}],&#xA;                  '8080/tcp': [{'HostIp': '', 'HostPort': '8080'}]},&#xA; 'VolumesFrom': []}&#xA;compose.service.create_container: Creating dockercompose_flousermanagement_1&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_container &lt;- (name=u'dockercompose_flousermanagement_1', image=u'dockercompose_flousermanagement', labels={u'com.docker.compose.service': u'flousermanagement', u'com.docker.compose.project': u'dockercompose', u'com.docker.compose.config-hash': 'fcbc2b05b3778b56210b9b7eaee882bd94227d1fdebf4936737d580c94631241', u'com.docker.compose.version': u'1.16.1', u'com.docker.compose.oneoff': u'False', u'com.docker.compose.container-number': '1'}, host_config={'NetworkMode': u'dockercompose_default', 'Links': [], 'PortBindings': {'8080/tcp': [{'HostPort': '8080', 'HostIp': ''}], '5001/tcp': [{'HostPort': '5001', 'HostIp': ''}]}, 'Binds': [u'C:\\Work\\FloAppCore\\FloUserManagement\\bin\\Debug\\netcoreapp2.0\\publish\\data:c:\\floUserManagement\\data:rw'], 'LogConfig': {'Type': u'', 'Config': {}}, 'VolumesFrom': []}, environment=[], volumes={u'c:\\floUserManagement\\data': {}}, detach=True, ports=[(u'5001', u'tcp'), (u'8080', u'tcp')], networking_config={u'EndpointsConfig': {u'dockercompose_default': {u'IPAMConfig': {}, u'Aliases': ['flousermanagement']}}})&#xA;compose.cli.verbose_proxy.proxy_callable: docker create_container -&gt; {u'Id': u'09deadd3680a9376ab1771c3034be403b814eeb93adf642b14ee26d2e5a60f39',&#xA; u'Warnings': []}&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_container &lt;- (u'09deadd3680a9376ab1771c3034be403b814eeb93adf642b14ee26d2e5a60f39')&#xA;compose.cli.verbose_proxy.proxy_callable: docker inspect_container -&gt; {u'AppArmorProfile': u'',&#xA; u'Args': [u'FloUserManagement.dll'],&#xA; u'Config': {u'AttachStderr': False,&#xA;             u'AttachStdin': False,&#xA;             u'AttachStdout': False,&#xA;             u'Cmd': None,&#xA;             u'Domainname': u'',&#xA;             u'Entrypoint': [u'dotnet', u'FloUserManagement.dll'],&#xA;             u'Env': [u'DOTNET_SDK_VERSION=2.0.0',&#xA;                      u'DOTNET_SDK_DOWNLOAD_URL=https://dotnetcli.blob.core.windows.net/dotnet/Sdk/2.0.0/dotnet-sdk-2.0.0-win-x64.zip',&#xA;...&#xA;compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network &lt;- (u'09deadd3680a9376ab1771c3034be403b814eeb93adf642b14ee26d2e5a60f39', u'dockercompose_default')&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network -&gt; None&#xA;compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network &lt;- (u'09deadd3680a9376ab1771c3034be403b814eeb93adf642b14ee26d2e5a60f39', u'dockercompose_default', ipv4_address=None, link_local_ips=None, ipv6_address=None, links=[], aliases=['flousermanagement', u'09deadd3680a'])&#xA;compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network -&gt; None&#xA;compose.cli.verbose_proxy.proxy_callable: docker start &lt;- (u'09deadd3680a9376ab1771c3034be403b814eeb93adf642b14ee26d2e5a60f39')&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.cli.verbose_proxy.proxy_callable: docker start -&gt; None&#xA;Creating dockercompose_flousermanagement_1 ... done&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;compose.parallel.parallel_execute_iter: Finished processing: &lt;Service: flousermanagement&gt;&#xA;compose.parallel.feed_queue: Pending: set([])&#xA;</code></pre>&#xA;&#xA;<p>here are the docker files.</p>&#xA;&#xA;<p>Dockerfile ==></p>&#xA;&#xA;<pre><code>   FROM microsoft/dotnet:2.0.0-sdk-nanoserver&#xA;   ENTRYPOINT [""dotnet"", ""FloUserManagement.dll""]&#xA;   ARG source=.&#xA;   WORKDIR /floUserManagement&#xA;   ENV ASPNETCORE_URLS http://+:5001&#xA;   EXPOSE 5001&#xA;   EXPOSE 8080&#xA;   COPY $source .&#xA;</code></pre>&#xA;&#xA;<p>Dockercompose ==> </p>&#xA;&#xA;<pre><code>   version: '2.1'&#xA;   services:&#xA;          flousermanagement:&#xA;          build: &#xA;                context: ../FloUserManagement/bin/Debug/netcoreapp2.0/publish&#xA;                dockerfile: Dockerfile&#xA;                ports:&#xA;                     - ""5001:5001""&#xA;                     - ""8080:8080""&#xA;              volumes:&#xA;                   -../FloUserManagement/bin/Debug/netcoreapp2.0/publish/data:c:\floUserManagement\data   &#xA;</code></pre>&#xA;&#xA;<p>The docker-compose command is exiting the asp.net code without any error code. So how to debug this issue or what could be the possible solution out of this issue.&#xA;I have clearly defined the entrypoint in the dockerfile as ""ENTRYPOINT [""dotnet"", ""FloUserManagement.dll""]"" but it fails to execute the code/microservice inside the container.</p>&#xA;"
46581254,Microservices and service granularity,2017-10-05 08:37:47,<domain-driven-design><microservices>,3,110,4,1.0,2,"<p>I have never worked with microservices architecture before and there is something important that it is still not clear in what I am reading.</p>&#xA;&#xA;<p>In a microservice architecture a service is a single endpoint or a single module with several endpoints?</p>&#xA;&#xA;<p>Are the endpoints that are fine grained or the granularity is at a higher level? I thought at the beginning that the endpoints were fine grained and this is why there was the risk of making the API too chatty. </p>&#xA;&#xA;<p>I am now finding articles that say that in microservices architecture a service is associated to ""bounded context"". It seems to me that a bounded context needs more than a single endpoint in an API.</p>&#xA;"
46585082,Async communication between spring boot micro services,2017-10-05 12:00:04,<asynchronous><spring-boot><microservices><spring-rabbitmq>,1,662,4,1.0,2,"<p>I am new to spring boot and created 2 micro services.&#xA;They need to communicate with one other in synchronous and asynchronous way.&#xA;For synchronous communication, I can use the RestTemplate.&#xA;But how to do for asynchronous calling ?&#xA;my requirement for Asynchonous is:&#xA;lets say I am querying for something from one micro service. To fetch the queried data it will take sometime because of queried for large sum of data. &#xA;In this case, I need to save the request into some transaction table and return the response with transactionId and callBackAPI. After sometime if I call the callBackAPI with transactionId. Then I should be able to get the previously queried data.</p>&#xA;&#xA;<p>Please help me with this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
47398736,JHipster - How the gateway authenticate within the microservices?,2017-11-20 18:26:08,<java><jwt><jhipster><microservices><consul>,1,386,0,0.0,2,"<p>I'm doing a microservice project usign JHipster, i'm using Consul for Service Discovery and JWT for authentication, but here's my question:</p>&#xA;&#xA;<p>For other clients to access my microservices, they need to authenticate by passing a JSON with the credentials via POST to the gateway and finally get de id_token. But how the gateway authenticate within the services? The gateway do something similar to what we did when there's external client? Or there's something to do with de Service Discovery?</p>&#xA;&#xA;<p>I found this in the application-dev.yml:</p>&#xA;&#xA;<pre><code>security:&#xA;    authentication:&#xA;        jwt:&#xA;            secret: my-secret-token-to-change-in-production&#xA;</code></pre>&#xA;&#xA;<p>My guess is that the both microservice and the gateway share a common secret key, but i didn't found this key, only this section on the yml.</p>&#xA;"
47451612,How to architect the serverless framework and microservices on AWS Lambda,2017-11-23 09:15:42,<microservices><serverless>,1,229,0,0.0,2,<p>I have been studying microservices and serverless solutions and am playing with an angular frontend hosted on S3 and Lambda functions that talk to various DynamoDb tables via the API gateway on AWS.</p>&#xA;&#xA;<p>Every example and video I read/watch uses a simple CRUD microservices as part of a simple 'todo' application or similar. My problem is where does the business logic sit? If I'm building a complex application I don't want all my business logic in my frontend Angular application. Or do I? I could build an Application API which in turn calls CRUD microservices but that feels like a monolithic approach.</p>&#xA;&#xA;<p>I appreciate there may not be a definitive answer but can anybody advise a novice on best practice?</p>&#xA;
47380189,Microservices governance vs SOA,2017-11-19 18:04:35,<architecture><domain-driven-design><microservices><soa>,2,475,5,2.0,2,"<p>I was working in SOA goverened projects for the last 10 years and now we switch to a Microservices architecture ones.</p>&#xA;&#xA;<p>The good thing in SOA was that we had a Canonical Data Model where which was built with some effort indeed but at the end all systems ended up speaking the same 'language' and communication was centralized via a Service Bus.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QNcwq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QNcwq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In a Microservice architecture teams are independent and as there is no service bus wonder how all this intergration points will work.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/37mGm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/37mGm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>1) Is there a way to enfore some contracts like there is WSDL in SOA (for SOAP) ?</p>&#xA;&#xA;<p>2) If team developing service B is autonoumous and deploys a new service it has to keep the old version as well no ? In SOA this problem was solved that on the service bus we kept v1 and a we did a transformation to v2.It was trasparent for consumers that service B has a new version.</p>&#xA;&#xA;<p>3) What type of govenrnance you would put in place in case the number of microservices is quite high like in the below picture knowing the teams have to be as much as possible autonoumous ('agile')?</p>&#xA;&#xA;<p>I am not looking fot the best answer , I am interested in different opinions as there is no magic solution here.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/k2mB3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k2mB3.png"" alt=""enter image description here""></a></p>&#xA;"
45255905,Cqrs + microservices architecture : how to get data from another service,2017-07-22 14:56:15,<java><node.js><microservices><cqrs>,2,342,0,0.0,2,"<p>I'm playing around with setting up a microservices / cqrs architecture for a personal project, and there's one point I don't understand in the ""standard"" setup.</p>&#xA;&#xA;<p>By standard setup, I mean </p>&#xA;&#xA;<p><a href=""https://www.ibm.com/developerworks/cloud/library/cl-build-app-using-microservices-and-cqrs-trs/index.html"" rel=""nofollow noreferrer"">https://www.ibm.com/developerworks/cloud/library/cl-build-app-using-microservices-and-cqrs-trs/index.html</a></p>&#xA;&#xA;<p>Say I have an orders service and a pickup points service, and I have a command like ""send order summary email"".</p>&#xA;&#xA;<p>How should the orders service get the data about the pickup point (eg opening hours etc) that it needs to send the email ? I see 4 possibilities, but there are surely others.</p>&#xA;&#xA;<ol>&#xA;<li><p>The command goes directly to the orders service, and then the orders service queries the pickup points service to get the data.</p></li>&#xA;<li><p>The command goes to the pickup points service, and then pickup points service publishes a new event for orders service with the needed information attached.</p></li>&#xA;<li><p>The command goes directly to the orders service, and the orders service then queries the read-only client-facing database.</p></li>&#xA;<li><p>Merge the 2 services... given that they have no other shared context, this would be a pity...</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks !</p>&#xA;"
45225151,Zuul is unable to fetch microservices instance list from Eureka,2017-07-20 21:04:27,<microservices><netflix-eureka><netflix-zuul>,1,290,2,1.0,2,"<p>I am trying to configure Zuul with Eureka with following Zuul auto configuration (Spring Boot):</p>&#xA;&#xA;<pre><code>zuul.ignoredServices: '*'&#xA;zuul.routes.service1.path: /test/**&#xA;zuul.routes.service1.serviceId: CUSTOMER-SERVICE&#xA;zuul.routes.service1.stripPrefix: false&#xA;eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka&#xA;eureka.instance.non-secure-port-enabled=true&#xA;server.port=9090&#xA;</code></pre>&#xA;&#xA;<p>But while making call to CUSTOMER-SERVICE through Zuul getting following exception:</p>&#xA;&#xA;<pre><code>com.netflix.client.ClientException: Load balancer does not have available server for client: CUSTOMER-SERVICE&#xA;</code></pre>&#xA;&#xA;<p>I have checked the Eureka for CUSTOMER-SERVICE with web console, I found an instance of  CUSTOMER-SERVICE registered there correctly.</p>&#xA;&#xA;<p>Can any one help me to know what went wrong? </p>&#xA;"
45243781,Make build docker task more productive,2017-07-21 17:47:00,<docker><containers><dockerfile><microservices><docker-machine>,1,51,2,0.0,2,"<p>I'm beginner with docker and I created a image with my application (with connections with oracle + db2 + gateways, in nodejs). </p>&#xA;&#xA;<p>But I'm coding and for build it's take a longtime. Before I was using just node in my local machine, and I was running my project with nodemon. It was being very productive!</p>&#xA;&#xA;<p>I need something like that, for to transform my build task faster.</p>&#xA;"
45146319,Spring - Make microservice only accessible internally,2017-07-17 14:00:20,<spring><spring-security><microservices>,2,221,3,0.0,2,"<p>How can I setup a microservice which can only be called by other internal services. The microservice should not be accessible in public, because it has access to databases with secret information. I already tried to secure the microservice with spring security but in this case I got problems with the FeignClient concerning authorization.</p>&#xA;"
40333799,Abstracting away the persistence layer in GO,2016-10-30 21:27:59,<go><architecture><domain-driven-design><microservices>,1,460,0,1.0,2,"<p>So, I'm relatively new to the world of Go programming and was wondering what the community considers to be ""best practice"" when attempting to abstract away the persistence layer.  </p>&#xA;&#xA;<p>In DDD this is often handled through the introduction of Repositories which exposes a set of Agreggates to an Application layer.  </p>&#xA;&#xA;<p>My concern is that I've been overly ""conditioned"" into thinking about these problems from the perspective of Object Oriented design and would like to explore other programming paradigms.</p>&#xA;&#xA;<p>This will also be my first attempt at developing micro-services; which is part of the reason why I'd like to keep my design as simple as possible.</p>&#xA;"
40377076,Access to Microservices via Eureka Server,2016-11-02 10:01:34,<spring><spring-boot><microservices><netflix-eureka>,2,1976,1,1.0,2,"<p>can I access to microservice with someting like this:&#xA;Eureka Server: <a href=""http://localhost:8761/"" rel=""nofollow noreferrer"">http://localhost:8761/</a>&#xA;Microservice url: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a>&#xA;Call to Microservice to be something like: <a href=""http://localhost:8761/name-service/"" rel=""nofollow noreferrer"">http://localhost:8761/name-service/</a>&#xA;Is it posible?&#xA;When i open the eureka server the service is registered.</p>&#xA;&#xA;<p>eureka/application.properties:</p>&#xA;&#xA;<pre><code>server.port=8761&#xA;eureka.client.register-with-eureka=false&#xA;eureka.client.fetch-registry=false&#xA;logging.level.com.netflix.eureka=OFF&#xA;logging.level.com.netflix.discovery=OFF&#xA;</code></pre>&#xA;&#xA;<p>name-service/application.properties</p>&#xA;&#xA;<pre><code>spring.application.name=name-service&#xA;server.port=8080&#xA;</code></pre>&#xA;&#xA;<p>How can i achieve this?</p>&#xA;"
40485481,Front End Developer workflow for Service Fabric Web Apps,2016-11-08 11:15:26,<azure><microservices><azure-service-fabric>,1,396,7,2.0,2,"<p>I'm a front end developer about to join a project team working with Service Fabric to build a Web Front End to their microservice driven application.</p>&#xA;&#xA;<p>One of the problems I've been having in my own research is that when working with local Service Fabric Clusters, I have to redeploy my Application to test if something does or doesn't work in my Web App. This slows down developer velocity massively, as the process will only take longer and longer as other Back End services are added. I largely work with the Web App communicating to an API Gateway Service (GraphQL.NET). </p>&#xA;&#xA;<p>What I'd like to know is if there's a way to run a local Web Application out outside of a Service Fabric cluster, but still have it communicate to one. This would allow my front end developer tool chain to remain intact, and develop at a much faster pace with incremental building and live-reload tools.</p>&#xA;&#xA;<p>Of course, if anyone's come up with any better solution to the problem, I'd love to hear about it! ;)</p>&#xA;"
43568325,Sharing custom code between two NodeJS microservices,2017-04-23 07:03:23,<javascript><node.js><git><shared-libraries><microservices>,2,385,0,0.0,2,"<p>I am creating web app and micorservice for that app, and both need to have same DB model created with Sequelize. What is approach for handling this task with NodeJS?</p>&#xA;&#xA;<p>I am thinking about creating separate module of my DB models and save it in private git and add this private git to my web app and microservice as npm dependency.</p>&#xA;&#xA;<p>But I am wondering is it right approach or what is right way to separate shared private module between few microservices, in my case it is DB models?&#xA;Should I go with DRY or not?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
43532494,Use ehcache for application deployed via docker against the stateless rule,2017-04-21 01:37:26,<docker><spring-boot><ehcache><microservices><stateless>,3,333,1,0.0,2,"<p>I have an spring-boot application which I would like to deploy it into multiple docker instances and there is a load balance before the instances.&#xA;However, the application uses ehcache to cache some data from a database. It makes the application stateful.&#xA;So without session sticky, a same customer might hit different docker instances and see different results.&#xA;My question is if I can't apply session sticky in load balance, what is the best practice to deploy an app with cache feature via docker style and still comply the rule of should-be-stateless?</p>&#xA;"
43538070,How to manage state in microservices?,2017-04-21 08:49:10,<kubernetes><microservices>,1,464,4,0.0,2,"<p>First of all, this is a question regarding my thesis for school. I have done some research about this, it seems like a problem that hasn't been tackled yet (might not be that common).</p>&#xA;&#xA;<p>Before jumping right into the problem, I'll give a brief example of my use case.</p>&#xA;&#xA;<p>I have multiple namespaces containing microservices depending on a state X. To manage this the microservices are put in a namespace named after the state. (so namespaces state_A, state_B, ...)</p>&#xA;&#xA;<p>Important to know is that each microservice needs this state at startup of the service. It will download necessary files, ... according to the state. When launching it with state A version 1, it is very likely that the state gets updated every month. When this happens, it is important to let all the microservices that depend on state A upgrade whatever necessary (databases, in-memory state, ...).</p>&#xA;&#xA;<p>My current approach for this problem is simply using events, the microservices that need updates when the state changes can subscribe on the event and migrate/upgrade accordingly. The only problem I'm facing is that while the service is upgrading, it should still work. So somehow I should duplicate the service first, let the duplicate upgrade and when the upgrade is successful, shut down the original. Because of this the used orchestration service would have to be able to create duplicates (including duplicating the state).</p>&#xA;&#xA;<p>My question is, are there already solutions for my problem (and if yes, which ones)? I have looked into Netflix Conductor (which seemed promising with its workflows and events), Amazon SWF, Marathon and Kubernetes, but none of them covers my problem.</p>&#xA;&#xA;<p>Best of all the existing solution should not be bound to a specific platform (Azure, GCE, ...).</p>&#xA;"
43664192,Do we create difference projects when implementing micro services architecture in spring,2017-04-27 17:19:09,<java><spring><spring-mvc><spring-boot><microservices>,1,99,5,0.0,2,"<p>I am confused with microservice architecture. I am not able to understand how to implement the microservice architecture in spring. In spring we use <code>@RestController</code> for Rest API. Let's say we have two rest controller like below</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/user"")&#xA;public class UserService {&#xA;// this class will hanlder operations related to user&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/role"")&#xA;public class RoleService {&#xA;// this class will hanlder operations related to role&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Both rest controllers belong to one single project. Can we say our above structure is microservices? Or we have to create two projects one is <code>UserServiceProject</code> and another one is <code>RoleServiceProject</code>. In <code>UserServiceProject</code> we create Rest Controller for rest API of User operations. In <code>RoleServiceProject</code> we create Rest Controller for rest API of Role Operations. </p>&#xA;&#xA;<p>As microservices architecture says each service should be independently deployable. From this definition can we say that if we have 2 services we need to create two projects so that both projects can be independently deployable. </p>&#xA;&#xA;<p>Please also note both services share the same database and also there is a relationship between User and Role.</p>&#xA;"
43633659,What to use for microservices inter-communications .NET,2017-04-26 12:03:03,<.net><design-patterns><microservices>,1,875,11,0.0,2,"<p>Doing some research on splitting our monolith into micro-services and trying to understand/determine the best way for communications between services, or if I should even be communicating between services?</p>&#xA;&#xA;<p>Should each micro-service be a web service that only serves Http or should I be using a service bus to pass work requests around?</p>&#xA;"
41127782,Gradle Composite build ignores resolutionStrategy customization for multi projects,2016-12-13 18:07:11,<gradle><build.gradle><microservices><gradle-plugin>,1,463,0,1.0,2,"<p>I am trying to use <a href=""https://docs.gradle.org/current/userguide/composite_builds.html"" rel=""nofollow noreferrer"">Gradle Composite Builds</a> to build a multiple independant projects in my solution. Any plugin that overrides <code>resolutionStrategy</code> seems to be ignored when building from a Composite build.</p>&#xA;&#xA;<p><strong>Project Layout</strong></p>&#xA;&#xA;<pre><code>| master               &lt;&lt;Composite Build&gt;&gt;&#xA;| |\ -- settings.gradle&#xA;| |  -- build.gradle&#xA;| library1&#xA;| |\ -- settings.gradle&#xA;| |  -- build.gradle&#xA;| library2&#xA;| |\ -- settings.gradle&#xA;| |  -- build.gradle&#xA;| mulitProj             &lt;&lt; Multi Project&gt;&gt;&#xA;| |\ -- settings.gradle&#xA;| |  -- build.gradle&#xA;| - multiProjChild1&#xA;| | |\ -- build.gradle&#xA;| - multiProjChild2&#xA;| | |\ -- build.gradle&#xA;</code></pre>&#xA;&#xA;<p><strong>Composite Build (master):</strong></p>&#xA;&#xA;<pre><code>settings.gradle&#xA;===============&#xA;&#xA;includeBuild('../library1') {&#xA;  dependencySubstitution {&#xA;    substitute module('com.company:library1') with project (':')&#xA;   }&#xA;}&#xA;&#xA;includeBuild('../library2') {&#xA;  dependencySubstitution {&#xA;    substitute module('com.company:library2') with project (':')&#xA;   }&#xA;}&#xA;&#xA;includeBuild('../multiProj')&#xA;</code></pre>&#xA;&#xA;<p><strong>Builds (library1, library2, multiProject):</strong></p>&#xA;&#xA;<p>Note that all <code>build.gradle</code> files are using spring dependency management to share common library versions.</p>&#xA;&#xA;<pre><code>build.gradle&#xA;============&#xA;buildscript {&#xA;    repositories {&#xA;        mavenLocal()&#xA;        mavenCentral()&#xA;    }&#xA;&#xA;    dependencies {&#xA;        classpath(               &#xA;            'io.spring.gradle:dependency-management-plugin:0.6.1.RELEASE'&#xA;        )&#xA;    }&#xA;}&#xA;&#xA;allprojects {&#xA;  apply plugin: ""io.spring.dependency-management""&#xA;&#xA;  dependencyManagement {&#xA;    dependencies {&#xA;      dependency 'com.fasterxml.jackson.core:jackson-core:2.6.3'&#xA;      dependency 'com.fasterxml.jackson.core:jackson-annotations:2.6.3'&#xA;      ...&#xA;    }&#xA;  }&#xA;}&#xA;&#xA;...&#xA;&#xA;dependencies {&#xA;  compile(&#xA;    'com.fasterxml.jackson.core:jackson-core',&#xA;    'com.fasterxml.jackson.core:annotations',&#xA;&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>When I build any of the projects (library1, library2, multiProj) individually, they build fine.</p>&#xA;&#xA;<p>When I build the Composite build, <code>master</code>, dependency resolution customization provided by <code>dependencyManagement</code> is ignored for the multi-project. </p>&#xA;&#xA;<p>I have written my own Gradle Plugin to see if I could reproduce this. It turns out that the <code>Closure</code> in <code>resolutionStrategy.eachDependency</code> is never called when building a multi-Project build in a Composite Build.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<pre><code>/** Gradle plugin to resolve dependencies **/&#xA;class DependencyResolverPlugin implements Plugin&lt;Project&gt; {&#xA;&#xA;@Override&#xA;public void apply(Project project) {&#xA;&#xA;    project.configurations.all {&#xA;&#xA;        // Resolve managed dependency versions&#xA;        resolutionStrategy.eachDependency { DependencyResolveDetails details -&gt;&#xA;            //    !!&#xA;            //    This Closure is never called when this plugin is&#xA;            //    applied to a multi project build, which is built&#xA;            //    in a composite build&#xA;            //    !!&#xA;&#xA;            if (details.requested.version == null) {&#xA;               //Replace the version with the managed dependency version&#xA;            }&#xA;         }&#xA;    }&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I would like resolution strategy customization to continue to work when used with a Composite Build.</p>&#xA;"
41039545,How to manage common frontend components on microservices,2016-12-08 12:27:36,<architecture><frontend><single-page-application><microservices><orchestration>,1,438,3,2.0,2,"<p>How to manage frontend on microservices, especially when you have common components? I found a few solutions on the internet but all of them have some drawbacks and none of them is a good fit for us.</p>&#xA;&#xA;<p>Let me clearify my problem. We have over 5 groups of people working on different microservices in a large single project. And almost all of them has some common,shared components on frontend. And these components are huge as they are already a different project but totally shared. Now how to manage these shared components or should we duplicate them?</p>&#xA;&#xA;<p>First solution I found is to make those components shared and maintain from a single point like node packages and npm install when needed from different groups. But at this point the microservice approach is broken since everybody will be dependent to these components and no one will be able to maintain as soon as they need, not good. And very hard to maintain since in the future different groups may different needs from the component.</p>&#xA;&#xA;<p>Second is to duplicate the components according to each project and develop within the microservice group but this time it becomes very frankenstein and the common concepts that we should obey are hard to catch. It's a really enterprise project that all components should match in terms of behaivor and look to the other components reoccured in the project. </p>&#xA;&#xA;<p>So we need a frontend solution for microservices that should be suitable for an enterprise project which is needed to obey same rules(like font size,color,actions etc..) at different points as it is monolithly written, but maintainable by different groups at the same time.</p>&#xA;&#xA;<p>How can we balance that or can we?</p>&#xA;&#xA;<p>Thanks to @kayess: Shortly how to apply shared kernel on microservices as the teams will not be dependent to each other?</p>&#xA;"
41019199,Enabling CORS in Azure Service Fabric Web Api,2016-12-07 13:50:41,<angularjs><azure><asp.net-web-api><microservices><azure-service-fabric>,2,883,5,1.0,2,"<p>I have an angular app that sends an http request to my Service Fabric Web API (deployed on a Secure Service Fabric cluster) like so:</p>&#xA;&#xA;<pre><code>    $scope.request_headers = {&#xA;            ""Content-Type"": ""application/xml; charset=utf-8"",&#xA;            ""Access-Control-Allow-Origin"":""*""&#xA;        }&#xA;    $http({&#xA;                url: ""Service_Fabric_web_api_url"",&#xA;                method: ""GET"",&#xA;                headers:$scope.request_headers&#xA;            }).&#xA;            then(function (result) {&#xA;                console.log(result);&#xA;            });&#xA;</code></pre>&#xA;&#xA;<p>I've also enabled CORS globally in my web api startup class like so:</p>&#xA;&#xA;<pre><code>HttpConfiguration config = new HttpConfiguration();&#xA;var cors = new EnableCorsAttribute(""*"", ""*"", ""*"");&#xA;config.EnableCors(cors);&#xA;</code></pre>&#xA;&#xA;<p>When I run my angular app locally and try sending the http request, I still get this error:</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load Service_Fabric_web_api_url. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:xxxxx' is therefore not allowed access. The response had HTTP status code 500.&#xA;</code></pre>&#xA;&#xA;<p>I'm able to access my service directly from my browser with the same url.</p>&#xA;&#xA;<p>Also, the same http request works when I tried deploying my Web Api on an unsecure Service Fabric Cluster with the same lines added to the startup class to enable CORS. </p>&#xA;&#xA;<p>Why is this happening even though I've enabled CORS globally in my Web API and particularly when its on a secure cluster?</p>&#xA;"
45934621,api.ai Fullfillment POST requests doesn't append the action in the POST URL,2017-08-29 08:51:02,<microservices><api.ai>,1,44,0,0.0,2,"<p>Currently all the Fulfilment requests originating from api.ai are, POST requests to the base url configured in api.ai Fulfilment section. But to be able to have proper routing (microservice style) set-up on the server side it would be more worthwhile to append the action in the POST URL. </p>&#xA;&#xA;<p>For a substantially large project, there can be hundreds of fulfilment actions and managing all of them in single monolithic project is cumbersome. If the action comes in the URL, then we can configure and organise the actions into multiple cloudfunctions in case of firebase hosting / server side microservices.</p>&#xA;&#xA;<p>Edit:&#xA;As answered by matthewayne, I can use my own proxy set-up to route the requests to achieve the goal. But I don't want to introduce any additional delay into the request processing. Because I am expecting huge number of webhooks being fired. This would be a very easy implementation for Google api.ai team to incorporate that allows for a greater flexibility! Hence expecting an answer from google team!</p>&#xA;"
45928269,Consul in a Docker-based Microservices architecture,2017-08-28 22:38:38,<networking><amazon-ec2><architecture><microservices><consul>,1,99,0,0.0,2,"<p>We are working on switching over to micro services from a monolithic application.&#xA;Each microservice is going to be running on Docker through Amazon ECS.</p>&#xA;&#xA;<p>We've decided to use Consul for service discovery. We have 3 servers running on EC2 instances inside the VPC.</p>&#xA;&#xA;<p>My question is as follows:</p>&#xA;&#xA;<p>How/Where do I start the Consul agent for each micro service? Do I run another container on each instance (through Docker-Compose) with Consul inside? Or do I somehow run a Consul agent inside the already existing Docker container for each micro service?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/HuJp9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HuJp9.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Attached is a rough representation of my situation.&#xA;Should the Consul Client (in yellow) be in its own Docker Container or inside the Node.js container?</p>&#xA;"
45990451,How to silently refresh expired JWT token with OAuth2?,2017-08-31 21:38:12,<authentication><oauth-2.0><jwt><microservices><refresh-token>,1,963,0,0.0,2,"<p>We have decided to switch from Hazelcast shared session to Stateless JWT authentication/authorization with OAuth2 and found out a problem that doesnt fit our infrastructure described below.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pLIL5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pLIL5.png"" alt=""Current Hazelcast shared session""></a></p>&#xA;&#xA;<p>So we have multiple Self-contained systems (scs) that may be accessed by direct link i.e. <em>mysite.com/scs1</em> and <em>mysite.com/scs2</em>. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qVsxd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qVsxd.png"" alt=""Stateless JWT so called Session""></a></p>&#xA;&#xA;<p>Each scs has it's own UI and BackEnd, but ""session"" (implemented via Stateless JWT Authorization) has to be valid across multiple scs'es.</p>&#xA;&#xA;<p>OAuth2 Authorizaion Server is a dedicated server (UAA).&#xA;In the OAuth2 terminology, each scs is a Resource Server.</p>&#xA;&#xA;<p>Let's assume that user has logged into <strong>scs1</strong> (via UAA) and got JWT with TTL=10 minutes and RefreshToken with TTL=30 minutes. Then he leaves that tab in browser for 15 minutes. JWT expires, but the tab still contains the previous page from <strong>scs1</strong>. And user clicks a link on that page that follows to <em>mysite.com/scs3</em>.</p>&#xA;&#xA;<p><strong>scs3</strong> receives a request, checks JWT and finds out that it has expired. But we have a RefreshToken (still alive for 15 minutes) that may refresh JWT.</p>&#xA;&#xA;<p>Is it possible to return a response from <strong>scs3</strong> that would ask browser to go to UAA and silently refresh JWT ?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GicBn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GicBn.png"" alt=""JWT has expired""></a></p>&#xA;&#xA;<p>Maybe some kind of REDIRECT to /uaa/authorization with an ability to add RefreshToken Header?</p>&#xA;"
45886359,Golang Nats subscribe issue,2017-08-25 17:05:11,<go><message-queue><microservices><nats.io>,1,262,5,0.0,2,"<p>I work currently on a micro service architecture.&#xA;Before I insert NATS into my project I wanted to test some simple scenarios with it.</p>&#xA;&#xA;<p>In one scenario I have a simple publisher, which publishes 100.000 messages in a for loop over a basic Nats server running on localhost:4222.</p>&#xA;&#xA;<p>The big problem with it, is the subscriber. When he receive between 30.000 - 40.000 messages my whole main.go program and all other go routines just stops and do nothing. I can just quit with ctrl + c. But the Publisher is still keep sending the messages. When I open a new terminal and start a new instance of the subscriber all again works well, till the Subscriber receive about 30000 messages. And the worst thing is that there appears not even one error and also no logs on the server so I have no idea whats going on.</p>&#xA;&#xA;<p>After that I was trying replace the Subscribe-method with the QueueSubscribe-method and all works fine.</p>&#xA;&#xA;<p>What is the main difference between Subscribe and QueueSubscribe?</p>&#xA;&#xA;<p>Is NATS-Streaming a better opportunity? Or in which cases I should prefer Streaming and in which the standard NATS-Server </p>&#xA;&#xA;<p>Here is my code:</p>&#xA;&#xA;<p>Publisher:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;func main() {&#xA;    go createPublisher()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createPublisher() {&#xA;&#xA;    log.Println(""pub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    msg := make([]byte, 16)&#xA;&#xA;    for i := 0; i &lt; 100000; i++ {&#xA;        nc.Publish(""alenSub"", msg)&#xA;        if (i % 100) == 0 {&#xA;            fmt.Println(""i"", i)&#xA;        }&#xA;        time.Sleep(time.Millisecond)&#xA;    }&#xA;&#xA;    log.Println(""pub finish"")&#xA;&#xA;    nc.Flush()&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Subscriber:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;var received int64&#xA;&#xA;func main() {&#xA;    received = 0&#xA;&#xA;    go createSubscriber()&#xA;    go check()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createSubscriber() {&#xA;&#xA;    log.Println(""sub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    nc.Subscribe(""alenSub"", func(msg *nats.Msg) {&#xA;        received++&#xA;    })&#xA;    nc.Flush()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func check() {&#xA;    for {&#xA;        fmt.Println(""-----------------------"")&#xA;        fmt.Println(""still running"")&#xA;        fmt.Println(""received"", received)&#xA;        fmt.Println(""-----------------------"")&#xA;        time.Sleep(time.Second * 2)&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
45637090,How to change backend technology iteratively?,2017-08-11 14:00:44,<node.js><grails><upgrade><microservices>,2,59,0,0.0,2,"<p><strong>Background</strong></p>&#xA;&#xA;<p>Our backend is currently written in <strong>Grails</strong>. We would like to change the backend to <strong>NodeJs</strong>. We would like to execute the change in small iterations. We deploy everything on <strong>AWS</strong>.</p>&#xA;&#xA;<p><strong>Question</strong></p>&#xA;&#xA;<p>How to change the technology from Grails to NodeJs iteratively?</p>&#xA;&#xA;<p><strong>My opinion</strong></p>&#xA;&#xA;<p>Although we don't use Microservice Architecture (and none of us has any experience with it) I personally would:</p>&#xA;&#xA;<ol>&#xA;<li>build a NodeJs server before our Grails server (something like a <a href=""https://www.quora.com/What-is-an-API-gateway"" rel=""nofollow noreferrer"">Gateway API</a> maybe?)</li>&#xA;<li>at first the NodeJs would just pass requests/responses to/from Grails</li>&#xA;<li>then we would move other functionality from Grails (request logging, validations, ...) until we moved everything needed. (Maybe we keep something on Grails but most of the logic should end up on NodeJs.)</li>&#xA;</ol>&#xA;"
45779616,How to simulate join concept using Micro service architecture,2017-08-20 07:32:54,<sql><database><microservices>,2,93,1,0.0,2,"<p>I'm new at micro service architecture,&#xA;for instance we have two separate services in isolate machines and two sql databases,<br>&#xA;Location.Service has a db like below</p>&#xA;&#xA;<pre><code>Locations:&#xA;[&#xA;{Id: key, Name: string}&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Product.Service has a db like below</p>&#xA;&#xA;<pre><code>Products:&#xA;[&#xA;{Id: key, Name: string, LocationId: key}&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>these two services can work beside together properly using event based message protocol like AMQP and everything sound really nice.&#xA;but I a have problem with listing products in UI like this</p>&#xA;&#xA;<pre><code>ProductId(ok), ProductName(ok), ProductLocationId(ok), ProductLocationName(???)&#xA;</code></pre>&#xA;&#xA;<p>How could I have a solution for listing products with their location Name ?&#xA;in simple monolith application, we could easily have join between these tables but problem raises on multiple databases ?<br>&#xA;<strong>Solution1:</strong> query should has a nested for having locationName for example like this in ORM tools</p>&#xA;&#xA;<pre><code>var products = productService.select(p =&gt; new ProductDto{&#xA;ProductId= p.Id,&#xA;ProductName= p.Name,&#xA;LocationId= p.LocationId,&#xA;LocationName= locationService.getNameById(p.LocationId)&#xA;}).ToList(); &#xA;</code></pre>&#xA;&#xA;<p>may be this way is not reasonable<br>&#xA;<strong>Solution2:</strong> changing the db design for ProductService like this</p>&#xA;&#xA;<pre><code>Products&#xA;[&#xA;{Id: key, Name: string, LocationId: key, LocationName: string} &#xA;] &#xA;</code></pre>&#xA;&#xA;<p>in this way I should update all products location name(using event message) if the name of location using locationService has been changed&#xA;so, I think this way should raise some confusing in project's structure&#xA;<br>&#xA;<strong>Solution3:</strong> these two services should be in the same service!&#xA;so in agile projects, we can't estimate future so we had to come to all services to one service that obviously is not recommended!&#xA;<br><br>&#xA;<strong>What is the best idea for solving this issue ?</strong></p>&#xA;"
24787801,Spring Boot Environment-specific configurations,2014-07-16 18:10:58,<spring-mvc><jpa><spring-boot><environment><microservices>,2,8119,0,2.0,3,"<p>I have a spring boot application that uses the <strong>actuator, auto-configuration and JPA</strong>. I want to be able to use an in-memory DB in my <strong>test</strong> profile, a MySQL DB configuration during <strong>development</strong> and a separate <strong>production</strong> DB configuration when the app is deployed in production. Presumably from the java command line I should be able to specify the environment and the right configuration file or config block in <strong>application.properties</strong> (or .yml) will be picked up.</p>&#xA;&#xA;<p>I have not found a good post with example describing how to do this switching so I thought I'd ask if anyone has a good example. My main aim is to pre-define the <code>spring.datasource</code> and <code>spring.jpa</code> properties at build time and then at run-time switch the app config per environment ""dynamically"" using the java command line argument. Secondary goal would be to do the same with the <code>management</code> configurations, etc.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
50700178,Should API gateway be responsible for authorisation?,2018-06-05 12:32:36,<authentication><architecture><authorization><microservices><api-gateway>,1,100,0,1.0,3,"<p>Currently I have a monolith application with Java/Spring Boot the following endpoints:</p>&#xA;&#xA;<ul>&#xA;<li><code>/login</code></li>&#xA;<li><code>/logout</code></li>&#xA;<li><code>/some-resource</code></li>&#xA;</ul>&#xA;&#xA;<p>To access <code>some-resource</code>, the flow is following:</p>&#xA;&#xA;<ol>&#xA;<li>The user makes a <code>POST</code> request to <code>/login</code> endpoint. If the credentials are correct, a JWT token is returned in header, otherwise a 401.</li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<p>Now I want to split the monolith into 2 services: ""AuthServer"" and ""SomeResourceServer"". There will be an API gateway on the top. I am thinking about 2 possible ways to handle authorisation</p>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 1</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway calls the ""AuthServer"" to validate the JWT token. If the token is valid, the API gateway calls ""SomeResourceServer"" and returns the results. Otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 2</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway simply forwards the request to ""SomeResourceServer"". Then ""SomeResourceServer"" calls ""AuthServer"" to validate the JWT token. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p>In Option 1 the API gateway is responsible to handle authorisation (communicate with ""AuthServer""), in option 2 the communication is done between the servers. So which option is more correct? Are there any good/bad practices? Or maybe another way/option?</p>&#xA;"
27857790,Best practice for redirecting between docker containers,2015-01-09 09:47:35,<redirect><docker><reverse-proxy><boot2docker><microservices>,1,964,4,0.0,3,"<p>Given I have multiple web applications running in docker containers, I want to be able to let the user be redirected from on service to another service in his browser. I wonder how to achieve this - especially if I want my applications to be portable from one docker host to a different host. </p>&#xA;&#xA;<p>Let's say we have a ServiceA which redirects the user to ServiceB. So we have a relationship </p>&#xA;&#xA;<p><code>ServiceA --&gt; ServiceB</code></p>&#xA;&#xA;<p>One approach would be to statically assign ports and hostnames and set them as environment vars to my web services - which I would not prefer because I don't want to care about which service runs on which port.</p>&#xA;&#xA;<p>A second approach would be to have a proxy like nginx and link the services and use the proxy host and port. But this would require to change the proxy configuration when moving a service to a different host.</p>&#xA;&#xA;<p>The third approach that comes to mind, is to use etcd and ambassadors to register and resolve services. So ServiceA would use a ServiceB-Ambassador which looks up ServiceB in etcd. This results in many docker containers just to connect between services.</p>&#xA;&#xA;<p>Which way would you prefer? Or are there different approaches?</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>The real problem is to inject the uri of ServiceB into ServiceA, so I can launch my ServiceA with an argument like <code>-DserviceB.uri=&lt;serviceUri&gt;</code>, so that serviceA can build the correct redirect header.</p>&#xA;"
33556707,Dynamic Scalable and adaptive architecture,2015-11-05 23:21:28,<docker><zeromq><microservices><consul>,2,434,0,1.0,3,"<p>I am a PhD student in Cloud Computing, I plan to use the microservices based architecture with consul and zeromq for my research project. I had few questions that I am finding hard to understand. Can someone help me out in sharing their experience.</p>&#xA;&#xA;<ol>&#xA;<li>We have microservices based on dockers, We have zeromq and we have consul. Can you mention how we could combine all the three together to have a dynamic adaptive environment? </li>&#xA;</ol>&#xA;&#xA;<p>Though I understand as to what zeromq, docker and consul is individually, I am still unable to get a clear picture of how all of them function as a whole.We have docker containers having microservices running inside them on a host. We use zeromq for transport (Pub-sub/pipeline) of messages between docker containers. The containers may be running on the same host/datacenter or on different hosts/datacenters. We then use consul for service discovery.Is my understanding correct here? </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>How does the architecture dynamically scale up/down according to workload? </li>&#xA;</ol>&#xA;&#xA;<p>Say, I have a situation where I need more worker nodes for a particular computation for sometime. Who spins up more number of worker nodes. Which component determines/takes this decision? </p>&#xA;&#xA;<p>Is there a scheduling component? If so, can someone briefly explain how it happens or which component performs that function?</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>So, what is the major role of consul? Is it used just for service discovery?Can it be used for configurations as well. If so, whats its limitation? </li>&#xA;</ol>&#xA;&#xA;<p>I see that even zeromq has service discovery mechanisms, so why do we require consul? </p>&#xA;&#xA;<ol start=""4"">&#xA;<li>How does a failure of a node information gets propagated in the architecture? Which component is responsible? Is it just consul ? Or zeroMq also?</li>&#xA;</ol>&#xA;&#xA;<p>Please advice.</p>&#xA;"
33478131,Centralised configuration of docker-compose services,2015-11-02 12:57:09,<database><docker><config><docker-compose><microservices>,1,87,6,2.0,3,"<p>Imagine a non-trivial <a href=""https://www.docker.com/docker-compose"" rel=""nofollow"">docker compose</a> app, with nginx in front of a webapp, and a few linked data stores:</p>&#xA;&#xA;<pre class=""lang-css prettyprint-override""><code>web:&#xA;  build: my-django-app&#xA;  volumes:&#xA;    - .:/code&#xA;  ports:&#xA;    - ""8000:8000""&#xA;  links:&#xA;    - redis&#xA;    - mysql&#xA;    - mongodb&#xA;nginx:&#xA;  image: nginx&#xA;  links:&#xA;    - web&#xA;redis:&#xA;  image: redis&#xA;  expose:&#xA;    - ""6379""&#xA;mysql:&#xA;  image: mysql&#xA;  volumes:&#xA;    - /var/lib/mysql&#xA;  environment:&#xA;    - MYSQL_ALLOW_EMPTY_PASSWORD=yes&#xA;    - MYSQL_DATABASE=myproject&#xA;mongodb:&#xA;  image: mongo&#xA;</code></pre>&#xA;&#xA;<p>The databases are pretty easy to configure (for now), the containers expose pretty nice environmental variables to control them (see the <code>mysql</code> container), but what of <code>nginx</code>? We'll need to template a vhost file for that, right?</p>&#xA;&#xA;<p>I don't want to roll my own image, that'll need rebuilding for each changed config, from different <strong>devs</strong>' setups, to <strong>test</strong>, through <strong>staging</strong> and <strong>production</strong>. And what if we want to, in a lightweight manner, do <strong>A/B testing</strong> by flipping a config option? </p>&#xA;&#xA;<p>Some <strong>centralised config management</strong> is needed here, maybe something controlled by docker-compose that can write out config files to a shared volume?</p>&#xA;&#xA;<p>This will only get more important as new services are added (imagine a microservice cloud, rather than, as in this example, a monolithic web app)</p>&#xA;&#xA;<p><strong>What is the correct way to manage configuration in a docker-compose project?</strong></p>&#xA;"
49875284,Logback to Elasticsearch through yaml or properties,2018-04-17 10:07:11,<spring><elasticsearch><logging><microservices><logback>,1,187,3,0.0,3,"<p>I have many spring based microservice project where I used Logback to Elasticsearch for saving all logs to Elastic search index. I have configured using xml based on some tutorials I got. The configuration is based on xml like as shown below. Instead of xml how can we configure Logback to Elasticsearch using yaml or key value property files.</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;configuration&gt;&#xA;    &lt;springProperty scope=""context"" name=""microserviceName""&#xA;        source=""spring.application.name"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""profile""&#xA;        source=""spring.profiles.active"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESHost""&#xA;        source=""logging.esHost"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESPort""&#xA;        source=""logging.esPort"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESLoggingLevel""&#xA;        source=""logging.esLoggingLevel"" /&gt;  &#xA;    &lt;springProperty scope=""context"" name=""consoleLoggingLevel""&#xA;        source=""logging.consoleLoggingLevel"" /&gt; &#xA;&#xA;    &lt;appender name=""ELASTIC"" class=""com.internetitem.logback.elasticsearch.ElasticsearchAppender""&gt;&#xA;        &lt;url&gt;http://${myESHost}:${myESPort}/_bulk&lt;/url&gt;&#xA;        &lt;index&gt;logs-%date{yyyy-MM-dd}&lt;/index&gt;&#xA;        &lt;type&gt;tester&lt;/type&gt;&#xA;        &lt;loggerName&gt;es-logger&lt;/loggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;errorLoggerName&gt;es-error-logger&lt;/errorLoggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;connectTimeout&gt;30000&lt;/connectTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;errorsToStderr&gt;false&lt;/errorsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeCallerData&gt;false&lt;/includeCallerData&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;logsToStderr&gt;false&lt;/logsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxQueueSize&gt;104857600&lt;/maxQueueSize&gt; &lt;!-- optional (default 104857600) --&gt;&#xA;        &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;!-- optional (default 3) --&gt;&#xA;        &lt;readTimeout&gt;30000&lt;/readTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;sleepTime&gt;250&lt;/sleepTime&gt; &lt;!-- optional (in ms, default 250) --&gt;&#xA;        &lt;rawJsonMessage&gt;false&lt;/rawJsonMessage&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeMdc&gt;false&lt;/includeMdc&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxMessageSize&gt;100&lt;/maxMessageSize&gt; &lt;!-- optional (default -1 --&gt;&#xA;        &lt;authentication class=""com.internetitem.logback.elasticsearch.config.BasicAuthentication"" /&gt; &lt;!-- optional --&gt;&#xA;        &lt;properties&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;host&lt;/name&gt;&#xA;                &lt;value&gt;${HOSTNAME}&lt;/value&gt;&#xA;                &lt;allowEmpty&gt;false&lt;/allowEmpty&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;severity&lt;/name&gt;&#xA;                &lt;value&gt;%level&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;thread&lt;/name&gt;&#xA;                &lt;value&gt;%thread&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;stacktrace&lt;/name&gt;&#xA;                &lt;value&gt;%ex&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;logger&lt;/name&gt;&#xA;                &lt;value&gt;%logger&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;        &lt;/properties&gt;&#xA;        &lt;headers&gt;&#xA;            &lt;header&gt;&#xA;                &lt;name&gt;Content-Type&lt;/name&gt;&#xA;                &lt;value&gt;text/plain&lt;/value&gt;&#xA;            &lt;/header&gt;&#xA;        &lt;/headers&gt;&#xA;    &lt;/appender&gt;&#xA;&#xA;    &lt;root level=""info""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;        &lt;appender-ref ref=""ELASTIC"" /&gt;&#xA;    &lt;/root&gt;&#xA;&#xA;    &lt;logger name=""es-error-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;    &lt;logger name=""es-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender name=""ES_FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;&#xA;            &lt;!-- ... --&gt;&#xA;            &lt;encoder&gt;&#xA;                &lt;pattern&gt;%msg&lt;/pattern&gt; &lt;!-- This pattern is important, otherwise it won't be the raw Elasticsearch format anyomre --&gt;&#xA;            &lt;/encoder&gt;&#xA;        &lt;/appender&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;"
49836268,How to deal with authentication in a micro-services architecture,2018-04-14 21:14:47,<microservices><grpc>,2,172,4,3.0,3,"<p>I am currently reading a lot about microservices but still, I don't understand some parts. I made the following draw:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GkgRC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GkgRC.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each microservice has 2 accesses:</p>&#xA;&#xA;<ul>&#xA;<li>REST: For http uses</li>&#xA;<li>gRPC: For intra/background communication/exchanges</li>&#xA;</ul>&#xA;&#xA;<p>If I want to login I can just send an Http Request to my Authentication service. But what about if I want to access the Stuff service that needs you to be already connected?</p>&#xA;&#xA;<p>Let say that the user wants to display the stuff available in the database STUFF, the service Stuff will first check if the ""token"" of the connected user is right, by exchanging with the Authentication service, and then return the stuff or a ""login requires request"".</p>&#xA;&#xA;<p>So the thing I don't understand is, if each services that needs a client already connected needs to exchange with Authentication, then it will create a huge internet traffic in order to check each user request.. So I though about make one Authentication service per service, but since I should have only one Database, then it's the database that will slow the traffic?</p>&#xA;&#xA;<p>Also, if I understand, each micro service should be on separate servers, not the same one?</p>&#xA;&#xA;<p>I hope I am clear, don't hesitate to ask for more details !</p>&#xA;&#xA;<p>Thanks in advance :)</p>&#xA;&#xA;<p>Max</p>&#xA;&#xA;<h1>Edit 1</h1>&#xA;&#xA;<p><strong>Based on @notionquest's answer:</strong></p>&#xA;&#xA;<p>So it should more looks like that right?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pdOdR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pdOdR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Also, based on Peter's comment, each service can implement its own middleware (JWT as mentioned) so the API Gateway is only a ""pass-through"". However, I don't feel like it could be a nice for me since each service make a token check for each internal exchange, doesn't it?</p>&#xA;&#xA;<p>For the stuff, it's easy since it checks only 1 time the token. Now, let's say that, after the user got the stuff, he choose one and wanna buy it. Then the ""Buying service"" will call the stuff service in order the verify the price of the item, but... It will have to check the user token since the stuff is a ""on authenticated access"", so it means that ""Buying"" service and ""Stuff"" service both check the token, which add an extra check.</p>&#xA;&#xA;<p>I though about an internal guaranteed access between services but is it worth it?</p>&#xA;&#xA;<p>Also, maybe you said to implement the middleware for each service since they have a REST access, but the API Gateway would just destroy the idea of having REST access</p>&#xA;"
31764926,Microservices API calls and dependency design,2015-08-01 18:35:43,<design><dependencies><microservices>,2,359,0,2.0,3,"<p>Are there any best practice on designing microservices service regarding API dependency (APIs that the service is calling to)?</p>&#xA;&#xA;<p>For example if I have a ""Order Management"" (OM) service, obviously it will need to call ""User Management"" (UM) service since it will need to query user info (shipping address, email, etc) many times. If I let my OM calls UM all the time when it needs user info this will create lots of dependency on UM service. </p>&#xA;&#xA;<p>As far as I understand services are supposed to be autonomous and as decoupled as possible - but now I got a OM service that will go down everytime UM service go down.</p>&#xA;&#xA;<p>Upon searching on Google I found 3 alternatives:</p>&#xA;&#xA;<ol>&#xA;<li>Use the event-based programming to replciate user data as soon as user data is created in UM module so it is always replicated into a table inside OM</li>&#xA;<li>Use database's replciation mechanism to replicate data from UM onto OM database</li>&#xA;<li>Copy user data into order object as nested json to eliminate dependency for order query and update (but I suppose initial order creation will still need to call UM)</li>&#xA;</ol>&#xA;&#xA;<p>Are there any best practices on the challenge here or are there any rules of thumb of deciding which design approach to take?</p>&#xA;"
48824086,Keycloak: AnonymousAuthenticationToken cannot be cast to KeycloakAuthenticationToken,2018-02-16 09:53:19,<java><spring><spring-security><microservices><keycloak>,6,1064,0,0.0,3,"<p>I am developing a microservice infrastructure based on Spring Cloud. I want to secure the application with Keycloak, which is basically working fine if the user is authenticated. </p>&#xA;&#xA;<p>If the user is not authenticated Keycloak throws the folling error:</p>&#xA;&#xA;<pre><code>java.lang.ClassCastException: org.springframework.security.authentication.AnonymousAuthenticationToken cannot be cast to org.keycloak.adapters.springsecurity.token.KeycloakAuthenticationToken&#xA;at org.keycloak.adapters.springsecurity.facade.SimpleHttpFacade.getSecurityContext(SimpleHttpFacade.java:63) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.corsRequest(AuthenticatedActionsHandler.java:102) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.handledRequest(AuthenticatedActionsHandler.java:54) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:78) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakSecurityContextRequestFilter.doFilter(KeycloakSecurityContextRequestFilter.java:79) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:82) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakPreAuthActionsFilter.doFilter(KeycloakPreAuthActionsFilter.java:84) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractAuthenticatedActionsValve.invoke(AbstractAuthenticatedActionsValve.java:67) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:595) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractKeycloakAuthenticatorValve.invoke(AbstractKeycloakAuthenticatorValve.java:181) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;</code></pre>&#xA;&#xA;<p>The security config looks as follows:</p>&#xA;&#xA;<pre><code>@KeycloakConfiguration&#xA;public class SecurityConfig extends KeycloakWebSecurityConfigurerAdapter&#xA;{&#xA;    private final KeycloakClientRequestFactory keycloakClientRequestFactory;&#xA;&#xA;    public SecurityConfig(KeycloakClientRequestFactory keycloakClientRequestFactory)&#xA;    {&#xA;        this.keycloakClientRequestFactory = keycloakClientRequestFactory;&#xA;    }&#xA;&#xA;    /**&#xA;   * define the actual constraints of the app.&#xA;   * @param http&#xA;   * @throws Exception&#xA;   */&#xA;  @Override&#xA;  protected void configure(HttpSecurity http) throws Exception&#xA;  {&#xA;      super.configure(http);&#xA;      http&#xA;      .cors()&#xA;      .and()&#xA;      .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)&#xA;      .sessionAuthenticationStrategy(sessionAuthenticationStrategy())&#xA;      .and()&#xA;      .authorizeRequests()&#xA;          .antMatchers(""/*"").hasRole(""user"")&#xA;          .anyRequest().permitAll();&#xA;  }&#xA;&#xA;    /**&#xA;     * define the session auth strategy so that no session is created&#xA;     * &#xA;     * @return concrete implementation of session authentication strategy&#xA;     */&#xA;    @Bean&#xA;    @Override&#xA;    protected SessionAuthenticationStrategy sessionAuthenticationStrategy()&#xA;    {&#xA;        return new NullAuthenticatedSessionStrategy();&#xA;    }&#xA;&#xA;    /**&#xA;     * registers the Keycloakauthenticationprovider in spring context and sets its&#xA;     * mapping strategy for roles/authorities (mapping to spring seccurities'&#xA;     * default ROLE_... for authorities ).&#xA;     * &#xA;     * @param auth&#xA;     *          SecurityBuilder to build authentications and add details like&#xA;     *          authproviders etc.&#xA;     * @throws Exception&#xA;     */&#xA;    @Autowired&#xA;    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception&#xA;    {&#xA;        KeycloakAuthenticationProvider keyCloakAuthProvider = keycloakAuthenticationProvider();&#xA;        keyCloakAuthProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper());&#xA;&#xA;        auth.authenticationProvider(keyCloakAuthProvider);&#xA;    }&#xA;&#xA;    /**&#xA;     * Sets keycloaks config resolver to use springs application.properties&#xA;     * instead of keycloak.json (which is standard)&#xA;     * &#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public KeycloakConfigResolver KeyCloakConfigResolver()&#xA;    {&#xA;        return new KeycloakSpringBootConfigResolver();&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakAuthenticationProcessingFilterRegistrationBean(&#xA;            KeycloakAuthenticationProcessingFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakPreAuthActionsFilterRegistrationBean(KeycloakPreAuthActionsFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions would be much apprechiated.</p>&#xA;&#xA;<p>Kind regards&#xA;Blacky</p>&#xA;"
48873507,Caching in a Microservices architecture,2018-02-19 20:14:02,<microservices>,1,589,0,0.0,3,"<p>In the <strong>API Gateway</strong> a caching feature can be implemented to reduce access time and bandwidth usage.<br>&#xA;What kind of data are cached in the gateway? <br>&#xA;In a <em>micro-services architecture</em>, does a gateway cache the discovered services descriptions ? if so, how he maintains the consistency of his cache?</p>&#xA;"
48963386,"Microservices, REST, event sourcing and data consistency",2018-02-24 13:29:08,<rest><apache-kafka><domain-driven-design><microservices><event-sourcing>,1,246,1,0.0,3,"<p>I'm planning a model for microservices using event sourcing. To achieve a high scalability and high throughput handling capacity, I'll use Kafka as a message broker for the microservices.</p>&#xA;&#xA;<p>At this point, I have questions about the implementation of the model to be able to have the benefits of Kafka topic and partition. There are some requirements that my model needs to fit:</p>&#xA;&#xA;<ol>&#xA;<li>Microservices must ingest data from the message broker (POST/PATCH/PUT/DELETE)</li>&#xA;<li>Data consistency is mandatory, if entity A needs previous existence of entity B, then must exists only records of entity A that points to valid records of entity B</li>&#xA;<li>The microservices can't couple their domains (refering to DDD)</li>&#xA;<li>The system must handle high thrgoughput of read and writes operations</li>&#xA;</ol>&#xA;&#xA;<p>Well, with this requirements in mind, I've endend up with a model that:</p>&#xA;&#xA;<ol>&#xA;<li>Use an Elasticsearch database that have the current valid state</li>&#xA;<li>All write requests are received by a ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Validate the request and the new state that is requested</li>&#xA;<li>Produce a write operation in the message broker</li>&#xA;<li>Receives state change events from the message broker</li>&#xA;<li>Responds to requester with the new state changed</li>&#xA;</ol></li>&#xA;<li>All write operations are consumed by a ""Microservice Processor"" that:&#xA;&#xA;<ol>&#xA;<li>Handles all the business logic and data denormalization</li>&#xA;<li>Updates the state in the Elasticsearch database</li>&#xA;<li>Produce a state change event in the message broker</li>&#xA;</ol></li>&#xA;<li>All read requests are handled by the ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Searchs at the Elasticsearch database for the requested resource's records</li>&#xA;<li>Responds to the requester with the results</li>&#xA;</ol></li>&#xA;</ol>&#xA;&#xA;<p>My questions:</p>&#xA;&#xA;<ol>&#xA;<li>This model does some coupling of the domains? The Gateway is validating subresources ID's to ensure data consistency in one Elasticsearch database (the case of A pointing to B).</li>&#xA;<li>I don't know if this model fits reports requests, there are some complex reports that process a lot of data with input parameters from the user and from his point of view, the operation must be ""synchronous"" (request/response REST)</li>&#xA;<li>Is the validation of requests/new state a part of the business logic (related to DDD)? If so, my model is incorret to separate them into two microservices?</li>&#xA;</ol>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>My new proposal for my client:</p>&#xA;&#xA;<ol>&#xA;<li>Instead of having a gateway acting as a part of the microservice, let gateway only for: routing (microservice registry), balancing and auth stuffs (calling a dedicated microservice for authentication/authorization)</li>&#xA;<li>The microservices hold their own data/database, consistency is ensured by event sourcing architeture</li>&#xA;<li>Reports: if it's about one domain, can be a resource at the microservice that holds the data, if more than one domain is required, another microservice will provide the report</li>&#xA;</ol>&#xA;"
48921774,Microservices unsuitable for business domain?,2018-02-22 07:28:39,<database><domain-driven-design><microservices><distributed-computing><soa>,2,80,2,1.0,3,"<p>The business domain has five high-level bounded contexts</p>&#xA;&#xA;<ul>&#xA;<li>Customers</li>&#xA;<li>Applications</li>&#xA;<li>Documents</li>&#xA;<li>Decisions</li>&#xA;<li>Preforms</li>&#xA;</ul>&#xA;&#xA;<p>Further, these bounded contexts has sub-contexts like ordering and delivery of the documents. Despite the project of consisting ten of thousands of classes and dozens of EJB's, most of the business logic resides in relational database views and triggers for a reason: A lot of joins, unions and constraints involved in all business transactions. In other words, there is complex web of dependencies and constraints between the bounded contexts, which restricts the state transfers. In layman terms: the business rules are very complicated.</p>&#xA;&#xA;<p>Now, if I were to split this monolith to database per service microservices architecture, bounded contexts being the suggested service boundaries, I will have to implement all the business logic with explicit API calls. I would end up with hundreds of API's implementing all these stupid little business rules. As the performance is main factor (we use a lot of effort to optimize the SQL as it is now), this is out of the question. Secondly, segregated API's would probably be nightmare to maintain in this web of ever evolving business rules, where as database triggers actually support the high cohesion and DRY mentality, enforcing the business rules transparently.</p>&#xA;&#xA;<p>I came up with a conclusion microservice architecture being unsuitable for this type of document management system. Am I correct, or approaching the idea from wrong angle?</p>&#xA;"
33680497,What is a Java MicroService,2015-11-12 20:16:11,<java><microservices>,2,1730,3,3.0,3,"<p>I been searching on the web but im a little confused on what exactly is a java microservice. I mean i know what a web service is, and im told that a microservice is the following per wiki:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In computing, microservices is a software architecture style in which complex applications are composed of small, independent processes communicating with each other using language-agnostic APIs.</p>&#xA;</blockquote>&#xA;&#xA;<p>and the properties of a microservice are:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Properties of microservices architecture:</p>&#xA;  &#xA;  <p>It's a kind of architecture The services are easy to replace Services&#xA;  are organized around capabilities, e.g. user interface front-end,&#xA;  recommendation, logistics, billing, etc Services can be implemented&#xA;  using different programming languages, databases, hardware and&#xA;  software environment, depending on what fits best Architectures are&#xA;  symmetrical rather than hierarchical (producer - consumer)</p>&#xA;</blockquote>&#xA;&#xA;<p>but i need a concrete java example to understand how i can make a microservice.  Does anyone have a example you could provide ?</p>&#xA;"
36844842,Patterns for knowing if a pub-sub message was successful,2016-04-25 15:26:16,<design-patterns><publish-subscribe><amazon-sqs><amazon-sns><microservices>,1,354,4,0.0,3,"<p>I'm developing microservices for a project and we're experimenting with pub-sub communication using AWS SNS+SQS. We're unsure how to signal to services whether or not other services have successfully completed tasks or not.<br>&#xA;For example, if service A emits an SNS Event and service D, E, and F all are listening to the subscribed SQS Queue, how does service A know if the activities kicked off by service A inside of service D, E, and F were successful?  </p>&#xA;&#xA;<p>I'll give a more concrete example:&#xA;A new user registers for a website.  This network call first reaches the <code>user service</code> in the backend.  If the user was successful, it sends off an event saying a new user was created.  That triggers the <code>email service</code> to send an email to for the user to confirm his registration. What happens if it fails to send an email? &#xA;Has the <code>user service</code>:</p>&#xA;&#xA;<p>1) Already responded to the frontend saying it was successful</p>&#xA;&#xA;<p>2) Or is it waiting for a confirmation?  What is a good pub-sub pattern for confirmations?  </p>&#xA;&#xA;<p>I know we could have just done a synchronous call, but this example is simplified for brevity's sake.  </p>&#xA;"
32604241,Best Protocol for a App to Use a Service on the Same Server?,2015-09-16 09:10:24,<php><api><http><service><microservices>,1,53,0,0.0,3,"<p>I have a PHP app that needs to talk to a service which has a API that produces XML responses to HTTP requests. If this service was on a separate server I would normally use a HTTP client like Guzzle to create and consume, requests and responses.</p>&#xA;&#xA;<p>But my service will be (for the time being) on the same server. In this scenario is making HTTP requests in this fashion still my best option? Will all my requests to the API leave the server which will add latency which could be avoided?</p>&#xA;"
32534401,SOA - Microservices : Use API REST or SOAP,2015-09-12 01:59:21,<architecture><soa><microservices>,3,4423,0,3.0,3,"<p>I'm face to a big dilemm : in my company, we are working on microservices architecture and switching to a full SOA eco system.</p>&#xA;&#xA;<p>Some consultants and developpers say it would be better to SOAP for web services, because it would allow to specify and give a validated format to all developer teams. I'm scared using SOAP we would be restricted at the end.</p>&#xA;&#xA;<p>Based on your experience, for a SOA / Microservices architecture, would it be better to use SOAP or REST API ?</p>&#xA;&#xA;<p>Thanks in advance for your helpful feedback.</p>&#xA;"
32574103,Microservices - how to solve security and user authentication?,2015-09-14 21:18:13,<authentication><java-ee><microservices>,2,1504,1,2.0,3,"<p>There is a lot of discussion about microservice architecture. What I am missing - or maybe what I did not yet understand is, how to solve the issue of security and user authentication?</p>&#xA;&#xA;<p>For example: I develop a microservice which provides a Rest Service interface to a workflow engine. The engine is based on JEE and runs on application servers like GlassFish or Wildfly. &#xA;One of the core concepts of the workflow engine is, that each call is user centric. This means depending of the role and access level of the current user, the workflow engine produces individual results (e.g. a user-centric tasklist or processing an open task which depends on the users role in the process).</p>&#xA;&#xA;<p>In my eyes, thus a service is not accessible from everywhere. For example if someone plans to implement a modern Ajax based JavaScript application which should use the workflow microservice there are two problems:</p>&#xA;&#xA;<p>1) to avoid the cross-scripting problem from JavaScript/Ajax the JavaScript Web application needs to be deployed under the same domain as the microservice runs</p>&#xA;&#xA;<p>2) if the microservice forces a user authentication (which is the case in my scenario) the application need to provide a transparent authentication mechanism. </p>&#xA;&#xA;<p>The situation becomes more complex if the client need to access more than one user-centric microservices forcing user authentication.&#xA;I always end up with an architecture where all services and the client application running on the same application server under the same domain.</p>&#xA;&#xA;<p>How can these problems be solved? What is the best practice for such an architecture?</p>&#xA;"
34722107,Is DAO microservice good approach in microservices architecture?,2016-01-11 12:55:19,<web-services><rest><database-design><architecture><microservices>,5,1813,0,1.0,3,"<p>I'm creating a web-application and decided to use micro-services approach. Would you please tell me what is the best approach or at least common to organize access to the database from all web-services (login, comments and etc. web-services). Is it well to create DAO web-service and use only it to to read/write values in the database of the application. Or each web-service should have its own dao layer.</p>&#xA;"
34526251,What is the difference between Kubernetes and Amazon ECS,2015-12-30 09:05:46,<docker><kubernetes><containers><microservices><amazon-ecs>,2,2207,2,0.0,3,<p>What is the difference between Amazon ECS and Kubernetes implementation architecture?</p>&#xA;&#xA;<p>I need to decide to pick a technology for container management in cloud.&#xA;What is the deciding factor while picking any of these technology?</p>&#xA;&#xA;<p>I am using Docker for container creation and execution.</p>&#xA;
34575783,Azure Service Fabric actor microservice,2016-01-03 11:03:07,<c#><microservices><azure-service-fabric>,2,1744,3,0.0,3,<p>Microsoft is offering a microservice solution for it's cloud platform Azure. There are two frameworks - reliable services and reliable actors. </p>&#xA;&#xA;<p>I was wondering if a reliable actor is an independently microservice? Or form multiple actors together a microservice?</p>&#xA;
35314963,What is best practice to communicate between React components and services?,2016-02-10 12:13:11,<rest><reactjs><redux><flux><microservices>,2,6713,0,3.0,3,"<p>Instead of using flux/redux architecture, how react components should communicate with services?</p>&#xA;&#xA;<p><strong>For example:</strong>&#xA;There is a container having few representational (react) components:</p>&#xA;&#xA;<ol>&#xA;<li>ChatBox - enables to read/write messages</li>&#xA;<li>AvatarBox with password changer - which enables to change user's password</li>&#xA;<li>News stream - lists news and apply filter to them</li>&#xA;</ol>&#xA;&#xA;<p>Thinking of them as resources representation, I want each of them to access Microservice API by itself (getting or updating data). Is this correct?&#xA;It will provide clean responsibility managing models, but it gives performance doubts using http requests to load each component's content</p>&#xA;&#xA;<p>This question also reffers to: <a href=""https://stackoverflow.com/questions/35286730/how-to-execute-efficient-communication-for-multiple-microservices"">How to execute efficient communication for multiple (micro)services?</a></p>&#xA;"
35348080,How to handle shared datasources using microservices architecture,2016-02-11 19:14:25,<java><architecture><redis><microservices><bigdata>,1,622,0,1.0,3,"<p>I have couple of services in my microservice architecture.</p>&#xA;&#xA;<p>Two of the service(Service A, Service B) got different api's and provide different domain logic. However they do share some logic that should be returned - user-state from Redis.</p>&#xA;&#xA;<ul>&#xA;<li>When user state is changed Iam publishing from a 3rd service to all the my micro-services</li>&#xA;</ul>&#xA;&#xA;<p>solutions:</p>&#xA;&#xA;<ol>&#xA;<li><p>I could create another service which would be responsible for ""user-state"" and will hold all user data on Redis.&#xA;Disadvantages: &#xA;My clients going to have additional call on every api requests(to get the user-state).</p></li>&#xA;<li><p>Duplicate the user-state datasource for each microservices(holding more than one redis instance) and return it independently for each request.&#xA;Disadvantages: &#xA;I am going to duplicate my data and duplicate Redis instances(each microservice will access it's own)</p></li>&#xA;<li><p>have one redis datasource while all services going to use it. &#xA;Disadvantages: &#xA;Duplicating redis-logic(in order to retrieve the data) among the services and break microservices principle by using one shared datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What would you suggest doing?</p>&#xA;"
35223505,Spring Boot project setup design decisions,2016-02-05 11:50:38,<java><spring><spring-boot><microservices>,1,252,1,1.0,3,"<p>We will be using Spring Boot to create services. Our initial idea would be that each service (not necessarily microservice) would be self-contained, and deployed as a .jar file. Maven for build.</p>&#xA;&#xA;<p>I'm wondering what would be a good Spring Boot project structure, as each service would be self-contained, but I'm guessing services will still have some code/entities that can or should be reused between services</p>&#xA;&#xA;<p>Options:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each service is a standalone Spring Boot project. Implements only the entities, controllers, and utils that the actual service requires.</p>&#xA;&#xA;<p>Good: each service is fully self-contained</p>&#xA;&#xA;<p>Bad: what about custom utility classes that need to be re-used between services? What about domain objects that services may need to share?</p></li>&#xA;<li><p>All services are created in the same codebase. All services can re-use utilities, controllers, etc. from all other services&#xA;Good: easy re-use&#xA;Bad: A JVM is now able to serve all service calls? service boundaries are now handled by load balancers?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!  </p>&#xA;"
34158847,Inter-microservices Communication using REST & PUB/SUB,2015-12-08 14:49:01,<rest><server><publish-subscribe><microservices>,3,925,0,1.0,3,"<p>This is still a theory in my mind.</p>&#xA;&#xA;<p>I'm rebuilding my backend by splitting things into microservices. The microservices I'm imagining for starting off are:<br/>&#xA;- Order (stores order details and status of each order)<br/>&#xA;- Customer (stores customer details, addresses, orders booked)<br/>&#xA;- Service Provider (stores service provider details, status &amp; location of each service provider, order(s) currently being processed by the service provider, etc.)<br/>&#xA;- Payment (stores payment info for each order)<br/>&#xA;- Channel (communicates with customers via email / SMS / mobile push)<br/></p>&#xA;&#xA;<p>I hope to be able to use PUB/SUB to create a message with corresponding data, which can be used by any other microservice subscribing to that message.</p>&#xA;&#xA;<p>First off, I understand the concept that each microservice should have complete code &amp; data isolation (thus, on different instances / VMs); and that all microservices should communicate strictly using HTTP REST API contracts.</p>&#xA;&#xA;<p>My doubts are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>To show a list of orders, I'll be using the Order DB to get all orders. In each Order document (I'll be using MongoDB for storage), I'll be having a customer_id Foreign Key. Now the issue of resolving customer_name by using customer_id.<br/>&#xA;If I need to show 100 orders on the page and go with the assumption that each order has a unique customer_id associated with it, then will I need to do a REST API call 100 times so as to get the names of all the 100 customer_ids?&#xA;Or, is data replication a good solution for this problem?</p></li>&#xA;<li><p>I am envisioning something like this w.r.t. PUB/SUB: The business center personnel mark an order as assigned &amp; select the service provider to allot to that order. This creates a message on the cross-server PUB/SUB channel.<br/>&#xA;Then, the Channel microservice (which is on a totally different instance / VM) captures this message &amp; sends a Push message &amp; SMS to the service provider's device using the data within the message's contents.<br/>&#xA;Is this possible at all?<br/>&#xA;<strong>UPDATE TO QUESTION 2:</strong> I want the Order microservice to be completely independent of any other microservices that will be built upon / side-by-side it. Channel microservice is an example of a microservice that depends upon events taking place within Order microservice.</p></li>&#xA;</ol>&#xA;&#xA;<p>Also, please guide me as to what all technologies / libraries to use.</p>&#xA;&#xA;<p>What I'll be developing on:<br/>&#xA;Java<br/>&#xA;MongoDB<br/>&#xA;Amazon AWS instances for each microservice.<br/></p>&#xA;&#xA;<p>Would appreciate anyone's help on this.<br/>&#xA;Thanks!</p>&#xA;"
35913253,Microservice based or Monolithic,2016-03-10 10:03:10,<cordova><spring-boot><microservices>,3,584,0,0.0,3,"<p>I read a lot about Microservices and their structure and it seems, that there are a lot of advantages when it comes to maintainability. </p>&#xA;&#xA;<p>I want to build a mobile app with Spring Boot and Phonegap, which pulls news from RESTful Web Services. </p>&#xA;&#xA;<p>So I'm thinking f building it as a microservice so I can add other services without rebuilding the whole application. Because in future I might want to add other services.</p>&#xA;&#xA;<p>But is it really worth to build a Microservice based application for such a small mobile app? </p>&#xA;"
34301614,"Zuul url mapping with spring boot,Eureka",2015-12-15 23:47:42,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-zuul>,1,3960,3,1.0,3,<p>I am building Rest api using microservice architecture. I have multiple apis for user that we have made into multiple projects. I have everything else ready except I am not able to map the user facing url to the application url in zuul.</p>&#xA;&#xA;<p>The user facing url is : user/v1/accountholders/{id}/cards and the actual url for my application is /user-cards/v1/accountholders/{id}/cards. </p>&#xA;&#xA;<p>Here id is the path variable. Below are other similar api url so if there is a way to configure them generically in zuul. Also the context root of the application url is also the project name in Eureka.</p>&#xA;&#xA;<pre><code>Other similar urls are:&#xA;&#xA;client side:- /user/v1/accountholders/{id}/cards/{cardid}&#xA;application:- /user-cards/v1/accountholders/{id}/cards/{cardid}&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders/{id}&#xA;application:- /user-cardholder/v1/accountholders/{id}&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts/{accid}&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts/{accid}&#xA;</code></pre>&#xA;&#xA;<p>Need some help to set this up in the properties or yml file for zuul. I havent been able to make any progress with the mapping stuff yet. Any inputs will be helpful.</p>&#xA;&#xA;<p><strong>SOLVED:-</strong>&#xA;After getting the input from @Daniel (which is the accepted answer)This is what i used in zuul config:-</p>&#xA;&#xA;<pre><code>zuul:&#xA; routes:&#xA;   User-Cards: &#xA;        path: /user/v1/accountholders/*/cards/**&#xA;        url: http://desktop-uvkv1ed:9999/user-cards/v1/accountholders&#xA;   User-Transactions1: &#xA;        path: /user/v1/accountholders/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Transactions2:  &#xA;        path: /user/v1/accountholders/*/accounts/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Accounts: &#xA;        path: /user/v1/accountholders/*/accounts/**&#xA;        url: http://desktop-uvkv1ed:7777/user-accounts/v1/accountholders&#xA;   User-Cardholders: &#xA;        path: /user/v1/accountholders/**&#xA;        url: http://desktop-uvkv1ed:8888/user-cardholders/v1/accountholders&#xA;</code></pre>&#xA;
39591223,Can SOA and Microservices co-exist?,2016-09-20 10:04:15,<design><architecture><soa><microservices>,3,379,0,0.0,3,<p>It is often documented to build a microservice based architecture from a monolith. Is it also possible to have microservices in SOA based architecture?</p>&#xA;
39540366,Go-kit real world example with inter microservice data transfers,2016-09-16 21:31:37,<go><microservices>,1,947,0,4.0,3,"<p>I try to work with go-kit (gokit.io) and to build real-work application with it.&#xA;I look through examples. These examples are great. But I do not understand how to do services to service communications / data transfers in go-kit framework. </p>&#xA;&#xA;<p>I can see ""real-world"" shipping app, but I do not understand how it could be ""real world"" micro-services. I can see in sources that, for example, they build the booking service just passing foreign repositories into service</p>&#xA;&#xA;<pre><code>type service struct {&#xA;    cargoRepository         cargo.Repository&#xA;    locationRepository      location.Repository&#xA;    routingService          routing.Service&#xA;    handlingEventRepository cargo.HandlingEventRepository&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and later they get data from repositories (this repository belongs to foreign micro-service) just calling the method:</p>&#xA;&#xA;<p><code>locationRepository.Find(...)</code></p>&#xA;&#xA;<p>Could someone please explain me:</p>&#xA;&#xA;<ul>&#xA;<li>how to build micro-service to micro-service communications in go-kit framework? Just show me the way / pattern, please. I do not understand it at all.</li>&#xA;</ul>&#xA;&#xA;<p>I see it as they just share direct access to data. But in real world micro-services, I expected that micro-services will communicate to each other to get needed data. And I do not understand how to do it in go-kit framework.</p>&#xA;"
39601492,how monolith spring 3 application will communicate with microservice?,2016-09-20 18:41:04,<spring><spring-boot><microservices><netflix-ribbon>,1,238,2,0.0,3,<p>I have one monolith spring web application developed using spring 3.1 and spring-security 3.1 with Java 7 and it is deployed on tomcat 7. </p>&#xA;&#xA;<p>Now I have a new requirement where I have to create a micro-service for a new module using spring boot with java 8. This micro-service will be deployed separately on different EC2 instance. </p>&#xA;&#xA;<p>I am looking for suggestion/idea to access new microservice from my existing spring web application. </p>&#xA;&#xA;<p>How to perform <em>inter process communication</em> within these two spring application?</p>&#xA;&#xA;<p>Can someone provide me any help/pointer?</p>&#xA;
32217639,Online Store and Microservices,2015-08-26 03:44:02,<restful-architecture><microservices>,1,443,0,3.0,3,"<p>I am working for a big online store. At the moment our architecture is something weird where we have microservices which actually all share the same DB (doesn't work well at all...).&#xA;I am considering improving that but have some challenges on how to make them independant.</p>&#xA;&#xA;<p>Here is a use case. I have customers, customers purchase products. Let say I have 3 microservices : customer authentication, order management, product management.&#xA;An order is linked to a customer and a product.&#xA;Could you describe a solution for the following problems :</p>&#xA;&#xA;<ol>&#xA;<li>How do you make the link between an order and a customer?</li>&#xA;<li>Let say both services share a customer ID, how do you handle data consistency? If you remove a customer on the customer service side, you end up with inconsistency. If your service has to notify the other services then you end up with tighlty coupled services which to me sounds like what you wanted to avoid in the first place. You could kind of avoid that by having an event mechanism which notify everyone but what about network errors when you don't even know who is supposed to receive the event?</li>&#xA;<li>I want to do a simple query : retrieve the customers from US that bought product A. Given that 3million people bought product A and we have 1 million customers in the US; How could you make that reasonably performant? (Our current DB would execute that in few milliseconds)</li>&#xA;</ol>&#xA;&#xA;<p>I can't think of any part of our code where we don't have this kind of relation. One of the solution I can think of is duplicating data. E.g. When a customer purchase something, the order management service will store the customer details and the product details. You end up with massive data replication, not sure if that's a good thing and I would still be worried about consistency.</p>&#xA;&#xA;<p>I couldn't find a paper addressing those issues. What are the different options?</p>&#xA;"
39839881,Is it OK to pass on OAuth Access Token between services?,2016-10-03 20:28:57,<oauth><oauth-2.0><authorization><access-token><microservices>,3,1446,0,0.0,3,"<p>Considering the following scenario in a context of the SSO/OAuth/microservices:</p>&#xA;&#xA;<ol>&#xA;<li>User successfully logs-in to the web application using OAuth's Implicit Flow.</li>&#xA;<li>Web app requests some data from <strong>Service A</strong> and <strong>Service B</strong> passing on user's Access Token to authorize both requests.</li>&#xA;<li><strong>Service A</strong> also calls <strong>Service B</strong> (passing on the same Access Token!) in order to build response to the initial Web App request.</li>&#xA;</ol>&#xA;&#xA;<p>Now, is this OK to pass on the user's Access Token from <strong>Service A</strong> to <strong>Service B</strong>? </p>&#xA;&#xA;<p>Or should <strong>Service A</strong> use ""Client Credentials"" grant to obtain its own Access Token to authorize call to the <strong>Service B</strong>?</p>&#xA;&#xA;<p><strong>UPDATE</strong>:<br>&#xA;Please assume both services are owned by the same organization and both trust the same Authorization Server. Also both services are behind the same API Gateway which validates Access Tokens.</p>&#xA;"
39672919,How to design a sails.js project with microservices architecture?,2016-09-24 05:35:16,<node.js><architecture><sails.js><microservices>,2,1195,0,3.0,3,"<p>I learned about microservices from <a href=""http://microservices.io/"" rel=""nofollow"">here</a></p>&#xA;&#xA;<p>Now, I want to use microservices architecture in my next sails.js project.</p>&#xA;&#xA;<p><strong>One way I could think of is:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Breaking my one sails.js application into multiple small sails.js sub-projects/repositories. </p></li>&#xA;<li><p>Having one controller-model in one sub-project. For example, If we consider simple eCommerce app with entities say User, Products, Orders, etc. then there will be separate sails.js repositories for each of them with respective sails.js model-controller.  Then this single sub-repository will from my one microservice.</p></li>&#xA;<li><p>Each sub-repository then will obviously have its own configs.</p></li>&#xA;<li><p>These microservices will them communicate with each other using some HTTP node module.</p></li>&#xA;<li><p>Then writing my own <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow"">API gateway</a> for routing in node.js, which will be responsible for invoking methods/web-services from these sub-repositories depending on the request from clients.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is this the best way OR is there alternative way to design your project using microservices architecture?</p>&#xA;&#xA;<p>What will be the best way to implement inter-service communication, API gateway with sail.js? If one microservice designed with above mentioned approach get bigger, and if I have to split it up in 2, how sails.js model should be changed?</p>&#xA;"
41609091,Sharing files between microservices,2017-01-12 09:12:44,<node.js><microservices><seneca>,2,1858,1,1.0,3,"<p>I'm trying to move a project from its current monolithic state to microservices architecture. The project is in Node.js, so I've started looking into <a href=""http://senecajs.org/"" rel=""nofollow noreferrer"" title=""Seneca.js"">Seneca.js</a>, especially with its <a href=""https://github.com/senecajs/seneca-mesh"" rel=""nofollow noreferrer"" title=""seneca-mesh"">seneca-mesh</a> module. Moving image manipulation (crop, resize, etc.) into a microservice seemed the most sensible first step, since it drastically slows down my application now.</p>&#xA;&#xA;<p>When the application is monolithic, there is no problem in passing certain files into file-manipulation logic â€” just read it from local storage disk. With microsevices, however, if we keep in mind <em>scalability</em>, it becomes more difficult. Of course, I could build an image manipulation microservice, scale it up <em>within the same host machine</em>, and share directories I need between it, so they, too, can read from a local disk.</p>&#xA;&#xA;<p>What if I want a truly scalable microservice, that can be run and scaled on <em>different</em> machines with different IP-adresses that <em>don't share the same filesystem</em>? I thought that maybe I could take advantage of Node's streaming API and send these files back and forth via HTTP or TCP or sockets or you name it.</p>&#xA;&#xA;<p>As far as I've learned, Seneca.js cannot do it <em>the right way</em>. Of course, I could send a file from the main app to image manipulation service via Seneca.js like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('/files/hello.jpg')&#xA;  .on('data', function(data) {&#xA;    seneca.act({ role: 'file', cmd: 'chunk', data: data }, cb);&#xA;  })&#xA;  .on('end', function(err) {&#xA;    seneca.act({ role: 'file', cmd: 'end' });&#xA;  })&#xA;  .on('error', function(err) {&#xA;    seneca.act({ role: 'test', cmd: 'error' });&#xA;  });&#xA;</code></pre>&#xA;&#xA;<p>And receive it in chunks:</p>&#xA;&#xA;<pre><code>seneca.add({ role: 'file', cmd: 'chunk' }, writeToFileCb);&#xA;seneca.add({ role: 'file', cmd: 'end' }, endFileWriteCb);&#xA;</code></pre>&#xA;&#xA;<p>But this approach seems ugly and wheel-reinventive.</p>&#xA;&#xA;<p>Another way would be to come up with some HTTP server and send files as <code>multipart/form-data</code> or <code>application/octet-stream</code>, like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('file.json')&#xA;  .pipe(request.post('http://image-manipulator'))&#xA;</code></pre>&#xA;&#xA;<p>But this means reinventing the framework for microservice communication. All in all, I ask for advice on file sharing between distributed microservices and possible frameworks for this.</p>&#xA;"
41661858,Microservice Interaction,2017-01-15 13:52:12,<c#><.net><microservices><restful-architecture>,2,439,2,0.0,3,"<p>I would like to know what is the best practice on making one Microservice to interact with another Microservice?</p>&#xA;&#xA;<p> I am developing in C#. What I currently have done is, created a service bus which passes new events created from one Microservice. I then use task runner (WebJob) which consumes the messages off the bus and then I am using Http to Post to another Microservice endpoint. Each microservice is a web api. </p>&#xA;&#xA;<p>I would like to ask if I am doing it correctly, if not I am happy to hear the suggestions. </p>&#xA;"
42949138,Rails: Microservice architecture with dedicated authorization service and app services using Knock (JWT),2017-03-22 10:37:22,<ruby-on-rails><ruby><jwt><microservices>,1,461,0,0.0,3,"<p>I'm now trying to separate monolithic application into microservices (dedicated rails app's) and wanted to know - is there a solution to move authorization service from each service?</p>&#xA;&#xA;<p>For example, I have 6 different Rails API services with 'knock' gem that have user model for authentication purpose.&#xA;All those services sharing one user database.</p>&#xA;&#xA;<p>I want to implement dedicated service with user model, but how other services will verify users with given tokens?</p>&#xA;&#xA;<p>Also I want to able to control what services user can and can't use. So there should be AccessRole service?</p>&#xA;&#xA;<p>Draft case:</p>&#xA;&#xA;<ol>&#xA;<li>User go to 'articles' (frontend UI client)</li>&#xA;<li>auth_service is validating token from client</li>&#xA;<li>access_service got message from auth_service somehow and validating user's role to access 'articles' resource.</li>&#xA;<li>articles_service send response to client with json data.</li>&#xA;</ol>&#xA;&#xA;<p>Here some more questions:</p>&#xA;&#xA;<ol>&#xA;<li>How access_service will communicate with auth_service? Should they use one user database to verify user's credentials and role?</li>&#xA;<li>articles_service and so on - should they become private services without access to public and act as black boxes to user?</li>&#xA;</ol>&#xA;"
36586934,Carrying request context through the stack and across thrift service boundaries with Node.js,2016-04-13 01:26:35,<node.js><typescript><microservices><restify>,1,305,0,0.0,3,"<p>I'm trying to figure out an appropriate method to carry a request-id (x-request-id from a restify request header) through my stack; across thrift inter-service calls, and with rabbitmq queue messages. The goal is that anywhere, in any service, I can correlate an error or event back to an initiating http request. Is there a known practice for doing this with Node? I'd like to avoid passing a context around through virtually every function call.</p>&#xA;&#xA;<p>I've looked into the way New Relic handles instrumentation, and there's this blog: <a href=""https://opbeat.com/blog/posts/how-we-instrument-nodejs/"" rel=""nofollow"">https://opbeat.com/blog/posts/how-we-instrument-nodejs/</a>; but these types of instrumentation require hooking into tons of node core library calls, and don't really help with carrying the context across thrift calls.</p>&#xA;&#xA;<p>How can I take a restify header id such as ""x-request-id"" from a request, and have access to it deeper in my stack (even in async callbacks) without modifying every function to pass the values through? </p>&#xA;&#xA;<p>I'm also looking for a clean way to pass it through all thrift calls (getting it across service boundaries).</p>&#xA;&#xA;<p>This is with TypeScript and Node.js 5.x</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
38254720,Migrate from monolith to Micro service architecture,2016-07-07 20:30:29,<microservices>,2,115,1,0.0,3,<p>We are on the initial stages of designing a micro service for my client from their standard monolith app that is sitting on 4 JBOSS servers in their own data center. Is micro service architecture target at only cloud based deployment? Can i deploy a micro service on premise production ready tomcat /JBOSS? Is that a good fit?</p>&#xA;
39967784,Microservice vs SOA differs,2016-10-10 22:35:46,<soa><microservices>,5,712,0,1.0,3,"<p>I was looking for differences b/w SOA and Microservices architecture style&#xA;and found a good link <a href=""https://www.infoq.com/articles/boot-microservices"" rel=""nofollow noreferrer"">https://www.infoq.com/articles/boot-microservices</a></p>&#xA;&#xA;<p>It Says:<br>&#xA;As a successor to ""Service Oriented Architecture"" (SOA), microservices can be categorized in the same family of ""distributed systems"", and carry forward many of the same concepts and practices of SOA. Where they differ, however, is in terms of the scope of responsibility given to an individual service. In SOA, a service may be responsible for handling a wide range of functionality and data domains, while a general guideline for a microservice is that it is responsible for managing a <strong>single data domain</strong> and the corresponding functions around that domain.</p>&#xA;&#xA;<p>Please help me to understand :<br>&#xA;The meaning of single data domain (recommended for microservice).&#xA;is it saying that a separate Microservice has to be build to manage a single domain/entity (and associated/composite domain/entities with this single domain/entity). Becasue if this case, then there will be many(~20 to ~50) microservices even to implement a basic functionality (enterprise) application</p>&#xA;&#xA;<p>Edit:&#xA;I have gone through the link <a href=""https://stackoverflow.com/questions/25501098/difference-between-microservices-architecture-and-soa"">Difference between Microservices Architecture and SOA</a>, but it explains, that it is same on the first two tenets, and different on 3rd point (in SOA, Services share schema and contract, not class), but that is SOAP contracts, but then what is the difference b/w SOA (with REST) vs Microservices (which is mostly with REST)</p>&#xA;"
40068013,ci/cd independent microservices in monorepo with git bash,2016-10-16 07:35:35,<git><bash><continuous-integration><microservices><monorepo>,1,249,0,1.0,3,"<p>Using Bash and git, how do I get a collection of directories containing files that differ from that last time the branch was merged into <code>master</code>?</p>&#xA;&#xA;<p>Even better would be a collection of changed that match a pattern such as containing a particular file name , i.e. building a collection of changed directories containing <code>package.json</code> and a different collection of changed containing <code>requirements.txt</code>.</p>&#xA;"
40058568,Synchronous communication in a mostly asynchronous microservices architecture,2016-10-15 11:40:51,<architecture><publish-subscribe><microservices>,1,253,2,1.0,3,"<p>I'm trying to extract some services from my monolithic application pet project, mostly as a learning exercise. I'm using AMQP (RabbitMQ) for communication between services, which is working just fine. However, I'm having trouble separating the web frontend from the rest of the application. The web service takes care of views and UI logic, but needs to query the backend ""core"" service for the main data. AMQP doesn't seem like a good fit for this, as the frontend service needs to wait for the response, and response times are critical. My first thought was to implement a REST interface for just this line of communication, but the same service also uses AMQP to subscribe to communication of other services. </p>&#xA;&#xA;<p>This seems like it should be a pretty common occurrence, but I haven't been able to find any answers.</p>&#xA;&#xA;<p>I guess my main question is what to do when one service needs to offer both synchronous and asynchronous communication. I'm also using Ruby, which doesn't lend itself to having the multiple threads it would require to listen on two interfaces. A few things I've considered:</p>&#xA;&#xA;<ul>&#xA;<li>Just using AMQP, sending a message with a <code>reply_to</code> field, and blocking until response is received.</li>&#xA;<li>Extract the data access part of the core backend service and giving it a REST API. Then both the web service and the part that ""subscribes"" would query this other service. Seems unnecessary to have a service just for access database.</li>&#xA;<li>Having multiple threads and using some kind of event loop to listen on two interfaces. Seems overly complex.</li>&#xA;</ul>&#xA;"
29689630,Moving over to microservices for .NET apps - some questions,2015-04-17 03:18:48,<.net><rest><architecture><restsharp><microservices>,2,1406,0,2.0,3,"<p>I'd like to start getting into splitting my apps into microservices. My first task is to remove functionality that is repeated in each of our apps. Things like email sending, exporting, searching indexes etc - stuff where the same or similar code is repeated in every app.</p>&#xA;&#xA;<p>I just feel a little overwhelmed and struggling to get a start. I understand that the purpose of microservices is that you can pick the right language for the job, but for our current purposes i'm going with the assumption that .NET would be the primary framework i'll be building everything in.</p>&#xA;&#xA;<p>Basically, to start with, I want to create a microservice that simply sends emails that all our apps can talk to and tell to send the emails they need. The way I was thinking was the email sender has the logic to send the email, but each app needs to tell it the recipients, body etc.</p>&#xA;&#xA;<p>I'm struggling with things like:</p>&#xA;&#xA;<ul>&#xA;<li><p>What protocol should the apps use to talk to this service? REST over HTTP? If this is the case, would the email sending microservice effectively just be a Web API 2 app (this is what I'd personally go with if i were to build a REST api).</p></li>&#xA;<li><p>If I'm going REST, whats the best way to make restful calls from the backend? Most emails in our system are sent via the backend code right now. I've seen the RestSharp name thrown around, is this generally considered the best way?</p></li>&#xA;<li><p>Future planning, I think having some sort of gateway which knows about all the services would be beneficial so that each app only needs to know about this gateway and then the gateway talks to whatever services it needs. Would this just be yet another REST API in between the apps and the micro services?</p></li>&#xA;</ul>&#xA;&#xA;<p>Sorry for all the questions, just getting a start in all this sort of stuff (and architecture in general) in order to step up in my workplace and it's a bit to get my head around currently.</p>&#xA;"
44253950,Using soap services(.asmx) with Azure Service fabric,2017-05-30 05:16:14,<web-services><rest><soap><microservices><azure-service-fabric>,1,256,0,1.0,3,<p>I am migrating my existing services to Azure service fabric. My existing application support the soap service(asmx) for the legacy users. I want to use the same web service as part of my microservice. That web service test.asmx(say) can be called from Rest Apis as well(If soln is there). But I'm not finding any way to use the soap service as part of Azure service fabric microservice approach. Help me out of possible solutions for tackling the web service scenario. Thanks!</p>&#xA;
44420585,Microservices: how to effectively deal with data dependencies between microservices,2017-06-07 18:47:49,<node.js><mean-stack><microservices>,2,125,0,1.0,3,"<p>I am developing an application utilizing the microservices development approach with the mean stack.  I am running into a situation where data needs to be shared between multiple microservices.  For example, let's say I have user, video, message(sending/receiving,inbox, etc.) services.  Now the video and message records belong to an account record.  As users create video and send /receive message there is a foreign key(userId) that has to be associated with the video and message records they create. I have scenarios where I need to display the first, middle and last name associated with each video for example.  Let's now say on the front end a user is scrolling through a list of videos uploaded to the system, 50 at a time.  In the worst case scenario, I could see a situation where a pull of 50 occurs where each video is tied to a unique user.</p>&#xA;&#xA;<p>There seems to be two approaches to this issue:</p>&#xA;&#xA;<p>One, I make an api call to the user service and get each user tied to each video in the list.  This seems inefficient as it could get really chatty if I am making one call per video.  In the second of the api call scenario, I would get the list of video and send a distinct list of user foreign keys to query to get each user tied to each video.  This seems more efficient but still seems like I am losing performance putting everything back together to send out for display or however it needs to be manipulated.</p>&#xA;&#xA;<p>Two, whenever a new user is created, the account service sends a message with the user information each other service needs to a fanout queue and then it is the responsibility of the individual services to add the new user to a table in it's own database thus maintaining loose coupling.  The extreme downside here would be the data duplication and having to have the fanout queue to handle when updates needs to be made to ensure eventual consistency.  Though, in the long run, this approach seems like it would be the most efficient from a performance perspective.  </p>&#xA;&#xA;<p>I am torn between these two approaches, as they both have their share of tradeoffs.  Which approach makes the most sense to implement and why?</p>&#xA;"
44331178,Testing same API for multiple response sets,2017-06-02 14:20:01,<javascript><node.js><rest><microservices><pact>,1,148,0,1.0,3,"<p>We've been trying to test an API exposed from a microservice (say GET /contacts) which is being consumed by another microservice.</p>&#xA;&#xA;<p>In order to avoid integration tests, we created consumer-driven contract tests where the consumer microservice created pacts and published them to a broker from where the producer would verify the pact separately.</p>&#xA;&#xA;<p>We've used <a href=""https://docs.pact.io/"" rel=""nofollow noreferrer"" title=""Pact IO"">Pact IO</a> to achieve this and it has been quite good so far.</p>&#xA;&#xA;<p>Now we are facing issues when trying to do exhaustive tests where we would want to see how an empty list is returned from GET /contacts.</p>&#xA;&#xA;<p>The problem is: while adding interactions, we could use Provider States but we couldn't find a way to differentiate between writing tests for getting a list of contacts from GET /contacts once and getting an empty list in another test.</p>&#xA;&#xA;<p>This is how we create pact tests in our consumer microservice:</p>&#xA;&#xA;<pre><code>mockServer.start()&#xA;        .then(() =&gt; {&#xA;          provider = pact({&#xA;            // config&#xA;          })&#xA;          return provider.addInteraction({&#xA;            state: 'Get all contacts',&#xA;            uponReceiving: 'Get all contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: //list of all contacts&#xA;            }&#xA;          })&#xA;        .then(() =&gt; {&#xA;          return provider.addInteraction({&#xA;            state: 'Get empty list of contacts',&#xA;            uponReceiving: 'Get empty list of contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: [] // empty list&#xA;            }&#xA;          })&#xA;        })&#xA;</code></pre>&#xA;&#xA;<p>We cannot find a way to differentiate between these interations in our tests! :(</p>&#xA;&#xA;<p>Any help would be appreciated!</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
38714097,Deploy Service Fabric Application through VSTS release pipeline using Hosted Agent,2016-08-02 07:19:59,<azure><vsts><microservices><azure-service-fabric><vsts-release>,1,888,8,0.0,3,"<p>I have set up continuous integration using Hosted Agent for service fabric by following this document <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/"" rel=""nofollow noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/</a></p>&#xA;&#xA;<p>In Release pipeline after importing certificate I am getting the following error and deployment failing. I am not able to identify where the issue is&#xA;<a href=""https://i.stack.imgur.com/Afc7G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Afc7G.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;  &#xA;  <p>Finishing task: ServiceFabricDeploy </p>&#xA;  &#xA;  <h2>[error]System.Exception: Task ServiceFabricDeploy failed.</h2>&#xA;  &#xA;  <p>This caused the job to fail. Look at the logs for the task for more details. </p>&#xA;  &#xA;  <p>[error]   at Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.Run(IJobContext jobContext, IJobRequest job, IJobExtension jobExtension, CancellationTokenSource tokenSource)</p>&#xA;</blockquote>&#xA;&#xA;<p>Under Deploy service fabric task it is showing the below error&#xA;<a href=""https://i.stack.imgur.com/bSCBZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bSCBZ.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>Imported cluster client certificate with thumbprint 'A6B32E70CFE715F608A247C1ED94AB3D0164A58E'.</p>&#xA;  &#xA;  <p>Thumbprint Subject                                            </p>&#xA;  &#xA;  <p>A6B32E70CFE715F608A247C1ED94AB3D0164A58E  >CN=clusternamedns.eastus.cloudapp.azure.com                                     </p>&#xA;  &#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;</blockquote>&#xA;&#xA;<h2><strong>Update</strong></h2>&#xA;&#xA;<p>After setting system.debug to true in variables, I got the following log</p>&#xA;&#xA;<pre><code>    2016-08-03T05:44:31.6556865Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.6566887Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.6577063Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.6587072Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.6597111Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.6606871Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.6647953Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.6656886Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.6666879Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.6676869Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.6770225Z ##[debug]Leaving C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1.&#xA;&#xA;2016-08-03T05:44:31.6850322Z ##[debug]Caught exception from task script.&#xA;&#xA;2016-08-03T05:44:31.6890370Z ##[debug]Error record:&#xA;&#xA;2016-08-03T05:44:31.7380329Z ##[debug]Connect-ServiceFabricCluster : An error occurred during this operation.  Please check the trace logs for more details.&#xA;&#xA;2016-08-03T05:44:31.7390333Z ##[debug]At C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1:73 char:12&#xA;&#xA;2016-08-03T05:44:31.7410325Z ##[debug]+     [void](Connect-ServiceFabricCluster @clusterConnectionParameters)&#xA;&#xA;2016-08-03T05:44:31.7420325Z ##[debug]+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;2016-08-03T05:44:31.7430323Z ##[debug]    + CategoryInfo          : InvalidOperation: (:) [Connect-ServiceFabricCluster], FabricException&#xA;&#xA;2016-08-03T05:44:31.7440363Z ##[debug]    + FullyQualifiedErrorId : CreateClusterConnectionErrorId,Microsoft.ServiceFabric.Powershell.ConnectCluster&#xA;&#xA;2016-08-03T05:44:31.7450426Z ##[debug] &#xA;&#xA;2016-08-03T05:44:31.7470318Z ##[debug]Script stack trace:&#xA;&#xA;2016-08-03T05:44:31.7500512Z ##[debug]at &lt;ScriptBlock&gt;, C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1: line 73&#xA;&#xA;2016-08-03T05:44:31.7910331Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7920318Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 22&#xA;&#xA;2016-08-03T05:44:31.7930364Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 18&#xA;&#xA;2016-08-03T05:44:31.7940315Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7960349Z ##[debug]Exception:&#xA;&#xA;2016-08-03T05:44:31.8000522Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.8010571Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.8020684Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.8030335Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.8040334Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.8060326Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.8070343Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.8080330Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.8090325Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.8100358Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.8340330Z ##[error]An error occurred during this operation.  Please check the trace logs for more details.&#xA;</code></pre>&#xA;"
46386326,Backing Services as attached resources,2017-09-24 03:32:03,<spring-boot><cloud><microservices><cloudfoundry><12factor>,1,126,0,0.0,3,"<p>I was looking at 12 factor app principle and saw this statement. I believe this statement states that the application must respond to any backing service such database or message broker and connect to them irrespective of what they are. How does it differ from traditional way of connecting? For eg: in my microservice , I was defined database and kafka broker as user provided service in cloud foundry. It just provides the connection parameters as vcap service variables. I still have code to connect to a database and kafka broker which are entirely different. What does this statement signify and how does it differ from what we do in non-cloud environment?</p>&#xA;"
46404449,Micro service architecture for Angular2,2017-09-25 11:44:49,<angular><design-patterns><architecture><microservices>,1,657,4,2.0,3,"<p>If we take an enterprise  angular 2 web app it has several modules(screens) such as Customer management, Reservations, Booking management, Reporting and etc....</p>&#xA;&#xA;<p>What we normally do is we create common components in a component library and use them on main angular application. The main angular app contains all the modules(screens) with REST API integrations(assuming backed is REST). When app is getting bigger &amp; bigger compile time and rendering consuming more time &amp; resources. Also if one particular area is having a issue we cannot have a release since all are bundle to one app.</p>&#xA;&#xA;<p>As you all know <strong>Micro service architecture</strong> is a method of developing software systems that has grown in popularity. So, my question is can we apply same architecture for these type of enterprise angular 2 apps?. </p>&#xA;&#xA;<p>It is like this. We have a customer management as a separate angular app. Again Booking management is another angular app. Reporting is another app. These apps are going to be separate war files when deploying to the web server. </p>&#xA;&#xA;<p>Once we have developed such loosely coupled apps this will reduce the over head of project size, compile time &amp; resources. Also this will make unit testing more easier. Particular set of developers are only considering the only one unit of the module.</p>&#xA;&#xA;<p>Kindly share your expert thoughts about this</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46471625,Multiple microservice symfony application share vendor folder,2017-09-28 14:27:00,<php><symfony><composer-php><share><microservices>,2,314,5,1.0,3,"<p>We are working on a new web project, with a microservice architecture.</p>&#xA;&#xA;<p>We will need around 5 Front Web project, and about 5 API microservice orchestrate with an API manager.</p>&#xA;&#xA;<p>We plan to use Symfony2 Framework, but I think it will be too Heavy. I mean because by the instance of the composer that will download all around the same library from symfony component, core... and same library used for each project (phpmailer for example).</p>&#xA;&#xA;<p>Actually, I was asking myself about a great sharing strategy for the vendor folder assuming that each SF2 project would use a share vendor folder and compute all library in a unique folder.&#xA;We need all the same version for each library in each project.</p>&#xA;&#xA;<p>Does somebody have some experiment on this kind of sharing? Best practices? Is it preferable to have one vendor folder per project? </p>&#xA;&#xA;<p>Open discution !</p>&#xA;&#xA;<p>Cheers.</p>&#xA;"
44495957,docker microservice apps restart over and over again in kubernetes,2017-06-12 09:29:14,<docker><kubernetes><microservices>,1,422,9,0.0,3,"<p>I am trying to run microservice applications with kubernetes. I have rabbitmq, elasticsearch and eureka discovery service running on kubernetes. Other than that, I have three microservice applications. When I run two of them, it is fine; however when I run the third one they all began restarting over and over again without any reason.</p>&#xA;&#xA;<p>One of my config files:</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: hrm&#xA;  labels:&#xA;    app: suite&#xA;spec:&#xA;  type: NodePort&#xA;  ports:&#xA;    - port: 8086&#xA;      nodePort: 30001&#xA;  selector:&#xA;    app: suite&#xA;    tier: hrm-core&#xA;---&#xA;apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: hrm&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: suite&#xA;        tier: hrm-core&#xA;    spec:&#xA;      containers:&#xA;      - image: privaterepo/hrm-core&#xA;        name: hrm&#xA;        ports:&#xA;        - containerPort: 8086&#xA;      imagePullSecrets:&#xA;      - name: regsecret&#xA;</code></pre>&#xA;&#xA;<p>Result from kubectl describe pod hrm:</p>&#xA;&#xA;<pre><code> State:     Running&#xA;      Started:      Mon, 12 Jun 2017 12:08:28 +0300&#xA;    Last State:     Terminated&#xA;      Reason:       Error&#xA;      Exit Code:    137&#xA;      Started:      Mon, 01 Jan 0001 00:00:00 +0000&#xA;      Finished:     Mon, 12 Jun 2017 12:07:05 +0300&#xA;    Ready:      True&#xA;    Restart Count:  5&#xA;  18m       18m     1   kubelet, minikube               Warning     FailedSync  Error syncing pod, skipping: failed to ""StartContainer"" for ""hrm"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=hrm pod=hrm-3288407936-cwvgz_default(915fb55c-4f4a-11e7-9240-080027ccf1c3)""&#xA;</code></pre>&#xA;&#xA;<p>kubectl get pods:</p>&#xA;&#xA;<pre><code>NAME                        READY     STATUS    RESTARTS   AGE&#xA;discserv-189146465-s599x    1/1       Running   0          2d&#xA;esearch-3913228203-9sm72    1/1       Running   0          2d&#xA;hrm-3288407936-cwvgz        1/1       Running   6          46m&#xA;parabot-1262887100-6098j    1/1       Running   9          2d&#xA;rabbitmq-279796448-9qls3    1/1       Running   0          2d&#xA;suite-ui-1725964700-clvbd   1/1       Running   3          2d&#xA;</code></pre>&#xA;&#xA;<p>kubectl version:</p>&#xA;&#xA;<pre><code>Client Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.4"", GitCommit:""d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae"", GitTreeState:""clean"", BuildDate:""2017-05-19T18:44:27Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.0"", GitCommit:""fff5156092b56e6bd60fff75aad4dc9de6b6ef37"", GitTreeState:""dirty"", BuildDate:""2017-04-07T20:43:50Z"", GoVersion:""go1.7.1"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;</code></pre>&#xA;&#xA;<p>minikube version:</p>&#xA;&#xA;<pre><code>minikube version: v0.18.0&#xA;</code></pre>&#xA;&#xA;<p>When I look at pod logs, there is no error. It seems like it starts without any problem. what could be the problem here?</p>&#xA;&#xA;<p>edit: output of kubectl get events:</p>&#xA;&#xA;<pre><code>19m        19m         1         discserv-189146465-lk3sm    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Created                   kubelet, minikube       Created container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Started                   kubelet, minikube       Started container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Pulled                    kubelet, minikube       Container image ""elasticsearch:2.4"" already present on machine&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Created                   kubelet, minikube       Created container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Started                   kubelet, minikube       Started container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned hrm-3288407936-d2vhh to minikube&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Created                   kubelet, minikube       Created container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Started                   kubelet, minikube       Started container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936              ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: hrm-3288407936-d2vhh&#xA;18m        18m         1         hrm                         Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set hrm-3288407936 to 1&#xA;19m        19m         1         minikube                    Node                                     Normal    RegisteredNode            controllermanager       Node minikube event: Registered Node minikube in NodeController&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kubelet, minikube       Starting kubelet.&#xA;19m        19m         1         minikube                    Node                                     Warning   ImageGCFailed             kubelet, minikube       unable to find data for container /&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeAllocatableEnforced   kubelet, minikube       Updated Node Allocatable limit across pods&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientDisk     kubelet, minikube       Node minikube status is now: NodeHasSufficientDisk&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientMemory   kubelet, minikube       Node minikube status is now: NodeHasSufficientMemory&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasNoDiskPressure     kubelet, minikube       Node minikube status is now: NodeHasNoDiskPressure&#xA;19m        19m         1         minikube                    Node                                     Warning   Rebooted                  kubelet, minikube       Node minikube has been rebooted, boot id: f66e28f9-62b3-4066-9e18-33b152fa1300&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeNotReady              kubelet, minikube       Node minikube status is now: NodeNotReady&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kube-proxy, minikube    Starting kube-proxy.&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeReady                 kubelet, minikube       Node minikube status is now: NodeReady&#xA;8m         8m          1         minikube                    Node                                     Warning   SystemOOM                 kubelet, minikube       System OOM encountered&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned parabot-1262887100-r84kf to minikube&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;18m        18m         1         parabot-1262887100          ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: parabot-1262887100-r84kf&#xA;18m        18m         1         parabot                     Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set parabot-1262887100 to 1&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulling                   kubelet, minikube       pulling image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Created                   kubelet, minikube       Created container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Started                   kubelet, minikube       Started container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Created                   kubelet, minikube       Created container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Started                   kubelet, minikube       Started container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;</code></pre>&#xA;"
31510697,Automating microservices load balancing / scaling,2015-07-20 07:16:00,<docker><load-balancing><coreos><microservices><akka-cluster>,1,381,0,1.0,3,"<p>Reading up on micro services for a few days now I was wondering how do people go about automating the load balancing and scaling these things?</p>&#xA;&#xA;<p>I have a specific scenario in mind what I would like to achieve but not sure if it's possible or maybe I'm thinking about it wrong. So here it goes...</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Let's say I have a cluster of 3 CoreOS machines named A,B and C.</p>&#xA;&#xA;<p>First thing I want is transparent deployment for which I can probably use fleet. </p>&#xA;&#xA;<p>Then I would like to detect, when one of the services is under huge load and deploy another instance of it and have that one and the first one deployed, automatically load balanced in a way that would not disrupt other services that are using it (traffic goes through load balancer from now on).</p>&#xA;&#xA;<p>Another way could be that I manually deploy another version of the services which then gets load balanced automatically and traffic router to the load balancer.</p>&#xA;&#xA;<p>Then the last question, how is this all different to something like Akka cluster and how does development of those differ from micro services?</p>&#xA;"
51602270,spring-data-rest and micro-services: Entity with @OneToOne relationship with Entity in another spring-data-rest service,2018-07-30 21:04:54,<java><spring-boot><microservices><spring-data-rest>,1,56,0,0.0,3,"<p>In my spring-data-rest application I have the following entities</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class com.foo.client.Foo {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    @OneToOne&#xA;    public Bar bar;        &#xA;}&#xA;&#xA;@Entity&#xA;public class Bar {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    public String name;        &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have JpaRepository for each entity class:</p>&#xA;&#xA;<pre><code>@RepositoryRestResource(collectionResourceRel = ""foos"", path = ""foos"")&#xA;public interface FooRepository extends JpaRepository&lt;Foo, String&gt; {&#xA;}&#xA;&#xA;&#xA;@RepositoryRestResource(collectionResourceRel = ""bars"", path = ""bars"")&#xA;public interface BarRepository extends JpaRepository&lt;Bar, String&gt; {&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8000/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8000/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>When the two entities are defined in the same spring-data-rest service endpoint then all is well and I can get the bar instance associated with the foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X GET -H ""Content-Type:application/json"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>Question: Looking at the postgresdb where entities are stored I see an association table FOO_BAR where there are two columns holding the id of each entity. However, I do not see where the URL for bar is stored and would like to understand where it is stored.</p>&#xA;&#xA;<p>Now if I split my app into two separate spring-data-rest services one foo-service for Foo and another bar-service for bar at separate ports, and also split the Repository classes between two project, then creating the association does not work and I get a 404. See modified code below:</p>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8001/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8001/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>This last request above gives me a 404 when Foo and Bar are managed by different spring-data-rest services.</p>&#xA;&#xA;<p>How can I get the second case to work?</p>&#xA;&#xA;<p>Note I used <a href=""http://www.baeldung.com/spring-data-rest-relationships"" rel=""nofollow noreferrer"">this</a> excellent resource for my example.</p>&#xA;"
51627473,Spring Boot YAML Auto Data Source Configuration Issue - Data Source URL not picked up,2018-08-01 07:18:19,<java><spring><spring-boot><yaml><microservices>,1,59,7,0.0,3,"<p>Currently, We are creating a spring boot project for our newer modules. </p>&#xA;&#xA;<p>Technology We have used as follows :</p>&#xA;&#xA;<ol>&#xA;<li>Java 1.8</li>&#xA;<li>Maven 3.5.2</li>&#xA;<li>Spring Boot: 1.5.6.RELEASE (spring-boot-starter-parent)</li>&#xA;</ol>&#xA;&#xA;<p>public class Application {</p>&#xA;&#xA;<pre><code>public static void main(String[] args) {&#xA;    SpringApplication.run(Application.class, args);&#xA;}&#xA;&#xA;@Autowired&#xA;private DataSource datasource;&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>application.properties</p>&#xA;&#xA;<ul>&#xA;<li>spring.datasource.url=<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>spring.datasource.username=XXX</li>&#xA;<li>spring.datasource.password=XXX</li>&#xA;<li>spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver</li>&#xA;</ul>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<ul>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles:</li>&#xA;<li>active: ""dev""</li>&#xA;<li>main:&#xA;&#xA;<h2>     - banner-mode: ""off""</h2></li>&#xA;</ul></li>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles: dev</li>&#xA;<li>datasource:&#xA;&#xA;<ul>&#xA;<li>url:<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>username:XXX</li>&#xA;<li>password:XXX</li>&#xA;<li>driver-class-name:oracle.jdbc.driver.OracleDriver</li>&#xA;</ul></li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>When we are adding data source information as properties file the application working as expected. But information as YAML means showing below error.</p>&#xA;&#xA;<p><strong>ERROR</strong></p>&#xA;&#xA;<p>Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'testapplication': <strong>Unsatisfied dependency expressed through field 'datasource'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource</strong> [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Tomcat.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.tomcat.jdbc.pool.DataSource]: Factory method 'dataSource' threw exception; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: <strong>Cannot determine embedded database driver class for database type NONE. If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (the profiles ""dev"" are currently active)</strong>.</p>&#xA;"
42053559,Eventual consistency with both database and message queue records,2017-02-05 15:04:53,<database><domain-driven-design><message-queue><microservices><eventual-consistency>,3,466,2,0.0,3,"<p>I have an application where I need to store some data in a database (mysql for instance) and then publish some data in a message queue. My problem is: If the application crashes after the storage in the database, my data will never be written in the message queue and then be lost (thus eventual consistency of my system will not be guaranted).&#xA;How can I solve this problem ?</p>&#xA;"
36832219,How to use redis for number of micro-services?,2016-04-25 04:51:34,<caching><redis><microservices>,3,4406,0,1.0,3,"<p>I am very much new to redis. I have been investigating on redis for past few days.I read the documentation on cache management(lru cache), commands ,etc. I want to know how to implement caching for multiple microservice(s) data .&#xA;I have few questions:</p>&#xA;&#xA;<ol>&#xA;<li>Can all microservices data(cached) be kept under a single instance of redis&#xA;    server?</li>&#xA;<li><p>Should every microservice have its own cache database in redis?</p></li>&#xA;<li><p>How to refresh cache data without setting EXPIRE? Since it would consume more memory.</p></li>&#xA;</ol>&#xA;&#xA;<p>Some more information on best practices on redis with microservices will be helpful.</p>&#xA;"
36642718,Two microservices for read and write to one database table,2016-04-15 09:01:05,<architecture><microservices>,2,1649,0,1.0,3,"<p>I'm a little bit confused about the microservice best practice approach. </p>&#xA;&#xA;<p>Following scenario:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Massive incoming messages from mqtt devices. A rest api where customers could read the messages (mostly only a part of them).</p>&#xA;</blockquote>&#xA;&#xA;<p>My idea was, to create one microservice for storing the messages in a database table. And a second microservice with a rest api to read this messages.&#xA;I want to do this, because of scaling issues. (The incoming storing part needs much more power, than the reading rest api)</p>&#xA;&#xA;<p>I read that the ""perfect"" microservice should be the only one, who accesses his data in a database. So other microservices should ask for this data, via its API and not on database level.&#xA;So my approach would be not the perfect one. I see a few options to handle this:</p>&#xA;&#xA;<ul>&#xA;<li>only one mircroservice, for storing and reading</li>&#xA;<li>making an api in the storing microservice, where the rest microservice could fetch the data.</li>&#xA;</ul>&#xA;&#xA;<p>But all of them, doesn't look good for me. </p>&#xA;&#xA;<p>Whats your opinion?</p>&#xA;&#xA;<p>Regards,&#xA;Markus</p>&#xA;"
36615117,microservice messaging db-assigned identifiers,2016-04-14 06:15:30,<microservices><spring-cloud-stream>,2,154,0,2.0,3,"<p>The company I work for is investigating moving from our current monolithic API to microservices. Our current API is heavily dependent on spring and we use SQL server for most persistence. Our microservice investigation is leaning toward spring-cloud, spring-cloud-stream, kafka, and polyglot persistence (isolated database per microservice). </p>&#xA;&#xA;<p>I have a question about how messaging via kafka is typically done in a microservice architecture. We're planning to have a coordination layer between the set of microservices and our client applications, which will coordinate activities across different microservices and isolate clients from changes to microservice APIs. Most of the stuff we've read about using spring-cloud-stream and kafka indicate that we should use streams at the coordination layer (source) for resource change operations (inserts, updates, deletes), with the microservice being one consumer of the messages. </p>&#xA;&#xA;<p>Where I've been having trouble with this is inserts. We make heavy use of database-assigned identifiers (identity columns/auto-increment columns/sequences/surrogate keys), and they're usually assigned as part of a post request and returned to the caller. The coordination layer may be saving multiple things using different microservices and often needs the assigned identifier from one insert before it can move on to the next operation. Using messaging between the coordination layer and microservices for inserts makes it so the coordination layer can't get a response from the insert operation, so it can't get the assigned identifier that it needs. Additionally, other consumers on the stream (i.e. consumers that publish the data to a data warehouse) really need the message to contain the assigned identifier.</p>&#xA;&#xA;<p>How are people dealing with this problem? Are database-assigned identifiers an anti-pattern in microservices? Should we expose separate microservice endpoints that return database-assigned identifiers so that the coordination layer can make a synchronous call to get an identifier before calling the asynchronous insert? We could use UUIDs but our DBAs hate those as primary keys, and they couldn't be used as an order number or other user-facing generated ids.</p>&#xA;"
36705199,Lock a Service-Bus Queue and prevent others from accessing it,2016-04-18 22:12:03,<c#><azureservicebus><microservices>,4,541,5,1.0,3,"<p>I have multiple queues that multiple clients insert messages into them.</p>&#xA;&#xA;<p>On the server side, I have multiple micro-services that access the queues and handle those messages. I want to lock a queue whenever a service is working on it, so that other services won't be able to work on that queue.</p>&#xA;&#xA;<p>Meaning that if service A is processing a message from queue X, no other service can process a message from that queue, until service A has finished processing the message. Other services can process messages from any queue other than X.</p>&#xA;&#xA;<p>Does anyone has an idea on how to lock a queue and prevent others from accessing it? preferably the other services will receive an exception or something so that they'll try again on a different queue.</p>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>Another way can be to assign the queues to the services, and whenever a service is working on a queue no other service should be assigned to the queue, until the work item was processed. This is also something that isn't easy to achieve.</p>&#xA;"
42836979,Can same dyno run multiple different processes?,2017-03-16 14:31:27,<amazon-web-services><heroku><microservices>,3,373,0,0.0,3,"<p>I got a question regarding heroku architecture. I am creating small app running as microservices (not a lot of - about 4-6 microservices). The point is, that I would like to get this app available 24/7, so free dyno hours are not enough for me.</p>&#xA;&#xA;<p>I saw that if I will expand to <code>hobby</code> plan I would get something what heroku calls <code>10 Process Types</code>. Here my question comes: </p>&#xA;&#xA;<p>Can I run another microservice on each of that process (web), or heroku gives me ability only to install one web process per dyno, and given <code>10 process types</code> are for scaling my app? In other words, If i need 6 microservices running 24/7 should I buy 6 hobby dynos?</p>&#xA;"
50989454,Python asyncio Protocol behaviour with multiple clients and infinite loop,2018-06-22 13:48:22,<python-3.x><server><client-server><microservices><python-asyncio>,1,105,0,1.0,3,"<p>I'm having difficulty understanding the behaviour of my altered echo server, which attempts to take advantage of python 3's <code>asyncio</code> module.</p>&#xA;&#xA;<p>Essentially I have an infinite loop (lets say I want to stream some data from the server to the client indefinitely whilst the connection has been made) e.g. <code>MyServer.py</code>:</p>&#xA;&#xA;<pre class=""lang-py prettyprint-override""><code>#! /usr/bin/python3&#xA;import asyncio&#xA;import os&#xA;import time&#xA;&#xA;class MyProtocol(asyncio.Protocol):&#xA;&#xA;    def connection_made(self, transport):&#xA;        peername = transport.get_extra_info('peername')&#xA;        print('Connection from {}'.format(peername))&#xA;        self.transport = transport&#xA;&#xA;    def connection_lost(self, exc):&#xA;        asyncio.get_event_loop().stop()&#xA;&#xA;    def data_received(self, data):&#xA;        i = 0&#xA;        while True:&#xA;            self.transport.write(b'&gt;&gt; %i' %i)&#xA;            time.sleep(2)&#xA;            i+=1&#xA;&#xA;loop = asyncio.get_event_loop()&#xA;coro = loop.create_server(MyProtocol, &#xA;    os.environ.get('MY_SERVICE_ADDRESS', 'localhost'), &#xA;    os.environ.get('MY_SERVICE_PORT', 8100))&#xA;server = loop.run_until_complete(coro)&#xA;&#xA;try:&#xA;    loop.run_forever()&#xA;except:&#xA;    loop.run_until_complete(server.wait_closed())&#xA;finally:&#xA;    loop.close()&#xA;</code></pre>&#xA;&#xA;<p>Next when I connect with <code>nc ::1 8100</code> and send some text (e.g. ""testing"") I get the following:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;*** Connection from('::1', 58503, 0, 0) ***&#xA;testing&#xA;&gt;&gt; 1&#xA;&gt;&gt; 2&#xA;&gt;&gt; 3&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Now when I attempt to connect using <code>nc</code> again, I do not get any welcome message and after I attempt to send some new text to the server I get an endless stream of the following error:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;Is there anybody out there?&#xA;socket.send() raised exception&#xA;socket.send() raised exception&#xA;...&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Just to add salt to the wound the <code>socket.send() raised exception</code> message continues to spam my terminal until I kill the python server process...</p>&#xA;&#xA;<p>As I'm new to web technologies (been a desktop dinosaur for far too long!), I'm not sure why I am getting the above behaviour and I haven't got a clue on how to produce the intended behaviour, which loosely looks like this:</p>&#xA;&#xA;<ol>&#xA;<li>server starts</li>&#xA;<li>client 1 connects to server</li>&#xA;<li>server sends welcome message to client&#xA;4  client 1 sends an arbitrary message</li>&#xA;<li>server sends messages back to client 1 for as long as the client is connected</li>&#xA;<li>client 1 disconnects (lets say the cable is pulled out)</li>&#xA;<li>client 2 connects to server</li>&#xA;<li>Repeat steps 3-6 for client 2</li>&#xA;</ol>&#xA;&#xA;<p>Any enlightenment would be extremely welcome!</p>&#xA;"
38106036,Documenting a message bus API?,2016-06-29 17:07:47,<c#><json><documentation><microservices><netmq>,1,337,0,1.0,3,"<p>I've been searching for the past couple of days for some way to document the API for a microservices architecture I'm working on.  First, I'll give a very quick description of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Written in C#, .NET 4.6.1</li>&#xA;<li>Using NetMQ with x-pub/x-sub proxy as a ""message broker""</li>&#xA;<li>All communication is plain C# objects serialized to JSON</li>&#xA;<li>Some clients are JavaScript in the browser, others are .NET applications</li>&#xA;</ul>&#xA;&#xA;<p>The short of it is that I'd like to know how other people document the models that are published to their message bus.  I've seen quite a few projects (like Swagger) that help document REST calls, but we're not using REST.  Our application is almost entirely event-based with pub-sub messaging using JSON.</p>&#xA;&#xA;<p>My first thought was to document the JSON with JSON-Schema and use a tool to convert that to nicely-formatted API docs.  That would probably work okay, but what bothers me is that there don't seem to be any tools to automate the schema generation as part of a build process.  If our models diverge from the API documentation, I want it to be a build error.  Even better, if there was some way to auto-generate the basic documentation as part of the build process, the docs could be kept in sync.</p>&#xA;&#xA;<p>How do you guys do it?  The lack of documentation tools specific to a message bus architecture in favor of REST is making me question our decision to use a messaging architecture based on message queues.  :)</p>&#xA;"
38070572,How to architecture Microservice & OpenID connect?,2016-06-28 08:10:32,<microservices><openid-connect><oauth2>,1,1235,0,1.0,3,"<p>We have three microservices: microA, microB &amp; microC.</p>&#xA;&#xA;<ul>&#xA;<li>microA &amp; microB are powering product 1.</li>&#xA;<li>microA &amp; microC are powering product 2.</li>&#xA;</ul>&#xA;&#xA;<p>Obviously, we would need a security layer, in our case implementing an ""OpenID Connect"" provider fits well with the business needs. We add to the stack the OpenID provider.</p>&#xA;&#xA;<p>The user/rights management is quite easy &amp; natural: we associate the OpenId identifier of the user on each microservices to a subset of rights:</p>&#xA;&#xA;<p>For example on the service microA, we store that the user OpenID XXX can do this and that. it's isolated on the microservice level. Respect the boundaries of our context. Fine.</p>&#xA;&#xA;<p>When the user login with OpenID on product1, we grant an access token to the user + an Id token.</p>&#xA;&#xA;<p>The situation becomes more complex when product1 expose an API that third-party use.</p>&#xA;&#xA;<p>Now, let say that my user comes to the third-party webapp and is prompted to login &amp; allow the third-party to get some rights on product1 API.</p>&#xA;&#xA;<p>If I understand correctly OpenID connect, it's all about authentication over OAuth2, but how do we handle classic OAuth2 scope management then?</p>&#xA;&#xA;<p>The best scenario I have found is:</p>&#xA;&#xA;<ol>&#xA;<li><p>make the whole OpenID connect to have the authentication info </p></li>&#xA;<li><p>and then make another full OAuth2 process to another Authorization server to ask the user to grant some scopes to the third party?</p></li>&#xA;</ol>&#xA;&#xA;<p>which means that on the third-party:</p>&#xA;&#xA;<ul>&#xA;<li>the user will be prompted to login on the OpenID Provider </li>&#xA;<li>then redirected and prompted to accept the scope requested</li>&#xA;</ul>&#xA;&#xA;<p>Is that correct? If yes, OAuth2 server flow is like 4 HTTP requests to the end user, so performing it twice is like executing eight requests to get the Authentication + Authorization flow done. Seems too massive.</p>&#xA;"
38168658,Multiple microservices and database associations,2016-07-03 09:40:56,<database><rest><spring-boot><microservices>,2,480,0,0.0,3,"<p>I have a question concerning microservices and databases. I am developing an application: a user sees a list of countries and can click through it so he can see a list of attractions of that country. I created a country-service, auth-service (contains users for oAuth2) and an attraction-service. Each service has its own database. I mapped the association between an attraction and its country by the <strong>iso code</strong> (for example: BE = belgium): /api/attraction/<strong>be</strong>.</p>&#xA;&#xA;<p>The approach above seems to work but I am a bit stuck with the following: a user must be able to add an attraction to his/her list of favorites, but I do not see how that's possible since I have so many different databases. </p>&#xA;&#xA;<p>Do I create a favorite-service, do I pass id's (I don't think I should do this), what kind of business key can I create, how do I associate the data in a correct way...?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
38023093,Refer to another service/task running in same ECS cluster,2016-06-24 22:43:57,<docker><microservices><amazon-ecs>,1,237,0,1.0,3,"<p>I know how to refer to ""services"" from within the same task. But how can I refer to an essential task from within another task definition?&#xA;For example:</p>&#xA;&#xA;<ul>&#xA;<li>Service ""mesage-broker"" is running task rabbitmq.&#xA;&#xA;<ul>&#xA;<li>Service ""user-api"" is running task user-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;<li>Service ""order-api"" is running task order-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;</ul></li>&#xA;</ul>&#xA;"
38224152,How to maintain repositories into a single repository,2016-07-06 12:34:37,<git><docker><docker-compose><microservices>,1,65,1,1.0,3,"<p>I have a repository for each micro-services ('A', 'B', ..). The structure of a repository looks like :</p>&#xA;&#xA;<pre><code>A&#xA;|-dockerfile&#xA;|-src&#xA;  |-Java&#xA;  |-Groovy&#xA;</code></pre>&#xA;&#xA;<p>Since all of these repositories belongs to a project called 'WholeProject', I want to maintain a repository 'WholeProject' which looks like :</p>&#xA;&#xA;<pre><code>WholeProject&#xA;|-docker-compose.yml&#xA;|-ÂµS&#xA;  |-A&#xA;  |-B&#xA;  |-..&#xA;</code></pre>&#xA;&#xA;<p>So I could easily maintain a docker-compose file and a repository that contains all the revelant things about my project.</p>&#xA;&#xA;<p>Is this a good idea ? How can I perform that ?</p>&#xA;"
38125926,Run Google App Engine application with microservice,2016-06-30 14:20:04,<python><google-app-engine><publish-subscribe><microservices>,1,515,2,3.0,3,"<p>I have a one big monolith application, and now its time to separate some modules to micro services!&#xA;I read a lot about pub/sub and microservices in Google docs, but can't find answers to my questions:</p>&#xA;&#xA;<ol>&#xA;<li>How app.yaml file looks like for my module(microservice)?</li>&#xA;<li>How app.yaml looks like for my app?(I mean, with microservice)</li>&#xA;<li>Where I need to declare this module - in application app.yaml or in both app.yaml?</li>&#xA;<li>How can I use single datastore with my app and my module?</li>&#xA;</ol>&#xA;&#xA;<p>My app.yaml now looks like:</p>&#xA;&#xA;<pre><code>application: my-application&#xA;version: 1&#xA;runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;</code></pre>&#xA;&#xA;<p>with some credentials and libs.</p>&#xA;&#xA;<p>Waiting for your answers!</p>&#xA;"
39268365,Nested GraphQL servers / microservices,2016-09-01 09:56:38,<microservices><graphql><apollo-server>,1,291,1,1.0,3,<p>I would like to replace all my REST APIs with GraphQL (apollo-server preferred). It's clear to me how to use GraphQL in monolithic apps but it's not clear how to do it for microservices.</p>&#xA;&#xA;<p>The main API server consists of multiple microservices where each microservice exposes its own REST API through which the central API server communicates with it. I would like to replace all these REST APIs with GraphQL thus I would get microservices as nested GraphQL servers communicating with each other through GraphQL instead of REST.</p>&#xA;&#xA;<p>The problem that I'm facing is how to easily build a GraphQL query string for microservices based on the received attributes in the resolver of the main GraphQL server. There is no way to tell GraphQL to return all the fields for microservice. The best way would be to simple forward just a part of a the main query further to a microservice. </p>&#xA;&#xA;<p>Any ideas? Do you think that REST is still more appropriate for microservices then GraphQL?</p>&#xA;
39305118,Event publisher for ASP.NET Web Api,2016-09-03 08:57:40,<c#><asp.net><asp.net-web-api><domain-driven-design><microservices>,2,1891,3,2.0,3,"<p>I have started to work with micro-services and I need to create an event publishing mechanism.</p>&#xA;&#xA;<p>I plan to use Amazon SQS. </p>&#xA;&#xA;<p>The idea is quite simple. I store events in the database in the same transaction as aggregates.&#xA;If user would change his email, event <code>UserChangedEmail</code> will be stored in the database.</p>&#xA;&#xA;<p>I also have event handler, such as <code>UserChangedEmailHandler</code>, which will (in this case) be responsible to publish this event to SQS queue, so other services can know that user changed email.</p>&#xA;&#xA;<p>My question is, what is the practice to achieve this? Should I have some kind of background timed process which will scan events table and publish events to SQS?&#xA;Can this be process within WebApi application (preferable), or should this be a separate a process?</p>&#xA;&#xA;<p>One of the ideas was to use Hangfire, but it does not support cron jobs under a minute.</p>&#xA;&#xA;<p>Any suggestions?</p>&#xA;&#xA;<p><strong>EDIT:</strong> </p>&#xA;&#xA;<p>As suggested in the one of the answers, I've looked in to NServicebus. One of the examples on the <a href=""http://docs.particular.net/samples/step-by-step/"" rel=""nofollow"">NServiceBus page</a> shows core of my concern.</p>&#xA;&#xA;<p>In their example, they create a log that order has been placed. What if log or database entry is successfully commited, but publish breaks and event never gets published?</p>&#xA;&#xA;<p>Here's the code for the event handler:</p>&#xA;&#xA;<pre><code>public class PlaceOrderHandler :&#xA;    IHandleMessages&lt;PlaceOrder&gt;&#xA;{&#xA;    static ILog log = LogManager.GetLogger&lt;PlaceOrderHandler&gt;();&#xA;    IBus bus;&#xA;&#xA;    public PlaceOrderHandler(IBus bus)&#xA;    {&#xA;        this.bus = bus;&#xA;    }&#xA;&#xA;    public void Handle(PlaceOrder message)&#xA;    {&#xA;        log.Info($""Order for Product:{message.Product} placed with id: {message.Id}"");&#xA;        log.Info($""Publishing: OrderPlaced for Order Id: {message.Id}"");&#xA;&#xA;        var orderPlaced = new OrderPlaced&#xA;        {&#xA;            OrderId = message.Id&#xA;        };&#xA;        bus.Publish(orderPlaced); &lt;!-- my concern&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
39126827,"Laravel passport, Oauth and microservices",2016-08-24 14:58:30,<laravel><oauth><oauth-2.0><microservices>,2,1351,0,0.0,3,"<p>I am having a difficulty in terms of architecture and wondering if someone has some insights.</p>&#xA;&#xA;<p><strong>The plan</strong></p>&#xA;&#xA;<ul>&#xA;<li>I will have multiple microservices (different laravel projects, catalog.microservice.com, billing.microservice.com) each providing an API. </li>&#xA;<li>On top of these will be an angular fronted consuming those APIs. </li>&#xA;<li>I will have another micro service (passport.microservice.com) for auth now thanks to laravel 5.3 passport this is even easier.  </li>&#xA;</ul>&#xA;&#xA;<p><strong>The flow:</strong></p>&#xA;&#xA;<ul>&#xA;<li>User goes to catalog.microservice.com </li>&#xA;<li>user need to authenticate and provides a user and password</li>&#xA;<li>request is made by angular (aka client) to passport.microservice.com through password grand type to get an authorization token</li>&#xA;<li>now that I have a token I am authorized to call a resource from catalog.microservice.com</li>&#xA;<li>catalog.microservice.com needs to know if the token is valid and makes a request (some kind of middleware?) to passport.microservice.com</li>&#xA;<li>passport.microservice.com returns the user, scope etc.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is this a good approach?</li>&#xA;<li>The token validation in catalog.microservice.com can be a middleware? </li>&#xA;</ul>&#xA;"
39044130,Java EE Microprofile,2016-08-19 16:47:42,<java><microservices>,2,1358,0,0.0,3,<p>I know it could be a pretty vague topic but please can someone explain it in plain English. I've read some articles regarding the trending topic java EE's 'microprofile' but was not able to clearly understand its purpose.</p>&#xA;&#xA;<p>My understanding in this emerging concept is that java community finds way to reshape the Java EE model to become a microservices friendly framework or platform. </p>&#xA;&#xA;<p>If we can already create a distributed microservice application in few minutes using spring boot or other API / library then why do we need microprofile?</p>&#xA;
39088230,How to ensure thrift objects are backward compatible?,2016-08-22 20:31:30,<java><thrift><microservices>,1,643,0,0.0,3,"<p>We're currently using <strong>thrift</strong> for developing our micro-services.&#xA;When I recently came across this below issue.</p>&#xA;&#xA;<p>Assume below is the thrift contract for Summary Object and there is an API which gets and updates summary using the summary object passed.</p>&#xA;&#xA;<p><strong>Version - 1.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<p>Now let's say there are 5 services which are using this <strong>1.0</strong> contract of Summary.<br/>&#xA;In the next release we add another Object called a <strong>list of summaryvalues</strong>.</p>&#xA;&#xA;<p>So the new contract would look like</p>&#xA;&#xA;<p><strong>Version - 2.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost,&#xA;    3: optional list&lt;i32&gt; summaryValues&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>So when this below list is populated, we save the list of values <code>summaryValues</code> aganist that <code>summaryId</code>.</li>&#xA;<li>And when the client sends this list as <code>null</code> we remove the existing values saved for that 'summaryId`.</li>&#xA;</ol>&#xA;&#xA;<p>Now the <strong>problem</strong> occurs when other services which are using <strong>OLDER</strong> version of the thrift contract (<strong>Version 1.0</strong>) try to call getSummary and updateSummary.<br/>&#xA;The intention of the Older Client by calling updateSummary was to set another value for <code>summaryCost</code>. However since this client doesn't contain the object <code>summaryValues</code> it sends the Summary object with <code>summaryValues</code> as null to Server.<br/></p>&#xA;&#xA;<p><strong>This is resulting in the Server removing all existing values of <code>summaryValues</code> for that <code>summaryId</code>.</strong></p>&#xA;&#xA;<p>Is there a way to handle this in thrift? The isSet() Methods don't work here, as they try to perform a simple null check.<br/>&#xA;Every time we release a newer client with modification to existing objects, we're having to forcefully upgrade client versions of other servers even though the change is not related to them.</p>&#xA;"
38975554,Multiple FabricTransportServiceRemotingListeners in a Single Service,2016-08-16 12:54:40,<microservices><azure-service-fabric>,1,434,0,0.0,3,"<p>I'd like to be able to expose multiple FabricTransportServiceRemotingListeners from a single Stateless service inside my cluster. I've attempted to register the listeners as follows:</p>&#xA;&#xA;<pre><code>    protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;    {&#xA;        return new[]&#xA;        {&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryCommandService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryCommandEndpoint""&#xA;                    }), ""SqlCategoryCommandService""),&#xA;&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryQueryService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryQueryEndpoint""&#xA;                    }), ""SqlCategoryQueryService"")&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>However when I make a proxy to the <code>ICategoryQueryService</code> which is implemented by the second listener this exception regarding an unimplemented Interface method is thrown leading me to believe that the first listener is incorrectly responding to all Proxy calls.</p>&#xA;&#xA;<pre><code>""Interface id '740213831' is not implemented by object 'TaxonomyService.SqlCategoryCommandService'""&#xA;</code></pre>&#xA;&#xA;<p>I'm creating the Proxy using the following code:</p>&#xA;&#xA;<pre><code>var proxy = ServiceProxy.&#xA;     Create&lt;ICategoryQueryService&gt;(new Uri(""fabric:/Taxonomy/TaxonomyService""));&#xA;</code></pre>&#xA;&#xA;<p>Is the scenario I've described possible?</p>&#xA;"
39020065,Marathon: How to specify environment variables in args,2016-08-18 13:54:03,<microservices><mesos><marathon><consul>,1,2340,1,0.0,3,"<p>I am trying to run a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<p>With Marathon I have the following JSON script:</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"": ""consul-agent"",&#xA;    ""instances"": 10,&#xA;    ""constraints"": [[""hostname"", ""UNIQUE""]],&#xA;    ""container"": {&#xA;        ""type"": ""DOCKER"",&#xA;        ""docker"": {&#xA;            ""image"": ""consul"",&#xA;            ""privileged"": true,&#xA;            ""network"": ""HOST""&#xA;        }&#xA;    },&#xA;    ""args"": [""agent"",""-bind"",""$MESOS_SLAVE_IP"",""-retry-join"",""$MESOS_MASTER_IP""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, it seems that marathon treats the <code>args</code> as plain text.</p>&#xA;&#xA;<p>That's why I always got errors:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Error starting agent: Failed to start Consul client: Failed to start lan serf: Failed to create memberlist: Failed to parse advertise address!&#xA;</code></pre>&#xA;&#xA;<p>So I just wonder if there are any workaround so that I can start a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>Thanks @janisz for the link.</p>&#xA;&#xA;<p>After taking a look at the following discussions:</p>&#xA;&#xA;<ul>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/3416"" rel=""nofollow"">#3416</a>: <em>args in marathon file does not resolve env variables</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/2679"" rel=""nofollow"">#2679</a>: <em>Ability to specify the value of the hostname an app task is running on</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1328"" rel=""nofollow"">#1328</a>: <em>Specify environment variables in the config to be used on each host through REST API</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1828"" rel=""nofollow"">#1828</a>: <em>Support for more variables and variable expansion in app definition</em></p></li>&#xA;</ul>&#xA;&#xA;<p>as well as the Marathon documentation on <a href=""https://mesosphere.github.io/marathon/docs/task-environment-vars.html"" rel=""nofollow"">Task Environment Variables</a>.</p>&#xA;&#xA;<p>My understanding is that:</p>&#xA;&#xA;<ul>&#xA;<li>Currently it is not possible to pass environment variables in args</li>&#xA;<li>Some post indicates that one could pass environment variables in <code>""cmd""</code>. But those environment variables are Task Environment Variables provided by Marathon, not the environment variables on your host machine.</li>&#xA;</ul>&#xA;&#xA;<p>Please correct if I was wrong.</p>&#xA;"
37243939,How to initialize a postgres database tables in microservice architecture with node running in docker,2016-05-15 21:39:56,<node.js><postgresql><docker><containers><microservices>,1,460,1,1.0,3,"<p>What is the best practice for initializing a node microservice's tables in a postgres database ? Should it be on service start ?</p>&#xA;&#xA;<p>I'm thinking of copying all the .sql files to the container (during docker build) + install psql into that container, and only run the .sql files during docker run before npm start. Does this make sense ?</p>&#xA;&#xA;<p>I need to consider the fact that soon I will need to manage upgrading the database's tables for the microservice as well.</p>&#xA;"
44124914,How to deploy multiple version of an application in production for microservice based application,2017-05-23 02:40:41,<api><amazon-web-services><elastic-beanstalk><microservices><production-environment>,4,920,0,3.0,3,"<p><br/>&#xA;Is it possible to have multiple versions of service(s) deployed in production at the same time. From my assumption, this should be pretty common pattern for microservice/api based projects or mobile projects. I want to know how do you do it and what are common pattern in industry for this kind of problems. It would be helpful if your answers around AWS environment or Kubernetes environment.&#xA;<br/>Thanks in Advance.</p>&#xA;"
44183595,Java - Kubernetes find services by label,2017-05-25 14:54:26,<java><spring-boot><kubernetes><spring-cloud><microservices>,2,436,0,3.0,3,"<p>I'm trying to develop a sample application using spring cloud and minikube which consist of 3 spring boot applications.</p>&#xA;&#xA;<p>The first two are two different application (servers) which have the same endpoint but different functionality, and the third one is a client used to integrates the two other applications into one single exposed api.</p>&#xA;&#xA;<p>I managed to deploy all three applications in minikube and managed to develop the full stack and make them communicate between each other, but now I want to go a step further and make the discovery of the two servers automatically, without hard coding the service names.</p>&#xA;&#xA;<p>I deployed the two servers in minikube using the same label and would like to find something so that the client is able to find the services related to the two server apps automatically. This will allow expanding the application easily, so that when I add a new server to the stack the client will find it and expose it without need of any change.</p>&#xA;&#xA;<p>Using Netflix Eureka this can be easily achieved by using something like </p>&#xA;&#xA;<pre><code>discoveryClient.getInstances(""service-name"").forEach((ServiceInstance s)&#xA;</code></pre>&#xA;&#xA;<p>But I do no want to add an extra eureka server to the list of microservices since we are going to use kubernetes.</p>&#xA;&#xA;<p>Is there any library which gives this functionality for kubernetes?</p>&#xA;"
38507565,"Connect ""MicroService Gateway"" with ""UAA Server"" Jhipster 3.5.0",2016-07-21 14:53:24,<jhipster><microservices>,4,1731,4,0.0,3,"<p>I created a UAA Server:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? [BETA] JHipster UAA server (for microservice OAuth2 authentication)&#xA;</code></pre>&#xA;&#xA;<p>And I created a Microservicio Gateway:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? Microservice gateway&#xA;...&#xA;? (6/16) What is the folder path of your UAA application?. ../elseruaa&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li>I created the docker containers, in ""docker-compose"", and creates well.</li>&#xA;<li>I have to add some extra configuration on the gateway to work with the server UAA?</li>&#xA;<li><p>I get the following error trace in the container gateway:</p>&#xA;&#xA;<p><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration.setFilterChainProxySecurityConfigurer(org.springframework.security.config.annotation.ObjectPostProcessor,java.util.List) throws java.lang.Exception; nested exception is org.springframework.beans.factory.BeanExpressionException: Expression parsing failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.springframework.security.oauth2.provider.token.TokenStore org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration.tokenStore; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tokenStore' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.TokenStore]: Factory method 'tokenStore' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jwtAccessTokenConverter' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter]: Factory method 'jwtAccessTokenConverter' threw exception; nested exception is java.lang.IllegalStateException: No instances available for elseruaa...</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you very much for your help.</p>&#xA;"
42199241,What is an efficient way to communicate in microservices architecture,2017-02-13 08:03:56,<node.js><web-services><amazon-ec2><microservices>,3,319,0,0.0,3,<p>I am using Node.js and a REST based light weight web service to communicate between servers. i want to know if there is another more efficient way to communicate between servers?&#xA;I am using ec2 instances in a vpn.</p>&#xA;
42332737,Exchange reference token for JWT - downstream microservices authorization,2017-02-19 20:52:59,<jwt><microservices><identityserver4>,2,743,0,2.0,3,"<p>I am currently creating a new application based on a Microservices architecture, with authentication provided by Identity Server 4. </p>&#xA;&#xA;<p>Following lots of research and also setting up proof of concepts, I have Identity Server setup to secure the API's and a native application successfully accessing these services using tokens.</p>&#xA;&#xA;<p>Initially the client was issued an access token which was used to access the API's, I have however now switched this out to use reference tokens.  Now, onto the issue!</p>&#xA;&#xA;<p>The approach I would like to take here is to adopt a Microservices gateway, which receives a reference token and then turns this into a JWT for inclusion in any requests to the downstream microservices.  Within the Gateway, how can I ""exchange"" the inbound reference token for a JWT? Is there something within Identity Server that can assist here? Or do I need to use the introspection endpoint, sending in the reference token and retrieving the claims to construct a JWT within the gateway service for passing in the Authorization header to all downstream services?</p>&#xA;&#xA;<p>If there is any further information that I can provide to help with understanding the goal of the architecture, please just let me know.</p>&#xA;"
47007159,Looking for JWT Auth microservice example,2017-10-30 01:54:51,<node.js><authorization><jwt><microservices>,1,982,0,1.0,3,"<p>I am wanting to build a authentication/authorization service using NodeJS, Mongo, and JWT.  This service would be a micro-service that handles requests not only from my API Gateway before allowing requests, but from other services that might want to check auth and roles. I am assuming that all other services will use this Auth Service to validate the JWT as well as roles, etc.</p>&#xA;&#xA;<p>Hopefully this diagram better explains what I am looking for.&#xA;<a href=""https://i.stack.imgur.com/NDuCY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NDuCY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Can anyone point me to a resource that might help me learn how to do this with NodeJS?</p>&#xA;"
46920685,How to do canary releases and dynamic routing with Netflix Zuul?,2017-10-24 21:55:19,<spring-boot><microservices><netflix-zuul><canary-deployment><dynamic-routing>,1,222,0,1.0,3,"<p>We faced with the problem that we need to do such thing as dynamic routing and canary releases. So, for example, we deploy microservice <code>microservice-1</code>. Then, when someone finished a big feature we want to deploy it as a microservice <code>microservice-1.1</code>.</p>&#xA;&#xA;<h3>Question</h3>&#xA;&#xA;<p>Is it possible to dynamically reroute requests using information, for example, from Headers, and route to the microservice version <code>microservice-1.1</code> instead on <code>microservice-1</code>?</p>&#xA;&#xA;<p>For example, someone needs this feature and he will modify/add specific Header and for all requests, he will use new <code>microservice-1.1</code>. And if that Header is missing then the current microservice-1 version should be used.</p>&#xA;&#xA;<p>For service discovery, I am using Eureka. Right now I am looking at <a href=""https://linkerd.io/"" rel=""nofollow noreferrer"">linkerd</a> but there is no support for Eureka and I am working on it right now. Of course, if it is possible to do it using Zuul that would be great. Please advise where to look at. </p>&#xA;"
43814764,Testing microservices?,2017-05-05 22:46:35,<testing><go><integration-testing><microservices>,3,437,1,0.0,3,<p>I know this question is a little subjective but I am lost on what to do here. At the moment I am using Go + Go-kit to write some microservices. I'd like to test the endpoints of these microservices in an integration test type fashion but I am unsure how to go about it. The only thing I can think of is to have shell scripts that hit the endpoints and check for responses. But this seems like kludge and not a real smart practice. I feel like there should be a better way to do this. Does anyone have any suggestions?</p>&#xA;
34020234,Communication between Node.js microservices,2015-12-01 12:15:03,<json><node.js><express><architecture><microservices>,1,1519,2,0.0,3,"<p>I'm creating an application with Node.js using microservices architecture. I'm trying to find the best way of communication between nodes. I have a Java background so the best option I can imagine is something like SOAP, where you create a proxy object and by calling it's method a request to a remote node would be made via http.</p>&#xA;&#xA;<p>Currently I only see an option of direct calls like </p>&#xA;&#xA;<pre><code>http.get(""remote-node/api/method1"", function(res) {&#xA;}).on('error', function(e) {&#xA;  console.log(""Got error: "" + e.message);&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However I don't think it's convenient. Are there better approaches?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48134800,Deploying Go apps with micro-service architecture in containers or not in containers?,2018-01-07 06:15:06,<go><kubernetes><microservices><devops><docker-container>,2,331,3,1.0,3,"<p>I'm new to DevOps specifically using golang and microservice architecture.</p>&#xA;&#xA;<p>I'm wondering if go applications should or should not be deployed in containers (Docker). In this case, I have a system built with micro-service architecture. For example here, I have 2 web services, A and B. Also I have another web server acts as a gateway in front of those two.</p>&#xA;&#xA;<p>Both A and B need access for a database, MySQL for example. A handles table A, and B handles table B.</p>&#xA;&#xA;<p>I know that in Go, source codes are compiled into a single executable binary file. And because I have 3 services here, I have 3 binaries. All three run as web server exposing JSON REST API.</p>&#xA;&#xA;<p>My questions are these:</p>&#xA;&#xA;<ul>&#xA;<li><p><strong>Can I deploy these servers together in one host running on different ports?</strong>&#xA;If my host get an IP x.x.x.x for example, my gateway can run in x.x.x.x:80, A in port 81, and B in port 82 for example. A and B will talk to a MySQL server somewhere outside or maybe inside the same host. Is this a good practice? Can Continuous Deployment works with this practice?</p></li>&#xA;<li><p><strong>Why should I deploy and run those binaries inside containers like Docker?</strong>&#xA;I know that since its release few years ago, Docker had found its way to be integrated inside a development workflow easily. But of course using Docker is not as simple as just compiling the code into a binary and then moving it to a deployment server. Using Docker we have to put the executable inside the container and then move the container as well to the deployment server.</p></li>&#xA;<li><p><strong>What about scalibility and high availability without using Docker?</strong>&#xA;Can I just replicate my services and run them all at once in different hosts using a load balancer? This way I should deploy A, B, and gateway in one host, and another A, B, and gateway in another host, then setup load balancer in front of them. A, B, and the gateway runs in port 80, 81, and 82 respectively. This way I could have  thousands of nodes in a form of VMs or LXD containers maybe, spread accross hundreds of bare metals, deployed with a simple bash script and ssh, or Ansible if things get complex. Yes or no?</p></li>&#xA;<li><p><strong>And what about the scalability and availability of using Docker?</strong>&#xA;Should I just put all my services inside containers and manage them with something like Kubernetes to achieve high availability? Doing this does add overhead, right? Because the team will have to learn new technology like Kubernetes if they haven't known it yet.</p></li>&#xA;<li><p>Can you give me an example of some best practices of deploying golang services?</p></li>&#xA;</ul>&#xA;"
46115104,Hazelcast cluster: serialization and replication issue,2017-09-08 11:08:51,<java><microservices><hazelcast><distributed-cache><hazelcast-imap>,1,198,0,2.0,3,"<p>Our application consists of several micro services. Each microservice has a configuration for its own hazelcast instance. All hazelcast instances form a cluster with distributed data. Hazelcast replicated map is used as a way to replicate data objects (DTOs include several fields) between those micro services. Microservices are hosted on AWS.</p>&#xA;&#xA;<p>There was a problem with data object serialization that's why we created a separated project with custom serialization config. All data objects (java classes) we want to replicate are listed in this config code. Artifact built from this very configuration project is included in each micro service as a maven dependency. This helps to solve serialization problem.</p>&#xA;&#xA;<p>This solution led us to the new problem what appear if it's needed to add new data object. Firstly we should add this very data object to config project, then rebuild this project. After that, we should rebuild all micro services with updated dependency and redeploy. And if at least one of micro services wasn't rebuilt there will be a serialization error because of this very micro service hazelcast instance doesn't know how to serialize new data object. The process of rebuilding and redeploying all application isn't so convenient for us.</p>&#xA;&#xA;<p>Please, share your experience! Is there any way to make it easier? </p>&#xA;"
46069921,Is there a difference between API gateway pattern and BFF?,2017-09-06 08:07:33,<microservices><netflix-zuul><api-gateway>,1,1333,1,1.0,3,<p>My understanding is that API gateway pattern is like a proxy to all microservices. So client calls the API gateway which takes care of further routing. BFF is a specific case of API gateway pattern where we have a routing mechanism for each type of client. Am I right?</p>&#xA;
41853686,Using RabbitMQ in for communication between different Docker container,2017-01-25 14:06:41,<docker><rabbitmq><message-queue><microservices>,2,332,0,0.0,3,"<p>I want to communicate between 2 apps stored in different docker containers, both part of the same docker network. I'll be using a message queue for this ( RabbitMQ )</p>&#xA;&#xA;<p>Should I make a 3rd Docker container that will run as my RabbitMQ server, and then just make a channel on it for those 2 specific containers ? So that later on I can make more channels if I need for example a 3rd app that needs to communicate with the other 2?</p>&#xA;&#xA;<p>Regards!</p>&#xA;"
41757509,How to setup Docker for a polyglot microservice-based application?,2017-01-20 06:38:13,<docker><docker-compose><dockerfile><microservices><docker-machine>,1,183,0,0.0,3,"<p>Working on a larger-than-usual project of mine, I am building an web application that will talk to several APIs of mine, each written in its own language. I use two databases, one being MariaDB and the second being Dgraph (graph database.)</p>&#xA;&#xA;<p>Here is my local director architecture:</p>&#xA;&#xA;<ul>&#xA;<li><strong>services</strong> - all my services&#xA;&#xA;<ul>&#xA;<li><strong>api</strong> - contains all my APIs&#xA;&#xA;<ul>&#xA;<li><strong>auth</strong> - contains my user auth/signup API&#xA;&#xA;<ul>&#xA;<li><strong>v1</strong> - contains my current (only) API version</li>&#xA;</ul></li>&#xA;<li><strong>trial</strong> - contains my an API of mine called <em>trial</em></li>&#xA;<li>etc...</li>&#xA;</ul></li>&#xA;<li><strong>application</strong> - contains the app users will interact with</li>&#xA;<li><strong>daemon</strong> - contains my programs that will run as daemons</li>&#xA;<li><strong>tools</strong> - contains tools (import data, scrapers, etc)</li>&#xA;</ul></li>&#xA;<li><strong>databases</strong> - to contain my two configs (MariaDB and Dgraph)</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/PewMe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PewMe.png"" alt=""Local File Structure""></a></p>&#xA;&#xA;<p>Because some components are written in PHP7-NGINX while others are in PYTHON-FLASK-NGINX, how can I do a proper Docker setup with that in mind? Each service, api, daemon and tool is independant and they all talk through their own REST-endpoints.</p>&#xA;&#xA;<p>Each has its own private github repository, and I want to be able to take each one and deploy it to its own server when needed.</p>&#xA;&#xA;<p>I am new to Docker and all the reading I do confuses me: should I create a docker-compose.yml for each service or one for the entire project? But each service is deployed separately so how does docker-compose.yml know that?</p>&#xA;&#xA;<p>Any pointers to a clean solution? Should I create a container for each service and in that container put NGINX, PHP or PYTHON, etc?</p>&#xA;"
41893494,Docker Swarm Mode routing mesh vs linkerd,2017-01-27 11:59:09,<docker><microservices><docker-swarm-mode><linkerd>,1,713,0,1.0,3,"<p>Is Docker Swarm Mode routing mesh a built-in substitute for linkerd routing mesh? In other words, is there still any reason to look into linkerd if there is an out-of-the-box solution?</p>&#xA;"
41914911,microservice based event store,2017-01-28 21:15:33,<microservices><cqrs><event-store><eventsource>,1,244,0,0.0,3,"<p>Unfamiliar with all the details of domain driven design, would it make sense  in a microservice architecture to think of each service as it's own domain and in turn build an event store per service?</p>&#xA;&#xA;<p>Not totally sure what the trade-offs might be from a single monolithic event store for the entire system. For example, more difficulty replaying conditions in the system or debugging cross service dependencies.</p>&#xA;"
41881610,Spring-Cloud Zuul breaks UTF-8 symbols in forwarded multipart request filename,2017-01-26 19:40:58,<spring-boot><utf-8><microservices><netflix-zuul><netflix-eureka>,1,770,1,1.0,3,"<p>this is first time for me on SO, so please be patient for my first question.</p>&#xA;&#xA;<p>I think i have some kind of configuration problem, but after a day of experiments i'm stuck. Our application is based on Spring-Cloud [Brixton release]. We have configuration like this: Portal (web application serving angular-based web-ui), which has zuul proxy with single route configured to our gateway service, like so:</p>&#xA;&#xA;<pre><code>zuul:&#xA;   ignoredServices: '*'&#xA;   prefix: /api&#xA;   routes:&#xA;       api-proxy:&#xA;          path: /**&#xA;          serviceId: api-gateway&#xA;</code></pre>&#xA;&#xA;<p>which has another Zuul configured and relays requests to inner bussiness logic services:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredServices: '*'&#xA;  routes:&#xA;     service1:&#xA;       path: /service1/**&#xA;       serviceId: service1&#xA;     service2:&#xA;       path: /service2/**&#xA;       serviceId: service2&#xA;</code></pre>&#xA;&#xA;<p>All this configuration is working with no problem.&#xA;The problem now that i am facing is with file upload multipart requests. To be more precise - those multipart requests, when file to be uploaded has non latin symbols (e.g. Ä…ÄÄ™Ä—Ä¯Å¡) from <code>UTF-8</code>. When request reaches service which has to deal with <code>@RequestPart MultipartFile file</code>, then <code>file.getOriginalFilename()</code> returns questionmarks in the places of aforementioned symbols. Now, i have tried to directly upload such file to such controller, and filename comes without questionmarks, that is, not broken, which suggests, that some bad interpretation/parsing of multipart request occurs somewhere in Zuul filters, when proxy relays incomming request.</p>&#xA;&#xA;<p>Maybe someone had similar experience with Zuul and can direct me some way to resolve this problem?</p>&#xA;"
35743527,Microservice with own UI with Spring and Thymleaf,2016-03-02 09:45:51,<spring><thymeleaf><microservices><ssi>,2,590,7,0.0,3,"<p>I have three web application microservices and one gateway that include the UI. So, what i want to do is to change the app's that every microservice has his own UI and the gateway should make server side includes. Im using Thymeleaf as template engine and do the includes like this: </p>&#xA;&#xA;<p><code>&lt;div th:replace=""http://localhost:8080/#/organizations""&gt;&lt;/div&gt;</code></p>&#xA;&#xA;<p>My Problem is that the CSS and JS files are not Included from the original localhost:8080 server rather from the server with includes the content localhost:9090.</p>&#xA;&#xA;<p>This is how i include the JS and CSS files at *:8080:</p>&#xA;&#xA;<p><code>&lt;script th:src=""@{webjars/jquery/$jquery.version$/jquery.min.js}""&lt;/script&gt;</code></p>&#xA;&#xA;<p>Hope you understand my problem and someone can help...</p>&#xA;"
51542197,Async Flows Design in Lagom or Microservices,2018-07-26 15:12:22,<domain-driven-design><microservices><lagom>,1,67,7,5.0,3,"<p>How to design asyn flows in Lagom ? </p>&#xA;&#xA;<p>Problem faced: In our product we have a Lead Aggregate which has a User Id (represents the owner of the lead), Now User has a limitation which says one user can have max of 10 Lead associated with this. We designed this by creating a separate Service ResourceManagement and when a User asks for Picking a Lead, we send a Command to LeadAggregate which generates a Event LeadPickRequested. On ProcessManager Listen to the event and asks for the Resource From ResourceManagement, on Success send Command to LeadAggregate - MarkAsPicked and on this send Push notification to the User that Lead is Picked but from building the UI perspective its very difficult and same cannot be done for exposing our API to third party. </p>&#xA;&#xA;<p>One Sol. we have done is when request is received on Service save a RequestID Vs Request Future . in Command Add the request Id and when the LeadAggregate finally change into Picked State or Picked Failure a PM listen to the event , checks if a RequestFuture is there for the request Id , then complete the future with correct response. This way it works as Sync API for the end User. </p>&#xA;&#xA;<p>Any Better Sol. for this</p>&#xA;"
44946517,Unable to get jhipster gateway home page,2017-07-06 10:34:22,<angular><jhipster><microservices>,2,390,1,0.0,3,<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in application-dev.yml)&#xA;There is no errors in console.</p>&#xA;&#xA;<p><code>index.html</code> completely loading may be routing is not working fine.</p>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is provided by yarn) </p>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other micro services applications.</p>&#xA;
44988481,Spring Cloud - how to allow access to endpoint for specific microservice only?,2017-07-08 16:42:24,<spring><oauth-2.0><microservices><spring-cloud>,2,286,4,1.0,3,"<p>I have simple microservice architecture:</p>&#xA;&#xA;<ul>&#xA;<li>edge service</li>&#xA;<li>service registry</li>&#xA;<li>auth service (I am using JWT and OAuth2)</li>&#xA;<li>user service</li>&#xA;<li>frontend and some core services</li>&#xA;</ul>&#xA;&#xA;<p>When the user tries to log in, the credentials are passing from edge service to auth service. Auth service fetches user's data from user service (using <strong>@FeignClient</strong>) and if username/password matches, it generates token. Nothing fancy about it.</p>&#xA;&#xA;<p>There a 'little' problem with this approach: the endpoint <code>/api/user/{username}</code> in user service, which is used by auth service to fetch user's data, might be used by any user to get any other user's data (password, roles etc.). The one solution would be somehow create JWT token for auth-service with role <code>AUTH_SERVICE</code> and at the user service side check JWT and if the role is different than <code>AUTH_SERVICE</code> reject the request.</p>&#xA;&#xA;<p>Are there any other solutions?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>I thought that my design is quite common but apparently I should have been more specific in the first place:</p>&#xA;&#xA;<ul>&#xA;<li>Auth-servie is my Authorization Server and the other services are Resource servers</li>&#xA;<li>I use API gateway pattern and my auth-service is also behin proxy</li>&#xA;<li>After the client application obtains JWT it adds it to every request and based on that the authentication and authorization is performed; every Resource server has a public key which is used to verify signature; if it's valid, the service knows that JWT has been generated by trusted auth-service and the service based on JWT creates OAuth2Authenication object which contains all the user information</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT2:</strong></p>&#xA;&#xA;<p>I ended up merging auth-service to user-service, which was the suggestion given from a couple of SO users. After thinking about it it seemed unnecessary to have a seperate auth-service for just JWT generation. I've accepted @Abhijit Sarkar answer because it has some valid points even though he wasn't right about additional call to auth-service to verify validity of the token.</p>&#xA;"
42582463,Monitoring a microservice architecture,2017-03-03 15:14:05,<amazon-web-services><aws-lambda><microservices><prometheus>,2,253,0,1.0,3,"<p>I'm designing an architecture that similar to what's described <a href=""https://aws.amazon.com/blogs/compute/better-together-amazon-ecs-and-aws-lambda/"" rel=""nofollow noreferrer"">here</a>.  The diagram is: &#xA;<a href=""https://i.stack.imgur.com/y72pp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/y72pp.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>My question is how do you monitor such an architecture where independent pieces compose into a logical unit?  It's almost as if we need a monitoring system that checks S3 for .zip files and then polls S3 for the corresponding png files.  If <em>after</em> X hours no png files are found then alert.  </p>&#xA;&#xA;<p>Is there a tool that does timeseries analysis?  Does Prometheus do this?</p>&#xA;"
42527724,Accessing microservices deployed on apache mesos agents,2017-03-01 09:18:27,<dns><load-balancing><microservices><mesos><marathon>,2,100,1,0.0,3,"<p>How client can access a deployed microservice <strong>without</strong> specifing the host agent ip-address and the related mapping port.</p>&#xA;&#xA;<p>If we add Mesos-DNS as the client resolver, we can only obtain agent ip-addresses but it doesn't return the list of  microservices instances and their related ports.</p>&#xA;&#xA;<p>Supposed we have three instannces of webapp1 as follow:</p>&#xA;&#xA;<pre><code>+---------+---------+&#xA;| agent1  | agent2  |&#xA;+---------+---------+&#xA;|         |         |&#xA;| ins1:11 | ins3:13 |&#xA;|         |         |&#xA;| ins2:12 |         |&#xA;|         |         |&#xA;+---------+---------+&#xA;</code></pre>&#xA;&#xA;<p>client should be enabled to access one of instances directly (without referring agent1 and agent2 ip-addresses or those 11, 12 and 13 port numbers). For example:</p>&#xA;&#xA;<pre><code>$ lynx webapp1.marathon.mesos&#xA;</code></pre>&#xA;"
42562820,DDD. Shared kernel? Or pure event-driven microservices?,2017-03-02 18:10:44,<domain-driven-design><microservices><bounded-contexts>,3,1670,1,1.0,3,"<p>I'm breaking my system into (at least) two bounded-contexts: study-design and survey-planning.</p>&#xA;&#xA;<p>There's a concept named ""subject"" (potential subject for interviewing) in the study-design context. We also maintain associations between subjects and populations in that domain.</p>&#xA;&#xA;<p>Now, in the survey-planning, we also need (some) information about the subject (for example: for planning a visit, or even for anticipated selection of questionnaire, in case the population the subject belongs to is known beforehand).</p>&#xA;&#xA;<p>So, I need that ""subject"" in both contexts. </p>&#xA;&#xA;<p>What approach should I pick? Having a shared kernel, as explained in Eric Evans DDD book? I don't mind (at least for now) having the two contexts sharing the same database.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FKtJ9.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FKtJ9.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Or... should I go pure microservice? Meaning: those two can't / shouldn't share database..., and in that case I might have to go the mirroring / duplicating route through event passing: <a href=""https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts"" rel=""nofollow noreferrer"">https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts</a></p>&#xA;&#xA;<p>Any thoughts on which one is better, for the above situation?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
42404800,How to build front end for Microservices,2017-02-23 00:20:21,<user-interface><architecture><microservices>,1,477,1,0.0,3,"<p>Let's say I have a dozen microservices. I am wondering where should the front end go. Let's say front end is HTML, Javascript, CSS. One way is to make it a separate service handled by a UI team. So it can form the API gateway where the request from browser comes in first. But this seems against the idea of independent self contained services.<br>&#xA;browser ------> API Gateway ------> Microservices&#xA;<br>&#xA;In <a href=""https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/"" rel=""nofollow noreferrer"">this</a> link, they say that Javascript and CSS should be served by microservices. API gateway should serve only the HTML page. THere is a nice diagram showing this >>&#xA;<a href=""https://i.stack.imgur.com/1suda.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1suda.png"" alt=""microservices with UI""></a>&#xA;I have two questions<br>&#xA;1. How will this be implemented? How will API gateway serve the JS and CSS files in microservices, and maybe HTML fragments too. How will initial page load happen and from where.<br>&#xA;2. Now we are mingling HTML into microservices. But what if I want to serve Android and iOS apps too? THanks.</p>&#xA;"
49612709,Should each microservice manage its own user-permissions and user-roles?,2018-04-02 13:58:40,<jwt><microservices>,2,215,3,0.0,3,"<p>I have a design issue I am not sure of how to solve.</p>&#xA;&#xA;<p>Let's say my main application consists of 6 modules:</p>&#xA;&#xA;<ul>&#xA;<li>client</li>&#xA;<li>gateway</li>&#xA;<li>auth-service</li>&#xA;<li>forum</li>&#xA;<li>gallery</li>&#xA;<li>messages</li>&#xA;</ul>&#xA;&#xA;<p>The client is supposed to communicate with the gateway-service only.</p>&#xA;&#xA;<p>Should I have my gateway do the user-authentication (which ideally results in a JWT) and the other 3 productive-services (forum, gallery, messages) just verify that token and retrieve permissions and roles <strong>they manage themselves</strong> for that given user?</p>&#xA;&#xA;<p>To perhaps illustrate my few troubles, I create a sequence diagram:&#xA;<a href=""https://i.stack.imgur.com/j82Fv.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j82Fv.jpg"" alt=""this image shows the sequence diagram, which I am having trouble with""></a></p>&#xA;&#xA;<p><a href=""https://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharinghttps://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharing"" rel=""nofollow noreferrer"" title=""link to Google Drive file"">Click here</a> for the original draw.io graphics if you prefer that.</p>&#xA;&#xA;<p>I do not want to use any 3rd-party auth-services; I just want my auth-service (which is pretty much done) to register users and let them login. Or should I be managing permissions and roles in that service as well?</p>&#xA;&#xA;<p>I tried to wrap my brain around this issue for months, but I simply cannot find a suitable structure so I can let the user register, login/logout and communicate with various productive services. I am currently using Java for the backend stuff, but the good thing about microservices is, that I do not have to use one programming language for them all.</p>&#xA;&#xA;<p>Any help here is welcome!</p>&#xA;&#xA;<p>P.s.: I read <a href=""https://stackoverflow.com/questions/29644916/microservice-authentication-strategy"">Microservice Authentication strategy</a> and <a href=""https://stackoverflow.com/questions/33921375/zuul-api-gateway-authentication"">Zuul - Api Gateway Authentication</a>, but both did not seem to apply in my case.</p>&#xA;"
48279479,How to query in a Event Driven Microservice architecture?,2018-01-16 10:50:06,<microservices><cqrs><event-driven>,3,308,0,1.0,3,"<p>Let suppose the following simple UC based on a CQRS architecture:</p>&#xA;&#xA;<p>We have a backend managing a Business Object, let says a Movie.</p>&#xA;&#xA;<ul>&#xA;<li>This backend is composed of 2 Microservices: a CommandManager (Create/Update/Delete Movie) and a QueryManager (Query Movie)</li>&#xA;<li>We have a frontend that offer a web page for creating a new Movie and this action lead automatically to another web page describing the Movie. </li>&#xA;</ul>&#xA;&#xA;<p>A simple way to do that is:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend make a POST request to the CommandManager</li>&#xA;<li>The CommandManager write the new movies to the datastore and return the movie key</li>&#xA;<li>The frontend make a GET using this key to the QueryManager</li>&#xA;<li>The QueryManager looks for the Movie in the Datastore using the key and return it.</li>&#xA;<li>The frontend deliver the page with the Movie Information.</li>&#xA;</ul>&#xA;&#xA;<p>Ok, now I want to transform this UC in a more Event Driven way. Here is the new flow:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend write a Message in the BUS with the new movie information</li>&#xA;<li>The CommandManager listen the BUS and create the new movies in the datastore. Eventually, it publish a new message in the BUS specifying that a new Movie has been created.</li>&#xA;</ul>&#xA;&#xA;<p>At this point, the frontend is no more waiting for a response due to the fact that this kind of flow is asynchronous. How could we complete this flow in order to forward the user to the Movie Information Web page? We should wait that the creation process is done before querying the QueryManager. </p>&#xA;&#xA;<p>In a more general term, in a asynchronous architecture based on bus/event, how to execute Query used to provide information in a web page?</p>&#xA;"
48271960,Event Sourcing and dealing with data dependencies,2018-01-15 23:09:44,<apache-kafka><microservices><event-sourcing><distributed-system><distributed-transactions>,1,181,0,0.0,3,"<p>Given a REST API with the following operations resulting in events posted to Kafka:</p>&#xA;&#xA;<ul>&#xA;<li>AddCategory</li>&#xA;<li>UpdateCategory</li>&#xA;<li>RemoveCategory</li>&#xA;<li>AddItem (refers to a category by some identifier)</li>&#xA;<li>UpdateItem</li>&#xA;<li>RemoveItem</li>&#xA;</ul>&#xA;&#xA;<p>And an environment where multiple users may use the REST API at the same time, and the consumers must all get the same events. The consumers may be offline for an extended period of time (more than a day). New consumers may be added, and others removed.</p>&#xA;&#xA;<p>The problems:</p>&#xA;&#xA;<ul>&#xA;<li>Event ordering (only workaround single topic/partition?)&#xA;&#xA;<ol>&#xA;<li>AddItem before AddCategory, invalid category reference.</li>&#xA;<li>UpdateItem before AddCategory, used to be a valid reference, now invalid.</li>&#xA;<li>RemoveCategory before AddItem, category reference invalid.</li>&#xA;<li>....infinite list of other concurrency issues.</li>&#xA;</ol></li>&#xA;<li>Event Store snapshots for fast resync of restarted consumers&#xA;&#xA;<ol>&#xA;<li>Should there be a compacted log topic for both categories and items, each entity keyed by its identifier?</li>&#xA;<li>Can the whole compacted log topic be somehow identified as an offset?</li>&#xA;<li>Should there only be one one entry in the compacted log topic, and the data of it contain a serialized blob of all categories and items given an offset (would require single topic/partition).</li>&#xA;<li>How to deal with the handover from replaying the rendered entities event store to the ""live stream"" of commands/events? Encode offset in each item in the compacted log view, and pass that to replay from the live event log?</li>&#xA;</ol></li>&#xA;</ul>&#xA;&#xA;<p>Are there other systems that fit this problem better?</p>&#xA;"
48201224,Kafka AND REST for communication between microservices?,2018-01-11 06:45:16,<rest><architecture><apache-kafka><message-queue><microservices>,1,429,2,1.0,3,"<p>I am currently working on an architecture see below. First I'm not sure if this kind of architecture is called an <em>event-driven</em> or a <em>data-driven</em> architecture or maybe both.</p>&#xA;&#xA;<p>There some input messages are sent from the <strong>Frontend</strong> to <strong>T1</strong>. These messages are first validated, then collected and in the end evaluated.</p>&#xA;&#xA;<p>My current approach is to persist the raw messages with all meta information in <strong>MS A</strong>, the sorted collections in <strong>MS B</strong> and the evaluations in <strong>MS C</strong>. This separates the data to the appropriately concerned microservices.  </p>&#xA;&#xA;<p>In <strong>T2</strong> I only produce the messages which <strong>MS B</strong> requires.<br>&#xA;In <strong>T3</strong> I only produce the messages which <strong>MS C</strong> requires.<br>&#xA;But when evaluation the collections all meta information from <strong>MS A</strong> is required. So how to proceed with this kind?</p>&#xA;&#xA;<ol>&#xA;<li>Should I send only the minimum of data to the queue and provide an API?</li>&#xA;<li>Should I send all data to the queues (forward data for following services)?</li>&#xA;<li>Should I send all information for the next service to the queue and provide an API?</li>&#xA;<li>Something else?</li>&#xA;</ol>&#xA;&#xA;<p>Or did I misunderstand the approach ""Communicating microservices through Kafka""?</p>&#xA;&#xA;<p>Please feel free to offer criticism!<br>&#xA;Thanks for advice!</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/BgT2M.png"" height=""500""/></p>&#xA;"
49443206,Difference between OSGI and microservices,2018-03-23 05:54:50,<osgi><microservices><osgi-bundle>,2,1173,1,0.0,3,<p>When would you like to choose for OSGI modules than micro services and is there anything i can do with micro services that i can not do with OSGI modules?</p>&#xA;
50312750,How can I keep databases of two web applications in sync?,2018-05-13 04:23:50,<java><sql-server><microservices><database-trigger>,2,65,0,0.0,3,"<p>I have two webapps, each with its own backend microservice and each microservice has its own database. For any changes in tables of database of microservice1, I want to change(create/update) entries in tables of database of microservice 2. How can I do that? </p>&#xA;&#xA;<h1>Context:</h1>&#xA;&#xA;<p><strong>Webapp 1:</strong> UI for human resource coordinators to schedule an interview. </p>&#xA;&#xA;<p><strong>Microservice 1:</strong> Backend service that schedules an interview.</p>&#xA;&#xA;<p><strong>DB for microservice 1:</strong> Stores information related to interview of a candidate. </p>&#xA;&#xA;<pre><code>  interviews: [ {&#xA;      ""interviewId"": ""1"",&#xA;      ""candidateId"": ""abc"",&#xA;      ""interviewers"": [&#xA;      {&#xA;         ""interviewer_name"": ""Thor"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      },&#xA;      {&#xA;         ""interviewer_name"": ""Loki"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      }&#xA;   ]&#xA;} ]&#xA;</code></pre>&#xA;&#xA;<p><strong>Webapp 2:</strong> UI for interviewers to coordinate on questions to ask in an interview. </p>&#xA;&#xA;<p><strong>Microservice 2:</strong> Backend service for interviewers to coordinate on question selection. i.e. each interviewer selects what question he/she is going to ask from a candidate in an interview (this is to ensure no two interviewers end up asking same question from a candidate).</p>&#xA;&#xA;<p><strong>DB for microservice 2:</strong> Schemas</p>&#xA;&#xA;<p>// QuestionBank : Table containing questions, that interviewers can select.</p>&#xA;&#xA;<p>// Interviewers : Table containing all interviewers in the firm.</p>&#xA;&#xA;<p>// InterviewToInterviewer : (many to many mapping of interviews with interviewers). One interview can have many interviewers, and each interviewer can participate in many interviews.</p>&#xA;&#xA;<p>// InterviewToInterviewerToQuestion :  (many to many mapping of interviewToInterviewers with questions). For each interview an Interviewer can select many questions and each of the question in a questionbank can be a part of many interviewToInterviewer entry.</p>&#xA;&#xA;<h1>Current Workflow:</h1>&#xA;&#xA;<p>As soon as interview is scheduled from webapp1:</p>&#xA;&#xA;<ol>&#xA;<li>An email is sent to all the interviewers. Email contains a link to a webapp 2, clicking on this link opens webapp2 that provides an interface for interviewers to select questions they plan to ask in an interview.</li>&#xA;</ol>&#xA;&#xA;<h1>Requirement:</h1>&#xA;&#xA;<ol>&#xA;<li><p>If the questions are not selected by interviewer, then I want to send reminders to them. For this I want webapp2 to know that an interview is scheduled. </p></li>&#xA;<li><p>I want webapp2 to know about any lineup changes (in a given interview, interviewer is changed or an interview is cancelled etc) that happens. </p></li>&#xA;</ol>&#xA;&#xA;<h1>Solutions I thought off:</h1>&#xA;&#xA;<ol>&#xA;<li><p>As soon as interview is scheduled/changed from webapp1, webapp1 will calls webapp2 (webapp2 exposes an API for that) to let webapp2 know that a new interview is created or an existing interview is updated. </p></li>&#xA;<li><p>For any new entry/update in interview table in DB1, a DB trigger is launched to DB2. I am not sure whether this is possible also. </p></li>&#xA;</ol>&#xA;&#xA;<p>Out of the two approaches above can someone help me with the pros and cons of one choosing over other. Or there is some other alternative approach to achieve this.</p>&#xA;&#xA;<p>Leads here are appreciated. </p>&#xA;"
50435696,Django admin + authentication system in microservice architecture,2018-05-20 14:13:20,<django><django-rest-framework><django-admin><microservices><django-apps>,1,165,0,1.0,3,"<p>I have a <strong>large</strong> Django project which is basically a monolith containing apps.&#xA;I need to break it to microservices.</p>&#xA;&#xA;<p>I have 2 questions that I couldn't find a clear answers to:</p>&#xA;&#xA;<ol>&#xA;<li><p>Currently we're using Django admin extensively and I wonder if it's&#xA;possible to continue using it once the monolith is broken. It means&#xA;reading and manipulating data from all the microservices in a ""used&#xA;to work on"" UI. It would also be helpful for this process to be done more smoothly.</p></li>&#xA;<li><p>Authentication and authorization - Would we still be able to use&#xA;this built in ""app"" in a microservice architecture? Is it possible&#xA;to take this pare only to another service and communicate with it&#xA;over HTTP?</p></li>&#xA;</ol>&#xA;"
50328886,How to setup nginx as reverse proxy for rest microservice in kubernetes?,2018-05-14 11:11:19,<docker><nginx><kubernetes><microservices>,3,125,2,2.0,3,<p>I have a rest microservice and would like to setup nginx as a reverse proxy for it. I am little confused about which approach to follow:</p>&#xA;&#xA;<ol>&#xA;<li>Run nginx in each pod where application code is running.</li>&#xA;<li>Run nginx in separate pods and redirect http requests to application code running in separate pods.</li>&#xA;</ol>&#xA;&#xA;<p>Can someone explain which one is better </p>&#xA;
48791411,Horizontal scaling of consumers when the publisher provides sequenced messages,2018-02-14 16:02:53,<asynchronous><rabbitmq><microservices>,4,167,0,1.0,3,"<p>In a distributed service oriented architecture, lets say I have a producer that send messages to a consumer using RMQ. </p>&#xA;&#xA;<p>We decided then to horizontally scale the consuming part of our architecture by adding more consumers and we faced some limitations.</p>&#xA;&#xA;<p>The publisher provide a sequence number in every message it sent. And itâ€™s very important that the consumers process the messages based on the sequence number it has.</p>&#xA;&#xA;<p>Every time that deal with a given resource, lets say A, the publisher will send RMQ messages that says ""Hey lets do sequence 1 for A"" and then ""Hey lets do sequence 2 for A"" and so on.</p>&#xA;&#xA;<p>If for example the publisher provides 3 messages for A with sequences 1, 2 and 3 and the 3 messages are distributed to 3 different instances of our consumer. The message of sequence 2 is requeued until sequence 1 is well processed, same for sequence 3.</p>&#xA;&#xA;<p>At the end the messages are all well processed, but after many retries! This causes some latency in our system as we retries many times if weâ€™ve 100 sequences to consume.</p>&#xA;&#xA;<p>A possible solution would be to make sure each set of sequences for a given resource has to be processed by the same consumer. But how can we achieve that?</p>&#xA;&#xA;<p>How can I avoid the requeuing in order to make sure every instance of our consumer always get the messages for a given resource well ordered?</p>&#xA;"
48624757,Asynchronous Message-Passing and Microservices,2018-02-05 14:27:51,<java><spring-boot><apache-kafka><microservices>,3,434,2,2.0,3,"<p>I am planning the develop of a microservice based architecture application and I decided to use kafka for the internal communicaton while I was reading the book <em>Microservice Architecture by Ronnie Mitra; Matt McLarty; Mike Amundsen; Irakli Nadareishvili</em> where they said: </p>&#xA;&#xA;<blockquote>&#xA;  <p>letting microservices directly interact with message brokers (such as&#xA;  RabbitMQ, etc.) is rarely a good idea. If two microservices are&#xA;  directly communicating via a message-queue channel, they are sharing a&#xA;  data space (the channel) and we have already talked, at length, about&#xA;  the evils of two microservices sharing a data space. Instead, what we&#xA;  can do is encapsulate message-passing behind an independent&#xA;  microservice that can provide message-passing capability, in a loosely&#xA;  coupled way, to all interested microservices.</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/XK10H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XK10H.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I am using Netflix Eureka for Service registration and discovery, Zuul as edge server and Hystrix. &#xA;Said so, in practice, how can I implement that kind of microservice? How can I make my microservices indipendent from the communcation channel ( in this case Kafka)? &#xA;Actually I'm directly interacting with the channel, so I don't have an extra layer between my publishers/subscribers and kafka.</p>&#xA;&#xA;<p><strong>UPDATE 06/02/2018</strong></p>&#xA;&#xA;<p>to be more precise, we have a couple of microservices: one is publishing news on a topic (activemq, kafka...) and the other microservice is subscribed on that topic and doing some operations on the messages that are coming through. So we have these services that are coupled to the message broker (to the channel)... we have the the message broker's apis ""embedeed"" on our code and for example, if we want to change the message broker we have to change all the microservices that made use of the message broker's api. So, they are suggesting to use a microservice(in the picture I assume is the Events Hub) that is the ""dispatcher"" of the various messages. In this way it is the only component that interacts with the channel.</p>&#xA;"
43529266,How to use Haskell Stack with Docker Compose?,2017-04-20 20:25:35,<haskell><docker><docker-compose><microservices><haskell-stack>,1,398,2,0.0,3,"<p>I am trying to use docker compose to tie together some haskell services for local development. Most of the time I'm messing around in <code>stack ghci</code>, running unit tests, etc, but I also need to be able to run code that hits a dependency. Docker compose is great for this: I can run the dependencies (databases, other services, etc), and link everything together. </p>&#xA;&#xA;<p>Stack has docker support. It can build in a docker container with <code>docker: enable: true</code>, and also can create an executable image with <code>stack image container</code>.</p>&#xA;&#xA;<p>How do I leverage stack's docker functionality from within <code>docker-compose.yml</code>? </p>&#xA;&#xA;<pre><code>version: ""3""&#xA;&#xA;services:&#xA;&#xA;  my-service:&#xA;&#xA;    # how can I use `stack image container` here? Is it possible?&#xA;    build: '.'&#xA;&#xA;    links:&#xA;    - other-service&#xA;&#xA;    env_file:&#xA;    - test.env&#xA;&#xA;  other-service:&#xA;    image: other-service-image&#xA;</code></pre>&#xA;&#xA;<p>Do I have to make my own Dockerfile, or is there some way to use the <code>stack image container</code> functionality?</p>&#xA;&#xA;<p>Follow-up questions: Is there some way to run <code>stack ghci</code> with all the settings (env, links, etc) from the docker compose file? </p>&#xA;"
43384538,Database location in Microservices Architecture,2017-04-13 05:57:03,<azure><docker><microservices>,3,361,4,0.0,3,"<p>We have a monolithic application which we are now converting to microservice architecture using containers. </p>&#xA;&#xA;<p>Our microservices are <em>stateful</em> (i.e they need to insert/retrieve data from db). As per microservice architecture, each microservice should have its own data (i.e database in our case).</p>&#xA;&#xA;<p>My question is that <strong>where</strong> the database of each microservice should be deployed, whether it should be in the same host in which the microservice is deployed, in the same container in which the microservice is deployed or it should be in the separate server like azure db or something?</p>&#xA;&#xA;<p>What would be the pros &amp; cons of each approach and what is the best approach according to microservice best practices?&#xA;*</p>&#xA;"
43396744,Microservices UI Frontend with Java and ReactJS Server Side Rendering,2017-04-13 15:52:36,<java><reactjs><microservices><serverside-rendering>,2,3077,9,3.0,3,"<p>My current design is to have clients connect to my (Java) Web API Gateway using a browser, the Web API Gateway will call each (Java) microservice to get their JSON data and return it to the UI component that made the request on the client. </p>&#xA;&#xA;<p>The only client side rendering will be from each ReactJS UI component for recurring requests to the gateway. </p>&#xA;&#xA;<p>On the server side the full HTML view will be rendered prior to being sent back to the client. </p>&#xA;&#xA;<pre><code>Client browser&#xA;&#xA;     â–¼ (Request Dashboard View)&#xA;&#xA;Web API Gateway&#xA;&#xA;     â–¼ (Request microservice JSON data)&#xA;&#xA;Microservice A JSON Data&#xA;Microservice B JSON Data&#xA;Microservice C JSON Data&#xA;Microservice D JSON Data&#xA;&#xA;     â–¼ (Return JSON Data to gateway)&#xA;&#xA;Web API Gateway&#xA;&#xA;     â–¼ (Render HTML and return to Client)&#xA;&#xA;Client browser&#xA;&#xA;     â–¼ (ReactJS UI Components request data from API Gateway)&#xA;</code></pre>&#xA;&#xA;<p>This is where it gets unclear, would it be best to have each UI component communicate with the Web API Gateway or the parent Microservice it came from to get data? </p>&#xA;&#xA;<p>Considerations</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components talk to the Web API Gateway seems reasonable but will couple the microservices to the gateway, meaning to expose a new API on the microservice the gateway will also need to be updated. </li>&#xA;<li>Having the UI components talk directly to its Microservice for data removes the need to also update the Web API Gateway, keeping them less coupled. But this then exposes the Microservice to external calls from the client browser. </li>&#xA;</ul>&#xA;&#xA;<p>Design Decisions</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components within the API gateways creates a UI monolith as opposed to having each microservice responsible for its own UI component. Using the monolithic approach simplifies the solution and also avoids the complexities of having to aggregate each microservices UI component when the client requests a particular view. </li>&#xA;</ul>&#xA;&#xA;<p>Tools:</p>&#xA;&#xA;<ul>&#xA;<li>Java</li>&#xA;<li>Nashorn</li>&#xA;<li>Dropwizard </li>&#xA;<li>ReactJS</li>&#xA;<li>Gradle</li>&#xA;<li>Webpack</li>&#xA;<li>NodeJS</li>&#xA;<li>NPM </li>&#xA;</ul>&#xA;&#xA;<p><strong>How do I aggregate multiple microservice ui components on the Web API Gateway using Java and ReactJS then serve this pre-rendered HTML data along with the JavaScript application to the client?</strong></p>&#xA;&#xA;<p><strong>Helpful References:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Server side rendering with Java 8 and Nashhorn <a href=""http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/"" rel=""nofollow noreferrer"">http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/</a></li>&#xA;</ul>&#xA;"
47566892,Microservices : Embedded tomcat vs standalone tomcat : Difference,2017-11-30 06:07:52,<java><tomcat><kubernetes><microservices><embedded-tomcat-8>,1,1205,0,0.0,3,"<p>Can embedded tomcat or any such embedded server be used for microservices in production environment? How, embedded server is different wrt the normal standalone full fledged server (performance . reliability wise)? Is the embedded server light weight compared to standalone? What are the features that embeded servers do not have compared to their standalone ones? Can we change the default security settings, tls ciphers etc advanced things in embedded tomcat?</p>&#xA;"
47757342,Programmatically add a service to docker compose project,2017-12-11 16:34:58,<docker><docker-compose><microservices>,1,231,0,0.0,3,"<p>I have a project with components base on Docker and orchestrated with <code>docker-compose</code>. Some of them are optional, and can be added at runtime.</p>&#xA;&#xA;<p>I can think about two ways to achieve that:</p>&#xA;&#xA;<ul>&#xA;<li>Create a new <code>serviceA.yml</code> compose file and run it as a separate project</li>&#xA;<li>Add <code>serviceA</code> to my base <code>compose.yml</code> and run it again</li>&#xA;</ul>&#xA;&#xA;<p>What is the preferred option to do that?</p>&#xA;&#xA;<p>I've also seen that you can combine <code>docker-compose</code> files with the <code>extend</code> keyword, but I don't think this can fit, since I have a variable number of services that I can add at runtime.</p>&#xA;"
41008507,Is there an established pattern for paging in Service Fabric ReliableCollections,2016-12-07 02:36:18,<azure><microservices><azure-service-fabric><service-fabric-stateful>,2,403,0,2.0,3,"<p>In reliable collections (specifically IReliableDictionary), an approach for implementing 'common' queries is to update a secondary dictionary which structures the keys to be ordered a specific way in an enumeration.  For large data sets, <strong>I would like to avoid shuttling a large amount of data around</strong>.  </p>&#xA;&#xA;<p>To achieve this I would like to <strong>implement some sort of continuation token</strong> which the caller can supply to me when requesting the data.  I am currently implementing this by first generating an ordered enumeration and returning the first n items where n = the MAX_PAGE size.   <strong>The continuation is essentially the last key in that list of n items</strong>. The next time the caller passes in the continuation token, <strong>I generate the ordered enumerable with the filter function specifying that the key should be greater than the continuation</strong>.  </p>&#xA;&#xA;<p>This has 2 problems (that I can see):</p>&#xA;&#xA;<ol>&#xA;<li>The <strong>collection could change between when the caller first requests a page and a subsequent request</strong>.  This, I'm not certain I can avoid since updates to the collection need to be able to occur at any time regardless of who is attempting to page through the data.</li>&#xA;<li>I'm not certain how the filter function is used. I would assume that since a developer could filter on anything, the <strong>GetEnumerableAsync() method must supply all keys in the dictionary before returning the enumerable</strong>.  For a sufficiently large data set, this seems slow.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Are there any prescribed approaches for paging data like this?</strong>  I am beginning to feel like I might be barking up the wrong tree with Reliable Collections for some of my use cases.  </p>&#xA;"
40932850,Mongodb IsoDate and the issue with if-modified-since on microservices,2016-12-02 13:00:42,<java><mongodb><microservices>,1,170,2,1.0,3,"<p>When I insert a document on my MongoDB using spring data, I do the following:</p>&#xA;&#xA;<pre><code>Update update = new Update();&#xA;update.currentDate(""lastModified"");&#xA;mongoTemplate.upsert(query, update, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>I'm using the currentDate of MongoDB, because I want to save the date that MyDocument was last modified with the date where my MongoDB database is located. </p>&#xA;&#xA;<p>Based on the <a href=""https://www.ietf.org/rfc/rfc2616.txt"" rel=""nofollow noreferrer"">spec</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>The If-Modified-Since request-header field is used with a method to&#xA;     make it conditional: if the requested variant has not been modified&#xA;     since the time specified in this field, an entity will not be&#xA;     returned from the server; instead, a 304 (not modified) response will&#xA;     be returned without any message-body.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, the purpose of saving this date is to verify if MyDocument was modified or not based on the received date.</p>&#xA;&#xA;<p>So, when I execute the update, the following IsoDate is created on the database:</p>&#xA;&#xA;<pre><code>ISODate(""2016-12-02T12:11:33.083Z"")&#xA;</code></pre>&#xA;&#xA;<p>So, when a client wants to know if the document has changed, they send me back this date, and I query on the database:</p>&#xA;&#xA;<pre><code>    Query query = new Query(where(""id"").is(filter.getId()));&#xA;    Criteria criteria = Criteria.where(""lastModified"").gt(filter.getLastModified());&#xA;    query.addCriteria(criteria);&#xA;    return mongoTemplate.findOne(query, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>This works perfectly, except for one problem: The spec says that the header if-modified-since has the following format:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT</p>&#xA;</blockquote>&#xA;&#xA;<p>Which means that the milliseconds is not passed on the if-modified-since header. However, MongoDB IsoDate saves the current date with milliseconds. So, when two dates are exactly the same, the query will not return 304 Not Modified, but it will return the entire resource, because the query will be the following:</p>&#xA;&#xA;<pre><code>{ ""id"" : 123, ""lastModified"" : { ""$gt"" : { $java : 2016-12-02T12:11:39.000Z } } }&#xA;</code></pre>&#xA;&#xA;<p>Since the client does not send the milliseconds, the java put the milliseconds as zeros ( 2016-12-02T12:11:39.<strong>000</strong>Z), which means that &#xA;the date on my database is greater than the date sended by my client:</p>&#xA;&#xA;<p>2016-12-02T12:11:33.083Z > 2016-12-02T12:11:39.000Z </p>&#xA;&#xA;<p>Because of the 83 milliseconds. </p>&#xA;&#xA;<p><strong>The final question is</strong>: What it is the correct way to solve this problem, and work correctly as the specs for if-modified-since suggests?</p>&#xA;"
40890804,Register MicroServices in Azure Active Directory (AAD) for Security,2016-11-30 14:24:14,<azure><asp.net-web-api><owin><azure-active-directory><microservices>,1,654,4,0.0,3,"<p>I have a service fabric application (Stateless and Statefull) deployed in Service fabric cluster. I am trying to implement security in the applications. The application uses the Active Directory Authentication Library (ADAL) to get a token from Azure AD using the OAuth 2.0 client credential flow, where the client credential is a password. I am able to implement the same scenario in ordinary web api applications by registering them in Azure portal. Can anyone tell me how to register a service fabric microservice application with WebApi exposed using Owin. i have difficulties registering the reply url and sign on url as the urls are dynamic(for statefull partitionid and replica id). I receive unauthorized access while calling the corresponding service. I am not sure of what url has to be registered for a statefull or stateless application when adding the application in in azure active directory. Could you please suggest me where I'm wrong and what to do to implement.</p>&#xA;"
50134195,Authorization between micro services and users,2018-05-02 12:01:47,<architecture><microservices>,1,127,0,1.0,3,"<p>What would be best way to handle access and authorization between microservices and users?</p>&#xA;&#xA;<p>I'm building an application on microservice architecture. Services speak to each other through REST. there are endpoints that should be accessed only by other microservices and not directly by users, some endpoints are public and some would require users to register or have admin privileges. On top of that Users will have roles like admins and regular users.</p>&#xA;&#xA;<p>I'm trying to figure out if Oauth2 and scopes is the best approach for what I'm trying to achieve. e.g. each microservice will have ""user"" that have permission on certain scopes like ""service1-place-order"". </p>&#xA;"
51783877,How Ribbon get the list of Available instances of a service,2018-08-10 09:56:30,<spring><microservices><ribbon><eureka>,1,27,0,0.0,3,<p>I am using ribbon as load balancer on API gateway and eureka server. When client request comes to my API gateway does it query service registry every time to get the avaliable instance of a service or ribbon stores the available instances into it's cache.</p>&#xA;
51939287,Design of cloud Microservice on Heroku advice,2018-08-20 22:28:01,<heroku><design><architecture><microservices><paas>,1,43,0,0.0,3,"<p>I am new to the world of microservice and I have tried to learn about it and how it could be apply to my needs. I need to design a cloud plaform easily maintenable and scalable with the following (as far as I see them) :</p>&#xA;&#xA;<ul>&#xA;<li>Rails API + PostgreSQL (microservice 1)</li>&#xA;<li>Frontend framework (microservice 2)</li>&#xA;<li>Some Python script (microservice 3)</li>&#xA;<li>Some other Python script (microservice 4)</li>&#xA;</ul>&#xA;&#xA;<p>Inspired by <a href=""https://stackoverflow.com/questions/41795612/how-to-deploy-microservices-on-heroku"">this question &amp; answer</a>, <strong>each microservice is a separate Heroku app</strong>. What about the security between them when they talk to each other and the response time?</p>&#xA;&#xA;<p>Also, since the service is meant to grow, it would be expensive sooner or later, how to optimize cost in this situation ? I just discovered <a href=""https://captainduckduck.com/"" rel=""nofollow noreferrer"">CaptainDuckDuck</a> but I'm afraid of the ""lack"" of experience from its user base since it's quite new and not as much popular as other PaaS. Is the only solution is to go to something like DigitalOcean or AWS EC2 and manage by ourselves the job that Heroku does ?</p>&#xA;&#xA;<p>Because doing microservice like this, is not really a microservice design since all the services are not hosted on the same machine, am I right ?&#xA;A more <em>microservice-friendly</em> approach would be to use <a href=""https://www.heroku.com/private-spaces"" rel=""nofollow noreferrer"">Heroku Private Spaces</a> (even if that doesn't answer the cost issue) ?</p>&#xA;&#xA;<p>For information, I have this design already up and running. So it's not a matter of <em>""will it work?""</em>, but more <em>""is it the right way?""</em>.</p>&#xA;&#xA;<p>Thanks for your feedbacks</p>&#xA;"
51821786,@EnableZuulProxy doesnot work due to `HttpServletRequest` class not found,2018-08-13 11:55:10,<java><spring-boot><microservices><netflix-zuul>,1,130,6,0.0,3,"<p>I am writing a <code>Zuul</code> enabled API gateway for my microservices,&#xA;However while starting the the microservice containing <code>zuul</code>, I am getting the below mentioned error</p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: <strong>Caused by: java.lang.ClassNotFoundException:</strong>&#xA;  <strong>javax.servlet.http.HttpServletRequest</strong></p>&#xA;</blockquote>&#xA;&#xA;<p>After numerous search, I have found below two solutions which does not help me. Hence I am here</p>&#xA;&#xA;<ol>&#xA;<li>Enable the <code>Apache tomcat facet</code>. This for some reason disabled in <code>Dynamic web module 3.0</code>.</li>&#xA;<li>Creating custom <code>dispatcher servlet</code>. But this solution should be feasible when we use servlet 2.5.</li>&#xA;</ol>&#xA;&#xA;<p>Since I am using a spring-boot app imported from <code>https://spring.io</code>, so it cements that I am using <code>servlet 3.0</code>.</p>&#xA;&#xA;<p>My API gateway <code>pom.xml</code>:</p>&#xA;&#xA;<pre><code>&lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>I have annotated my API gateway class with <code>@EnableZuulProxy</code>.</p>&#xA;&#xA;<p>Having said these could you please help me with my error highlighted above.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Edit:  When I change the &#xA;  1. <code>spring-starter-parent</code> to <strong>1.5.3RELEASE</strong> instead of the latest.&#xA;  2. <code>spring-cloud.version</code> to <strong>Edgware.SR2</strong> from <strong>Finchley.SR1</strong>. I face no issue at all.</p>&#xA;</blockquote>&#xA;&#xA;<p>I guess it is latest spring thing ? Any thoughts!</p>&#xA;"
51889526,Why would we go for micro-services if there is requirement for lower latency code?,2018-08-17 06:25:20,<java><microservices>,1,63,8,1.0,3,"<p>In a monolith, we just need to either make a function call or method invocation as opposed to inter process communication. Can someone familiar with micro-services architecture help to understand reasons how you can use micro services for developing low latency applications?</p>&#xA;&#xA;<p>I think Chronicle framework claims that you can develop micro-services based products and use chronicle queues to communicate without incurring network hop latency. </p>&#xA;"
40702179,micro service web app with AWS,2016-11-20 08:43:36,<amazon-web-services><amazon-s3><amazon-ec2><microservices>,1,601,0,2.0,3,"<p>I am developing a web application for image upload and retrieval with AWS cloud services using a micro service architecture.&#xA;I am new to AWS and micro service architecture, please help me map the components of the architecture to AWS components.</p>&#xA;&#xA;<p>Do i consider each micro service to run on one EC2 instance with auto scaling and load balancing?&#xA;Or do I run each micro service on one EC2 cluster?</p>&#xA;&#xA;<p>If i put my static html files in an S3, how can i call database methods to load the html pages with content? &#xA;Is it by calling am API gateway from the client?</p>&#xA;&#xA;<p>I have searched the web, but was unable to find a tutorial which implements multiple services as micro services using AWS EC2 / ECS.</p>&#xA;&#xA;<p>Please help me figure out how to map my requirements and if there are any tutorials on implementing a similar app, will be very helpful.</p>&#xA;&#xA;<p>Thank you in advance! :)</p>&#xA;"
40760397,java.lang.ClassNotFoundException on Maven dependencies,2016-11-23 09:23:29,<java><spring><maven><spring-boot><microservices>,1,542,4,3.0,3,"<p>We have a set of Spring Boot applications organized as microservices running successfully for a few months. We used Sprig Boot 1.3.3.</p>&#xA;&#xA;<p>Now we have a problem with maven build process switching to Spring Boot 1.4.2. We are developing microservice based software architecture. We have <strong>core.common</strong> service which is referenced by other services using dependecies like this:</p>&#xA;&#xA;<pre><code>&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;com.group&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;core.common&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;        &lt;scope&gt;compile&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt; &#xA;</code></pre>&#xA;&#xA;<p>This service is responsible for providing common classes and methods needed to each of other services. </p>&#xA;&#xA;<p>We also use separate service (<strong>root.service</strong>) to build <strong>all other services</strong> and to package them into <code>jar</code> files. This is the part of <code>pom.xml</code> from that <strong>root.service</strong>:</p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;modules&gt;&#xA;        &lt;module&gt;../core.adminservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.locationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.reportservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.userservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.notificationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.trackingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.mappingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.common&lt;/module&gt;&#xA;    &lt;/modules&gt;&#xA;</code></pre>&#xA;&#xA;<p>Until switched to Spring Boot 1.4.2 version we were able to do <code>mvn clean install</code> over <strong>root.service</strong> to test and build the rest of the services from <strong>modules</strong> specification. </p>&#xA;&#xA;<p>After switching to Spring Boot 1.4.2 version, when I try to execute <code>mvn clean install</code> in <strong>root.service</strong> I am getting <code>java.lang.ClassNotFoundException</code>. Exception message says that none of the services form <strong>modules</strong> specification cannot find any of classes from <strong>core.common</strong> service used in particular service from <strong>modules</strong>.&#xA;When I try to run <code>mvn compile</code> or <code>mvn test</code> everything runs just fine and I get successful builds and tests. When I try to run services from <strong>eclipse</strong> also everything is just fine.</p>&#xA;&#xA;<p>Do you have any ideas? Please help.</p>&#xA;&#xA;<p><strong>EDIT</strong>&#xA;Full stack trace for one use case:</p>&#xA;&#xA;<pre><code>Running com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.002 sec &lt;&lt;&lt; FAILURE! - in com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;initializationError(com.blockpeek.core.adminservice.tests.services.AdminServiceTest)  Time elapsed: 0.002 sec  &lt;&lt;&lt; ERROR!&#xA;java.lang.NoClassDefFoundError: com/blockpeek/core/common/services/AbstractCRUDService&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;Caused by: java.lang.ClassNotFoundException: com.blockpeek.core.common.services.AbstractCRUDService&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;</code></pre>&#xA;&#xA;<p>Maven Version:</p>&#xA;&#xA;<pre><code>$ mvn -version&#xA;Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T17:41:47+01:00)&#xA;Maven home: C:\Program Files\apache-maven-3.3.9&#xA;Java version: 1.8.0_101, vendor: Oracle Corporation&#xA;Java home: C:\Program Files\Java\jdk1.8.0_101\jre&#xA;Default locale: en_US, platform encoding: Cp1252&#xA;OS name: ""windows 10"", version: ""10.0"", arch: ""amd64"", family: ""dos""&#xA;</code></pre>&#xA;&#xA;<p><strong>EDIT 2:</strong> This is what I get if i run <code>mvn -e clean install</code>:</p>&#xA;&#xA;<pre><code>[ERROR] -&gt; [Help 1]                                                                                                                             &#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:compile (def&#xA;ult-compile) on project core.adminservice: Compilation failure                                                                                  &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)                                                      &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)                             &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)                              &#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)                &#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)                                              &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)                                                                       &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)                                                                       &#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)                                                                         &#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)                                                                             &#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)                                                                              &#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)                                                                                &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                          &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                        &#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                &#xA;        at java.lang.reflect.Method.invoke(Method.java:498)                                                                                     &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)                                                  &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)                                                          &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)                                                &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)                                                            &#xA;Caused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure                                                    &#xA;        at org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:1029)                                        &#xA;        at org.apache.maven.plugin.compiler.CompilerMojo.execute(CompilerMojo.java:137)                                                         &#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)                                    &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)                                                      &#xA;        ... 20 more                                                                                                                             &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.                                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:                                       &#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] After correcting the problems, you can resume the build with the command                                                                &#xA;[ERROR]   mvn &lt;goals&gt; -rf :core.adminservice  &#xA;</code></pre>&#xA;"
48458627,How to filter and sort data from multiple microservices?,2018-01-26 09:27:49,<architecture><microservices>,1,362,0,3.0,3,"<p>We have microservices which work with different, but related data. For example, ads and their stats. We want to be able to filter, sort and aggregate this related data for UI(and not only for it). For example, we want to show to a user ads which have 'car' in their text and which have more than 100 clicks.</p>&#xA;&#xA;<p><strong>Challenges:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There could be a lot of data. Some users have millions of rows after filtration</li>&#xA;<li>Services doesn't have all the data. For example, for statistics service ad without stats == non existent ad. It doesn't know anything about such ads. But sorting and filtration should work anyway(ad without stats should be considered as ad without zero clicks)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Requirements:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Eventual consistency within couple of seconds is OK</li>&#xA;<li>Data loss is not acceptable</li>&#xA;<li>5 to 10 seconds filtration and sorting for big clients with millions of rows is OK</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solutions we could think of:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Load all data required by query from all services and filter and sort it in memory.</li>&#xA;<li>Push updates from services to Elasticsearch(or something like this). Elastic handles query and returns ids of desired entities which then loaded from services.</li>&#xA;<li>One big database for all services which has everything</li>&#xA;</ul>&#xA;&#xA;<p>What should we pay attention to? Are there other ways to solve our problem?</p>&#xA;"
48525262,"Visual Studio Container Tools requires Docker to be running before building, debugging or running a containerized project",2018-01-30 15:41:32,<docker><visual-studio-2017><docker-compose><microservices><asp.net-core-webapi>,1,1793,2,0.0,3,"<p>I am working on .Net core Microservices. I installed Docker Toolbox containing docker cli and kitematics. After that i created a simple (.Net core) web api project in visual studio 2017 and also enable docker support.</p>&#xA;&#xA;<p>But when i hit  F5 to run the program it shows following error and doesn't run.</p>&#xA;&#xA;<p><strong>Visual Studio Container Tools requires Docker to be running before building, debugging or running a containerized project.</strong></p>&#xA;&#xA;<p>Please review the attached image.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NEvRa.png"" rel=""nofollow noreferrer"">Visual studio error on running the project</a></p>&#xA;&#xA;<p>If i build and run the project using docker cli, it's working. The problem is with visual studio 2017.</p>&#xA;"
37697171,"Docker, independent multiple rails instances",2016-06-08 08:30:43,<ruby-on-rails><docker><docker-compose><microservices>,1,528,0,4.0,3,"<p>I an trying to create a development environment with multiple microservices running like in a production environment.</p>&#xA;&#xA;<p>I would like to run with Docker two <code>rails applications</code> that makes calls between them. </p>&#xA;&#xA;<p>I know that I can use <code>links</code>, but with this I always has to run one of them as the master one. That means, that I only can debug this one, and I would like to see the console ouput of each of them. Maybe I am doing something wrong, and that's why I am asking.</p>&#xA;&#xA;<p>This is my docker-compose.yml file:</p>&#xA;&#xA;<pre><code>rails-app-A:&#xA;  build: .&#xA;  dockerfile: ""DockerfileA""&#xA;  environment:&#xA;    RAILS_ENV: development&#xA;  links:&#xA;    - db&#xA;  command: bundle exec rails server -p 3005 -b '0.0.0.0'&#xA;  volumes:&#xA;    - "".:/home/app""&#xA;  volumes_from:&#xA;    - bundle&#xA;  expose:&#xA;    - ""3005""&#xA;  ports:&#xA;    - ""3005:3005""&#xA;&#xA;rails-app-B:&#xA;  build: .&#xA;  dockerfile: ""DockerfileB""&#xA;  environment:&#xA;    RAILS_ENV: development&#xA;  links:&#xA;    - db&#xA;  command: bundle exec rails server -p 3000 -b '0.0.0.0'&#xA;  volumes:&#xA;    - "".:/home/app""&#xA;  volumes_from:&#xA;    - bundle&#xA;  expose:&#xA;    - ""3000""&#xA;  ports:&#xA;    - ""3000:3000""&#xA;</code></pre>&#xA;&#xA;<p>This is how I run the rails app:</p>&#xA;&#xA;<pre><code>docker-compose run --service-ports rails-app-A&#xA;docker-compose run --service-ports rails-app-B&#xA;</code></pre>&#xA;&#xA;<p>I always get errors like these:</p>&#xA;&#xA;<pre><code>Errno::ECONNREFUSED: Connection refused - connect(2) for ""localhost"" port 3000&#xA;&#xA;Errno::ECONNREFUSED (Failed to open TCP connection to localhost:3000 (Connection refused - connect(2) for ""localhost"" port 3000))&#xA;</code></pre>&#xA;&#xA;<p>The thing is that I can access to all of them with the browser.</p>&#xA;&#xA;<p>With the Docker version for OSX using VirtualBox this was working fine (just calling <code>localhost:3000</code> or <code>localhost:3005</code>), but in Ubuntu or with Docker-beta, is failing.</p>&#xA;&#xA;<h1>EDIT</h1>&#xA;&#xA;<p>I understand that ""localhost"" for rails-app-A is a different server as ""localhost"" in rails-app-B, because they run as different machines. When I had <code>VirtualBox</code> I could access because I had the IP of the VirtualBox instance (192.169.99.100).</p>&#xA;&#xA;<p>I am now using <code>http://localtunnel.me/</code> and I can access to the other services. But, anyway, <strong>Is there a better way to do this?</strong></p>&#xA;"
47837207,Entity-level access restriction in the microservice architecture based on user or group membership,2017-12-15 17:31:03,<security><design><architecture><permissions><microservices>,3,982,1,1.0,3,"<p>In the systems, there may be data that is restricted in nature. &#xA;Sometimes access to specific entities should be easily restricted or granted based on user or group membership. </p>&#xA;&#xA;<p>What is the best way to implement this in the microservice architecture?</p>&#xA;&#xA;<h2>#1</h2>&#xA;&#xA;<p>Should access control, managing permissions etc. be the responsibility of the microserive itself? Developers will have to implement access control, store, and update permissions for every service. Seems like not very robust and error-prone approach.</p>&#xA;&#xA;<h2>#2</h2>&#xA;&#xA;<p>Create dedicated microservice handling permission management? This service will be called by other microserives to check access permissions for each entity and filtering entities before returning results. Centralized permissions storage and management is an advantage but microservice will have to make a call to ""Permission Service"" for each entity to check access rights what may have a negative influence on performance. And developers still have to integrate access checks into their services what leaves space for an error.</p>&#xA;&#xA;<h2>#3</h2>&#xA;&#xA;<p>Make access control responsibility of the API Gateway or Service Mesh. It is possible to think of an implementation that will automatically filter responses of all services. But in the case when the microservice returns list of entities permissions should be checked for each entity. Still a potential performance problem.</p>&#xA;&#xA;<h2>Example</h2>&#xA;&#xA;<p>Consider the following synthetic example. &#xA;Healthcare system dealing with test results, X-Ray images etc. Health information is very sensitive and should not be disclosed.</p>&#xA;&#xA;<p>Test results should be available only to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>laboratory</li>&#xA;</ul>&#xA;&#xA;<p>Attending doctor may send the patient to another specialist. A new doctor should have access to test results too. So access can be granted dynamically.</p>&#xA;&#xA;<p>So each entity (e.g. test results, X-Ray image) has a set of rules what users and groups are allowed to access it.</p>&#xA;&#xA;<p>Imagine there is a microservice called ""Test Results Service"" dealing with test results. Should it be responsible for access control, manage permissions etc.? Or permissions management should be extracted to separate microservice?</p>&#xA;&#xA;<p>Healthcare system may also handle visits to a doctor. Information about patient's visit to the doctor should be available to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>clinic receptionist</li>&#xA;</ul>&#xA;&#xA;<p>This is the example of a different entity type that requires entity level access restriction based on user or group membership.</p>&#xA;&#xA;<p>It is easy to imagine even more examples when entity level access control is required.</p>&#xA;"
45241581,Microservices vs functions as service (faas),2017-07-21 15:36:08,<aws-lambda><microservices>,1,909,0,1.0,3,"<p>Microservice architecture is/was next big thing. Easy to deploy, easy to develeop, not as complicated to scale and develop as monolith systems.</p>&#xA;&#xA;<p>Oriented mostly towards containers, it all looked new and promising, but i recently discovered there is a new hype about function as service or faas (aws lambda for example). </p>&#xA;&#xA;<p>Wikipedia says the following about Faas ""Building an application following this model is one way of achieving a ""serverless"" architecture, and is typically used when building microservices applications.""</p>&#xA;&#xA;<p>My conclusion was that in faas one should not worry about maintaining hardware and network resources. But is that the only advantage? Could microservice architecture pattern be fully achieved using functions as service?</p>&#xA;"
45167593,Authorization of actions across microservices,2017-07-18 13:01:29,<web-services><rest><authorization><microservices><event-sourcing>,2,108,1,1.0,3,"<p>A modern multi-user web application imposes a lot of restrictions on the actions that users can perform. In other words, the actions require authority. For example, a user can only change its own personal data, and only members of a group can post content to that group. In a classic monolith application, such restrictions are easily enforced by joining several database tables and acting according to the results of queries. However, with microservices, it becomes much less clear where and how such limitations should be handled.</p>&#xA;&#xA;<p>For the sake of argument, consider a Facebook clone. The whole application consists of several parts:</p>&#xA;&#xA;<ul>&#xA;<li>A front-end, written in JS and other web technologies</li>&#xA;<li>A backend consisting of a number of microservices</li>&#xA;<li>An API for retrieving and submitting data to the backend, i.e. a gateway</li>&#xA;</ul>&#xA;&#xA;<p>As for the business logic, there are (among others) two well-known entities:</p>&#xA;&#xA;<ul>&#xA;<li>Events (as in concerts, birthday parties etc.)</li>&#xA;<li>Posts (text entries existing on walls, pages, events etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Suppose that these two entities are managed by separate services, EventService and PostService. Then consider the following constraint:</p>&#xA;&#xA;<blockquote>&#xA;  <p>A post to an event can be deleted by two kinds of users: the author of the post, and the host(s) of the event.</p>&#xA;</blockquote>&#xA;&#xA;<p>In a monolith, this constraint would've been conceptually very easy to deal with. Upon receiving a request to delete a post, supplying the post id and user id,</p>&#xA;&#xA;<ol>&#xA;<li>Fetch the event which the post belongs to.</li>&#xA;<li>Check if the user is the author of the post.</li>&#xA;<li>If yes, delete the post. If not, fetch the hosts of the event.</li>&#xA;<li>Check if the user is among the hosts.</li>&#xA;<li>If yes, delete the post.</li>&#xA;</ol>&#xA;&#xA;<p>However, with a microservice strategy, I have a hard time figuring out how to divide the responsibilities of an operation like this across the services.</p>&#xA;&#xA;<h2>Alternative 1</h2>&#xA;&#xA;<p>An easy way around it would be to put logic like this in the gateway. That way, the same procedure as described above could essentially be performed, but with calls to the services instead of directly to the database. Rough sketch:</p>&#xA;&#xA;<pre class=""lang-js prettyprint-override""><code>// Given postId and userId&#xA;// Synchronous solution for presentational purposes&#xA;&#xA;const post = postClient('GET', `/posts/${postId}`);&#xA;const hosts = eventClient('GET', `/events/${post.parentId}/hosts`);&#xA;const isHost = hosts.find(host =&gt; host.id == userId);&#xA;&#xA;if (isHost) {&#xA;    postClient('DELETE', `/posts/${postId}`);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I'm not happy with this solution. Once I start putting logic like this in the gateway, it'll become very tempting to <em>always</em> do it, as it's a quick and simple way to get things done. All business logic would eventually amass in the gateway, and the services would become ""stupid"" CRUD endpoints. This would defeat the purpose of having separate services with well-defined areas of responsibility.  Furthermore, it could be slow as it could give rise to a high number of calls to the services when operations are getting more complex.</p>&#xA;&#xA;<p>I would essentially be reinventing the monolith, replacing database queries with slow and limited network calls.</p>&#xA;&#xA;<h2>Alternative 2</h2>&#xA;&#xA;<p>Another option would be to allow unlimited communication <em>between</em> services, allowing PostService to simply ask EventService whether the user is a host of the event in question before performing the delete. However, I'm afraid that having a potentially large number of microservices communicating with each other could introduce a lot of coupling in the longer run. Experts seem to generally advise against direct inter-service communication.</p>&#xA;&#xA;<h2>Alternative 3</h2>&#xA;&#xA;<p>With a solid system for publishing and subscribing to events, the services could stay updated about what happens in other services. For example, every time a user is promoted to host in EventService, an event would be posted (e.g. <code>events.participant-status-changed, {userId: 14323, eventId: 12321, status: 'host'}</code>). PostService could subscribe to the event and remembering this fact when a request to delete a post is received.</p>&#xA;&#xA;<p>However, I'm not quite happy with this one either. It'd create a very intricate and error-prone system, where an unhandled (but potentially rare) event could make services go out of sync. Also, there's a risk that logic would end up in the wrong place. For example, the constraint in this question would be handled by PostService even though conceptually it's a property of the event entity.</p>&#xA;&#xA;<p>I should stress though that I'm very optimistic about the usefulness of events when implementing applications using microservices. I'm just not sure they are the answer to this category of problems.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How would you tackle this hypothetical, but quite realistic difficulty?</p>&#xA;"
45351222,Is it possible to proxy a POJO in microservices application?,2017-07-27 12:45:39,<java><spring-boot><microservices>,1,140,2,0.0,3,"<p>I would like to avoid duplicating my POJOs in a microservices application, so I am wondering if there is a way to do that (like proxying)?</p>&#xA;&#xA;<p>I mean, is there a way for a <code>Service A</code> to access POJOs (or other classes/interfaces) defined inside a <code>Service B</code> without physically creating these POJOs classe files in <code>Service A</code>? </p>&#xA;&#xA;<p>The big big challenge in a microservice architecture is that point and I didn't find a way to solve it.</p>&#xA;"
40422613,Sharing data between isolated microservices,2016-11-04 12:24:29,<web-services><heroku><database-design><web-applications><microservices>,1,804,1,3.0,3,"<p>I'd like to use the microservices architectural pattern for a new system, but I'm having trouble figuring out how to share and merge data between the services when the services are isolated from each other. In particular, I'm thinking of returning consolidated data to populate a web app UI over HTTP.</p>&#xA;&#xA;<p>For context, I'm intending to deploy each service to its own isolated environment (Heroku) where I won't be able to communicate internally between services (e.g. via <code>//localhost:PORT</code>. I plan to use RabbitMQ for inter-service communication, and Postgres for the database.</p>&#xA;&#xA;<p>The decoupling of services makes sense for CREATE operations:</p>&#xA;&#xA;<ul>&#xA;<li>Authenticated user with <code>UserId</code> submits 'Join group' webform on the frontend</li>&#xA;<li>A new <code>GroupJoinRequest</code> including the <code>UserId</code> is added to the RabbitMQ queue</li>&#xA;<li>The <code>Groups</code> service picks up the event and processes it, referencing the user's <code>UserId</code></li>&#xA;</ul>&#xA;&#xA;<p>However, READ operations are much harder if I want to merge data across tables/schemas. Let's say I want to get details for all the users in a certain group. In a monolithic design, I'd just do a SQL <code>JOIN</code> across the Users and the Groups tables, but that loses the isolation benefits of microservices.</p>&#xA;&#xA;<p>My options seem to be as follows:</p>&#xA;&#xA;<h3>Database per service, public API per service</h3>&#xA;&#xA;<p>To view all the <code>Users</code> in a <code>Group</code>, a site visitor gets a list of <code>UserID</code>s associated with a group from the Groups service, then queries the <code>Users</code> service separately to get their names.</p>&#xA;&#xA;<p><strong>Pros:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>very clear separation of concerns</li>&#xA;<li>each service is entirely responsible for its own data</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>requires multiple HTTP requests</li>&#xA;<li>a lot of postprocessing has to be done client-side</li>&#xA;<li>multiple SQL queries can't be optimized</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data over HTTP, single public API</h3>&#xA;&#xA;<p>A public API server handles request endpoints. Application logic in the API server makes requests to each service over a HTTP channel that is only accessible to other services in the system.</p>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>good separation of concerns</li>&#xA;<li>each service is responsible for an API contract but can do whatever it wants with schema and data store, so long as API responses don't change</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>non-performant</li>&#xA;<li>HTTP seems a weird transport mechanism to be using for internal comms</li>&#xA;<li>ends up exposing multiple services to the public internet (even if they're notionally locked down), so security threats grow from greater attack surface</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data through message broker</h3>&#xA;&#xA;<p>Given I've already got RabbitMQ running, I could just use it to queue requests for data and then to send the data itself. So for example:</p>&#xA;&#xA;<ul>&#xA;<li>client requests all Users in a Group</li>&#xA;<li>the public API service sends a <code>GetUsersInGroup</code> event with a <code>RequestID</code></li>&#xA;<li>the <code>Groups</code> service picks this up, and adds the <code>UserID</code>s to the queue</li>&#xA;<li>The `Users service picks this up, and adds the User data onto the queue</li>&#xA;<li>the API service listens for events with the <code>RequestID</code>, waits for the responses, merges the data into the correct format, and sends back to the client</li>&#xA;</ul>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Using existing infrastructure</li>&#xA;<li>good decoupling</li>&#xA;<li>inter-service requests remain internal (no public APIs)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Multiple SQL queries</li>&#xA;<li>Lots of data processing at the application layer</li>&#xA;<li>harder to reason about</li>&#xA;<li>Seems strange to pass large quantities around data via event system</li>&#xA;<li>Latency?</li>&#xA;</ul>&#xA;&#xA;<h3>Services share a database, separated by schema, other services read from <code>VIEW</code>s</h3>&#xA;&#xA;<p>Services are isolated into database schemas. Schemas can only be written to by their respective services. Services expose a SQL <code>VIEW</code> layer on their schemas that can be queried by other services. </p>&#xA;&#xA;<p>The <code>VIEW</code> functions as an API contract; even if the underlying schema or service application logic changes, the <code>VIEW</code> exposes the same data, so that </p>&#xA;&#xA;<p><strong>Pros</strong>: </p>&#xA;&#xA;<ul>&#xA;<li>Presumably much more performant (single SQL query can get all relevant data)</li>&#xA;<li>Foreign key management much easier</li>&#xA;<li>Less infrastructure to maintain</li>&#xA;<li>Easier to run reports that span multiple services</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>tighter coupling between services</li>&#xA;<li>breaks the idea of fundamentally atomic services that don't know about each other</li>&#xA;<li>adds a monolithic component (database) that may be hard to scale (in contrast to atomic services which can scale databases independently as required)</li>&#xA;<li>Locks all services into using the same system of record (Postgres might not be the best database for all services)</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>I'm leaning towards the last option, but would appreciate any thoughts on other approaches.</p>&#xA;"
40539447,Run two processes in a single docker container or two containers connecting to the same DB?,2016-11-11 00:37:10,<python><docker><containers><apache-kafka><microservices>,1,224,1,1.0,3,"<p>I need to develop an application that listens to a kafka topic and saves the data to a DB (cassandra). It will be a high density stream of data so saving the data will be resource expensive. Once the data is saved it will be queried and exposed through a REST API.</p>&#xA;&#xA;<p>I see two options, but both of them have downsides:</p>&#xA;&#xA;<p><strong>Option 1</strong><br>&#xA;Create two services, each one in a separate docker container. One would run only the kafka listener process in python and the other one a flask web server.<br>&#xA;<em>Advantages</em>: Every container runs only one process<br>&#xA;<em>Downsides</em>: Both services connect to the same DB, which is not ideal according to the microservices pattern architecture, for the services are not completely decoupled.</p>&#xA;&#xA;<p><strong>Option 2</strong><br>&#xA;Run both, kafka listener and web service in one container.<br>&#xA;<em>Advantages</em>: Just one service to connect to the DB.<br>&#xA;<em>Downsides</em>: More than one process running in a single docker container, and one of them (saving and updating) would be a lot more resource expensive than the other, so it would not scale uniformly.   </p>&#xA;&#xA;<p>Is there another way to go that doesn't involve moving to a monolithic architecture? Or which one of them is the best practice?</p>&#xA;"
41164987,User's locale in microservice - JHipster,2016-12-15 13:09:07,<java><spring-security><jwt><jhipster><microservices>,1,264,0,0.0,3,"<p>In one of the microservices, in a JHipster microservice architecture, I want to generate a document, in the users' language.</p>&#xA;&#xA;<p>In the gateway, the users' language is retrieved by a cookie (AngularCookieLocaleResolver). But when a request, routed through the gateway, arrives at the microservice, no cookies are found on the request.</p>&#xA;&#xA;<p>I see a few options here:</p>&#xA;&#xA;<ol>&#xA;<li>Add a locale claim to the JWT-token</li>&#xA;<li>Contact the gateway with the username, to retrieve the locale</li>&#xA;<li>Do not generate locale specific content at a microservice</li>&#xA;</ol>&#xA;&#xA;<p>I would prefer the first option, but maybe there are some better options...</p>&#xA;&#xA;<p>Can anyone help me choose or list up alternatives?</p>&#xA;"
41036330,Store private key in microservices,2016-12-08 09:49:19,<microservices><private-key><public-key>,1,140,0,1.0,3,"<p>There are some microservice which communicating with each other with rsa encrypted messages. The private keys are in files currently, what is the best practice to store the private and public keys in the containers? The current solution is in the /etc/ssl, but this is a little bit hard to manage and not to safety.</p>&#xA;"
45853546,"Two processes reside in different AP servers and refer to a same boolean flag. (Spring, Java)",2017-08-24 05:25:54,<java><spring><microservices><consistency>,4,41,0,0.0,3,"<p>I am using Spring Framework to develop a web application. I have two services which are going to store some processed results into one table T in Database. The logic now is:</p>&#xA;&#xA;<p><strong>Service A</strong></p>&#xA;&#xA;<pre><code>for all items:&#xA;    result = func(item)&#xA;    store result to Table T (with status = new)&#xA;is_running = False&#xA;</code></pre>&#xA;&#xA;<p><strong>Service B</strong></p>&#xA;&#xA;<pre><code>for some items:&#xA;    if is_running == False:&#xA;        result = func(item)&#xA;        store result to Table T (with status = new)&#xA;    else:&#xA;        store result to Table T (with status = inprogress)&#xA;</code></pre>&#xA;&#xA;<p>The boolean flag <code>is_running</code> will be a field in Service A.</p>&#xA;&#xA;<p>Since we have MicroService Architechture for the domain server, Service A and Service B may reside in different AP servers. How can I ensure Servie A and Service B refer to the same <code>is_running</code>?</p>&#xA;&#xA;<p>Is it possible to use <a href=""https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html#beans-factory-scopes"" rel=""nofollow noreferrer"">Spring's bean scope</a> to achieve this?</p>&#xA;"
46002727,What is the difference between an API-Gateway and an Edge Service?,2017-09-01 14:42:21,<microservices>,1,935,0,0.0,3,"<p>I understand the concept behind an API gateway as described by Richardson:</p>&#xA;&#xA;<p><a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a></p>&#xA;&#xA;<p>But what is the difference to an Edge service. Is this a concrete implementation of the API gateway pattern?</p>&#xA;"
45648115,Dockering a nodejs application with external dependencies,2017-08-12 08:20:12,<node.js><docker><containers><microservices>,2,178,0,1.0,3,"<p>We are building Node.js microservices. For some reusable components we have created a utils folder. This folder is outside the actual microservices package. When we run the microservices, we can refer to that code using <code>require(../../utils/logger)</code> and it works like a charm.&#xA;However when trying to create the docker image for my microservices </p>&#xA;&#xA;<pre><code>project the container gives me an error saying:&#xA;Error: Cannot find module '../../Utils/logger&#xA;</code></pre>&#xA;&#xA;<p>which makes a lot of sense as we are building the docker image inside the microservice project.&#xA;There are few architectural decisions which needs to be taken here:</p>&#xA;&#xA;<ol>&#xA;<li><p>We move the utils code into each microservice as required.</p>&#xA;&#xA;<ul>&#xA;<li>Pro: Microservice remains self sustained completely and no code level dependency on any other package.</li>&#xA;<li>Cons: Maintenance of cross cutting concerns and the changes would be cumbersome.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>2.Create a private npm module and inject dependency into the microservice package.json file. Not sure if that would work.</p>&#xA;&#xA;<p>Any suggestions on this are highly appreciated.</p>&#xA;&#xA;<p>Best,&#xA;- Vaibhav</p>&#xA;"
45688730,Decompose microservices: Business capability vs Domain,2017-08-15 08:01:46,<domain-driven-design><microservices><software-design>,1,1010,2,3.0,3,"<p>As I read, there are two patterns to define one microservice, by <a href=""http://microservices.io/patterns/decomposition/decompose-by-business-capability.html"" rel=""nofollow noreferrer"">business capability</a> and by <a href=""http://microservices.io/patterns/decomposition/decompose-by-subdomain.html"" rel=""nofollow noreferrer"">subdomain</a>. But I still find it very ambiguous. I get confused how these two patterns differentiate from each other. Both of them revolve around activities involving an area of business logic. All of components in each service are small enough to get packaged with each other without affecting other services. Could anyone please give me a further explanation about these two?</p>&#xA;"
28339882,"service discovery, load balancing and connection pooling approach",2015-02-05 09:03:45,<load-balancing><connection-pooling><soa><microservices>,1,642,0,1.0,4,<p>There are two approaches that can be used for service interaction when having SOA for large systems deployed on cloud like AWS.</p>&#xA;&#xA;<ol>&#xA;<li><p>Have each service cluster behind internal elb. client makes a connection pool with corresponding elb and elb does round-robin balancing.</p></li>&#xA;<li><p>going with service discovery approach like netflix eureka.</p></li>&#xA;</ol>&#xA;&#xA;<p>Currently we are using 1st approach where each service cluster is behind internal elb and clients communicate via elbs so each client instance has to maintain only 1 pool i.e. with the elb endpoint.</p>&#xA;&#xA;<p>I have following doubts regarding 2nd apporach.</p>&#xA;&#xA;<ol>&#xA;<li>Is there a benefit in moving to service discovery and smart client architecture where service client knows all service instances (via eureka service or equivalent) and does internal load balancing?</li>&#xA;<li>In above case how does connection pooling work? Currently each client instance has to maintain exactly 1 connection pool i.e. with the corresponding service's elb. But with rich client each client will have all the service instance endpoints to directly communicate to. Making connection on each request will not be efficient and having so many connection pools (1 for each service instance) for each client is a overkill I guess.</li>&#xA;</ol>&#xA;&#xA;<p>Need inputs/suggestions on above two questions.</p>&#xA;
29071226,What is a good practice to promote a microservice to a public API?,2015-03-16 07:03:15,<design><architecture><microservices>,3,996,0,3.0,4,"<p>Microservices seem to be a very good fit for my software after watching and reading number of articles from Martin Fowler, Sam Newman, Adrian Cockcroft and Sudhir Tones. However, when thinking deeper into the implementation, there are number of concerns:</p>&#xA;&#xA;<ol>&#xA;<li>My software has an UI, let's call it a web-based component. This component will need to coordinate/orchestrate calls to 10-20 different microservices internally (let's call it ""private microservices"") and return data to the AJAX call. Is it a good design to couple the orchestration logic in this component? Or should I create another microservice that does the job and the web-based component should be very thin to delegate the call to this microservice?</li>&#xA;<li>I will need to expose some public APIs. Should I have a separate layer to delegate the call like in the case above? </li>&#xA;</ol>&#xA;&#xA;<p>I think it might be more or less about the design pattern for public/private microservices. </p>&#xA;&#xA;<p>What would be a good pattern to address the above concerns?</p>&#xA;&#xA;<p><strong>Updated on 9 Apr 2015</strong>:</p>&#xA;&#xA;<p>API Gateway Pattern actually addresses my concerns. I also agree with other answers regarding EAI patterns or security consideration.</p>&#xA;&#xA;<p>To extend more regarding my findings, I think Netflix architecture is having, so-called ""edge service"", which is the front tier that is serving requests coming from either web-based or devices and the middle-tier services are actually your microservices. So i think to promote a middle-tier service to be an edge-service, this has to be a delegate. It will keep the middle-tier clean and consistent. </p>&#xA;&#xA;<p>Have a look at <a href=""https://github.com/cfregly/fluxcapacitor#project-overview"" rel=""nofollow"">https://github.com/cfregly/fluxcapacitor#project-overview</a> to have more ideas.</p>&#xA;"
26529567,What are the strategies available for doing pagination or filtering data using microservices architecture?,2014-10-23 13:46:09,<filter><pagination><filtering><paging><microservices>,1,743,0,1.0,4,<p>Usually when you have a monolithic application or data model then you can create a SQL joining different tables and apply filters to them. Then once you get resultset back you can page that data as well. But if you are using microservice architecture the data model might be disparate. I heard netflix actually takes it to an extreme where they have every table  exposed as a microservice. How can you handle paging and filtering in this case?</p>&#xA;&#xA;<p>I know they use API Gateway pattern which  could act as aggregation layer (probably this is where RxJava like projects come in). It would be great to have ideas from people using microservices or tackle this problem.</p>&#xA;
30995669,Microservices service registry registration and discovery,2015-06-23 06:46:40,<web-services><rest><service><amqp><microservices>,1,1494,0,3.0,4,"<p><strong>Little domain presentation</strong></p>&#xA;&#xA;<p>I m actually having two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User - managing CRUD on users</li>&#xA;<li>Billings - managing CRUD on billings, with a ""reference"" on a user concerned by the billing</li>&#xA;</ul>&#xA;&#xA;<p><strong>Explanation</strong></p>&#xA;&#xA;<p>I need, when a billing is called in a HTTP request, to send the fully billing object with the user loaded. In that case, and in this specifical case, I really need this.</p>&#xA;&#xA;<p>In a first time, I looked around, and it seems that it was a good idea to use message queuing, for asynchronicity, and so the billing service can send on a queue :</p>&#xA;&#xA;<blockquote>&#xA;  <p>""who's the user with the id 123456 ? I need to load it""</p>&#xA;</blockquote>&#xA;&#xA;<p>So my two services could exchange, without really knowing each other, or without knowing the ""location"" of each other.</p>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>My first question is, what is the aim of using a service registry in that case ? The message queuing is able to give us the information without knowing anything at all concerning the user service location no ?</p></li>&#xA;<li><p>When do we need to use a service registration :&#xA;In the case of Aggregator Pattern, with RESTFul API, we can navigate through hateoas links. In the case of Proxy pattern maybe ? When the microservices are interfaced by another service ?</p></li>&#xA;<li><p>Admitting now, that we use proxy pattern, with a ""frontal service"". In this case, it's okay for me to use a service registration. But it means that the front send service know the name of the userService and the billing service in the service registration ? Example :</p></li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>Service User registers as ""UserServiceOfHell:<a href=""http://80.80.80.80/v1/"" rel=""nofollow"">http://80.80.80.80/v1/</a>""&#xA;  on ZooKeeper</p>&#xA;  &#xA;  <p>Service Billing registers as ""BillingService:<a href=""http://90.90.90.90/v4.3/"" rel=""nofollow"">http://90.90.90.90/v4.3/</a>""</p>&#xA;</blockquote>&#xA;&#xA;<p>The front end service  needs to send some requests to the user and billing service, it implies that it needs to know that the user service is ""UserServiceOfHell"". Is this defined at the beginning of the project ?</p>&#xA;&#xA;<ul>&#xA;<li>Last question, can we use multiple microservices patterns in one microservices architecture or is this a bad practice ?</li>&#xA;</ul>&#xA;&#xA;<p><em>NB : Everything I ask is based on <a href=""http://blog.arungupta.me/microservice-design-patterns/"" rel=""nofollow"">http://blog.arungupta.me/microservice-design-patterns/</a></em></p>&#xA;"
41445442,How to sync the database with the microservices (and the new one)?,2017-01-03 14:12:27,<mysql><database><message-queue><microservices><nsq>,1,888,12,0.0,4,"<p>I'm developing a website with the microservice architecture, and each of the service owns a database. The database stores the data which the microservice needs.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><code>Post</code>, <code>Video</code> services need the user information, so both of the services subscribed to the <code>NEW_USER_EVENT</code>. </p>&#xA;&#xA;<p>The <code>NEW_USER_EVENT</code> will be triggered when there's a new user registered.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0SY8a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0SY8a.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Once the services received the <code>NEW_USER_EVENT</code>, they put the incoming user information to each of their own database. So they can do things without asking the <code>User</code> service.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NR8Xk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NR8Xk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>So far so good. But here comes the question:</p>&#xA;&#xA;<ul>&#xA;<li>What if I'm going to create a new service? How do I get the registered user informations and put them in the new service?</li>&#xA;</ul>&#xA;&#xA;<p>Maybe I can get the informations from the existing services. But the events are pushed by the messaging queue (<code>NSQ</code>). </p>&#xA;&#xA;<p>If I'm going to copy the data from one of the microservices, how do I make sure which service has the latest user informations? (<em>Because some services haven't received the latest event</em>) </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/vJoGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vJoGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><em>Read More:</em></p>&#xA;&#xA;<p><a href=""http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/"" rel=""nofollow noreferrer"">The Hardest Part About Microservices: Your Data</a></p>&#xA;&#xA;<p><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""nofollow noreferrer"">Intro to Microservices, Part 4: Dependencies and Data Sharing</a></p>&#xA;"
30288968,Micro Services and noSQL - Best practice to enrich data in micro service architecture,2015-05-17 16:03:12,<microservices>,4,2100,0,5.0,4,"<p>I want to plan a solution that manages enriched data in my architecture.<br>&#xA;To be more clear, I have dozens of micro services.<br>&#xA;let's say - Country, Building, Floor, Worker.<br>&#xA;All running over a separate NoSql data store.  </p>&#xA;&#xA;<p>When I get the data from the worker service I want to present also the floor name (the worker is working on), the building name and country name.</p>&#xA;&#xA;<p><strong>Solution1.</strong><br>&#xA;Client will query all microservices.<br>&#xA;Problem - multiple requests and making the client be aware of the structure.<br>&#xA;I know multiple requests shouldn't bother me but I believe that returning a json describing the entity in one single call is better.</p>&#xA;&#xA;<p><strong>Solution 2.</strong><br>&#xA;Create an orchestration that retrieves the data from multiple services.<br>&#xA;Problem - if the data (entity names, for example) is not stored in the same document in the DB it is very hard to sort and filter by these fields.</p>&#xA;&#xA;<p><strong>Solution 3.</strong><br>&#xA;Before saving the entity, e.g. worker, call all the other services and fill the relative data (Building Name, Country name).<br>&#xA;Problem - when the building name is changed, it doesn't reflect in the worker service. </p>&#xA;&#xA;<p><strong>solution 4.</strong><br>&#xA;(This is the best one I can come up with).<br>&#xA;Create a process that subscribes to a broker and receives all entities change.<br>&#xA;For each entity it updates all the relavent entities.<br>&#xA;When an entity changes, let's say building name changes, it updates all the documents that hold the building name.<br>&#xA;Problem:&#xA;Each service has to know what can be updated.&#xA;When a trailing update happens it shouldnt update the broker again (recursive update),  so this can complicate to the microservices.</p>&#xA;&#xA;<p><strong>solution 5.</strong><br>&#xA;Keeping everything normalized. Fileter and sort in ElasticSearch.&#xA;Problem: keeping normalized data in ES is too expensive performance-wise</p>&#xA;"
30267737,Microservice Database shared with other services,2015-05-15 19:56:41,<mysql><web-services><deployment><microservices>,1,1114,3,1.0,4,"<p>Something I have searched for but cannot find a straight answer to is this:</p>&#xA;&#xA;<p>For a given service, if there are two instances of that service deployed to two machines, do they share the same persistent store or do they have separate stores with some syncing mechanism (master/slave, clustering)?</p>&#xA;&#xA;<p>E.g. I have a OrderService backed by MySQL. We're getting many orders in so I need to scale this service up, so we deploy a second OrderService. Where does its data come from?</p>&#xA;&#xA;<p>It may sound silly but, to me, every discussion makes it seem like the service and database are a packaged unit that are deployed together. But few discussions mention what happens when you deploy a second service.</p>&#xA;"
52031350,How ACID works in a restful micro-service architecture,2018-08-27 00:47:44,<java><rest><microservices><acid>,1,59,2,1.0,4,"<p>I'm pretty new at implementing microservice architecture and this question is breaking my mind</p>&#xA;&#xA;<p>How a microservice architecture address transactional mechanism between different end-points calls.</p>&#xA;&#xA;<p>An example is banking services based on a microservice architecture&#xA;basically, the banking operation is for different calls to different services to complete a transaction, if one of them fails, then there is no way to eliminate the partial process, I do not know if there is any mechanism to solve this problem</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>create a payment</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /payments/customer/10/payment/100/ </p>&#xA;  &#xA;  <p><strong>debit money from the account</strong></p>&#xA;  &#xA;  <p><strong>PUT</strong> /customers/10/accounts/20</p>&#xA;  &#xA;  <p><strong>Send a customer notification</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /alerts/customers/10</p>&#xA;</blockquote>&#xA;"
33118913,Authentication and Authorization in Microservices,2015-10-14 07:13:53,<authentication><oauth-2.0><authorization><microservices>,1,608,0,1.0,4,"<p>I've been reading a fair bit on Microservices recently, and especially around AuthN and AuthZ. For the most part, this all makes a lot of sense, and I can see how it all should work.</p>&#xA;&#xA;<p>For what I'm playing with, I going with delegated authorization - so I'm to be passing tokens around from client to service, and then passing the same token on from service to service. I also have an endpoint on the OAuth2 Service that will accept a token and return the details of the token - the User ID, the Start and End of the validity period, the scopes that the token is valid for, etc.</p>&#xA;&#xA;<p>The problem that I'm running into here is - in order to correctly issue a token, there needs to be some communication with the User Service to ensure that the User that the token is for is actually valid. And in order to verify a Token, there needs to be some communication with the User Service to ensure that the User is still valid. And yet, in order to safely communicate with the User Service to get details about a User, a Token is needed that gives permission for this access.</p>&#xA;&#xA;<p>I assume there is some standard practice on how to solve this circular dependency between the OAuth2 and User Service, but I've not seen any mention of it at all. Is this a common problem? Or have I just missed something obvious?</p>&#xA;&#xA;<p>(Note - for now I'm only implementing Client Credentials Grant and Resource Owner Password Credentials Grant, since I'm only playing around to see how it all works and they're easier to call with cURL. I don't know that this makes any difference though)</p>&#xA;"
35264620,Feign Client + Eureka POST request body,2016-02-08 07:46:48,<spring><rest><microservices><netflix-eureka><netflix-feign>,1,5991,0,0.0,4,"<p>I'm trying to use Feign and Eureka to forward a post request from server A to server B. Both servers are discrovered sucessfully by Eureka.</p>&#xA;&#xA;<p>This works:</p>&#xA;&#xA;<pre><code>@Feignclient&#xA;public interface MyFeignClient {&#xA;    @RequestMapping(value = ""test"", = RequestMethod.POST, consumes = ""application/json"")&#xA;    ResponseEntity&lt;String&gt; theActualMethod(&#xA;            HttpServletRequest request,&#xA;            @RequestHeader(""firstHeader"") String header1,&#xA;            @RequestHeader(""secondHeader"") byte[] header2);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, when I change the second argument to @RequestBody in order to read the POST request content, I get an exception:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Method has too many Body parameters: public abstract org.springframework.http.ResponseEntity MyFeignClient.theActualMethod(javax.servlet.http.HttpServletRequest,java.lang.String,byte[])&#xA;</code></pre>&#xA;"
35361819,how to scale microservice (service fabric) instance when queue length increass,2016-02-12 11:45:43,<azure><scale><microservices><azure-service-fabric>,2,1690,0,0.0,4,"<p><a href=""https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/"" rel=""nofollow"">https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/</a></p>&#xA;&#xA;<p>But how can I scale up my microservice when queue length increases. have any inbuild way in azure service fabric ?</p>&#xA;"
36080524,Rails: How to listen to / pull from service or queue?,2016-03-18 09:21:32,<ruby-on-rails><rabbitmq><apache-kafka><microservices>,4,2107,3,0.0,4,"<p>Most Rails applications work in a way that they are waiting for requests comming from a client and then do their magic.&#xA;But if I want to use a Rails application as part of a microservice architecture (for example) with some asychonious communication (Serivce A sends an event into a Kafka or RabbitMQ queue and Service B - my Rails app - is supposed to listen to this queue), how can I tune/start the Rails app to immediately listen to a queue and being triggered by event from there? (Meaning the initial trigger is not comming from a client, but from the App itself.)</p>&#xA;&#xA;<p>Thanks for your advice!</p>&#xA;"
34503547,Spring MVC - Calling a rest service from inside another rest service,2015-12-29 02:22:05,<java><spring><rest><spring-mvc><microservices>,2,19997,4,3.0,4,"<p>I'm currently having a really weird issue with calling one REST service from inside another one and I could really use a hand in working out what I'm doing wrong.</p>&#xA;&#xA;<p><strong>So first off, a bit of context:</strong></p>&#xA;&#xA;<p>I have a webapp which calls off to a REST service to create a user account (for the sake of this explanation, the endpoint is localhost:8080/register). Earlier in the user journey I've called a different service to create the user's login credentials <code>localhost:8090/signup</code> but I need to check a few things in the call to /register so inside the call I'm calling out to a different endpoint on 8090 to get this information (<code>localhost:8090/availability</code>). Long story short, the webapp calls localhost:8080/register which in turn calls <code>localhost:8090/availability</code>.</p>&#xA;&#xA;<p>When I call the availability endpoint directly, from either a REST client or the webapp itself, everything works as expected, but for some strange reason, when I call it from inside the call to the register endpoint I get a HTTP415. Anyone have any insight into what's going wrong?</p>&#xA;&#xA;<p>The register controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And the availability controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public Boolean isUsernameAvailable(@RequestBody String username) {&#xA;&#xA;    // a load of business logic that returns a boolean&#xA;    return Boolean.TRUE;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Full disclosure - in practice, what I've shown as the contents of createUser() are actually several calls up the call stack, using the same class as I use to call the services from the webapp (which works perfectly well in that context), and I'm not actually just returning true in isUsernameAvailable (because that would be silly) but this is the simplest version of the code that replicates the issue. </p>&#xA;&#xA;<p>My current assumption is that I'm doing something that I'm going to kick myself over when I see it but I've been staring at this code too long to be able to see it any more.</p>&#xA;&#xA;<p><strong>Edit</strong> Vikdor's comment below solved this problem for me. I changed the createUser method to:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    restTemplate.setMessageConverters(Arrays.asList(new MappingJackson2HttpMessageConverter()));&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;"
39615381,Advantages of Service Fabric Microservices vs Collection of Azure Cloud services/web apps,2016-09-21 11:31:17,<azure><microservices><azure-service-fabric><azure-cloud-services><azure-appfabric>,2,4502,0,2.0,4,"<p>I have a application that can be broken down into multiple communicating services. My current implementation is monolithic and I want to reorganize the same so that individual components can be deployed,iterated upon, scaled independently. I see two ways to do this with Azure:</p>&#xA;&#xA;<ol>&#xA;<li>Service Fabric service composed of set of communicating micro-services(stateless, web-api etc.)</li>&#xA;<li>A collection of individual Azure Web Apps/ Cloud Services that call each other at the http end points.</li>&#xA;</ol>&#xA;&#xA;<p>Are there any obvious advantages of 1 over 2? Any rule of thumb to chose one over the other would also be very helpful.</p>&#xA;"
39467200,How to self register a service with Consul,2016-09-13 09:58:28,<c#><asp.net-core><microservices><consul>,1,2286,0,6.0,4,"<p>I'm trying to <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow noreferrer"">self</a> register my ASP.NET Core application to Consul registry on startup and deregister it on shutdown.</p>&#xA;&#xA;<p>From <a href=""https://www.consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow noreferrer"">here</a> I can gather that calling the http api [<code>put /v1/agent/service/register</code>] might be the way to go (or maybe not!).</p>&#xA;&#xA;<p>From my app, I thought I'll target the <code>Startup</code> class, starting with adding the my <code>.json</code> file</p>&#xA;&#xA;<pre><code>public Startup(IHostingEnvironment env)&#xA;{&#xA;   var builder = new Configuration().AddJsonFile(""consulconfig.json"");&#xA;   Configuration = builder.Build();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But now, I'm stuck as <code>ConfigureServices</code> method tells me thats where I add services to the container, and <code>Configure</code> method is where I configure the Http request pipeline.</p>&#xA;&#xA;<p>Anybody to point me in the right directions, online readings, examples, etc.                                        </p>&#xA;"
39763013,many log files on azure service fabric,2016-09-29 06:33:42,<azure><microservices><azure-service-fabric>,2,628,0,0.0,4,"<p>I have a azure service fabric development cluster running locally with two applications.</p>&#xA;&#xA;<p>After a two week holiday I come back and see that my hard drive is completely full, consequently nothing really works anymore.</p>&#xA;&#xA;<p>the sfdevcluster\log\traces folder has many *.etl files all larger than 100MB.&#xA;And all kinds of other log files > 250 MB are present</p>&#xA;&#xA;<p>So my questions: how to disable tracing/logging on azure service fabric and are there tools to administer log files?</p>&#xA;"
39852947,"Spring microservices, stateless session, angular and static file serving",2016-10-04 12:56:13,<angularjs><spring-security><spring-boot><spring-cloud><microservices>,1,577,1,0.0,4,"<p>I am designing the backend of large application which is divided into microservices. I am using <strong>Spring Cloud</strong> with its tools: <strong>Eureka</strong>, <strong>Zuul</strong> and etc. I have implemented <strong>OAuth2</strong> authorization server which supports four grant types. It is working without problems.</p>&#xA;&#xA;<p>Then I was asked to serve <strong>html files</strong> and <strong>in such manner that if not authorized, backend must redirect to login page and strongly recommended that I don't use sessions</strong>. I thought that without session spring cant really know what's going with, in the end <strong>it must have token to decide to build security context</strong>.</p>&#xA;&#xA;<p>I started researching about this issue. I found that examples from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/"" rel=""nofollow"">Spring Security and Angular JS tutorial</a> show that routings and redirections are accomplished inside <strong>angular</strong> with the help of <strong>ui-route</strong>. I skimmed several projects in github and they also were using angular for redirections.</p>&#xA;&#xA;<p>Is it possible to redirect using backend in totally stateless session?(This sounds so dumb, but it couldn't be expressed otherwise. I want to give this answer to my coworkers that are stating that is possible). If possible, are there any examples?</p>&#xA;"
40234243,OAuth 2.0 service to service authentication and best practices,2016-10-25 07:48:33,<authentication><oauth><microservices>,1,519,0,0.0,4,"<p>I have to deal with such type of auth flows:</p>&#xA;&#xA;<ol>&#xA;<li>Create auth flows for Web users;</li>&#xA;<li>In the same way deal with service to service authentication</li>&#xA;</ol>&#xA;&#xA;<p>Briefly following diagram can depict main components that we'll have:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NzDM7.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/NzDM7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>For users Authentication we'd like to use OAuth2 (the Implicit Flow) and in general it looks more or less clear.</p>&#xA;&#xA;<p>The question about service to service authorization can it be OAuth2 Authorization Code Flow used?</p>&#xA;&#xA;<p>The main problem there that inside of datacenter1 it will be plenty of backend services that's why it will be good as services will work on the similar permission model as a users (at least some some functionality might be retracted ).</p>&#xA;&#xA;<p>And additional question: what is the general recommendation for this use case if Authorization Server is inside of Datacenter1 or outside?</p>&#xA;"
35613841,Most efficient way to communicate between multiple .NET apps,2016-02-24 21:48:15,<.net><rest><azure><architecture><microservices>,4,1116,0,2.0,4,"<p>Currently i have a setup where my clients (web apps, iOS app etc) talks to my backend API .NET web app (Nancy) via REST calls. Nothing special.</p>&#xA;&#xA;<p>I now have a requirement to split this API up into microservices, where each service can be individually upgraded/deployed. </p>&#xA;&#xA;<p>My main API (public) will just perform authentication, then call into one of my microservices, which will be in my private network.</p>&#xA;&#xA;<p><strong>What's the different ways i could communicate between my main API and other microservice API's? Pros/cons of each approach?</strong></p>&#xA;&#xA;<p>The communication needs to be realtime - e.g request comes in from a browser/device, main API performs auth, then calls into microservice API then returns response. So i can't use things like queues or pub/sub. It doesn't necessarily need to use HTTP, but it needs to be realtime communication (request/response). I also have other services (WebJobs, cloud services, etc) that need to talk to these microservices (they are also in the private network).</p>&#xA;&#xA;<p>The only approach that comes to mind is simple REST-based calls. Totally fine, but latency is the main issue here.</p>&#xA;&#xA;<p>Can anyone recommend any other solutions to this problem? Is there anything in Azure suited to this?</p>&#xA;&#xA;<p>Many thanks</p>&#xA;"
35465175,"microservice architecture questions about code resue, security and database sharing",2016-02-17 18:49:53,<microservices>,1,117,0,1.0,4,<p>I have the following questions about micro service architecture</p>&#xA;&#xA;<ol>&#xA;<li><p>How common code/utility-libs are being reused between different micro services? Where this common code is also being developed</p></li>&#xA;<li><p>In my micro-service some services are for clients and some can be internal ( for other micro services to use). What is the best option to make internal services secure?</p></li>&#xA;<li><p>What if two micro-services has to use the same database? Say they do totally different operations but using the same database table?</p></li>&#xA;<li><p>Micro services are mostly about the back end but the GUI is going to be the same. In that case each micro service deployment requires website update as well. Is that consider as a disadvantage?</p></li>&#xA;</ol>&#xA;
41636566,Inter-communication microservices - How?,2017-01-13 14:14:59,<node.js><web-services><rest><rabbitmq><microservices>,2,2165,1,1.0,4,"<p>I'm working on a personnal project which is to transform a monolithic web application into microservices (each service has its own database).</p>&#xA;&#xA;<p>At this moment the monolithic backend is made with  NodeJS and is able to reply REST request. &#xA;When I began to split the application into multiple services I faced the next problem : How to make the communication between them nicely ?</p>&#xA;&#xA;<p>First I tried to use <strong>REST call</strong> with the next example : &#xA;""Register Service"" inserts interesting things into its database, then forward (HTTP POST) the user information to the ""User Service"" in order to persist it into the ""user"" database.&#xA;From this example we have 2 services thus 2 databases.</p>&#xA;&#xA;<p>I realized at this moment <strong>it wasn't a good choice</strong>. Because my ""Register Service"" depends on ""User service"". They are kind of coupled and this is an anti-pattern of the microservices conception ( from what I read about ).</p>&#xA;&#xA;<p>The second idea was to use a <strong>message broker</strong> like RabbitMQ. ""Register Service"" still insert interesting things into its own database and publish a message in a queue with the user information as data. ""User Service"" consumes this message and persists data into its ""user"" database. By using this conception, both of the services are fully isolated and could be a great idea.</p>&#xA;&#xA;<p>BUT, <strong>how about the response to send to the client</strong> ( who made the request  to ""Register Service""). With the first idea we could send ""200, everything's ok !"" or 400. It is not a problem. With the second idea, we don't know if the consumer (""User Service"")  persisted the user data, so what do I need to reply to the client ?</p>&#xA;&#xA;<p>I have the same problem with the shop side of the web application. The client post the product he wants to buy to ""Order Service"". This one needs to check the virtual money he has into ""User Service"" then forward the product detail to ""Deliver Service"" if the user has enough money. How to do that with fully isolated services ? </p>&#xA;&#xA;<p>I don't want to use the http request time from the client to make async request/reply on the message broker. </p>&#xA;&#xA;<p>I hope some of you will enlighten me.</p>&#xA;"
43041563,User authentication in microservice application hosted on Amazon WS,2017-03-27 08:36:46,<amazon-web-services><authentication><architecture><microservices><aws-cognito>,1,259,0,3.0,4,"<p>I am building web application based on microservice architecture. At this moment I am considering few ways of user authentication flow. I predict following, example user roles:</p>&#xA;&#xA;<ul>&#xA;<li>admin - is able to create content, upload files etc (admin account can be created only by another admin)</li>&#xA;<li>unauthorized user - can view content</li>&#xA;<li>authorized user - can comment content</li>&#xA;</ul>&#xA;&#xA;<p>Here is, how I was thinking about authentication flow so far:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - have access to DB with users credentials and permissions</li>&#xA;<li>api gateway - retrieve requests from user, check if user is logged in (ie verifies OAuth2 access token with auth service) and transfer flow to other services based on user request (attaching JWT token with some basic user info)</li>&#xA;<li>another service - accept only requests from api gateway, and trusts user data from JWT token (does not need to connect with auth service to get information about user).</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>After deploying some stuff on AWS infrastructure my way of thinking have changed a little bit. As far as I understand AWS products (Lambda - serverless applications and API gateway), I should implement authentication flow as follows:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - gets request from user, retrieve data from dynamoDB and provide user cookie with JWT signed by private key</li>&#xA;<li>any other service - retrieves request with JWT token, verifies signature using public key, and perform some action.</li>&#xA;</ul>&#xA;&#xA;<h1>And now the question comes:</h1>&#xA;&#xA;<p>How deos AWS Cognito fits here? Is it something useful for me? As far as I understand, Cognito simplifies flow of authenticating users via 3rd parties (facebook, twitter etc. etc.). Does AWS Cognito serves login page, separated from my application, or it is only background/webservices impelementation?</p>&#xA;&#xA;<p>So far I am thinking about Cognito as a replacement for my <code>authentication service</code> - any of my services, should impelemnt Cognito authentication flow provided by SDK from amazon, and my static website would implement JavaScript SDK for user login/register. Am I right?</p>&#xA;"
42981194,How do you handle validation in composite microservice request?,2017-03-23 16:01:34,<architecture><microservices><software-design><distributed-transactions>,3,1030,0,0.0,4,"<p>Consider an application with two entities:</p>&#xA;&#xA;<ul>&#xA;<li><code>User</code> (contains basic user data, such as name)</li>&#xA;<li><code>Passport</code> (contains authentication credentials, i.e. password)</li>&#xA;</ul>&#xA;&#xA;<p>And two internal microservices:</p>&#xA;&#xA;<ul>&#xA;<li><code>UserService</code> (responsible for creating and managing users and their basic data)</li>&#xA;<li><code>AuthService</code> (responsible for user authentication and password handling)</li>&#xA;</ul>&#xA;&#xA;<p>The <code>User</code> entity belongs to the <code>UserService</code> and <code>Passport</code> entity belongs to the <code>AuthService</code>.</p>&#xA;&#xA;<p>Those two services should be separated, because they solve very different tasks: <em>profile data</em> and <em>authentication</em>.</p>&#xA;&#xA;<p>Also, consider we have a registration form with three fields:</p>&#xA;&#xA;<ul>&#xA;<li>E-Mail</li>&#xA;<li>Name</li>&#xA;<li>Password</li>&#xA;</ul>&#xA;&#xA;<p>This form will trigger HTTP-request to the <code>GatewayService</code>, which intercepts all requests to the application and routes them to internal microservices (or composes/aggregates them).</p>&#xA;&#xA;<p>Now, when gateway service receives the request with all the form data it needs to do the following:</p>&#xA;&#xA;<ol>&#xA;<li>Call <code>UserService</code> to create new user (it will respond with generated <code>userId</code>).</li>&#xA;<li>Call <code>AuthService</code> to create a passport for newly created user. It will need the <code>userId</code> received in step #1 and a <code>password</code> field from the original request.</li>&#xA;</ol>&#xA;&#xA;<p>This looks pretty straightforward, but what will happen if <code>AuthService</code> is unavailable on step #2? We will need to somehow separate those requests!</p>&#xA;&#xA;<p>The classic approach is to use the eventual consistency and to create <code>Passport</code> entity via asynchronous call (we can place this request to the queue and process it in separate service). In order to do this we will send an asynchronous request to the <code>AuthService</code> passing <code>userId</code> and <code>password</code> to it, instead of step #2, so the step #1 will immediately return response to the client.</p>&#xA;&#xA;<p>However, what if <code>password</code> field is not properly formatted (breaks validation rules)? The validation logic is only present in the <code>AuthService</code>, so we can't know if password is correct until the call is made to it. And now, the request is processed asynchronously, so we can't get back to user and tell him to correct the password.</p>&#xA;&#xA;<p><strong>SO, how do you properly handle validation in distributed composite requests to microservice application?</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>The naive solution is to move validation logic to the <code>GatewayService</code> itself, but it's a terrible idea, because it will make it fat and will leak business logic from <code>AuthService</code>.</p></li>&#xA;<li><p>The other idea is to provide an additional method for password validation and to call it prior to steps #1 and #2. It looks like a viable solution, but it will force us to have two methods for each business method in our microservices, one for prior validation and one for actual operation. Also, there is a time space between validation and operation, so the earlier correct value could become incorrect when operation is actually performed.</p></li>&#xA;<li><p>We could split the form in two to avoid composite requests and ask user for password after asking for personal data and creating an account for him. However, this could lead to security problems, where user account could be intercepted by some other party who could guess the next <code>userId</code>. We could, use some additional security token, but it will introduce odd functionality to services and will make the whole setup more complex.</p>&#xA;&#xA;<p>Also, this approach looks like an attempt to escape the problem, you can't always avoid composite requests.</p></li>&#xA;<li><p>We could use full-scale distributed transactions, e.g. <a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""nofollow noreferrer"">2PC</a>, but it will make the system dramatically complex and will mitigate the use of MSA in the first place.</p></li>&#xA;<li><p>And the final idea is to merge those two services together, but it will make no sense in microservice architecture to do so.</p></li>&#xA;</ol>&#xA;"
43034203,node.js api gateway implementation and passport authentication,2017-03-26 20:33:25,<node.js><passport.js><microservices>,1,837,1,0.0,4,"<p>I am working on implementing a microservices-based application using node.js.  While searching for examples on how to implement the api gateway, I came across the following article that seems to provide an example on implementing the api gateway: <a href=""https://memz.co/api-gateway-microservices-docker-node-js/"" rel=""nofollow noreferrer"">https://memz.co/api-gateway-microservices-docker-node-js/</a>.  Though, finding example for implementing the api gateway pattern in node.js seems to be a little hard to come by so far, this article seemed to be a really good example.  </p>&#xA;&#xA;<p>There are a few items that are still unclear and I am still have issues finding doc. on.  </p>&#xA;&#xA;<p>1) Security is a major item for the app. I am developing, I am having trouble seeing where the authentication should take place (i.e. using passport, should I add the authentication items in the api gateway and pass the jwt token along with the request to the corresponding microservice as the user's logged in information is needed for certain activities?  The only issue here seems to be that all of the microservices would need passport in order to decrypt the jwt token to get the user's profile information.  Would the microservice be technically, inaccessible to the outside world except through the api gateway as this seems to be the aim?</p>&#xA;&#xA;<p>2) How does this scenario change if I need to scale to multiple servers with docker images on each one?  How would this affect load balancing, as it seems like something would have to sit at a higher level to deal with load balancing?</p>&#xA;"
36519652,Share data between microservices,2016-04-09 16:32:32,<database-design><architecture><microservices>,2,2792,0,2.0,4,"<p>I work on a microservices architecture and I want to solve a small data sharing problem (I don't know if is the right word).</p>&#xA;&#xA;<p>Example :</p>&#xA;&#xA;<p>I have one user service and is DB that stores email, username, password...</p>&#xA;&#xA;<p>I have another service and his database that work with the user data for generate documents with the user informations.</p>&#xA;&#xA;<p>Which is the best way for the second service for accessing to the user data ? Replicate user data (Just if is required for his job) for her in is database ?</p>&#xA;"
36571963,Python Development in multiple repositories,2016-04-12 11:28:36,<python><git><pip><setuptools><microservices>,2,594,4,0.0,4,"<p>We are trying to find the best way to approach that problem.&#xA;Say I work in a Python environment, with pip &amp; setuptools.&#xA;I work in a normal git flow, or so I hope.&#xA;So:</p>&#xA;&#xA;<ol>&#xA;<li>Move to feature branch in some app, make changes.</li>&#xA;<li>Move to feature branch in a dependent lib - Develop thing. </li>&#xA;<li>Point the app, using ""-e git+ssh"" to the feature branch of the dependent lib.</li>&#xA;<li>Create a Pull Request.</li>&#xA;</ol>&#xA;&#xA;<p>When this is all done, I want to merge stuff to master, but I can't without making yet another final change to have the app (step 3 above) requirements.txt now point to the main branch of the feature.</p>&#xA;&#xA;<p>Is there any good workflow for ""micro services"" or multiple dependent source codes in python that we are missing?</p>&#xA;"
29787063,"Is kafka a good fit for a small scale microservices environment, or should I look for lightweight alternatives",2015-04-22 03:16:02,<apache-kafka><microservices>,2,1786,0,4.0,4,"<p>I'm working on a series of applications that will be deployed as microservices. Each one will have a separate database and I'm looking to coordinate data through single unified event store/log like Apache Kafka. I've started experimenting with Kafka, and most users seem to be using kafka at fairly large scale with clustering and fairly complex fault tolerance setups. We don't anticipate having particularly large volume initially, so I'm wondering if Kafka is the right choice? Is this a good fit for kafka or should I be looking at lighterweight alternatives given our current scale.</p>&#xA;"
38820356,Does Kong support API Aggregation,2016-08-08 02:04:58,<microservices><kong>,1,1695,1,2.0,4,"<p>We are just researching a couple of API gateways, in particular <a href=""https://getkong.org"" rel=""noreferrer"">Kong</a>.&#xA;Looking through their documentation it seems they support request/response transformation. </p>&#xA;&#xA;<p>However, if I understand this correctly, this seems limited to headers.</p>&#xA;&#xA;<p>Does Kong support API Aggregation like <a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""noreferrer"">Netflix</a> does it?</p>&#xA;"
38734740,How to config SpringBoot logback setting in application.yml?,2016-08-03 05:01:34,<spring-boot><yaml><logback><microservices>,2,2551,1,0.0,4,"<p>I want to specify my logback.xml file in my project, and in my SpringBoot application I was using the application.yml, I just add</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: logback.xml&#xA;</code></pre>&#xA;&#xA;<p>but it doesn't work for me, the error is :</p>&#xA;&#xA;<pre><code> Logging system failed to initialize using configuration from 'logback.xml'&#xA;java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Exception in thread ""main"" java.lang.IllegalStateException: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:289)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Caused by: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    ... 19 more&#xA;</code></pre>&#xA;&#xA;<p>And if I use</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: ./logback.xml&#xA;</code></pre>&#xA;&#xA;<p>to specify the config location, it appears the same error.&#xA;What should I do ?</p>&#xA;"
46315996,Transformation from Legacy to Microservices architecture,2017-09-20 07:38:36,<rest><design><microservices><soa>,2,156,0,2.0,4,"<p>I want to discuss a transformation from fat DB to microservices architecture.</p>&#xA;&#xA;<p><strong>A bit of history:</strong>&#xA;So we have a legacy loan application system, which captures customer detail into a FAT database with some 1000+ tables. The application is doing a lot more than just just capturing loan with 100+ screens/processes built that are beyond loan capturing. Like administration, reporting, config etc.</p>&#xA;&#xA;<p><strong>Current State:</strong>&#xA;The whole Presentation Layer, Logic Layer, DB Layer, ORM layer is part of the one project.</p>&#xA;&#xA;<p><strong>Current Task In Hand:</strong>&#xA;The app is built in Win Forms, and my job is transform it to Modern UI as we need modern feature. </p>&#xA;&#xA;<p><strong>Approach:</strong>&#xA;The approach I am taking is to built some Micro Services on current DB Structure. Using the same DB will allow the current application to run as it is, and we can write a new DB Layer, Logic Layer in some Micro Services. We can then write Modern User Interface (angular/react) that will consume those services. &#xA;The second step then will be then stop the use of capturing operation from legacy app.</p>&#xA;&#xA;<p>Third step is to move the specific DB tables out of the legacy databases to their own databases.</p>&#xA;&#xA;<p>This approach seems best by keeping the current operation running as it is. Also, this approach allows us to run both applications parallel on the production environment. </p>&#xA;&#xA;<p><strong>Confusion:</strong>&#xA;The question I have is on detailed design. I am struggling to understand the context split in Micro Services. The information in the scope of first iteration is:&#xA;- Some Qualification Questions&#xA;- Contact details&#xA;- App requirements&#xA;- Bank Details&#xA;- Income details&#xA;- Expense details&#xA;- Previous loan information</p>&#xA;&#xA;<p>The microservices I am thinking to have is&#xA; - Application Service&#xA;    - Qual questions&#xA;    - App requirements&#xA;    - Previous Loan information&#xA;    - Income/Expense details&#xA; - Demographics Information&#xA;    - Bank Details&#xA;    - Contact Details</p>&#xA;&#xA;<p><strong>Questions:</strong>&#xA;- Does the approach sounds correct from legacy to microservices?&#xA;- The microservice split. Can someone suggest if this is right?</p>&#xA;&#xA;<p>Thanks a lot in advance.&#xA;Regards&#xA;Gaurav Sharma</p>&#xA;"
44582199,"Angular microservices, loadChildren from url",2017-06-16 06:25:06,<angular><architecture><microservices>,1,383,0,2.0,4,"<p>I recently started thinking of how to effectively implement Angular in a microservices architecture.</p>&#xA;&#xA;<p>Let's say we have a service for login, a service for user management and a service for browsing, adding and editing certain media. Each service has its own backend and frontend served in its own private container. So each part is then isolated with a clearly defined API to interact with for the backend, and its own isolated user interface consuming this API.</p>&#xA;&#xA;<p>Now, let's say I would like to tie up each of these microservices into a single application. I have two ways (as far as I can see) to do this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can configure a server to place each service under a sub-url, and have the application be an array of SPA's, a sort of MPA (Multi Page App). </p></li>&#xA;<li><p>I can create a master app where I set up the routes for each of my micro-apps and load them on demand (custom PreloadingStrategy, I'm looking at you).</p></li>&#xA;<li><p><sup>I also found <a href=""https://stackoverflow.com/questions/39904153/front-end-micro-services-with-angular-2#answer-39937403"" title=""this"">this</a>, a process which I personally don't think highly of, because you'll lose many of the benefits of microservices in a continuous delivery scheme of things. This aims to create a SPA monolith out of microservices.</sup></p></li>&#xA;</ol>&#xA;&#xA;<p>Now, the first alternative seems like a chore, and no fun at all. The second is intriguing to me. I came accross this article: <a href=""https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular"" rel=""nofollow noreferrer"">https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular</a> and immediately started thinking; how can I exploit this to load pre-built angular modules from a url instead of packaging them from the file system?</p>&#xA;&#xA;<p>So my question is; has anybody done this before? Is it possible? Are there security issues in doing this?&#xA;Or are there other alternatives of tying up my microservices into a larger application?</p>&#xA;"
31717615,Databases in a microservices pattern/architecture,2015-07-30 07:27:01,<web-services><rest><design-patterns><microservices>,2,453,0,3.0,4,"<p>I'm trying to understand the layout of the microservices pattern. Given that each microservice would run on its on VM (for sake of example) how does the database fit into this architecture? </p>&#xA;&#xA;<p>Would each service, in turn, connect to the consolidated database to read/write data? </p>&#xA;&#xA;<p>Thanks for any insight</p>&#xA;"
42651456,Spring cloud Zuul retry when instance is down and forward to other available instance,2017-03-07 14:56:39,<spring-cloud><microservices><netflix-zuul><spring-cloud-netflix><spring-cloud-feign>,2,2435,0,1.0,4,"<p>using 'Camden.SR5' for spring-cloud-dependencies, with spring boot '1.5.2.RELEASE'.</p>&#xA;&#xA;<p>In my current setup, I have </p>&#xA;&#xA;<ul>&#xA;<li>eureka server </li>&#xA;<li>config server  (running on random ports)</li>&#xA;<li>zuul gateway server  </li>&#xA;<li>and 2 instances of a service (running on random ports)</li>&#xA;</ul>&#xA;&#xA;<p>All these instances are successfully register with Eureka.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BYNWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BYNWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>When all the services are running, The load balancing is done properly through zuul without any issues.</p>&#xA;&#xA;<p>when an instance is killed, Zuul is still trying to fulfil the request using the same service which is down. However if waited till the eureka registry is fetched after shutting down the instance, requests are fulfilled with the other instances which are 'UP'.</p>&#xA;&#xA;<pre><code>    2017-03-07 19:57:41.409 DEBUG 26658 --- [nio-5555-exec-3] c.n.l.reactive.LoadBalancerCommand       : Got error org.apache.http.conn.HttpHostConnectException: Connect to 10.99.4.151:64381 [/10.99.4.151] failed: Connection refused when executed on server 10.99.4.151:64381&#xA;2017-03-07 19:57:41.420 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : Error executing HystrixCommand.run(). Proceeding to fallback logic ...&#xA;&#xA;com.netflix.client.ClientException: null&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:123) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:81) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:96) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>    at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    ... 162 common frames omitted&#xA;&#xA;2017-03-07 19:57:41.425 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : No fallback for HystrixCommand. &#xA;&#xA;java.lang.UnsupportedOperationException: No fallback available.&#xA;    at com.netflix.hystrix.HystrixCommand.getFallback(HystrixCommand.java:292) [hystrix-core-1.5.6.jar:1.5.6]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:117) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.11.jar:8.5.11]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_66]&#xA;&#xA;2017-03-07 19:57:41.428  WARN 26658 --- [nio-5555-exec-3] o.s.c.n.z.filters.post.SendErrorFilter   : Error during filtering&#xA;&#xA;com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:170) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:145) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:88) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Following are the zuul configuration used with @EnableZuulProxy and @EnableEurekaClient</p>&#xA;&#xA;<pre><code>    server:&#xA;  port: 5555&#xA;&#xA;spring:&#xA;  application:&#xA;    name: gateway-server&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        service-id: CONFIGSERVER&#xA;      fail-fast: true&#xA;      retry:&#xA;        multiplier:  1.1&#xA;        initial-interval: 1000&#xA;        max-attempts: 6&#xA;        max-interval: 2000&#xA;&#xA;hystrix:&#xA;  command:&#xA;    default:&#xA;      execution:&#xA;        isolation:&#xA;          thread:&#xA;            timeoutInMilliseconds: 100000&#xA;        timeout:&#xA;          enabled: false&#xA;&#xA;ribbon:&#xA;  ReadTimeout: 5000&#xA;  ConnectTimeout: 3000&#xA;  maxAutoRetries: 1&#xA;  MaxAutoRetriesNextServer: 2&#xA;  OkToRetryOnAllOperations: true&#xA;&#xA;&#xA;logging:&#xA;  level:&#xA;    ROOT: DEBUG&#xA;&#xA;zuul:&#xA;  routes:&#xA;    security-service:&#xA;      retryable: true&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The 2 instances of service with are running with unique instance-ids </p>&#xA;&#xA;<pre><code>@EnableEurekaClient&#xA;@EnableHystrix&#xA;@SpringBootApplication&#xA;public class SecurityServer implements HealthIndicator{&#xA;&#xA;    public static void main(String args[])&#xA;    {&#xA;        SpringApplication.run(SecurityServer.class,args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public Health health() {&#xA;        return Health.up().withDetail(""STATUS"", ""SUCCESS"").build();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>instanceId: ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${random.uuid}}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Can you help me with the zuul &amp; instances configuration, so that request is automatically forwarded to the other available instances when an instance goes down. </p>&#xA;"
42788267,"Can I use Oauth2 Authorization Code flow for a SPA (React app), if I have a server-side proxy?",2017-03-14 14:09:44,<oauth-2.0><single-sign-on><microservices><openid-connect><identityserver4>,1,1407,1,1.0,4,"<p>After watching an obscene amount of tutorials on OAuth2, there is one best practice that everyone repeatedly states - if you have a React app (or Angular, or Ember) - you <strong>must</strong> use <em>Implicit flow</em> with it.</p>&#xA;&#xA;<p>I understand that storing client credentials in publicly visible javascript would not work. However, my scenario is a bit different:</p>&#xA;&#xA;<ol>&#xA;<li>I'm only using Oauth2 for single sign on and token generation for microservices. I chose it instead of simply generating tokens, since well-supported third party libraries are built around the Oauth2 idea.</li>&#xA;<li>My idea is to have a React app, and a ASP.NET MVC app which serves the javascript and acts as a proxy for API requests. The user authenticates for the server-side app (by using Oauth2 authorization code flow).</li>&#xA;<li>Then if I need to retrieve data from an API, I call my ASP.NET MVC app from React (by sending a simple cookie). The MVC app holds the token without ever exposing it to the user's browser.</li>&#xA;<li>Obviously, when called, my MVC app then redirects the request to the necessary API, providing the bearer token.</li>&#xA;</ol>&#xA;&#xA;<p>To better understand why this is what I came up with, here are some requirements I've received that might be unusual:</p>&#xA;&#xA;<ol>&#xA;<li>I really don't want the access token to be shared - even if it's relatively short lived.</li>&#xA;<li>I also want to be able to limit each user account to 3 concurrent user sessions. Easy to do using cookies and server-side sessions.</li>&#xA;</ol>&#xA;&#xA;<p>I can't wrap my head around why this idea would be that bad. Is there any technical problem that might prevent this from working? Or maybe a security risk?</p>&#xA;"
39215533,spring cloud config : how to use multiple configs,2016-08-29 21:30:41,<java><microservices><spring-cloud-config>,1,4253,0,1.0,4,"<h3>What I want to try:</h3>&#xA;&#xA;<p>I want to try the <code>spring cloud config</code> for microservice project where I have a <code>common config</code> for all services and <code>multiple configs</code> for each service.<br>&#xA;I got idea on how to use multiple <code>profiles</code> using <code>spring.profiles.active</code> and <code>include</code>. I am trying to understand how can I load multiple configs on config client?</p>&#xA;&#xA;<h3>What I have:</h3>&#xA;&#xA;<p>In my git repo I have <code>spring-config-repo</code> where I have ...</p>&#xA;&#xA;<pre><code>application.yml&#xA;orderclient.yml&#xA;subscriberclient.yml&#xA;jmsclient.yml&#xA;productclient.yml&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>config Server</code> pointed to my config repo. </p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;  name: config-service&#xA;  cloud:&#xA;   config:&#xA;    server:&#xA;      git:&#xA;        uri: https://github.com/&lt;user&gt;/spring-config-repo&#xA;&#xA;server:&#xA; port: 8888&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>spring client</code> where I want to use multiple configs. Here in my case for <code>orderService</code> I want to load <code>application.yml,orderclient.yml,jmsconfig.yml</code> and For Product microService I need 'orderconfig.yml,jmsclient.yml,productclient.yml'</p>&#xA;&#xA;<pre><code>spring:&#xA;application:&#xA;  name: orderclient&#xA;profiles:&#xA;  active: test&#xA;cloud:&#xA;  config:&#xA;    uri: http://localhost:8888&#xA;&#xA;###Any kind of config properties to load jmsclient, productclient?&#xA;</code></pre>&#xA;&#xA;<p>Above I can access properties from orderclient.yml.</p>&#xA;&#xA;<h2>My Question:</h2>&#xA;&#xA;<h3>Question1:</h3>&#xA;&#xA;<p>How to access properties of <code>jmsclient.yml,productclient.yml</code> in <code>orderclient</code> application. </p>&#xA;&#xA;<h3>Question2:</h3>&#xA;&#xA;<p>Is there anyway to get list of all <code>propertySources.name</code> exposed by config server? where in above case it should dispaly</p>&#xA;&#xA;<pre><code>""propertySources"": {&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/aplication.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test,&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/orderclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/jmsclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA; ....}&#xA;</code></pre>&#xA;&#xA;<p>Please let me know if my question is not clear or need more information. Thanks.</p>&#xA;"
39228311,Best practices for storing content in secure area,2016-08-30 13:04:59,<node.js><microservices>,1,44,1,0.0,4,<p>In our project we have separate login page and several SPAs which user can access only after proper authentication.&#xA;All static content is placed in public CDN. But html files of SPAs are stored in DB and delivered to user by index service.&#xA;We don't want to store html files in DB because it is inconvenient for us.</p>&#xA;&#xA;<p>What is the best way to store html files in secure area?</p>&#xA;
39015444,Should instances of a horizontally scaled microservice share DB?,2016-08-18 10:08:28,<docker><soa><microservices>,1,134,0,3.0,4,"<p>Given a microservice that owns a relational database and needs to scale horizontally, I see two approaches to provisioning of the database server:</p>&#xA;&#xA;<ul>&#xA;<li>provide each instance of the service with it's own DB server instance with a coupled process lifecycle </li>&#xA;</ul>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<ul>&#xA;<li>have the instances connect to a shared (by identical instances of the same service) independent db server or cluster</li>&#xA;</ul>&#xA;&#xA;<p>With an event driven architecture and the former approach, each instance of the microservice would need to process each event and take the appropriate action to mutate its own isolated state. This seems inefficient.  </p>&#xA;&#xA;<p>Taking the latter approach, only one instance has to process the event to achieve the same effect but as a mutation of the shared state. One must ensure each event is processed by only one instance of the given microservice (is this trivial?) to avoid conflict.</p>&#xA;&#xA;<p>Is there consensus on preferred approach here? What lessons has your experience taught you on this?</p>&#xA;"
37289634,How to Set Request Headers Using a Feign Client?,2016-05-18 03:14:49,<spring-mvc><spring-cloud><microservices><netflix-feign><spring-cloud-netflix>,1,6976,0,3.0,4,"<p>We are developing a suite of Microservices using Spring Cloud framework and one of the the things that we need to do is to set request headers. I know I can pass a parameter <code>@RequestHeader</code> to a Feign method but the value needs to come from another bean. I don't know if SPEL can be used for a Feign param value.&#xA;I was thinking that this is a common enough use case for most clients so there'd be some examples, but so far I've not found any. Of course I can dig through the Spring course code and try to override the default Feign configuration but it kinda defeats the purpose of a declarative client if I've to write a lot of code to achieve this.&#xA;Any thoughts?</p>&#xA;"
37074642,Settings in application.yml for spring.cloud.config aren't used when app is executing,2016-05-06 14:13:00,<java><spring><spring-boot><spring-cloud><microservices>,1,4981,0,0.0,4,"<p>I have a problem with spring cloud: my settings in application.yml for spring.cloud.config aren't used when app is executing. let me put more detail here.&#xA;I'd like to my services could get settings from a remote ConfigServer. I've created the ConfigServer as a spring boot app with annotation @EnableConfigServer. &#xA;After that i've created client app with next config file:</p>&#xA;&#xA;<pre><code>    application:&#xA;      name: mw&#xA;    cloud:&#xA;      config:&#xA;        enabled: true&#xA;        uri: http://172.17.42.1:8888&#xA;        fail-fast: true&#xA;</code></pre>&#xA;&#xA;<p>main class:</p>&#xA;&#xA;<pre><code>    @EnableEurekaClient&#xA;    @SpringBootApplication&#xA;    public class MwApplication&#xA;</code></pre>&#xA;&#xA;<p>and extra configuration into app:</p>&#xA;&#xA;<pre><code>    @Configuration&#xA;    @EnableJpaRepositories(basePackages = {""com.sample.repository""})&#xA;    @EnableTransactionManagement&#xA;    @EnableScheduling&#xA;    public class AppConfiguration&#xA;</code></pre>&#xA;&#xA;<p>also i have next dependencies:</p>&#xA;&#xA;<pre><code>    spring-cloud-starter-eureka&#xA;    spring-cloud-config-client&#xA;    spring-boot-configuration-processor&#xA;    spring-boot-starter-data-jpa&#xA;</code></pre>&#xA;&#xA;<p>When i execute my client app, i've got this message: ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""<a href=""http://localhost:8888/mw/default"" rel=""nofollow"">http://localhost:8888/mw/default</a>""</p>&#xA;&#xA;<p>The app try to get data from default uri(localhost) instead of to use uri from my setting. I've looked at app in debug mode and saw org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration was creating ConfigClientProperties with default property and my settings from application.yml weren't used. </p>&#xA;&#xA;<p>What am i doing wrong?&#xA;thanks.</p>&#xA;"
38687434,Best Practices for Microservices discovery without Hard Coding?,2016-07-31 19:01:30,<architecture><microservices>,2,397,0,0.0,4,"<p>This is a question that's been annoying me for a while, how does one write a series of microservices that run on on various machines at different locations without the need to hard code each services individual location?</p>&#xA;&#xA;<p>Like say for instance I had service A which does some form of validation of a json message. Service A runs on box 1,3,5 and more instances can be brought up as demand grows.</p>&#xA;&#xA;<p>Now say I have service B which looks to call upon service A, how would I communicate to service B where my service A resides? </p>&#xA;&#xA;<p>Possible Solutions I've considered:</p>&#xA;&#xA;<ul>&#xA;<li><p>Hard coding service B with the location of a 'master' node for Service A which then delegates tasks out to all instances of service A.</p></li>&#xA;<li><p>Utilization of message queues? - Service B writes to a series of message queues, Service A instances read from set message queues and sends back results to service B. </p></li>&#xA;<li><p>SSDP - utilizing some form of simple service discovery protocol to broadcast which services are running where on a set network and keeping track of these services. </p></li>&#xA;</ul>&#xA;&#xA;<p>I'm quite new to this architectural style so I'm hoping I've not missed something very simple?</p>&#xA;"
38554037,How to deal with shared models in micro service architectures,2016-07-24 16:06:26,<node.js><microservices>,3,1289,1,0.0,4,"<p>My goal is to create an architecture in which services should be able to deploy independent of each other and are completely autonomous, but what do you do when you have 2 services that reads from DB the same object type?</p>&#xA;&#xA;<p>In my case I have a socket server (micro service 1) and a http server (micro service 2). Using the http server my users creates an asset called: A, this asset gets stored on a DB and a mongoID is returned. Then, using another protocol and the ID, there are calls to the socket server that needs to check that validity of that ID, thus, needs to read from DB. This two services will have to share the model of A in order to map it to an object, but this means the 2 services will have to share code, and that's not ok.</p>&#xA;&#xA;<p>Do I need another service? or should I make only service1 able to read from DB and then make the second one talks to service 1?</p>&#xA;"
43246560,Microservices Architecture: Chatty services or data duplication,2017-04-06 05:39:28,<architecture><domain-driven-design><microservices>,3,395,0,1.0,4,"<p>TL;DR Should a service opt for saving data in its local database that it needs occasionally, or request the data every time from the service that the data originated from?</p>&#xA;&#xA;<p>Let's have some generic example of a web store / ordering app. Service A is a user session management service. It handles business logic of what a user is doing, what he can do, etc. The user can create his own shirt for purchase. Service B is a data aggregator that contains a lot of the inventory and what's available.</p>&#xA;&#xA;<p>The user starts creating a shirt, so service A request from service B, what styles/colors are available. Service B sends down a list of possible choices which service A then displays for the user. The user then selects one, customizes it and moves on to a new shirt. Again service A has to request from service B, what styles/colors are available. </p>&#xA;&#xA;<p>Now let's assume within a life cycle of a user session, these styles/colors won't change and we know this is going to be the same data being retrieved over and over again. Not by just this user, but all users. So in this case, since the styles/colors are really part of Service B's domain, they should stay there and live there, or would it be advised to prevent all these needless calls and upon the first request (temporarily) save in Service A the data for the lifecycle of the session to prevent chatty services.</p>&#xA;&#xA;<p>This is an over-simplified example but the problem remains real-world. Which is more suggested way of architecting this design? &#xA;This usually applies for example when some fairly-static data is passing through some service, and this service will need this data again a few times within the lifecycle of these transactions. So I'm unsure whether the service should just save it temporarily for the life-cycle knowing the data won't change or not caring if it changes within the lifecycle or opt for more chatty services and keep requesting every time.</p>&#xA;"
43763418,How to update Update X509 certificates for On-Premise Service Fabric cluster,2017-05-03 14:49:28,<microservices><azure-service-fabric>,1,288,2,0.0,4,"<p>The documentation for updating x509 certificates in Service Fabric is unclear to me with regards to non-Azure (On-Prem) installations: <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server</a></p>&#xA;&#xA;<p>I have followed these steps, but they have not worked.</p>&#xA;&#xA;<ol>&#xA;<li>Updated the cluster setup json template so that the thumbprint of the original certificate is now ""ThumbprintSecondary"".</li>&#xA;<li><p>Added the new certificate thumbprint under ""Thumbprint"". e.g.</p>&#xA;&#xA;<p>""security"": {&#xA;     ""metadata"": ""The Credential type X509 indicates this is cluster is &#xA;      secured using X509 Certificates. The thumbprint format is - d5 ec 42 3b 79 cb e5 07 fd 83 59 3c 56 b9 d5 31 24 25 42 64."",&#xA;        ""ClusterCredentialType"": ""X509"",&#xA;        ""ServerCredentialType"": ""X509"",&#xA;        ""CertificateInformation"": {&#xA;            ""ClusterCertificate"": {&#xA;                ""Thumbprint"": ""New Thumbprint"",&#xA;                ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;                ""X509StoreName"": ""My""&#xA;        },&#xA;        ""ServerCertificate"": {&#xA;        ""Thumbprint"": ""New Thumbprint"",&#xA;        ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;        ""X509StoreName"": ""My""&#xA;    },</p></li>&#xA;<li><p>Install the new certificate pfx and update the ACL for ""NETWORK SERVICE""</p></li>&#xA;<li>Run Start-ServiceFabricClusterConfigurationUpgrade -ClusterConfigPath ""Path to json Configuration File""</li>&#xA;</ol>&#xA;"
43785728,Where is the best place to do data aggregation for UI in microservices architecture,2017-05-04 14:30:33,<rest><api><web><single-page-application><microservices>,1,716,3,0.0,4,"<p>I am building an application using microservice architecture. It has five Rest API and one UI(single page application) microservices. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DbuHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DbuHq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Could anyone advise me which is the best option to do the data aggregation? </p>&#xA;&#xA;<ol>&#xA;<li>Make UI application as a static web application and do all API requests from the front end (from the browser using javascript framework) and all data aggregation do in front end itself and render? </li>&#xA;<li>Make UI application as a dynamic web application and do all API request and data aggregation in web application backend?</li>&#xA;</ol>&#xA;"
33926707,Passing objects between microservices,2015-11-25 21:28:36,<php><oop><soa><microservices>,1,527,0,1.0,4,"<p>I am experimenting with moving some parts of a monolith to external services. I like the idea so far and it seems a lot cleaner to encapsulate all related functionality inside one application. The different applications use RabbitMQ to communicate. </p>&#xA;&#xA;<p>I have a user object in one service. If I want to use this exact same class in the service I can easily serialize it and send the serialized object in the message body. But since both the sender and receiver need to contain the user class I would have to share a library containing some representation of the user object (although to me it seems strange to put the real user object in the library since it's core to the main application). I guess I could also just pass an array with a <code>user</code> key and defined key-values.</p>&#xA;&#xA;<p>I'm also thinking that if I someday create a service in something other than PHP then it won't be able to unserialize the user object and thus will have no access to the data in the message.</p>&#xA;&#xA;<p>So basically I like the idea of passing entities between services and being able to user them as objects in the receiving end, but I'm not sure if this is the right approach.</p>&#xA;&#xA;<p>My question is what would the best way to pass objects between these services be?</p>&#xA;"
34909182,Microservice solution structure in .NET applications,2016-01-20 19:48:28,<visual-studio><microservices>,1,1384,2,1.0,4,"<p>I'm developing an application using the microservices approach, and I'm having a hard time defining how those microservices will look like on a visual studio project.</p>&#xA;&#xA;<p>My initial approach is to create one visual studio solution for every microservice. Every solution will have the following projects:</p>&#xA;&#xA;<ul>&#xA;<li>Host</li>&#xA;<li>Business API</li>&#xA;<li>Data Access Layer</li>&#xA;<li>Model</li>&#xA;<li>Interfaces (for DI) </li>&#xA;<li>Data Access Mock</li>&#xA;<li>Tests for Business API</li>&#xA;</ul>&#xA;&#xA;<p>So there are 7 projects per microservice. Somehow it feels a lot of projects being reimplemented for every solution.</p>&#xA;&#xA;<p>Is this approach correct? Has anybody built microservices with .net? How does your projects configuration look like?</p>&#xA;"
31206417,SOA by microservices - how to normalize/transform messages,2015-07-03 12:03:08,<architecture><soa><transformation><microservices>,3,555,0,1.0,4,"<p>We are developing solution which adapts Messages Pattern and Microservices to define and run business flows.</p>&#xA;&#xA;<p>It should have such components:</p>&#xA;&#xA;<ul>&#xA;<li>Gateways to initiate transaction, with given flow id,</li>&#xA;<li>BPM to store rules (which services should be called for given flow)</li>&#xA;<li>Service selector - kind of processor, it takes request from gateway, get flow definition and then call appropriate services one by one,</li>&#xA;<li>Functional Services.</li>&#xA;</ul>&#xA;&#xA;<p>We should be able to define multiple flows where each step is to call different service.</p>&#xA;&#xA;<p>Output of one service may be input for another one. Problem is that they can have different schema so it should be transformed/normalized somehow.</p>&#xA;&#xA;<p>But which part should be responsible to do such transformation? It should be configurable, because we want to add new flows without redeployment.</p>&#xA;&#xA;<p>First idea is to store responses from each services, and then each step will use XSLT transformation to produce input xml out of previous responses. But it may be configuration hell, cause creating and testing such XSLT won't be easy</p>&#xA;&#xA;<p>Do you have any suggestions how to solve this properly?</p>&#xA;"
31190685,Microservices explained,2015-07-02 17:07:56,<php><microservices>,4,1266,0,1.0,4,<p>I'm trying to understand micro services. Can someone please explain to me how it works? I've looked at several tutorials and still confused.</p>&#xA;&#xA;<p>Let's say you have a shopping application. What are the different microservices entailed for such an application?</p>&#xA;&#xA;<p>I will need to do the following</p>&#xA;&#xA;<ul>&#xA;<li>Account creation</li>&#xA;<li>Charge the customer</li>&#xA;<li>Get a list of items for sale&#xA;etc</li>&#xA;</ul>&#xA;
46131196,com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server,2017-09-09 13:26:18,<java><spring-boot><microservices>,4,9807,0,2.0,4,"<p>I am very new to the microservices and trying to run the code from link: <a href=""https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa"" rel=""nofollow noreferrer"">https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa</a> . When I simply run the code I see the following error comes. </p>&#xA;&#xA;<p>What is the issue ?</p>&#xA;&#xA;<pre><code>com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server&#xA;    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1030) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:944) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1468) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1435) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;&#xA;2017-09-09 18:53:11.909 ERROR 16268 --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error&#xA;</code></pre>&#xA;&#xA;<p>I have not installed anything special on to the system. Please let me know what do I need to install? </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/8oWl2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8oWl2.png"" alt=""enter image description here""></a></p>&#xA;"
41837637,Microservices vs multi-layered architecture,2017-01-24 19:45:25,<asp.net-web-api><architecture><microservices><multi-layer>,1,2806,0,1.0,4,"<p>My project has one backend service (Web API) and one frontend SPA application. Backend service has presentation, application services, domain and infrastructure layers located in different .net assemblies. Domain layer has business domain objects, infrastructure â€“ communication with external data and other stuff, application services â€“ set of services used by presentation layer, presentation â€“ Web API controllers. I think itâ€™s very common layered architecture.</p>&#xA;&#xA;<p>Our new architect announced we are going to move backend to microservices architecture braking down our layers and dividing domain, application service and infrastructure layers to a few services and convert presentation layer to backend for frontend layer (as <a href=""http://samnewman.io/patterns/architectural/bff/"" rel=""nofollow noreferrer"">here</a> described). In feature, we are going to have mobile application. Sql Server database is going to leave as is for now.</p>&#xA;&#xA;<p>I donâ€™t have experience with microservice architecture, so my questions are: &#xA;Is multi-layered architecture out of fashion already? What benefits and problems can bring such architecture design for my application?</p>&#xA;"
41824300,.NET Core API Gateway,2017-01-24 09:18:44,<c#><api><.net-core><microservices><gateway>,2,6347,9,3.0,4,"<p>I've got some work to do for school around Microservices. </p>&#xA;&#xA;<p>I've got the architectural concept, but need an implementation to show off. I'll be using angular2 as a client, would like to use a .NET core API gateway to dispatch my requests to different services. </p>&#xA;&#xA;<p>What's the best approach for this? I red something about using Rx.Net, but no definitive example or implementation that I can follow.</p>&#xA;&#xA;<p>So what should I do to implement an API gateway in .NET Core?</p>&#xA;"
51416552,How to call one microservice from another microservice using docker images,2018-07-19 07:16:12,<java><rest><docker><spring-boot><microservices>,2,103,8,2.0,4,"<p>I have two <code>SpringBoot</code> microservices <code>M1</code>(port 2002) and <code>M2</code>(port 2004)</p>&#xA;&#xA;<p><code>M1</code> and <code>M2</code> are communicating successfully if I run them using <code>eclipse</code> (run as Java Project or SpringBoot Project). </p>&#xA;&#xA;<p>However, I want to communicate them using <code>Docker container</code>.</p>&#xA;&#xA;<p>So I build images for both <code>Microservices</code> (<code>M1</code> and <code>M2</code>) using the command:</p>&#xA;&#xA;<pre><code>docker build -f Dockerfile -t image_name .&#xA;</code></pre>&#xA;&#xA;<p>And run the images using:</p>&#xA;&#xA;<pre><code>docker run -p 2004:2004 image_name&#xA;</code></pre>&#xA;&#xA;<p><strong>Note: I am exposing same port from docker as defined above</strong></p>&#xA;&#xA;<p>But the M1 and M2 are not able to communicate.&#xA;I am using <code>RestTemplate</code> </p>&#xA;&#xA;<pre><code>RestTemplate restTemplate = new RestTemplate();&#xA;ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://localhost:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p>I am getting below exception : </p>&#xA;&#xA;<pre><code>I/O error on GET request for \""http://localhost:2002/apis/test\"": Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)&#xA;</code></pre>&#xA;&#xA;<p>However, If I call the other microservice using my <strong>machine's IP</strong>, It's communicating successfully </p>&#xA;&#xA;<pre><code>ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://XX.XX.XX.XXX:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p><strong>Can someone please tell if I am  doing it write(using IP address) or there is another good approach to call one microservice from another using Docker?</strong> </p>&#xA;"
45002471,Are docker containers safe enough to run third-party untrusted containers side-by-side with production system?,2017-07-10 01:02:04,<docker><microservices>,2,147,0,1.0,4,"<p>We plan to allow execution of third-party micro-services code on our infrastructure interacting with our api. &#xA;Is dockerizing safe enough? Are there solutions for tracking resources(network, ram,cpu)container consumes? </p>&#xA;"
42498492,Avoid bottlenecks in microservices,2017-02-28 00:51:28,<microservices>,1,295,0,2.0,4,"<p>I'm going to apply Microservices for my Datawarehouse application. There are 4 main Microservices in application:</p>&#xA;&#xA;<p>1) Data Service: Import/Export external data sources to DWH and Query data from DWH.</p>&#xA;&#xA;<p>2) Analytics Service: for chart visualization on UI</p>&#xA;&#xA;<p>3) Machine Learning: for recommendation system</p>&#xA;&#xA;<p>4) Reports: for report generating</p>&#xA;&#xA;<p>The diagram as below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hW6lc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hW6lc.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each service has its own DB and they communicate directly with each other via TCP and Thift serialization. The problem here is Data Service suffer a high load from other services and can become a SPOF of application. Data in DWH is big too (maybe up to hundred miliions of records). How to avoid the bottlenecks for Data Service in this case? Or How do I define a properly bounded context to avoid the bottlenecks?</p>&#xA;"
47311911,Event sourcing / CQRS read model - projections,2017-11-15 15:57:11,<domain-driven-design><microservices><cqrs><event-sourcing>,2,407,0,0.0,4,"<p>I have a microservice-based application running on AWS Lambda. Two of the microservices, the most crucial ones, use event-sourcing/cqrs. </p>&#xA;&#xA;<p><strong>Background: (this is also for me to organize my thoughts)</strong></p>&#xA;&#xA;<p>I'm using <a href=""https://github.com/bakerface/easy-source"" rel=""nofollow noreferrer"">this library</a>  and storing events in DynamoDB and projections in AWS S3.</p>&#xA;&#xA;<p>The write part works like a charm: Each command invocation loads the current state of the aggregate from DynamoDB (by running events through a handler and/or loading an cached aggregate), it decides to accept or reject the command based on some business logic, then writes to DynamoDB with <code>KeyConditionExpression: 'aggregateId = :a AND version &gt;= :v'</code> where the version is a count of events processed for that aggregate. If there's a conflict, the write fails. Seems like a good system to me!</p>&#xA;&#xA;<p>Each event is then broadcast to SNS (topic name is the service name) so other services can react to the event, if they want.</p>&#xA;&#xA;<p>The part that I really struggle with is the read. Projections are stored in S3 and tagged with the last commitId processed for each event source. When a read query comes in, it loads the entire projected state from S3 <em>(for all aggregates)</em>, queries the event sources for all newer events, computes the latest state (again, for all aggregates - and writing an updated object to S3 if it's newer), and returns relevant parts of the state based on the query params.</p>&#xA;&#xA;<p><strong>My problem: (or one of them)</strong></p>&#xA;&#xA;<p>I think I'm doing projections wrong. </p>&#xA;&#xA;<p>Most of my projections only group ids by important attribute, so the files stay relatively small. But I also need a way to retrieve an individual aggregate. Using projections for that seems crazy, because I need to load the entire state each time (i.e. every projected aggregate) apply new events to that, then retrieve the record I want (it may not have even changed).</p>&#xA;&#xA;<p>This is what I'm doing now, it's performing fine (&lt;100k records) but I can't imagine it will continue much longer. </p>&#xA;&#xA;<p>The other problem is queries. I need to build a projection mapping value to matching aggregateIds for every attribute I need to query on!! There's got to be a better way!</p>&#xA;&#xA;<p>No matter what way I think about this problem, projections always need the entire current state + any new events before it can return even a single record that hasn't changed.</p>&#xA;"
49612911,Understanding microservices using Express.js and docker,2018-04-02 14:13:05,<node.js><express><microservices>,2,332,0,1.0,4,"<p>I am new to node.js and docker as well as the microservices architecture.&#xA;I am trying to understand what microservices architecture actually is and theoretically I do understand what microservices arch is.Please see the following implementation&#xA;This is the <strong>index.js</strong> file:</p>&#xA;&#xA;<pre><code>var express = require(""express""); &#xA;var app = express();&#xA;var service1 = require(""./service1"");&#xA;var service2 = require(""./service2"");&#xA;app.use(""/serviceonerequest"",service1);&#xA;app.use(""/servicetwo"",service2);&#xA;app.listen(3000,function(){&#xA;    console.log(""listening on port 3000"");&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service1</strong>:</p>&#xA;&#xA;<pre><code>    var express = require(""express"");&#xA;    var router = express.Router();&#xA;    router.use(express.json());&#xA;    router.get(""/"",(req,res)=&gt;{&#xA;        //perform some service here&#xA;        res.send(""in the get method of service 1"");&#xA;        res.end();&#xA;        });&#xA;&#xA;        router.post(""/letsPost"",(req,res)=&gt;{&#xA;            res.send(req.body);&#xA;            res.end(""in post method here"");&#xA;        })&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service2:</strong></p>&#xA;&#xA;<pre><code>var express = require(""express"");&#xA;var router = express.Router();&#xA;&#xA;router.use(express.json());&#xA;router.get(""/"",(req,res)=&gt;{&#xA;    //perform some service here&#xA;    res.end(""in the GET method for service 2"");&#xA;});&#xA;&#xA;router.post(""/postservice2"",(req,res)=&gt;{&#xA;    res.send(req.body);&#xA;});&#xA;&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>Does the above qualifies as 'micro service architecture'?Since there are two services and they can be accessed through the 'api-gateway' index.js?</li>&#xA;<li>I have read the basic tutorial of Docker.Is it possible to have the above three ""modules"" in separate containers?</li>&#xA;<li>If the above does not qualify as a microservice what should be done to convert the above sample into microservices?</li>&#xA;</ol>&#xA;"
50454109,Communication between microservices - request data,2018-05-21 17:46:22,<rest><rabbitmq><microservices><rpc>,3,363,3,1.0,4,"<p>I am dealing with communication between microservices.</p>&#xA;&#xA;<p>For example (<em>fictive example, just for the illustration</em>):</p>&#xA;&#xA;<ul>&#xA;<li><strong>Microservice A - Store Users (getUser, etc.)</strong></li>&#xA;<li><strong>Microservice B - Store Orders (createOrder, etc.)</strong></li>&#xA;</ul>&#xA;&#xA;<p>Now if I want to add new Order from the Client app, I need to know user address. So the request would be like this:</p>&#xA;&#xA;<p><strong>Client -> Microservice B (createOrder for userId 5) -> Microservice A (getUser with id 5)</strong></p>&#xA;&#xA;<p>The microservice B will create order with details (address) from the User Microservice.</p>&#xA;&#xA;<p><strong>PROBLEM TO SOLVE:</strong> How effectively deal with communication between microservice A and microservice B, as we have to wait until the response come back?</p>&#xA;&#xA;<p><strong>OPTIONS:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Use RestAPI,</li>&#xA;<li>Use AMQP, like RabbitMQ and deal with this issue via RPC. (<a href=""https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html"" rel=""nofollow noreferrer"">https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html</a>)</li>&#xA;</ul>&#xA;&#xA;<p>I don't know <strong>what will be better for the performance</strong>. Is call faster via RabbitMQ, or RestAPI? <strong>What is the best solution for microservice architecture</strong>?</p>&#xA;"
45538292,"In a publish/subscribe model in microservices, how to receive/consume a message only once per service type",2017-08-07 01:38:32,<rabbitmq><apache-kafka><messaging><publish-subscribe><microservices>,4,360,0,1.0,4,"<p>We are designing for a microservices architecture model where service A publishes a message and services B, and C would like to receive/consume the message. However, for high availability multiple instances of services B and C are running at the same time. Now the question is how do we design such that only one service instance of B and one service instance of C receive the message and not all the other service instances. </p>&#xA;&#xA;<p>As far as I know about RabbitMQ, it is not easy to achieve this behavior. I wonder if Kafka or any other messaging framework has a built-in support for this scenario, which I believe should be very common in a microservices architecture.</p>&#xA;"
37409153,"No cluster endpoint is reachable, please check if there is connectivity/firewall/DNS issue",2016-05-24 09:14:05,<azure><microservices>,1,2227,2,0.0,4,"<p>I am currently working on cloud technology, in one of my current project I was created the service fabric cluster in azure after created the service fabric in azure, next I am trying to connect the cluster through the Windows Power shell It gives the error like this below figure.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6YnM8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6YnM8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Please tell me how to resolve the above issue.</p>&#xA;&#xA;<p>Regards,</p>&#xA;&#xA;<p>Pradeep</p>&#xA;"
43350853,Authentication with Kong,2017-04-11 15:56:31,<django><authentication><microservices><restful-authentication><kong>,1,741,0,4.0,4,"<p>I'm looking at <a href=""https://getkong.org/"" rel=""nofollow noreferrer"">Kong</a> to replace my current hand-rolled NodeJS API gateway. Currently I have a user service that handles authentication (written in Django) by providing a JWT back upon login, which the client then passes in through a header. My current API gateway then intercepts any calls, does a validation call back to the user service, and replaces the JWT Header with <code>X-User-Id</code> and <code>X-User-Email</code>. </p>&#xA;&#xA;<p>As far as I can tell, Kong can do roughly the same thing. I'm trying to figure out the flow of how this should work <em>in a perfect world</em>. I still have the opportunity to replace much of the infrastructure, so rewriting some services is not completely out of the question. </p>&#xA;&#xA;<p>So, in my mind, what would happen is the following:</p>&#xA;&#xA;<ol>&#xA;<li>User registers on my site. I then create a new consumer with their username/id on Kong</li>&#xA;<li>User logs in. This is where I get stuck. Do I log in (or in this case, simply authenticate the user as being said user), ask Kong for the JWT for this consumer, and return that? What if I wanted some more data in the payload of the JWT? What happens on Kong's side when the JWT expires?</li>&#xA;<li>When the user requests a service, Kong will the sniff out the JWT from the headers, replace it with <code>X-Consumer-*</code> - is that correct? </li>&#xA;</ol>&#xA;&#xA;<p>Please do correct me if my thinking is wrong, or if there is a better way to achieve this. I'm fairly new to the whole microservices thing. </p>&#xA;"
47554214,Design choice for a microservice event-driven architecture,2017-11-29 13:39:28,<domain-driven-design><microservices><cqrs>,3,248,0,1.0,4,"<p>Let's suppose we have the following:</p>&#xA;&#xA;<p>DDD aggregates A and B, A can reference B.</p>&#xA;&#xA;<p>A microservice managing A that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create A</li>&#xA;<li>delete A</li>&#xA;<li>link A to B</li>&#xA;<li>unlink A from B</li>&#xA;</ul>&#xA;&#xA;<p>A microservice managing B that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create B</li>&#xA;<li>delete B</li>&#xA;</ul>&#xA;&#xA;<p>A successful creation, deletion, link or unlink always results in the emission of a corresponding event by the microservice that performed the action.</p>&#xA;&#xA;<p>What is the best way to design an event-driven architecture for these two microservices so that:</p>&#xA;&#xA;<ol>&#xA;<li>A and B will always eventually be consistent with each other. By consistency, I mean A should not reference B if B doesn't exist.</li>&#xA;<li>The events from both microservices can easily be projected in a separate read model on which queries spanning both A and B can be made</li>&#xA;</ol>&#xA;&#xA;<p>Specifically, the following examples could lead to transient inconsistent states, but consistency must in all cases eventually be restored:</p>&#xA;&#xA;<p><strong>Example 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B doesn't, A is not linked to B</li>&#xA;<li>Command: link A to B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 2</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is linked to B</li>&#xA;<li>Command: delete B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 3</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is not linked to B</li>&#xA;<li>Two simultaneous commands: link A to B and delete B</li>&#xA;</ul>&#xA;&#xA;<p>I have two solutions in mind.</p>&#xA;&#xA;<p><strong>Solution 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has previously received a ""B created"" event and no ""B deleted"" event.</li>&#xA;<li>Microservice B only allows deleting B if it has not previously received a ""A linked to B"" event, or if that event was followed by a ""A unlinked from B"" event.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B (for the race condition in which B is deleted before it has received the A linked to B event).</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A always allows linking A to B.</li>&#xA;<li>Microservice B listens for ""A linked to B"" events and, upon receiving such an event, verifies that B exists. If it doesn't, it emits a ""link to B refused"" event.</li>&#xA;<li>Microservice A listens for ""B deleted"" and ""link to B refused"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT: Solution 3, proposed by Guillaume:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has not previously received a  ""B deleted"" event.</li>&#xA;<li>Microservice B always allows deleting B.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p>The advantage I see for solution 2 is that the microservices don't need to keep track of of past events emitted by the other service. In solution 1, basically each microservice has to maintain a read model of the other one.</p>&#xA;&#xA;<p>A potential disadvantage for solution 2 could maybe be the added complexity of projecting these events in the read model, especially if more microservices and aggregates following the same pattern are added to the system.</p>&#xA;&#xA;<p>Are there other (dis)advantages to one or the other solution, or even an anti-pattern I'm not aware of that should be avoided at all costs?&#xA;Is there a better solution than the two I propose?</p>&#xA;&#xA;<p>Any advice would be appreciated.</p>&#xA;"
47680711,Which HTTP errors should never trigger an automatic retry?,2017-12-06 18:02:51,<http><microservices><hystrix><spring-retry>,1,461,3,2.0,4,"<p>I'm trying to make a few microservices more resilient and retrying certain types of HTTP requests would help with that.</p>&#xA;&#xA;<p>Retrying timeouts will give clients a terribly slow experience, so I don't intend to retry in this case. Retrying 400s doesn't help because a bad request will remain a bad request a few milliseconds later. </p>&#xA;&#xA;<p>I imagine there are other reasons to not retry a few other types of errors, but which errors and why?</p>&#xA;"
40786831,How do I version control a kubernetes application?,2016-11-24 12:48:39,<kubernetes><microservices><kubernetes-helm>,2,771,0,1.0,4,"<p>I've checked out helm.sh of course, but at first glance the entire setup seems a little complicated (helm-client &amp; tiller-server). It seems to me like I can get away by just having a helm-client in most cases.</p>&#xA;&#xA;<p><strong>This is what I currently do</strong></p>&#xA;&#xA;<p>Let's say I have a project composed of 3 services viz. <code>postgres</code>, <code>express</code>, <code>nginx</code>.</p>&#xA;&#xA;<p>I create a directory called <code>product-release</code> that is as follows:</p>&#xA;&#xA;<pre><code>product-release/&#xA;    .git/&#xA;    k8s/&#xA;        postgres/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;            Secret.mustache.yaml   # Needs to be rendered by the dev before use&#xA;        express/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;        nginx/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;    updates/&#xA;        0.1__0.2/&#xA;            Job.yaml    # postgres schema migration&#xA;            update.sh   # k8s API server scritps to patch/replace existing k8s objects, and runs the state change job&#xA;</code></pre>&#xA;&#xA;<p>The usual git stuff can apply now. Everytime I make a change, I make changes to the spec files, test them, write the update scripts to help move from the last version to this current version and then commit it and tag it.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<ol>&#xA;<li>This works for me so far, but is this ""the right way""?</li>&#xA;<li>Why does <code>helm</code> have the tiller server? Isn't it simpler to do the templating on the client-side? Of course, if you want to separate the activity of the deployment from the knowledge of the application (like secrets) the templating would have to happen on the server, but otherwise why?</li>&#xA;</ol>&#xA;"
40936597,Spring Eureka App doesn't show dashboard,2016-12-02 16:16:44,<java><spring><microservices><netflix-eureka>,3,1019,1,0.0,4,"<p>There is a Eureka Server application:</p>&#xA;&#xA;<pre><code>@EnableEurekaServer&#xA;@SpringBootApplication&#xA;public class RegistrationModulesServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(RegistrationModulesServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>With applicaton.yml config (be default):</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    hostname: localhost&#xA;  client: &#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;server:&#xA;  port: 1111  &#xA;</code></pre>&#xA;&#xA;<p>On the first run - I saw dashboard with statuses.&#xA;Like in documentation:&#xA;<a href=""https://i.stack.imgur.com/Sa2cD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Sa2cD.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Then - after restart I can see only xml response:&#xA;<a href=""https://i.stack.imgur.com/1lC5l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1lC5l.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Why?</p>&#xA;&#xA;<p>No error in log.</p>&#xA;"
50264214,How to edit the source code in module after installed it using zef?,2018-05-10 01:28:25,<web><microservices><perl6><cro>,2,109,0,0.0,4,"<p>For example, I've installed the <a href=""http://cro.services"" rel=""nofollow noreferrer"">Cro</a> module, when I run my simple code:</p>&#xA;&#xA;<pre><code> my %headers = {Authorization =&gt; OAuth realm="""", oauth_consumer_key=""xxxxxxxxxxxxxxxx"", oauth_nonce=""29515362"", oauth_signature=""KojMlteEAHlYjMcLc6LFiOwRnJ8%3D"", oauth_signature_method=""HMAC-SHA1"", oauth_timestamp=""1525913154"", oauth_token=""xxxx-xxxxxxxxxxxxxxxxxx"", oauth_version=""1.0"", User-Agent =&gt; Cro};&#xA;&#xA; my $resp = await Cro::HTTP::Client.get: 'http://api.fanfou.com/statuses/home_timeline.json',&#xA;     headers =&gt; [&#xA;            user-agent   =&gt; 'Cro',&#xA;            content-type =&gt; 'application/json;charset=UTF-8',&#xA;            |%headers&#xA;     ];&#xA;&#xA; say $resp.header('content-type'); # Output: application/json; charset=utf-8;&#xA; my Str $text = await $resp.body-text(); &#xA;</code></pre>&#xA;&#xA;<p>And it says 'Could not parse media type <code>application/json; charset=utf-8;</code></p>&#xA;&#xA;<pre><code>Died with the exception:&#xA;    Could not parse media type 'application/json; charset=utf-8;'&#xA;      in method parse at /Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69 (Cro::MediaType) line 74&#xA;      in method content-type at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 74&#xA;      in method body-text-encoding at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 83&#xA;      in block  at /Users/ohmycloud/.perl6/sources/F870148C579AB45DEB39F02722B617776C3D6D5F (Cro::MessageWithBody) line 49&#xA;</code></pre>&#xA;&#xA;<p>It seems that <code>application/json; charset=utf8;</code> is not a valid <code>content-type</code>, so I add a test:</p>&#xA;&#xA;<pre><code>use Cro::MediaType;&#xA;use Test;&#xA;&#xA;sub parses($media-type, $desc, &amp;checks) {&#xA;    my $parsed;&#xA;    lives-ok { $parsed = Cro::MediaType.parse($media-type) }, $desc;&#xA;    checks($parsed) if $parsed;&#xA;}&#xA;&#xA;parses 'application/json; charset=utf-8;', 'application/json media type with charset', {&#xA;    is .type, 'application', 'Correct type';&#xA;    is .subtype, 'json', 'Correct subtype';&#xA;    is .subtype-name, 'json', 'Correct subtype name';&#xA;    is .tree, '', 'No tree';&#xA;    is .suffix, '', 'No suffix';&#xA;    is .Str, 'application/json; charset=utf-8;', 'Stringifies correctly';&#xA;};&#xA;&#xA;done-testing;&#xA;</code></pre>&#xA;&#xA;<p>And the output is:</p>&#xA;&#xA;<pre><code>not ok 1 - application/json media type with charset&#xA;# Failed test 'application/json media type with charset'&#xA;# at cro_media.pl6 line 6&#xA;# Could not parse media type 'application/json; charset=utf-8;'&#xA;1..1&#xA;# Looks like you failed 1 test of 1&#xA;</code></pre>&#xA;&#xA;<p>the source code seems locate in the <code>/Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69</code> file, and I add <code>';'?</code> after the <code>TOP</code> token:</p>&#xA;&#xA;<pre><code>token TOP { &lt;media-type&gt; ';'? }&#xA;</code></pre>&#xA;&#xA;<p>save, and run my code again, but the error is the same. So how to make the change work? In Perl 5, I can just edit my <code>.pm</code> module, but in Perl 6, I dont't know what to do. </p>&#xA;"
40669943,why hystrix or any other circuit breaker for a microservice?,2016-11-18 05:28:16,<java><spring><spring-boot><microservices><hystrix>,2,799,0,1.0,4,"<p>I am developing microservice with spring boot and spring cloud. I came to know about hystrix and circuit breaker pattern. I know that circuit breakers are for responding with alternate response in case of errors from downstream microservices on which I depend on to get the data. My question is, if I don't have any meaningful alternative response to provide, why would I need a circuit breaker at all?</p>&#xA;"
48515460,Is it recommended to use Database as a container in Production environment?,2018-01-30 06:46:30,<database><docker><containers><microservices><production-environment>,3,1693,0,0.0,4,"<p>Assuming we are using a micro service architecture for a product and we decide to use 'Database per service' model, and deploy in cloud servers by provider like AWS. &#xA;It is convenient to have databases running as a container for development and test environments. </p>&#xA;&#xA;<p>But can same be implemented for Production environment! If so, how safe it would be?&#xA;Or is it proper to go with cloud solution as AWS RDS-DB instead!!</p>&#xA;"
37739538,API Gateway example for node.js,2016-06-10 03:45:31,<node.js><microservices>,1,2858,0,1.0,4,"<p>Looking for a good example of how to implement a node API gateway for a microservice application, I understand the purpose of having a gateway, I am just not sure of how to implement this without just adding another level of RESTful route calls. To me a gateway is supposed to just direct the route to the microservice. </p>&#xA;&#xA;<p><strong>API Gateway port 3000</strong></p>&#xA;&#xA;<pre><code>router.use('/microservicename/*', function (req, res, next) {&#xA;     **code that will direct to microservice**&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 server.js port 3001</strong></p>&#xA;&#xA;<pre><code>var express = require('express');&#xA;var app = express();&#xA;&#xA;var routes = require('./routes/routes');&#xA;&#xA;app.use('/microservicename', routes);&#xA;&#xA;var server = app.listen(3001, function () {&#xA;    console.log('Server running at http://127.0.0.1:3001/');&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 router.js (3001)</strong></p>&#xA;&#xA;<pre><code>router.get('/route1', function (req, res, next) {&#xA;  //get route code&#xA;});&#xA;&#xA;router.post('/route2', function (req, res, next) {&#xA;  //post route code&#xA;});&#xA;&#xA;router.put('/route3', function (req, res, next) {&#xA;  //put route code&#xA;});&#xA;&#xA;router.delete('/route4', function (req, res, next) {&#xA;  //delete route code&#xA;});&#xA;</code></pre>&#xA;"
46605663,Best practices sharing types across multiple Haskell packages/microservices,2017-10-06 12:22:41,<haskell><architecture><microservices>,1,131,3,1.0,4,"<p>I am working in a Haskell project that is composed of multiple microservices. There are certain types that are needed by multiple services at the same time and therefore are defined in separate libraries that are imported by whichever needs them (each type is versioned). But there are things about it that make me uncomfortable and I was wondering which are the best practises regarding that topic. In particular:</p>&#xA;&#xA;<ul>&#xA;<li>I don't know how to handle instances of shared types. In order to avoid orphans the instances must be defined in the type's module for each of the types. But then there are instances that are not needed by all the microservices that import the package and have to be included regardless, potentially adding redundant dependencies to the microservice. An example would be a datatype <strong>T</strong> that is shared by a frontend and a backend. It has an instance of <strong>Store</strong> in order to be stored in a database that is not needed by the frontend, but still makes the frontend depend of the store package.</li>&#xA;<li>In order to avoid the previous issue I could introduce a wrapper every time the type has to ""leave"" a microservice to represent that type going through the wire. In the previous example I would have a <strong>Storable T</strong> which would have an instance for <strong>Store</strong>. This adds quite a lot of overhead to the overall development process though.</li>&#xA;<li>Is it even a good idea to share the types or should each microservice define its own representation of each type, so nothing has to be shared? So for a type <strong>T</strong> a microservice <strong>MA</strong> would have a representation <strong>A.T</strong> and an instance to serialise it in order to send the data to a microservice <strong>B</strong> which would decode that data into a representation <strong>MB.T</strong>.</li>&#xA;</ul>&#xA;&#xA;<p>And finally, regarding the logistical side of the matter,</p>&#xA;&#xA;<ul>&#xA;<li>What's the most convenient way to structure the project? Would a monorepo be a better choice than having separate repos/submodules?</li>&#xA;<li>Maybe related to the previous one, is there any way to find out automatically which microservices should be redeployed when one of the shared libraries is modified because the changes in the library affect a piece of code that is being used by the microservice?</li>&#xA;</ul>&#xA;"
47938835,How to create replay mechanism within event-drive microservice,2017-12-22 09:17:08,<java><architecture><transactions><microservices><event-driven-design>,2,170,3,1.0,4,"<p>We have 7 microservices communicated via eventbus.&#xA;We have a real-time transaction sequence:</p>&#xA;&#xA;<p>Service 1->service2->service3 (and so on.) Until transactions considered as completed</p>&#xA;&#xA;<p>We must make sure all transactions happened.</p>&#xA;&#xA;<p>Ofcourse we can have failures at any point. So we are thinking about mechanisem to replay ""half-baked"" transactions into completion.</p>&#xA;&#xA;<p>It's getting tricky. Two ways we thought about:</p>&#xA;&#xA;<ol>&#xA;<li><p>Having another service (supervisor service) that will log each part in our real time sequence and will be smart enough when transactions are not completed (timedout) to understand how we can continune from left point</p>&#xA;&#xA;<p>Disadvantages:&#xA;lots of ""smart"" logic on one central service</p></li>&#xA;<li><p>having retry mechanisem on every service while each one taking care of it's own and replay it's own until success or exhusated</p>&#xA;&#xA;<p>Disadvantages:&#xA; lots of retry duplicated code on each service</p></li>&#xA;</ol>&#xA;&#xA;<p>What do you experts think?</p>&#xA;&#xA;<p>Thank</p>&#xA;"
47451190,Kafka instead of Rest for communication between microservices,2017-11-23 08:53:42,<rest><apache-kafka><microservices>,1,912,0,1.0,4,"<p>I want to change the communication between (micro)-services from REST to Kafka.&#xA;I'm not sure about the topics and wanted to hear some opinions about that.</p>&#xA;&#xA;<p>Consider the following setup:&#xA;I have an API-Gateway that provides CRUD functions via REST for web applications. So I have 4 endpoints which users can call.&#xA;The API-Gateway will produce the request and consumes the responses from the second service.&#xA;The second service consumes the requests, access the database to execute the CRUD operations on the database and produces the result.</p>&#xA;&#xA;<p>How many topics should I create?&#xA;Do I have to create 8 (2 per endpoint (request/response)) or is there a better way to do it?</p>&#xA;&#xA;<p>Would like to hear some experience or links to talks / documentation on that.</p>&#xA;"
47364834,Microservices sharing code,2017-11-18 10:09:25,<javascript><node.js><microservices>,1,94,7,1.0,4,"<p>There are so many answers and blogposts saying ""never share code between microservices"" and I wonder right now how I am supposed to follow that advice. I've got the following microservices and each of them is communicating via RabbitMQ:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0Agof.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Agof.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The express server and the two different background services have completely different code, while the request workers are just multiple instances. Each request worker is supposed to process a request and return a direct reply to it once it is done with it (RPC).</p>&#xA;&#xA;<p><strong>My question:</strong></p>&#xA;&#xA;<p>I have written a class (<code>RequestScheduler</code>) which offers methods to schedule a request (e. g. <code>getProfile: Promise&lt;IProfile&gt;</code>). Since I am apparently not allowed to share code between microservices what about the code for the communication between the microservices?</p>&#xA;&#xA;<p>I don't see a way how I could avoid sharing that code along my microservices on the left side.</p>&#xA;"
40457443,azure service fabric reliable dictionary linq query very slow,2016-11-07 03:36:20,<c#><performance><linq-to-entities><microservices><azure-service-fabric>,1,1465,7,1.0,4,"<p>I have a reliable dictionary in service fabric stateful service. I have a simple linq expression.<br>&#xA;I am using Ix-Async package for building an asyncenumerable.  </p>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>using (ITransaction tx = this.StateManager.CreateTransaction())  &#xA;        {  &#xA;&#xA;          var result = (await customers.CreateLinqAsyncEnumerable(tx))&#xA;                .Where(x =&gt; x.Value.NameFirst != null &amp;&amp; x.Value.NameFirst.EndsWith(n, StringComparison.InvariantCultureIgnoreCase))&#xA;                    .Select(y =&gt; y.Value);&#xA;&#xA;           return await result.ToList();&#xA;&#xA;&#xA;        }  &#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The data is organized into 2 partitions with around 75,000 records in each partition. I am using Int64 range as the partition key. In the above code, the ""Result.ToList()"" takes around 1 minute to execute for each partition. Another weired thing is, the actual result is empty!. The same sql run in sql server returns rows with customer first names ending with ""c"". But, this is besides the point. My biggest concern is performance of ""ReliableDictionary"" linq query.<br>&#xA;Regards</p>&#xA;"
43609390,User as a microservice,2017-04-25 11:26:44,<architecture><microservices>,1,506,1,1.0,4,"<p>I'm working on PAAS solution as a product. we have divided business processes in several microservices. One core part of the processes is closely connected to nearly all microservices.</p>&#xA;&#xA;<p>Is this a good practice to create a separate service to manage data such as user management? After the implementation, only this service will have access to users and other related DB tables. All other services will have to call this new user microservice for user related tasks.</p>&#xA;&#xA;<p>This approach will enforced us to refactor DB schema by adding denormalization. We would not get underlying tables that is served among multiple microservices. If serveral services needs data, it would be shared via a microservice.</p>&#xA;"
41067341,"what is the difference between distributed computing, microservice and parallel computing",2016-12-09 19:11:53,<terminology><distributed-computing><microservices>,1,2395,0,1.0,4,"<p>My basic understanding for:</p>&#xA;&#xA;<p>Distributed computing is a model of connected nodes -from hardware perspective they share only network connection- and communicate through messages. each node code be responsible for one part of the business logic as in ERP system there is a node for hr, node for accounting. communication could be HTML, SOA, RCP</p>&#xA;&#xA;<p>Microservice is a service that is responsible for one part of the business logic and communicate with each other usually by http. microservices could share the hardware resources and are accessed by thier api.</p>&#xA;&#xA;<p>Parallel systems are systems which optimize the use of resources. for example multithreaded app running on several thread where sharing memory resources.</p>&#xA;&#xA;<p>I am a little bit confused since microservices are distributed systems, but when running multiple microservices on single hardware resources they are also parallel systems. Am i getting it right here:</p>&#xA;"
41018981,Microservices and database,2016-12-07 13:38:59,<database><docker><cloud><microservices><docker-swarm>,1,656,0,1.0,4,"<p>What is the best practice to deploy database in microservices architecture, more precisely in distributed environment, such as docker swarm? Microservices principles states each service should be stateless to enable scaling. As database obviously has a state, should it live at fixed position outside of cluster, deployed and configured before the cluster is initialized?</p>&#xA;&#xA;<p>I'm confused, because all docker compose examples includes database container in the service definition. But things aren't that simple. Often the database needs a lot of configuration before it's ready to use. Also, docker sucks at coordinating the service starting order.</p>&#xA;&#xA;<p>If it's really a good practice to deploy the database alongside with services to docker swarm, how to ensure consistency and persistence of cricial data?</p>&#xA;"
45847796,What is a sidecar in the context of microservices?,2017-08-23 19:19:33,<kubernetes><microservices><istio>,2,1026,0,1.0,4,<p>I'm currently looking through an Istio and Kubernetes talk and mention the management of services along with the use of sidecars. I'm not sure what that is.</p>&#xA;
27865814,Does my concept follow a Microservice architecture?,2015-01-09 17:18:25,<php><magento><soa><single-page-application><microservices>,2,5151,0,3.0,5,"<p>I read <a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">the article on Microservices</a> on Martin Fowler's page and find it quite interesting. Now I plan structuring an E-Commerce Web Application as proof-of-concept and am wondering if my concept is considered being a Microservice architecture.</p>&#xA;&#xA;<p>The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li>a javascript based single page application, which sends AJAX requests to</li>&#xA;<li>a server with a REST API which feeds JSON data received by calling other services (I think you call this behaviour API Gateway)</li>&#xA;<li>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento (PHP) Shopsystem. In future I plan to then swap the providers with other systems.</p>&#xA;&#xA;<p>So my questions are:</p>&#xA;&#xA;<ul>&#xA;<li><p>MS are considered to be 'independently deployable'. I understand that in the world of JAVA we are talking about one JAR- or WAR-file, but how is a PHP service 'independently deployable'?</p></li>&#xA;<li><p>Does my concept NOT follow the principles of a MS architecture, because the providers are all part of one big (Magento) system?</p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading. I'm happy for any suggestions.</p>&#xA;"
32093067,Microservices styles and tradeoffs - Akka cluster vs Kubernetes vs,2015-08-19 10:35:06,<akka><microservices><fault-tolerance><akka-cluster><tradeoff>,1,1425,0,1.0,5,"<p>So, here's the thing. I really like the idea of microservices and want to set it up and test it before deciding if I want to use it in production. And then if I do want to use it I want to slowly chip away pieces of my old rails app and move logic to microservices. This I think I can do using HAProxy and set up different routing based on URLs. So this should be covered.</p>&#xA;&#xA;<p>Then my next biggest concern is that I don't want too much overhead to ensure everything is running smoothly on the infrastructure side. I want preferrably low configuration and the ease of development, testing and deployment.</p>&#xA;&#xA;<p>Now, I want to know what are the benefits and downsides of each styles. Akka (cluster) vs something like Kubernetes (maybe even fabric8 on top of it).</p>&#xA;&#xA;<p>What I also worry about is fault tolerance. I don't know how do you do that with Kubernetes. Do you then have to include some message queue to ensure your messages don't get lost? And then also have multiple queue if one of the queues goes down? Or just retry until queue comes up again? Akka actors already have that right? Retrying and mail boxes? What are the strategies for fault tolerance for microservices? Do they differ for each approach?</p>&#xA;&#xA;<p>Someone please enlighten me! ;)</p>&#xA;"
48900551,Why ESB is considered bad in microservices architecture,2018-02-21 07:45:26,<architecture><microservices><distributed-computing><soa><esb>,1,1068,5,2.0,5,"<p>In microservices architecture, autonomous business services should talk directly with each other. The communication may be synchronous (orchestration) or event-based (choreography). An API gateway may aggregate the API's for the client (backends for frontends). With microservices we are seeking two ultimate goals</p>&#xA;&#xA;<ul>&#xA;<li>Low coupling</li>&#xA;<li>High cohesion</li>&#xA;</ul>&#xA;&#xA;<p>Which grants continuous deployment, fine-grained scaling, rapid technology adaptation, reusability, auditability an much more, of course for the price of higher complexity.</p>&#xA;&#xA;<p>However, it is highly discouraged to use ESB (Enterprise Service Bus) or other middleware. Microservices and ESB is often seen as an rival solutions. Why is an ESB seen so bad? As long as it is just used as an meditation channel with some additional monitoring and authentication layers (no business logic), what's the problem of using it in the microservice architecture?</p>&#xA;"
29303048,HATEOAS and Microservices,2015-03-27 14:26:23,<rest><hateoas><microservices><hypermedia>,2,2172,6,0.0,5,"<p>I'm having some serious trouble seeing how HATEOAS and Microservices can co-exist.</p>&#xA;&#xA;<p>Let's take an example:</p>&#xA;&#xA;<p>Let's say we have a shopping cart resource.&#xA;And we need to put snapshots of products into it, e.g. product Id, product price; snapshot of current price when item was added to cart, and possibly some other values.&#xA;The actual use-case is not relevant, but just to get some idea on the problem at hand.</p>&#xA;&#xA;<p>When I have been doing HATEOAS earlier, I would have put a link in the shopping cart resource that links to products or a template url that links to a specific product.</p>&#xA;&#xA;<p>This way, the client can still be ignorant of resource URL's.</p>&#xA;&#xA;<p>But in the microservice world, a service should have no knowledge of other services. AFAIK.</p>&#xA;&#xA;<p>So how could they both work together?</p>&#xA;&#xA;<p>My interpretation of microservices is that they can never link to anything else than themselves, which would pretty much be a <code>Self</code> link.</p>&#xA;&#xA;<p>I've found the same question asked on ther places, e.g.&#xA;<a href=""https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc"" rel=""noreferrer"">https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc</a></p>&#xA;&#xA;<p>Where solutions like ""macro services"" that weave all this together is used.&#xA;Which doesn't seem like a clean way to solve things.</p>&#xA;&#xA;<p>[Edit]</p>&#xA;&#xA;<p>I've found some more nice info on the topic:&#xA;<a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">https://github.com/Netflix/eureka</a>&#xA;<a href=""https://github.com/RestExpress/HyperExpress"" rel=""noreferrer"">https://github.com/RestExpress/HyperExpress</a></p>&#xA;&#xA;<p>This seems nice to have some tool augument the resources with links, but this makes me think, where does the logic to decide what links a resource should have belongs?&#xA;In the service that exposes the resource?&#xA;In the central service registry?</p>&#xA;"
41433856,emailing in microservice architecture,2017-01-02 22:08:52,<rest><email><microservices><restful-architecture><email-integration>,1,1709,0,3.0,5,"<p>Sorry about my english - if some thing is not clear please ask me in comments - i will clarify this.</p>&#xA;&#xA;<p>I build system in microservice architecture. I have one service with user information, one service for ""offers"", and one service for ""ideas"". Services ""offers"" and ""ideas"" comunicate (by Restful API) with ""User"" service on login and other operations. And i wonder - how to deal with emails? Each service have it separate frontend and send emails after some actions (eg. when some third person open link with some offer the user who create this offer will get email, or when some user create idea the manager will get email). Moreover, on each service frontend, manager can create ""periodic"" mailing with season statistical data or just some other information. Each service email looks differently and have different content.</p>&#xA;&#xA;<p>I have many choices and don't know which will be better. This are some propositions:</p>&#xA;&#xA;<ol>&#xA;<li>Each service has his own separate emailing system and send all kinds&#xA;of email (after action, and periodic) independent. </li>&#xA;<li>The ""user service"" have ""engine"" to send action and periodic emails and other services give the task. Inside task there is link to service who give task and that link will generate email content (for example witch statistical data in periodic email). This solution is complicated...</li>&#xA;<li>The ""user service"" has only engine to periodic emails (tasks have link to generate email body...) but email after actions are send from each microservice indepenndent</li>&#xA;<li>Create new microservice only for sending email (periodic and ""after action"") with proper API. Ofcourse each service like ""offers"" should send also link (to themself) in mailing task - this link will be call when the periodic email will be send and the response of this link will be generated body of email....</li>&#xA;</ol>&#xA;&#xA;<p>Which one will be better? Or may be there is some better alternative? </p>&#xA;"
32529742,how to roll back a transaction happening between microservices?,2015-09-11 18:15:08,<java><spring><spring-mvc><spring-data><microservices>,4,2904,0,1.0,5,"<p>we have <code>microservice</code> architecture where for most part each <code>microservice</code> is independent. But for some legacy reasons, there is a situation where we have to call another <code>microservice</code> from within another.</p>&#xA;&#xA;<p>eg: the following method is part of <code>Legal Service</code></p>&#xA;&#xA;<pre><code>@Autowired&#xA;public ServiceManager UserServiceManager;&#xA;&#xA;public void updateUserLegalData(){&#xA;&#xA;    //do db update of Legal info for the user&#xA;&#xA;   userServiveManager.setAcceptedLegal(true);&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There are two <code>db transactions</code> going on above. one is updating legalService db and other is updating UserService db. please NOTE userService is a <code>microservice</code>running on a separate VM.</p>&#xA;&#xA;<p>we are seeing situations where legal Service db is updated but call to userService is failing (<code>Internal server error</code>). so this leaves the application in an inconsistent state. How can we fix this in a recommended way?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
34534079,How to sync the time of a java application running on docker container?,2015-12-30 17:19:17,<java><docker><spring-boot><dockerfile><microservices>,1,488,1,1.0,5,"<p>I am docker file like this:</p>&#xA;&#xA;<pre><code>FROM anapsix/alpine-java:jre8 &#xA;ADD service-god-sac-1.0.0-SNAPSHOT.jar app.jar &#xA;ENTRYPOINT [""java"", ""-Xmx64m"", ""-XX:MaxMetaspaceSize=64m"", ""-jar"", ""/app.jar""]&#xA;</code></pre>&#xA;&#xA;<p>When I compile and deploy the app settint the time using this:</p>&#xA;&#xA;<blockquote>&#xA;  <p>-v /etc/localtime:/etc/localtime:ro</p>&#xA;</blockquote>&#xA;&#xA;<p>I notice that the host time and containter time are syncronized, but the logs of the app shows a diferent time, the UTC time.&#xA;How can I sync the host machine, the container and the java app with the same time?</p>&#xA;"
34094882,"Storing submodules for micro services, but still using forks",2015-12-04 18:18:43,<git><docker><git-submodules><docker-compose><microservices>,3,869,0,2.0,5,"<p>I am stumped here.  A lot of this is already in place, its just the wrapping that I cannot figure out.</p>&#xA;&#xA;<p>We have a micro-service architecture, with many separate repositories.  We are using Docker, and Docker Compose for building and running the development environment, which works beautifully.</p>&#xA;&#xA;<p>The question I have, is how to package up the main collection of repositories.  So if I have a folder structure like:</p>&#xA;&#xA;<pre><code>\&#xA;    service1&#xA;        .git&#xA;        Dockerfile&#xA;    service2 &#xA;        .git&#xA;        Dockerfile&#xA;    service3&#xA;        .git&#xA;        Dockerfile&#xA;    docker-compose.yml&#xA;    README.md&#xA;</code></pre>&#xA;&#xA;<p>...Where service1, service2, service3 are each their own git repository.</p>&#xA;&#xA;<p>My first thought was to use git submodules, which <em>would</em> work, however we enforce policies to require developers to fork repositories instead of working off the main repository due to continuous integration constraints and code reviews.  I was not overly excited about using git submodules at all, even before I thought of this caveat, so an alternative solution would be much preferred.</p>&#xA;&#xA;<p>At the moment i can only think to write scripts to store a list of repositories; run a query for each to see if the logged-in developer has a fork of each, creating one if not, then pulling into the master folder; and then booting docker-compose.  This seems like a horrible solution though, enough so that I may just have to write docs to just tell devs how to manually do this process...</p>&#xA;&#xA;<p>Thoughts??</p>&#xA;&#xA;<p>Thanks for your time :)</p>&#xA;"
34295221,Microservices: decomposing a graph db based application,2015-12-15 17:05:38,<graph-databases><microservices>,1,583,0,0.0,5,"<p>I'm planning to decompose an application I started to build as a monolith with a graph database into microservices. But the dilema i'm facing is trying to find a proper solution to split the different services and not loosing the benefits provided by the graph database. </p>&#xA;&#xA;<p>The idea I've considered initially is to split each different entity into it's own microservice, using a document store to persist the data on each service. And then define a higher level service to manage the relationships. </p>&#xA;&#xA;<p>For example with a relationship (A)-->(B), would produce 3 microservices, a service for entities of type A, another for the entities of type B, and a third higher level with a graph database, storing nodes of type A and B, containing only the ID's and the relationships between those. </p>&#xA;&#xA;<p><strong>Question 1</strong>: Is there anything wrong with this approach in terms of coupling, fault tolerance, or anything else that I can't think of right now?</p>&#xA;&#xA;<p><strong>Question 2</strong>: When you toss a third entity into the game, for example (A)-->(B), (A)-->(C) and (C)-->(B), which one would be the best approach in this scenario? </p>&#xA;&#xA;<ul>&#xA;<li>Do I stick to the strategy of just one higher level service to maintain all the relationships? </li>&#xA;<li>Do I generate several higher level services to maintain each type of relationship?</li>&#xA;</ul>&#xA;&#xA;<p><strong>Question 3</strong>: In the case of relationships between entities of the same type, for example (Person)--isFriendOf-->(Person), having in mind the concept of separation of concerns, is it appropiate to separate the management of the relationships into a different service?</p>&#xA;&#xA;<p>Any input, feedback and ideas are very welcome.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I've been doing some research on the subject, and for the sake of clarity, I'll propose a more concrete scenario, so it will be easier to discuss about it. &#xA;The graph model would be something like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/87MOt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/87MOt.png"" alt=""Graph relationships""></a></p>&#xA;&#xA;<p>The goal here would be to implement a song playlist recommendation service, trying to find the songs that a given user haven't listened yet, based on genres and artists from the songs that the user already listened, and also from other songs listened by other users, followed by the current user.</p>&#xA;"
39485459,Microservice Versioning,2016-09-14 08:07:28,<architecture><versioning><soa><microservices>,4,834,0,1.0,5,"<p>What is the best practice to adapt for versioning in a Microservice Based Architecture, in terms of supporting multiple versioned deployment of the same service during runtime and how the consumers would be able to use different versions?&#xA;1) If we use Routing based Versioning as one of the approaches mentioned <a href=""http://niels.nu/blog/2016/microservice-versioning.html"" rel=""nofollow noreferrer"">here</a>&#xA;then I guess we would have the following drawbacks </p>&#xA;&#xA;<ol>&#xA;<li>Internal Services have to go through Reverse Proxy for consumption.</li>&#xA;<li>Consumers always have to be aware of the required versioning.</li>&#xA;</ol>&#xA;&#xA;<p>Is it a best practice to expose the version information to consumers?  </p>&#xA;&#xA;<p>In any case, as I feel, the following always applies:</p>&#xA;&#xA;<ol>&#xA;<li>For MAJOR version change, the consumers have to be changed.</li>&#xA;<li>For MINOR version change (backwards compatible), only the consumer(s) that requires the added functionality needs to change.</li>&#xA;<li>For PATCH version change, it's optional and would probably be seamless for any consumers to make use of it.</li>&#xA;</ol>&#xA;&#xA;<p>What kind of Microservice versioning strategy can help us in enabling the above?</p>&#xA;&#xA;<p>NOTE - Please feel free to let me know if this needs to be split in multiple questions.</p>&#xA;"
39450504,Serverless Framework - Two services under one APIGW endpoint,2016-09-12 12:37:05,<microservices><amazon-cloudformation><aws-api-gateway><serverless-framework>,5,628,0,1.0,5,"<p>If I have two services, 'Users' and 'Products', each with several functions with endpoints defined for each one (as any traditional API would), is it possible for them to be organised separately in a code base (for clarity) but once deployed share the same API base URL? For example, consider I have the following structure:</p>&#xA;&#xA;<pre><code>/src&#xA;-- /users&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;-- /products&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/users/serverless.yml</code> has the following defined:</p>&#xA;&#xA;<pre><code>functions:&#xA;  create:&#xA;    handler: handler.create&#xA;    events:&#xA;      - http: POST user&#xA;&#xA;  read:&#xA;    handler: handler.read&#xA;    events:&#xA;      - http: GET user&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/products/serverless.yml</code> has basically the same thing, just swap 'user' for 'products'.</p>&#xA;&#xA;<p>Currently, both of those services will be deployed to distinctly different API endpoints, one with a URL <code>https://fghijklmnop.execute-api...</code> and another with a URL <code>https://abcdevwxyz.execute-api....</code> </p>&#xA;&#xA;<p>My question is, would it be possible to have these services be deployed but remain under a single API with a single URL (so both would be served under URL <code>https://abcdevwxyz.execute-api....</code>)?</p>&#xA;&#xA;<p>I'm assuming the answer to be, 'No, because Cloud Formation...', but I thought I would post the question here simply for the sake of discussion and to aid my own understanding of building serverless applications.</p>&#xA;&#xA;<p>I'm aware of using Custom Domains, as per <a href=""https://stackoverflow.com/questions/38408493/serverless-framework-v1-multiple-resources-in-one-service"">the answer here</a>, but for a quicker development cycle this is not really an ideal solution.</p>&#xA;&#xA;<p>My only solution so far would be to simply create a service called 'api' which would contain all the endpoints my API would need which would simply invoke my other services' Lambda functions directly rather than via previously-configured endpoints. It would be an abstraction layer, really, but add potentially unnecessary layers to my application. Again, curious to see what the community feels on this.</p>&#xA;"
39913816,Zero Downtime Deployment for Micro Service architecture,2016-10-07 09:22:58,<java><database><docker><spring-boot><microservices>,1,911,4,0.0,5,"<p>At the moment I'm working on an application which will be based on the <strong>Micro Service architecture</strong>. As main technologies we planned to use <strong>Spring Boot and Docker</strong> for each Micro Service development. One of the goals is to provide Zero Downtime Deployment feature for the users. </p>&#xA;&#xA;<p>I spent some time trying to found some solution and know about <code>Blue Green Deployment (BGD)</code> but some aspects is still not clear for me. The main problem is DataBase state and version compatibility. </p>&#xA;&#xA;<blockquote>&#xA;  <p>For example if <code>BGD</code> is used how to migrate all the data changes from&#xA;  Green to Blue contour after successful deployment?</p>&#xA;</blockquote>&#xA;&#xA;<p>I found interesting approach in Spring's <a href=""https://spring.io/blog/2016/05/31/zero-downtime-deployment-with-a-database"" rel=""nofollow"">Zero Downtime Deployment with a Database</a> article, but I think that such approach has too complicated Application Versions and Releases Planing process and backward compatibility requirements.</p>&#xA;&#xA;<p>So my I want to ask following questions:</p>&#xA;&#xA;<ol>&#xA;<li>Any suggestions on the Zero Downtime Deployment process concept, backed by real  experience using  it?</li>&#xA;<li>Is there any Out Of The box solutions (Paid or Free)  that provide Zero Downtime Deployment feature for applications with Relational Data Base?</li>&#xA;</ol>&#xA;&#xA;<p><strong>PS</strong></p>&#xA;&#xA;<p><em>It is interesting how Zero Downtime Deployment works in StackOverflow.com if it is?</em></p>&#xA;"
29830038,Logging in microservices,2015-04-23 17:04:04,<logging><tracing><microservices>,3,1836,0,5.0,5,"<p>assume we've got a number of Web API microservices, and they are written in different languages/framworks (some are ASP.NET Web API, some are NodeJS, some are Flask etc.).</p>&#xA;&#xA;<p>I would like to log every request made to any service, and I would prefer a centralized log.</p>&#xA;&#xA;<p>What method/tools should I use?</p>&#xA;&#xA;<p>Regards,&#xA;DanÃ­el</p>&#xA;"
29636094,Microservices communication,2015-04-14 19:45:33,<java><node.js><apache-zookeeper><microservices>,2,2362,1,3.0,5,"<p>I'm actually studying microservices and I'm facing a problem.</p>&#xA;&#xA;<p><strong>Context</strong></p>&#xA;&#xA;<p>I m developing two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User management, Spring Based, with MySQL database</li>&#xA;<li>Planning management, ASP.NET based with SQL Server database. The only access point of this service is an API listing some RESTFUL endpoints like <code>/planning/{day}/{userId} or /planning/{startDate}/{endDate}/{idUser}</code></li>&#xA;<li>Billing management, Node.Js based with MongoDB.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>What can I do to only permit accessing the planning information through the user service without couple the two services ? Knowing that the planning service could be accessed later from somewhere else, but not now.</p></li>&#xA;<li><p>How can I do to access billing information from billing service corresponding to a user from the MySQL database? I know that microservices are not coupled, and this point is killing me, cause it has to be coupled in a way no? Like referencing <code>idUser</code> in a billing? Else, how can I know which billing from my API should I expose? More precisely, how do microservices communicate between them, without to be coupled?</p></li>&#xA;<li><p>How to create authentication without duplicating authentication requests to the authentication service, from other services?</p></li>&#xA;</ol>&#xA;"
44355294,How to offer multiple versions of an API with different database schemas?,2017-06-04 14:44:09,<database><versioning><microservices>,1,387,2,2.0,5,"<p>In Kevin Goldsmith's 2015 talk about <a href=""https://youtu.be/7LGPeBgNFuU?t=925"" rel=""noreferrer"">microservices at Spotify</a> (from 15:25 - 17:43), he mentions that when they create a new version of an API they just create a new server, and keep the old server running with the old version for as long as there are still clients calling it (in this case, a smart lamp with Spotify embedded on it).</p>&#xA;&#xA;<p>I am confused about how they would be able to maintain and offer older versions for potentially years, when surely there would be database schema changes during that timeframe?</p>&#xA;&#xA;<p>I can see a few possible solutions, but none of them seem very reasonable:</p>&#xA;&#xA;<ol>&#xA;<li>Using the same database across all versions, only ever add new tables, and new nullable fields. Never delete fields, nor rename fields, nor set fields to non-nullable, nor delete tables, nor rename tables.</li>&#xA;<li>Using a different database per version, keep each version's data separate.</li>&#xA;<li>Using a different database per version, keep each version's data separate, but write a way to migrate and pass the requests from one version to another, so that each version receives the request with the valid parameters for that version.</li>&#xA;</ol>&#xA;&#xA;<p>Solution 1 sounds like it would induce way too much code smell, with legacy code everywhere (which Kevin, in my opinion, seems to suggest they certainly do not do).</p>&#xA;&#xA;<p>Solution 2 sounds like a nightmare to pull data out of for other services, or for reporting. What if the information about an entity that you want is in another version's database than the one you request?</p>&#xA;&#xA;<p>Solution 3 sounds like more of a nightmare as you would have to write code to migrate a request for your version, to the versions above and below yours. This would mean that you can't just leave the existing (the one currently in production) version as-is when creating a new version, as you would need to add migrations to move the request both forward and backward so that all versions received the correct parameters for the request.</p>&#xA;&#xA;<p>Hopefully I am just missing something simple here, and there is a magic solution to make this problem easier, but I really cannot see how they could accomplish this?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
46453981,How an authorization service implements ownership checks in a role-based microservice architecture,2017-09-27 17:34:28,<design><architecture><authorization><microservices><soa>,2,162,0,2.0,5,"<p>Let's say I have three types of users on a blogging app</p>&#xA;&#xA;<ol>&#xA;<li><strong>Author</strong> (is able to modify their own posts but not others)</li>&#xA;<li><strong>Administrator</strong> (is able to modify all posts)</li>&#xA;<li><strong>Reader</strong> (can not modify any posts)</li>&#xA;</ol>&#xA;&#xA;<p>To manage this system I want to have three main services: </p>&#xA;&#xA;<ul>&#xA;<li>An <strong>API Gateway</strong> that exposes all the APIs clients will consume, composing services as needed. </li>&#xA;<li>A <strong>Post Management Service</strong> which provides the CRUD operations for blog posts (including the data of who owns what posts)</li>&#xA;<li>An <strong>Authorization Service</strong> which stores roles and permissions, exposing an API which takes in an array of roles (the roles a requesting user has) and an array of permissions (the permissions needed to access an API) and determines if those inputted roles cover all the permissions inputted. </li>&#xA;</ul>&#xA;&#xA;<p>Now what I am struggling with is ownership of a resource (and where ownership should be checked).</p>&#xA;&#xA;<p>Without communicating with other services how would an authorization service determine if a user should be able to access something they own without knowing how to determine if a user owns a given resource. </p>&#xA;&#xA;<p>I've come up with a few different solutions to this problem, although I'm not quite happy with any of them. </p>&#xA;&#xA;<ol>&#xA;<li>The API Gateway would query a different service that manages the posts to determine if a requesting user owns the post they are trying to access, this would mean there is authorization logic that happens outside of the authorization service.</li>&#xA;<li>The service managing blog posts would handle authorization based on ownership, this would also mean authorization logic is happening outside the authorization service as well as the fact that unauthorized requests are being marked as authorized initially (since they will still pass through the authorization service)</li>&#xA;<li>The Authorization service could be given the knowledge of how to check ownership, the API would have to be able to be told whether or not it should check for ownership along with the permissions. This would add complexity to the authorization service and increase the cross-service communication which I'd like to relegate as much as possible to the API gateway since it should be the primary service composer. </li>&#xA;</ol>&#xA;&#xA;<p>Looking for ideas on alternative methods or insight into what the best solution to this problem might be.</p>&#xA;"
46311488,Confused about ESBs as a solution to point-to-point integration,2017-09-20 00:20:34,<architecture><microservices><esb>,4,675,0,0.0,5,"<p>Still very new to studying application architecture and having trouble stomaching some ideas in a book about microservices. In my readings, I have come across the older idea of the ESBs(Enterprise Service Bus) and its role in coordinating messages between new services and legacy applications. ESBs are touted as a solution to problems poised by point-to-point integration. Microservices seem to be the approach taken by newer companies as the de facto standard to creating an agile, scalable, and resilient app. But aren't microservices using point-to-point integration? Each node in an application built from microservices is communicating directly with other nodes, right? I feel I am connecting some dots that shouldn't be connected. Any help much appreciated, thanks in advance.</p>&#xA;"
36627628,setting up Elasticsearch server for processing data from microservices,2016-04-14 15:29:55,<ruby-on-rails><elasticsearch><architecture><microservices>,1,880,0,3.0,5,"<p>I am very new to elasticsearch and its scaling, and I've got a question I don't even know how to approach. </p>&#xA;&#xA;<p>Here's the situation:</p>&#xA;&#xA;<p>There're several servers with Rails microservice applications. Each of them is getting each its own pretty big piece of data (more specifically, aggregating posts from different social networks - so the indexable search fields are the same in all databases).</p>&#xA;&#xA;<p>I need to find a solution that would allow to keep the data where it currently is and setting up an elasticsearch server dedicated exclusively to searching through multiple databases without the respective Rails apps turning on this search server. It potentially means setting up ES on each of the other servers, defining the search patterns there but making the multiple-model search on a totally different server.</p>&#xA;&#xA;<p>The final goal of these manipulations should be sending the entire ActiveRecord objects / or all the related attributes to the main application.</p>&#xA;&#xA;<p>Is it even possible to achieve? Maybe anyone has had a similar problem? </p>&#xA;&#xA;<p>I am a little lost about how to get started with it.</p>&#xA;"
36680157,Communication between REST Microservices: Latency,2016-04-17 17:59:56,<http><connection-pooling><microservices><http2>,3,2688,2,2.0,5,"<p>The problem I'm trying to solve is latency between Microservice communication on the backend. Scenario. Client makes a request to service A, which then calls service B that calls service C before returning a response to B which goes to A and back to the client.</p>&#xA;&#xA;<pre><code>Request: Client -&gt; A -&gt; B -&gt; C&#xA;Response: C -&gt; B -&gt; A -&gt; Client&#xA;</code></pre>&#xA;&#xA;<p>The microservices expose a REST interface that is accessed using HTTP. Where each new HTTP connection between services to submit requests is an additional overhead. I'm looking for ways to reduce this overhead without bringing in another transport mechanism into the mix (i.e. stick to HTTP and REST as much as possible). Some answers suggest using <a href=""https://stackoverflow.com/questions/35673254/communication-between-microservices"">Apache Thrift</a> but I'd like to avoid that. Other possible solutions are using Messaging Queues which I'd also like to avoid. (To keep operational complexity down).</p>&#xA;&#xA;<p>Has anyone experience in microservices communication using HTTP Connection pooling or HTTP/2? The system is deployed on AWS where service groups are fronted by a ELB. </p>&#xA;"
36792713,Dynamic component loading from external content,2016-04-22 11:31:26,<angular><distributed><microservices><angular2-template>,3,1136,4,0.0,5,"<p>The system I am working on consists of a number of distributed microservices with potentially multiple versions of each component active at the same time.</p>&#xA;&#xA;<p>The Angular2 app I am attempting to build shall be able to interact with each of these components by means of websockets. Because it seems unfeasible to prepare this application for all future versions and features of each component, the respective protocol implementation and even new components, I would like to push this responsibility to the components itself. </p>&#xA;&#xA;<p>Each component is able to communicate its capabilities (in the form of a NG2 component) as well as the protocol implementation and the necessary GUI elements (HTML/CSS) via a package sent over the very same websocket connection.</p>&#xA;&#xA;<p>Is there a pattern that enables this kind of 'on-demand-loading' of components and their templates in ng2?</p>&#xA;"
38186942,Correlation Token for Service Fabric Actors and Services,2016-07-04 14:20:13,<logging><token><actor><microservices><azure-service-fabric>,1,292,0,1.0,5,"<p>We started playing with Service Fabric as a microservice platform and after having succesfully implemented our firsts ""hello world"" samples about actor pattern, stateless/stateful services, web api (and so on) we are moving to looking solutions for other core aspects like auth/autz and application logging.</p>&#xA;&#xA;<p>I have a doubt about the Logging; in all the SOA we have designed till now we always added a ""correlation token"" to all the services involved (often at architectural level, automatically added as header onto WCF, hidden to the developers) so, now we are trying to do the same with Service Fabric.</p>&#xA;&#xA;<p>Looking for the best solution to let flow a ""Correlation Token"" through all the actor/service calls, since we haven't found out anything ready out-of-the-box, we are wondering if we are looking for something theoretically wrong.</p>&#xA;&#xA;<p>Any suggestion out there?</p>&#xA;"
36197572,How to improve communication between microservices,2016-03-24 10:07:12,<java><rest><spring-boot><microservices>,3,2704,0,0.0,5,"<p>In our company we use spring boot, microservices, spring cloud and so on... We are happy with this infrastructure, but I still have some concerns:&#xA;we use rest as comunication protocoll and even if a I find it great, I still think that we could find something better. With rest:</p>&#xA;&#xA;<ul>&#xA;<li>you need to use a client and a server (restcontroller)</li>&#xA;<li>you need to know the server <code>URI</code>, the http method (<code>POST, GET, PUT,...</code>)</li>&#xA;<li>you need know where params go (body, querystring)</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>Don't you think It would be much easier if we had something like RMI? I know it's a quite old technology(and it's not language independent), but it made life easier (you just need an interface and its implementation).</p>&#xA;&#xA;<p>Searching around, I found some interesting projects like feign clients or spring cloud stream, but none of them seem to be the silver bullet. </p>&#xA;&#xA;<p>What do you think about this topic? Is that a problem that you feel? If so, how do you approach it? </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
36144330,Scaling microservices using Docker,2016-03-22 00:49:13,<node.js><meteor><amazon-ec2><docker><microservices>,2,389,2,1.0,5,"<p>I've created a Node.js (Meteor) application and I'm looking at strategies to handle scaling in the future. I've designed my application as a set of microservices, and I'm now considering implementing this in production.</p>&#xA;&#xA;<p>What I'd like to do however is have many microservices running on one server instance to maximise resource usage whilst they are using a small number of resources. I know containers are useful for this, but I'm curious if there's a way to create a dynamically scaling set of containers where I can:</p>&#xA;&#xA;<ul>&#xA;<li>Write commands such as ""provision another app container on this server if the containers running this app reach > 80% CPU/other limiting metrics"",</li>&#xA;<li>Provision and prepare other servers if needed for extra containers,</li>&#xA;<li>Load balance connections between these containers (and does this affect server load balancing, e.g., send less connections to servers with fewer containers?)</li>&#xA;</ul>&#xA;&#xA;<p>I've looked into AWS EC2, Docker Compose and nginx, but I'm uncertain if I'm going in the right direction.</p>&#xA;"
39154613,Netflix Ribbon and Hystrix Timeout,2016-08-25 20:57:31,<spring-boot><spring-cloud><microservices><hystrix><netflix-ribbon>,1,3615,2,1.0,5,"<p>We are using Spring cloud in our project. We have several micro services and each has its own .yml file.</p>&#xA;&#xA;<p>Below properies are only in zuul server</p>&#xA;&#xA;<pre><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000&#xA;&#xA;    ribbon: &#xA;     ConnectTimeout: 3000&#xA;     ReadTimeout: 60000&#xA;</code></pre>&#xA;&#xA;<p><strong>Test 1:</strong></p>&#xA;&#xA;<p><strong>Accounts Service:</strong></p>&#xA;&#xA;<p>This service is what I'm calling to test the timeout and I'm calling the request through zuul i.e., using the port 8006.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>The above service internally calls the below one using Spring RestTemplate.&#xA;I started testing by adding a sleep time of 5000ms like below in <strong>Association Service</strong> and made a request to <strong>Accounts Service</strong> (getAccounts call).</p>&#xA;&#xA;<p><strong>Association Service:</strong></p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/internal/userassociationstatus"", produces = ""application/json; charset=utf-8"", consumes = ""application/json"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public UserAssociationStatusVO getUserAssociationStatus(@RequestParam final Map&lt;String, String&gt; allRequestParams) {&#xA;        try {&#xA;            Thread.sleep(5000);&#xA;        } catch (InterruptedException e) {&#xA;            // TODO Auto-generated catch block&#xA;            e.printStackTrace();&#xA;        }&#xA;        return iUserAssociationsService.getUserAssociationStatus(allRequestParams);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Association Service</strong></p>&#xA;&#xA;<pre><code>org.apache.catalina.connector.ClientAbortException: java.io.IOException: An established connection was aborted by the software in your host machine&#xA;at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:393) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.tomcat.util.buf.ByteChunk.flushBuffer(ByteChunk.java:426) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:342) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Accounts Service</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://USERASSOCIATIONS-V1/user/v1/internal/userassociationstatus?cardholderid=123&amp;usercontextid=222&amp;role=ACCOUNT"": com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out; nested exception is java.io.IOException: com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;</code></pre>&#xA;&#xA;<p>If I keep the sleep time as 4500 it gives me response, but if is >=4800 it throws the above exception. I'm thinking this is not related to Ribbon Timeouts but something else. Any specific reason for the above exception after certain point. </p>&#xA;&#xA;<p><strong>Test 2</strong></p>&#xA;&#xA;<p>Then I tried keeping a sleep time of 75000 ms in <strong>Accounts Service</strong> directly and removed sleep time <strong>Association Service</strong>.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        try {&#xA;            Thread.sleep(75000);&#xA;        } catch (InterruptedException ex) {&#xA;            // TODO Auto-generated catch block&#xA;            ex.printStackTrace();&#xA;        }&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>In this case I got   ""exception"": ""com.netflix.zuul.exception.ZuulException"",</p>&#xA;&#xA;<p>And in my APIGateway(Zuul application) log I see the below error.</p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:134) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:76) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:112) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;    at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:197) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: useraccounts-v1RibbonCommand timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;</code></pre>&#xA;&#xA;<p>I think this has nothing to do with Ribbon ConnectTimeout or ReadTimeout. This error is because of the property <strong>""execution.isolation.thread.timeoutInMilliseconds: 60000""</strong>. I have also reduced this property to 10000 ms to test the behavior and got the same exception if the sleep time is more(ex: 12000).</p>&#xA;&#xA;<p><strong>I want to understand Ribbon ConnectTimeout and Read-timeout vs Hystrix timeout and how to test ribbon timeouts in my application. Also if I want different timeouts for different microservices, Do I keep these properties in respective .yml files?.</strong> Any thoughts?</p>&#xA;&#xA;<p>I'm trying to create a document to be used by my team so that it is easy for a developer to know how these timeout options work in Spring cloud.</p>&#xA;&#xA;<p>(It's a lengthy description but to make it clearer I had to write in detail)</p>&#xA;"
37148836,"What is service discovery, and why do you need it?",2016-05-10 20:56:48,<web-services><configuration><architecture><microservices>,1,1765,2,4.0,5,"<p>As far as I can tell, ""service discovery"" means a way for a client to find out about a server (or cluster of servers) that it wants to connect to.</p>&#xA;&#xA;<p>I've built web applications that communicate with other back-end processes using protocols like HTTP and AMQP. In those, each client has a config file that contains a host name or whatever information it needs to connect to the server, which gets set at deployment time using a configuration tool like Ansible. That's simple and seems to work pretty well.</p>&#xA;&#xA;<p>Is service discovery an alternative to just putting server information in a client's config file? If so, why is it better? If not, what problem does it solve?</p>&#xA;"
44085454,Join table between Different Microservices,2017-05-20 11:41:21,<architecture><microservices>,3,2111,0,1.0,5,"<p>I am still trying to make sense of micro service architecture.</p>&#xA;&#xA;<p>The idea to separate different application (include the database) excites me. But I am still confused if there are two micro-services e.g. Product and User. both product and user own table product and user respectively in their database. According to best practice in micro service, we only can access the database from the service. </p>&#xA;&#xA;<p>The problem is, let us suppose we have product table that has user_id column. We want to do search product which also return the name of the user who create the product. This requires join between product table in product micro-service and user table in user micro-service. How do you handle this? </p>&#xA;"
44065186,How to implement distributed transaction with hystrix fallback based on Spring Cloud architect,2017-05-19 08:35:52,<spring-cloud><microservices><distributed-transactions><hystrix><spring-cloud-netflix>,1,1134,1,4.0,5,"<p>I am using spring cloud to implement my micro services system, a ticket sale platform. The scenario is, there is a zuul proxy, a eureka registry, and 3 service: user service, order service and ticket service. Services use feign declarative REST Client to communicate with each other.</p>&#xA;&#xA;<p>Now there is a function to buy tickets, the main process is as below:<br>&#xA;  1. order service accept request to create order<br>&#xA;  2. order service create Order entity with Pending status.<br>&#xA;  3. order service call user service to process user pay.<br>&#xA;  4. order service call ticket service to update user tickets.<br>&#xA;  5. order service update the order entity as FINISHED.</p>&#xA;&#xA;<p>And I want to use <code>Hystrix Fallback</code> to implement transaction. For example, if the payment process is finished, but some error happened during ticket movement. How to revet user payment, and order status. Because user payment is in other service.</p>&#xA;&#xA;<p>The following is my current solution, I am not sure whether it is proper. Or is there any other better way to do that.</p>&#xA;&#xA;<p>At first, the OrderResource:</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/api/order"")&#xA;public class OrderResource {&#xA;&#xA;  @HystrixCommand(fallbackMethod = ""createFallback"")&#xA;  @PostMapping(value = ""/"")&#xA;  public Order create(@RequestBody Order order) {&#xA;    return orderService.create(order);&#xA;  }&#xA;&#xA;  private Order createFallback(Order order) {&#xA;    return orderService.createFallback(order);&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then the OrderService:</p>&#xA;&#xA;<pre><code>@Service&#xA;public class OrderService {&#xA;&#xA;    @Transactional&#xA;    public Order create(Order order) {&#xA;        order.setStatus(""PENDING"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        userCompositeService.payForOrder(payDTO);&#xA;&#xA;        order.setStatus(""PAID"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        ticketCompositeService.moveTickets(ticketIds, currentUserId);&#xA;&#xA;        order.setStatus(""FINISHED"");&#xA;        order = orderRepository.save(order);&#xA;        return order;&#xA;    }&#xA;&#xA;    @Transactional&#xA;    public Order createFallback(Order order) {&#xA;        // order is the object processed in create(), there is Transaction in create(), so saving order will be rollback,&#xA;        // but the order instance still exist.&#xA;        if (order.getId() == null) { // order not saved even.&#xA;            return null;&#xA;        }&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        try {&#xA;            if (order.getStatus() == ""FINISHED"") { // order finished, must be paid and ticket moved&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PAID"") { // is paid, but not sure whether has error during ticket movement.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PENDING"") { // maybe have error during payment.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;            }&#xA;        } catch (Exception e) {&#xA;            LOG.error(e.getMessage(), e);&#xA;        }&#xA;&#xA;        order.setStatus(""FAILED"");&#xA;        orderRepository.save(order); // order saving is rollbacked during create(), I save it here to trace the failed orders.&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Some key points here are:</p>&#xA;&#xA;<ol>&#xA;<li>Using <code>@HystrixCommand</code> in <code>OrderResource.create(order)</code> method, with <code>fallback</code> function.   </li>&#xA;<li>If there is some error in creation, the <code>order</code> instance used in  <code>OrderResource.create(order)</code> will be used again in fallback function. Although the persistence of this <code>order</code> will be roll-backed. But the data in this instance still can be used to check the running.   </li>&#xA;<li>So I use a status: 'PENDING', 'PAID', 'FINISHED' to check whether some service call is made.   </li>&#xA;<li><code>ticketCompositeService</code> and <code>userCompositeService</code> is a feign client. For feign client method <code>payForOrder()</code>, there is another method <code>payForOrderFallback()</code> for fallback.   </li>&#xA;<li>I need to make sure the fallback methods can be called multiple times.   </li>&#xA;<li>I add <code>try/catch</code> for <code>ticketCompositeService</code> and <code>userCompositeService</code> call, to make sure the order will be save anyway with 'FAILED' status.</li>&#xA;</ol>&#xA;&#xA;<p>It seems that this solution can work at the most of the time. Except that, in fallback function, if there is some error in <code>userCompositeService.payForOrderFallback(payDTO);</code>, then the following composite service call will not be called.</p>&#xA;&#xA;<p>And, another problem is, I think it is too complicated.</p>&#xA;&#xA;<p>So, for this scenario, how should I implement dist transaction properly and effectively. Any suggestion or advice will help. Thanks.</p>&#xA;"
47050984,Enabling session in lumen framework,2017-11-01 08:39:14,<laravel><microservices><lumen>,3,2894,12,1.0,5,"<p>I have two (but let's image more) micro-services (API) which need to be aware of authenticated user. Ideally I would simple like to resume their sessions.</p>&#xA;&#xA;<p>All micro-services are using same storage for sessions: redis.</p>&#xA;&#xA;<p>All API calls will have Cookie header, so all services will be able to resume sessions based on that cookie. I have successfully implemented this via PHP $_SESSIONs.</p>&#xA;&#xA;<p>Now the question: how would you go about implementing this with Laravel/Lumen?</p>&#xA;"
46742274,About the Mediator in Event-Driven Topology,2017-10-14 08:00:14,<events><microservices><event-driven><orchestration><event-driven-design>,2,278,0,2.0,5,"<p>I was reading this article called <a href=""http://radar.oreilly.com/2015/02/variations-in-event-driven-architecture.html"" rel=""nofollow noreferrer"">Variations in event-driven architecture</a> in which they demonstrate both the mediator and broker topologies.</p>&#xA;&#xA;<p>According to the article the mediator topology looks somewhat like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QTwOw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QTwOw.jpg"" alt=""Mediator Topology""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>The event flow starts with the client sending an event to an <em>event queue</em>, which is used to transport the event to the mediator. The <em>event mediator</em> receives the initial event and orchestrates that event by sending additional asynchronous events to <em>event channels</em> to execute each step of the process. <em>Event processors</em>, which listen on the event channels, receive the event from the even mediator and execute specific business logic to process the event [...] It is important to note that the event mediator doesn't actually perform the business logic necessary to process the initial event, rather, it knows of the steps required to process the event [...] The event channels can be either message queues o message topics.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, I was studying this diagram, trying to understand how the mediator could determine when a given processor has finished processing a given event, such that it could orchestrate the next step of the process.</p>&#xA;&#xA;<p>The article is not clear enough when it says</p>&#xA;&#xA;<blockquote>&#xA;  <p>For each initial event step, the event mediator creates a processing event, sends that processing event and <em>waits</em> for the processing event to be processed by the corresponding event processor. This process continues until all of the steps in the initial event have been processed.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now, the article is clear in that the communication is asynchronous, and event messages will travel through message queues, but the diagram does not show <em>any events coming out of the event processor and back to the mediator</em>.</p>&#xA;&#xA;<p>The article says the mediator waits for the event processor to finish, but it is not clear how this is supposed to happen in architectural terms.</p>&#xA;&#xA;<p>Is it asynchronous, queue-based RPC (e.g. <a href=""https://www.rabbitmq.com/tutorials/tutorial-six-python.html"" rel=""nofollow noreferrer"">Rabbit RPC</a>), or is there another listener waiting for an asynchronous response somewhere?</p>&#xA;&#xA;<p>Any thoughts on how this can be implemented from an architectural standpoint?</p>&#xA;"
33881958,Spring Oauth2 client credentials flow example,2015-11-23 22:29:42,<java><spring-security><oauth-2.0><spring-security-oauth2><microservices>,1,1125,1,0.0,5,"<p>I am trying to implement service to service security into spring boot services using spring oauth2. I want a service to access a secured resource of another service without any user action involved.</p>&#xA;&#xA;<p>There are a lot of examples for authorization code grant type, but not very much about the client credentials grant type, which seems to be the right one for this use case.</p>&#xA;&#xA;<p>I can set up the auth server and use a curl request to get a token.&#xA;The tests I found used Http Objects to check status codes.</p>&#xA;&#xA;<p>How can I use the client credentials grant type in a java client with RestTemplate and spring oauth2?</p>&#xA;&#xA;<p>I would think it must be as simple as adding a dependency, an annotation and a config file, yet I can't make it run.</p>&#xA;"
31046924,Building authentication with Microservices Architecture,2015-06-25 09:52:50,<microservices>,3,3023,0,4.0,5,<p>I'm developing an app with microservices and I don't know how to distribute microservices to allow auth.</p>&#xA;&#xA;<p>I've read that each microservice should have its own database to avoid coupling.</p>&#xA;&#xA;<p>The problem is that Authentication (via JWT) and Users Microservices must have access to the same database and table (Users). I suppose this problem has been solved before due to similar applications having to deal with the same issue.</p>&#xA;&#xA;<p>How can I solve this?</p>&#xA;
31097306,Spring Boot + Tomcat - Microservices solution,2015-06-28 07:44:28,<spring-boot><microservices>,2,4706,4,1.0,5,<p>I'm planning to expose few microservices (~20 at this stage) using Spring Boot. I will be creating executable fat jars using the embededed Tomcat. The executable jar will be wrapped in Docker container and deployed to AWS. </p>&#xA;&#xA;<p>In my case 20 jars will have 20 tomcat instances running at the same time. I'm concerned about the overhead of running so many tomcat instances in the production server. Is this a valid concern?</p>&#xA;&#xA;<p>I was wondering if someone has used something similar configuration in production and can share their experience.</p>&#xA;&#xA;<p>Any suggestions will be appreciated.</p>&#xA;&#xA;<p>Thanks&#xA;JP</p>&#xA;
46236744,Swagger for Event?,2017-09-15 09:53:26,<events><swagger><microservices><event-driven>,4,327,1,0.0,5,"<p>The <a href=""https://github.com/OAI/OpenAPI-Specification"" rel=""nofollow noreferrer"">Swagger / OpenAPI specification</a> is useful to document and run automated tests against HTTP APIs. However, I run an event-driven microservices architecture and it is important to document the event payload passed among different services, even when they are not accessed via HTTP paths. Since eerything I've seen is API-based via HTTP paths, I'm wondering if Swagger handle this or, if not, is there anything similar for events?</p>&#xA;"
46244677,Verifying Access Token (JWT) in Each Service of a Microservices Architecture,2017-09-15 17:16:46,<rest><authentication><architecture><cloud><microservices>,2,422,1,0.0,5,"<p>I have an application which is implemented using microservice architecture. There is an authentication service (A) which uses jwt standard, and there are other services in the application like S1, S2, S3 and so on.&#xA;Now for example S1 receives a request, it should validate the token to see if the user is authorized or not. The validation can be achieved by:</p>&#xA;&#xA;<ul>&#xA;<li>Sending the token from S1 to A, then A validates the token and sends the result to S1 (which is a kind of overhead)</li>&#xA;<li>Validating the token inside S1 (which is a duplicate action inside every service, also requires secret key or public/private keys inside each service,  for signing/verification)</li>&#xA;</ul>&#xA;&#xA;<p>I'm not asking about how these approaches work exactly. The questions is, which one of them is better? Or what is the best practice in this situation?</p>&#xA;"
41814001,Heroku load balancer vs Netflix zuul,2017-01-23 19:20:54,<heroku><docker><microservices><netflix-zuul><netflix-eureka>,1,514,0,1.0,5,"<p>According to this answer <a href=""https://stackoverflow.com/a/41811770/2849613"">https://stackoverflow.com/a/41811770/2849613</a> I would like to get a little bit more information about best practices with microservices on Heroku. </p>&#xA;&#xA;<p>The question is which approach is better?</p>&#xA;&#xA;<ol>&#xA;<li>Install every services as independent app, and use one of them as REST ""proxy"" (for example Netflix Eureka)?</li>&#xA;</ol>&#xA;&#xA;<p>Or</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Create docker based approach with, for example Netflix Zuul as a load balancer?</li>&#xA;</ol>&#xA;&#xA;<p>On my own I see already some pros and cons of both approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p><strong>Pros</strong>: better scalability (easy to create new machines for bigger load). <strong>Cons</strong>: communication between services goes ""outside of heroku"" in other words: because heroku app have public address everyone can connect directly to service (without going threw Eureka), because of that every services need to provide some authentication method and share it between each other - I think that this is risk prone. </p></li>&#xA;<li><p><strong>Pros</strong>: easy to reproduce production environment for tests and develop (docker image), communication between services is done ""internally"" (image to image instead app to app). <strong>Cons</strong>: hard to scale (I think that load balancing between Heroku apps and then docker images is a little bit overhead). </p></li>&#xA;</ol>&#xA;&#xA;<p>Which approach is better? Maybe I can mix them together? Or maybe there is some different, better solution?</p>&#xA;&#xA;<p>Do be honest the only thing which I am sure, is that I want to use rabbitMQ as a message queue...</p>&#xA;"
35673254,Communication Between Microservices,2016-02-27 17:50:46,<rpc><thrift><microservices>,1,2549,4,2.0,5,"<p>Say you have microservice A,B, and C which all currently communicate through HTTP. Say service A sends a request to service B which results in a response. The data returned in that response must then be sent to service C for some processing before finally being returned to service A. Service A can now display the results on the web page. </p>&#xA;&#xA;<p>I know that latency is an inherent issue with implementing a microservice architecture, and I was wondering what are some common ways of reducing this latency? </p>&#xA;&#xA;<p>Also, I have been doing some reading on how Apache Thrift and RPC's can help with this. Can anyone elaborate on that as well?  </p>&#xA;"
42486386,Does CQRS With OLTP and OLAP Databases Make Sense?,2017-02-27 12:57:36,<api><olap><microservices><cqrs><oltp>,1,219,2,1.0,5,"<p>I have several OLTP databases with API's talking to them. I also have ETL jobs pushing data to an OLAP database every few hours.</p>&#xA;&#xA;<p>I've been tasked with building a custom dashboard showing hight level data from the OLAP database. I want to build several API's pointing to the OLAP database. Should I:</p>&#xA;&#xA;<ol>&#xA;<li>Add to my existing API's and call the OLAP database and use a CQRS type pattern, so reads come from OLAP, while writes come from OLTP. My concern here is that there could be a mismatch in the data between reads and writes. How mismatched the data is depends on how often you run the ETL jobs (Hours in my case).</li>&#xA;<li>Add to my existing API's and call the OLAP databases then ask the client to choose whether they want OLAP or OLTP data where API's overlap. My concern here is that the client should not need to know about the implementation detail of where the data is coming from.</li>&#xA;<li>Write new API's that only point to the OLAP database. This is a lot of extra work.</li>&#xA;</ol>&#xA;"
49944806,"How we configure API gateway, service discovery for micro services in pcf?",2018-04-20 15:13:55,<spring-boot><microservices><spring-cloud-netflix><pcf>,2,254,0,2.0,5,"<p>I am learning building  microservices using spring boot, Spring Cloud(netflix OSS Components). I have used netflix Eureka for service discovery, zuul for api gateway, ribbon, feign while running in my local machine.</p>&#xA;&#xA;<p>Netflix eureka, zuul, ribbon, feign spring cloud config are not useful when we deploy to PCF?(if yes what are the alternatives available in pcf and how to configure them?)</p>&#xA;&#xA;<p>As who are building microservices follows CI/CD approach, how developer verify working of  their micro services before pushing code as we don't use eureka, zuul,ribbon,feign in production pcf. (how to simulate pcf environment in developer machine?). </p>&#xA;"
44704629,identity aspnet core microservices,2017-06-22 16:15:48,<asp.net-core><microservices><identityserver4>,1,373,0,1.0,5,"<p>I want to develop an application using microservices architecture. I'm really new at microservices and until now I've only worked with monolithich approach.</p>&#xA;&#xA;<p>What I would like to do is to have a microservice which takes care of user authentication and have Proxy APIS to authorize the requests. </p>&#xA;&#xA;<p>Authorizing the request in the Proxy API is pretty well documented on the IdentityServer4 docs, but, when the proxy api passes the request to the end microservice how do I authorize this request?</p>&#xA;&#xA;<p>I know that if I setup the end microservice correctly, the same token used in the proxy api can be used to authorize the request at the end microservice. But how do I pass it? Do I grab the token from the request in the Proxy API and pass it down to the end microservice just like that? is it a good practice to do this?</p>&#xA;&#xA;<p>Or is it a better option to block the end microservice to receive only requests from my proxy apis and have no authorization logic there?</p>&#xA;&#xA;<p>PD: I would like to use asp.net-core</p>&#xA;"
37523631,HTTP vs Thrift in microservices architecture,2016-05-30 10:39:41,<java><microservices>,1,2185,0,1.0,5,"<p>I'm have just start learning about micro-services and I have a question that I cannot answer myself. (and I'm also a Java based developer)</p>&#xA;&#xA;<p>I have a situation like this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I have service A (an API service) that call Thrift services (Named T1) for get data.</p></li>&#xA;<li><p>Then I have a service B that can use data response from A, parse these data and then generate some new data, finally, return it to client.</p></li>&#xA;</ol>&#xA;&#xA;<p>The question is: Which I should use?&#xA;B call API from A and parse (for example JSON data) with HttpClient/ AsyncHttpClient with connection pool or B direct call T1 and repeat what A do?</p>&#xA;&#xA;<p>IMHO, I think Thrift (with connection pooling too) is faster than HTTP call? Am I right?</p>&#xA;&#xA;<p>I see a lot of services that use HTTP for internal like Elastic search, Neo4j, Eureka Netflix, etc ...</p>&#xA;&#xA;<p>So, which one should I use? And why HTTP is so popular for internal use instead of RPC like Thrift, ProtoBuf, ...?</p>&#xA;&#xA;<p>Sorry for my bad english.&#xA;Thank you in advance.</p>&#xA;"
47647560,How to share entity between REST service between two microservices?,2017-12-05 06:41:54,<java><rest><microservices>,3,643,2,2.0,5,<p>I have created two micro-services using java. I need to make a REST api call from service A to service B. The data sent will be in JSON format. Using jax-rs I need to create entity class in both the service.</p>&#xA;&#xA;<p>Since both the entity class be same in both the projects. Do i </p>&#xA;&#xA;<ul>&#xA;<li>Create an common jar and use is for all my entity/domain objects? Does this make my microservice more tightly coupled?</li>&#xA;<li>Do i create the same class in both the microservice projects? This will just mean repeating the work in both the projects?</li>&#xA;</ul>&#xA;&#xA;<p>Is there a better way to communicate between the sevices?</p>&#xA;
40947247,"Event sourcing, CQRS and database in Microservice",2016-12-03 11:30:16,<microservices><cqrs><event-sourcing>,1,1104,1,1.0,5,"<p>I am quite new in context of Micro-service architecture and reading this post : <a href=""http://microservices.io/patterns/data/event-sourcing.html"" rel=""noreferrer"">http://microservices.io/patterns/data/event-sourcing.html</a> to get familiar with Event sourcing and data storage in Microservice architecture. &#xA;I have read many documents about 3 important aspect of system :</p>&#xA;&#xA;<ol>&#xA;<li>Using event sourcing instead of a simply shared DB and ORM and&#xA;    row update</li>&#xA;<li>Events are JAVA objects. </li>&#xA;<li>In case of saving data permanently&#xA;    , we need to use DB (either relational or noSQL)</li>&#xA;</ol>&#xA;&#xA;<p>Here are my questions :</p>&#xA;&#xA;<ol>&#xA;<li><p>How database comes along with event sourcing? I have read CQRS&#xA;pattern, but I can not understand how CQRS pattern is related to&#xA;event store and event objects ?  </p></li>&#xA;<li><p>Can any body provide me a&#xA;    complete picture and set of operations happens with all players to&#xA;    gather: CQRS pattern , Event sourcing (including event storage&#xA;    module) and finally different microservices?</p></li>&#xA;<li>In a system&#xA;        composed of many microservices, should we have one event storage or&#xA;        each microservice has its own ? or both possible ?</li>&#xA;<li>same&#xA;    question about CQRS. This pattern is implemented in all&#xA;    microservices or only in one ?  </li>&#xA;<li>Finally, in case of using&#xA;        microservice architecture, it is mandatory to have only one DB or&#xA;        each Microserivce should have its own ?</li>&#xA;</ol>&#xA;&#xA;<p>As you can see, I have understood all small pieces of game , but I can not relate them together to compose a whole image. Specially relevance between CQRS and event sourcing and storing data in DB. &#xA;I read many articles for example :</p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://ookami86.github.io/event-sourcing-in-practice/"" rel=""noreferrer"">https://ookami86.github.io/event-sourcing-in-practice/</a></li>&#xA;<li><a href=""https://msdn.microsoft.com/en-us/library/jj591577.aspx"" rel=""noreferrer"">https://msdn.microsoft.com/en-us/library/jj591577.aspx</a></li>&#xA;</ul>&#xA;&#xA;<p>But in all of them small players are discussed. Even a hand drawing piece of image will be appreciated. </p>&#xA;"
40972026,Netflix-Zuul vs Mashape-Kong,2016-12-05 10:26:37,<microservices><netflix-zuul><kong><mashape>,1,4235,4,3.0,5,<p>Both Zuul and kong serve as a good API gateway layer in a microservices architecture. What are some important differences between these two?</p>&#xA;
37662379,Jhipster import-jdl not generating entities,2016-06-06 16:23:46,<jhipster><microservices>,4,2344,1,4.0,5,"<p>I am running into a problem with import-jdl and I am not sure why it is not working. I am trying to generate entities for microservices application. </p>&#xA;&#xA;<p>All I get is </p>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;&#xA;<p>but nothing else.</p>&#xA;&#xA;<p>I used the sample <a href=""https://jhipster.github.io/jdl-studio/"" rel=""nofollow"">https://jhipster.github.io/jdl-studio/</a> entity provided by JDL without any modification. </p>&#xA;&#xA;<p>I have tried this in my Mac, Linux (Ubuntu), and Docker container but I get the same error. </p>&#xA;&#xA;<p>Here are the versions of the software: </p>&#xA;&#xA;<pre><code>JHipster Generator: v3.3.0&#xA;npm : 3.9.2&#xA;yo : 1.8.3&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>Microservices Application </p>&#xA;  &#xA;  <p>------- Application files will be generated in folder: /Users/anand/Desktop/jhexample </p>&#xA;  &#xA;  <hr>&#xA;  &#xA;  <p>JHipster update available: 3.4.0 (current: 3.3.0)   Run npm install&#xA;  -g generator-jhipster to update.  ______________________________________________________________________________</p>&#xA;  &#xA;  <p>? (1/16) Which <em>type</em> of application would you like to create?&#xA;  Microservice application</p>&#xA;  &#xA;  <p>? (2/16) What is the base name of your application? jhexample</p>&#xA;  &#xA;  <p>? (3/16) As you are running in a microservice architecture, on which&#xA;  port would like your server to run? It should be unique to avoid port&#xA;  conflicts. 8081</p>&#xA;  &#xA;  <p>? (4/16) What is your default Java package name? com.anand</p>&#xA;  &#xA;  <p>? (5/16) Which <em>type</em> of authentication would you like to use? JWT&#xA;  authentication (stateless, with a token)</p>&#xA;  &#xA;  <p>? (6/16) Which <em>type</em> of database would you like to use? MongoDB</p>&#xA;  &#xA;  <p>? (7/16) Would you like to use Maven or Gradle for building the&#xA;  backend? Maven</p>&#xA;  &#xA;  <p>? (8/16) Would you like to enable internationalization support? No</p>&#xA;  &#xA;  <p>? (9/16) Which testing frameworks would you like to use? (Press&#xA;   to select)Gatling</p>&#xA;</blockquote>&#xA;&#xA;<p>...snip...</p>&#xA;&#xA;<blockquote>&#xA;  <p>Server app generated successfully.</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>anand$ yo jhipster:import-jdl ./jhipster-jdl.jh&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;"
47527983,Designing java project for monoliths and microservices at same time,2017-11-28 09:25:20,<java><scope><package><domain-driven-design><microservices>,3,268,2,0.0,5,"<p>I would like to know how you divide project modules in java for monolith with possibility of transforming modules to micro-services later?<br>&#xA;My personal naming looks like this:</p>&#xA;&#xA;<pre><code>com.company.shopapp.product&#xA;...product.domain (ddd, services, repositories, entities, aggregates, command handlers - everything with package scope)&#xA;...product.api (everything with public scope)&#xA;...product.controller (CQRS endpoints for commands in web perspective - (package scope))&#xA;...product.query(CQRS - package scope)&#xA;&#xA;com.company.shopapp.sales&#xA;- domain&#xA;- api &#xA;- controller&#xA;- query &#xA;</code></pre>&#xA;&#xA;<p>What we have here is basically product management context and sales context as packages. </p>&#xA;&#xA;<p>Modules communicate each other using public interfaces (api package) only. In my project I use ""..api.ProductFacade"" to centralize communication points.</p>&#xA;&#xA;<p>When my ""sales"" module grow i will turn it into microservice by implementing ""..api.ProductFacade"" interface as a ""rest"" or ""soap"" client and on the other side I will create Endpoint/RestController based on ProductFacade interface.&#xA;Package ""com.company.shopapp.product.api"" will be transformed into extended library and added to both projects. </p>&#xA;&#xA;<p>Edit: &#xA;I can achive this out of the box using @Feign library.&#xA;<a href=""https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance"" rel=""nofollow noreferrer"">https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance</a></p>&#xA;&#xA;<p>The whole idea feels nice, but maybe you have better way to design project and ensure that breaking it into micro-services will not break whole application. </p>&#xA;"
47544877,Websockets in microservices architecture,2017-11-29 04:05:22,<web-applications><websocket><microservices><api-gateway>,1,1872,5,0.0,5,"<p>Let's say we have a notification service which read an event from message queue and notify all web clients in real time. I know how web socket work but i am puzzled when there is an API gateway in between then how web socket connection is maintained between client, API gateway and notification service.</p>&#xA;&#xA;<p>Please help! Thanks</p>&#xA;&#xA;<p><strong>Edit:</strong>&#xA;Architecture:&#xA;<a href=""https://i.stack.imgur.com/wEeu3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wEeu3.jpg"" alt=""enter image description here""></a></p>&#xA;"
47516458,CQRS: project out-of-order notifications in an ElasticSearch read model,2017-11-27 17:17:35,<elasticsearch><apache-kafka><domain-driven-design><microservices><cqrs>,1,162,8,4.0,5,"<p>We have a microservice architecture and apply the CQRS pattern. A command sent to a microservice triggers an application state change and the emission of the corresponding event on our Kafka bus. We project these events in a read model built with ElasticSearch.</p>&#xA;&#xA;<p>So far, so good.</p>&#xA;&#xA;<p>Our microservices are eventually consistent with each other. But at any given time, they aren't (necessarily). Consequently, the events they send are not always consistent with each other either.</p>&#xA;&#xA;<p>Moreover, to guarantee the coherence between an application state change and the emission of the corresponding event, we persist in DB the new state and the corresponding event in the same transaction (I am aware that we could use event sourcing and avoid persisting the state altogether). An asynchronous worker is then responsible to send these events on the Kafka bus. This pattern guarantees that at least one event will be sent for each state change (which is not an issue since our events are idempotent). However, since each microservice has its own event table and asynchronous worker, we cannot guarantee that events will be sent in the sequence in which the corresponding state changes occurred in their respective microservices.</p>&#xA;&#xA;<p>EDIT: to clarify, each microservice has its own database, its own event table and its own worker. A specific worker processes the events in the order in which they were persisted in its corresponding event table, but different workers on different event tables, i.e. for distinct microservices, do not give such guarantee.</p>&#xA;&#xA;<p>The problem arises when projecting these incoherent or out-of-sequence events from different microservices in the same ElasticSearch document.</p>&#xA;&#xA;<p>A concrete example: let's imagine three different aggregates A, B and C (aggregate in the Domain Driven Design sense) managed by different microservices:</p>&#xA;&#xA;<ul>&#xA;<li>There is a many-to-many relation between A and B. Aggregate A references the aggregate roots B he is bound to, but B is unaware of its relationships with A. When B is deleted, the microservice managing A listens for the corresponding event and undoes the binding of A with B.</li>&#xA;<li>Similarily, there is a many-to-many relation between B and C. B knows of all related C aggregates, but the inverse is not true. When C is deleted, the microservice managing B listens for the corresponding event and undoes the binding of B with C.</li>&#xA;<li>C has a property ""name"".</li>&#xA;</ul>&#xA;&#xA;<p>One of the use cases is to find, through ElasticSearch, all aggregates A that are bound to an aggregate B that is in turn bound to an aggregate C with a specific name.</p>&#xA;&#xA;<p>As explained above, the separate event tables and workers could introduce variable delays between the emission of events from different microservices. Creating A, B and C and binding them together could for example result in the following sequence of events:</p>&#xA;&#xA;<ol>&#xA;<li>B created</li>&#xA;<li>B bound to C</li>&#xA;<li>C created with name XYZ</li>&#xA;<li>A created</li>&#xA;<li>A bound to B</li>&#xA;</ol>&#xA;&#xA;<p>Another example of batch of events: let's suppose we initially have aggregates B and C and two commands are issued simultaneously:</p>&#xA;&#xA;<ul>&#xA;<li>delete C</li>&#xA;<li>bind B to C</li>&#xA;</ul>&#xA;&#xA;<p>this could result in the events:</p>&#xA;&#xA;<ol>&#xA;<li>C deleted</li>&#xA;<li>B bound to C</li>&#xA;<li>B unbound from C (in response to event 1)</li>&#xA;</ol>&#xA;&#xA;<p>Concretely, we have trouble projecting these events in ElasticSearch document(s) because the events sometimes reference aggregates that do not exist anymore or do not exist yet. Any help would be appreciated.</p>&#xA;"
41024771,Micro Service vs Nano Service?,2016-12-07 18:30:53,<web-services><agile><microservices>,2,3641,4,0.0,5,"<p>So, what do you call it? A Micro service or a Nano Service?</p>&#xA;&#xA;<p>What differences they have? I came across many blogs on internet and I could find any satisfactory answer. </p>&#xA;&#xA;<p>Found this quotation from Mark Little on <a href=""https://www.infoq.com/news/2014/05/nano-services"" rel=""noreferrer"">InfoQ</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>First things first what actually is a micro service? Well there really isnâ€™t a hard and fast definition but from conversations with various people there seems to be a consensus that a micro service is a simple application that sits around the 10-100 LOC mark.</p>&#xA;</blockquote>&#xA;&#xA;<p>another one:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Nanoservice is an antipattern where a service is too fine-grained. A nanoservice is a service whose overhead (communications, maintenance, and so on) outweighs its utility. Like Steve and others, Arnon concludes that Microservices is just another name for SOA</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm looking for an accurate and explainable distinction between a Micro and a Nano Service. I highly appreciate your opinions!</p>&#xA;"
45622414,Should there be authentication/authorization between microservices?,2017-08-10 19:51:25,<soa><microservices>,3,1038,0,0.0,5,"<p>I know this may be not a good question.</p>&#xA;&#xA;<p>I was asked a question: do we really need authentication among microservices. And I have no idea the answer. I did read some tutorials on SOA, microservices, and how to add authentication among the services. But I did not have too many ideas <strong>why we need authentication/authorization between microservices? Any use cases where they are required? Any use cases where they are not required?</strong> Any potential risk without authentication/authorization? </p>&#xA;&#xA;<p>Any comments welcomed. It is better to give some practical examples. Thanks</p>&#xA;"
45655728,What is the real difference between an API and an microservice?,2017-08-12 23:17:02,<api><microservices>,5,11680,0,2.0,5,"<p>I am learning about microservices and I don't understand what the real difference between creating a REST API and creating microservices is. Iâ€™m working in Go, but my question applies over all languages.</p>&#xA;"
20693516,"In a micro-service architecture, how the micro-services will be served?",2013-12-19 23:12:37,<service><deployment><architecture><port><microservices>,1,3018,0,1.0,6,"<p>I have read some articles and watched some videos, but did not find a concrete suggestion when it comes to serving those micro-services. My understanding is that they should be served with their own application server. </p>&#xA;&#xA;<p>My question is should they be deployed on different servers or it does not matter.</p>&#xA;&#xA;<p>When they are served on the same server(computer) won't there be port conflicts?</p>&#xA;"
28319278,How to connect separate microservice applications?,2015-02-04 10:40:39,<api><security><rest><http><microservices>,5,3209,2,1.0,6,"<p>I am building huge application using microservices architecture. The application will consist of multiple backend microservices (deployed on multiple cloud instances), some of which I would like to connect using rest apis in order to pass data between them.</p>&#xA;&#xA;<p>The application will also expose public api for third parties, but the above mentioned endpoints should be restricted ONLY to other microservices within the same application creating some kind of a private network.</p>&#xA;&#xA;<p>So, my question is: </p>&#xA;&#xA;<p><strong>How to achieve that restricted api access to other microservices within the same application?</strong></p>&#xA;&#xA;<p>If there are better ways to connect microservices than using http transport layer, please mention them.</p>&#xA;&#xA;<p>Please keep the answers server/language agnostic if possible.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
29888108,How to call a microservice in .NET,2015-04-27 05:49:37,<c#><.net><rest><asp.net-web-api><microservices>,4,11466,1,3.0,6,"<p>I've created a very simple REST microservice that receives information about an email and sends it. The microservice send method looks something like this:</p>&#xA;&#xA;<pre><code>//EmailController&#xA;[HttpPost]&#xA;public IHttpActionResult Send(Email email)&#xA;{&#xA;    // send email via exchange&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now in my application, I call it using RestSharp like this:</p>&#xA;&#xA;<pre><code>var client = new RestClient(""http://localhost:51467/api/"");&#xA;var request = new RestRequest(""email/send"", Method.POST);&#xA;request.RequestFormat = DataFormat.Json;&#xA;dynamic obj = new ExpandoObject();&#xA;obj.FromAddress = from;&#xA;obj.ToAddress = to;&#xA;obj.Subject = subject;&#xA;obj.Body = body;&#xA;&#xA;request.AddBody(obj);&#xA;client.Execute(request);&#xA;</code></pre>&#xA;&#xA;<p>Questions I have:</p>&#xA;&#xA;<ol>&#xA;<li><p>Is this the best way to do the call? Obviously i'll later have to add error handling etc, but I'm talking more the way I'm using RestSharp to do the call.</p></li>&#xA;<li><p>I'm finding it a bit uncomfortable that my app needs to kind of know what object the microservice expects to receive - there's no sort of definition/interface/contract that it uses to know for sure. Is this generally accepted as being ok for REST or should I implement some sort of interface that my app has so it can call my microservice in a bit more of a defined way. Is that even something possible with REST?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!</p>&#xA;"
27891019,How to build a streamlined development environment for micro-services,2015-01-11 19:14:05,<git><github><vagrant><fig><microservices>,1,972,2,2.0,6,"<p>I was thinking about the micro services architecture and wondering if folks have a good best practice for development environments.</p>&#xA;&#xA;<p>My working assumption is that each micro service will live in it's own git repository for isolation and ease of deployment. I'm also assuming that each developer will create a fork of any repo that they are working on. </p>&#xA;&#xA;<p>The issue I'm considering arises where you are working on an issue that involves multiple micro-services. For example, there is a defect that impacts one micro service and how it appropriately consumes another micro-service. </p>&#xA;&#xA;<p>Assuming n projects are involved in the defect, you would have to check out n git repositories and configure them to work together. If they each have a Vagratefile and Dockerfile, you end up running n VMs. Ideally you'd only have 1 Vagrant VM and each serivce would just be a new Docker instance in that same VM.</p>&#xA;&#xA;<p>A master repo/project with git sub modules could work. The problem with that is if we create a generic master repo/project then the sub module will point to the upstream not the fork for the developer.</p>&#xA;&#xA;<p>I'm currently thinking that a master project that had some configs, vagrant and fig might do the trick.  I'm currently considering two methods of implementing this approach.</p>&#xA;&#xA;<ol>&#xA;<li>Provide a config with some defaults i.e. project_1 should be located&#xA;at ../project_id, etc </li>&#xA;<li>Provide a script that will create submodules&#xA;based on the user's github account, this would create the remote for&#xA;the user's fork as well as the remote for the upstream project.</li>&#xA;</ol>&#xA;&#xA;<p>Has anybody else solved this problem or have a good workflow?</p>&#xA;"
26491425,Why should a 12 Factor app be self contained?,2014-10-21 16:16:05,<java><paas><12factor><microservices>,2,1169,0,0.0,6,"<p>In the 12 Factor article on Port Binding&#xA;<a href=""http://12factor.net/port-binding"" rel=""nofollow noreferrer"">http://12factor.net/port-binding</a> there is a requirement that every app&#xA;be self-contained and not have a runtime injected e.g. Tomcat. For&#xA;what reason is this advised... what are advantages of self-contained apps for microservices?</p>&#xA;"
41358754,Looking for API Gateway Technology that call multiple microservices,2016-12-28 09:10:08,<amazon-web-services><microservices><aws-api-gateway><gateway><service-discovery>,1,422,1,4.0,6,"<p>In my company, we plan to migrate our back-end solution, which is a huge monolith, to a sexier microservices architecture.</p>&#xA;&#xA;<p>So far, we have benchmarked many technologies, and we will probably use the AWS infrastructure with AWS EC2 Container Services (ECS). Our microservices will be wrapped in Docker containers.</p>&#xA;&#xA;<p>We have already deployed containers and configured the auto-scaling and the load balancing. Everything works great.</p>&#xA;&#xA;<p>However, we are looking for an API Gateway technology that could allow us to call multiple microservices with only one request for the client.</p>&#xA;&#xA;<p>The idea is to develop an architecture that looks like Netflix one: &#xA;<a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""nofollow noreferrer"">http://techblog.netflix.com/2013/01/optimizing-netflix-api.html</a></p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>If the client (a web site) wants to fetch the cart of a client. It will send a Get request to the API.</p>&#xA;&#xA;<p>First, I would like that our gateway call the ""user"" microservice that will return the user's information and the list of the id product that his cart contains:</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [1,2,3]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then, without directly responding to the client, the gateway will call the ""product"" microservice to hydrate the Json with the information about each product.</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [&#xA;         {""id"": 1, ""name"": ""Iphone"", ...},&#xA;         {""id"": 2, ""name"": ""Ipad"", ...},&#xA;         {""id"": 3, ""name"": ""Ipod"", ...}&#xA;    ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, my question is do you know a nice technology that could do the job ?</p>&#xA;"
30173267,Microservice Architecture- cross-domain chattiness,2015-05-11 16:48:08,<architecture><soa><microservices>,3,808,6,3.0,6,"<p>I have a relatively new project that employs a microservice architecture. I feel pretty good about the size and granularity of the individual services, with the exception or our security service.</p>&#xA;&#xA;<p>I have three main services, let's say <code>foo-service</code>, <code>bar-service</code>, and <code>baz-service</code>. These services never need to communicate, but all three services regularly talk via HTTP requests to the <code>security-service</code>. I want this to stop for a variety of reasons- the biggest is that each request to my individual services spawns a request to the security service, which can turn into several extra hops once you account for load balancing, etc. I've been reading ""Software Architecture Patterns"" by Mark Richards, and he recommends in these instances you should share databases and violate DRY: copy the required functionality into each service. Still, he uses this example with smaller ""utility"" classes, which may not really apply in this instance. </p>&#xA;&#xA;<p>The security service isn't that big, so I could definitely copy it into each of the other services. That said, it's just big enough that I don't feel great copying and pasting it - 314 'relevant' lines of code according to coveralls (java so there's a lot more actual code ;-). I could easily turn it into a module that each service brings in- but then my services have a shared dependency and that has bit me in the past. Of course the security code will grow over time as we add authentication methods, but we aren't reinventing the wheel when it comes to auth so It's mostly integrating with other libraries and authentication services. That is, I don't imagine this particular code base getting huge.</p>&#xA;&#xA;<p>So my question, should I copy and paste the code or build a module that every service brings in? Thanks!</p>&#xA;"
35172625,Spring Cloud Config Eureka-first approach not working,2016-02-03 09:08:19,<spring><spring-boot><spring-cloud><microservices><netflix-eureka>,1,11088,3,2.0,6,"<p>I'm developing a Spring Cloud Eureka microservices application. I want my services to connect to the config service via an Eureka-first approach. Microservices are packaged as docker containers and deployed via docker-compose. The application is composed by:</p>&#xA;&#xA;<ol>&#xA;<li><code>myapp-service-registry</code>: a service registry service implemented with Spring Cloud Eureka</li>&#xA;<li><code>myapp-config-service</code>: a Spring Cloud config service server</li>&#xA;<li><code>myapp-service-test</code>: An example microservice which should try to take its config data from the config service by connecting to this via an Eureka-first approach. </li>&#xA;</ol>&#xA;&#xA;<p>The connection to the config service fail as described below. First of all some configuration data:</p>&#xA;&#xA;<p>Here is <code>myapp-service-registry</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${PORT:8761}&#xA;&#xA;eureka:&#xA;  client:&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;  server:&#xA;    waitTimeInMsWhenSyncEmpty: 0&#xA;</code></pre>&#xA;&#xA;<p>Here the <code>myapp-config-service</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${MYAPP_CONFIG_SERVICE_PORT:8888}&#xA;&#xA;spring: &#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;  config:&#xA;    name: myapp-config-service&#xA;&#xA;# eureka service registry client&#xA;&#xA;eureka: &#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>Config server and client are initialized as in <code>configserver-eureka</code> and <code>eureka-first</code> samples in <a href=""https://github.com/spring-cloud-samples/tests"" rel=""nofollow"">https://github.com/spring-cloud-samples/tests</a> :</p>&#xA;&#xA;<p><code>myapp-config-service</code>'s <code>bootstrap.yml</code> is:</p>&#xA;&#xA;<pre><code>spring:&#xA;    application:&#xA;        name: myapp-config-service&#xA;    cloud:&#xA;        config:&#xA;            discovery:&#xA;                enabled: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>eureka:&#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>bootstrap.yml</code>:</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: myapp-service-test&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        serviceId: myapp-config-service&#xA;</code></pre>&#xA;&#xA;<p>Following is the <code>docker-compose.yml</code> (env variable are replaced with actual values at launch):</p>&#xA;&#xA;<pre><code>myapp-service-registry:&#xA;image: myapp/myapp-service-registry:0.0.1&#xA;ports:&#xA;    - ${EUREKA_PORT}:${EUREKA_PORT}&#xA;&#xA;# myapp-config-service&#xA;&#xA;myapp-config-service:&#xA;    image: myapp/myapp-config-service:0.0.1&#xA;    volumes:&#xA;    - ${MYAPP_DATA_FOLDER}/config:/var/opt/myapp/config&#xA;    environment:&#xA;      MYAPP_CONFIG_SERVICE_PORT: ${MYAPP_CONFIG_SERVICE_PORT}&#xA;      SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;      SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;      MYAPP_CONFIG_SERVICE_GIT_URI: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;    ports:&#xA;        - ${MYAPP_CONFIG_SERVICE_PORT}:${MYAPP_CONFIG_SERVICE_PORT}&#xA;&#xA; # myapp-service-test&#xA;&#xA;myapp-service-test:&#xA;  image: myapp/myapp-service-test:0.0.1&#xA;  environment:&#xA;    SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;    SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;  ports:&#xA;    - ${MYAPP_SERVICE_TEST_TWO_PORT}:8080&#xA;</code></pre>&#xA;&#xA;<p>I can check that Eureka is working by connecting the browser to <a href=""http://[...MACHINE-IP...]:8761/"" rel=""nofollow"">http://[...MACHINE-IP...]:8761/</a> and seeing the Eureka dashboard. Similarly, I test that the config service is working and responds to <a href=""http:///[...MACHINE-IP...]:8888/myapp-config-service"" rel=""nofollow"">http:///[...MACHINE-IP...]:8888/myapp-config-service</a>; With the above configuration, on the other hand, myapp-service-test crashes at startup with the following log:</p>&#xA;&#xA;<pre><code>-02-03 08:26:45.191  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Starting TestServiceApplication v0.0.1 on b1bc37422027 with PID 1 (/app.jar started by root in /)&#xA;2016-02-03 08:26:45.223  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : No active profile set, falling back to default profiles: default&#xA;2016-02-03 08:26:45.448  INFO 1 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@4d97e82d: startup date [Wed Feb 03 08:26:45 UTC 2016]; root of context hierarchy&#xA;2016-02-03 08:26:46.382  INFO 1 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2016-02-03 08:26:46.442  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'configurationPropertiesRebinderAutoConfiguration' of type [class org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6b65138e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-02-03 08:26:47.089  INFO 1 --- [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING&#xA;2016-02-03 08:26:48.231  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:48.237  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.496  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false&#xA;2016-02-03 08:26:49.498  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false&#xA;2016-02-03 08:26:49.502  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server&#xA;2016-02-03 08:26:49.720  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't get a response from http://localhost:8761/eureka/apps/&#xA;&lt;...&gt;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.jar!/:1.19]&#xA;    at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.jar!/:1.19]&#xA;    at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    &lt;...&gt;&#xA;Caused by: java.net.ConnectException: Connection refused&#xA;    at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_66-internal]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.747 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.770 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_MYAPP-SERVICE-TEST/b1bc37422027:myapp-service-test - was unable to refresh its cache! status = java.net.ConnectException: Connection refused&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.785  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.&#xA;2016-02-03 08:26:49.810  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 10&#xA;2016-02-03 08:26:49.818  INFO 1 --- [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4&#xA;2016-02-03 08:26:50.443  WARN 1 --- [           main] lientConfigServiceBootstrapConfiguration : Could not locate configserver via discovery&#xA;&#xA;java.lang.RuntimeException: No matches for the virtual host name :myapp-config-service&#xA;    at com.netflix.discovery.DiscoveryClient.getNextServerFromEureka(DiscoveryClient.java:782) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    at org.springframework.cloud.netflix.config.DiscoveryClientConfigServiceBootstrapConfiguration.refresh(DiscoveryClientConfigServiceBootstrapConfiguration.java:71) [spring-cloud-netflix-core-1.1.0.M3.jar!/:1.1.0.M3]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:50.470  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Started TestServiceApplication in 7.101 seconds (JVM running for 9.329)&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v1.3.1.RELEASE)&#xA;&#xA;2016-02-03 08:26:50.773  INFO 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://localhost:8888&#xA;2016-02-03 08:26:51.015  WARN 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""http://localhost:8888/myapp-service-test/default"":Connection refused; nested exception is java.net.ConnectException: Connection refused&#xA;&#xA;&lt;...&gt;&#xA;&#xA;2016-02-03 08:26:54.856 ERROR 1 --- [pool-5-thread-1] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:57.272  WARN 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testTwoServiceController': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: java.lang.String myapp.services.two.TestServiceController.message; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'message' in string value ""${message}""&#xA;2016-02-03 08:26:57.281  INFO 1 --- [           main] o.apache.catalina.core.StandardService   : Stopping service Tomcat&#xA;2016-02-03 08:26:57.299 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Note that if I don't implement an Eureka-first approach (and set spring.cloud.config.uri directly in the service's <code>bootstrap.yml</code>), the service registers to Eureka, finds the config server and works correctly (I can see the registered service in Eureka's dashboard and can check that config properties are correctly read).</p>&#xA;"
32470907,"Microservices - Maintaining Multiple Data stores, initial data load etc",2015-09-09 04:28:10,<microservices>,1,547,2,1.0,6,"<p>On aspects of granulatiry of mictoservices have read about the 2 pizza rule, services that can be developed in 2 weeks etc.  When the case studies of amazon, nelflix, gilt are read we hear about 100s of services. While the service granularity does make sense, what is still not clear to me is about the data stores of each of these microservices. Will there not be just too many data stores if each of the services store/maintain their own data ?? It might be the same logical entity like a product, customer etc that is sliced &amp; the relevant portion/attributes stored/maintained by a corresponding microservice. There could be a service that maintains basic customer information, another that maintains the additional customer information like say his subscription information or his interests etc. </p>&#xA;&#xA;<p>Couple of questions that come to mind around the data stores</p>&#xA;&#xA;<ol>&#xA;<li>Will this not be a huge maintenance issue in terms of backups,&#xA;restores etc? </li>&#xA;<li>How is the initial data populated into these stores ? Are there any best practices around this ? Organisations are bound to have huge volumes of customer or product data &amp; they will most likely be mastered in other systems. </li>&#xA;<li>How does this approach of multiple data stores impact the 'omni-channel' approach where it  implies getting a single view of all data? Organizations might have had data consolidation initiatives going on to achieve the same</li>&#xA;</ol>&#xA;&#xA;<p>Edit: Edited the subject a bit</p>&#xA;"
35379246,Django models across multiple projects/microservices. How to?,2016-02-13 11:24:40,<django><microservices>,4,2688,0,1.0,6,"<p>I'm wondering how to solve sharing of the model structure between multiple (separated) django projects/microservices. Eg:</p>&#xA;&#xA;<ol>&#xA;<li>Project: API</li>&#xA;<li>Project: Users dashboard</li>&#xA;<li>Project: Admin dashboard</li>&#xA;<li>Project: Statistics</li>&#xA;</ol>&#xA;&#xA;<p>Each of that projects uses the same django models. Is there a one, proper way to solve that?</p>&#xA;"
34442192,Api gateway or No Api Gateway,2015-12-23 19:09:44,<microservices>,1,1401,1,0.0,6,"<p>I am developing an application based on the <code>microservice architecture</code>. Here, each <code>service</code> is an independently deployable <code>play-scala application</code> exposing <code>rest apis</code>. I want to implement an <code>Api gateway</code> on top of these services for mapping incoming requests.I am following the architecture discussed here :<a href=""http://%20https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""nofollow noreferrer"">Building Microservices</a></p>&#xA;&#xA;<p>There are very few projects with substantial maturity that are based on the microservice architecture. One of them is <a href=""https://github.com/theiterators/reactive-microservices#master"" rel=""nofollow noreferrer"">Reactive Microservices</a>.But this project is not using the <code>api gateway pattern</code> and seems to be following the <a href=""http://www.infoq.com/articles/seven-uservices-antipatterns"" rel=""nofollow noreferrer"">Anti Pattern</a> There is an <a href=""https://github.com/theiterators/reactive-microservices/issues/10"" rel=""nofollow noreferrer"">issue</a> opened for this project regarding the missing Api Gateway here .The contributors here claim that they did not follow the <code>api gateway pattern</code> because it has the risk of <code>single-point of failure</code>. </p>&#xA;&#xA;<p>This varying opinion is very confusing to me. So,I am looking for the suggestions on whether I should be using Api Gateway or not. <code>What is the right practice here ?</code> </p>&#xA;"
40222469,"GraphQL: Filtering, sorting and paging on nested entities from separate data sources?",2016-10-24 15:46:21,<microservices><graphql><graphql-js><apollo-server>,1,2634,3,1.0,6,"<p>I'm attempting to use graphql to tie together a number of rest endpoints, and I'm stuck on how to filter, sort and page the resulting data.  Specifically, I need to filter and/or sort by nested values.   </p>&#xA;&#xA;<p>I cannot do the filtering on the rest endpoints in all cases because they are separate microservices with separate databases.  (i.e. I could filter on <code>title</code> in the rest endpoint for articles, but not on author.name). Likewise with sorting.  And without filtering and sorting, pagination cannot be done on the rest endpoints either.</p>&#xA;&#xA;<p>To illustrate the problem, and as an attempt at a solution, I've come up with the following using <code>formatResponse</code> in <a href=""https://github.com/apollostack/graphql-server"" rel=""noreferrer"">apollo-server</a>, but am wondering if there is a better way.</p>&#xA;&#xA;<p>I've boiled down the solution to the most minimal set of files that i could think of:</p>&#xA;&#xA;<p>data.js represents what would be returned by 2 fictional rest endpoints:</p>&#xA;&#xA;<pre><code>export const Authors = [{ id: 1, name: 'Sam' }, { id: 2, name: 'Pat' }];&#xA;&#xA;export const Articles = [&#xA;  { id: 1, title: 'Aardvarks', author: 1 },&#xA;  { id: 2, title: 'Emus', author: 2 },&#xA;  { id: 3, title: 'Tapir', author: 1 },&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>the schema is defined as:</p>&#xA;&#xA;<pre><code>import _ from 'lodash';&#xA;import {&#xA;  GraphQLSchema,&#xA;  GraphQLObjectType,&#xA;  GraphQLList,&#xA;  GraphQLString,&#xA;  GraphQLInt,&#xA;} from 'graphql';&#xA;&#xA;import {&#xA;  Articles,&#xA;  Authors,&#xA;} from './data';&#xA;&#xA;const AuthorType = new GraphQLObjectType({&#xA;  name: 'Author',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    name: {&#xA;      type: GraphQLString,&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const ArticleType = new GraphQLObjectType({&#xA;  name: 'Article',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    title: {&#xA;      type: GraphQLString,&#xA;    },&#xA;    author: {&#xA;      type: AuthorType,&#xA;      resolve(article) {&#xA;        return _.find(Authors, { id: article.author })&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const RootType = new GraphQLObjectType({&#xA;  name: 'Root',&#xA;  fields: {&#xA;    articles: {&#xA;      type: new GraphQLList(ArticleType),&#xA;      resolve() {&#xA;        return Articles;&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;export default new GraphQLSchema({&#xA;  query: RootType,&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>And the main index.js is:</p>&#xA;&#xA;<pre><code>import express from 'express';&#xA;import { apolloExpress, graphiqlExpress } from 'apollo-server';&#xA;var bodyParser = require('body-parser');&#xA;import _ from 'lodash';&#xA;import rql from 'rql/query';&#xA;import rqlJS from 'rql/js-array';&#xA;&#xA;import schema from './schema';&#xA;const PORT = 8888;&#xA;&#xA;var app = express();&#xA;&#xA;function formatResponse(response, { variables }) {&#xA;  let data = response.data.articles;&#xA;&#xA;  // Filter&#xA;  if ({}.hasOwnProperty.call(variables, 'q')) {&#xA;    // As an example, use a resource query lib like https://github.com/persvr/rql to do easy filtering&#xA;    // in production this would have to be tightened up alot&#xA;    data = rqlJS.query(rql.Query(variables.q), {}, data);&#xA;  }&#xA;&#xA;  // Sort&#xA;  if ({}.hasOwnProperty.call(variables, 'sort')) {&#xA;    const sortKey = _.trimStart(variables.sort, '-');&#xA;    data = _.sortBy(data, (element) =&gt; _.at(element, sortKey));&#xA;    if (variables.sort.charAt(0) === '-') _.reverse(data);&#xA;  }&#xA;&#xA;  // Pagination&#xA;  if ({}.hasOwnProperty.call(variables, 'offset') &amp;&amp; variables.offset &gt; 0) {&#xA;    data = _.slice(data, variables.offset);&#xA;  }&#xA;  if ({}.hasOwnProperty.call(variables, 'limit') &amp;&amp; variables.limit &gt; 0) {&#xA;    data = _.slice(data, 0, variables.limit);&#xA;  }&#xA;&#xA;  return _.assign({}, response, { data: { articles: data }});&#xA;}&#xA;&#xA;app.use('/graphql', bodyParser.json(), apolloExpress((req) =&gt; {&#xA;  return {&#xA;    schema,&#xA;    formatResponse,&#xA;  };&#xA;}));&#xA;&#xA;app.use('/graphiql', graphiqlExpress({&#xA;  endpointURL: '/graphql',&#xA;}));&#xA;&#xA;app.listen(&#xA;  PORT,&#xA;  () =&gt; console.log(`GraphQL Server running at http://localhost:${PORT}`)&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>For ease of reference, these files are available at <a href=""https://gist.github.com/scags9876/d96da7c2dbc98c43f8d735447928480a"" rel=""noreferrer"">this gist</a>.</p>&#xA;&#xA;<p>With this setup, I can send this query:</p>&#xA;&#xA;<pre><code>{&#xA;  articles {&#xA;    id&#xA;    title&#xA;    author {&#xA;      id&#xA;      name&#xA;    }&#xA;  } &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Along with these variables (It seems like this is not the intended use for the variables, but it was the only way I could get the post processing parameters into the formatResponse function.):</p>&#xA;&#xA;<pre><code>{ ""q"": ""author/name=Sam"", ""sort"": ""-id"", ""offset"": 1, ""limit"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>and get this response, filtered to where Sam is the author, sorted by id descending, and getting getting the second page where the page size is 1.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Or these variables:</p>&#xA;&#xA;<pre><code>{ ""sort"": ""-author.name"", ""offset"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>For this response, sorted by author name descending and getting all articles except the first.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      },&#xA;      {&#xA;        ""id"": 2,&#xA;        ""title"": ""Emus"",&#xA;        ""author"": {&#xA;          ""id"": 2,&#xA;          ""name"": ""Pat""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, as you can see, I am using the formatResponse function for post processing to do the filtering/paging/sorting.   .</p>&#xA;&#xA;<p>So, my questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Is this a valid use case?</li>&#xA;<li>Is there a more canonical way to do filtering on deeply nested properties, along with sorting and paging?</li>&#xA;</ol>&#xA;"
41655915,Microservices: Atomic Events,2017-01-14 22:54:45,<database><events><microservices>,2,582,1,3.0,6,"<p>I'm learning about microservice data replication right now, and one thing I'm having trouble with is coming up with the right architecture for ensuring event atomicity.  The way I understand it, the basic flow is:</p>&#xA;&#xA;<ol>&#xA;<li>Commit changes to a database.</li>&#xA;<li>Publish an event detailing the changes on the global message bus.</li>&#xA;</ol>&#xA;&#xA;<p>But what if, for example, a power outage occurred in-between Steps 1 and 2?  In a naively-built system, that would mean the changes persist but the event detailing them will never be published.  I've pondered the following ideas to create better guarantees, but I'm not quite sure of all the pros and cons of each:</p>&#xA;&#xA;<p>A:  Use an embedded database (like SQLite) in my microservice instance to track the full transaction, from the commit to the main database to the event publishing.</p>&#xA;&#xA;<p>B:  Create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  The service would then push the Event to the bus, and then make another commit to the main database to mark the Event as Published.</p>&#xA;&#xA;<p>C:  As above, create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  Then, notify (either manually via REST/Messages from within the service or via database hooks) a dedicated EventPusher service that a new event has been appended.  The EventPusher service will query the Events table and push the events to the bus, marking each one as Published upon acknowledgement.  Should a certain amount of time pass without any notification, the EventPusher will do a manual query.</p>&#xA;&#xA;<p>What are the pros and cons of each of the choices above?  Is there another superior option I have yet to consider?</p>&#xA;"
39920488,What is the role of falcor in a microservice architecture?,2016-10-07 15:09:11,<microservices><falcor>,2,1336,0,4.0,6,"<p>Say we have following taxi-hailing application that is composed of loosely coupled microservices:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QgctP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QgctP.png"" alt=""https://www.nginx.com/blog/introduction-to-microservices/""></a></p>&#xA;&#xA;<p><em>The example is taken from <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/introduction-to-microservices/</a></em></p>&#xA;&#xA;<p>Each services has its own rest api and all services are combined in a single api gateway. The client does not talk to a single service but to the gateway. The gateway requests information from several services and combines them to a single response. For the client it looks like it is talking to a monolithic application.</p>&#xA;&#xA;<p><strong>I am trying to understand: where could we incorporate falcor into this application?</strong></p>&#xA;&#xA;<p><strong>One Model Everywhere</strong> from <a href=""http://netflix.github.io/falcor/"" rel=""nofollow noreferrer"">http://netflix.github.io/falcor/</a> </p>&#xA;&#xA;<blockquote>&#xA;  <p>Falcor lets you represent all your remote data sources as a single&#xA;  domain model via a virtual JSON graph. You code the same way no matter&#xA;  where the data is, whether in memory on the client or over the network&#xA;  on the server.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this taxi-hailing application each microservice represents a single domain model already. Can you think of any benefit we could thrive by wrapping each microservice with falcor? I cannot.</p>&#xA;&#xA;<p>However I think it is very convenient to incorporate falcor into the api gateway because we can abstract away the different domain models created by the microservices into one single or at least a few models.</p>&#xA;&#xA;<p>What is your opinion?</p>&#xA;"
38863827,How to handle REST API paths when related resources belong to different microservices?,2016-08-10 03:39:49,<rest><microservices>,2,309,0,1.0,6,"<p>I have two microservices:</p>&#xA;&#xA;<ul>&#xA;<li>UserService, which defines paths such as /users, /users/:id;</li>&#xA;<li>MessageService, which defines paths such as /messages, /messages/:id.</li>&#xA;</ul>&#xA;&#xA;<p>Also, each message in MessageService has an attribute user_id which references a user in UserService.</p>&#xA;&#xA;<p>Now, lets say I want to list all messages of a given user. Right now I can think of the following approaches:</p>&#xA;&#xA;<ol>&#xA;<li>A path such as <strong>/users/:id/messages</strong> seems like the best approach if I want to follow the best REST API practices. However, it seems to me that I couldn't define such path inside MessageService because I would be tight-coupling it to UserService. I believe paths starting with /users should belong to UserService only.</li>&#xA;<li><strong>/messages?user_id=:id</strong> so I could use the existing /messages path and add a filter by attribute (user_id). Not sure if a good practice.</li>&#xA;<li>Put an API gateway in front of the microservices and create a proxy from <strong>/users/:id/messages</strong> to <strong>/messages?user_id=:id</strong>. This allows clients to use the most REST-friendly path while keeping the microservices loosely coupled.</li>&#xA;</ol>&#xA;&#xA;<p>Which of these approaches would be the most appropriate?</p>&#xA;"
44610425,Good practices to propagate errors through micro services,2017-06-17 23:41:37,<rest><api><http><microservices><restful-architecture>,2,445,3,0.0,6,"<p>We have a micro services architecture and we are having some discussions about how to expose internal errors to the client.</p>&#xA;&#xA;<p>Here's an example:</p>&#xA;&#xA;<p>Let's suppose we have 3 services, service A, B and C.&#xA;When the client sends a request to the service A, which is public, this service sends a request to service B that sends a request to service C (which are internal and needs authentication, but the credentials are stored internally like environment variables, they are not send by the client).</p>&#xA;&#xA;<p>And for some reason the communication between B and C receives a 401 (could be 422, 403 or any client related errors), which means that the request was not authorized.</p>&#xA;&#xA;<p>Something like that:<a href=""https://i.stack.imgur.com/NmQB7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NmQB7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The communication between B and C is internal, the user don't know about these services. Should I expose our internal structure sending a 401 to the client? Given it's not the client's fault? Should I send a 500?</p>&#xA;"
31573823,Microservice Composition Approaches,2015-07-22 20:55:23,<web-services><architecture><microservices>,4,2048,0,3.0,6,"<p>I have a question for the microservices community. I'll give an example from the educational field but it applies to every microservices architecture.</p>&#xA;&#xA;<p>Let's say I have <strong>student-service</strong> and <strong>licensing-service</strong> with a business requirement that the number of students is limited by a license. So every time a student is created a licensing check has to be made. There are multiple types of licenses so the type of the license would have to be included in the operation.</p>&#xA;&#xA;<p>My question is which approach have you found is better in practice:</p>&#xA;&#xA;<ol>&#xA;<li>Build a composite service that calls the 2 services</li>&#xA;<li>Coupling student-service to licensing-service so that when createStudent is called the student-service makes a call to licensing-service and only when that completes will the student be created</li>&#xA;<li>Use an event-based architecture</li>&#xA;</ol>&#xA;&#xA;<p>People talk about microservice architectures being more like a graph than a hierarchy and <strong>option 1</strong> kinda turns this into a hierarchy where you get increasingly coarse composites. Other downsides is it creates confusion as to what service clients should actually use and there's some duplication going on because the composites API would have to include all of the parameters that are needed to call the downstream services.&#xA;It does have a big benefit because it gives you a natural place to do failure handling, choreography and handle consistency.</p>&#xA;&#xA;<p><strong>Option 2</strong> seems like it has disadvantages too:</p>&#xA;&#xA;<ul>&#xA;<li><p>the API of licensing would have to leak into the student API so that you can specify licensing restrictions. </p></li>&#xA;<li><p>it puts a lot of burden on the student-service because it has to handle consistency across all of the dependent services</p></li>&#xA;<li>as more services need to react when a student is created I could see the dependency graph quickly getting out of control and the service would have to handle that complexity in addition to the one from its own logic for managing students.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Option 3</strong> While being decoupling heaven, I don't really think would work because this is all triggered from an UI and people aren't really used to ""go do something else until this new student shows up"" approach.</p>&#xA;&#xA;<p>Thank you </p>&#xA;"
42140285,How to implement a microservice Event Driven architecture with Spring Cloud Stream Kafka and Database per service,2017-02-09 15:12:27,<apache-kafka><spring-cloud><microservices><spring-cloud-stream><spring-kafka>,2,2318,0,5.0,6,"<p>I am trying to implement an event driven architecture to handle distributed transactions. Each service has its own database and uses Kafka to send messages to inform other microservices about the operations.</p>&#xA;&#xA;<p>An example:</p>&#xA;&#xA;<pre><code> Order service -------&gt; | Kafka |-------&gt;Payment Service&#xA;       |                                       |&#xA;Orders MariaDB DB                   Payment MariaDB Database&#xA;</code></pre>&#xA;&#xA;<p>Order receives an order request. It has to store the new Order in its DB and publish a message so that Payment Service realizes it has to charge for the item:</p>&#xA;&#xA;<p>private OrderBusiness orderBusiness;    </p>&#xA;&#xA;<pre><code>@PostMapping&#xA;public Order createOrder(@RequestBody Order order){&#xA;    logger.debug(""createOrder()"");&#xA;    //a.- Save the order in the DB&#xA;    orderBusiness.createOrder(order);&#xA;    //b. Publish in the topic so that Payment Service charges for the item.&#xA;    try{&#xA;        orderSource.output().send(MessageBuilder.withPayload(order).build());&#xA;    }catch(Exception e){&#xA;        logger.error(""{}"", e);&#xA;    }&#xA;    return order;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>These are my doubts:</p>&#xA;&#xA;<ol>&#xA;<li>Steps a.- (save in Order DB) and b.- (publish the message) should be performed in a transaction, atomically. How can I achieve that?</li>&#xA;<li>This is related to the previous one: I send the message with: orderSource.output().send(MessageBuilder.withPayload(order).build()); This operations is asynchronous and ALWAYS returns true, no matter if the Kafka broker is down. How can I know that the message has reached the Kafka broker?</li>&#xA;</ol>&#xA;"
44043159,How do I include end-to-end tests across microservices into multiple continuous delivery pipelines?,2017-05-18 08:59:34,<automated-tests><microservices><end-to-end><continuous-delivery><ase>,1,259,1,1.0,6,"<p>My team develops three microservices. The three work together to provide a business scenario. They communicate with REST and RabbitMQ. Looks like in <a href=""https://martinfowler.com/articles/microservice-testing/#testing-end-to-end-diagram"" rel=""noreferrer"">Toby Clemson's presentation on Microservice Testing</a>.</p>&#xA;&#xA;<p>Each microservice has its own continuous delivery pipeline. They are <em>delivery</em>, not <em>deployment</em> pipelines, meaning there is a manual release decision at the end.</p>&#xA;&#xA;<p><strong>How do I include an end-to-end test for the <em>business scenario</em>, i.e. across all microservices, into the delivery pipelines?</strong></p>&#xA;&#xA;<p>My team suggested this:</p>&#xA;&#xA;<p>We add one <em>shared</em> end-to-end stage that deploys all three microservices and runs the end-to-end test on them. Each time one of the pipelines reaches this stage, it deploys and tests. A semaphore ensures the pipelines pass the stage one after the other. Failure stops all three pipelines.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ODu29.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ODu29.png"" alt=""Shared end-to-end stage""></a></p>&#xA;&#xA;<p>To me, this seems to sacrifice all the independence the microservice architecture wins in the first place:</p>&#xA;&#xA;<ul>&#xA;<li><p>The end-to-end stage is a bottleneck. A fast pipeline could thwart slow pipelines because it reserves the end-to-end stage more often, making the others wait before they may run their tests.</p></li>&#xA;<li><p>Failure in one pipeline would stop the other pipelines from delivering, also disabling them from shipping urgent bug fixes.</p></li>&#xA;<li><p>The solution doesn't adapt to new business scenarios that need different combinations of microservices. We would either end up with a super-stage that wires all microservices, or each business scenario would require its own, new end-to-end stage.</p></li>&#xA;<li><p>The end-to-end stage shows only a narrow result because it confirms only that one exact combination of microservice versions work together. If production contains different versions, it does not guarantee this will work as well.</p></li>&#xA;<li><p>The stage is also in conflict with the manual release decision at the end: What if a build passed end-to-end but we decide to not release it to production? Production would then contain a different version of that microservice than end-to-end, causing warped results.</p></li>&#xA;</ul>&#xA;&#xA;<p><strong>So what's a better way to do this?</strong></p>&#xA;"
44065208,Data integrity across the databases of different Microservices,2017-05-19 08:37:06,<database><foreign-keys><relational-database><rdbms><microservices>,1,801,4,0.0,6,"<p>Let's say I am using relational databases for my microservices. I have <code>CustomersMService</code> which has its own database with table <code>Customer</code>, then I have <code>OrdersMService</code> which also has its own database but with table <code>Order</code> and that table has column <code>CustomerId</code>. My question is how can I ensure data integrity between databases, that <code>Orders</code> table won't point to non-existent Customers?</p>&#xA;"
38565470,Can Service Fabric Cluster Maintains the old versions of a service?,2016-07-25 10:35:16,<azure><microservices><azure-service-fabric>,1,327,1,0.0,6,"<p>I have a Micro Service in service fabric cluster which is a V1 for example. Now I upgraded it to the new version lets say v2. After a successful upgrade, Service Fabric replaced the old version with the new version of micro service. But I want to have and communicate with both versions of services. Can I achieve this in Service Fabric? If yes can anyone help me out on this?</p>&#xA;&#xA;<p>-Kishore.</p>&#xA;"
38627025,Golang Microservices can't communicate using Docker for Mac,2016-07-28 04:18:45,<go><docker><microservices>,1,313,2,2.0,6,"<p>I am trying to get two containers that are each running a different golang service. Both services were built with the <code>net/http</code> package. I have an API frontend as one and an Authentication service backend.</p>&#xA;&#xA;<p>Here is my compose file:</p>&#xA;&#xA;<pre><code>version: ""2""&#xA;services:&#xA;  staticfiles:&#xA;    build: ./files&#xA;    volumes:&#xA;      - /public&#xA;      - /views&#xA;  api:&#xA;    build: ./api&#xA;    environment:&#xA;      - PORT=8080&#xA;      - BASE_URL=https://example.org&#xA;      - AUTH_HOST=auth&#xA;      - AUTH_PORT=8080&#xA;      - VIEW_DIR=/views&#xA;      - PUBLIC_DIR=/public&#xA;    ports:&#xA;      - ""80:8080""&#xA;    volumes_from:&#xA;      - staticfiles:ro&#xA;    links:&#xA;      - auth&#xA;    depends_on:&#xA;      - staticfiles&#xA;  db:&#xA;    build: ./postgres&#xA;    environment:&#xA;      - POSTGRES_USER=inheritor&#xA;      - POSTGRES_DB=inheritor&#xA;  auth:&#xA;    build: ./auth&#xA;    expose:&#xA;      - ""8080""&#xA;    environment:&#xA;      - PORT=8080&#xA;      - DB_USER=inheritor&#xA;      - DB_NAME=inheritor&#xA;      - DB_HOST=db&#xA;      - DB_Port=5432&#xA;    links:&#xA;      - db&#xA;</code></pre>&#xA;&#xA;<p>I know the links are working because from the api container I can <code>ping auth</code> and <code>curl -X Post http://auth:8080/validate</code> but within golang I get a <code>dial address tcp i/o timeout</code>. Here is the golang code.</p>&#xA;&#xA;<pre><code>var (&#xA;    authString = ""http://"" + env.AuthHost + "":"" + env.AuthPort&#xA;)&#xA;&#xA;//ValidateToken validates a token using the session in DB&#xA;func ValidateToken(req *model.ValidateRequest) (*model.JWTClaims, error) {&#xA;    client := new(http.Client)&#xA;    api := authString + ""/validate""&#xA;    cont, err := model.Jsonify(req)&#xA;    if err != nil {&#xA;        return nil, exception.NewInternalError(""Could not turn the request into a json object."")&#xA;    }&#xA;&#xA;    request, err := http.NewRequest(""POST"", api, bytes.NewBuffer(cont))&#xA;    if err != nil {&#xA;        return nil, exception.NewInternalError(""Could not create request: "" + err.Error())&#xA;    }&#xA;    request.Header.Set(""Content-type"", ""application/json"")&#xA;    response, err := client.Do(request)&#xA;    if err != nil {&#xA;        return nil, exception.NewInternalError(""Could not make the request: "" + err.Error())&#xA;    }&#xA;    defer response.Body.Close()&#xA;&#xA;    res := new(model.AuthResponse)&#xA;    res.Claims = new(model.JWTClaims)&#xA;    decoder := json.NewDecoder(response.Body)&#xA;    err = decoder.Decode(&amp;res)&#xA;    spew.Dump(response.Body)&#xA;    if err != nil {&#xA;        return nil, exception.NewInternalError(""Could not parse response back from auth service. "" + err.Error())&#xA;    }&#xA;&#xA;    if response.StatusCode != http.StatusOK {&#xA;        return nil, exception.NewInvalidJWTError(res.Error)&#xA;    }&#xA;&#xA;    return res.Claims, nil&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The <code>client.Do(request)</code> is what is throwing the Dial error. Now my auth service is not even being touched because I have a logger that prints to screen every request that is coming in. </p>&#xA;&#xA;<ul>&#xA;<li><code>env.AuthHost</code> is mapped to the <code>AUTH_HOST</code> environment variable.</li>&#xA;<li><code>env.AuthPort</code> is mapped to the <code>Auth_PORT</code> environment variable.</li>&#xA;</ul>&#xA;&#xA;<p>Much help is appreciated.</p>&#xA;&#xA;<p>If it helps I am running MacOSX.</p>&#xA;&#xA;<pre><code>Client:&#xA; Version:      1.12.0-rc4&#xA; API version:  1.24&#xA; Go version:   go1.6.2&#xA; Git commit:   e4a0dbc&#xA; Built:        Wed Jul 13 03:28:51 2016&#xA; OS/Arch:      darwin/amd64&#xA; Experimental: true&#xA;&#xA;Server:&#xA; Version:      1.12.0-rc4&#xA; API version:  1.24&#xA; Go version:   go1.6.2&#xA; Git commit:   e4a0dbc&#xA; Built:        Wed Jul 13 03:28:51 2016&#xA; OS/Arch:      linux/amd64&#xA; Experimental: true&#xA;</code></pre>&#xA;&#xA;<p>Both golangs <code>Dockerfile</code> looks like this:</p>&#xA;&#xA;<pre><code>FROM golang:1.6&#xA;RUN mkdir -p /go/src/github.com/dixonwille/Inheritor/api&#xA;WORKDIR /go/src/github.com/dixonwille/Inheritor/api&#xA;&#xA;COPY . /go/src/github.com/dixonwille/Inheritor/api&#xA;&#xA;RUN go build -v -o Inheritor cmd/Inheritor/main.go&#xA;&#xA;USER nobody&#xA;ENTRYPOINT [""./Inheritor""]&#xA;</code></pre>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>So I ran <code>net.LookupHost(env.AuthHost)</code> within golang and it is returning a different IP address then <code>ping</code>, <code>curl</code>, and even <code>docker inspect</code>. Is this a golang thing then?</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>Sorry for all the edits kind of trying to debug as the day goes.</p>&#xA;&#xA;<p>If I remove the port portion of the <code>authString</code>, the request goes through but get an error when parsing response. The response is a 301 redirect by NGINX which I think is strange because that is not even in my stack. The location header for the redirect is <code>localhost</code>, which I think is strange as well.</p>&#xA;&#xA;<p>I have tried exposing a port on the host machine and accessing it with that port with no better luck (same hostname).</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>So it is a Mac only thing I assume. I cloned down the repo and ran on Windows 10 and I was able to connect to my auth service. Would this be Docker for Mac error? I am probably going to report it to them, but I would not consider this closed since it still is an issue for Mac users.</p>&#xA;"
43290480,Using celery to build microservices,2017-04-08 05:19:33,<python-2.7><celery><microservices><celerybeat>,1,1023,0,3.0,6,"<p>I am going break down a project into small microservices.</p>&#xA;&#xA;<p>All microservices are cron-based. I am thinking of celery as a task distribution as well a mechanism to run periodic tasks (celerybeat).</p>&#xA;&#xA;<p>I don't want to build multiple celery app per microserverice as that will increase overhead of having multiple brokers and multiple flower system to use for monitoring.</p>&#xA;&#xA;<p>I tried with single app on multiple servers but I failed. My needs with celery are :</p>&#xA;&#xA;<ol>&#xA;<li>I need to have independent servers for each microservice </li>&#xA;<li>Task belonging to certain microservice should execute only on their servers; no sharing of task among other servers</li>&#xA;<li>In case microservice is down i don't want celerybeat to clog the broker with thousands of pending tasks, resulting in halting service at other microservices. </li>&#xA;<li>In do not have any need of communication between microservices.</li>&#xA;</ol>&#xA;&#xA;<p>I tried separating queues per worker which doesn't seem to be possible&#xA;I tried one worker per server but i need more than one worker on per microservices</p>&#xA;"
43179951,Business data querying/reporting in service oriented architecture,2017-04-03 08:33:41,<database><reporting><soa><microservices><database-replication>,2,254,7,1.0,6,"<p>For the better part of the last year my company has been slicing up a monolith and building new products upon principles of (micro) service architecture. This is all fine and gives us great flexibility in keeping UI and backend logic separate and lowering the amount of dependencies.</p>&#xA;&#xA;<p>BUT!</p>&#xA;&#xA;<p>There is an important part of our business that has a growing headache as a result of this, namely reporting.</p>&#xA;&#xA;<p>Since we make sure that there is no data replication (and business logic sharing) between services, then each service knows its own data and if another service really needs to keep a reference for that data, they do it through ID's (entity linking, essentially). And while otherwise its great, it's not great for reporting.</p>&#xA;&#xA;<p>Our business often needs to create ad-hoc reports about specific instances happening with our customers. In the 'old days' you made a simple SQL query that joined a couple of database tables and queried whatever you needed, but it is not possible with decoupled services. And this is a problem as business sees it.</p>&#xA;&#xA;<p>I am personally not a fan of data replication for reporting purposes in the back end, as that may have another tendency to grow into a nightmare (which it already is even in our legacy monoliths). So this problem is really not about legacy monoliths versus modern microservices, but about data dependencies in general.</p>&#xA;&#xA;<p>Have you faced issues like this and if yes, then how did you solve it?</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>We have been discussing in-house the few potential solutions how to solve this, but none of them are actually good and I've not gotten the answer I am looking for yet that solves the issues in large scale.</p>&#xA;&#xA;<ol>&#xA;<li><p>Good old replicate-everything-and-let-BI-people-figure-it-out is what is still used to this day. From the old monolith times the BI/data-warehouse team made duplicates of all databases, but same practice is more inconvenient, but still done to this day for all microservices that use a database. This is not good for various reasons and comes with the shared sandbox cancer you can expect.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that are meant for fetching out specific reports. Each of them connect to set microservices that carries the relevant data and builds the report as expected. This introduces tighter coupling however and can be incredibly complicated and slow with large datasets.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that each have databases replicated from other databases in background. This is problematic as team databases are being coupled and data is directly replicated and there is a strong dependency on technology of databases that is being used.</p></li>&#xA;<li><p>Have each service send out an event to RabbitMQ that BI services would pick up on and then fetch additional data, if needed. It sounds by far the best for me, but by far the most complex to implement as all services need to start publishing relevant data. It is what I would personally choose at present time, from a very abstract level, that is.</p></li>&#xA;</ol>&#xA;"
34023438,microservices: How to model related domain objects?,2015-12-01 15:02:03,<soa><microservices>,1,353,0,1.0,6,"<p>I have 2 domain objects: Project and Contract. A project can have many contracts so in the database it is modeled as a classic one-to-many relationship. Our question is this: How do you model the above in the context of microservices? Do you (a) have 2 microservices ProjectService and ContractService? or (b) Do you have one ProjectService which encompasses both Projects and Contracts?</p>&#xA;&#xA;<p>We are thinking that answer (a) (i.e. 2 microservices ProjectService and ContractService) implies that one would have to call 2 services to retrieve and save the complete Project object hierarchy. On the other hand, answer (a) completely decouples Projects from Contracts which may be a good thing in theory, but practically useless since a Contract cannot logically exist without a Project.</p>&#xA;&#xA;<p>What is the correct approach here? Is answer (a) an example of the nano service anti pattern?</p>&#xA;"
33952306,"Microservice, amqp and service registry / discovery",2015-11-27 07:31:10,<rest><architecture><amqp><microservices><service-discovery>,1,767,1,1.0,6,"<p>I m studying Microservices architecture and I m actually wondering something.</p>&#xA;&#xA;<p>I m quite okay with the fact of using (back) service discovery to make request able on REST based microservices. I need to know where's the service (or at least the front of the server cluster) to make requests. So it make sense to be able to discover an ip:port in that case.</p>&#xA;&#xA;<p>But I was wondering what could be the aim of using service registry / discovery when dealing with AMQP (based only, without HTTP possible calls) ?</p>&#xA;&#xA;<p>I mean, using AMQP is just like ""I need that, and I expect somebody to answer me"", I dont have to know who's the server that sent me back the response.</p>&#xA;&#xA;<p>So what is the aim of using service registry / discovery with AMQP based microservice ?</p>&#xA;&#xA;<p>Thanks for your help</p>&#xA;"
34794630,Micro service security,2016-01-14 16:25:39,<c#><microservices>,2,1298,7,2.0,6,"<p>Over the last few days I've been playing with the micro service pattern and all is going well but security seems to baffle me.</p>&#xA;&#xA;<p><strike>&#xA;So If I may ask a question:&#xA;How do I handle user authentication on an individual service? At the moment I pass a request to the <code>Gateway API</code> which in turns connects to the service.&#xA;</strike></p>&#xA;&#xA;<p><strong>Question Edited Please See Below</strong></p>&#xA;&#xA;<p>Bearing in mind that the individual services should not know about each other. The <code>Gateway</code> is the aggregator as such. </p>&#xA;&#xA;<p><strong>Current architecture.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/60tiY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60tiY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>A little code to simulate the request:</p>&#xA;&#xA;<p><strong>Frontend - Client App</strong></p>&#xA;&#xA;<pre><code>public class EntityRepository&lt;T&gt;&#xA;{&#xA;    private IGateway _gateway = null;&#xA;    public EntityRepository(IGateway gateway)&#xA;    {&#xA;        this._gateway = gateway;&#xA;    }&#xA;    public IEnumerable&lt;T&gt; FindAll()&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;IEnumerable&lt;T&gt;&gt;().Result;&#xA;    }&#xA;    public T FindById(int id)&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;T&gt;().Result;&#xA;    }&#xA;    public void Add(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Update(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Save(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;}&#xA;&#xA;&#xA;   //Logic lives elsewhere&#xA;   public HttpResponseMessage Get(Type type)&#xA;   {&#xA;      return Connect().GetAsync(Path(type)).Result;&#xA;   }&#xA;   public HttpResponseMessage Post(Type type, dynamic obj)&#xA;   {&#xA;      return Connect().PostAsync(Path(type), obj);&#xA;   }&#xA;    private string Path(Type type)&#xA;    {&#xA;        var className = type.Name;&#xA;        return ""api/service/"" + Application.Key + ""/"" + className;&#xA;    }&#xA;    private HttpClient Connect()&#xA;    {&#xA;        var client = new HttpClient();&#xA;        client.BaseAddress = new Uri(""X"");&#xA;&#xA;        // Add an Accept header for JSON format.&#xA;         client.DefaultRequestHeaders.Accept.Add(&#xA;         new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;&#xA;        return client;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>I use generics to determine where it needs to fire once it hit's the gateway.&#xA;So if the <code>Type</code> is <strong>Category</strong> it will fire the <strong>Category</strong> service thus calling:</p>&#xA;&#xA;<pre><code>public IEnumerable&lt;dynamic&gt; FindAll(string appKey, string cls)&#xA;{&#xA;    var response = ConnectTo.Service(appKey, cls);&#xA;    return (appKey == Application.Key) ? (response.IsSuccessStatusCode) ? response.Content.ReadAsAsync&lt;IEnumerable&lt;dynamic&gt;&gt;().Result : null : null;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The Gateway does not contain the physical files/Class's of the types.</p>&#xA;&#xA;<p>After a little code, I was hoping someone could give me a little demonstration or the best approach to handle security/user authentication with the current architecture.</p>&#xA;&#xA;<p><strong>Case Scenario 1</strong>&#xA;User hits the web app and logs in, at that point the users encrypted email and password is sent to the <code>Gateway API</code> which is then passed to the <code>User Service</code> and decides whether the user is authenticated - all well and good but now I want to fetch all Messages from the <code>Message Service</code> that the user has received. I cannot really say in the Gateway if the user is authenticated, fetch the messages because that does not solve the issue of calling the <code>Message Service</code> outside of the <code>Gateway API</code></p>&#xA;&#xA;<p>I also cannot add authentication to each individual service because that would require all respective services talking to the <code>User Service</code> and that defeats the purpose of the pattern.</p>&#xA;&#xA;<p><strong>Fixes:</strong>&#xA;Only allow the Gateway to call the Services. Requests to services outside of the Gateway should be blocked.</p>&#xA;&#xA;<p>I know security is a broad topic but within the current context, I'm hoping someone could direct me with the best course of action to resolve the issue.</p>&#xA;&#xA;<p>Currently I have Hardcoded a <code>Guid</code> in all off the applications, which in turn fetches data if the app is equal.</p>&#xA;"
31047564,How to get a visualization of cross-app Spring Integration flow?,2015-06-25 10:19:06,<java><spring-integration><esb><microservices>,2,892,2,2.0,6,"<p>We have a microservices architecture, i.e. each of the main components of our system is designed to be run as a separate Java app (jar or war).</p>&#xA;&#xA;<p>We use Spring Integration to facilitate communication between the components (over a MQ service).</p>&#xA;&#xA;<p><strong>How can we get a graphical diagram of the whole integration layer of the system, given that each component has its own Spring Integration XML config?</strong></p>&#xA;&#xA;<p>Note that we know how to do it within a single application. The question is how to do it cross-app.</p>&#xA;&#xA;<p>Example: &#xA;Component 1 generates stream of POJOs -> MQ -> Component 2 serializes POJO object graph to JSON -> MQ -> Component 3 saves JSON to DB</p>&#xA;&#xA;<p>Also, if a viable solution would be to create a single Spring Integration config, then how to make sure all components use it?</p>&#xA;"
35882330,how to get my configuration values in yml - using dropwizard (microservice) Jersey D.I @Injection?,2016-03-09 03:26:41,<java><jersey><dropwizard><inject><microservices>,1,4347,0,2.0,6,"<p>here's my code snippets.</p>&#xA;&#xA;<p>here's my yml file:</p>&#xA;&#xA;<pre><code>productionServer:&#xA;  host: production-server.amazonaws.com&#xA;  publicIp: xx.xx.xx.xx&#xA;  privateIp: xx.xx.xx.xx&#xA;  userName: xx.xx.xx.xx&#xA;  password: xx.xx.xx.xx&#xA;  remoteFilePath: fake/path/&#xA;  fileName: test.txt&#xA;  privateKey: private-public-key.ppk&#xA;&#xA;server:&#xA;  applicationConnectors:&#xA;    - type: http&#xA;      port: 8080&#xA;    - type: https&#xA;      port: 8443&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;  adminConnectors:&#xA;    - type: http&#xA;      port: 8081&#xA;    - type: https&#xA;      port: 8444&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;</code></pre>&#xA;&#xA;<p>MyConfiguration class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Configuration;&#xA;&#xA;public class MyConfiguration extends Configuration{&#xA;&#xA;    @NotNull&#xA;    @JsonProperty&#xA;    private ProductionServer productionServer;&#xA;&#xA;    // getters&#xA;&#xA;public class ProdctionServer{&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private host;&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private publicIp;&#xA;&#xA;      // getters&#xA;</code></pre>&#xA;&#xA;<p>Application class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Application;&#xA;&#xA;public class MyApplication extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    public static void main(String[] args) throws Exception{&#xA;        new MysApplication().run(args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public String getName(){ return ""micro-service""; }&#xA;&#xA;    @Override&#xA;    public void initialize(Bootstrap&lt;MyConfiguration&gt; bootstrap){}&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration conf, Environment environment ){&#xA;        final MyResource myResource = new MyResource();&#xA;        // health check&#xA;&#xA;        // environment.healthChecks().register(""template"",healthCheck);&#xA;&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println( ""==&gt; "" + conf.getProductionServer() );&#xA;&#xA;        // register&#xA;        environment.jersey().register( MyResource );&#xA;</code></pre>&#xA;&#xA;<p>and when running this app:</p>&#xA;&#xA;<p>i received a logged as follows:</p>&#xA;&#xA;<pre><code>==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@623e088f, io.dropwizard.jetty.HttpsConnectorFactory@39fcbef6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34f22f9d, io.dropwizard.jetty.HttpsConnectorFactory@77d67cf3], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@663411de]}}&#xA;==&gt; com.mycompany.myproject.model.ProductionServer@5b04476e&#xA;</code></pre>&#xA;&#xA;<p>meaning it is successfully gets the value of my yaml.&#xA;but my problem is during the D.I or dependency injection of MyConfiguration class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service. </p>&#xA;&#xA;<p>here's my code snippet of dependency binding the MyService.class and the MyConfiguration.class </p>&#xA;&#xA;<p>DependencyBinder.class</p>&#xA;&#xA;<p>import org.glassfish.hk2.utilities.binding.AbstractBinder;</p>&#xA;&#xA;<p>public class DependencyBinder extends AbstractBinder {</p>&#xA;&#xA;<pre><code>@Override&#xA;protected void configure() {&#xA;    bind(MyConfiguration.class).to(MyConfiguration.class);&#xA;    bind(MyService.class).to(MyService.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>public class MyService {&#xA;&#xA;    @Inject&#xA;    MyConfiguration conf;&#xA;&#xA;    public void invoke(){&#xA;        System.out.println( ""=============================== "" );&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println(""==&gt; "" + conf.getProductionServer() );&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>and during the invoking of the method invoke()...&#xA;i got a logged as follows:</p>&#xA;&#xA;<pre><code>=============================== &#xA;==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34e82c4d], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@19b70fbd], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@543f81c9]}}&#xA;==&gt; null&#xA;</code></pre>&#xA;&#xA;<p>now my problem is during the D.I or dependency injection of MyConfiguration class in MyService.class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service.&#xA;please give me some resolution? thnx.</p>&#xA;"
42484087,Microservice: Service discovery and Service Registry with Akka,2017-02-27 11:01:10,<akka><microservices>,1,535,2,2.0,6,<p>I'm going to apply Microservices architecture for my application. The internal communication between microservices will be achieved by using Akka. But I don't know how to make all microservices aware and register each other. I have some options to design Service Registry and Discovery:</p>&#xA;&#xA;<p>1) Use Zookeeper as a centrailized service to hold all metadata of all microservices (nodes) and let them access these metadata to communicate. The metadata of each node contains Akka path (address) information to let the other nodes communicate to.</p>&#xA;&#xA;<p>2) Join all microservices (Akka Nodes) to an Akka Cluster and each node will keep reference of each other to communicate. Akka Cluster supports gossip protocol and it will let all nodes in cluster aware together.</p>&#xA;&#xA;<p>Can anybody give me some advices about this? How to design Service Discovery and Service Registry efficiently on top of Akka? Are there any options for this?</p>&#xA;
45453061,What is the difference between microservices and webservices?,2017-08-02 06:29:44,<web-services><microservices>,3,3866,1,1.0,6,"<p>The closest I got to finding the actual difference is this <a href=""http://www.tatvasoft.com/blog/the-difference-between-micro-services-and-web-services/"" rel=""nofollow noreferrer"">article</a>.</p>&#xA;&#xA;<p>But I didn't understand what would make me choose one over the other and if microservices can also use a REST API and communicate via http.</p>&#xA;&#xA;<p>I mainly didn't understand what a microservice is and if it can come instead of a webservice, other than the purpose of </p>&#xA;&#xA;<blockquote>&#xA;  <p>breaking large software applications into loosely coupled modules</p>&#xA;</blockquote>&#xA;"
45510905,Authentication to access Spring boot Zuul Service routes,2017-08-04 15:47:31,<spring-mvc><spring-boot><microservices><netflix-eureka><netflix-zuul>,1,938,3,2.0,6,"<p>I have configured my micro services using Spring boot zuul and eureka services. &#xA;Now I need to authenticate all routes/REST API calls.&#xA;I mean, for all APIs client send one accessToken. &#xA;On zuul service, before routing to the particular service, I have to call a micro service (auth-service) with accessToken and that auth-service will check the user exists or not for the accessToken sent.&#xA;If the accessToken is valid then only routing should happen.</p>&#xA;&#xA;<p>Please help me to implement this using spring boot service.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
37830008,Handling multiple event dependency in event-driven architecture,2016-06-15 08:28:15,<publish-subscribe><microservices><event-driven>,2,348,0,2.0,6,<p>What would be best practice if you have an event-driven architecture and a service subscribing to events has to wait for multiple event (of the same kind) before proceeding with creating the next event in the chain?</p>&#xA;&#xA;<p>An example would be a book order handling service that has to wait for each book in the order to have been handled by the warehouse before creating the event that the order has been picked so that the shipping service (or something similar) picks up the order and starts preparing for shipping.</p>&#xA;
40938088,Microservices in practice,2016-12-02 17:44:43,<spring><docker><cloud><microservices><docker-swarm>,1,387,1,1.0,6,"<p>I have studied concept of microservices for a good while now, and understand what they are are and why they are necessary.</p>&#xA;&#xA;<p><strong>Quick refresher</strong></p>&#xA;&#xA;<p>In a nutshell, monolith application is decomposed into independent deployable units, each of which typically exposes it's own web API and has it's own database. Each service fulfills a single responsibility and does it well. These services communicates over synchronous web services such as REST or SOAP, or using asynchronous messaging such as JMS to fulfill some request in synergy. Our monolith application has became a distributed system. Typically all these fine grained APIs are made available through an API gateway or proxy, which acts as an single-point-of-entry facade, performing security and monitoring related tasks.</p>&#xA;&#xA;<p>Main reasons to adapt microservices is high availability, zero downtime update and high performance achieved via horizontal scaling of a particular service, and looser coupling in the system, meaning easier maintenance. Also, IDE functionality, build and deployment process will be significantly faster, and it's easier to change framework or even the language.</p>&#xA;&#xA;<p>Microservices goes hand in hand with clustering and containerization technologies, such as Docker. Each microservice could be packed as a docker container to run it in any platform. Principal concepts of clustering are <em>service discovery</em>, <em>replication</em>, <em>load balancing</em> and <em>fault tolerance</em>. Docker Swarm is a clustering tool which orchestrates these containerized services, glues them together, and handles all those tasks under the hood in a declarative manner, maintaining the desired state of the cluster.</p>&#xA;&#xA;<p>Sounds easy and simple in theory, but I still don't understand how to implement this in practice, even I know Docker Swarm pretty well. Let's view an concrete example.</p>&#xA;&#xA;<p><strong>Here is the question</strong></p>&#xA;&#xA;<p>I'm building a simplistic java application with <em>Spring Boot</em>, backed by <em>MySQL</em> database. I want to build a system, where user gets a webpage from <em>Service A</em> and submits a form. <em>Service A</em> will do some manipulation to data and sends it to <em>Service B</em>, which will further manipulate data, write to database, return something and in the end some response is sent back to user.</p>&#xA;&#xA;<p>Now the problem is, <em>Service A</em> doesn't know where to find <em>Service B</em>, nor <em>Service B</em> know where to find <em>database</em> (because they could be deployed at any node in the cluster), so I don't know how I should configure the Spring boot application. First thing to come in my mind is to use DNS, but I can't find tutorials how to setup such a system in docker swarm. What is the correct way to configure connection parameters in Spring for distributed cloud deployment? I have researched about Spring Cloud project, but don't understand if it's the key for this dilemma.</p>&#xA;&#xA;<p>I'm also confused how databases should be deployed. Should they live in the cluster, deployed alongside with the service (possibly with aid of docker compose), or is it better to manage them in more traditional way with fixed IP's?</p>&#xA;&#xA;<p>Last question is about load balancing. I'm confused if there should be multiple load balancers for each service, or just a single master load balancer. Should the load balancer has a static IP mapped to a domain name, and all user requests target this load balancer? What if load balancer fails, doesn't it make all the effort to scale the services pointless? Is it even necessary to setup a load balancer with Docker Swarm, as it has it's own routing mesh? Which node end user should target then?</p>&#xA;"
40856925,Microservices: database and microservice instances,2016-11-29 02:42:17,<microservices><instances><horizontal-scaling>,3,873,3,1.0,6,"<p>Lets say we have a microservice A and a B. B has its own database. However B has to be horizontally scaled, thus we end up having 3 instances of B. What happens to the database? Does it scale accordingly, does it stays the same (centralized) database for the 3 B instances, does it become a distributed database, what happens?</p>&#xA;"
40660618,AWS API Gateway + Elastic Beanstalk and Microservices,2016-11-17 16:49:51,<amazon-web-services><elastic-beanstalk><microservices><aws-api-gateway>,1,4604,1,3.0,6,"<p>I'm going to build microservices' architecture on AWS and I want to ask you to clarify my doubts.</p>&#xA;&#xA;<p><strong>My current general concept</strong></p>&#xA;&#xA;<p>I would like to use API Gateway, which exposes microsevices' APIs running in Elastic Beanstalk. I would like to place the Elastic Beanstalk in VPC without direct access from Internet to its instances.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6BQi4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6BQi4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Questions &amp; Doubts:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Elastic Beanstalk gets subdomain on application creation. This subdomain should be used by API Gateway with integration type: AWS service, in action configuration - Am I right?</li>&#xA;<li>What would represent a single microservice? An Elastic Beanstalk's application is a specific scalable microservice?</li>&#xA;<li>How the microservices should communicate with each other? There would be some task where Im going to use SQS (Simple Queue Service). But in other cases, is it better when two microservices communicates with each other through API Gateway rather than directly - am I right?</li>&#xA;<li>Test environment: What structure should I use in test environment (or staging env.)? I think about creating separate VPC with another Elastic Beanstalk and other Amazon services.</li>&#xA;<li>Test environment and API Gateway: How should I set up an API Gateway? It should allow clients to access the microservices in test environment if request has specific subdomain, like: test.mydomain.com/hello_world/say_hello. I'm not sure how to use API Gateway in CI/CD to make it fast and simple, without manual copying some configuration from test stage to the production stage. (I'm not expecting any complex solution, only some hints about what components, parts, concepts could I use for it. More details I'll find on my own).</li>&#xA;<li>Have you any experience in deploying apps to Elastic Beanstalk using Codep Deploy and/or Jenkins? I'm interesting in which way could be better: Jenkins, AWS Code Deploy or Jenkins+CodeDeploy.</li>&#xA;</ol>&#xA;"
47918407,Microservice architecture - carry message through services when order doesn't matter,2017-12-21 05:21:21,<design-patterns><architecture><rabbitmq><message-queue><microservices>,2,521,0,3.0,6,"<p><strong>Tl;dr</strong>: ""How can I push a message through a bunch of asynchronous, unordered microservices and know when that message has made it through each of them?""</p>&#xA;&#xA;<p>I'm struggling to find the right messaging system/protocol for a specific microservices architecture. This isn't a ""which is best"" question, but a question about what my options are for a design pattern/protocol.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/MbHRf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/MbHRf.png"" alt=""Diagram""></a></p>&#xA;&#xA;<ul>&#xA;<li>I have a <em>message</em> on the beginning queue. Let's say a RabbitMQ message with serialized JSON</li>&#xA;<li>I need that message to go through an arbitrary number of microservices</li>&#xA;<li>Each of those microservices are long running, must be independent, and may be implemented in a variety of languages</li>&#xA;<li>The order of services the message goes through does not matter. In fact, it should not be synchronous.</li>&#xA;<li>Each service can <em>append</em> data to the original message, but that data is ignored by the other services. There should be <em>no</em> merge conflicts (each service writes a unique key). No service will change or destroy data.</li>&#xA;<li>Once <em>all the services have had their turn</em>, the message should be published to a second RabbitMQ queue with the original data and the new data.</li>&#xA;<li>The microservices will have no other side-effects. If this were all in one monolithic application (and in the same language), functional programming would be perfect.</li>&#xA;</ul>&#xA;&#xA;<p>So, the question is, what is an appropriate way to manage that message through the various services? I <strong>don't</strong> want to have to do one at a time, and the order isn't important. But, if that's the case, how can the system know when all the services have had their whack and the final message can be written onto the ending queue (to have the next batch of services have their go).</p>&#xA;&#xA;<p>The only, semi-elegant solution I could come up with was </p>&#xA;&#xA;<ol>&#xA;<li>to have the first service that encounters a message write that message to common storage (say mongodb)</li>&#xA;<li>Have each service do its thing, mark that it has completed for that message, and then check to see if all the services have had their turn</li>&#xA;<li>If so, that last service would publish the message</li>&#xA;</ol>&#xA;&#xA;<p>But that still requires each service to be aware of all the other services <em>and</em> requires each service to leave its mark. Neither of those is desired.</p>&#xA;&#xA;<p>I am open to a ""Shepherd"" service of some kind.</p>&#xA;&#xA;<p>I would appreciate any options that I have missed, and am willing to concede that their may be a better, fundamental design.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
41161769,Authorisation in microservices - how to approach domain object or entity level access control using ACL?,2016-12-15 10:22:31,<spring><security><authorization><acl><microservices>,1,948,2,1.0,6,"<p>I am currently building microservices based system on java Spring Cloud. Some microservices use PostgreSQL and some of them MongoDB. REST and JMS is used for communication. The plan is to use SSO and OAuth2 for authentication</p>&#xA;&#xA;<p>The challenge I am facing is that authorisation have to be done on domain object/entity level. It means some kind of ACL (Access Control List) is needed. The best practice for this kind of architecture is to avoid something like this and have coarse grained security probably on application/service layer level in every microservice but unfortunately it is not possible.</p>&#xA;&#xA;<p>My final idea is to use Spring Security ACL and have the ACL tables in shared database between all microservices. The database would be accessed only by Spring infrastructure or through Spring api. The DB schema looks stable and unlikely will change. In this case I would simply break the rule about sharing db between microservices.</p>&#xA;&#xA;<p>I was considering different kinds of distributed solutions but left them: </p>&#xA;&#xA;<ul>&#xA;<li>One microservice with ACL and accessing it using rest - The problem is too many http calls and performance degradation. I would have to extend Spring Security ACL to replace db access by rest calls</li>&#xA;<li>ACL in every microservice for its own entities - Sounds quite reasonable but imagine a case having some read models of entities synchronised to some other microservices or same entity that exists in different bounded contexts (different microservices). ACLs can become really unmanageable and can be source of errors.</li>&#xA;<li>One microservice with ACL tables that are synchronised to other microservices as a read model. The problem is that there is no support in Spring Security ACL for MongoDB. I have seen some custom solutions on github and yes it is doable. But...when creating a new entity I have to create record in the microservice  that owns ACL and then it is asynchronously synchronised as a read model to microservice owning the entity. It does not sound as a easy solution</li>&#xA;<li>Choose some URL based access control on API gateway. But I would have to modify Spring Security ACL somehow. The API gateway would have to know too much about other services. Granularity of access control is bound to REST api granularity. Maybe I can not imagine all the consequences and other problems that would this approach bring</li>&#xA;<li>Finally the solution with shared db that I mentioned is my favorite. Actually it was the first one I have disqualified because it is â€œsharedâ€ database. But after going through possibilities it seemed to me that this is the only one that would work. There is some more additional complexity in case I would like to use some kind of caching because distributed cache would be needed.</li>&#xA;</ul>&#xA;&#xA;<p>I would really use some advice and opinions how to approach the architecture because this is really tricky and a lot of things can go wrong here.</p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>Lukas</p>&#xA;"
27790905,How to establish relationships between Spring Data REST / Spring HATEOAS based (micro) services?,2015-01-06 01:50:17,<spring-data-rest><hateoas><spring-cloud><microservices>,2,2702,2,3.0,7,"<p>Trying to figure out a pattern for how to handle relationships when using a hypermedia based microservices based on Spring Data Rest or HATEOAS.</p>&#xA;&#xA;<p>If you have service A (Instructor) and Service B (Course) each exist as an a stand alone app.</p>&#xA;&#xA;<p>What is the preferred method for establishing a relationship between the two services.  In a manner that does not require columns for IDs of the foreign service.  It would be possible for each service to have many other services that need to communicate in the same manor.</p>&#xA;&#xA;<p>Possible solution (Not sure a correct path)</p>&#xA;&#xA;<p>Each service has a second table with a OneToMany with the primary entity within the service.  The table would have the following fields:</p>&#xA;&#xA;<p>ID, entityID, rel, relatedID</p>&#xA;&#xA;<p>Then in the opposite service using Spring Data Rest setup a find that queries the join table to find records that match.</p>&#xA;&#xA;<p>The primary goal I want to accomplish would be any service can have relationships with any number of other services without having to have knowledge of the other service.</p>&#xA;"
30621628,BDD and microservices,2015-06-03 13:31:54,<c#><bdd><distributed><specflow><microservices>,3,686,2,2.0,7,"<p>Our solution relies on microservices. On the other hand, our CIO expects us to practice Behavior Driven Development on every new feature. </p>&#xA;&#xA;<p>Is it possible to manage BDD in a microservices architecture ? Based on your experience, is it a good practice to adopt BDD against such an architecture, or do you think we should directly look at integration testing ?</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>More precisely, in my opinion, BDD Tests are expected to verify the business logic, and only the business logic. In many frameworks, BDD Tests scenarios are created by the skateholders, with a DSL. BDD Tests tend to converge to exclusive ""Infrastructure Ignorant"" practices. On the other hand, Integration Tests are supposed to verify that the solution matches the target infrastructure (they are done by DevOps ?), and only the infrastructure. When business functions are ""distributed"" over microservices, you should mock almost everything (infra and business) in your BDD Tests environment (it should be the local environment) and mocking business weakens a lot your goals. Do you think these practices are compatible ?</p>&#xA;"
30908112,Micro Service cross service dependencies,2015-06-18 06:36:30,<architecture><microservices>,3,3388,1,2.0,7,"<p>Just to simplify my situation I currently have 3 micro services.</p>&#xA;&#xA;<ol>&#xA;<li>Authentication</li>&#xA;<li>Locations</li>&#xA;<li>Inventory</li>&#xA;</ol>&#xA;&#xA;<p>The authentication service authenticates the user and sends back a JWT access token and I use that across the other services. Its stateless and all works well.</p>&#xA;&#xA;<p>I setup locations among some other things in the location service and this works well and as expected.</p>&#xA;&#xA;<p>But now I am at the inventory service and I need to add some inventory but it is linked to a location. I can easily pass the locationId in the API call but I have no way of authorizing the current user to add something to that location unless I then call the location service to validate this.</p>&#xA;&#xA;<p>This then creates service dependencies between each other and it is something I am trying to avoid at all costs otherwise you just lose most of the benefits of micro services.</p>&#xA;&#xA;<p>What would be the recommended approach to validate that the current user has permissions for that location? The only thing I have thought of so far is either</p>&#xA;&#xA;<ol>&#xA;<li>Getting the location API to issue out another access token with additional claims of what locations they have access to.</li>&#xA;<li>Or issuing out another completely separate token of some kind and passing that via the header to the inventory micro service to do a validation similar to how the JWT is authenticated.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>As mentioned below on providing aggregate roots (or I am assuming that means the same as API gateways) it would provide the 3rd option of another service on top to communicate to both to provide the information.</p>&#xA;&#xA;<p>However it then leaves a 3rd service dependent upon 2 others, so I just increased my service dependencies.</p>&#xA;"
36957369,Fabric Message is too large,2016-04-30 16:28:29,<c#><azure><microservices><azure-service-fabric>,2,1577,0,0.0,7,"<p>I'm trying to pass 5MB~ data from a service to an actor, and I'm getting the error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Fabric Message is too large</p>&#xA;</blockquote>&#xA;&#xA;<p>How can I increase the maximum size that can be transferred between micro-services?</p>&#xA;&#xA;<p>I looked at the following <a href=""https://github.com/Azure/azure-content/blob/master/articles/service-fabric/service-fabric-reliable-actors-reliabledictionarystateprovider-configuration.md"" rel=""noreferrer"">page</a> to see my options.</p>&#xA;&#xA;<p>I tried setting:</p>&#xA;&#xA;<pre><code>&lt;Section Name=""ServiceReplicatorConfig""&gt;&#xA;    ...&#xA;    &lt;Parameter Name=""MaxReplicationMessageSize"" Value=""1073741824"" /&gt;&#xA;&lt;/Section&gt;&#xA;</code></pre>&#xA;&#xA;<p>Please help.</p>&#xA;"
32715464,How to forward all requests to specific version (of same service) during deployment using netflix?,2015-09-22 11:17:13,<spring-cloud><microservices><netflix><netflix-eureka><netflix-zuul>,1,918,1,1.0,7,"<p>I have 4 instance of the same service running on different hosts. I am deploying new version for that service node by node. While deployment, incoming requests get forwarded according to the load balancer to any version (host). Is there any way in netflix where I can forward all incoming requests to a specific version?</p>&#xA;&#xA;<p>Is there any generic way where we can define version (for same serviceId). And if incoming requests has version defined in header, we can use that to forward the requests to specific version.</p>&#xA;&#xA;<p>Could be something like:</p>&#xA;&#xA;<p>In Zuul Proxy,</p>&#xA;&#xA;<pre><code>zuul:&#xA;  routes:&#xA;    sample:&#xA;      path: /sample/{version}/**&#xA;      serviceId: sample-service&#xA;</code></pre>&#xA;&#xA;<p>In sample-service,</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    appname: sample-service&#xA;    metadataMap:&#xA;      version: v1&#xA;</code></pre>&#xA;&#xA;<p>or any other mechanism to achieve versioning of same service?</p>&#xA;"
40205675,Microservices Authentication best practices and security (OAuth 2.0 and OpenIdConnect),2016-10-23 17:19:04,<security><oauth><oauth-2.0><microservices><openid-connect>,2,1694,2,3.0,7,"<p>There are several ways to build authentication in micro-services. However very popular is using JWT tokens and OAuth protocol together with OpenID Connect identity layer.</p>&#xA;&#xA;<p>In <a href=""http://nordicapis.com/api-security-oauth-openid-connect-depth/"" rel=""nofollow"">this tutorial</a> explaining how it can be achieved there is one tip:  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Pass by reference when tokens have to leave your network, and then convert them to by-value tokens as they enters your space. Do this conversion in your API gateway.</p>&#xA;</blockquote>&#xA;&#xA;<p>However it's not clear to me what's reason behind it. I suspect it might be due to some security benefits (not to give client possibility to read any specific info). Because in the JWT token itself it might be info about roles/permission. But for this purpose token can also be encrypted.</p>&#xA;&#xA;<p>Another reason might be that JWT token is too big and in order to don't carry this token every time such approach might be used. (or if JWT token is stored in cookie it has size limits).</p>&#xA;&#xA;<p>I haven't seen any info that JWT token authentication is compromised and it's a bad practice to keep it on client (in browser).</p>&#xA;&#xA;<p>On the other hand I see that Ping Identity is also using <strong>pass by reference</strong> approach. Can you help me understand the reasoning behind it?</p>&#xA;"
36541906,centralized settings with microservices,2016-04-11 07:01:48,<microservices>,1,2419,0,2.0,7,"<p>Microservices are all about decomposing your system into separate components.&#xA;However, some things in a system seem like centralized in nature.&#xA;My concern is about the system settings.&#xA;In a monolith you have one big file / db with all the parameters, settings and preferences.&#xA;This can be updated, backup, restore, export, import etc (think about Windows registry). More than this, your customers are used to go to this one ""place"" and set the system.&#xA;With microservices architecture this ""centralism"" seems like an anti pattern.</p>&#xA;&#xA;<p>What are the mechanisms/ frameworks to deal with such contradiction?</p>&#xA;"
33165216,Micro Service with API Gateway,2015-10-16 07:51:50,<c#><api><gateway><microservices>,2,8252,1,5.0,7,"<p>For my new project, I have to use <strong>Micro Services with Api Gateway</strong>. So I gathered detailed informations about Micro Service but the Api Gateway part is not clear.</p>&#xA;&#xA;<p>My question is,</p>&#xA;&#xA;<ol>&#xA;<li>Is anyone know about how the request routing part is done in Api&#xA;Gateway?</li>&#xA;<li>Is that can be done by simple if condition[<strong><em>pseudo code:</em></strong>&#xA;if(keyword==""product"") then route(""product service"")]?</li>&#xA;<li>Or Is that any better way to do it?</li>&#xA;</ol>&#xA;&#xA;<p>I am using C#.Net to develop Api.<br>&#xA;I got some info about Api Gateway from <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">https://www.nginx.com/blog/building-microservices-using-an-api-gateway/</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jVOVq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/jVOVq.png"" alt=""Api Gateway""></a></p>&#xA;"
38328727,What is the best way to design background jobs in microservices architecture?,2016-07-12 12:19:34,<architecture><microservices>,1,1727,1,1.0,7,"<p>I am using microservices architecture. As per my requirements, there are some Restful services required and some background jobs to be developed. </p>&#xA;&#xA;<p>For an example of Groceries delivery system,</p>&#xA;&#xA;<ul>&#xA;<li>Customers service - some restful service</li>&#xA;<li>Provider service - some restful service</li>&#xA;<li>OrderProvision - some background service which checks whether all of customer items got provided by different providers. </li>&#xA;</ul>&#xA;&#xA;<p>Once done, send an initiation to customer with the status and initiate delivery system to start delivering</p>&#xA;&#xA;<p>For the case of OrderProvision what is the best way to implement microservices?&#xA;In case of .Net framework, I can create a windows service/ scheduler task to run in background and do the checks. If it needs to be deployed on other servers like Linux, it does not work. What would be the best way to code such background tasks in microservices architecture?</p>&#xA;"
29636899,Do microservices break the bounded context?,2015-04-14 20:33:12,<domain-driven-design><microservices>,2,3461,3,3.0,7,"<p>I am a bit confused. I am working in a young banking company and we decided to implement a DDD architecture to break complexity.</p>&#xA;&#xA;<p>So, here is my question (it follows a design suggestion made by someone in the team). Let's say we have 3 different domains. D1, D2, D3, that expose domain (web)services. Each domain manipulates strongly typed business entities, that rely on the same tables. In front of these domains, we want a microservice to garantee that data persisted in tables is consistent, in a centralized manner. D1, D2 and D3 ask the microservice to persist data conforming to specific rules. We want the microservice to act as a CRUD proxy to the tables. The microservice provides specific DTOs to D1, D2 and D3 domains, obfuscating the tables to D1, D2, D3.</p>&#xA;&#xA;<p>Does this approach sound good ? Would you consider using microservices in a DDD architecture to manage CRUD and data consistency for 1+ domains ? Does ""CRUDing"" and validating data with a microservice break the bounded context ? What are the best practices with dealing with microservices in a DDD architecture, if any ?</p>&#xA;&#xA;<p>Many thanks for your contribution,</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>The following article helped me to refine my thoughts : <a href=""http://martinfowler.com/bliki/MicroservicePremium.html"" rel=""noreferrer"">http://martinfowler.com/bliki/MicroservicePremium.html</a></p>&#xA;&#xA;<p>Microservices are useful on complex situations where monolithic systems failed at being maintainable. They are not good candidates for upfront design implementations. On the other hand, DDD tries to tackle complexity at the very beginning of the projects. Successful DDD should not meet microservices implementations.</p>&#xA;"
29704842,Integration testing Spring Boot based Microservices,2015-04-17 16:35:27,<junit><spring-boot><microservices>,2,3024,4,1.0,7,"<p>I have read many of the guides about working with Spring Boot and RESTful services, and many of them contain information about running unit tests, most notably ""Building an Application with Spring Boot"".  However, I haven't seen anything that gives an example on how to unit test a Spring Boot application that consumes/depends on other Spring Boot applications, as is common in cloud micro-services architecture. So, for example, we have the following Spring Boot services:</p>&#xA;&#xA;<p>ServiceMediator,&#xA;Adapter1,&#xA;Adapter2</p>&#xA;&#xA;<p>ServiceMediator calls Adapter1 or Adapter2, depending on the input.</p>&#xA;&#xA;<p>Is there a way to start up the Spring Boot services Adapter1 and Adapter2  before starting and testing the ServiceMediator in a Spring JUnit test?</p>&#xA;"
51726683,How should microservices developed using AWS API Gateway + Lambda/ECS talk?,2018-08-07 12:20:51,<amazon-web-services><aws-lambda><microservices><aws-api-gateway><amazon-ecs>,5,197,0,5.0,7,"<p>I am developing a ""micro-services"" application using AWS API Gateway with either Lambda or ECS for compute. The issue now is communication between services are via API calls through the API gateway. This feels inefficient and less secure than it can be. Is there a way to make my microservices talk to each other in a more performant and secure manner? Like somehow talk directly within the private network? </p>&#xA;&#xA;<p>One way I thought of is multiple levels of API gateway. </p>&#xA;&#xA;<ul>&#xA;<li>1 public API gateway</li>&#xA;<li>1 private API gateway per microservice. And each microservice can call another microservice ""directly"" inside the private network</li>&#xA;</ul>&#xA;&#xA;<p>But in this way, I need to ""duplicate"" my routes in 2 levels of API ... this does not seem ideal. I was thinking maybe use <code>{proxy+}</code>. So anything <code>/payment/{proxy+}</code> goes to payment API gateway and so on - theres still 2 levels of API gateway ... but this seem to be the best I can go? </p>&#xA;&#xA;<p>Maybe there is a better way? </p>&#xA;"
42062199,Reactive Programming Advantages/Disadvantages,2017-02-06 07:14:55,<java><reactive-programming><microservices><rx-java2><project-reactor>,4,6250,1,6.0,7,"<p>I keep studying and trying Reactive Style of coding using Reactor and RxJava. I do understand that reactive coding makes better utilization of CPU compared to single threaded execution. </p>&#xA;&#xA;<p>Is there any concrete comparison between reactive programming vs imperative programming in web based applications? </p>&#xA;&#xA;<p>How much is the performance gain, throughput I achieve by using reactive programming over non-reactive programming?</p>&#xA;&#xA;<p>Also what are the advantages and disadvantages of Reactive Programming? </p>&#xA;&#xA;<p>Is there any statistical benchmark? </p>&#xA;"
36137802,An event store could become a single point of failure?,2016-03-21 17:25:54,<cqrs><microservices><event-sourcing><get-event-store>,4,2355,4,3.0,7,"<p>Since a couple of days I've been trying to figure it out how to inform to the rest of the microservices that a new entity was created in a microservice A that store that entity in a MongoDB.</p>&#xA;&#xA;<p>I want to:</p>&#xA;&#xA;<ul>&#xA;<li><p>Have low coupling between the microservices</p></li>&#xA;<li><p>Avoid distributed transactions between microservices like Two Phase Commit (2PC)</p></li>&#xA;</ul>&#xA;&#xA;<p>At first a message broker like RabbitMQ seems to be a good tool for the job but then I see the problem of <strong>commit</strong> the new document in MongoDB and <strong>publish</strong> the message in the broker not being atomic.</p>&#xA;&#xA;<p><a href=""http://eventuate.io/whyeventsourcing.html"" rel=""nofollow noreferrer"">Why event sourcing?</a> by eventuate.io:&#xA;<a href=""https://i.stack.imgur.com/xovbk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xovbk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>One way of solving this issue implies make the schema of the documents a bit dirtier by adding a mark that says if the document have been published in the broker and having a scheduled background process that search unpublished documents in MongoDB and publishes those to the broker using <a href=""https://www.rabbitmq.com/confirms.html"" rel=""nofollow noreferrer"">confirmations</a>, when the confirmation arrives the document will be marked as published (using at-least-once and idempotency semantics). This solutions is proposed in <a href=""https://stackoverflow.com/a/13490358/3517383"">this</a> and <a href=""https://stackoverflow.com/a/17812090/3517383"">this</a> answers.</p>&#xA;&#xA;<p>Reading an <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">Introduction to Microservices</a> by Chris Richardson I ended up in this great presentation of <a href=""http://www.slideshare.net/chris.e.richardson/developing-functional-domain-models-with-event-sourcing-sbtb-sbtb2015"" rel=""nofollow noreferrer"">Developing functional domain models with event sourcing</a> where one of the slides asked:</p>&#xA;&#xA;<blockquote>&#xA;  <p>How to <strong>atomically</strong> update the database <strong>and</strong> publish events and publish events without 2PC? (dual write problem).</p>&#xA;</blockquote>&#xA;&#xA;<p>The answer is simple (on the next slide)</p>&#xA;&#xA;<blockquote>&#xA;  <p><strike>Update the database <strong>and</strong></strike> publish events</p>&#xA;</blockquote>&#xA;&#xA;<p>This is a different approach to <a href=""https://stackoverflow.com/q/13488982/3517383"">this one</a> that is based on <a href=""https://github.com/MarkNijhof/Cre8iveThought/blob/master/blog/articles/2009-11-12-cqrs--la-greg-young.txt"" rel=""nofollow noreferrer"">CQRS a la Greg Young</a>.</p>&#xA;&#xA;<blockquote>&#xA;  <p>The domain repository is responsible for publishing the events, this&#xA;  would normally be inside a single transaction together with storing&#xA;  the events in the event store.</p>&#xA;</blockquote>&#xA;&#xA;<p>I think that delegate the responsabilities of storing and publishing the events to the event store is a good thing because avoids the need of 2PC or a background process.</p>&#xA;&#xA;<p>However, in a certain way it's true <a href=""https://stackoverflow.com/a/12678477/3517383"">that</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If you rely on the event store to publish the events you'd have a&#xA;  tight coupling to the storage mechanism.</p>&#xA;</blockquote>&#xA;&#xA;<p>But we could say the same if we adopt a message broker for intecommunicate the microservices.</p>&#xA;&#xA;<p>The thing that worries me more is that the Event Store seems to become a Single Point of Failure.</p>&#xA;&#xA;<p>If we look this <a href=""https://github.com/cer/event-sourcing-examples"" rel=""nofollow noreferrer"">example</a> from <a href=""http://eventuate.io"" rel=""nofollow noreferrer"">eventuate.io</a>&#xA;<a href=""https://i.stack.imgur.com/52rMK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/52rMK.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>we can see that if the event store is down, we can't create accounts or money transfers, losing one of the advantages of microservices. (although the system will continue responding querys).</p>&#xA;&#xA;<p>So, it's correct to affirmate that the Event Store as used in the eventuate example is a Single Point of Failure?</p>&#xA;"
47071729,AWS Load Balancer 502,2017-11-02 09:27:21,<amazon-web-services><amazon-ec2><microservices><elastic-load-balancer><internal-load-balancer>,1,873,4,3.0,7,"<p>I have microservices(in different programming languages) running on an EC2 instance.&#xA;On production I notice a few 502 Bad Gateway Errors when these services try to interact with each other.&#xA;Also in the logs of the requested service it doesn't show any api call is being hit</p>&#xA;&#xA;<p>example service A calls service B, but in service B logs there is nothing to indicate that a call came from service A.</p>&#xA;&#xA;<p>Can it be AWS load balancer issue? Any help would be appreciated. Thanks in advance.</p>&#xA;&#xA;<p>Solution tried:&#xA;We tried making http/https connection agents in each service but still we get this issue.</p>&#xA;&#xA;<p>Update:&#xA;In lb logs, the api is logged, but the target response code shows ""-"" whereas lb response code shows 502 or 504. Does it mean that lb is not able to handle the traffic or my application?</p>&#xA;&#xA;<p>Also what can be the possible solution?</p>&#xA;"
41903352,How do I register a microservice (or its methods) to Task in Netflix Conductor?,2017-01-27 21:33:02,<microservices><netflix><amazon-swf><axon><netflix-conductor>,2,1341,1,0.0,7,"<p>I was looking for a more sophisticated workflow than Saga from AxonFramework  -- which we are currently using -- and I found one in Netflix Conductor. &#xA;Sadly, I have searched the Internet for a decent example but to no avail.</p>&#xA;&#xA;<p>My question is, in Netflix Conductor, how might one define and create Task or WorkflowTask and most importantly, link a microservice to it? Here is a Netflix Conductor code from github:</p>&#xA;&#xA;<pre><code>    WorkflowDef def = new WorkflowDef();&#xA;    def.setName(""test"");&#xA;    WorkflowTask t0 = new WorkflowTask();&#xA;    t0.setName(""t0"");&#xA;    t0.setType(Type.SIMPLE);&#xA;    t0.setTaskReferenceName(""t0"");&#xA;&#xA;    WorkflowTask t1 = new WorkflowTask();&#xA;    t1.setName(""t1"");&#xA;    t1.setType(Type.SIMPLE);&#xA;    t1.setTaskReferenceName(""t1"");&#xA;&#xA;    def.getTasks().add(t0);&#xA;    def.getTasks().add(t1);&#xA;</code></pre>&#xA;&#xA;<p>Pardon my confusion as I am new to Netflix Conductor.</p>&#xA;"
48635782,Zookeeper vs Eureka for microservices?,2018-02-06 05:00:32,<apache-zookeeper><microservices><netflix-eureka><orchestration>,2,4240,0,4.0,7,"<p>I am going to implement the orchestration of a set of microservices in my application. Two widely using tools I found vs Apache <a href=""https://zookeeper.apache.org/"" rel=""noreferrer"">Zookeeper</a> and Netflix <a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">Eureka</a>.</p>&#xA;&#xA;<p>Can anyone please give me a comparison based on fundamental differences, those two services have?</p>&#xA;&#xA;<p>Is there any other powerful tool?</p>&#xA;"
40966759,Microservices: Centralized Authorization vs Authorization in each service,2016-12-05 03:42:29,<architecture><microservices>,1,1391,0,1.0,7,"<p>Let's say I have a Microservices system built with an API Gateway.  </p>&#xA;&#xA;<p>Every request after coming through the Gateway have to be pre-authenticated by an Authentication Service (The Firewall pattern)  </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DySBr.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DySBr.png"" alt=""Firewall Pattern""></a>  </p>&#xA;&#xA;<p>But how about Authorization? For instance, I have 3 models and 3 services according to them in a <em>Hotel Management</em> system:  </p>&#xA;&#xA;<p><strong>User</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>each user can have many hotels  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Hotel</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a hotel is owned by a single user (owner)  </li>&#xA;<li>each hotel can have many employees (also a user)  </li>&#xA;<li>a hotel can have many rooms</li>&#xA;<li>for the sake of simplicity let's pretend that an employee have the same rights as the owner over a hotel  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Room</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a room can only belong to a single hotel</li>&#xA;<li>owner and employees can only edit rooms in hotels that they owned/employed at</li>&#xA;</ul>&#xA;&#xA;<p>An example request to edit a room <strong>Y</strong>, after being authenticated it will have a verified claim that state something like <strong>'I am user X'</strong>.  </p>&#xA;&#xA;<p>To know whether <strong>X</strong> has the right to edit over <strong>Y</strong> I have to make requests to Hotel Service asking ""Does <strong>Y</strong>'s Hotel associated with (owned by/employing) <strong>X</strong>?"".  </p>&#xA;&#xA;<p>The question is: <strong>Where do I make these requests?</strong><br>&#xA;Have the Gateway ask the <em>Hotel Service</em> before forwarding client request to <em>Room Service</em>, or let the <em>Room Service</em> ask the <em>Hotel Service</em> by itself. When to choose one over another ? What's the benefit ?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Also, this modeling seems kinda wrong to me. All these relations laying around Microservices just make my system really complicated. As it grows it becomes harder for me to visualize the workflow between services. Is there a solution to this problem? A centralized relationship service that utilizes graph database like Neo4j perhaps?</p>&#xA;"
50176793,Automate RabbitMQ consumer testing,2018-05-04 14:02:25,<rabbitmq><integration-testing><microservices>,2,245,0,0.0,7,"<p>I have a .net micro-service receiving messages using RabbitMQ client, I need to test the following:</p>&#xA;&#xA;<p>1- consumer is successfully connected to rabbitMq host.</p>&#xA;&#xA;<p>2- consumer is listening to queue.</p>&#xA;&#xA;<p>3- consumer is receiving messages successfully.</p>&#xA;&#xA;<p>To achieve the above, I have created a sample application that sends messages and I am debugging consumer to be sure that it is receiving messages.</p>&#xA;&#xA;<p>How can I automate this test? hence include it in my micro-service CI.</p>&#xA;&#xA;<p>I am thinking to include my sample app in my CI so I can fire a message then run a consumer unit test that waits a specific time then passes if the message received, but this seems like a wrong practice to me because the test will not start until a few seconds the message is fired.</p>&#xA;&#xA;<p>Another way I am thinking of is firing the sample application from the unit test itself, but if the sample app fails to work that would make it the service fault.</p>&#xA;&#xA;<p>Is there any best practices for integration testing of micro-services connecting through RabbitMQ?</p>&#xA;"
26975640,Why are Micro-Services Architectures not based on Enterprise Service Buses?,2014-11-17 15:08:19,<esb><microservices>,4,2300,0,2.0,8,"<p>What reasons are there against (or for) using the features of an Enterprise Service Bus when building an overall service adhering to a micro-service architecture (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">http://martinfowler.com/articles/microservices.html</a>)? Why should we use dumb pipes and smart endpoints as opposed to using smarter pipes and be able to develop simpler services? </p>&#xA;"
26854986,Cross-service linking for HATEOAS micro-services,2014-11-10 23:33:32,<spring><spring-boot><hateoas><spring-hateoas><microservices>,1,1372,3,4.0,8,"<p>I have a number of micro-services built with Spring Boot, so for a bit of fun, I thought I'd have a go at adding HATEOAS to them to help set up cross-resource linking. It seems to work quite nicely within a particular project, but I was wondering whether there's a good way to link across APIs. As an example, imagine I have 3 services:</p>&#xA;&#xA;<p>A user details service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}&#xA;</code></pre>&#xA;&#xA;<p>A user calendar service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/appointments&#xA;/users/{userid}/appointments/{appointmentid}&#xA;</code></pre>&#xA;&#xA;<p>A user messaging service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/messages&#xA;/users/{userid}/messages/{messageid}&#xA;</code></pre>&#xA;&#xA;<p>To make this browsable via the API, it would be good to have links from a user resource to its appointments and messages. Similarly, it would be nice to have links back from those resources. This is all very achievable when I have a single API with everything on the classpath, where I can write code such as:</p>&#xA;&#xA;<p>Code:</p>&#xA;&#xA;<pre><code>user.add(linkTo(methodOn(CalendarController.class).appointments(user.getKey())).withRel(""appointments""))&#xA;</code></pre>&#xA;&#xA;<p>However I'm not able to do this if CalendarController is not on the classpath of the service I'm currently hitting.</p>&#xA;&#xA;<p>Is there a good/recommended method for creating links to controllers which are not in the current project?</p>&#xA;&#xA;<p>Referenced from <a href=""http://forum.spring.io/forum/spring-projects/web/749306-cross-service-linking-for-hateoas-micro-services"">spring forums</a></p>&#xA;"
28930710,How to avoid concurrency issues when scaling writes horizontally?,2015-03-08 19:10:29,<azure><scalability><sharding><microservices><horizontal-scaling>,5,639,2,3.0,8,"<p>Assume there is a worker service that receives messages from a queue, reads the product with the specified Id from a document database, applies some manipulation logic based on the message, and finally writes the updated product back to the database (a).</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/RZYlA.png"" alt=""horizontally scaling writes""></p>&#xA;&#xA;<p>This work can be safely done in parallel when dealing with different products, so we can scale horizontally (b). However, if more than one service instance works on the same product, we might end up with concurrency issues, or concurrency exceptions from the database, in which case we should apply some retry logic (and still the retry might fail again and so on). </p>&#xA;&#xA;<p><strong>Question</strong>: How do we avoid this? Is there a way I can ensure two instances are not working on the same product?</p>&#xA;&#xA;<p><strong>Example/Use case</strong>: An online store has a great sale on productA, productB and productC that ends in an hour and hundreds of customers are buying. For each purchase, a message is enqueued (productId, numberOfItems, price).  <strong>Goal</strong>: How can we run three instances of our worker service and make sure that all messages for productA will end up in instanceA, productB to instanceB and productC to instanceC (resulting in no concurrency issues)?</p>&#xA;&#xA;<p><strong>Notes</strong>: My service is written in C#, hosted on Azure as a Worker Role, I use Azure Queues for messaging, and I'm thinking to use Mongo for storage. Also, the Entity IDs are <code>GUID</code>.</p>&#xA;&#xA;<p>It's more about the technique/design, so if you use different tools to solve the problem I'm still interested.</p>&#xA;"
22987482,Can you use Hapi.JS as a Micro-services framework?,2014-04-10 12:04:08,<node.js><api><plugins><microservices>,1,2226,0,2.0,8,"<p>I've seen various interesting presentations recently about the joys of Micro Services (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow noreferrer"">http://martinfowler.com/articles/microservices.html</a>) and also wonder how we might use those concepts with Hapi.JS. </p>&#xA;&#xA;<p>The CTO of Mail Online (largest online newspaper on the planet) name checks HAPI and its plugin system in relation to micro-services :</p>&#xA;&#xA;<p><a href=""http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline"" rel=""nofollow noreferrer"">http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline</a></p>&#xA;&#xA;<blockquote>&#xA;  <p>A micro-services architecture is used, which was inspired by Fred George, which is a&#xA;  slightly different take on the hapi plugin architecture, structuring applications to be &#xA;  maintainable as they get bigger is a key challenge going forward and micro-services is a &#xA;  solution to this. The MailOnline are also heavy users of Joyent (On Premise SDC and public &#xA;  cloud).</p>&#xA;</blockquote>&#xA;&#xA;<p>There are also new node frameworks set up specifically for micro-services (senecajs.org)</p>&#xA;&#xA;<p>Has anyone seen any case studies (and ideally tutorials) on leveraging Hapi in this way?</p>&#xA;"
31317470,How should you deal with auth and sharing Users info across microservices?,2015-07-09 12:26:19,<node.js><mongodb><nginx><microservices>,1,1189,3,6.0,8,"<p><strong>TLTR:</strong> What is a good way to communicate across services for Auth and User Info regardless of location of server or technology used</p>&#xA;&#xA;<p>I'm trying to learn about microservices and I'm a little bit unclear as to how I should approach accessing user information and control access with multiple services. Please let me know if I am approaching this completely wrong.</p>&#xA;&#xA;<p>For example I have a basic service for Blog CRUD operations and a Service for uploading and storing images and videos. I haven't done anything with Authorization or Users yet (except I am accounting for UserIds eventually being present in my Models (e.g. in my blog model ObjectID's for author, commenters, etc).</p>&#xA;&#xA;<p>I want to keep this as separated as possible (for learning purposes more then anything) and while at the moment I am building it all in Node.js I hope to be able to swap in and out different technologies such as nginx, a java/go/python service or a different storage (currently mongo, but would like to be able to switch to sql as an option )</p>&#xA;&#xA;<p>How I currently have these structured is I have both services built as Express.js apps and currently I am using node-http-proxy to proxy to the express services (this is just to save with setting up nginx for now but I don't want to be dependent on nginx either).</p>&#xA;&#xA;<p><em>How should I approach:</em></p>&#xA;&#xA;<ul>&#xA;<li><p>Authenticated user or some of the routes (e.g. when creating a new post or updating/deleting) and Not when getting the post to Read (eventually I would like to incorporate roles too)</p></li>&#xA;<li><p>populating the User information e.g. from the user's ID stored in the blog author and replacing it with the user information (in a single app I could just use mongoose populate</p></li>&#xA;</ul>&#xA;&#xA;<p>The main aim is I would like to keep the Auth and Users in separate services that could be called in any other service and stored in another DB for example if they were located on different physical servers.</p>&#xA;&#xA;<p>someone had suggested to me I could do this using HTTP/S but is there a better way to do this and can anyone point me to any implementation examples, Node.js would be preferable but not essential</p>&#xA;&#xA;<p>This likely requires some service registry but I am a bit lost as to how this would be implemented</p>&#xA;"
30648096,centralized API documentation for microservices,2015-06-04 15:30:59,<api><documentation><microservices>,3,3386,5,2.0,8,"<p>My team and I are currently building multiple services in parallel. We have the benefit of building all the services from scratch. I would like the ability to automatically display all API endpoints, from all services, in one page/site.  This would be helpful because (among other things):</p>&#xA;&#xA;<ol>&#xA;<li><p>I don't have to go to multiple documentation sites to see what are the available endpoints in my entire ""system"". </p></li>&#xA;<li><p>It'll be a good first step to determine if any of the services should be split, combined or simply refactored.  </p></li>&#xA;</ol>&#xA;&#xA;<p>Some of our services are in Django and the <a href=""http://swagger.io/"" rel=""noreferrer"">rest-swagger</a> module is a great help. But I don't see how I can combine rest-swagger documentation from multiple services into a single documentation page/site.</p>&#xA;&#xA;<p>I'm currently looking through <a href=""http://microservices.io/index.html"" rel=""noreferrer"">this site</a> and anything related to the <a href=""http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/"" rel=""noreferrer"">Netflix experience</a> but could not find a solution to my problem. Maybe centralized documentation isn't a big deal with 600+ services at Netflix, but that's hard to believe.</p>&#xA;&#xA;<p>Can anyone suggest a tool or method to have a combined API documentation for all services in a microservice architecture? </p>&#xA;&#xA;<p>My ideal scenario of what happens when a service is changed: </p>&#xA;&#xA;<ol>&#xA;<li>I click on the link to see the list of endpoints in my system.</li>&#xA;<li>A teammate updates a service and also it's documentation.</li>&#xA;<li>I refresh the page I am currently and I see that change made from step #2.</li>&#xA;</ol>&#xA;"
41262716,Don't allow direct calls to Microservices. Only allow through API Gateway,2016-12-21 12:20:58,<java><spring><rest><microservices><gateway>,4,1584,6,1.0,8,"<p>Maybe this is a strange question (I'm new with Microservices). But I'm looking for some info on how proceed with this. Does not need to be Spring specific, but that's the framework I'm using at the moment.</p>&#xA;&#xA;<p>Example:&#xA;Lets say we have two Microservices</p>&#xA;&#xA;<p>a) <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>b) <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>and we have setup Spring Zuul (acting as the API Gateway) with the following rules that forward the incoming calls:</p>&#xA;&#xA;<p>/rest/one -> <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>/rest/two -> <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>The question...&#xA;Is there a way to stop users from directly accessing the services mentioned in A and B (only allow the ones that come through the API Gateway)?</p>&#xA;&#xA;<p>Can this be done with Springs Zuul (Acting as a API Gateway) by setting up some extra filters or do we set it up in Microservices endpoints?</p>&#xA;&#xA;<p>Would even like to know if there is a way to not even processing the direct calls on the Microservices endpoints that don't come via the API Gateway.</p>&#xA;&#xA;<p>Maybe this is solved with server specific rules and has nothing to do with Spring? </p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>/D</p>&#xA;"
34593341,Trade offs and best practices building microservices with Azure Service Fabric,2016-01-04 14:26:47,<c#><azure><asp.net-web-api2><microservices><azure-service-fabric>,2,2284,2,3.0,8,"<p>I want to build a microservice application based on Azure Service Fabric. For some stateful services or actors I want to access the state from outside via web api.</p>&#xA;&#xA;<p>What are the general trade-offs and best practices for such a Service Fabric project regarding to:</p>&#xA;&#xA;<ol>&#xA;<li><p>using one vs. multiple services in a single application? Therefore if I use one service per application, I will have multiple applications for my project. When is it useful to use one service per application?</p></li>&#xA;<li><p>using one vs. multiple actors in a single service? When is it useful to have more than one actor per service?</p></li>&#xA;<li><p>using one stateless web api service for the whole project vs. multiple stateless web services for each stateful service or for each application?</p></li>&#xA;</ol>&#xA;&#xA;<p>I know these decisions are based on the specific project. But maybe there are general advantages and disadvantages for the three points above.</p>&#xA;"
35409492,Eureka service discovery without Spring-boot,2016-02-15 12:32:50,<java><spring><spring-boot><microservices><netflix-eureka>,3,8751,1,5.0,8,"<p>I have written a spring boot micro-service and a REST client. The client is a part of another module and make RESTful calls to the micro-service. The micro-service registers with the Eureka registry and I want my client (Which is not a spring boot project) to use the Eureka to query and get the service endpoints. </p>&#xA;&#xA;<p>My problem is since the client is not a Spring-Boot applications I can not use the annotations like <code>@SpringBootApplication</code>, <code>@EnableDiscoveryClient</code> and the <code>DiscoveryClient</code> is not get auto wired to the application. Is there anyway to manually auto-wire the <code>DiscoveryClient</code> bean to the client without using the annotations ?</p>&#xA;"
36083504,Database connection pool strategy for micro services,2016-03-18 11:44:23,<database><postgresql><jdbc><connection-pooling><microservices>,1,1749,2,0.0,8,"<p>We are trying to convert our monolithic application to a micro services based architecture. We use Postgresql as one of our database in the monolithic application with BoneCP for connection pooling. </p>&#xA;&#xA;<p>When this monolith is split to a number of independent micro-services with each of them running in a different JVM, I can think about two options for connection pooling</p>&#xA;&#xA;<ol>&#xA;<li>BoneCP or any decent connection pool for each microservice - My initial research shows that this is the primary choice. It is possible to have a fine grained control of connection requirements for each service.But, down side is that as the number of services increase, number of connection pool also increases and eventually there will be too many idle connections assuming that minimum connections in each pool is greater than 0.</li>&#xA;<li>Rely on database specific extensions like PGBouncer - This approach has the advantage that connection pool is managed by a central source rather than a pool for each micro service and hence number of idle connections can be brought down. It is also language/technology agnostic. Down side is that these extensions are database specific and some of the functionalities in JDBC may not work. For eg: Prepared statments may not work with PGBouncer in Transaction_Pooling mode. </li>&#xA;</ol>&#xA;&#xA;<p>In our case most of the micro-services(at least 50) will be connecting to the same Postgres server even though the database can be different. So, if we go with option 1, there is a higher chance of creating too many idle connections.The traffic to most of our services are very moderate and the rationale behind moving to micro-service is for easier deployment, scaling etc.</p>&#xA;&#xA;<p>Has anyone faced a similar problem while adopting micro-services architecture? Is there a better way of solving this problem in micro-service world?</p>&#xA;"
32334161,What is the conceptual difference between Service Discovery tools and Load Balancers that check node health?,2015-09-01 14:24:24,<load-balancing><distributed-computing><microservices><service-discovery><consul>,3,414,3,6.0,8,"<p>Recently several service discovery tools have become popular/""mainstream"", and Iâ€™m wondering under what primary use cases one should employ them instead of traditional load balancers.</p>&#xA;&#xA;<p>With LBs, you cluster a bunch of nodes behind the balancer, and then clients make requests to the balancer, who then (typically) round robins those requests to all the nodes in the cluster.</p>&#xA;&#xA;<p>With service discovery (<a href=""https://www.consul.io"" rel=""noreferrer"">Consul</a>, <a href=""https://zookeeper.apache.org"" rel=""noreferrer"">ZK</a>, etc.), you let a centralized â€œconsensusâ€ service determine what nodes for particular service are healthy, and your app connects to the nodes that the service deems as being healthy. <strong>So while service discovery and load balancing are two separate concepts, service discovery gives you load balancing as a convenient side effect.</strong></p>&#xA;&#xA;<p>But, if the load balancer (say <a href=""http://www.haproxy.org"" rel=""noreferrer"">HAProxy</a> or <a href=""http://wiki.nginx.org/Main"" rel=""noreferrer"">nginx</a>) has monitoring and health checks built into it, then you pretty much get service discovery as a side effect of load balancing! Meaning, if my LB knows not to forward a request to an unhealthy node in its cluster, then thatâ€™s functionally equivalent to a consensus server telling my app not to connect to an unhealty node.</p>&#xA;&#xA;<p>So to me, service discovery tools feel like the â€œ6-in-one,half-dozen-in-the-otherâ€ equivalent to load balancers. Am I missing something here? If someone had an application architecture entirely predicated on load balanced microservices, what is the benefit (or not) to switching over to a service discovery-based model?</p>&#xA;"
41618538,Securing REST microservices with Spring Security,2017-01-12 16:41:21,<spring><spring-security><microservices>,1,4585,2,7.0,8,"<p>I'm looking for a best-practice and efficient solution to secure multiple microservices communicating via REST to a Web Client application.</p>&#xA;&#xA;<p><strong>Current setup</strong>:</p>&#xA;&#xA;<p>These microservices are made in Java, with Spring Framework and run into Docker containers.</p>&#xA;&#xA;<p>The client is an Angular 2 application.</p>&#xA;&#xA;<p>I made a new ÂµService that will act as a ""<em>gateway</em>"" and be the only communication point between my web client and my other services.</p>&#xA;&#xA;<p>I retrieve a JWT encrypted token from a remote authentication API (let's call it LOCK)</p>&#xA;&#xA;<p><strong>Solution I was thinking about</strong>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ajEpM.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ajEpM.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I could store the login JWT into a cookie, and send it to the gateway.</p>&#xA;&#xA;<p>The gateway embed in the final payload sent to the concerned ÂµService the token and store the user if it's new into a database.</p>&#xA;&#xA;<p>The microservice then get the query, checks in the remote authentication service the user role, and if it's sufficient, it returns a 200 status with result.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>We will need to have a RabbitMQ Broker into our ÂµServices hive, and thus, to use the WebSockets. In order to secure WebSockets in the same way as securing REST APIs, I'm not sure if we still should manage security in a gateway, and maybe manage it at the microservice level by itself. Because lots of messages will transit, and we should maybe get rid a middleware that will slow down the thing.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<p>Is it a good practice ? What could possibly be done better ? Do you have any example of things done that fills the same needs ? Thanks a lot for your shares &amp; thoughts.</p>&#xA;"
31546631,What are the option to API gateway with docker?,2015-07-21 18:13:46,<api><docker><microservices><gateway><tyk>,2,6049,0,6.0,8,"<p>I've created several RESTful microservices and dockerized them. Now I want to have a web-based UI for them and the ability to create users and grant permissions to them to use some of the APIs.</p>&#xA;&#xA;<p>I know that I need some kind of API gateway. My first thought was that I always could do that bruteforce way: create some django app that would serve UI and proxy all request to APIs by hand, but this seems very dull. Maybe there are some alternatives? I've ready about Tyk, but can't find any information about the ability to add users and grant permissions to them.</p>&#xA;&#xA;<p>I probably could create an application that would serve as API gateway and automate proxying of requests by writing some code that would model that. So for example I basically need a mapping between external urls to actual api urls and some authorization logic. Maybe there are already something like that?</p>&#xA;"
36157778,Accessing stateless service via ServiceProxy fails + ASP.NET 5 Web API project throws Health State error,2016-03-22 14:55:29,<c#><asp.net><.net><microservices><azure-service-fabric>,6,5965,4,3.0,8,"<p>I'm new to microsoft azure service fabric. For my master's degree I have to develop a microservice-approach prototype in service fabric. After hours of researching I am still not getting my issue(s) solved.</p>&#xA;&#xA;<p>I want to access my (in a local fabric cluster deployed) stateless service in a web front-end like in <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/"" rel=""noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/</a>. The simplest way for doing that is by adding an ASP .NET 5 Web Api project to the Service Fabric application and make a <code>ServiceProxy</code> method call in the <code>ValuesController</code>. So I added this code to my solution:</p>&#xA;&#xA;<p><strong>ValuesController.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>[Route(""api/[controller]"")]&#xA;public class ValuesController : Controller&#xA;{&#xA;  // GET api/values/IObject&#xA;  [HttpGet(""{interfaceName}"")]&#xA;  public async Task&lt;string&gt; Get(string interfaceName)&#xA;  {&#xA;    var serviceName = ""fabric:/DataServiceFabric/MasterDataMService"";&#xA;    var masterDataService = ServiceProxy.Create&lt;IMasterDataMService&gt;(new Uri(serviceName));&#xA;    var result = await masterDataService.GetMasterDataByName(interfaceName);&#xA;    return result.Content;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After a F5-deploy my browser doesn't automatically navigate to my web front-end. By looking into the Service Fabric Explorer my ASP .NET 5 application throws a Health State error:</p>&#xA;&#xA;<pre><code>Kind        Health State  Description&#xA;=============================================================================&#xA;Partitions  Error         Unhealthy partitions: 100% (1/1), MaxPercentUnhealthyPartitionsPerService=0%.&#xA;Partition   Error         Unhealthy partition: PartitionId='413...', AggregatedHealthState='Error'.&#xA;Event       Error         Error event: SourceId='System.FM', Property='State'. Partition is below target replica or instance count.&#xA;</code></pre>&#xA;&#xA;<p>After this <a href=""https://stackoverflow.com/questions/34892366/partition-is-below-target-replica-or-instance-count-error-after-deploying-serv"">this</a> question the <em>""Partition is below target replica or instance count""</em> indicates that a unhandled exception in my service is preventing it from starting. But I'm not able to find a stack strace in my Service Fabric Explorer to debug this failure. This is my <code>ServiceManifest.xml</code> of my ASP .NET web service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (Web1):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Name=""Web1"" Version=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;ServiceTypes&gt;&#xA;      &lt;StatelessServiceType ServiceTypeName=""Web1Type""&gt;&#xA;         &lt;Extensions&gt;&#xA;            &lt;Extension Name=""__GeneratedServiceType__""&gt;&#xA;               &lt;GeneratedNames xmlns=""http://schemas.microsoft.com/2015/03/fabact-no-schema""&gt;&#xA;                  &lt;DefaultService Name=""Web1Service"" /&gt;&#xA;                  &lt;ServiceEndpoint Name=""Web1TypeEndpoint"" /&gt;&#xA;               &lt;/GeneratedNames&gt;&#xA;            &lt;/Extension&gt;&#xA;         &lt;/Extensions&gt;&#xA;      &lt;/StatelessServiceType&gt;&#xA;   &lt;/ServiceTypes&gt;&#xA;   &lt;CodePackage Name=""C"" Version=""1.0.0""&gt;&#xA;      &lt;EntryPoint&gt;&#xA;         &lt;ExeHost&gt;&#xA;            &lt;Program&gt;approot\runtimes\dnx-clr-win-x64.1.0.0-rc1-update1\bin\dnx.exe&lt;/Program&gt;&#xA;            &lt;Arguments&gt;--appbase approot\src\Web1 Microsoft.Dnx.ApplicationHost Microsoft.ServiceFabric.AspNet.Hosting --server Microsoft.AspNet.Server.WebListener&lt;/Arguments&gt;&#xA;            &lt;WorkingFolder&gt;CodePackage&lt;/WorkingFolder&gt;&#xA;            &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048"" /&gt;&#xA;         &lt;/ExeHost&gt;&#xA;      &lt;/EntryPoint&gt;&#xA;   &lt;/CodePackage&gt;&#xA;   &lt;Resources&gt;&#xA;      &lt;Endpoints&gt;&#xA;         &lt;Endpoint Name=""Web1TypeEndpoint"" Protocol=""http"" Type=""Input"" Port=""80"" /&gt;&#xA;      &lt;/Endpoints&gt;&#xA;   &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>And here my <code>ApplicationManifest.xml</code> of my service fabric solution:</p>&#xA;&#xA;<p><strong>ApplicationManifest.xml:</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ApplicationManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" ApplicationTypeName=""DataServiceFabricType"" ApplicationTypeVersion=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;Parameters&gt;&#xA;      &lt;Parameter Name=""ActorTestServiceActorService_PartitionCount"" DefaultValue=""10"" /&gt;&#xA;      &lt;Parameter Name=""MasterDataMService_InstanceCount"" DefaultValue=""-1"" /&gt;&#xA;   &lt;/Parameters&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;     &lt;ServiceManifestRef ServiceManifestName=""Web2Pkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;     &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""Web1"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""ActorTestServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""MasterDataMServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;      &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;DefaultServices&gt;&#xA;      &lt;Service Name=""Web1Service""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""Web1Type""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""ActorTestServiceActorService"" GeneratedIdRef=""761ee3cf-5a3a-49d8-9c57-aa3480d1acf1""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""ActorTestServiceActorServiceType""&gt;&#xA;            &lt;UniformInt64Partition PartitionCount=""[ActorTestServiceActorService_PartitionCount]"" LowKey=""-9223372036854775808"" HighKey=""9223372036854775807"" /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""MasterDataMService""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""MasterDataMServiceType"" InstanceCount=""[MasterDataMService_InstanceCount]""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;   &lt;/DefaultServices&gt;&#xA;&lt;/ApplicationManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>So I created a new solution with an ASP.NET 5 web application and the same <code>ValuesController.cs</code>. I ensured my stateless service is running on my local cluster and than I started my new web application. After calling the GET-Method in my Controller I got the following exception:</p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 0,2593ms 500&#xA;Microsoft.AspNet.Server.Kestrel: Error: An unhandled exception was thrown by the application.&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1}&#xA;</code></pre>&#xA;&#xA;<p>My stateless service is a SingletonPartition, so do I need a partition key here? And if yes, how do I get the key? The Service Fabric Explorer doesn't provide me with this information for my stateless service. Here is the <code>ServiceManifest.xml</code> of my stateless service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (MasterDataMService):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest Name=""MasterDataMServicePkg""&#xA;                 Version=""1.0.0""&#xA;                 xmlns=""http://schemas.microsoft.com/2011/01/fabric""&#xA;                 xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&#xA;                 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;&#xA;  &lt;ServiceTypes&gt;&#xA;    &lt;!-- This is the name of your ServiceType. &#xA;         This name must match the string used in RegisterServiceType call in Program.cs. --&gt;&#xA;    &lt;StatelessServiceType ServiceTypeName=""MasterDataMServiceType"" /&gt;&#xA;  &lt;/ServiceTypes&gt;&#xA;&#xA;  &lt;!-- Code package is your service executable. --&gt;&#xA;  &lt;CodePackage Name=""Code"" Version=""1.0.0""&gt;&#xA;    &lt;EntryPoint&gt;&#xA;      &lt;ExeHost&gt;&#xA;        &lt;Program&gt;MasterDataMService.exe&lt;/Program&gt;&#xA;      &lt;/ExeHost&gt;&#xA;    &lt;/EntryPoint&gt;&#xA;  &lt;/CodePackage&gt;&#xA;&#xA;  &lt;!-- Config package is the contents of the Config directoy under PackageRoot that contains an &#xA;       independently-updateable and versioned set of custom configuration settings for your service. --&gt;&#xA;  &lt;ConfigPackage Name=""Config"" Version=""1.0.0"" /&gt;&#xA;&#xA;  &lt;Resources&gt;&#xA;    &lt;Endpoints&gt;&#xA;      &lt;!-- This endpoint is used by the communication listener to obtain the port on which to &#xA;           listen. Please note that if your service is partitioned, this port is shared with &#xA;           replicas of different partitions that are placed in your code. --&gt;&#xA;      &lt;Endpoint Name=""ServiceEndpoint"" Type=""Input"" Protocol=""http"" Port=""80""/&gt;&#xA;    &lt;/Endpoints&gt;&#xA;  &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that I decided to set up a service communication with OWIN:</p>&#xA;&#xA;<p><strong>MasterDataMService.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>internal sealed class MasterDataMService : StatelessService, IMasterDataMService&#xA;{&#xA;  [...]      &#xA;&#xA;  protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;  {&#xA;    return new[]&#xA;    {&#xA;      new ServiceInstanceListener(initParams =&gt; new OwinCommunicationListener(""MasterDataMService"", new StartUp(), initParams))&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I can acess my microservice by using a <code>HttpClient</code> in my <code>DefaultController</code>:</p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>var client = new HttpClient();&#xA;var request = ""http://localhost:80/MasterDataMService/api/values/query"";&#xA;var result = string.Empty;&#xA;HttpResponseMessage response = await client.GetAsync(request);&#xA;if (response.IsSuccessStatusCode)&#xA;{&#xA;  result = await response.Content.ReadAsStringAsync();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But thats not what I originally wanted. I don't want to specifiy the service endpoint in my request. Instead I would like to communicate with my stateless service over a <code>ServiceProxy</code>. How do I achieve that here? What did I wrong? And how can I solve this Health State error with my ASP .NET 5 application which is deployed into my service fabric cluster?</p>&#xA;&#xA;<p>Thanks for your time.</p>&#xA;&#xA;<p><strong>Edit:</strong></p>&#xA;&#xA;<p><em>Extended stacktrace of invalid partition key exception:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,35ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1} ---&gt; System.Runtime.InteropServices.COMException: exception of HRESULT: 0x80071BBF&#xA;   at System.Fabric.Interop.NativeClient.IFabricServiceManagementClient4.EndResolveServicePartition(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.FabricClient.ServiceManagementClient.ResolveServicePartitionEndWrapper(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.Interop.AsyncCallOutAdapter2`1.Finish(IFabricAsyncOperationContext context, Boolean expectedCompletedSynchronously)&#xA;   --- End of inner exception stack trace ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Client.ServicePartitionResolver.&lt;ResolveAsyncHelper&gt;d__2a.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;GetClientAsync&gt;d__a.MoveNext()&#xA;</code></pre>&#xA;&#xA;<p>Please give me feedback if you need more. (full stack trace is 82 lines long)</p>&#xA;&#xA;<p><em>Invalid scheme exception stack trace:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.ArgumentException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,45ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.ArgumentException: the provided uri scheme 'http' is invalid; expected 'net.tcp'.&#xA;Parametername: via&#xA;   at System.ServiceModel.Channels.TransportChannelFactory`1.ValidateScheme(Uri via)&#xA;   at System.ServiceModel.Channels.ConnectionOrientedTransportChannelFactory`1.OnCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ChannelFactoryBase`1.InternalCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.ServiceChannelFactoryOverDuplexSession.CreateInnerChannelBinder(EndpointAddress to, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateServiceChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateChannel(Type channelType, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, Binding binding, EndpointAddress endpointAddress)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Wcf.Client.WcfCommunicationClientFactory`1.&lt;CreateClientAsync&gt;d__2.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;CreateClientWithRetriesAsync&gt;d__1e.MoveNext()&#xA;</code></pre>&#xA;"
45515650,Client per MicroService vs Generic Client | Who is responsible for microservice client?,2017-08-04 21:19:05,<distributed-computing><microservices>,1,156,1,2.0,8,"<p>I have a microService architecture with 10 microServices and each of those provides a client. Inside of that client which is managed/controlled by microService team we just receive the parameters and pass them to a generic http invoker which receives the endpoint and N params and then does the call.&#xA;All microService use http and web api (I guess technology doesn't matter).</p>&#xA;&#xA;<p>For me doesn't make sense to be the microService team to provide a client, should be the responsibility of the consumer, if they want to create some abstractions or invoke it directly is their problem, not a microService problem. And the way I see a web API is as a contract. So I think we should delete all clients (pass responsibility to consumers) on the microService side and create a service layer on the consumer's side that uses the generic invoker to reach the endpoints.</p>&#xA;&#xA;<p>The image below represents all components where the <strong>red line defines</strong> the boundaries, <strong>who is responsible for what</strong>:</p>&#xA;&#xA;<ul>&#xA;<li>The gateway has Adapter Layer </li>&#xA;<li>Adapter Layer references the microService client package </li>&#xA;<li>MicroService client package references Generic HTTP invoker package&#xA;<a href=""https://i.stack.imgur.com/EnjD5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/EnjD5.jpg"" alt=""enter image description here""></a></li>&#xA;</ul>&#xA;&#xA;<p>The other side of that is because we might have N number of consumers and they are all repeating the code of the client. And if the microService provides a client, we have a unique/central place to control that.</p>&#xA;&#xA;<p><strong>Which approach is correct? Is the client a responsability of the microService or the consumer?</strong></p>&#xA;&#xA;<p>This is an internal product.</p>&#xA;"
45551966,Can (or should) 2 docker containers interact with each other via localhost?,2017-08-07 16:50:30,<docker><docker-compose><microservices><consul><docker-networking>,3,938,1,2.0,8,"<p>We're dockerizing our micro services app, and I ran into some discovery issues.</p>&#xA;&#xA;<p>The app is configured as follows:</p>&#xA;&#xA;<p>When the a service is started in 'non-local' mode, it uses Consul as its Discovery registry.&#xA;When a service is started in 'local' mode, it automatically binds an address per service (For example, tcp://localhost:61001, tcp://localhost:61002 and so on. Hard coded addresses)</p>&#xA;&#xA;<p>After dockerizing the app (for local mode only, for now) each service is a container (Docker images orchestrated with docker-compose. And with docker-machine, if that matters)&#xA;But one service can not interact with another service since they are not on the same machine and tcp://localhost:61001 will obviously not work.</p>&#xA;&#xA;<p>Using docker-compose with <a href=""https://docs.docker.com/compose/compose-file/#links"" rel=""noreferrer"">links</a> and specifying localhost as an alias (service:localhost) didn't work. Is there a way for 2 containers to ""share"" the same localhost? </p>&#xA;&#xA;<p>If not, what is the best way to approach this?&#xA;I thought about using specific hostname per service, and then specify the hostname in the links section of the docker-compose. (But I doubt that this is the elegant solution)&#xA;Or maybe use a dockerized version of Consul and integrate with it?</p>&#xA;&#xA;<p>This post: <a href=""https://stackoverflow.com/questions/43547795/how-to-share-localhost-between-two-different-docker-containers"">How to share localhost between two different Docker containers?</a> provided some insights about why localhost shouldn't be messed with - but I'm still quite puzzled on what's the correct approach here.</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
43426699,DB design for microservice architecture,2017-04-15 13:34:54,<database><design><microservices>,2,7671,0,4.0,8,"<p>I am planning to use the Microservices architecture for the implementation of our website. I wanted to know if it is right to share databases between services or if it is preferable to have a separate database for each service. In this regard, can I consider having one common database for all services or does it violate the very essence of Microservice architecture ?</p>&#xA;"
43313424,Consul and Spring Boot services in Docker - not deregistering,2017-04-10 00:36:46,<java><docker><spring-boot><microservices><consul>,2,585,1,2.0,8,"<p>So we have Java microservices written with Spring-Boot, using Consul for service discovery and config management and running in Docker containers.  All of it is working, but when a container dies or a service restarts the old service-id never goes away in Consul and the service forever after shows as ""Failing"" in the Consul UI, even though the new container has registered and shows all Green.</p>&#xA;&#xA;<p>We are not using heartbeat - but I cannot find much documentation on what the difference between heartbeat and healthcheck are for Consul.</p>&#xA;&#xA;<p>Here's my bootstrp.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: my-service&#xA;  cloud:&#xA;    config:&#xA;      enabled: false&#xA;    consul:&#xA;      host: ${discovery.host:localhost}&#xA;      port: ${discovery.port:8500}&#xA;      config:&#xA;        watch:&#xA;          wait-time: 30&#xA;          delay: 10000 &#xA;        profile-separator: ""-""&#xA;        format: FILES&#xA;      discovery:&#xA;        prefer-ip-address: true&#xA;        instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}&#xA;</code></pre>&#xA;&#xA;<p>There are other settings to enable heartbeat, but the docs say something about this putting more stress on the Consul cluster.</p>&#xA;&#xA;<p>Has anyone managed to get Consul and Spring Boot/Docker services to actually de-register automatically?  It actually doesn't cause any real problems, but it makes the Consul UI pretty useless to actually monitor for up/down services.</p>&#xA;"
43489589,.NET Core Microservice using RabbitMQ,2017-04-19 07:47:42,<c#><asp.net-web-api><.net-core><microservices><rawrabbit>,1,5075,2,1.0,8,"<p>I am planing to use Microservice architecture for a project. The selected technology stack is <code>.NET Core</code> with <code>Docker</code> and <code>RabbitMQ</code> as a simple service bus and this should be able to deploy on <code>Linux</code>.</p>&#xA;&#xA;<p>Lets say I have a <code>Payment</code> service and an <code>Order</code> Service, I want each of these services to expose <code>REST</code> endpoints. Because of that, I thought of making these two services as <code>.NET Core Web APIs</code>. </p>&#xA;&#xA;<p>But the problem is the inter-service communication using <code>RabbitMQ</code>. Whenever I get a new <code>order</code>, I want to publish an event using <code>RabbitMQ</code> and then listen to that event in <code>Payment</code> service to perform certain operations (database updates). But since these are <code>Web APIs</code>, I don't think it's possible to listen to events as I described. (I feel like I might have to use something like a console application to subscribe to events.)</p>&#xA;&#xA;<p>I would like to find the most viable method to achieve this using the best practices considering the scalability and extendability of the system.</p>&#xA;"
40458770,"Microservice to Microservice calls, authorization from a queue message",2016-11-07 06:05:22,<spring-security><jwt><microservices><netflix-zuul><keycloak>,2,1044,0,3.0,8,"<p><strong>Context:</strong> I'm creating a cloud platform to support multiple applications with SSO. I'm using <strong>Keycloak for authentication</strong> and <strong>Netflix Zuul for authorization</strong> (API Gateway) thru <strong>Keycloak Spring Security Adapter</strong>.</p>&#xA;&#xA;<p>Each microservice expect an Authorization header, which contains a valid JWT, from which it will take the username (sub) to process the request. Each microservice-to-microservice call should go thru Netflix Zuul first, passing the Authorization header to maintain a stateless validation. That strategy allow to every microservice to know who is the user (sub) who is invoking the microservice indirectly.</p>&#xA;&#xA;<p><strong>Problem/Question 1:</strong> What happens if a microservice is invoked from a queue message? One idea that I had is to storage in the queue the information related to the message + userInfo, and, create a dedicated microservice to process that kind of messages, with that approach this special microservice should read the userInfo from the queue and process the message.</p>&#xA;&#xA;<blockquote>&#xA;  <p>UPDATE 1: Per an email reply from another forum, storing the JWT in a queue isn't a good idea, since it could be mined easily.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Problem/Question 2:</strong> But, what happens if the previous special microservice wants to call another normal microservice which expect to receive a JWT in a header? Should this special microservice create by himself a JWT to impersonate the user and be able to call the regular microservices?</p>&#xA;&#xA;<p>Another solution that I thought was to storage the original JWT in the queue, but, what happens if the queue calls to the special microservice later? Just after the JWT is not valid anymore (it expired) and the microservice called will reject the request?</p>&#xA;&#xA;<p><strong>Possible solutions:</strong> (Updated per JoÃ£o Angelo discussion, see below)</p>&#xA;&#xA;<blockquote>&#xA;  <p>I should authenticate the requests from my users (<strong>Authorization code flow</strong>) and my services (<strong>Client credentials grant</strong>), both requests should contain user information in the payload. When the request it comes from the user, I need to validate that the payload user info match with the JWT claims. When the request comes from a service, I just need to trust in that service (as long as it is under my control).</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate very much your help. Thanks.</p>&#xA;"
40377377,Micro Services communication,2016-11-02 10:16:49,<java><spring><rest><spring-integration><microservices>,5,1062,0,4.0,8,"<p>I'm new to micro-services, and I'm trying to take my project and turn it into  A micro services based project. My problem is figuring out how each service communicates with each other.</p>&#xA;&#xA;<p>First, I explored the REST style service, but if each service is based HTTP REST how do they ""talk"" to each other after all?</p>&#xA;&#xA;<p>Then I tried to learn Spring Integration, but then it became even unclearer how should they communicate because now it came to my mind that maybe I need to use RabbitMQ to be the middleware between the front end and the micro services back end.</p>&#xA;&#xA;<p>I also run into cloud and Docker technologies, so I guess each service should be on the cloud but still it doesn't make it clear how services communicate.</p>&#xA;&#xA;<p>I'm using Java, Spring technologies.</p>&#xA;&#xA;<p>I'll be happy if someone would give me a better picture how things should be.</p>&#xA;"
28607400,Sessions in a Microservice architecture for an E-Commerce system,2015-02-19 13:15:53,<php><magento><soa><single-page-application><microservices>,4,1282,2,5.0,10,"<p>I plan on developing a microservice E-Commerce system as proof of concept. The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li><p>a javascript based single page application, which sends AJAX requests to</p></li>&#xA;<li><p>a server (API Gateway) with a REST API which feeds JSON data received by calling other services</p></li>&#xA;<li><p>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</p></li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento Shopsystem. </p>&#xA;&#xA;<p>When I try to log in a user into they Magento system by sending a request to the REST Api obviously the server doesn't remember the session when sending the next request.</p>&#xA;&#xA;<p>Also I handle the shopping cart on the server side with Magento and add/update/remove items by REST Api calls. Here, also the added items get lost when sending the next request as the session got lost.</p>&#xA;&#xA;<p>So my question is:</p>&#xA;&#xA;<p>What are possible approaches to solve issues regarding session handling in a microservice architecture?</p>&#xA;"
30116581,Call frontend methods from external meteor application,2015-05-08 05:44:51,<meteor><meteor-accounts><microservices>,2,630,0,0.0,10,"<p>I am making a dockerized services-based application. Some of the services will be written in meteor, some won't.</p>&#xA;&#xA;<p>One of the services is a registration service, where users can register for the platform. </p>&#xA;&#xA;<p>When doing microservices, normally I do the following:</p>&#xA;&#xA;<pre><code>var MyService = DDP.connect(service_url);&#xA;var MyOtherService = DDP.connect(other_service_url);&#xA;var RegistrationService = DDP.connect(registration_service_url);&#xA;</code></pre>&#xA;&#xA;<p>What I want to do is use the <code>loginWithFacebook</code> method. The issue is that using <code>Meteor.loginWithFacebook</code> on the frontend will invoke its backend methods on the main frontend server. </p>&#xA;&#xA;<p>However, I want to invoke its backend methods on the RegistrationService server (which has the relevant packages). The reason is because I am using the <code>Accounts.onCreateUser</code> hook to do extra stuff, and also because I want to keep the registration service separate from the frontend.</p>&#xA;&#xA;<p>Just for clarity, even though it is not correct, imagine I have this:</p>&#xA;&#xA;<pre><code>'click #facebook-login': function() {&#xA;  Meteor.loginWithFacebook(data, callback)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I want the <code>loginWithFacebook</code> method to use the server-side methods from <code>RegistrationService</code> <strong>when calling the client-side method .loginWithFacebook</strong>, so I actually want to do something to the effect of the following:</p>&#xA;&#xA;<pre><code>'click #facebook-login': function() {&#xA;  RegistrationService.loginWithFacebook(data, callback)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any help on this will be greatly appreciated. Thank you!</p>&#xA;"
35289988,Authorization and user microservices design,2016-02-09 10:46:09,<microservices>,2,856,2,4.0,10,"<p>I'm trying to design microservice from an existing application with a quite standard user management: has authentication and authorization, and stores user data.</p>&#xA;&#xA;<p>I'm developping an <em>Authorization server</em> to manage user <strong>authentication</strong> and <strong>authorization</strong> using <code>OAuth2</code> as authorization. On other side I have to store user's information/profile.</p>&#xA;&#xA;<p><strong>Question:</strong> Should <em>Authorization server</em> manage:</p>&#xA;&#xA;<ul>&#xA;<li><strong>both authorization and user API?</strong> Thus other microservices can contact <em>Authorization server</em> on <code>/me</code> to get current user but also <code>/users</code> to get full list of users.</li>&#xA;<li><strong>Or only authorization and I have to create <em>User microservices</em>?</strong> Thus <em>Authorization server</em> only exposes <code>/me</code> API related to user and <em>User microservices</em> will expose <code>/users</code>?</li>&#xA;</ul>&#xA;&#xA;<p>The first solution is a bit simpler but the <em>Authorization server</em> will become less generic (less reusable) because user application data model will be part of it (database data model of <code>User</code> table).</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>The other requirement is <strong><em>Authorization server</em> should check if a user exists before authorizing it</strong>. </p>&#xA;&#xA;<p>There is no user auto-creation, users must be invited by <em>administrator</em> to get access.&#xA;With this requirement, the first solution is simple because <em>Authorization server</em> has access to user database but the second solution <em>Authorization server</em> implies:</p>&#xA;&#xA;<ol>&#xA;<li>Share database with <em>User service</em> (hum don't like that)</li>&#xA;<li>Call <em>User service</em> before authorization using REST API (for example) </li>&#xA;<li><em>Authorization server</em> should maintain minimal <code>User</code> table (can be renamed <code>Account</code>) and administrator will not create user on <em>User service</em> but only user account on <em>Authorization server</em></li>&#xA;</ol>&#xA;&#xA;<p>I think <strong>1.</strong> solution is out but any advices about <strong>2.</strong> and <strong>3.</strong>?</p>&#xA;&#xA;<p><strong>3.</strong> in first place seems the best, but if I want to switch to another <em>Authorization server</em>, for example a public one (OAuth2) like Google, Github, Facebook, etc... Security can be compromise because we can't control user account creation.</p>&#xA;&#xA;<p>Any feedback?</p>&#xA;"
32741333,Session Management in microservices,2015-09-23 13:43:15,<java><session><cookies><weblogic><microservices>,1,9293,3,5.0,10,"<p>We have the following setup.</p>&#xA;&#xA;<ol>&#xA;<li>STM (Stingrey Traffic Manager) does load balancing + session stickiness</li>&#xA;<li>Weblogic 'cluster'</li>&#xA;<li>Auth handled by a third party tool</li>&#xA;</ol>&#xA;&#xA;<p>Therefore I do not have to worry about session with regards to horizontal scaling/ running multiple instances of the application. STM/ Weblogic cluster makes sure that the subsequent request come to same managed server.</p>&#xA;&#xA;<p>What we currently have is a monolithic application and we are trying to move to microservices. Also we do not wan't to move out of current infrastructure (i.e. STM/ Weblogic cluster/ Auth tool). What we have planned is:</p>&#xA;&#xA;<ol>&#xA;<li>A Gateway WAR which routes requests to other microservices</li>&#xA;<li>N x Microservices (WAR) for each functional sub-domain</li>&#xA;<li>Only the API Gateway receives user requests and other microservices are not accessible from outside</li>&#xA;</ol>&#xA;&#xA;<p>So my question is</p>&#xA;&#xA;<ol>&#xA;<li>Should API Gateway be state-full while other microsevices are stateless?</li>&#xA;<li>If so, how should the user session data be shared between API Gateway and microservices?</li>&#xA;</ol>&#xA;&#xA;<p>Please suggest any better alternatives and resources/links as well.  Thanks.</p>&#xA;"
36461493,Customizing Zuul Exception,2016-04-06 20:17:50,<java><spring-boot><spring-cloud><microservices><netflix-zuul>,4,9134,5,6.0,10,"<p>I have a scenario in Zuul where the service that the URL is routed too might be down . So the reponse body gets thrown with 500 HTTP Status and ZuulException in the JSON body response.</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": 1459973637928,&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""com.netflix.zuul.exception.ZuulException"",&#xA;  ""message"": ""Forwarding error""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>All I want to do is to customise or remove the JSON response and maybe change the HTTP status Code.</p>&#xA;&#xA;<p>I tried to create a exception Handler with @ControllerAdvice but the exception is not grabbed by the handler.</p>&#xA;&#xA;<p><strong>UPDATES:</strong></p>&#xA;&#xA;<p>So I extended the Zuul Filter I can see it getting into the run method after the error has been executed how do i change the response then. Below is what i got so far. I read somewhere about SendErrorFilter but how do i implement that and what does it do?</p>&#xA;&#xA;<pre><code>public class CustomFilter extends ZuulFilter {&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        return ""post"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;&#xA;        return 1;&#xA;    }&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        return true;&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;        final RequestContext ctx = RequestContext.getCurrentContext();&#xA;        final HttpServletResponse response = ctx.getResponse();&#xA;        if (HttpStatus.INTERNAL_SERVER_ERROR.value() == ctx.getResponse().getStatus()) {&#xA;            try {&#xA;                response.sendError(404, ""Error Error""); //trying to change the response will need to throw a JSON body.&#xA;            } catch (final IOException e) {&#xA;                e.printStackTrace();&#xA;            } ;&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added this to the class that has @EnableZuulProxy</p>&#xA;&#xA;<pre><code>@Bean&#xA;public CustomFilter customFilter() {&#xA;    return new CustomFilter();&#xA;}&#xA;</code></pre>&#xA;"
38786207,Netflix Feign - Propagate Status and Exception through Microservices,2016-08-05 09:46:14,<java><spring><spring-boot><microservices><netflix-feign>,4,13177,0,1.0,10,"<p>I'm using <a href=""https://github.com/OpenFeign/feign/blob/master/okhttp/src/main/java/feign/okhttp/OkHttpClient.java"" rel=""noreferrer"">Netflix Feign</a> to call to one operation of a Microservice A to other other operation of a Microservice B which validates a code using Spring Boot. </p>&#xA;&#xA;<p>The operation of Microservice B throws an exception in case of the validation has been bad. Then I handled in the Microservices and return a <code>HttpStatus.UNPROCESSABLE_ENTITY</code> (422) like next:</p>&#xA;&#xA;<pre><code>@ExceptionHandler({&#xA;       ValidateException.class&#xA;    })&#xA;    @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY)&#xA;    @ResponseBody&#xA;    public Object validationException(final HttpServletRequest request, final validateException exception) {&#xA;        log.error(exception.getMessage(), exception);&#xA;        error.setErrorMessage(exception.getMessage());&#xA;        error.setErrorCode(exception.getCode().toString());&#xA;        return error;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So, when Microservice A calls to B in a interface as next:</p>&#xA;&#xA;<pre><code>@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /other"")&#xA;void otherOperation(@Param(""other"")  String other );&#xA;&#xA;@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /code/validate"")&#xA;Boolean validate(@Param(""prefix"") String prefix);&#xA;&#xA;static PromotionClient connect() {&#xA;&#xA;    return Feign.builder()&#xA;        .encoder(new GsonEncoder())&#xA;        .decoder(new GsonDecoder())&#xA;        .target(PromotionClient.class, Urls.SERVICE_URL.toString());&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the validations fails It returns a internal error 500 with next message:</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": ""2016-08-05T09:17:49.939+0000"",&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""feign.FeignException"",&#xA;  ""message"": ""status 422 reading Client#validate(String); content:\n{\r\n  \""errorCode\"" : \""VALIDATION_EXISTS\"",\r\n  \""errorMessage\"" : \""Code already exists.\""\r\n}"",&#xA;  ""path"": ""/code/validate""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I need to return the same as the Microservice operation B.</p>&#xA;&#xA;<p>Wich would be the best ways or techniques to propagate Status and Exceptions through microservices using Netflix Feign?</p>&#xA;"
43983286,GraphQL and Microservices,2017-05-15 15:26:09,<rest><architecture><microservices><graphql>,2,1942,0,7.0,10,"<p>At my company we've decided on a microservice architecture for a new project.&#xA;We've taken a look at GraphQL and realised its potential and advantages for using as our single API endpoint.</p>&#xA;&#xA;<p>What we disagree on is how the communication should be done between GraphQL and each micro service. Some argue for REST, others say we should also have a graphQL endpoint for each service. </p>&#xA;&#xA;<p>I was wondering what are some of the pros and cons of each.&#xA;For example, having everything in graphQL seems a bit redundant, as we'd be replicating parts of the schema in each service.&#xA;On the other hand, we're using GraphQL to avoid some REST pitfalls. We're afraid having REST endpoints will nullify the advantages gained from gQL.</p>&#xA;&#xA;<p>Has anyone come across a similar dilemma?&#xA;None of us are experienced with GraphQL, so is there some obvious pro and con here that we might be missing?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
44884316,How to implement contract testing when kafka is involved in microservice architecture?,2017-07-03 11:23:29,<java><jvm><apache-kafka><microservices><pact>,1,1471,0,2.0,10,<p>I am currently working on a project where we have kafka implementation in micro service architecture. Were you successful in creating contract test cases for mS to kafka topic interaction please using pact-jvm ?</p>&#xA;&#xA;<p>My implementation is microservice1 publishes a message to a REST Client which in turn posts the message to Kafka Topic. microservice2 uses GET method to retrieve messages from the Kafka Topic.</p>&#xA;
41010290,Microservices: REST vs Messaging,2016-12-07 05:49:29,<rest><architecture><messaging><microservices>,2,5671,2,2.0,10,"<p>I heard Amazon uses HTTP for its microservice based architecture. An alternative is to use a messaging system like RabbitMQ or Solace systems. I personally have experience with Solace based microservice architecture, but never with REST. <br>&#xA;Any idea what do various big league implementations like Amazon, Netflix, UK Gov etc use?<br>&#xA;Other aspect is, in microservices, following things are required (besides others):<br>&#xA;* Pattern matching<br>&#xA;* Async messaging.. receiving system may be down<br>&#xA;* Publish subscribe<br>&#xA;* Cache load event.. i.e. on start up, a service may need to load all data from a couple of other services, and should be notified when data is completely loaded, so that it can 'know' that it is now ready to service requests&#xA;<br>&#xA;These aspects are naturally done with messaging rather than REST. Why should anyone use REST (except for public API). Thanks.</p>&#xA;"
40495213,Service fabric projects in separate git repos,2016-11-08 19:46:45,<c#><azure><microservices><azure-service-fabric>,4,514,1,3.0,10,<p>Following a normal microservices framework we would like to place each microservice in it's own git repo and then have one repository for the Service Fabric project.  When we update one of the microservice the though would be that the Service Fabric project would redeploy just that service.</p>&#xA;&#xA;<p>Is there any examples of splitting the Service Fabric project up like this?  I've noticed in all of their examples everything is in one solution/repository.</p>&#xA;
43612866,Microservices with shared database? using multiple ORM's?,2017-04-25 14:01:50,<database><orm><microservices>,2,7791,3,3.0,10,"<p>I'm learning about microservices and I'm gonna build a project with a microservices architecture.</p>&#xA;&#xA;<p>The thing is, one of my team mates want to use one database for all services, sharing all tables so ""data doesn't get repeated"", each service would be built with different frameworks and languages like django and rails which use very different ORM standards.</p>&#xA;&#xA;<p>What would be the correct approach? Since I think working with one database would involve a lot of ""hacking"" the ORMs in order to make them work correctly.</p>&#xA;"
25965275,what suitable Scala framework can I choose to use for microservice,2014-09-22 00:36:00,<scala><microservices>,1,1197,1,0.0,-2,"<p>Currently, I am using finagle Scala web framework as microservice for our project, They are very easy to use and also convenient to be deployable. At the same time, my colleague are trying to use Play framework for micro service, but I think it is too huge. It is not micro anymore. </p>&#xA;&#xA;<p>May I know what is your opinion about this and is there any other good microservice framework in scala should be taken into consideration ?</p>&#xA;&#xA;<p>Many thanks in advance</p>&#xA;"
50629814,"Javascript library to collect objects properties, do batch processing and map results back to objects",2018-05-31 17:33:21,<javascript><node.js><microservices>,3,65,0,0.0,-2,"<p>For array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1},&#xA;    {id: 2, name: ""test"", tagId: 15},&#xA;    {id: 3, name: ""test"", tagId: 5},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Need to reduce list of specific properties (tagId) to unique array [1,15,5], call some batch processing method, for example, doing http request for API for list of entities:</p>&#xA;&#xA;<pre><code>async (ids) =&gt; await axios.get('http://apihost/tag', {id: ids})&#xA;</code></pre>&#xA;&#xA;<p>For result array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""tag1""},&#xA;    {id: 15, name: ""tag2""},&#xA;    {id: 5, name: ""tag3""},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Finally need to map this objects by ID attribute to original array of objects matching by result.id => original.tagId, in fact doing an SQL join of two arrays to get this (like <a href=""https://github.com/mtraynham/lodash-joins"" rel=""nofollow noreferrer"">https://github.com/mtraynham/lodash-joins</a>):</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1, tag: {id: 1, name: ""tag1""}},&#xA;    {id: 2, name: ""test"", tagId: 15, tag: {id: 15, name: ""tag2""}},&#xA;    {id: 3, name: ""test"", tagId: 5, tag: {id: 5, name: ""tag3""}},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>I'm already wrote a PHP library for this with API like:</p>&#xA;&#xA;<pre><code>new BulkMap(source).map(&#xA;  'tagId',&#xA;  'tag',&#xA;  async (ids) =&gt; axios.get('http://apihost/tag', {id: ids})&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>But now i need this in JS. Is there any Javascript/NodeJS library to do so? It looks like pretty common used pattern for microservices.</p>&#xA;"
36415988,Is there some crashreporting library for java applications?,2016-04-05 02:17:38,<java><monitoring><microservices><reliability>,1,56,3,0.0,-2,"<p>I wan't to be able to perform Asserts in production runtime, and send out crash reports (with CRITICAL or WARNING messages) through different channels. Emails being one of them.</p>&#xA;&#xA;<p>As you can see, I wan't this library to be performing collection of most commonly required stats - like Stacktrace, Host details, configurations etc. </p>&#xA;"
38697565,I want to break my monolithic to microservices but I'm still stuck on it. Need advise,2016-08-01 11:21:48,<architecture><microservices>,1,198,1,0.0,-2,"<p>So far, my developing application is planned to be available on web and mobile so I decided to do it as microservice.</p>&#xA;&#xA;<p>What my app can do so far is listed below:</p>&#xA;&#xA;<ul>&#xA;<li>Sign up (email, username, password, password_confirmation)</li>&#xA;<li>Sign in (email, password)</li>&#xA;<li>Sign in using Facebook (automatically sign in if email is exist in db, or create new record then automatically sign in when email is not exist in db)</li>&#xA;<li>View articles</li>&#xA;<li>Post articles</li>&#xA;<li>Edit articles</li>&#xA;<li>Delete articles</li>&#xA;</ul>&#xA;&#xA;<p>As actions above, <strong>how many services should I break into</strong>? <em>I'm not sure to split every actions in to service like sign-up-service / sign-in-service or group it up as user-service is the right way.</em></p>&#xA;&#xA;<p>An another question, <strong>when I split services separately how can I get articles data with the authors to render on my sites?</strong> <em>Build new broker service which get articles data within article-service then get author data within user-service after that</em>? Or, broker service is no needed, just simply get articles data then author data in my web-application controller.</p>&#xA;"
51035930,Spring Boot REST API Endpoint Mapping best practice,2018-06-26 06:08:59,<rest><api><web-services><spring-boot><microservices>,2,185,1,0.0,-2,"<p>I am using bellow endPoint  URL Mapping with HTTP Methods like ( POST,DELETE,GET,PUT)</p>&#xA;&#xA;<p>POST for Create a new Trade - </p>&#xA;&#xA;<pre><code>@PostMapping(""/trade"")&#xA;</code></pre>&#xA;&#xA;<p>DELETE for Delete a Trade with specific id - </p>&#xA;&#xA;<pre><code>@DeleteMapping(""/trade/{id}"")&#xA;</code></pre>&#xA;&#xA;<p>GET for Get details of specific Trade - </p>&#xA;&#xA;<pre><code>@GetMapping(""/trade/{id}"")&#xA;</code></pre>&#xA;&#xA;<p>PUT for Update Trade details - </p>&#xA;&#xA;<pre><code>@PutMapping(â€œ/trade/{id}â€)&#xA;</code></pre>&#xA;&#xA;<p>GET for Retrieve all Trade list of collection - </p>&#xA;&#xA;<pre><code>@GetMapping(""/trades"")&#xA;</code></pre>&#xA;&#xA;<p>if I am missing anything here Please suggest</p>&#xA;"
51388064,JSF application : should I use micro-services and how?,2018-07-17 18:25:22,<angularjs><reactjs><jsf><java-ee><microservices>,1,69,0,0.0,-2,"<p>I have a web application developed with JSF 2 and primefaces. The project has been frozen for months, but it's quite advanced, the whole application run inside the same container under glassfish, so it's a monolith.</p>&#xA;&#xA;<p>My application has an user interface and its purpose is to offer them the possibility to organize urls to tutorials (any kinds) as cards, with tags for the classification, into folders. So any user has its own tree, they can make a research inside the other users's tree create a link on a file in their own tree, copy a entire folder, reorganize it etc.</p>&#xA;&#xA;<p>Nowedays we hear a lot about microservices, Spring boot, Angular Js, react etc. I like to develop with JSF it's a great framework, but I'm asking myself about refactoring my application, at least the necessary parts into microservices, and if JSF is appropriate for that or if I should user other tools.</p>&#xA;&#xA;<p>What I like for example with JSF is the facility to create views, its component approach, and how it handle the full cycle of a request.</p>&#xA;&#xA;<p>For example with a simple folder creation form :</p>&#xA;&#xA;<p>I have to choose the parent folder, so I can bind a research component to a backing bean that makes a research indirectly in my DB using a DAO ( in my app an EJB using JPA). That happens at the ""invoke application"" phase and refresh my form list with ajax at the end. When I submit the form I can also bind a converter to the research component to retrieve directly a Folder object, the converter uses also a DAO to retrieve the object that I need at the ""Invoke application"" phase to finish the job.</p>&#xA;&#xA;<p>I also use validators to control different attributes of a new folder, usually I declare them inside my entity class (Folder, User ...) with annotations like @NotNull etc. Before I save the folder on my db, I also check the user rights to see if he can write inside the parent folder and so on. I do that inside the backing bean, so at the 'invoke application' phase, and return a faces message if anything happens wrong.</p>&#xA;&#xA;<p>When I read about micro-services I see that you can use them directly inside a form using json for communication, so it seems quite different. For example if I have a micro-service for the CRUD operations of my folders, are the validators, the converters, part of the service or are they stand alone services ? And what about the security checks ? that kind of architecture is quite mysterious to me.</p>&#xA;&#xA;<p>ps : English is not my mother tongue so be indulgent please :)</p>&#xA;"
51382040,How to merge user accounts in different systems?,2018-07-17 13:00:08,<c#><microservices>,1,41,2,0.0,-2,<p>I writing a system that synchronyze with another systems. We work on user account synchronization. Currently I faced with next problem: </p>&#xA;&#xA;<p>User register in System_1 and then register in System_2. </p>&#xA;&#xA;<p>System_2 send notification (via RebbitMQ) to  System_1.</p>&#xA;&#xA;<p>System_1 should understand is it need to create new account OR Update existed account and write a ExternalID for concrete user.</p>&#xA;&#xA;<p>What about best practice of how it should be done? </p>&#xA;
42491958,How to use two different database in one app?,2017-02-27 17:22:09,<php><node.js><mongodb><google-cloud-messaging><microservices>,1,45,0,0.0,-2,"<p>Just asking, how to use two different databases (<code>mysql</code>, <code>mongodb</code>) in one app.</p>&#xA;&#xA;<p>I have created two micro-services </p>&#xA;&#xA;<ol>&#xA;<li>Authentication service</li>&#xA;<li>Messaging service for my chat app.</li>&#xA;</ol>&#xA;&#xA;<p>The authentication is done in <code>node.js</code> mongo&#xA;The messaging service in <code>php</code> and <code>mysql</code> using <code>FCM</code>.</p>&#xA;&#xA;<p>At the moment i have two different android app&#xA;One authenticate user and the other send messaging with push notification.</p>&#xA;&#xA;<p>Both information are stored in their own respective database.</p>&#xA;&#xA;<p>How do i coming the two of them and allowing the <code>mongodb</code> to store user info only with <code>GCM</code> reg token and <code>mysql</code> to store chat rooms and channel.</p>&#xA;&#xA;<p>If this question is kinda vague let me know, I will narrow it down.</p>&#xA;&#xA;<p>thanks in advance </p>&#xA;"
47202936,Study- or research-paper on how to implement trunk-based/master-branch development?,2017-11-09 13:20:53,<microservices><branching-and-merging><trunk><featuretoggle>,1,28,1,0.0,-2,"<p>Please could You share a study- or research-paper on how to implement â€œtrunk-basedâ€/master-branch development (as opposed to have long-lived sub branches) in a micro-service based environment ?</p>&#xA;&#xA;<p>Preferably a study giving business case ($$$) justifications and proofs of benefits of such approach.</p>&#xA;&#xA;<p>Which can convince developers and managers alike that itâ€™s important to strive for short-lived branches for example using â€œfeature togglesâ€.</p>&#xA;&#xA;<p>As opposed to having long-lived (sub)branches that is difficult to merge back into master, and which makes automation testing hard due to not testing â€œthe (main)trunk/masterâ€ sufficiently often.</p>&#xA;&#xA;<p>Furthermore it would be interesting if the paper discuss, common pitfalls, pros and cons and  (practical) obstacles in implementing ""trunk-based"" development for example how to handle changes in contract versions between micro-services(teams), for example using feature toggles between micro-services when trunk/master is updated continuously from many micro-teams?</p>&#xA;&#xA;<p>If the paper mention PACT or similar framework would be a additional benefit to convince management in the right direction.</p>&#xA;&#xA;<p>Thank you!</p>&#xA;"
47296131,Transaction Management for Shared DB in Microservices,2017-11-14 22:14:06,<database><spring><microservices>,2,66,2,0.0,-2,"<p>I have 2 Microservices that using same DB </p>&#xA;&#xA;<ol>&#xA;<li>First Microserivce for Balance Management .</li>&#xA;<li>Second Microserivce for Reservation Management.</li>&#xA;</ol>&#xA;&#xA;<p>And I have the following business scenario: </p>&#xA;&#xA;<ol>&#xA;<li>Need to check if the client have balance by calling REST Services from (Balance Management Microservice).</li>&#xA;<li>If he have balance , then I have to call another REST Services to reserved the balance from (Balance Management Microservice ) .</li>&#xA;<li>Then I have to do some kind of airline reservation also by calling another REST Service from (Reservation Management).</li>&#xA;</ol>&#xA;&#xA;<p>So the question is how to rollback the step 2 if the step 3 fail by using Transaction Management between REST Services by taking care that all Microservice using same DB</p>&#xA;"
49607242,Is docker only used for applications that based on micro-service architecture,2018-04-02 07:40:43,<docker><microservices><virtualization><linux-containers>,1,28,0,0.0,-2,"<p>I am totally new to this... So please explain in layman's terms.</p>&#xA;&#xA;<p>We want to shift our application(actually my employer application, currently using Weblogic server) to micro-service architecture and deploy each component to individual containers(planning to use docker).</p>&#xA;&#xA;<p>My concern is, can we only use docker for applications that are based on micro-service architecture or we can use docker for any kind of application. I am sure, I am missing something here and there. </p>&#xA;&#xA;<p>Please Explain the whole process in simple terms as I am a newbie in this technology.</p>&#xA;"
49973699,Extend an interface method in a non-local package,2018-04-23 05:02:37,<go><interface><network-programming><microservices>,2,62,0,0.0,-2,"<p>Trying to create a microservice within Go, I have a package network to take care of getting the bytes and converting to a particular request:</p>&#xA;&#xA;<pre><code>package network&#xA;&#xA;type Request interface {&#xA;}&#xA;&#xA;type RequestA struct {&#xA;a int&#xA;}&#xA;&#xA;type RequestB struct {&#xA;b string&#xA;}&#xA;&#xA;func GetRequestFromBytes(conn net.Conn) Request {&#xA;buf := make([]byte, 100)&#xA;_, _ := conn.Read(buf)&#xA;switch buf[0] {&#xA;case 0:&#xA;    // convert bytes into RequestA&#xA;    requestA = RequestAFromBytes(buf[1:])&#xA;    return requestA&#xA;case 1:&#xA;    requestB = RequestBFromBytes(buf[1:])&#xA;    return requestB&#xA;}}&#xA;</code></pre>&#xA;&#xA;<p>Now in the main, I want to handle the request.</p>&#xA;&#xA;<pre><code>package main&#xA;import (&#xA;    ""network""&#xA;)&#xA;&#xA;(ra *RequestA) Handle() {&#xA;// handle here&#xA;}&#xA;&#xA;(rb *RequestB) Handle() {&#xA;// handle&#xA;}&#xA;&#xA;func main() {&#xA;    // get conn here&#xA;    req = GetRequestFromBytes(conn)&#xA;    req.Handle()&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, Golang does not allow RequestA/RequestB classes to be extended in the main package. Two solutions I found online were type aliasing/embedding, but in both it looks like we'll have to handle by finding the specific type of the request at runtime. This necessitates a switch/if statement in both network and main packages, which duplicates code in both.</p>&#xA;&#xA;<p>The simplest solution would be to move the switch statement into package main, where we determine the type of the request and then handle it, but then package main would have to deal with raw bytes, which I'd like to avoid. The responsibility of finding the request type and sending it 'upwards' should rest with the network package.</p>&#xA;&#xA;<p>Is there a simple idiomatic Go way to solve this?</p>&#xA;"
49910421,Is this microserviced?,2018-04-18 23:21:42,<java><spring-boot><microservices>,3,59,5,3.0,-2,"<p>I have created a simple blogging application using Spring Boot and RESTful APIs.  I have connected the same to a MySQL database to run some SQL queries like those for adding a blog, deleting a blog, etc.</p>&#xA;&#xA;<p>My questions are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>Does it mean that I have used a <em>microservice</em> architecture?  When does an architecture become a <em>microservice</em>? (I ask because many similar websites call an application as microservice-based.  Other than the main application, e.g., currency exchange instead of blogging, I see no other difference; for e.g., <a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">this one</a> - it does have many more aspects, but they are not contributing to its <em>microservice</em>-ness, IMHO).  </p></li>&#xA;<li><p>Can I call an application as horizontally scalable if I am using <em>microservice-based</em> architecture?</p></li>&#xA;</ol>&#xA;&#xA;<p>Note:  The tutorial I followed is <a href=""https://medium.com/@salisuwy/building-a-spring-boot-rest-api-part-iii-integrating-mysql-database-and-jpa-81391404046a"" rel=""nofollow noreferrer"">here</a> and the GitHub repo is <a href=""https://github.com/salisuwy/building-spring-boot-resp-api-v3"" rel=""nofollow noreferrer"">here</a>.</p>&#xA;"
50334652,Creating Microservices in ATG 10.2,2018-05-14 16:05:45,<microservices><atg>,1,38,1,0.0,-2,"<p>As part of requirements, there is an expectation to create microservices for an existing ecommerce platform. The current architecture runs on ATG 10.2 version and has some rest API's hosted on it.</p>&#xA;&#xA;<p>Given the fact that ATG is a monolithic ecommerce framework, is there any way that we can create microservices in ATG? Even if we are able to do so, how will they run as independent services? i mean how can we deploy them and test them in other environment? Wanted to know the technical feasibility of creating microservices on ATG ecommerce platform.</p>&#xA;"
40884616,REST based message queue for microservices,2016-11-30 09:29:26,<java><activemq><message-queue><microservices>,1,660,3,0.0,-2,"<p>I'm given a task to implement Message queue to publish and consume message over queue but my requirement is, i'm gonna need to interact with queue using REST API (eg: ActiveMQ having REST API but problem with ActiveMq is when implementing consumer  we don't have way to keep waiting for message queue to fetch,we cant listen to the queue using REST client ).&#xA;So  i'm leaving my problem to you guys to give me better alternative for this &#xA;NOTE - solution should use only open source product only </p>&#xA;"
50281965,Microservice architecture with API Gateway talking to Message Broker instead of directly to Microservices,2018-05-10 21:45:51,<docker><architecture><rabbitmq><microservices><messagebroker>,1,86,1,0.0,-2,<p>One of the main concerns when implementing an API Gateway is that you are coupling that tier with the internal microservices. Is there such an architecture having the API Gateway only communicate directly to a message broker like Rabbit MQ which then talks to the microservices based on the message?</p>&#xA;&#xA;<p>In most architecture guides that I see the message broker is used for microservice to microservice communication only. Why not make it be used for API Gateway and microservice to microservice communication?</p>&#xA;
50835951,Monolith to microservices,2018-06-13 11:21:06,<microservices><roadmap>,1,44,0,0.0,-2,"<p>Heeeey,</p>&#xA;&#xA;<p>I have to create a roadmap for a website that wants to go from a monolith website to a microservices website. Now I understand that you have to do it step by step, but I am not sure which exacts tasks there need to be done in every step. Can someone help me to define these detailed taks?</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
50891382,Unit test does not cover locally imported packages,2018-06-16 20:08:02,<go><microservices><go-gin><go-toolchain>,1,55,4,0.0,-2,"<p>I am new to golang and trying to understand how i can make this scenario work?</p>&#xA;&#xA;<p>Here is my structure&#xA;GOPATH set to /Users/xyz/project</p>&#xA;&#xA;<pre><code>/Users/xyz/project/src/main.go // import calculator and call SUM with two integeres&#xA;/Users/xyz/project/src/main_test.go // test function&#xA;/Users/xyz/project/src/calculator/sum.go // SUM function (add two integers)&#xA;</code></pre>&#xA;&#xA;<p>i have a main go file that imports ""calculator"" which is a local packages. When i run </p>&#xA;&#xA;<pre><code>go test -cover&#xA;</code></pre>&#xA;&#xA;<p>it only gives the coverage of main but not for the package ""calculator"" imported by main. i know i can write a test inside calculator and that would do the trick but is there any way possible to get the coverage of locally imported package from main?</p>&#xA;&#xA;<p>Bigger Context - The reason i want to do this is because i have a micro service written in go using gin framework and i want to spin it up as a service and make http calls and further see how the coverage looks like (like component test). I can easily spin it up by writing a main_test go file which starts the service but i am not getting the coverage of the imported packages.</p>&#xA;"
47469430,Add failover to Java microservice,2017-11-24 08:46:48,<java><microservices><failover>,1,63,0,0.0,-2,"<p>I have a Java miroservice, which will be deployed as multiple service instances. The microservice works statelessly in a simple way: fetch a request according to predefined criteria from DB, process the request, fetch next and process it, and so on. &#xA;I consider now to add failover to the service. I might need add extra information(like processor_id) to the request if it's processed by some instance. So if the instance is determined without response, the request can be taken by other instances. I also need add heartbeat to the microservice. Maybe I can leverage Apache Zookeeper or Curator to achieve this.&#xA;But I don't know how to make different pieces work together. It'll be better if there are examples in Java.</p>&#xA;"
43657535,Is there an alternative to an API Gateway?,2017-04-27 12:14:43,<api><soa><microservices><gateway>,1,275,2,0.0,-2,"<p>I am designing a new architecture for a group of services in my organization, and I want to know -&#xA;Is there an alternative method for the API Gateway as we know it, which serves similar needs (Centralization, monitoring etc.) or should I focus on this common architecture?</p>&#xA;&#xA;<p>Thanks :)</p>&#xA;"
43593778,Microservices design,2017-04-24 16:53:13,<java><spring><microservices>,1,122,9,1.0,-2,"<p>I am new to microservices and I am getting a hardtime in understanding what they exactly are. I would take an example situation, if you can break it down to how microservices should be written for this scenario then it woud be really great. </p>&#xA;&#xA;<p>Scenario: I have to work with two content management systems: Documentum and IBM FileNet.</p>&#xA;&#xA;<p>For each content management system I want to write an implementation to - </p>&#xA;&#xA;<ol>&#xA;<li>Create a new file or a folder.</li>&#xA;<li>Update a fileor a folder. </li>&#xA;<li>Delete a fileor a folder.</li>&#xA;<li>Update fileor folder metadata.</li>&#xA;<li>Search a file.</li>&#xA;<li>Get content of a file.</li>&#xA;<li>Create and Update permission sets applied on file or folder.&#xA;etc. </li>&#xA;</ol>&#xA;&#xA;<p>How should I break this down to microservices? &#xA;Should I write implementation for each content management systems in a seperate microservice? </p>&#xA;&#xA;<p>Please help.</p>&#xA;&#xA;<p>Thanks </p>&#xA;"
45830528,Separating Login and User Management from Application,2017-08-23 04:11:35,<wordpress><authentication><oauth><microservices><user-management>,2,40,1,0.0,-2,"<p>I'm looking to completely decouple user management, login, permissions, and user data from my application. The main reason for this, is the application will consist of a WordPress site, native app, and a custom PHP API that all need to allow a user to login.</p>&#xA;&#xA;<p>I don't want to use WP as the user login as I don't want to tie all our user data to WP in case we want to migrate to something else in the future. I've looked at things like Auth0, but it seems like it fairly heavy and costly.&#xA;What I'd like to do instead is build a separate service that can be used to store user fields, meta data, permissions, and act as a login service.</p>&#xA;&#xA;<p>Based on those credentials, I can give access to certain sections of WP, unlock content on the Native App, and authenticate for certain access level for our API. Has anyone had any experience with decoupling their user management with a similar scenario?</p>&#xA;"
26247474,Is Apache Camel irrelevant when Spring Cloud is used?,2014-10-08 00:38:08,<apache-camel><mule><spring-boot><microservices><spring-cloud>,1,1095,0,0.0,-1,"<p>I am involved in the design of a service that uses Spring Cloud and Apache Camel. I was taken aback today when a colleague asked (maybe advocating would be a better term) whether we really need Apache Camel. From his perspective, most of the downstream systems we talk to are REST-based and therefore, no integration framework should be needed. If my recollection is correct, he also implied that Microservices and Integration Frameworks are incompatible.</p>&#xA;&#xA;<p>I started passionately suggesting that Spring Cloud helps solve a deployment/ops issue while Integration frameworks solve integration issues and that they have orthogonal requirements.</p>&#xA;&#xA;<p>Here are some of the protocols the system will be using to communicate:</p>&#xA;&#xA;<pre><code>REST&#xA;SOAP&#xA;AMQP&#xA;Azure SDK&#xA;AWS SDK (S3, SimpleBD, etc.)&#xA;Dropbox SDK&#xA;Paypal SDK&#xA;Braintree SDK&#xA;Caching (Memcached, EhCache)&#xA;Async (VM, Direct-VM, SEDA, SEDA-VM)&#xA;Facebook&#xA;Twitter&#xA;FTP&#xA;SMTP&#xA;File IO&#xA;SOLR/Elesticsearch&#xA;Quartz&#xA;</code></pre>&#xA;&#xA;<p>Unknown protocols: as we integrate in customers environment we need to integrate with their systems. The communication protocols are yet unknown.</p>&#xA;&#xA;<p>The following statement by Martin Fowler and James Lewis seems to suggest that ESB and Microservices are incompatible: ""We can't resist mentioning Jim Webber's statement that ESB stands for ""Egregious Spaghetti Box"". Now, how far do you think this statement applies to an integration framework such as Apache Camel?</p>&#xA;&#xA;<p>And more generally, does my colleague have a point? Does this mean that integration patterns have no place in microservices?</p>&#xA;"
25974964,Are micro-services in low latency systems a good recommendation?,2014-09-22 13:08:57,<java><design><low-latency><microservices>,1,609,2,0.0,-1,"<p>I am building a low latency system that does some currency exchange transactions to some exchanges and a friend recently told me that my micro-services approach is going to make things slower... I don't fully agree with him, and I think that it should be no major impact in performance and micro-services is the right path to go in order to have a more maintainable system. &#xA;I would be happy in getting some feedback from you to see what do you think about this topic.</p>&#xA;&#xA;<p>More specifically, in use case, I have an app that queries some data from some provider, transforms it to a JSon and sends it to the next application. The second application unmarshall the JSonMessage do some calculations, marshalls again and sends it to the third application. The third and last application its very simple it just needs to perform an operation in some currency exchanges with that message.  </p>&#xA;&#xA;<p>So my friend says that I should embed all 3 apps into 1 due to lack of performance when marshalling and unmarshalling... I can clearly distinguish different reasons to exist independently to each of the 3 apps, and I don't think it will be problematic to work in this style. Also I want to mention that I don't use any database or any sort of state, the hold system its completely stateless.</p>&#xA;"
50677506,Udacity Docker and Kubernets,2018-06-04 09:35:33,<docker><kubernetes><microservices>,1,31,0,0.0,-1,"<p>What all courses are necessary before taking the course <a href=""https://in.udacity.com/course/scalable-microservices-with-kubernetes--ud615"" rel=""nofollow noreferrer"">scalable-microservices-with-kubernetes</a></p>&#xA;"
28635179,Microservices with Flask,2015-02-20 17:50:37,<python><flask><docker><soa><microservices>,1,3560,0,0.0,-1,"<p>We are building a pretty large system that will expose several different REST API's, contain a Mongodb database, a Redis cache layer, and a backend computational library. Currently we are using Flask-Restful for building our API's, but for various reasons we also need to run another instance of Flask that provides database resources, and another layer on top of a front facing site. Blueprints are not really a solution since we might want to decouple these various services on different machines in ec2.</p>&#xA;&#xA;<p>We were planning to use Apache+WSGI as a production server, however each flask server would require a unique port, and it is a nightmare to manage all these microservices. I've heard of the concept of a gateway API, but I couldn't really find an documentation on how to implement one or how that looks in practice. </p>&#xA;&#xA;<p>Microservices/SOA seems like a really huge deal these days and in some sense our architecture is designed around that. But I am having trouble finding any info on how to do that in practice, especially in our specific setup. Management of all these servers seems like a potential nightmare. It feels like using Docker could solve most of our headaches, but I'm really curious to know what people did before containers.</p>&#xA;&#xA;<p>TLDR: Have lots of flask servers that are making up our microservice architecture. Have no idea how to manage that.</p>&#xA;"
49026008,Can Eureka registry one service like two different services?,2018-02-28 09:25:17,<java><spring><microservices><spring-cloud><netflix-eureka>,1,43,1,0.0,-1,"<p>I have few micro services and I use eureka for service discovery. I want to split one micro service, but I can't do it from code now(create separate jar). I want to registry one service twice in eureka with same address but different service name. Can I do it?</p>&#xA;"
49004413,How to create a microservice that replicates itself as load of data increases?,2018-02-27 08:40:32,<twitter><streaming><microservices>,1,24,2,1.0,-1,"<p>Iam working on a  project of big data, where Iam trying to get tweets from Twitter and analyse these tweets and make predictions out of it.&#xA;I have followed this tutorial : <a href=""http://blog.cloudera.com/blog/2012/10/analyzing-twitter-data-with-hadoop-part-2-gathering-data-with-flume/"" rel=""nofollow noreferrer"">http://blog.cloudera.com/blog/2012/10/analyzing-twitter-data-with-hadoop-part-2-gathering-data-with-flume/</a>&#xA; for getting the tweets. Now Iam planning to build a microservice which can replicate itself as I increase the number of topics on which I want tweets. Now whatever code I have written to gather the tweets with that  I want to make a microservice that can take a keyword and create a instance of that code for that keyword and gather tweets, for each keyword an instance should be created.&#xA;It will also be helpful if you inform me what tools to use for such application.&#xA;Thank you.</p>&#xA;"
41270649,Choosing API Gateway tool to implement SOA/microservices architecture,2016-12-21 19:38:17,<web-services><rest><api><soa><microservices>,2,319,0,0.0,-1,"<p>I am certain I need to use an API Gateway, but I can't understand the main differences between the different tools in my use case scenario.</p>&#xA;&#xA;<p>Currently, I have multiple services (DBs, Mobile App, Web App and some additional systems. Consider there are 15 different services) that communicate with each other through REST APIs. This is difficult to manage and test, so I would like to change the architecture into something more like what Netflix is doing with Zuul.</p>&#xA;&#xA;<p>Ideally, the services don't know about the other services. They send a request to a specific endpoint (the API Gateway). Then, the API Gateway interacts with the necessary services and sends the response back.&#xA;Here is one example in practice: a service sends a request to a custom (endpoint) connector, the request is parsed, broken down into smaller requests that are sent to other services (that own the specific content requested), get the content back in the response, gather all the responses, create a final response with all the content gathered, send the response back to the first service that sent a request.</p>&#xA;&#xA;<p>I need high availability, scalibility, fault tolerance, the ability to monitor and test all services in one place, ability to do canary testing, easy to add new services and manage the older services. I value open source software and mature software. Should run off premise.</p>&#xA;&#xA;<p>The best solutions that I believe would solve my problem are: WSO2, Apigee, Zuul and Amazon API Gateway. I don't know which is more appropriate for my use case. I have looked at others, but I haven't found any advantages in features or cost against these 4.</p>&#xA;&#xA;<p>Thank you for your feedback regarding advantages and disadvantages regarding these technologies! Other suggestions are also welcome!</p>&#xA;&#xA;<p>Notes:&#xA;Not all of my services are on AWS, but some are.&#xA;The system needs to handle peaks with tens of thousands of requests per minute that happen regurarly, but never continuasly.</p>&#xA;"
41293238,High Availability Websockets Server,2016-12-22 23:39:48,<.net><websocket><microservices><high-availability>,1,178,0,0.0,-1,"<p>I want to know the best way to set up a WebSockets server in a high availability (.NET Core) microservices infrastructure.</p>&#xA;&#xA;<p>My current plan is to have two instances of my WebSockets server behind a load balancer, with session affinity so that once a connection is open, subsequent messages return to the same instance. Then if an instance fails, the client will reconnect to another instance.</p>&#xA;&#xA;<p>Is this the best way to set it up or is there a better way? My primary concern is high availability, but I also want to be able to scale horizontally.</p>&#xA;&#xA;<p>Also if a message needs to be broadcast to a browser client then should I use some kind of reliable message queue to be sure that all instances of the WebSockets server know about the message, in case they own the connection to that browser client? The alternative I thought of for this is that if the servers are somehow stateless, with the connection information stored somewhere else (Redis cluster?) then I wouldn't need to notify all the instances because none of them would ""own"" the connection to that client? Is that possible?</p>&#xA;&#xA;<p>Thanks for any help :)</p>&#xA;&#xA;<p>Chris</p>&#xA;"
49116339,Run multiple node apps on same server and domain,2018-03-05 17:37:21,<node.js><backend><microservices>,2,338,0,0.0,-1,"<p>I am wanting to split up an application I have into multiple different applications. I want to start with the presentation layer and the logical layer. I want the HTML, CSS and JS all in it's own application but then have the backend code (API) run in it's own application. I don't understand is how to run both on the same server. Currently my overgrown application runs on port 8080 and I use Nginx to do proxy_pass to port 8080 for the <code>/</code> location.</p>&#xA;&#xA;<p>What do I do here? </p>&#xA;"
49036468,Inter-Process communication in a microservices architecture,2018-02-28 18:44:13,<web-services><ipc><microservices>,6,171,0,0.0,-1,"<p>we are moving from monolithic to microservice architecture application, we're still in planning phase and we want to know what is the best practices of building it.</p>&#xA;&#xA;<p>suppose we have two services :</p>&#xA;&#xA;<ol>&#xA;<li><strong>User</strong> </li>&#xA;<li><strong>Device</strong>&#xA;&#xA;<ul>&#xA;<li>getUserDevices(UserId)</li>&#xA;<li>addDevice(DeviceInfo, UserId)</li>&#xA;<li>...</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p><strong>Each user has multiple devices</strong></p>&#xA;&#xA;<p>what is the most common, cleaner and proper way of asking the server to get all user devices ?</p>&#xA;&#xA;<p>1- <strong>{api-url}/User/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>needs another HTTP request to communicate with Device service.</p>&#xA;  &#xA;  <p>for user X, get linked devices from <strong>User</strong> service.</p>&#xA;</blockquote>&#xA;&#xA;<p>// <strong>OR</strong></p>&#xA;&#xA;<p>2- <strong>{api-url}/Device/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>for user X, get linked devices from <strong>Device</strong> service.</p>&#xA;</blockquote>&#xA;"
51953109,Does backend web development mean REST API and MICROSERVICES development,2018-08-21 16:32:21,<rest><microservices><backend>,2,29,0,0.0,-1,<p>Is the <strong>backend</strong> developers' job to create <strong>rest api</strong>s and <strong>microservice</strong>s ?</p>&#xA;&#xA;<p>If not then what else the backend developers do ?</p>&#xA;
36840448,Is it a good idea to write wrapper around elastic search or solr,2016-04-25 12:22:35,<elasticsearch><solr><architecture><soa><microservices>,2,77,0,0.0,-1,"<p>We recently migrated from solr to elastic search.&#xA;So decision was taken to write a wrapper in custom query format, which converts to elastic search queries.In future if we change to another data store we just have to modify this api but not all applications. Is it good decision from architecture point of view.</p>&#xA;"
36026454,SFTP ChannelSftp.put stop it's execution process but successfully being uploaded or copy the source file,2016-03-16 03:49:51,<java><sftp><dropwizard><jsch><microservices>,1,571,5,1.0,-1,"<p>details:</p>&#xA;&#xA;<p>in my API i have struggle on debugging why is that the ChannelSftp.put method hangs up or stop it's execution process but when checking it's output it is successfully being uploaded. </p>&#xA;&#xA;<p>here's my code snippet:</p>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>@Inject&#xA;MyConfiguration conf;&#xA;&#xA;public String copyAndMove( String fileName ){&#xA;    try{&#xA;        MyServer origin = conf.getOriginServer().setFileName( fileName );&#xA;        MyServer destination = conf.getDestinationServer().setFileName( fileName );&#xA;&#xA;        SFTPServer originSftpServer = new SFTPServer( origin ).build();&#xA;        SFTPServer destinationSftpServer = new SFTPServer( destination ).build();&#xA;&#xA;        // originSftpServer.copyTo(destinationSftpServer);&#xA;        originSftpServer.copyTo(originSftpServer);&#xA;&#xA;        return ""Successfully copied file."";&#xA;        }catch( Exception ex ){&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>SFTPServer.class</p>&#xA;&#xA;<pre><code>public class SFTPServer {&#xA;&#xA;    private MyServer server;&#xA;    private static SFTPServer instance;&#xA;&#xA;    private Session session = null;&#xA;    private Channel channel = null;&#xA;    private ChannelSftp channelSftp = null;&#xA;&#xA;    // getters and setters&#xA;&#xA;    public SFTPServer(){}&#xA;&#xA;    public SFTPServer(MyServer server) throws  Exception{&#xA;        if(CommonUtil.isNull( server )){&#xA;            throw new Exception(""MyServer cannot be null!"");&#xA;        }&#xA;&#xA;        this.server = server;&#xA;    }&#xA;&#xA;    public SFTPServer build(){&#xA;        try{&#xA;            this.session = SFTPUtil.constructSession(getServer());&#xA;            this.channel = SFTPUtil.constructChannel(getSession());&#xA;            this.channelSftp = (ChannelSftp) channel;&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;&#xA;    public SFTPServer copyTo( SFTPServer destination ) {&#xA;        InputStream is = null;&#xA;        try{&#xA;            ChannelSftp channel = destination.getChannelSftp();&#xA;            String originSourceFile = String.format(""%s/%s"", getServer().getSourceFilePath(), getServer().getFileName());&#xA;            String destinationProcessedFile = String.format(""%s/%s"", destination.getServer().getProcessedFilePath(), destination.getServer().getFileName());&#xA;&#xA;            is = getChannelSftp().get(originSourceFile);&#xA;            channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }finally{&#xA;            CommonUtil.closeQuitely(is); // close input stream&#xA;            destination.destroy(); // disconnect session, channel, channelSftp&#xA;        }&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is this. it's seems that it cannot proceed until the program done for it's execution. when i debug on it it stop and it's execution for this code: <strong>channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);</strong> but on the sftp server it is successfully being copied from source to destination file path. please help me with this problem because it cannot return the <strong>Successfully copied file.</strong> on the service part. thanx. </p>&#xA;"
39683166,How would I use the M.E.A.N. Stack with a Python script backend where the python script is in a container?,2016-09-25 03:41:57,<python><docker><containers><mean-stack><microservices>,1,384,1,0.0,-1,"<p>So I am in the process of writing a web app with the full M.E.A.N. stack and know how to work with both the front end and the back end.  My only problem is incorporating things outside of M.E.A.N.  As an example, I am going to be running a Python script as the algorithmic back end for the web app (mainly due to necessity of specific libraries) where that Python script will be inside of a docker container.  What would be the most optimal way to connect to and run said Python code through M.E.A.N.?</p>&#xA;"
43057349,Are Windows Services not appropriate as Microservices?,2017-03-27 22:14:08,<windows><service><microservices>,1,360,1,0.0,-1,"<p>Are Windows Services not appropriate as Microservices?&#xA;Hear allot about ASP.Net Web Api Microservices but i need to write a service that listens to a queue, are Windows Services ok for this?</p>&#xA;"
51259786,Sending protobuf java file or JsonFormat string,2018-07-10 07:48:00,<java><protocol-buffers><microservices><proto3>,1,32,0,0.0,-1,"<p>Some background first:&#xA;I have a system in which client hits the API to get some resources.&#xA;The API call a microservice to get the required data. The job of API is to finally send a json string (constructed from data obtained from microservice) to client </p>&#xA;&#xA;<p>The client is a legacy system which expects application/json.However, I want the API and microservice to talk using application-x-protobuf over http.</p>&#xA;&#xA;<p>My question is does it make sense to convert my proto java file to string in the microservice itself and then send it to API ? Or does that defeat the purpose of using proto?</p>&#xA;&#xA;<p>Is it necessary to send a proto java file over the wire, rather than a string converted from proto java file (<code>JsonFormat.printer().print(myprotofile)</code>) for leveraging the speed of protobuf ?</p>&#xA;"
51206924,how many hours each container is started,2018-07-06 09:14:01,<docker><microservices><swarm>,3,52,1,1.0,-1,"<p>how many hours each container is started</p>&#xA;&#xA;<p>Hi, I need know if have any tool or idea for take metrics, I want know how many hours, each container is up .</p>&#xA;&#xA;<p>This is possible actuality?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
51220369,Standards in developing microservices with c#,2018-07-07 05:55:20,<c#><asp.net><.net><microservices>,1,62,2,0.0,-1,"<p>What is a c# microservices? I have found different versions of microservices on the internet.</p>&#xA;&#xA;<ol>&#xA;<li>The first one talked about using microServices4Net, l am currently getting an error about the microsoft.owin assembly:</li>&#xA;</ol>&#xA;&#xA;<p>Could not load file or assembly 'Microsoft.Owin.Hosting, Version=3.0.1.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' or one of its dependencies. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040) </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>The second one talked abt a code that publishes a message.</li>&#xA;</ol>&#xA;&#xA;<p>What is the original way of creating a microservice, l really want to grasp the concept.</p>&#xA;"
51277418,mvn clean install -PbuildDocker don't work,2018-07-11 04:44:46,<java><spring><microservices>,2,64,3,0.0,-1,"<p>It is my error info:</p>&#xA;&#xA;<pre><code>Step 9/10 : EXPOSE ${EXPOSED_PORT}&#xA;â”‚[INFO] ------------------------------------------------------------------------&#xA;â”‚[INFO] Reactor Summary:&#xA;â”‚[INFO]&#xA;â”‚[INFO] spring-petclinic-microservices ..................... SUCCESS [ 0.246 s]&#xA;â”‚[INFO] spring-petclinic-admin-server ...................... FAILURE [ 10.753 s]&#xA;â”‚[INFO] spring-petclinic-monitoring ........................ SKIPPED&#xA;â”‚[INFO] spring-petclinic-customers-service ................. SKIPPED&#xA;â”‚[INFO] spring-petclinic-vets-service ...................... SKIPPED&#xA;â”‚[INFO] spring-petclinic-visits-service .................... SKIPPED&#xA;â”‚[INFO] spring-petclinic-config-server ..................... SKIPPED&#xA;â”‚[INFO] spring-petclinic-discovery-server .................. SKIPPED&#xA;â”‚[INFO] spring-petclinic-api-gateway ....................... SKIPPED&#xA;â”‚[INFO] spring-petclinic-tracing-server .................... SKIPPED&#xA;â”‚[INFO] ------------------------------------------------------------------------&#xA;â”‚[INFO] BUILD FAILURE&#xA;â”‚[INFO] ------------------------------------------------------------------------&#xA;â”‚[INFO] Total time: 11.951 s&#xA;â”‚[INFO] Finished at: 2018-07-11T10:30:27+08:00&#xA;â”‚[INFO] Final Memory: 75M/651M&#xA;â”‚[INFO] ------------------------------------------------------------------------&#xA;â”‚[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;â”‚ng-petclinic-admin-server: Exception caught: EXPOSE requires at least one argument -&gt; [Help 1]&#xA;â”‚[ERROR]&#xA;â”‚[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;â”‚[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;â”‚[ERROR]&#xA;â”‚[ERROR] For more information about the errors and possible solutions, please read the following artic&#xA;â”‚les:&#xA;â”‚[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;â”‚[ERROR]&#xA;â”‚[ERROR] After correcting the problems, you can resume the build with the command&#xA;â”‚[ERROR] mvn -rf :spring-petclinic-admin-server&#xA;</code></pre>&#xA;&#xA;<p>It seems like the expose require an argument. What it should be?</p>&#xA;&#xA;<p>This is the dockerfile.</p>&#xA;&#xA;<p>I have tried to set <code>EXPOSE_PORT</code> to <code>22</code> and <code>8899</code> which doesn't work.&#xA;This error info:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;â”‚ng-petclinic-admin-server: Exception caught: Request error: POST unix://localhost:80/build?buildargs=&#xA;â”‚%7B%22ARTIFACT_NAME%22%3A%22spring-petclinic-admin-server-1.5.9%22%2C%22EXPOSED_PORT%22%3A%229090%22%&#xA;â”‚7D&amp;t=mszarlinski/spring-petclinic-admin-server: 500: HTTP 500 Internal Server Error -&gt; [Help 1]&#xA;â”‚[ERROR]&#xA;</code></pre>&#xA;&#xA;<h2>Thanks!</h2>&#xA;&#xA;<p>This is the plugin apart of pom.xml about admin-server:</p>&#xA;&#xA;<pre><code>&lt;profiles&gt;&#xA;    &lt;profile&gt;&#xA;        &lt;id&gt;buildDocker&lt;/id&gt;&#xA;        &lt;build&gt;&#xA;            &lt;plugins&gt;&#xA;                &lt;plugin&gt;&#xA;                    &lt;groupId&gt;com.spotify&lt;/groupId&gt;&#xA;                    &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;&#xA;                    &lt;version&gt;${docker.plugin.version}&lt;/version&gt;&#xA;                &lt;/plugin&gt;&#xA;            &lt;/plugins&gt;&#xA;        &lt;/build&gt;&#xA;    &lt;/profile&gt;&#xA;&lt;/profiles&gt;&#xA;</code></pre>&#xA;"
36570654,Aggregation of jenkins pipelines,2016-04-12 10:32:09,<jenkins><aggregate><microservices><build-pipeline-plugin>,2,401,0,0.0,-1,<p>The Jenkins pipeline plugin is awesome.&#xA;But is it also possible to aggregate pipelines of (dependent projects) e.g. micro-services?</p>&#xA;
38403001,How to listen two micro services on same port in Node.js,2016-07-15 18:33:54,<node.js><microservices>,1,760,9,1.0,-1,"<p>I am new to micro service. I want to create one application with two micro services. But i don't know how to listen both (or more) micro services on a same port to make it as one application. &#xA;Is there any good tutorial pages available in online ? Please suggest me any blogpost or tutorial pages or help me to create a application with two micro services.</p>&#xA;&#xA;<p>I am trying to create a Bus booking application which has two services, </p>&#xA;&#xA;<ol>&#xA;<li>Bus Service (which gives bus names &amp; availability)</li>&#xA;<li>User Service (which gives &amp; connect user details with bus).</li>&#xA;</ol>&#xA;&#xA;<p>I created two this as two nodejs application. Now i need to know how to combine this two as one application (with microservice).for that i can't listen this to one port.</p>&#xA;"
38855867,How to implement complex microservices?,2016-08-09 16:18:55,<java><amazon-web-services><architecture><microservices>,1,301,0,0.0,-1,"<p>A have some questions about microservices using a complex cenario. For example, checkout.</p>&#xA;&#xA;<p>I need to work with product's details, update inventory, user's details, taxes &#xA;according with user's region, calculate final price and send the product. So i have the following services:</p>&#xA;&#xA;<ul>&#xA;<li>ProductService;</li>&#xA;<li>InventoryService;</li>&#xA;<li>UserService;</li>&#xA;<li>TaxesService;</li>&#xA;<li>ShippingService;</li>&#xA;<li>CheckoutService?</li>&#xA;</ul>&#xA;&#xA;<p>My first question, i need a new service (like CheckoutService) to do all this logic (and calculate final price)?</p>&#xA;&#xA;<p>In case of yes, this new service will control the transaction (like two-phase commit)?</p>&#xA;&#xA;<p>Every service have to be your own database? If my application runs in amazon environment, i need to have one instance of RDS for each service?</p>&#xA;"
46321751,How to set the access control for microservices,2017-09-20 12:11:05,<javascript><rest><microservices><loopbackjs><tyk>,1,31,0,0.0,-1,"<p>I use Loopback Framework to create several services and I use an api gateway (tyk) to manage them.</p>&#xA;&#xA;<p>Unfortunately I do not see how to set the access control for each of them.</p>&#xA;&#xA;<p>I do not want a user to access data that does not belong to him.</p>&#xA;&#xA;<p>Many thanks,</p>&#xA;"
46334096,What is the best practice to implement an api status endpoint?,2017-09-21 01:42:17,<microservices>,1,83,0,0.0,-1,"<p>Let's say I have 100 APIs and each api talks to 6 databases. I'm thinking of two approaches to build status endpoints. Consumers are not required to access all 100 apis to perform their business needs, they can access 1 or 2 apis as they need.</p>&#xA;&#xA;<p>1) Each api will have its own /status endpoint and that end point will check the connectivity to the all 6 databases that it uses and if one fails it will return unhealthy otherwise healthy. In this case api consumers access only the status endpoint that they consume. In this case who ever consume a particular api will access its /status end point to check the health status.</p>&#xA;&#xA;<p>2) In this case, the consumers access only 1 endpoint which contains the statuses of all 100 apis based on if any of the 6 databases are down and the api it self is down, so if the api is up and the database is down the status is unhealthy for that particular api and if the database is up and api is up the api is up and healthy, consumer can either get individual status or status of all api's if required from this single endpoint. Each api will have its own internal /status endpoint and it will return healthy irrespective of the status of the 6 databases that it relies on. And I will add 6 different status endpoints for all 6 databases and it will check the connectivity and return healthy if connects otherwise unhealthy.</p>&#xA;&#xA;<p>What would be the best approach out of these two?</p>&#xA;&#xA;<p>I would really appreciate all of your inputs.</p>&#xA;"
46390552,which is the best API gateway for micro services using spring?,2017-09-24 13:27:44,<spring-boot><microservices>,1,1655,0,0.0,-1,"<p>I am trying to build a simple application with microservices architecture.&#xA;Below are the details about 3 microservices I have created.</p>&#xA;&#xA;<pre><code>1] Customer.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8081&#xA;2] vendor.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8082&#xA;3] product.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8083&#xA;</code></pre>&#xA;&#xA;<p>All the 3 micros runs on an embeded tomcat server.&#xA;Now I want to create a common gateway for all these micros [API gateway].&#xA;which help me to route my request based on the request I get for example:-&#xA;for example if I get a request of <a href=""http://hostname:port_of_gateway/customer"" rel=""nofollow noreferrer"">http://hostname:port_of_gateway/customer</a>.&#xA;on reading this I need to route the request tom my customer micro and fetch its response and send it back to client.&#xA;Which of the spring tool I can use to achieve this?</p>&#xA;"
46377039,Understanding Docker and micro-services,2017-09-23 07:11:42,<asp.net><docker><microservices>,1,27,2,0.0,-1,"<p>All, Forgive me I just an newbie for <code>Docker</code> and <code>Micro-services</code>. I am going to to get into the world of <code>Micro-services</code> and <code>Docker</code>. But currently I have no idea of how to get started with them. I have the experience of <code>Asp.net</code>. I heard of <code>Asp.net core</code>can work in the <code>Linux</code>.&#xA;I want to know what is the <code>Docker</code>. how does it work. how <code>Docker</code> help to build <code>Micro-services</code>. Is it <code>Docker</code> is the only way to host <code>Micro-services</code>? Thanks.</p>&#xA;"
46364880,RestAPI versioning through headers,2017-09-22 12:30:33,<java><spring-boot><microservices>,2,43,2,0.0,-1,"<p>I'm trying to implement backward compatibility of API versioning . I'm searching end to end flow of API versioning through headers, could some one please give any sample link/project of this kinda implementation.</p>&#xA;"
46321680,How correctly make project structure in IntelliJ IDEA for Spring Boot microservices?,2017-09-20 12:08:32,<java><spring-boot><intellij-idea><microservices>,1,662,2,0.0,-1,<p>I used to work with Monolithic architecture and I don't have experience with Microservices. I need to create project with some modules (microservices).</p>&#xA;&#xA;<ol>&#xA;<li>auth </li>&#xA;<li>messages</li>&#xA;</ol>&#xA;&#xA;<p>I use IntelliJ IDEA for my project.</p>&#xA;&#xA;<p>Can you explain me what is the best practice for microservices project structure in this IDE?</p>&#xA;&#xA;<p>Should I use Maven or it is better to add IntelliJ IDEA project modules?</p>&#xA;
44521929,How to setup Amazon Lambda with micro services in Node.js,2017-06-13 12:44:32,<aws-lambda><microservices>,1,64,0,0.0,-1,"<p>I am looking forward to work in a Amazon Lambda with Node.js&#xA;They call it server less, So is it a better way to host our code then traditional hosting servers ?</p>&#xA;&#xA;<p>I am open for the suggestions, thanks in advance!!</p>&#xA;"
51734002,Keycloak spring boot microservices,2018-08-07 19:21:17,<spring-boot><microservices><keycloak>,1,46,2,0.0,-1,"<p>i have a few java micro services deployed on open shift . all of them are protected by a api-gateway application which uses keycloak for authentication &amp; Authorization. &#xA;Down stream services need to log which user perform certain actions. </p>&#xA;&#xA;<p>in my api-gateway application properties i have already set zuul.sensitiveHeaders to empty </p>&#xA;&#xA;<p>zuul.sensitiveHeaders: </p>&#xA;&#xA;<p>i can see bearer token in the downstream applications . &#xA;but how do i get the principal/user from token as downstream applications don't have keycloak dependency in gradle. ( if i add the dependency , i need to reconfigure realm and other properties ) .. is this the right way to do ?</p>&#xA;&#xA;<p>i also tried adding a filter in api-gateway to separately set the user_name in header</p>&#xA;&#xA;<p>@Override&#xA;    public void doFilter(&#xA;            ServletRequest request,&#xA;            ServletResponse response,&#xA;            FilterChain chain) throws IOException, ServletException {</p>&#xA;&#xA;<pre><code>    HttpServletRequest req = (HttpServletRequest) request;&#xA;&#xA;    HttpServletResponse res = (HttpServletResponse) response;&#xA;&#xA;    System.out.println("" Filter doFilter ""+req.getUserPrincipal());&#xA;    if(req.getUserPrincipal() != null ){&#xA;        res.setHeader(""MYUSER"",req.getUserPrincipal()==null?""NULL"":req.getUserPrincipal().getName());&#xA;    }&#xA;&#xA;&#xA;&#xA;&#xA;    chain.doFilter(request, response);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But when i try to get the header in downstream microservices is null. </p>&#xA;"
42105805,Microservices Communication Design,2017-02-08 06:03:09,<python><api><microservices>,2,629,0,0.0,-1,<p>I would like to know how to create a communication for each services. I am using API Gateway for the outside of the system to communicate with the services within. Is it necessary for a service to call another service through API Gateway or just directly into the service itself ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;
42816444,Microservice Architecture Monitoring,2017-03-15 17:13:21,<architecture><monitoring><microservices>,2,248,0,0.0,-1,"<p>My company is in the process of migrating from a monolithic approach to a microservices architecture.  I am wondering what tools are available to manage start up, shutdown, load balancing,  and overall health monitoring.  </p>&#xA;&#xA;<p>The solution has to be windows based, but have the option to run in a linux environment as well.</p>&#xA;&#xA;<p>At this time deploying locally is fine, we are not considering cloud at this time.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
51012725,How to merge two spring boot micro-services response in wrapper class,2018-06-24 18:18:22,<java><spring><spring-boot><microservices><spring-webflux>,1,149,0,0.0,-1,"<p>I new to Spring boot microservices and exploring webflux framework. I'm trying to merge response from two microservices to one wrapper class to have the response in proper JSON. Below is the scenario in detail.</p>&#xA;&#xA;<p>Micro-Service 1 : <a href=""http://localhost:8080/products"" rel=""nofollow noreferrer"">http://localhost:8080/products</a>&#xA;in controller of this micro-service its returning Flux and I'm get</p>&#xA;&#xA;<pre><code>[&#xA;    {&#xA;        ""id"": ""5b2fd1e5f57d731904c54ad7"",&#xA;        ""name"": ""Product3"",&#xA;        ""price"": ""30""&#xA;    },&#xA;    {&#xA;        ""id"": ""5b2fd1e4j9fdj3kds9djkj43"",&#xA;        ""name"": ""Product2"",&#xA;        ""price"": ""20""&#xA;    }&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Micro-Service 2 : <a href=""http://localhost:8181/person"" rel=""nofollow noreferrer"">http://localhost:8181/person</a>&#xA;In controller of second service its returning Mono and for this also I'm getting correct response as below,</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"": ehj8u3jmodmdj,&#xA;    ""name"": ""PersonXXX"",&#xA;    ""email"": ""PersonXXX@somecorp.com""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I want to create another microservice <a href=""http://localhost:8282/personproduct"" rel=""nofollow noreferrer"">http://localhost:8282/personproduct</a> which should combine the result of above two microservices in a wrapper class as below,</p>&#xA;&#xA;<pre><code>{&#xA;    {&#xA;        ""id"": ehj8u3jmodmdj,&#xA;        ""name"": ""PersonXXX"",&#xA;        ""email"": ""PersonXXX@somecorp.com""&#xA;    },&#xA;&#xA;    [&#xA;        {&#xA;            ""id"": ""5b2fd1e5f57d731904c54ad7"",&#xA;            ""name"": ""Product3"",&#xA;            ""price"": ""30""&#xA;        },&#xA;        {&#xA;            ""id"": ""5b2fd1e4j9fdj3kds9djkj43"",&#xA;            ""name"": ""Product2"",&#xA;            ""price"": ""20""&#xA;        }&#xA;    ]&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Right now I have a Parent class Entity for both Product and Person classes and I'm calling both above mentioned micro-services via WebClient and concatinating the response using Flux.concat(personResp, productResp); where personResp is of type Mono and productResp is of type Flux but I'm getting response of this (3rd) microservice only in Text and not in JSON as below,</p>&#xA;&#xA;<pre><code>data:{""id"":ehj8u3jmodmdj,""name"":""PersonXXX"",""email"":""PersonXXX@somecorp.com""}&#xA;data:{""id"":""5b2fd1e5f57d731904c54ad7"",""name"":""Product3"",""price"":""30""}&#xA;data:{""id"":""5b2fd1e4j9fdj3kds9djkj43"",""name"":""Product2"",""price"":""20""}&#xA;</code></pre>&#xA;&#xA;<p>This might be due to each element is sent as a different stream.</p>&#xA;&#xA;<p>So just want to know if is there any way to combine two responses in one wrapper class without using block() method on any of the calls done to these two services. </p>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>Currently Im calling product microservice as,</p>&#xA;&#xA;<pre><code>clientProd.get().uri(productUrl)&#xA;                .header(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE)&#xA;                .retrieve().bodyToFlux(Product.class).onErrorReturn(new Product());&#xA;</code></pre>&#xA;&#xA;<p>And similarly Person service as,</p>&#xA;&#xA;<pre><code>clientPerson.get().uri(personUri)&#xA;                .header(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE)&#xA;                .retrieve().bodyToMono(Person.class).onErrorReturn(new Person());&#xA;</code></pre>&#xA;&#xA;<p>And concatenating is using Flux.concat(),</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
51090375,Spring boot 2 with OAUTH 2.0 implementation in own authorization server,2018-06-28 19:54:25,<spring><spring-boot><spring-security><microservices><spring-security-oauth2>,1,260,2,0.0,-1,"<p>I created a new spring boot 2 project in a view to create microservices with eureka server, api gateway using zuul proxy and tried inter communication between microservices.</p>&#xA;&#xA;<p>But, coming to security, tried to implement oauth for the api gateway. But now the <strong>'oauth/token'</strong> endpoint which i used in spring 1.x versions to get the access token is not working in spring boot 2. </p>&#xA;&#xA;<p>As i googled, <strong>spring boot 2</strong> undergone some changes with <strong>spring security 5</strong> to default encryption and decryption for</p>&#xA;&#xA;<ul>&#xA;<li>client-id</li>&#xA;<li>client-secret</li>&#xA;<li>user password </li>&#xA;</ul>&#xA;&#xA;<p>as well and changed that too in mysql database with bcrypted data with prefiexed as <strong>{encryption type}</strong> used Bcrypt with also works with matching the user entered credentials.</p>&#xA;&#xA;<p>But, the request:&#xA;<a href=""http://localhost:8030/oauth/token?grant_type=password&amp;username=XXXX@sdf.com&amp;password=yyyyy"" rel=""nofollow noreferrer"">http://localhost:8030/oauth/token?grant_type=password&amp;username=XXXX@sdf.com&amp;password=yyyyy</a></p>&#xA;&#xA;<p>returns me the 401 unauthorized as response</p>&#xA;&#xA;<blockquote>&#xA;  <p>{&#xA;      ""timestamp"": ""2018-06-28T17:31:07.181+0000"",&#xA;      ""status"": 401,&#xA;      ""error"": ""Unauthorized"",&#xA;      ""message"": ""Unauthorized"",&#xA;      ""path"": ""/oauth/token""&#xA;  }</p>&#xA;</blockquote>&#xA;&#xA;<p>Which works smoothly in spring boot 1.x version but not in spring boot 2.0. I have not clue what i'm doing wrong. Please throw some lights as i stuck with this.</p>&#xA;&#xA;<p>Kindly correct me if i'm wrong or comment below if the question needs to be more clear. so that i update the question with some worked code snippets. Please suggest some demo or any source to understand. Any small help will be appreciated.</p>&#xA;&#xA;<p><strong>Edited with - Log details:</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>:: Spring Boot ::        (v2.0.3.RELEASE)&#xA;  2018-06-30 00:26:01.086  INFO 1396 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.2.17.Final}&#xA;  2018-06-30 00:26:01.088  INFO 1396 --- [           main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found&#xA;  2018-06-30 00:26:01.138  INFO 1396 --- [           main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.1.Final}&#xA;  2018-06-30 00:26:01.388  INFO 1396 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect&#xA;  2018-06-30 00:26:02.115  INFO 1396 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'&#xA;  2018-06-30 00:26:02.359 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Looking for request mappings in application context: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@515aebb0: startup date [Sat Jun 30 00:25:55 IST 2018]; root of context hierarchy&#xA;  2018-06-30 00:26:02.373 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : 2 request handler methods found on class org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint: {public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint.authorize(java.util.Map,java.util.Map,org.springframework.web.bind.support.SessionStatus,java.security.Principal)={[/oauth/authorize]}, public org.springframework.web.servlet.View org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint.approveOrDeny(java.util.Map,java.util.Map,org.springframework.web.bind.support.SessionStatus,java.security.Principal)={[/oauth/authorize],methods=[POST],params=[user_oauth_approval]}}&#xA;  2018-06-30 00:26:02.377  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/authorize]}"" onto public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint.authorize(java.util.Map,java.util.Map,org.springframework.web.bind.support.SessionStatus,java.security.Principal)&#xA;  2018-06-30 00:26:02.381  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/authorize],methods=[POST],params=[user_oauth_approval]}"" onto public org.springframework.web.servlet.View org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint.approveOrDeny(java.util.Map,java.util.Map,org.springframework.web.bind.support.SessionStatus,java.security.Principal)&#xA;  2018-06-30 00:26:02.384 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : 2 request handler methods found on class org.springframework.security.oauth2.provider.endpoint.TokenEndpoint: {public org.springframework.http.ResponseEntity org.springframework.security.oauth2.provider.endpoint.TokenEndpoint.getAccessToken(java.security.Principal,java.util.Map) throws org.springframework.web.HttpRequestMethodNotSupportedException={[/oauth/token],methods=[GET]}, public org.springframework.http.ResponseEntity org.springframework.security.oauth2.provider.endpoint.TokenEndpoint.postAccessToken(java.security.Principal,java.util.Map) throws org.springframework.web.HttpRequestMethodNotSupportedException={[/oauth/token],methods=[POST]}}&#xA;  2018-06-30 00:26:02.386  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/token],methods=[GET]}"" onto public org.springframework.http.ResponseEntity org.springframework.security.oauth2.provider.endpoint.TokenEndpoint.getAccessToken(java.security.Principal,java.util.Map) throws org.springframework.web.HttpRequestMethodNotSupportedException&#xA;  2018-06-30 00:26:02.387  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/token],methods=[POST]}"" onto public org.springframework.http.ResponseEntity org.springframework.security.oauth2.provider.endpoint.TokenEndpoint.postAccessToken(java.security.Principal,java.util.Map) throws org.springframework.web.HttpRequestMethodNotSupportedException&#xA;  2018-06-30 00:26:02.390 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : 1 request handler methods found on class org.springframework.security.oauth2.provider.endpoint.CheckTokenEndpoint: {public java.util.Map org.springframework.security.oauth2.provider.endpoint.CheckTokenEndpoint.checkToken(java.lang.String)={[/oauth/check_token]}}&#xA;  2018-06-30 00:26:02.392  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/check_token]}"" onto public java.util.Map org.springframework.security.oauth2.provider.endpoint.CheckTokenEndpoint.checkToken(java.lang.String)&#xA;  2018-06-30 00:26:02.394 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : 1 request handler methods found on class org.springframework.security.oauth2.provider.endpoint.WhitelabelApprovalEndpoint: {public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.WhitelabelApprovalEndpoint.getAccessConfirmation(java.util.Map,javax.servlet.http.HttpServletRequest) throws java.lang.Exception={[/oauth/confirm_access]}}&#xA;  2018-06-30 00:26:02.397  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/confirm_access]}"" onto public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.WhitelabelApprovalEndpoint.getAccessConfirmation(java.util.Map,javax.servlet.http.HttpServletRequest) throws java.lang.Exception&#xA;  2018-06-30 00:26:02.399 DEBUG 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : 1 request handler methods found on class org.springframework.security.oauth2.provider.endpoint.WhitelabelErrorEndpoint: {public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.WhitelabelErrorEndpoint.handleError(javax.servlet.http.HttpServletRequest)={[/oauth/error]}}&#xA;  2018-06-30 00:26:02.401  INFO 1396 --- [           main] .s.o.p.e.FrameworkEndpointHandlerMapping : Mapped ""{[/oauth/error]}"" onto public org.springframework.web.servlet.ModelAndView org.springframework.security.oauth2.provider.endpoint.WhitelabelErrorEndpoint.handleError(javax.servlet.http.HttpServletRequest)&#xA;  2018-06-30 00:26:02.625  INFO 1396 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/<strong>/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;  2018-06-30 00:26:03.361  INFO 1396 --- [           main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory&#xA;  2018-06-30 00:26:03.591  INFO 1396 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@515aebb0: startup date [Sat Jun 30 00:25:55 IST 2018]; root of context hierarchy&#xA;  2018-06-30 00:26:03.651  WARN 1396 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning&#xA;  2018-06-30 00:26:03.688  INFO 1396 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped ""{[/check/data]}"" onto public java.lang.String com.cheers.authserver.auth.DataCheck.data()&#xA;  2018-06-30 00:26:03.690  INFO 1396 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped ""{[/api/open]}"" onto public java.lang.String com.cheers.authserver.auth.DataCheck.testing()&#xA;  2018-06-30 00:26:03.703  INFO 1396 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped ""{[/error]}"" onto public org.springframework.http.ResponseEntity> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)&#xA;  2018-06-30 00:26:03.705  INFO 1396 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped ""{[/error],produces=[text/html]}"" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)&#xA;  2018-06-30 00:26:03.769  INFO 1396 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/</strong>] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;  2018-06-30 00:26:03.770  INFO 1396 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/<strong>] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]&#xA;  2018-06-30 00:26:04.148 DEBUG 1396 --- [           main] s.c.a.w.c.WebSecurityConfigurerAdapter$3 : No authenticationProviders and no parentAuthenticationManager defined. Returning null.&#xA;  2018-06-30 00:26:04.289 DEBUG 1396 --- [           main] eGlobalAuthenticationAutowiredConfigurer : Eagerly initializing {org.springframework.boot.autoconfigure.security.servlet.WebSecurityEnablerConfiguration=org.springframework.boot.autoconfigure.security.servlet.WebSecurityEnablerConfiguration$$EnhancerBySpringCGLIB$$c3e8db27@77aea}&#xA;  2018-06-30 00:26:04.316  INFO 1396 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: Ant [pattern='/api/</strong>'], []&#xA;  2018-06-30 00:26:04.425 DEBUG 1396 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression 'fullyAuthenticated', for Ant [pattern='/oauth/token']&#xA;  2018-06-30 00:26:04.428 DEBUG 1396 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression 'permitAll()', for Ant [pattern='/oauth/token_key']&#xA;  2018-06-30 00:26:04.428 DEBUG 1396 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression 'isAuthenticated()', for Ant [pattern='/oauth/check_token']&#xA;  2018-06-30 00:26:04.439 DEBUG 1396 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes&#xA;  2018-06-30 00:26:04.459 DEBUG 1396 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes&#xA;  2018-06-30 00:26:04.477  INFO 1396 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: OrRequestMatcher [requestMatchers=[Ant [pattern='/oauth/token'], Ant [pattern='/oauth/token_key'], Ant [pattern='/oauth/check_token']]], [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@11826398, org.springframework.security.web.context.SecurityContextPersistenceFilter@76ac68b0, org.springframework.security.web.header.HeaderWriterFilter@5e2a6991, org.springframework.security.web.authentication.logout.LogoutFilter@7a358613, org.springframework.security.web.authentication.www.BasicAuthenticationFilter@59b492ec, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@63917fe1, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@2b7facc7, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@6c5ca0b6, org.springframework.security.web.session.SessionManagementFilter@409732fb, org.springframework.security.web.access.ExceptionTranslationFilter@5aea8994, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@2e4eda17]&#xA;  2018-06-30 00:26:04.503 DEBUG 1396 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression 'permitAll', for Ant [pattern='/']&#xA;  2018-06-30 00:26:04.504 DEBUG 1396 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression 'authenticated', for org.springframework.security.web.util.matcher.AnyRequestMatcher@1&#xA;  2018-06-30 00:26:04.506 DEBUG 1396 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes&#xA;  2018-06-30 00:26:04.507 DEBUG 1396 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes&#xA;  2018-06-30 00:26:04.509  INFO 1396 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: Ant [pattern='/api/<strong>'], [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@15a8cebd, org.springframework.security.web.context.SecurityContextPersistenceFilter@410fc508, org.springframework.security.web.header.HeaderWriterFilter@a316f6b, org.springframework.security.web.authentication.logout.LogoutFilter@62e73ab6, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@5ebbde60, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@4e17442f, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4f5c30b1, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3f6c2763, org.springframework.security.web.session.SessionManagementFilter@63f9ddf9, org.springframework.security.web.access.ExceptionTranslationFilter@35e74e08, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@7bf018dd]&#xA;  2018-06-30 00:26:04.532  INFO 1396 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@76a6f045, org.springframework.security.web.context.SecurityContextPersistenceFilter@59e7564b, org.springframework.security.web.header.HeaderWriterFilter@6793f752, org.springframework.security.web.csrf.CsrfFilter@2ad7bd26, org.springframework.security.web.authentication.logout.LogoutFilter@1510b9a2, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@482ba4b1, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@307af381, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@633ddc0c, org.springframework.security.web.session.SessionManagementFilter@1216eb3f, org.springframework.security.web.access.ExceptionTranslationFilter@44faa4f2]&#xA;  2018-06-30 00:26:04.684  INFO 1396 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup&#xA;  2018-06-30 00:26:04.759  INFO 1396 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8030 (http) with context path ''&#xA;  2018-06-30 00:26:04.768  INFO 1396 --- [           main] c.c.authserver.AuthServerApplication     : Started AuthServerApplication in 9.893 seconds (JVM running for 10.573)&#xA;  2018-06-30 00:27:40.919  INFO 1396 --- [nio-8030-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'&#xA;  2018-06-30 00:27:40.919  INFO 1396 --- [nio-8030-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started&#xA;  2018-06-30 00:27:41.004  INFO 1396 --- [nio-8030-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 85 ms&#xA;  2018-06-30 00:27:41.026 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/oauth/token'; against '/api/</strong>'&#xA;  2018-06-30 00:27:41.026 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/oauth/token']&#xA;  2018-06-30 00:27:41.026 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/oauth/token'; against '/oauth/token'&#xA;  2018-06-30 00:27:41.026 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : matched&#xA;  2018-06-30 00:27:41.027 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /oauth/token?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 1 of 11 in additional filter chain; firing Filter: 'WebAsyncManagerIntegrationFilter'&#xA;  2018-06-30 00:27:41.029 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /oauth/token?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 2 of 11 in additional filter chain; firing Filter: 'SecurityContextPersistenceFilter'&#xA;  2018-06-30 00:27:41.030 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /oauth/token?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 3 of 11 in additional filter chain; firing Filter: 'HeaderWriterFilter'&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /oauth/token?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 4 of 11 in additional filter chain; firing Filter: 'LogoutFilter'&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/logout', GET]&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/oauth/token'; against '/logout'&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/logout', POST]&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request 'GET /oauth/token' doesn't match 'POST /logout&#xA;  2018-06-30 00:27:41.032 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/logout', PUT]&#xA;  2018-06-30 00:27:41.033 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request 'GET /oauth/token' doesn't match 'PUT /logout&#xA;  2018-06-30 00:27:41.033 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/logout', DELETE]&#xA;  2018-06-30 00:27:41.033 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request 'GET /oauth/token' doesn't match 'DELETE /logout&#xA;  2018-06-30 00:27:41.033 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : No matches found&#xA;  2018-06-30 00:27:41.033 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /oauth/token?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 5 of 11 in additional filter chain; firing Filter: 'BasicAuthenticationFilter'&#xA;  2018-06-30 00:27:41.034 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.a.www.BasicAuthenticationFilter  : Basic Authentication Authorization header found for user 'fooClientIdPassword'&#xA;  2018-06-30 00:27:41.038 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.authentication.ProviderManager     : Authentication attempt using org.springframework.security.authentication.dao.DaoAuthenticationProvider&#xA;  2018-06-30 00:27:41.844 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.a.dao.DaoAuthenticationProvider    : User 'fooClientIdPassword' not found&#xA;  2018-06-30 00:27:41.845 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.a.www.BasicAuthenticationFilter  : Authentication request for failed: org.springframework.security.authentication.BadCredentialsException: Bad credentials&#xA;  2018-06-30 00:27:41.845 DEBUG 1396 --- [nio-8030-exec-2] s.w.a.DelegatingAuthenticationEntryPoint : Trying to match using RequestHeaderRequestMatcher [expectedHeaderName=X-Requested-With, expectedHeaderValue=XMLHttpRequest]&#xA;  2018-06-30 00:27:41.845 DEBUG 1396 --- [nio-8030-exec-2] s.w.a.DelegatingAuthenticationEntryPoint : No match found. Using default entry point org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint@6dad2eff&#xA;  2018-06-30 00:27:41.846 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.header.writers.HstsHeaderWriter  : Not injecting HSTS header since it did not match the requestMatcher org.springframework.security.web.header.writers.HstsHeaderWriter$SecureRequestMatcher@547de45b&#xA;  2018-06-30 00:27:41.848 DEBUG 1396 --- [nio-8030-exec-2] s.s.w.c.SecurityContextPersistenceFilter : SecurityContextHolder now cleared, as request processing completed&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/error'; against '/api/<strong>'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/oauth/token']&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/error'; against '/oauth/token'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/oauth/token_key']&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/error'; against '/oauth/token_key'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern='/oauth/check_token']&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/error'; against '/oauth/check_token'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : No matches found&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : '/error'; against '/api/</strong>'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 1 of 10 in additional filter chain; firing Filter: 'WebAsyncManagerIntegrationFilter'&#xA;  2018-06-30 00:27:41.854 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 2 of 10 in additional filter chain; firing Filter: 'SecurityContextPersistenceFilter'&#xA;  2018-06-30 00:27:41.855 DEBUG 1396 --- [nio-8030-exec-2] w.c.HttpSessionSecurityContextRepository : No HttpSession currently exists&#xA;  2018-06-30 00:27:41.856 DEBUG 1396 --- [nio-8030-exec-2] w.c.HttpSessionSecurityContextRepository : No SecurityContext was available from the HttpSession: null. A new one will be created.&#xA;  2018-06-30 00:27:41.857 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 3 of 10 in additional filter chain; firing Filter: 'HeaderWriterFilter'&#xA;  2018-06-30 00:27:41.857 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 4 of 10 in additional filter chain; firing Filter: 'CsrfFilter'&#xA;  2018-06-30 00:27:41.857 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 5 of 10 in additional filter chain; firing Filter: 'LogoutFilter'&#xA;  2018-06-30 00:27:41.859 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request 'GET /error' doesn't match 'POST /logout&#xA;  2018-06-30 00:27:41.860 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 6 of 10 in additional filter chain; firing Filter: 'RequestCacheAwareFilter'&#xA;  2018-06-30 00:27:41.860 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 7 of 10 in additional filter chain; firing Filter: 'SecurityContextHolderAwareRequestFilter'&#xA;  2018-06-30 00:27:41.863 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 8 of 10 in additional filter chain; firing Filter: 'AnonymousAuthenticationFilter'&#xA;  2018-06-30 00:27:41.863 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.a.AnonymousAuthenticationFilter  : Populated SecurityContextHolder with anonymous token: 'org.springframework.security.authentication.AnonymousAuthenticationToken@784958e0: Principal: anonymousUser; Credentials: [PROTECTED]; Authenticated: true; Details: org.springframework.security.web.authentication.WebAuthenticationDetails@b364: RemoteIpAddress: 0:0:0:0:0:0:0:1; SessionId: null; Granted Authorities: ROLE_ANONYMOUS'&#xA;  2018-06-30 00:27:41.864 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 9 of 10 in additional filter chain; firing Filter: 'SessionManagementFilter'&#xA;  2018-06-30 00:27:41.865 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.session.SessionManagementFilter  : Requested session ID E5A0A21A0F7DF095CB629DA455BDEEA0 is invalid.&#xA;  2018-06-30 00:27:41.865 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password at position 10 of 10 in additional filter chain; firing Filter: 'ExceptionTranslationFilter'&#xA;  2018-06-30 00:27:41.865 DEBUG 1396 --- [nio-8030-exec-2] o.s.security.web.FilterChainProxy        : /error?grant_type=password&amp;username=raja@gmail.com&amp;password=password reached end of additional filter chain; proceeding with original chain&#xA;  2018-06-30 00:27:42.018 DEBUG 1396 --- [nio-8030-exec-2] w.c.HttpSessionSecurityContextRepository : SecurityContext is empty or contents are anonymous - context will not be stored in HttpSession.&#xA;  2018-06-30 00:27:42.036 DEBUG 1396 --- [nio-8030-exec-2] o.s.s.w.a.ExceptionTranslationFilter     : Chain processed normally&#xA;  2018-06-30 00:27:42.037 DEBUG 1396 --- [nio-8030-exec-2] s.s.w.c.SecurityContextPersistenceFilter : SecurityContextHolder now cleared, as request processing completed</p>&#xA;</blockquote>&#xA;"
39364901,Micro services for graphql,2016-09-07 08:29:59,<ajax><microservices><graphql>,1,176,0,0.0,-1,<p>I have created a graphql server that send data to client and show results to react component using relay. If i want't to get data from different sources( different server or different DB) I have to change my resolve function and put there the code that get data with ajax for example?</p>&#xA;
39056199,What considerations besides development time must I make in choosing server languages?,2016-08-20 16:08:47,<performance><service><microservices>,1,37,1,0.0,-1,"<p>I'm trying to get a better understanding of server languages / frameworks and their potential advantages and disadvantages as used in a microservice environment. Development time is not important to me since this is for my own personal project and learning to use the right tool for the problem is more important to me than the development time required to build the service.</p>&#xA;&#xA;<p>The more I think about it, the more I think that Elixir should be used 90% of the time. The reason is twofold: </p>&#xA;&#xA;<p>1) concurrency implies many users can hit the service without fail</p>&#xA;&#xA;<p>2) most microservices have 0 processing overhead, they hit a database and return a json. I.e. the gains from hitting a database with a faster language are not differentiable from using a slower language. The database in question will determine the speed at which data is returned, not the server language since the database implementation will itself be written in lower language like C++. (Is this true? Will Elixir + Postgresql be noticably slower than Go + Postgresql? Or even Ruby + Postgresql? Is the bottleneck Postgresql or the language making the request?)</p>&#xA;&#xA;<p>Assuming the above 2 are true, then it stands to reason to me that I would use Elixir 90% of the time because I would get a service that is future-proofed to traffic spikes and since it will generally have the same speed of execution as any other database retrieval Rest APIs. </p>&#xA;&#xA;<p>The other 10% of the time where a service requires processor speed like  an Image Recognition service I would then implement in C++ or in Python because it has libraries already implemented in C++ for Image Recognition (ie Tensor Flow).</p>&#xA;&#xA;<p>Is this a correct way of thinking about when to use specific languages for a microservice? If not, besides Development Time what else should I consider? </p>&#xA;"
44161386,"In microservice, how do you make sure that all services get updated when more than one micro service is affected?",2017-05-24 14:29:45,<c#><docker><architecture><microservices><software-design>,1,85,0,0.0,-1,"<p>Example</p>&#xA;&#xA;<p>Online checkout:</p>&#xA;&#xA;<p>User adds item to shopping cart, clicks checkout and pays for order via credit card.</p>&#xA;&#xA;<ol>&#xA;<li>Order is created via OrderMicroservice</li>&#xA;<li><p>a) Order is updated with â€œCompleteâ€ status via OrderMicroservice</p>&#xA;&#xA;<p>b) Payment is processed via credit card and logged via PaymentMicroservice</p>&#xA;&#xA;<p>c) Invoice is created and emailed to user via InvoiceMicroservice</p></li>&#xA;</ol>&#xA;&#xA;<p>For some reason the invoice microservice failed, the database storage is full or email failed to send, OR payment failed but the order has already been marked as â€œcompleteâ€, do we need to roll back the database? or what do we do here to make sure that the entire workflow has been executed correctly?</p>&#xA;"
44000273,Micro service Architecture based on RESTful API's in java,2017-05-16 11:30:28,<java><rest><design-patterns><microservices>,3,152,4,0.0,-1,"<p>Best Architecture for implementing a <strong>WebService</strong> that takes requests from one side, save and enhance that and then call another service with new parameters.&#xA;is there any special <code>Design Pattern</code> for this?</p>&#xA;"
42289439,How to manage continuous delivery with micro services?,2017-02-17 04:32:03,<jenkins><microservices><jenkins-pipeline><continuous-delivery>,1,209,2,0.0,-1,"<p>Right now we are working with Jenkins as our CI and CD, we are also using an Agile methodology (sprint). I was wondering how can I manage the releases of my software.</p>&#xA;&#xA;<p>For example we are developing a shopping site for a business. The development consists of an application which consumes 3 micro services.</p>&#xA;&#xA;<p>Components:&#xA;<br>&#xA;<br>&#xA;Application: Is the user interface&#xA;<br>&#xA;Micro service 1: Sales&#xA;<br>&#xA;Micro service 2: Users&#xA;<br>&#xA;Micro service 3: Products &#xA;<br></p>&#xA;&#xA;<p>Initial state of the shopping site:&#xA;<br></p>&#xA;&#xA;<p>We start developing the shopping site from scratch. As I said before we are working with an Agile Methodology (Sprints).</p>&#xA;&#xA;<p>Sprint 1:&#xA;<br>&#xA;  - Develop products micro service.&#xA;<br>&#xA;  - Develop users micro service.&#xA;<br>&#xA;End of Sprint 1</p>&#xA;&#xA;<p>By this time I can only apply micro service testing, like unit testing, contract testing, etc. Because I don't have the application ready I can't make end to end testing or functional testing based on the entire system, as well I can't deploy to UAT environment (show a beta version to the users) because the user wont be able to do exploratory testing. So for now I need to wait until the application and sales micro service is finished, so I can show the beta version to the user and apply any other type of testing.</p>&#xA;&#xA;<p>Sprint 2:&#xA;<br>&#xA;   - Develop sales micro service.&#xA;<br>&#xA;   - Develop application.&#xA;<br>&#xA;End of Sprint 2</p>&#xA;&#xA;<p>Now that all the components needed are finished to accomplish the user requirements, we can continue with the pipeline. applying  all the testing needed before we show a beta version to the user.</p>&#xA;&#xA;<p>So the million dollar question is, how would you do this scenario with Jenkins and GitLab?</p>&#xA;&#xA;<p>I understand that micro services should be independent to every component in the system, but at the end the entire system depends on each other, for example if I add a new micro service like ""shipping"", this new functionality should be seen in the application interface, so it means that before releasing the new system I have a dependency on ""shipping"" micro service and the application interface, because without both developments I cant fully test the user requirements before deploying to production.</p>&#xA;&#xA;<p>P.S. I'm sorry for any confusion in this post, but I complety new at this topic.</p>&#xA;"
43282528,Data in Event Driven Microservices Architecture,2017-04-07 15:59:34,<architecture><apache-kafka><microservices><datastore><event-sourcing>,2,422,2,0.0,-1,"<p>I'm trying to build an Event Driven Microservices Architecture, as I understand It's recommended to build my services <strong>without</strong> a DB, and instead to use the Event Store technique which is based on Event Driven Microservices Architecture.</p>&#xA;&#xA;<p>My question is, if my services would be small and totally independent from each other, including not have a dedicated DB for each service, should my Event Store act as one single unit \ ""service"" which holds other services events'?</p>&#xA;&#xA;<p>If yes, one of the Event store components is a message bus (like apache Kafka), in order that services could consume and publish events, does it mean that the Event Store domain is virtual? (because whole its components including Kafka doesn't being packaged as a single unit). </p>&#xA;"
46936582,How microservice apps are better than cluster of monolithic apps cluster with load balancing,2017-10-25 15:36:36,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix>,1,65,0,0.0,-1,<p>How micro-service apps are better than cluster of monolithic apps cluster with a load balancer ?</p>&#xA;&#xA;<p>I already know that micro services are :-</p>&#xA;&#xA;<p>1- easy to develop &#xA;2- helps for continuous delivery </p>&#xA;&#xA;<p>in what other ways it's better ?</p>&#xA;
46724191,Do I need a microservice?,2017-10-13 06:59:10,<php><symfony><architecture><acl><microservices>,1,179,0,0.0,-1,"<p>I'm learning the microservices architecture and it's a bit unclear for me when I should wrap a piece of functionality into a microservice and when it's better to keep it in a separate component installing the component in the dependent microservices. </p>&#xA;&#xA;<p>Examples:</p>&#xA;&#xA;<ol>&#xA;<li><p>Symfony Security ACL component (<code>symfony/security-acl</code>). I could wrap it into a microservice which would only add a layer of abstraction in the form of the REST API on the top of the Symfony Security ACL API. Apart from that, I would be going to need a service agent component which gets installed on the dependent microservices and provides access to the ACL microservice. What's the point? Isn't it easier to install <code>symfony/security-acl</code> where it's needed and give it a separate database connection?</p></li>&#xA;<li><p>Payment System. In this case it's more clear that it needs wrapping into a microservice. It contains a huge volume of business logic which is just asking for separation.</p></li>&#xA;</ol>&#xA;&#xA;<p>Basically the questions are:</p>&#xA;&#xA;<ol>&#xA;<li><p>What criterion should I consider when deciding to put a piece of software in a microservice rather than into a module?</p></li>&#xA;<li><p>Is it a good idea to wrap <code>symfony/security-acl</code> into a very thin microservice (isn't it good for a microservice to be thin)? </p></li>&#xA;</ol>&#xA;"
34767582,Why/When Are Microservices Beneficial?,2016-01-13 13:08:53,<ruby-on-rails><sinatra><microservices>,1,44,0,0.0,-1,"<p>I used to build apps to be entirely self-contained, but I've seen more <code>Microservices architecture</code> apps more trending these days.</p>&#xA;&#xA;<p><strong>My questions are these:</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>Why is this more beneficial than building a single app containing all&#xA;of its components? </p></li>&#xA;<li><p>When is it better to use this approach?</p></li>&#xA;<li><p>What types of apps should be developed in this way?</p></li>&#xA;</ul>&#xA;"
48019661,How to avoid Race Condition to update sql record insert/update by microservice containers,2017-12-29 08:26:53,<sql><amazon-web-services><docker><microservices>,1,101,2,0.0,-1,<p>I am working with microservices architecture using &#xA;consul for service discovery and ECS for maintaining docker containers</p>&#xA;&#xA;<p>Now I am Developing a micro service which will read record from AWS SQS and after some validation it will be inserted into SQL. </p>&#xA;&#xA;<p>Problem&#xA;For scalability suppose we launch two containers A and B say and if both A and B tries to update same record on SQL then how can I manage isolation and avoid race condition</p>&#xA;&#xA;<p>One solution not sure I think can be to have some tokens on Elasticache aws service </p>&#xA;&#xA;<p>However would appreciate if somebody can share his proven solution to work on this kind of use cases</p>&#xA;
46240639,Getting Cross-Origin issue while accessing API in Docker container but working fine in local,2017-09-15 13:22:10,<spring-boot><cors><dockerfile><microservices>,1,99,0,0.0,-1,"<p><a href=""https://i.stack.imgur.com/ILavh.png"" rel=""nofollow noreferrer"">enter image description here</a></p>&#xA;&#xA;<p>I'm using Spring boot microservices API + dockerfile &#xA;Kindly Help</p>&#xA;"
46185971,Shared cache between different servers,2017-09-12 22:02:18,<caching><microservices><hazelcast>,1,248,2,0.0,-1,"<p>Am trying to implement a shared cache application, I have 4 different servers which should use that cache, am also concerned with the response time, the response need to be as fast as possible, so my question is, which method should I go with ? </p>&#xA;&#xA;<p>1 - something like Hazelcast or &#xA;2 - implement it as a single application and expose/access it through webservice, something like a microservice application ...</p>&#xA;"
41749456,How to integrate Machine learning into a ruby on rails application,2017-01-19 18:47:59,<python><ruby-on-rails><r><ruby><microservices>,1,1288,0,1.0,-1,"<p>Given Python and R have huge machine learning libraries that make it easy to train a machine learning model, and given rails provides a very fast way of building a web app, is there a 'best practice' for integrating a machine learning model (written in python or R) into a rails application? </p>&#xA;&#xA;<p>If so what tools can we use? What are pros and cons of each?</p>&#xA;"
41746212,How to Refactor Java web project package structure so that conform to microservice?,2017-01-19 15:55:27,<java><maven><microservices>,1,111,1,0.0,-1,"<p>We have such a mess java web project need to be refactor.First, we need to confirm the new package structure or maven project structure.</p>&#xA;&#xA;<p>As the microservice is very hot now, we want to design the  package structure that conform to microservice (which I do not know much).&#xA;So we can take less effort to refactor the project to microservice in the second phase.</p>&#xA;&#xA;<p>Is there such a 'silver bullet'?</p>&#xA;"
35838016,Which microservice library is best or mostly used?,2016-03-07 07:08:50,<microservices>,1,472,3,0.0,-1,<p>I am split my business logic into micro services. Which micro services library is good or mostly used? what about apache karaf? </p>&#xA;
51454764,View injection container for angular,2018-07-21 09:38:02,<angular><dependency-injection><microservices><view-injection><micro-frontend>,1,49,3,1.0,-1,"<p>I'm trying to have an angular module for each backend microservice. So to keep each module independent and clean while they use each other's components when available and a default ""service-is-not-available"" component, when the component is not found in the container.</p>&#xA;&#xA;<p><strong>Example Scenario:</strong> Let's say there are a sales and accounting module.&#xA;The sales module needs a component with selector: 'total-price'.&#xA;Sales module and Accounting module are both used by the main module, but the sales doesn't know about accounting.&#xA;When I call the 'total-price' tag in sales I want the main module to find it in the accounting and display it in the sales.</p>&#xA;&#xA;<p>Here the 'total-price' tag selector works like an abstraction (OO interface) which it's implementation is placed at accounting module, and the main module should have an IOC to search and find the implementation an inject it to the sales, and return a not found view if the view is unavailable (kind of like null object pattern). This may also help with handling authorization and returning a proper view whenever the user is not permitted to see some component.</p>&#xA;&#xA;<p><strong>Code Sample:</strong>&#xA;<a href=""https://stackblitz.com/edit/angular-vxstyk?file=src%2Fapp%2Fsales%2Fsales%2Fsales.component.html"" rel=""nofollow noreferrer"">This</a> is a sample code for the scenario but it doesn't compile, because as my question states I'm looking for a way of orchestrating, and composing the UI and injecting the <code>&lt;total-price&gt;</code> component to sales without referencing the accounting module directly.</p>&#xA;"
45080886,Is it ok to reset database on running programs in acceptance testing?,2017-07-13 12:40:04,<ruby><microservices><acceptance-testing>,1,34,1,0.0,-1,"<p>I have a system of multiple ruby applications. Full stop and start of this system takes about 2 minutes. I decided to make my apps fault-tolerant to DB downs, so when I drop databases and restore them my apps don't fail.</p>&#xA;&#xA;<p>Is it normal? Are there any pitfalls?</p>&#xA;"
45115860,how to use golang microservices?,2017-07-15 07:49:07,<go><microservices>,3,381,1,3.0,-1,"<p>My company use Go to build some HTTP API services. We want these services share one HTTP port. </p>&#xA;&#xA;<p>So the solution right now is we create a project named router, and router import some modules, every request pass through router to their own modules.<br>&#xA;But the question is that if one of these modules process crashed, the router just crash.</p>&#xA;&#xA;<p>Is there any solutions?</p>&#xA;&#xA;<p>Require:</p>&#xA;&#xA;<ol>&#xA;<li>One http port.</li>&#xA;<li>Every service is independent.</li>&#xA;</ol>&#xA;&#xA;<p>I know go-kit and go micro, also I have tried, but still not too understand.</p>&#xA;"
49615519,"What is the best way to communicate between microservices in vertx, by web client or some middleware?",2018-04-02 17:08:45,<java><microservices><vert.x>,1,245,0,0.0,-1,"<p>I have not done much in vert.x microservices, but I ran into the doubt of knowing the best way to communicate with each other miscroservices vert.x, using some middleware or web client, I do not know, or any other way that vert.x allows me.</p>&#xA;"
48208376,Optional MicroServices - Design considerations,2018-01-11 13:35:56,<design><architecture><microservices><netflix-eureka>,1,30,0,0.0,-1,"<p>I am developing an app which is going to have a suite of micro-services(50+ Services). Based on the Geo-location where it is deployed, few of the Services will not activated. For instance, in Europe Cluster only 40 Services would be deployed. </p>&#xA;&#xA;<p>Communication between the Micro-Services are asynchronous and are done using Apache Kafka</p>&#xA;&#xA;<p>Question I have is, when Service-1 wants to propagate an asynchronous event to Service-2 and Service-2 is not deployed in the cluster, which one of the following is a good practice</p>&#xA;&#xA;<p><strong>Option-1:</strong> Lets Service-1 propagate the events, if the Services are not deployed, gracefully exit with a circuit-breaker option . For example: Netflix's Circuit Breaker. But believe, there might be an added complexity if the Service was down for legitimate reasons </p>&#xA;&#xA;<p><strong>Option-2 :</strong> Before Propagating events, check if the Service is Up (for example: Through Netflix's Eureka) and then send the message</p>&#xA;&#xA;<p><strong>Option-3 :</strong> Implement a Centralised event Composite Service which will identify if the respective Service is up and then propagate the message. </p>&#xA;&#xA;<p><strong>Option-4:</strong> Set the retention days appropriately in the Message Queue(Apache Kafka), so that if the Service is not up for a specific set of day(s), then the message would be ignored</p>&#xA;&#xA;<p><strong>Option-5 :</strong> Any other better option!</p>&#xA;"
48269479,Can I somehow use JHipster Microservice application with DB2,2018-01-15 19:27:41,<hibernate><db2><jhipster><microservices>,1,150,0,0.0,-1,"<p>My application would mostly depend on already running stored procedures. I may do hibernate or native jdbc calls to DB2 from microservices. Is there a way to use DB2 database (cause I can not change the database)? </p>&#xA;&#xA;<p>I may also accept generation of the microservices, gateways in jhipster and changing db configuration manually for DB2 as answer or anything similar which allows automatic code generation with jhipster and benefiting from gateway, service registry and load balancing. </p>&#xA;&#xA;<p>May be I can configure a second db for Jhipster configuration? and use DB2 for data only??</p>&#xA;&#xA;<p>I need quick answer on this subject.</p>&#xA;&#xA;<p>Regards,&#xA;Ferda  </p>&#xA;"
49377817,how do i handle security within my microservice architecture?,2018-03-20 06:45:05,<authentication><google-cloud-platform><microservices><vpc><api-gateway>,2,46,0,0.0,-1,"<p>In my webapp architecture i have an api gateway which proxies requests to my microservices, also there is a a common microservice which other microservices can query via rest api. All of these run on node servers.&#xA;i want the microservices to only be approachable from the api gateway, besides the common server which can also be approachable from the other microservices. what is the best network architecture to make this happen and do i need to handle authentication between the servers in some way?&#xA;<a href=""https://i.stack.imgur.com/uW4Te.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uW4Te.png"" alt=""enter image description here""></a></p>&#xA;"
49450592,RabbitMQ - How to handle 2 asynchronous messages as consuming microservice?,2018-03-23 13:18:39,<java><c#><rabbitmq><message-queue><microservices>,1,54,1,0.0,-1,"<p>I have a question searching for the best approach of solving a problem. We are currently working on replacing our software monolith by a microservice architecture.</p>&#xA;&#xA;<p>We want to use a message queue as communication between the different microservices.</p>&#xA;&#xA;<p>One of our microservice (the mail service) need to react after he has received two messages from two several microservices. The first message gives information about an order that has been made. It provides info about email content and recipients, the second message provides link to attachments, the email should include. </p>&#xA;&#xA;<p>The mail service should wait until both messages are received. Currently i am planning to store all messages into the database (one table for each message) and check every 5 seconds if both info is existing and the email can be send. </p>&#xA;&#xA;<p>But I have the feeling that maybe RabbitMQ also offers an approach, so I do not need to make my own development to avoid that race condition between those two messages. </p>&#xA;&#xA;<p>What would be your approach to solve this? </p>&#xA;"
49922136,Nuget package restore ERROR,2018-04-19 13:17:32,<.net><.net-core><nuget><microservices><nuget-package>,1,47,6,0.0,-1,<p>We created one rest client application and pushed it to nuget with version 1.0.0 and used it in one of our Micro Services and then recently we updated our Rest client application with new version 1.1.0 and tried to update it in our Micro services using nuget package restore. </p>&#xA;&#xA;<p>Now we got the latest version of our RestClient application dll ie Project.json file got updated with my latest version 1.1.0. But now when i try to build the application i am getting error for namespace not found for restclient</p>&#xA;&#xA;<p>When i checked project.json its already updated with my new version 1.1.0</p>&#xA;&#xA;<p>NOTE: I am using .net core</p>&#xA;&#xA;<p>Why i am not getting reference to my latest RestClient dll (1.1.0) in my MicroServices? </p>&#xA;&#xA;<p>Is there any work around for it?</p>&#xA;&#xA;<p>One work around i did is i deleted Project.json.lock files and i tried to restore again. But no luck</p>&#xA;
50314370,How to implement Rest APIs in monolithic architecture,2018-05-13 08:50:27,<rest><soap><microservices><soa>,1,22,0,0.0,-1,"<p>I understand (somewhat) what are differences between monolithic , microservices .&#xA;And also what is SOA it is a service consumer/provider architecture and microservice is subset of SOA. and they use Restfull/SOAP APIs to communicate.&#xA;So when a a request something he/she does using Rest/SOAP API but how in a Monolithic architecture a client request through which API? I searched all the links/blogs on google, videos on youtube but still I am not clear about this.</p>&#xA;&#xA;<p>Or may be my whole understanding is not correct.</p>&#xA;"
50484505,Asynchronous microservices in java,2018-05-23 09:19:56,<java><spring-mvc><spring-boot><asynchronous><microservices>,1,78,0,0.0,-1,"<p>My task is to create two simple microservices for movie management. One of them is responsible for movies and another for reviews. I have to create function for adding reviews (reviews will be added after approve). To check review movie service should call approving (review) service asynchronously. This is my very first time with asynchronous methods and I am not sure how should I create it. </p>&#xA;&#xA;<p>Below is my simple method from movie service to adding review. </p>&#xA;&#xA;<pre><code>public boolean addReviewForMovie(Review review, String movieId){&#xA;    Movie movie = movieRepository.findById(movieId);&#xA;    if(movie == null){&#xA;        return false;&#xA;    }&#xA;    review.setMovieId(movieId);&#xA;    return reviewService.addReview(review);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My approving algorithm is really simple - I want just to check couple of parameters. Here is my code.</p>&#xA;&#xA;<pre><code>public boolean addReview(Review review){&#xA;    if (review.getReviewContent().length() &lt; 10&#xA;            || review.getReviewContent().length() &gt; 250) {&#xA;        return false;&#xA;    }else if(review.getRating()&lt;1d || review.getRating() &gt; 10d){&#xA;        return false;&#xA;    }else if(review.getUserName().length() &lt; 1&#xA;            || review.getUserName().length() &gt; 15){&#xA;        return false;&#xA;    }&#xA;    review.setApproved(true);&#xA;    reviewRepository.save(review);&#xA;    return review.isApproved();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Could you please explain me how to create these methods asynchronous? I would appreciate if you send me some articles about it.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I refecator my code however I am not sure if this is the proper way. I exepect something else I guess.</p>&#xA;&#xA;<p>Below is my method in movie service class. I use it to add review. This method should ask for asynchronous one.</p>&#xA;&#xA;<pre><code>public void addReviewForMovie(Review review){&#xA;    CompletableFuture&lt;Boolean&gt; completableFuture = reviewService.addReview(review);&#xA;&#xA;    try {&#xA;       Boolean result = completableFuture.get();&#xA;       System.out.println(result);&#xA;    } catch (InterruptedException | ExecutionException e) {&#xA;        e.printStackTrace();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And here is my approving method</p>&#xA;&#xA;<pre><code>public CompletableFuture addReview(Review review){&#xA;CompletableFuture&lt;Boolean&gt; completableFuture = new CompletableFuture&lt;&gt;();&#xA;Executors.newCachedThreadPool().submit(()-&gt;{&#xA;    try{&#xA;        Thread.sleep(10000);&#xA;        boolean addedFlag = true;&#xA;        if (review.getReviewContent().length() &lt; 10&#xA;                || review.getReviewContent().length() &gt; 250) {&#xA;            addedFlag = false;&#xA;            completableFuture.complete(addedFlag);&#xA;        }else {&#xA;            review.setApproved(true);&#xA;            reviewRepository.save(review);&#xA;            completableFuture.complete(addedFlag);&#xA;        }&#xA;    } catch (Exception e){&#xA;        e.printStackTrace();&#xA;    }&#xA;    return null;&#xA;});&#xA;return completableFuture;&#xA;</code></pre>&#xA;&#xA;<p>Is implementation correct? I thought that the idea is that the first method will not be waiting for the second one and send it back once the addReview will be complited.</p>&#xA;"
50448620,Issue while using the kubernetes annotations,2018-05-21 12:10:46,<kubernetes><microservices>,3,151,0,0.0,-1,"<p>I've read documentation of kubernetes annotations. </p>&#xA;&#xA;<p>But I couldn't find basic example about using this annotations. For Example;</p>&#xA;&#xA;<p>I have a deployment yaml like below:</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  annotations:&#xA;    test_value: ""test""&#xA;  name: nginx-deployment&#xA;  labels:&#xA;    app: nginx&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: nginx&#xA;    spec:&#xA;      containers:&#xA;      - name: nginx&#xA;        image: nginx:1.13&#xA;        ports:&#xA;        - containerPort: 80&#xA;</code></pre>&#xA;&#xA;<p>How can I use this annotation named test_value and where.</p>&#xA;&#xA;<p>Best Regards...</p>&#xA;"
45424413,Which is the best option to query postgres node js?,2017-07-31 20:04:28,<node.js><postgresql><orm><microservices><database-performance>,1,355,0,0.0,-1,"<p>i want to make scalable micro services for millions of user with node js and postgres i want to know which is the best &#xA;way to query with  db, either by using orm or by  postgres stored function?</p>&#xA;"
45546510,How to interact with different microservices in a cloud,2017-08-07 12:05:57,<java><rest><web-services><amazon-web-services><microservices>,1,26,2,0.0,-1,"<p>I am asking me every day how is it possible to communicate between 2 or more microservices. I have to know the other service to invoke the url with the correct parameter is that right? But if I deploy my services on aws at Amazon where do my services know which Ip addresses assigned to the other services?</p>&#xA;&#xA;<p>For instance:</p>&#xA;&#xA;<p>I uploaded and deployed service A and service B. Service B want to communicate with service A but service B doesn't know the exact IP of service A. Do I need to declare it somewhere in a config file or undertake aws(Amazon) this task for me?</p>&#xA;&#xA;<p>My second question is about the authorization of each service. Every service need to create a token which is able to make a request. Is there a library outside where somebody can refer to? Or do I need to implement?</p>&#xA;&#xA;<p>Many thanks</p>&#xA;&#xA;<p>I know a lot of questions but hopefully someone can help me and solve this problems easly. </p>&#xA;&#xA;<p>If someone have a good practical example of this, please share it.</p>&#xA;"
48732814,Does Spring Boot with its Blocking IO really fit well with Microservices?,2018-02-11 14:56:37,<spring-boot><microservices><blocking>,2,153,2,0.0,-1,"<p>There are a lot of tutorials and articles (including official site) promoting spring boot as a good tool for building microservices.</p>&#xA;&#xA;<p>Let's say we have some rest api endpoint (User profile) which aggregates data from multiple services (User service, Stat service, Friends service).</p>&#xA;&#xA;<p>To achieve this, user profile endpoint makes 3 http calls to those services. </p>&#xA;&#xA;<p>But in Spring, requests are blocking and as I see, the server will quickly run out of available resources (threads) to serve request in such system.  </p>&#xA;&#xA;<p>So to me, it as quite inefficient way to build such systems (compared to non-blocking frameworks, like play! framework or node.js)</p>&#xA;&#xA;<p>Do I miss something? </p>&#xA;&#xA;<p>P.S.: I do not mean here spring 5 with its new webflux framework.</p>&#xA;"
37944398,How to pass two pass one more parameter other than key in google guava cache,2016-06-21 12:25:32,<java><caching><microservices><google-guava-cache>,1,179,2,0.0,-1,"<p>I have create a cache using google guava cache</p>&#xA;&#xA;<p>here is my implementation of it</p>&#xA;&#xA;<pre><code>private final LoadingCache&lt;Long, DistChannel&gt; channelServiceCache = CacheBuilder.newBuilder().maximumSize(50)&#xA;        .refreshAfterWrite(4, TimeUnit.HOURS).build(new CacheLoader&lt;Long, DistChannel&gt;() {&#xA;&#xA;            @Override&#xA;            public DistChannel load(Long channelId) throws InvalidRequestException, TException {&#xA;                long start = System.nanoTime();&#xA;                try {&#xA;                    return channelService.getDistributionChannelById(channelId, SOLR_API_KEY);&#xA;                } catch (InvalidRequestException e) {&#xA;                    log.error(""Cannot look up channel: {}"", channelId, e);&#xA;                    String serviceName = StringUtils.isNotBlank(e.getServiceName()) ? e.getServiceName() : CHANNEL_SERVICE;&#xA;                    throw e.setServiceName(serviceName + ""."" + SERVICE_NAME + ""."" + hostName);&#xA;                } finally {&#xA;                    log.info(""Channel Service call, ChannelId: {} Time : {}"", channelId,&#xA;                            TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start));&#xA;                }&#xA;            }&#xA;&#xA;&#xA;            @Override&#xA;            public ListenableFuture&lt;DistChannel&gt; reload(final Long channelId, final DistChannel oldValue) throws Exception {&#xA;                ListenableFutureTask&lt;DistChannel&gt; task = ListenableFutureTask.create(new Callable&lt;DistChannel&gt;() {&#xA;                    public DistChannel call() {&#xA;                        long start = System.nanoTime();&#xA;                        try {&#xA;                            return channelService.getDistributionChannelById(channelId, SOLR_API_KEY);&#xA;                        } catch (TException e) {&#xA;                            log.error(""Cannot look up channel: {}"", channelId, e);&#xA;                        }finally {&#xA;                            log.info(""reload Channel Service call, ChannelId: {} Time : {}"", channelId,&#xA;                                    TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start));&#xA;                        }&#xA;                        return oldValue;&#xA;                    }&#xA;                });&#xA;                executorServiceForCache.execute(task);&#xA;                return task;&#xA;            }&#xA;&#xA;        });&#xA;</code></pre>&#xA;&#xA;<p>now in channelService.getDistributionChannelById method, I need to paas two values namely channelId and apiKey.</p>&#xA;&#xA;<p>Currently its working fine as apiKey is constant. But now apiKey is modified to this contant ~ timestamp. for example:</p>&#xA;&#xA;<blockquote>&#xA;  <p>SOLR_API_KEY~123456789</p>&#xA;</blockquote>&#xA;&#xA;<p>So My Problem is:</p>&#xA;&#xA;<blockquote>&#xA;  <p>How can I pass one more parameter in <strong>channelServiceCache.get(key,&#xA;  extraparam here)</strong> without modifying the key.</p>&#xA;</blockquote>&#xA;&#xA;<p>Thing which I tried :&#xA;I created a Key object in which my actual key as well as apiKey will be present and pass that as key in <strong>channelServiceCache</strong>  But this will kill the purpose of cache as every kill will be considered a new key as it contains timestamp in apikey.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Is there any way I can do this with google guava?</p>&#xA;</blockquote>&#xA;&#xA;<p>EDIT : One more thing which I missed:</p>&#xA;&#xA;<p>service will give same output for same channelId, API key is only used for authentication and logging and monitoring request counts. But I guess it makes sense, If I can serve next request with same channelID from cache, then apiKey will never be passed to actual service (where actual logging and monitoring is taking place.) Is there any other way to implement this functionality without actually killing purpose of google guava.</p>&#xA;"
37405221,Implement microservice using spring boot without rest services,2016-05-24 05:39:59,<spring-boot><microservices>,2,148,2,0.0,-1,"<p>In my project ""DE"" ,I have many services like snmp,DiameterService,Cli service etc. I want to create a microservice arhitecture for it using spring boot like DE1 for SNMP, DE2,DE3 etc which will be registered in Eureka registry. But i dont want to access service through REST implementaion.Is there any other way to do this apart from REST.</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;  &lt;service-config-list&gt;&#xA;&#xA;    &lt;service-config&gt;&#xA;        &lt;service-name&gt;SNMPService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;snmpService&lt;/service-class-name&gt;&#xA;       &lt;service-status&gt;true&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;   &#xA;    &lt;service-config&gt;&#xA;        &lt;service-name&gt;IPC_MSG&lt;/service-name&gt;&#xA;        service-status&gt;true&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;   &#xA;&#xA;&lt;!--   &#xA; &lt;service-config&gt;&#xA;        &lt;service-name&gt;ControllerService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;controllerService&lt;/service-class-name&gt;&#xA;        &lt;service-status&gt;false&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;&#xA;&#xA; &lt;service-config&gt;&#xA;        &lt;service-name&gt;SubsNetworkNotfService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;subsNetworkNotfService&lt;/service-class-name&#xA;        &lt;service-status&gt;false&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;   --&gt;        &#xA;    &lt;service-config&gt;&#xA;        &lt;service-name&gt;TariffCheckService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;tariffCheckService&lt;/service-class-name&gt;&#xA;        &lt;service-status&gt;true&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;&#xA;     &lt;service-config&gt;&#xA;        &lt;service-name&gt;DiameterService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;diameterService&lt;/service-class-name&gt;&#xA;        &lt;service-status&gt;true&lt;/service-status&gt;&#xA;     &lt;/service-config&gt;  &#xA;&#xA;&#xA;     &lt;service-config&gt;&#xA;         &lt;service-name&gt;CLIService&lt;/service-name&gt;&#xA;        &lt;service-class-name&gt;cliService&lt;/service-class-name&gt;&#xA;         &lt;service-status&gt;false&lt;/service-status&gt;&#xA;    &lt;/service-config&gt;&#xA;</code></pre>&#xA;"
43492974,Multiple docker services to listen on same host and port,2017-04-19 10:23:58,<nginx><docker><docker-compose><microservices><jwilder-nginx-proxy>,1,578,0,0.0,-1,"<p>i am new to nginx and I am not sure is this normal behavior...</p>&#xA;&#xA;<p>Here is the lib I am using: <a href=""https://github.com/jwilder/nginx-proxy"" rel=""nofollow noreferrer"">https://github.com/jwilder/nginx-proxy</a></p>&#xA;&#xA;<p>I will explain here what I trying to accomplish... </p>&#xA;&#xA;<p>I have 2 additional services <code>service1</code> and <code>service2</code> those services are simple node.js images with API endpoints</p>&#xA;&#xA;<pre><code>service1 have routes:&#xA;- service1/api/first&#xA;- service1/api/second&#xA;`&#xA;&#xA;`&#xA;service2 have routes:&#xA;- service2/api/third&#xA;- service2/api/fourth&#xA;`&#xA;&#xA;So is possible to be able to access this services from same host, like this:&#xA;localhost/service1/api/first&#xA;localhost/service2/api/third&#xA;?&#xA;&#xA;I tried like this:&#xA;&#xA;My `docker-compose.yml` file:&#xA;&#xA;&#xA;version: '2'&#xA;services:&#xA;  nginx-proxy:&#xA;    image: jwilder/nginx-proxy&#xA;    container_name: nginx-proxy&#xA;    ports:&#xA;      - ""80:80""&#xA;    volumes:&#xA;      - /var/run/docker.sock:/tmp/docker.sock:ro&#xA;&#xA;  whoami:&#xA;    image: jwilder/whoami&#xA;    environment:&#xA;      - VIRTUAL_HOST=whoami.local&#xA;  service1:&#xA;    image: mynode:1.1&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service1.local&#xA;      - VIRTUAL_PORT=8080&#xA;  service2:&#xA;    image: mynodeother:1.2&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service2.local&#xA;      - VIRTUAL_PORT=8081&#xA;</code></pre>&#xA;&#xA;<p>Here is generated config file from command <code>docker exec nginx-proxy cat /etc/nginx/conf.d/default.conf</code>:&#xA;<a href=""http://pushsc.com/show/code/58f739790a58d602a0b99d22"" rel=""nofollow noreferrer"">http://pushsc.com/show/code/58f739790a58d602a0b99d22</a></p>&#xA;&#xA;<p>Also when I visit localhost in browser I get: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Welcome to nginx!</p>&#xA;  &#xA;  <p>If you see this page, the nginx web server is successfully installed&#xA;  and working. Further configuration is required.</p>&#xA;  &#xA;  <p>For online documentation and support please refer to nginx.org.&#xA;  Commercial support is available at nginx.com.</p>&#xA;  &#xA;  <p>Thank you for using nginx.</p>&#xA;</blockquote>&#xA;"
50280470,Micro-service architecture need advice,2018-05-10 19:47:36,<architecture><microservices><separation-of-concerns>,2,22,0,0.0,-1,"<p>We work in agile mode with two different teams/applications, we are facing a new situation and we need your advice. The front-end of the application A (developed by team A) is now needing a service from micro-service B (which is developed by team B). Should the front-end A directly ask the micro-service B or would you prefer that it goes through micro-service A ? is it a matter of separation of concerns here ? </p>&#xA;&#xA;<p>Help/advise would be highly appreciated.</p>&#xA;&#xA;<p>Thanx a lot!!</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/dC1e0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dC1e0.png"" alt=""enter image description here""></a></p>&#xA;"
50278841,Spring Integration microservices visualization tool,2018-05-10 17:58:09,<java><spring><spring-integration><visualization><microservices>,1,112,0,0.0,-1,"<p>I have an application based on microservices which communicate to each other via queues and topics. Each microservice is built using Spring Integration <em>with XML configurations</em>.</p>&#xA;&#xA;<p>Is there a tool/framework that I could use to automatically generate diagram for the whole application, which would ideally show Spring Integration details for each microservice and as well the connection (via queues/topics) between the microservices? </p>&#xA;"
50289509,Microservices : not getting response but all services are running,2018-05-11 09:45:23,<spring-boot><microservices>,1,29,2,0.0,-1,"<p>I am new into microservices, my all services are up but i do not get response from API. Could you please help me to find out exact cause? how to handle it? </p>&#xA;"
51908605,Spring Microservices - Caused by: java.lang.ClassNotFoundException: org.springframework.expression.spel.support.SimpleEvaluationContext,2018-08-18 12:21:13,<spring><spring-boot><microservices>,1,39,0,1.0,-1,"<p>I am following tutorial from the link : <a href=""https://dzone.com/articles/quick-guide-to-microservices-with-spring-boot-20-e"" rel=""nofollow noreferrer"">https://dzone.com/articles/quick-guide-to-microservices-with-spring-boot-20-e</a> without any customization.</p>&#xA;&#xA;<p>I've successfully started the <code>""config-service""</code>, <code>""discovery-service""</code> and <code>""proxy-service""</code> as per the sequentially.</p>&#xA;&#xA;<p>Now, when I simply tried to start the ""gateway-service"", I get the below error.</p>&#xA;&#xA;<p>Could anyone please guide me on this ?</p>&#xA;&#xA;<pre><code>    Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.&#xA;    2018-08-18 17:44:38 ERROR [gateway-service,,,] Application run failed&#xA;    org.springframework.context.ApplicationContextException: Unable to start reactive web server; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'httpHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/HttpHandlerAutoConfiguration$AnnotationConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.http.server.reactive.HttpHandler]: Factory method 'httpHandler' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/WebFluxAutoConfiguration$EnableWebFluxConfiguration.class]: Initialization of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routePredicateHandlerMapping' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routePredicateHandlerMapping' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.onRefresh(ReactiveWebServerApplicationContext.java:76) ~[spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:61) ~[spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752) [spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:388) [spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) [spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1234) [spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at pl.piomin.services.gateway.GatewayApplication.main(GatewayApplication.java:13) [classes/:na]&#xA;    Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'httpHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/HttpHandlerAutoConfiguration$AnnotationConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.http.server.reactive.HttpHandler]: Factory method 'httpHandler' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/WebFluxAutoConfiguration$EnableWebFluxConfiguration.class]: Initialization of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routePredicateHandlerMapping' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routePredicateHandlerMapping' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' parameter 3; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:587) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1250) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1099) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:502) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:312) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:310) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:205) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.getHttpHandler(ReactiveWebServerApplicationContext.java:155) ~[spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.createWebServer(ReactiveWebServerApplicationContext.java:99) ~[spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.onRefresh(ReactiveWebServerApplicationContext.java:73) ~[spring-boot-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        ... 8 common frames omitted&#xA;    Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.http.server.reactive.HttpHandler]: Factory method 'httpHandler' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/WebFluxAutoConfiguration$EnableWebFluxConfiguration.class]: Initialization of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routePredicateHandlerMapping' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routePredicateHandlerMapping' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' parameter 3; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:579) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        ... 19 common frames omitted&#xA;    Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webHandler' defined in class path resource [org/springframework/boot/autoconfigure/web/reactive/WebFluxAutoConfiguration$EnableWebFluxConfiguration.class]: Initialization of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routePredicateHandlerMapping' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routePredicateHandlerMapping' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' parameter 3; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:591) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:502) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:312) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:310) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:205) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1091) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.web.server.adapter.WebHttpHandlerBuilder.applicationContext(WebHttpHandlerBuilder.java:161) ~[spring-web-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig.httpHandler(HttpHandlerAutoConfiguration.java:59) ~[spring-boot-autoconfigure-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig$$EnhancerBySpringCGLIB$$d70fd0de.CGLIB$httpHandler$0(&lt;generated&gt;) ~[spring-boot-autoconfigure-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig$$EnhancerBySpringCGLIB$$d70fd0de$$FastClassBySpringCGLIB$$8ebbee2e.invoke(&lt;generated&gt;) ~[spring-boot-autoconfigure-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) ~[spring-core-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig$$EnhancerBySpringCGLIB$$d70fd0de.httpHandler(&lt;generated&gt;) ~[spring-boot-autoconfigure-2.0.0.RELEASE.jar:2.0.0.RELEASE]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_151]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_151]&#xA;        at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_151]&#xA;        at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        ... 20 common frames omitted&#xA;    Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routePredicateHandlerMapping' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routePredicateHandlerMapping' parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' parameter 3; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:729) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:470) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1250) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1099) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:502) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:312) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:310) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:515) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1202) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.BeanFactoryUtils.beansOfTypeIncludingAncestors(BeanFactoryUtils.java:311) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.web.reactive.DispatcherHandler.initStrategies(DispatcherHandler.java:126) ~[spring-webflux-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.web.reactive.DispatcherHandler.setApplicationContext(DispatcherHandler.java:121) ~[spring-webflux-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.context.support.ApplicationContextAwareProcessor.invokeAwareInterfaces(ApplicationContextAwareProcessor.java:120) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.context.support.ApplicationContextAwareProcessor.postProcessBeforeInitialization(ApplicationContextAwareProcessor.java:96) ~[spring-context-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:423) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1702) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:583) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        ... 38 common frames omitted&#xA;    Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'cachedCompositeRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'cachedCompositeRouteLocator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' parameter 3; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionLocator' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:729) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:470) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1250) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1099) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:502) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:312) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:310) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1065) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:815) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:721) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        ... 57 common frames omitted&#xA;    Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'routeDefinitionRouteLocator' defined in class path resource [org/springframework/cloud/gateway/config/GatewayAutoConfiguration.class]: Unsatisfied dependency expressed through method 'routeDefinitionRouteLocator' org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'discoveryClientRouteDefinitionLocator' defined in class path resource [org/springframework/cloud/gateway/discovery/GatewayDiscoveryClientAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.gateway.discovery.DiscoveryClientRouteDefinitionLocator] from ClassLoader [sun.misc.Launcher$AppClassLoader@764c12b6]&#xA;org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        at      ... 115 common frames omitted&#xA;    Caused by: java.lang.NoClassDefFoundError: org/springframework/expression/spel/support/SimpleEvaluationContext&#xA;        at java.lang.Class.getDeclaredMethods0(Native Method) ~[na:1.8.0_151]&#xA;        at java.lang.Class.privateGetDeclaredMethods(Unknown Source) ~[na:1.8.0_151]&#xA;        at java.lang.Class.getDeclaredMethods(Unknown Source) ~[na:1.8.0_151]&#xA;        at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:641) ~[spring-core-5.0.4.RELEASE.jar:5.0.4.RELEASE]&#xA;        ... 122 common frames omitted&#xA;    Caused by: java.lang.ClassNotFoundException: org.springframework.expression.spel.support.SimpleEvaluationContext&#xA;        at java.net.URLClassLoader.findClass(Unknown Source) ~[na:1.8.0_151]&#xA;        at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;        at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;        at java.lang.ClassLoader.loadClass(Unknown Source) ~[na:1.8.0_151]&#xA;        ... 126 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p>Using the Spring Boot Parent version : &#xA;<a href=""https://i.stack.imgur.com/iCDvb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iCDvb.png"" alt=""enter image description here""></a></p>&#xA;"
51842460,Miscroservice Intercommunication with RabbitMQ,2018-08-14 13:18:11,<java><rabbitmq><microservices><messaging>,1,43,4,0.0,-1,"<p>I'm new in the worls of Microservices and I'm buildung a pretty basic Architecture the combine the basic components I might need for a later project.&#xA;My enviroment is eclipse using spring.&#xA;So I thought about having 3 different Microservices.&#xA;Service A does a simple calculation after a rest call and writes the parameters, the operand and the result in a database.&#xA;Service B should read the the last result from the database.&#xA;Service C should take the last 10 results from the Database.</p>&#xA;&#xA;<p>So after reading about best practice handling this task I thought about realizing it asynchronous. So A should message B and C when the result is written into the database so that they can read their needed values in parallel from the database instead of on waiting for another.&#xA;I found a pretty good tutorial where I think I got the code I need <a href=""https://www.youtube.com/watch?v=c7cWKZlgnNc"" rel=""nofollow noreferrer"">here</a> &#xA;I thought about running an instance of RabbitMQ on my localhost:9999 for example.&#xA;Then I would set Service A my message producer and B and C as my consumers with registering the connection to this adress. To communicate I would do one queue for each service where I send the signal when A is finished.&#xA;Is this a proper solution for this task and is my plan of realizing it reliable? Or do you have any better solution?&#xA;I hope this is not a dump question.&#xA;Thank you guys</p>&#xA;"
50736767,"Micro services , docker in Aws",2018-06-07 08:44:04,<amazon-web-services><docker><microservices>,1,20,0,0.0,-1,"<p>I am trying to deploy spring boot based micro services in docker to aws , but i am completely confused how should i start , i had seen few links from internet , but it did not gave me good start  , below are my links : </p>&#xA;&#xA;<pre><code>https://www.youtube.com/watch?v=jKrLAwDN7uY&#xA;&#xA;http://www.adrianmilne.com/deploying-a-spring-boot-microservice-to-docker-aws-elastic-beanstalk/&#xA;&#xA;https://keyholesoftware.com/2017/09/26/using-docker-aws-to-build-deploy-and-scale-your-application/&#xA;</code></pre>&#xA;&#xA;<p>can u please provide the best practice for developer , how should i do it ?...</p>&#xA;"
50893043,How to bundle UI with Microservice,2018-06-17 01:44:21,<angular><spring-boot><microservices><spring-cloud><angular-universal>,1,66,0,0.0,-1,"<p>We have nearly 70+ <strong>microservices with Spring Cloud</strong>. Everything works as expected. But, we have a big giant UI Angular app which is consuming all services.</p>&#xA;&#xA;<p>I have read somewhere that the better approach is to bundle UI along with service to avoid dependencies. Sounds good, but couldn't pointers for it. Just got that there is a <strong>UI composition pattern</strong> but couldn't connect how could it really help.b</p>&#xA;&#xA;<p>How do we really <strong>couple a service with the UI</strong> as one system and ship(deploy) it? <strong>Is it really worth</strong>? If so, can someone point me to any sample example? How to <strong>combine different HTML responses</strong> of various services at client side?</p>&#xA;"
50801690,Working with microservices. Hibernate or Scripts,2018-06-11 15:52:24,<java><database><hibernate><microservices>,1,58,3,0.0,-1,"<p>What is the best approach for database creation and relationship management when working with microservices?Hibernate or scripts, as i feel it shouldn't be the responsibility of microservices to create a database </p>&#xA;"
48536106,Configuring Microservices with springboot and AWS need help to start,2018-01-31 06:48:44,<amazon-web-services><spring-boot><microservices>,1,33,0,0.0,-1,<p>I am a beginner in creating micro-services using springboot with aws. What is the best way to start?</p>&#xA;
37738759,Scrapy throttling and request scheduling only microservices,2016-06-10 01:52:04,<python><scrapy><python-requests><microservices><grequests>,1,125,0,0.0,-1,"<p>I'm currently using python requests to download around 20,000 pages of json. I'm running into some bottlenecking due to rate limiting by the server I'm scraping, and maybe a lack of asynchronous calls/scheduling. I thought scrapy would be a good solution because I heard it has features to combat these problems associated with scraping. The thing is, those are the only parts I need, I don't need spidering/parsing/orm/etc. Looking at the docs, it was unclear how I would seperate out just these components. I need a microservice for just these parts of what scrapy does. The Flask to Scrapy's Django. I saw grequests might help with async, but if I go that route I still need rate limiting and a way to retry failed requests. Can someone point me in the right direction?</p>&#xA;"
46644740,Microservice design - How call for every record,2017-10-09 10:54:07,<java><spring><rest><design-patterns><microservices>,1,38,0,1.0,-1,"<p>As I understood, in microservice design application every microservice serve exact purpose and have (must) own database.</p>&#xA;&#xA;<p>But in case, when you show list of orders from Finance microservice and for every orders have customer which is on CRM microservice, its mean you must call getCustmerSimpeDetail for every order's row ?</p>&#xA;"
47767993,Split Rails app to small microservices with Go,2017-12-12 08:16:08,<ruby-on-rails><go><microservices>,1,126,0,2.0,-1,"<p>I'm wondering to do some scaling on our Rails app and I'd like to use Go lang. So, today we have quite big application written in RoR and Postgresql, where a lot of processing&amp;computations goes through Ruby which turned to be slow. </p>&#xA;&#xA;<p>I'm wondering to take some parts of our application, and to re-write them in Golang for the sake of better performances. </p>&#xA;&#xA;<p>I'd like to hear some good advices&amp;practices, especially how to start splitting them. How Go&amp;Rails can communicate and how to move some <strong>hard</strong> computations to Go ? Is there some way they can share same database/data ? </p>&#xA;&#xA;<p>Best Regards</p>&#xA;"
47357038,Microservice shared database,2017-11-17 18:27:35,<mysql><node.js><database><microservices>,1,221,1,0.0,-1,"<p>I know that this question has been discussed a lot already, but I would like to describe my situation.</p>&#xA;&#xA;<p>As far as I know, there are techniques and best practices to solve the shared database in microservices architectures (event sourcing, CQRS...) but all of that seems to complex for my case, let me explain.</p>&#xA;&#xA;<p>I built a rest API using nodejs. This API allow you to fetch, using a GET request, the data stored in a mysql database.&#xA;Now I need to import a lot of data in the same database (creating every time a new table). The first solution could be to add a new endpoint (POST request) to the existing microservice  to create the new table and add the new data.</p>&#xA;&#xA;<p>But I was thinking about to create a different nodejs microservice (import service) because the import feature could be very CPU time consuming and nodejs is single thread;  I donâ€™t want that a user has to wait to fetch the data because another one is importing the new one.</p>&#xA;&#xA;<p>The problem whit that solution is that I have to share the same database between the 2 microservices. Using the typical approaches (event sourcing, CQRS) could be the best solution but it complexs too much the architecture ( for this project I don't need to address the data consistency problem). </p>&#xA;&#xA;<p>There are others 2 solution that I can use: </p>&#xA;&#xA;<ol>&#xA;<li>create a common Lib to access the DB and use the lib in the microservices</li>&#xA;<li>The â€œimport microserviceâ€ instead of access to the database directly, can use the API rest of the other service to post the new data as soon as they are ready to be imported.</li>&#xA;</ol>&#xA;&#xA;<p>What is the best solution? Do you know other possible ways to address this problem?</p>&#xA;&#xA;<p>Thank you very much</p>&#xA;"
45349101,Microservice Messaging Choices,2017-07-27 11:09:41,<c#><azure><data-structures><messaging><microservices>,1,193,1,1.0,-1,"<p>I am new to microservices, but I'd like to know what the best way to handle communication is.&#xA;I've looked into some solutions, but like to know your opinion what todo :&#xA;My microservices are hosted on azure atm and I call them with REST services,</p>&#xA;&#xA;<p>but...</p>&#xA;&#xA;<p>I want that the services cannot be called from anybody except from other services as I have a facade API for external apps. </p>&#xA;&#xA;<p>I've looked into Servicebus, Eventhubs, REST , WCF, SQL with RabbitMQ, but I have no idea what is the fastest messaging service.</p>&#xA;&#xA;<p>I prefer speed and stability over everything ,high complexityis not a problem.</p>&#xA;&#xA;<p>Does anybody have advice on this?</p>&#xA;&#xA;<p>Thank you in advance</p>&#xA;"
41171413,Docker in docker and docker compose block one port for no reason,2016-12-15 18:55:41,<docker><docker-compose><microservices>,1,120,0,0.0,-1,"<p>Right now I am setting up an application that has a deployment based upon docker images.</p>&#xA;&#xA;<p>I use gitlab ci to:</p>&#xA;&#xA;<ol>&#xA;<li>Test each service</li>&#xA;<li>Build each service</li>&#xA;<li>Dockerize each image (create docker container)</li>&#xA;<li>Run integration tests (start docker compose that starts all services on special ports, run integration tests)</li>&#xA;<li>Stop prod images and run new images</li>&#xA;</ol>&#xA;&#xA;<p>I did this for each service, but I ran into an issue.</p>&#xA;&#xA;<p>When I start my docker container for integration tests then it is setup within a gitlab ci task. For each task a docker based runner is used. I also mount my host docker socket to be able to use docker in docker.</p>&#xA;&#xA;<p>So my gradle docker image is started by the gitlab runner. Then docker will be installed and all images will be started using docker compose.</p>&#xA;&#xA;<p>One microservice listens to port 10004. Within the docker compose file there is a 11004:10004 port mapping. </p>&#xA;&#xA;<p>My integration tests try to connect to port 11004. But this does not work right now.</p>&#xA;&#xA;<p>When I attach to the image that run docker compose while it tries to execute the integration test then I am not able to do it manually by calling</p>&#xA;&#xA;<pre><code>wget ip: port &#xA;</code></pre>&#xA;&#xA;<p>I just get the message connected and waiting for response. Either my tests can connect successfully. My service does not log any message about a new connection.</p>&#xA;&#xA;<p>When I execute this <code>wget</code> command withinÂ  my host shell then it works.</p>&#xA;&#xA;<p>It's a public ip and within my container I can also connect to other ports using <code>telnet</code> and <code>wget</code>. Just one port of one service is broken when I try to connect from my docker in docker instance.</p>&#xA;&#xA;<p>When I do not use docker compose then it works. Docker compose seems to setup a special default network that does something weird.</p>&#xA;&#xA;<p>Setting network to host also works...</p>&#xA;&#xA;<p>So did anyone also make such an experience when using docker compose?</p>&#xA;&#xA;<p>The same setup works flawless in docker for mac, but my server runs on Debian 8.</p>&#xA;&#xA;<p>My solution for now is to use a shell runner to avoid docker in docker issues. It works there as well.</p>&#xA;&#xA;<p>So docker in docker combined with docker compose seems to have an ugly bug.</p>&#xA;&#xA;<p>I'm writing while I am sitting in the subway but I hope describing my issue is also sufficient to talk about experiences. I don't think we need some sourcecode to find bad configurations because it works without docker in docker and on Mac.</p>&#xA;"
45771097,Microservices Architectural Design,2017-08-19 11:41:09,<java><spring-boot><architecture><microservices>,1,54,0,0.0,-1,"<p>I have been reading tutorials and codes on microservices, mostly, in Java (I know microservice is independent of language).</p>&#xA;&#xA;<p>But, I'm still confused how to design microservices.</p>&#xA;&#xA;<p>For example, in a sale application, at least, it has the following resources:</p>&#xA;&#xA;<ul>&#xA;<li>products</li>&#xA;<li>customers</li>&#xA;<li>orders</li>&#xA;</ul>&#xA;&#xA;<p>Should I create a project for each resource? Let's say: <strong>product-service</strong>, <strong>customer-service</strong>, and <strong>order-service</strong>. If I were to use Spring Boot, these would have respective port number to run on - 8080, 8081, 8082.</p>&#xA;&#xA;<p>How about the domain model classes - Customer, Product, Order? Should I create another project and import it to the three projects?</p>&#xA;&#xA;<p>Please enlighten me. Add more relevant topics if possible.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
45592666,"How to establish communication between ""AZURE Application Gateway and Linux VM"" on azure cloud ?",2017-08-09 13:51:12,<azure><deployment><virtual-machine><microservices><azure-application-gateway>,1,167,2,0.0,-1,<p>Dear All we want to use AZURE Application Gateway to implement SSL in front of our LINUX VM (hosting our node.js microservices).</p>&#xA;&#xA;<p><strong>As per current configuration:</strong></p>&#xA;&#xA;<p>-we have same resource group for both application gateway and linux VM.</p>&#xA;&#xA;<p>-both are on the same virtual network but different subnets (as application gateway needs its own subnet).</p>&#xA;&#xA;<p>-Without application gateway i can access my microservices without any issue.</p>&#xA;&#xA;<p>Could somebody please suggest regarding how to establish a communication between application gateway and our microservices hosted on linux VM.</p>&#xA;
45598647,Microservice between my own application and a logging application to structure logging,2017-08-09 18:56:37,<c#><microservices>,2,307,4,0.0,-1,<p>I'm trying to find a good example which explains me how I can build a micro-service that I can put between my own application and a logging application like seq. In this way I'll try to put the logging data in the same destination an I can switch easily from those logging application so I don't have to edit my entire code. Is there a way to do this and maybe a example which explains this. I've already googled for it but I didn't found any clear explanations.</p>&#xA;
