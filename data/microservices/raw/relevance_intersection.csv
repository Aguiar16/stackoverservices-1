Id,Title,CreationDate,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
27007353,How does data denormalization work with the Microservice Pattern?,2014-11-19 01:25:07,<database><denormalization><microservices>,4,6219,4,21.0,62,"<p>I just read an article on <a href=""http://java.dzone.com/articles/microservices-and-paas-part-2"">Microservices and PaaS Architecture</a>. In that article, about a third of the way down, the author states (under <strong>Denormalize like Crazy</strong>):</p>&#xA;&#xA;<blockquote>&#xA;  <p>Refactor database schemas, and de-normalize everything, to allow complete separation and partitioning of data. That is, do not use underlying tables that serve multiple microservices. There should be no sharing of underlying tables that span multiple microservices, and no sharing of data. Instead, if several services need access to the same data, it should be shared via a service API (such as a published REST or a message service interface).</p>&#xA;</blockquote>&#xA;&#xA;<p>While this <em>sounds</em> great in theory, in practicality it has some serious hurdles to overcome. The biggest of which is that, often, databases are tightly coupled and every table has <em>some</em> foreign key relationship with at least one other table. Because of this it could be impossible to partition a database into <em>n</em> sub-databases controlled by <em>n</em> microservices.</p>&#xA;&#xA;<p>So I ask: <strong>Given a database that consists entirely of related tables, how does one denormalize this into smaller fragments (groups of tables) so that the fragments can be controlled by separate microservices?</strong></p>&#xA;&#xA;<p>For instance, given the following (rather small, but exemplar) database:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;user_id&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;product_id&#xA;order_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p>Don't spend too much time critiquing my design, I did this on the fly. The point is that, to me, it makes logical sense to split this database into 3 microservices:</p>&#xA;&#xA;<ol>&#xA;<li><code>UserService</code> - for CRUDding users in the system; should ultimately manage the <code>[users]</code> table; and</li>&#xA;<li><code>ProductService</code> - for CRUDding products in the system; should ultimately manage the <code>[products]</code> table; and</li>&#xA;<li><code>OrderService</code> - for CRUDding orders in the system; should ultimately manage the <code>[orders]</code> and <code>[products_x_orders]</code> tables</li>&#xA;</ol>&#xA;&#xA;<p>However all of these tables have foreign key relationships with each other. If we denormalize them and treat them as monoliths, they lose all their semantic meaning:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p><strong>Now there's no way to know who ordered what, in which quantity, or when.</strong></p>&#xA;&#xA;<p>So is this article typical academic hullabaloo, or is there a real world practicality to this denormalization approach, and if so, what does it look like (bonus points for using my example in the answer)?</p>&#xA;"
28767707,How to deal with shared state in a micro-service architecture?,2015-02-27 14:44:20,<deployment><architecture><integration-testing><microservices><test-environments>,3,4043,8,13.0,17,"<p>In our company we are transitioning from a huge monolithic application to a micro-service architecture. The main technical drivers for this decision were the need to be able to scale services independently and the scalability of development - we've got ten scrum teams working in different projects (or 'micro-services').</p>&#xA;&#xA;<p>The transition process is being smooth and we've already started to benefit from the advantages of this new technical and organizational structures. Now, on the other hand, <strong>there is a main point of pain that we are struggling with: how to manage the 'state' of the dependencies between these micro-services</strong>. </p>&#xA;&#xA;<p>Let's put an example: one of the micro-services deals with users and registrations. This service (let's call it X) is responsible for maintaining identity information and thus is the main provider for user 'ids'. The rest of the micro-services have a strong dependency on this one. For example, there are some services responsible for user profile information (A), user permissions (B), user groups (C), etc. that rely on those user ids and thus there is a need for maintaining some data sync between these services (i.e. service A should not have info for a userId not registered in service X). We currently maintain this sync by notifying changes of state (new registrations, for example) using RabbitMQ. </p>&#xA;&#xA;<p>As you can imagine, there are <em>many</em> Xs: many 'main' services and many more complicated dependencies between them.</p>&#xA;&#xA;<p>The main issue comes when managing the different dev/testing environments. Every team (and thus, every service) needs to go through several environments in order to put some code live: continuous integration, team integration, acceptance test and live environments. </p>&#xA;&#xA;<p>Obviously we need all services working in all these environments to check that the system is working as a whole. Now, this means that in order to test dependent services (A, B, C, ...) we must not only rely on service X, but also on its state. <strong>Thus, we need somehow to maintain system integrity and store a global &amp; coherent state</strong>.</p>&#xA;&#xA;<p>Our current approach for this is getting snapshots of all DBs from the live environment, making some transformations to shrink and protect data privacy and propagating it to all environments before testing in a particular environment. This is obviously a tremendous overhead, both organizationally and in computational resources: we have ten continuous integration environments, ten integration environments and one acceptance test environment that all need to be 'refreshed' with this shared data from live and the latest version of the code frequently. </p>&#xA;&#xA;<p>We are struggling to find a better way to ease this pain. Currently we are evaluating two options: </p>&#xA;&#xA;<ol>&#xA;<li>using docker-like containers for all these services </li>&#xA;<li>having two versions of each service (one intended for development of that service and one another as a sandbox to be used by the rest of the teams in their development &amp; integration testing)</li>&#xA;</ol>&#xA;&#xA;<p><strong>None of these solutions ease the pain of shared data between services</strong>. We'd like to know how some other companies/developers are addressing this problem, as we think this must be common in a micro services architecture. </p>&#xA;&#xA;<p>How are you guys doing it? Do you also have this problem? Any recommendation?</p>&#xA;&#xA;<p>Sorry for the long explanation and thanks a lot!</p>&#xA;"
28500066,How to deploy SpringBoot Maven application with Jenkins ?,2015-02-13 12:51:45,<maven><tomcat><jenkins><spring-boot><microservices>,4,19550,5,5.0,16,"<p>I have a Spring Boot application which runs on embedded Tomcat servlet container <code>mvn spring-boot:run</code> . And I donâ€™t want to deploy the project as separate war to standalone Tomcat. </p>&#xA;&#xA;<p>Whenever I push code to BitBucket/Github, a hook runs and triggers Jenkins job (runs on Amazon EC2) to deploy the application. </p>&#xA;&#xA;<p>The Jenkins job has a post build action: <code>mvn spring-boot:run</code>, the problem is that the job hangs when post build action finished. </p>&#xA;&#xA;<p>There should be another way to do this. Any help would be appreciated.</p>&#xA;"
30213456,Transactions across REST microservices?,2015-05-13 11:27:25,<rest><architecture><transactions><microservices>,10,43100,6,79.0,120,"<p>Let's say we have a User, Wallet REST microservices and an API gateway that glues things together. When Bob registers on our website, our API gateway needs to create a user through the User microservice and a wallet through the Wallet microservice. </p>&#xA;&#xA;<p>Now here are a few scenarios where things could go wrong:</p>&#xA;&#xA;<ul>&#xA;<li><p>User Bob creation fails: that's OK, we just return an error message to the Bob. We're using SQL transactions so no one ever saw Bob in the system. Everything's good :)</p></li>&#xA;<li><p>User Bob is created but before our Wallet can be created, our API gateway hard crashes. We now have a User with no wallet (inconsistent data).</p></li>&#xA;<li><p>User Bob is created and as we are creating the Wallet, the HTTP connection drops. The wallet creation might have succeeded or it might have not.</p></li>&#xA;</ul>&#xA;&#xA;<p>What solutions are available to prevent this kind of data inconsistency from happening? Are there patterns that allow transactions to span multiple REST requests? I've read the Wikipedia page on <a href=""http://en.wikipedia.org/wiki/Two-phase_commit_protocol"">Two-phase commit</a> which seems to touch on this issue but I'm not sure how to apply it in practice. This <a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"">Atomic Distributed Transactions: a RESTful design</a> paper also seems interesting although I haven't read it yet.</p>&#xA;&#xA;<p>Alternatively, I know REST might just not be suited for this use case. Would perhaps the correct way to handle this situation to drop REST entirely and use a different communication protocol like a message queue system? Or should I enforce consistency in my application code (for example, by having a background job that detects inconsistencies and fixes them or by having a ""state"" attribute on my User model with ""creating"", ""created"" values, etc.)?</p>&#xA;"
41640621,Data Sharing between micro services,2017-01-13 17:52:49,<design-patterns><architecture><microservices><aws-api-gateway><data-sharing>,4,6060,9,11.0,24,"<p><strong>Current Architecture:</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qlrIu.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qlrIu.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Problem:</strong></p>&#xA;&#xA;<p>We have a two-step flow between frontend and backend layers.  </p>&#xA;&#xA;<ul>&#xA;<li>First step:&#xA;The frontend validates an input <strong>I1</strong> from the user on microservice 1 (MS1)</li>&#xA;<li>Second step:&#xA;The frontend submits <strong>I1</strong> and more information to the microservice 2</li>&#xA;</ul>&#xA;&#xA;<p>The micro service 2 (MS2) needs to validates the integrity of <strong>I1</strong> as it is coming from the frontend. How to do avoid a new query to MS1? What's the best approach?</p>&#xA;&#xA;<p><strong>Flows that I'm trying to optimize removing the steps 1.3 and 2.3</strong></p>&#xA;&#xA;<p>Flow 1:</p>&#xA;&#xA;<ul>&#xA;<li>1.1 The User X requests data (MS2_Data) from MS2</li>&#xA;<li>1.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>1.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>1.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p>Flow 2:</p>&#xA;&#xA;<ul>&#xA;<li>2.1 The User X already has data (MS2_Data) stored on local/session storage</li>&#xA;<li>2.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>2.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>2.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Approach</strong></p>&#xA;&#xA;<p>One possible approach is to use a B2B HTTP request between MS2 and MS1 but we would be duplicating the validation in the first step.&#xA;Another approach will be duplicating data from MS1 to MS2. however this is prohibitive due to the amount of data and it's volatility nature. Duplication does not seem to be a viable option.</p>&#xA;&#xA;<p>A more suitable solution is my opinion will the frontend to have the responsibility to fetch all the information required by the micro service 1 on the micro service 2 and delivered it to the micro service 2. This will avoid all this B2B HTTP requests.</p>&#xA;&#xA;<p><strong>The problem is how the micro service 1 can trust the information sent by the frontend. Perhaps using <a href=""https://jwt.io/introduction/"" rel=""noreferrer"">JWT</a> to somehow sign the data from the micro service 1 and the micro service 2 will be able to verify the message.</strong></p>&#xA;&#xA;<p><strong>Note</strong>&#xA;Every time the micro service 2 needs information from the micro service 1 a B2B http request is performed. (The HTTP request use <a href=""https://en.wikipedia.org/wiki/HTTP_ETag"" rel=""noreferrer"">ETAG</a> and <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control"" rel=""noreferrer"">Cache Control: max-age</a>). How to avoid this? </p>&#xA;&#xA;<p><strong>Architecture Goal</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FR7E7.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FR7E7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The micro service 1 needs the data from the micro service 2 on demand to be able to persist MS1_Data and MS2_Data on MS1 database, so the ASYNC approach using a broker does not apply here.</strong></p>&#xA;&#xA;<p>My question is if exists a design pattern, best practice or a framework to enable this kind of thrust communication. </p>&#xA;&#xA;<p>The downside of the current architecture is the number of B2B HTTP requests that are performed between each micro services. Even if I use a cache-control mechanism the response time of each micro service will be affected. The response time of each micro services is critical. The goal here is to archive a better performance and some how use the frontend as a gateway to distribute data across several micro services but using a <strong>thrust communication</strong>. </p>&#xA;&#xA;<p>MS2_Data is just an Entity SID like product SID or vendor SID that the MS1 must use to maintain data integrity. </p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qSYQY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qSYQY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The idea is to use the gateway as an api gateway request processing that will cache some HTTP response from MS1 and MS2 and use them as a response to MS2 SDK and MS1 SDK. This way no communication (SYNC OR ASYNC) is made directly between MS1 and MS2 and data duplication is also avoided.</p>&#xA;&#xA;<p>Of course the above solution is just for shared UUID/GUID across micro services. For full data, an event bus is used to distribute events and data across micro services in an asynchronous way (Event sourcing pattern). </p>&#xA;&#xA;<p>Inspiration: <a href=""https://aws.amazon.com/api-gateway/"" rel=""noreferrer"">https://aws.amazon.com/api-gateway/</a> and <a href=""https://getkong.org/"" rel=""noreferrer"">https://getkong.org/</a></p>&#xA;&#xA;<p><strong>Related questions and documentation:</strong></p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://stackoverflow.com/questions/41445442/how-to-sync-the-database-with-the-microservices-and-the-new-one/41475346"">How to sync the database with the microservices (and the new one)?</a></li>&#xA;<li><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""noreferrer"">https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/30213456/transactions-across-rest-microservices"">Transactions across REST microservices?</a></li>&#xA;<li><a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></li>&#xA;<li><a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"" rel=""noreferrer"">http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf</a></li>&#xA;<li><a href=""https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/"" rel=""noreferrer"">https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/</a></li>&#xA;</ul>&#xA;"
29644916,Microservice Authentication strategy,2015-04-15 08:10:33,<authentication><architecture><microservices>,4,35930,7,47.0,92,"<p>I'm having a hard time choosing a decent/secure authentication strategy for a microservice architecture. The only SO post I found on the topic is this one: <a href=""https://stackoverflow.com/questions/25595492/single-sign-on-in-micro-service-architecture"">Single Sign-On in Microservice Architecture</a></p>&#xA;&#xA;<p>My idea here is to have in each service (eg. authentication, messaging, notification, profile etc.) a unique reference to each user (quite logically then his <code>user_id</code>) and the possibility to get the current user's <code>id</code> if logged in.</p>&#xA;&#xA;<p>From my researches, I see there are two possible strategies:</p>&#xA;&#xA;<h3>1. Shared architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/po7Qr.png"" alt=""Shared architecture""></p>&#xA;&#xA;<p>In this strategy, the authentication app is one service among other. But each service must be able to make the conversion <code>session_id</code> => <code>user_id</code> so it must be dead simple. That's why I thought of Redis, that would store the key:value <code>session_id:user_id</code>.</p>&#xA;&#xA;<h3>2. Firewall architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/NHGjh.png"" alt=""Firewall architecture""></p>&#xA;&#xA;<p>In this strategy, session storage doesn't really matter, as it is only handled by the authenticating app. Then the <code>user_id</code> can be forwarded to other services. I thought of Rails + Devise (+ Redis or mem-cached, or cookie storage, etc.) but there are tons of possibilities. The only thing that matter is that Service X will never need to authenticate the user.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How do those two solutions compare in terms of:</p>&#xA;&#xA;<ul>&#xA;<li>security</li>&#xA;<li>robustness</li>&#xA;<li>scalability</li>&#xA;<li>ease of use</li>&#xA;</ul>&#xA;&#xA;<p>Or maybe you would suggest another solution I haven't mentioned in here?</p>&#xA;&#xA;<p>I like the solution #1 better but haven't found much default implementation that would secure me in the fact that I'm going in the right direction.</p>&#xA;&#xA;<p>I hope my question doesn't get closed. I don't really know where else to ask it.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
36701111,Communication between two microservices,2016-04-18 17:58:51,<java><spring><spring-boot><jhipster><microservices>,4,13403,5,9.0,29,"<p>I am creating a project with microservices architecture. And I created two microservices.</p>&#xA;&#xA;<p>One of them is for product entity, the other is for bill entity. They have their own endpoints and they are connected together with the gateway (i am using jhipster microservices architecture). </p>&#xA;&#xA;<p>The bill-ms should access to list of products. I'm wondering how I can communicate between those two ms. I have three approaches in my mind:</p>&#xA;&#xA;<ol>&#xA;<li><p>Send a request from bill-ms to queue - like rabbitMQ, to get these products with these ids from product-ms (I don't know what is bottleneck of this)</p></li>&#xA;<li><p>Send a request to gateway for product service and get the product from there (I'm worried about the latency because of the data size between them and in this way I'm not touching the database directly so I always depend on the gateway)</p></li>&#xA;<li><p>I can duplicate the repositories, services and entities in bill-ms (it's an ugly way, and I think it breaks the rule of ms-architecture and the maintenance is very difficult)</p></li>&#xA;</ol>&#xA;&#xA;<p>If you have any other approaches, I appreciate you to share it with me.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<ol>&#xA;<li>Now I know what the bottleneck is: say that there are 3 instance of bill-ms and how does rabbitMQ decide which instance to respond? or how should I say to ribbon ""<strong>give me the free instance of bill-ms to subscribe to the request from rabbitMQ</strong>"" for load balancing.</li>&#xA;</ol>&#xA;"
37180375,Using Zuul as an authentication gateway,2016-05-12 07:42:05,<spring-boot><spring-cloud><microservices><gateway><netflix-zuul>,3,14024,3,14.0,18,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I want to implement the design presented in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""noreferrer"">article</a>.</p>&#xA;&#xA;<p>It can be summarised by the diagram below:&#xA;<a href=""https://i.stack.imgur.com/viaL4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viaL4.png"" alt=""Security Architecture""></a></p>&#xA;&#xA;<ol>&#xA;<li>The client first authenticate with the IDP (OpenID Connect/OAuth2)</li>&#xA;<li>The IDP returns an access token (opaque token with no user info)</li>&#xA;<li>The client makes a call through the API gateway use the access token in the Authorization header</li>&#xA;<li>The API gateway makes a request to the IDP with the Access Token</li>&#xA;<li>The IDP verifies that the Access Token is valid and returns user information in JSON format</li>&#xA;<li>The API Gateway store the user information in a JWT and sign it with a private key. The JWT is then passed to the downstream service which verifies the JWT using the public key</li>&#xA;<li>If a service must call another service to fulfil the request it passes the JWT along which serves as authentication and authorisation for the request</li>&#xA;</ol>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have most of that done using:</p>&#xA;&#xA;<ul>&#xA;<li>Spring cloud as a global framework</li>&#xA;<li>Spring boot to launch individual services</li>&#xA;<li>Netflix Zuul as the API gateway</li>&#xA;</ul>&#xA;&#xA;<p>I have also written a Zuul PRE filter that checks for an Access Token, contacts the IDP and create a JWT. The JWT is then added to the header for the request forwarded to the downstream service.</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>Now my question is quite specific to Zuul and its filters. If authentication fails in the API gateway for any reason, how can I can stop the routing and respond directly with a 401 without continuing the filter chain and forwarding the call?</p>&#xA;&#xA;<p>At the moment if authentication fails the filter won't add the JWT to the header and the 401 will come from the downstream service. I was hoping my gateway could prevent this unnecessary call.</p>&#xA;&#xA;<p>I tried to see how I could use <code>com.netflix.zuul.context.RequestContext</code>to do this but the documentation is quite poor and I couldn't find a way. </p>&#xA;"
47793065,Angular and Micro-Frontends,2017-12-13 12:29:00,<javascript><html><angular><microservices>,6,3468,5,14.0,36,"<p>I am doing some research on how to split a huge single-page-monolith into a micro-frontend architecture.</p>&#xA;&#xA;<h1>The idea:</h1>&#xA;&#xA;<ul>&#xA;<li>the page consists of several components which would be running autonomously</li>&#xA;<li>each component is managed by one dev-team</li>&#xA;<li>each team can change, update and deploy their components without breaking components of other teams</li>&#xA;<li>each team chooses its own toolstack</li>&#xA;</ul>&#xA;&#xA;<h1>The reason</h1>&#xA;&#xA;<p>To efficiently develop large applications you need to have many people working on it. However the number of developers per app/team does not scale well. Parallel development of multiple independent apps by independent teams however can be scaled arbitrarily</p>&#xA;&#xA;<p>With this in mind it is imperative that teams can choose their own toolstack and especially perform independent version-upgrades of third party-libraries (like angular, react, jquery). If this was not the case a framework-update would need to be compatible with every single component before you could deploy it to production.</p>&#xA;&#xA;<h1>Does this work with Angular?</h1>&#xA;&#xA;<p>While independent version-upgrades are necessary, it would be reasonable to restrict the teams to a few supported frameworks (Angular, React, Vue, Polymer...) and for now I try to build a demo purely consisting of Angular-Apps.</p>&#xA;&#xA;<p>However even though Angular 5 is supposedly a platform-framework which supports huge multi-module apps, it seems to be almost impossible to have several independent angular-apps running in the same browser window.</p>&#xA;&#xA;<p>I managed to bootstrap several Angular-Apps (different versions, each hosted on its own server) on a single webapp by utilizing HTML-Imports. However there are several <code>global</code> dependencies which need to be shared between apps</p>&#xA;&#xA;<ul>&#xA;<li>zone.js can only be started once</li>&#xA;<li>routing requires url-changes</li>&#xA;<li>Browser-stuff like cookies, sessionstorage, etc...</li>&#xA;</ul>&#xA;&#xA;<p>There are several articles in the net on how to bootstrap multiple angular-modules but they all refer to multiple modules in the same core-app, which in turn means they all are running on the same framework-version and an update means you have to rebuild and deploy the whole monolith.</p>&#xA;&#xA;<p><strong>Is there any solution other than ""<code>iframes</code>"" to get multiple Angular (5) Apps running on the same Page?</strong></p>&#xA;"
30173267,Microservice Architecture- cross-domain chattiness,2015-05-11 16:48:08,<architecture><soa><microservices>,3,808,6,3.0,6,"<p>I have a relatively new project that employs a microservice architecture. I feel pretty good about the size and granularity of the individual services, with the exception or our security service.</p>&#xA;&#xA;<p>I have three main services, let's say <code>foo-service</code>, <code>bar-service</code>, and <code>baz-service</code>. These services never need to communicate, but all three services regularly talk via HTTP requests to the <code>security-service</code>. I want this to stop for a variety of reasons- the biggest is that each request to my individual services spawns a request to the security service, which can turn into several extra hops once you account for load balancing, etc. I've been reading ""Software Architecture Patterns"" by Mark Richards, and he recommends in these instances you should share databases and violate DRY: copy the required functionality into each service. Still, he uses this example with smaller ""utility"" classes, which may not really apply in this instance. </p>&#xA;&#xA;<p>The security service isn't that big, so I could definitely copy it into each of the other services. That said, it's just big enough that I don't feel great copying and pasting it - 314 'relevant' lines of code according to coveralls (java so there's a lot more actual code ;-). I could easily turn it into a module that each service brings in- but then my services have a shared dependency and that has bit me in the past. Of course the security code will grow over time as we add authentication methods, but we aren't reinventing the wheel when it comes to auth so It's mostly integrating with other libraries and authentication services. That is, I don't imagine this particular code base getting huge.</p>&#xA;&#xA;<p>So my question, should I copy and paste the code or build a module that every service brings in? Thanks!</p>&#xA;"
36137802,An event store could become a single point of failure?,2016-03-21 17:25:54,<cqrs><microservices><event-sourcing><get-event-store>,4,2355,4,3.0,7,"<p>Since a couple of days I've been trying to figure it out how to inform to the rest of the microservices that a new entity was created in a microservice A that store that entity in a MongoDB.</p>&#xA;&#xA;<p>I want to:</p>&#xA;&#xA;<ul>&#xA;<li><p>Have low coupling between the microservices</p></li>&#xA;<li><p>Avoid distributed transactions between microservices like Two Phase Commit (2PC)</p></li>&#xA;</ul>&#xA;&#xA;<p>At first a message broker like RabbitMQ seems to be a good tool for the job but then I see the problem of <strong>commit</strong> the new document in MongoDB and <strong>publish</strong> the message in the broker not being atomic.</p>&#xA;&#xA;<p><a href=""http://eventuate.io/whyeventsourcing.html"" rel=""nofollow noreferrer"">Why event sourcing?</a> by eventuate.io:&#xA;<a href=""https://i.stack.imgur.com/xovbk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xovbk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>One way of solving this issue implies make the schema of the documents a bit dirtier by adding a mark that says if the document have been published in the broker and having a scheduled background process that search unpublished documents in MongoDB and publishes those to the broker using <a href=""https://www.rabbitmq.com/confirms.html"" rel=""nofollow noreferrer"">confirmations</a>, when the confirmation arrives the document will be marked as published (using at-least-once and idempotency semantics). This solutions is proposed in <a href=""https://stackoverflow.com/a/13490358/3517383"">this</a> and <a href=""https://stackoverflow.com/a/17812090/3517383"">this</a> answers.</p>&#xA;&#xA;<p>Reading an <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">Introduction to Microservices</a> by Chris Richardson I ended up in this great presentation of <a href=""http://www.slideshare.net/chris.e.richardson/developing-functional-domain-models-with-event-sourcing-sbtb-sbtb2015"" rel=""nofollow noreferrer"">Developing functional domain models with event sourcing</a> where one of the slides asked:</p>&#xA;&#xA;<blockquote>&#xA;  <p>How to <strong>atomically</strong> update the database <strong>and</strong> publish events and publish events without 2PC? (dual write problem).</p>&#xA;</blockquote>&#xA;&#xA;<p>The answer is simple (on the next slide)</p>&#xA;&#xA;<blockquote>&#xA;  <p><strike>Update the database <strong>and</strong></strike> publish events</p>&#xA;</blockquote>&#xA;&#xA;<p>This is a different approach to <a href=""https://stackoverflow.com/q/13488982/3517383"">this one</a> that is based on <a href=""https://github.com/MarkNijhof/Cre8iveThought/blob/master/blog/articles/2009-11-12-cqrs--la-greg-young.txt"" rel=""nofollow noreferrer"">CQRS a la Greg Young</a>.</p>&#xA;&#xA;<blockquote>&#xA;  <p>The domain repository is responsible for publishing the events, this&#xA;  would normally be inside a single transaction together with storing&#xA;  the events in the event store.</p>&#xA;</blockquote>&#xA;&#xA;<p>I think that delegate the responsabilities of storing and publishing the events to the event store is a good thing because avoids the need of 2PC or a background process.</p>&#xA;&#xA;<p>However, in a certain way it's true <a href=""https://stackoverflow.com/a/12678477/3517383"">that</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If you rely on the event store to publish the events you'd have a&#xA;  tight coupling to the storage mechanism.</p>&#xA;</blockquote>&#xA;&#xA;<p>But we could say the same if we adopt a message broker for intecommunicate the microservices.</p>&#xA;&#xA;<p>The thing that worries me more is that the Event Store seems to become a Single Point of Failure.</p>&#xA;&#xA;<p>If we look this <a href=""https://github.com/cer/event-sourcing-examples"" rel=""nofollow noreferrer"">example</a> from <a href=""http://eventuate.io"" rel=""nofollow noreferrer"">eventuate.io</a>&#xA;<a href=""https://i.stack.imgur.com/52rMK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/52rMK.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>we can see that if the event store is down, we can't create accounts or money transfers, losing one of the advantages of microservices. (although the system will continue responding querys).</p>&#xA;&#xA;<p>So, it's correct to affirmate that the Event Store as used in the eventuate example is a Single Point of Failure?</p>&#xA;"
30648096,centralized API documentation for microservices,2015-06-04 15:30:59,<api><documentation><microservices>,3,3386,5,2.0,8,"<p>My team and I are currently building multiple services in parallel. We have the benefit of building all the services from scratch. I would like the ability to automatically display all API endpoints, from all services, in one page/site.  This would be helpful because (among other things):</p>&#xA;&#xA;<ol>&#xA;<li><p>I don't have to go to multiple documentation sites to see what are the available endpoints in my entire ""system"". </p></li>&#xA;<li><p>It'll be a good first step to determine if any of the services should be split, combined or simply refactored.  </p></li>&#xA;</ol>&#xA;&#xA;<p>Some of our services are in Django and the <a href=""http://swagger.io/"" rel=""noreferrer"">rest-swagger</a> module is a great help. But I don't see how I can combine rest-swagger documentation from multiple services into a single documentation page/site.</p>&#xA;&#xA;<p>I'm currently looking through <a href=""http://microservices.io/index.html"" rel=""noreferrer"">this site</a> and anything related to the <a href=""http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/"" rel=""noreferrer"">Netflix experience</a> but could not find a solution to my problem. Maybe centralized documentation isn't a big deal with 600+ services at Netflix, but that's hard to believe.</p>&#xA;&#xA;<p>Can anyone suggest a tool or method to have a combined API documentation for all services in a microservice architecture? </p>&#xA;&#xA;<p>My ideal scenario of what happens when a service is changed: </p>&#xA;&#xA;<ol>&#xA;<li>I click on the link to see the list of endpoints in my system.</li>&#xA;<li>A teammate updates a service and also it's documentation.</li>&#xA;<li>I refresh the page I am currently and I see that change made from step #2.</li>&#xA;</ol>&#xA;"
36157778,Accessing stateless service via ServiceProxy fails + ASP.NET 5 Web API project throws Health State error,2016-03-22 14:55:29,<c#><asp.net><.net><microservices><azure-service-fabric>,6,5965,4,3.0,8,"<p>I'm new to microsoft azure service fabric. For my master's degree I have to develop a microservice-approach prototype in service fabric. After hours of researching I am still not getting my issue(s) solved.</p>&#xA;&#xA;<p>I want to access my (in a local fabric cluster deployed) stateless service in a web front-end like in <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/"" rel=""noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/</a>. The simplest way for doing that is by adding an ASP .NET 5 Web Api project to the Service Fabric application and make a <code>ServiceProxy</code> method call in the <code>ValuesController</code>. So I added this code to my solution:</p>&#xA;&#xA;<p><strong>ValuesController.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>[Route(""api/[controller]"")]&#xA;public class ValuesController : Controller&#xA;{&#xA;  // GET api/values/IObject&#xA;  [HttpGet(""{interfaceName}"")]&#xA;  public async Task&lt;string&gt; Get(string interfaceName)&#xA;  {&#xA;    var serviceName = ""fabric:/DataServiceFabric/MasterDataMService"";&#xA;    var masterDataService = ServiceProxy.Create&lt;IMasterDataMService&gt;(new Uri(serviceName));&#xA;    var result = await masterDataService.GetMasterDataByName(interfaceName);&#xA;    return result.Content;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After a F5-deploy my browser doesn't automatically navigate to my web front-end. By looking into the Service Fabric Explorer my ASP .NET 5 application throws a Health State error:</p>&#xA;&#xA;<pre><code>Kind        Health State  Description&#xA;=============================================================================&#xA;Partitions  Error         Unhealthy partitions: 100% (1/1), MaxPercentUnhealthyPartitionsPerService=0%.&#xA;Partition   Error         Unhealthy partition: PartitionId='413...', AggregatedHealthState='Error'.&#xA;Event       Error         Error event: SourceId='System.FM', Property='State'. Partition is below target replica or instance count.&#xA;</code></pre>&#xA;&#xA;<p>After this <a href=""https://stackoverflow.com/questions/34892366/partition-is-below-target-replica-or-instance-count-error-after-deploying-serv"">this</a> question the <em>""Partition is below target replica or instance count""</em> indicates that a unhandled exception in my service is preventing it from starting. But I'm not able to find a stack strace in my Service Fabric Explorer to debug this failure. This is my <code>ServiceManifest.xml</code> of my ASP .NET web service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (Web1):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Name=""Web1"" Version=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;ServiceTypes&gt;&#xA;      &lt;StatelessServiceType ServiceTypeName=""Web1Type""&gt;&#xA;         &lt;Extensions&gt;&#xA;            &lt;Extension Name=""__GeneratedServiceType__""&gt;&#xA;               &lt;GeneratedNames xmlns=""http://schemas.microsoft.com/2015/03/fabact-no-schema""&gt;&#xA;                  &lt;DefaultService Name=""Web1Service"" /&gt;&#xA;                  &lt;ServiceEndpoint Name=""Web1TypeEndpoint"" /&gt;&#xA;               &lt;/GeneratedNames&gt;&#xA;            &lt;/Extension&gt;&#xA;         &lt;/Extensions&gt;&#xA;      &lt;/StatelessServiceType&gt;&#xA;   &lt;/ServiceTypes&gt;&#xA;   &lt;CodePackage Name=""C"" Version=""1.0.0""&gt;&#xA;      &lt;EntryPoint&gt;&#xA;         &lt;ExeHost&gt;&#xA;            &lt;Program&gt;approot\runtimes\dnx-clr-win-x64.1.0.0-rc1-update1\bin\dnx.exe&lt;/Program&gt;&#xA;            &lt;Arguments&gt;--appbase approot\src\Web1 Microsoft.Dnx.ApplicationHost Microsoft.ServiceFabric.AspNet.Hosting --server Microsoft.AspNet.Server.WebListener&lt;/Arguments&gt;&#xA;            &lt;WorkingFolder&gt;CodePackage&lt;/WorkingFolder&gt;&#xA;            &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048"" /&gt;&#xA;         &lt;/ExeHost&gt;&#xA;      &lt;/EntryPoint&gt;&#xA;   &lt;/CodePackage&gt;&#xA;   &lt;Resources&gt;&#xA;      &lt;Endpoints&gt;&#xA;         &lt;Endpoint Name=""Web1TypeEndpoint"" Protocol=""http"" Type=""Input"" Port=""80"" /&gt;&#xA;      &lt;/Endpoints&gt;&#xA;   &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>And here my <code>ApplicationManifest.xml</code> of my service fabric solution:</p>&#xA;&#xA;<p><strong>ApplicationManifest.xml:</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ApplicationManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" ApplicationTypeName=""DataServiceFabricType"" ApplicationTypeVersion=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;Parameters&gt;&#xA;      &lt;Parameter Name=""ActorTestServiceActorService_PartitionCount"" DefaultValue=""10"" /&gt;&#xA;      &lt;Parameter Name=""MasterDataMService_InstanceCount"" DefaultValue=""-1"" /&gt;&#xA;   &lt;/Parameters&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;     &lt;ServiceManifestRef ServiceManifestName=""Web2Pkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;     &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""Web1"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""ActorTestServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""MasterDataMServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;      &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;DefaultServices&gt;&#xA;      &lt;Service Name=""Web1Service""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""Web1Type""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""ActorTestServiceActorService"" GeneratedIdRef=""761ee3cf-5a3a-49d8-9c57-aa3480d1acf1""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""ActorTestServiceActorServiceType""&gt;&#xA;            &lt;UniformInt64Partition PartitionCount=""[ActorTestServiceActorService_PartitionCount]"" LowKey=""-9223372036854775808"" HighKey=""9223372036854775807"" /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""MasterDataMService""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""MasterDataMServiceType"" InstanceCount=""[MasterDataMService_InstanceCount]""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;   &lt;/DefaultServices&gt;&#xA;&lt;/ApplicationManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>So I created a new solution with an ASP.NET 5 web application and the same <code>ValuesController.cs</code>. I ensured my stateless service is running on my local cluster and than I started my new web application. After calling the GET-Method in my Controller I got the following exception:</p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 0,2593ms 500&#xA;Microsoft.AspNet.Server.Kestrel: Error: An unhandled exception was thrown by the application.&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1}&#xA;</code></pre>&#xA;&#xA;<p>My stateless service is a SingletonPartition, so do I need a partition key here? And if yes, how do I get the key? The Service Fabric Explorer doesn't provide me with this information for my stateless service. Here is the <code>ServiceManifest.xml</code> of my stateless service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (MasterDataMService):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest Name=""MasterDataMServicePkg""&#xA;                 Version=""1.0.0""&#xA;                 xmlns=""http://schemas.microsoft.com/2011/01/fabric""&#xA;                 xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&#xA;                 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;&#xA;  &lt;ServiceTypes&gt;&#xA;    &lt;!-- This is the name of your ServiceType. &#xA;         This name must match the string used in RegisterServiceType call in Program.cs. --&gt;&#xA;    &lt;StatelessServiceType ServiceTypeName=""MasterDataMServiceType"" /&gt;&#xA;  &lt;/ServiceTypes&gt;&#xA;&#xA;  &lt;!-- Code package is your service executable. --&gt;&#xA;  &lt;CodePackage Name=""Code"" Version=""1.0.0""&gt;&#xA;    &lt;EntryPoint&gt;&#xA;      &lt;ExeHost&gt;&#xA;        &lt;Program&gt;MasterDataMService.exe&lt;/Program&gt;&#xA;      &lt;/ExeHost&gt;&#xA;    &lt;/EntryPoint&gt;&#xA;  &lt;/CodePackage&gt;&#xA;&#xA;  &lt;!-- Config package is the contents of the Config directoy under PackageRoot that contains an &#xA;       independently-updateable and versioned set of custom configuration settings for your service. --&gt;&#xA;  &lt;ConfigPackage Name=""Config"" Version=""1.0.0"" /&gt;&#xA;&#xA;  &lt;Resources&gt;&#xA;    &lt;Endpoints&gt;&#xA;      &lt;!-- This endpoint is used by the communication listener to obtain the port on which to &#xA;           listen. Please note that if your service is partitioned, this port is shared with &#xA;           replicas of different partitions that are placed in your code. --&gt;&#xA;      &lt;Endpoint Name=""ServiceEndpoint"" Type=""Input"" Protocol=""http"" Port=""80""/&gt;&#xA;    &lt;/Endpoints&gt;&#xA;  &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that I decided to set up a service communication with OWIN:</p>&#xA;&#xA;<p><strong>MasterDataMService.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>internal sealed class MasterDataMService : StatelessService, IMasterDataMService&#xA;{&#xA;  [...]      &#xA;&#xA;  protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;  {&#xA;    return new[]&#xA;    {&#xA;      new ServiceInstanceListener(initParams =&gt; new OwinCommunicationListener(""MasterDataMService"", new StartUp(), initParams))&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I can acess my microservice by using a <code>HttpClient</code> in my <code>DefaultController</code>:</p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>var client = new HttpClient();&#xA;var request = ""http://localhost:80/MasterDataMService/api/values/query"";&#xA;var result = string.Empty;&#xA;HttpResponseMessage response = await client.GetAsync(request);&#xA;if (response.IsSuccessStatusCode)&#xA;{&#xA;  result = await response.Content.ReadAsStringAsync();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But thats not what I originally wanted. I don't want to specifiy the service endpoint in my request. Instead I would like to communicate with my stateless service over a <code>ServiceProxy</code>. How do I achieve that here? What did I wrong? And how can I solve this Health State error with my ASP .NET 5 application which is deployed into my service fabric cluster?</p>&#xA;&#xA;<p>Thanks for your time.</p>&#xA;&#xA;<p><strong>Edit:</strong></p>&#xA;&#xA;<p><em>Extended stacktrace of invalid partition key exception:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,35ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1} ---&gt; System.Runtime.InteropServices.COMException: exception of HRESULT: 0x80071BBF&#xA;   at System.Fabric.Interop.NativeClient.IFabricServiceManagementClient4.EndResolveServicePartition(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.FabricClient.ServiceManagementClient.ResolveServicePartitionEndWrapper(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.Interop.AsyncCallOutAdapter2`1.Finish(IFabricAsyncOperationContext context, Boolean expectedCompletedSynchronously)&#xA;   --- End of inner exception stack trace ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Client.ServicePartitionResolver.&lt;ResolveAsyncHelper&gt;d__2a.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;GetClientAsync&gt;d__a.MoveNext()&#xA;</code></pre>&#xA;&#xA;<p>Please give me feedback if you need more. (full stack trace is 82 lines long)</p>&#xA;&#xA;<p><em>Invalid scheme exception stack trace:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.ArgumentException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,45ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.ArgumentException: the provided uri scheme 'http' is invalid; expected 'net.tcp'.&#xA;Parametername: via&#xA;   at System.ServiceModel.Channels.TransportChannelFactory`1.ValidateScheme(Uri via)&#xA;   at System.ServiceModel.Channels.ConnectionOrientedTransportChannelFactory`1.OnCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ChannelFactoryBase`1.InternalCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.ServiceChannelFactoryOverDuplexSession.CreateInnerChannelBinder(EndpointAddress to, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateServiceChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateChannel(Type channelType, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, Binding binding, EndpointAddress endpointAddress)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Wcf.Client.WcfCommunicationClientFactory`1.&lt;CreateClientAsync&gt;d__2.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;CreateClientWithRetriesAsync&gt;d__1e.MoveNext()&#xA;</code></pre>&#xA;"
36461493,Customizing Zuul Exception,2016-04-06 20:17:50,<java><spring-boot><spring-cloud><microservices><netflix-zuul>,4,9134,5,6.0,10,"<p>I have a scenario in Zuul where the service that the URL is routed too might be down . So the reponse body gets thrown with 500 HTTP Status and ZuulException in the JSON body response.</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": 1459973637928,&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""com.netflix.zuul.exception.ZuulException"",&#xA;  ""message"": ""Forwarding error""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>All I want to do is to customise or remove the JSON response and maybe change the HTTP status Code.</p>&#xA;&#xA;<p>I tried to create a exception Handler with @ControllerAdvice but the exception is not grabbed by the handler.</p>&#xA;&#xA;<p><strong>UPDATES:</strong></p>&#xA;&#xA;<p>So I extended the Zuul Filter I can see it getting into the run method after the error has been executed how do i change the response then. Below is what i got so far. I read somewhere about SendErrorFilter but how do i implement that and what does it do?</p>&#xA;&#xA;<pre><code>public class CustomFilter extends ZuulFilter {&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        return ""post"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;&#xA;        return 1;&#xA;    }&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        return true;&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;        final RequestContext ctx = RequestContext.getCurrentContext();&#xA;        final HttpServletResponse response = ctx.getResponse();&#xA;        if (HttpStatus.INTERNAL_SERVER_ERROR.value() == ctx.getResponse().getStatus()) {&#xA;            try {&#xA;                response.sendError(404, ""Error Error""); //trying to change the response will need to throw a JSON body.&#xA;            } catch (final IOException e) {&#xA;                e.printStackTrace();&#xA;            } ;&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added this to the class that has @EnableZuulProxy</p>&#xA;&#xA;<pre><code>@Bean&#xA;public CustomFilter customFilter() {&#xA;    return new CustomFilter();&#xA;}&#xA;</code></pre>&#xA;"
