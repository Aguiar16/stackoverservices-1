Id,Title,CreationDate,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
27054162,"what are REST,RESTFul, SOA and microservices in simple terms?",2014-11-21 04:31:46,<rest><soa><microservices>,2,19619,3,11.0,23,"<p>I thought I knew what REST/""RESTFul"", restfulservices, webservices, SOA and microservices were but I came across so many different definitions that I reached the conclusion that those terms are overused, misused , or simply badly defined.</p>&#xA;&#xA;<p>I hope to have a clear understanding of what the aforementioned terms represent, their concrete definition , their commonality and differences, advantages vs disadvantages, and most importantly the bottom line - the most important things to remember in order to use those terms appropriately. </p>&#xA;"
27007353,How does data denormalization work with the Microservice Pattern?,2014-11-19 01:25:07,<database><denormalization><microservices>,4,6219,4,21.0,62,"<p>I just read an article on <a href=""http://java.dzone.com/articles/microservices-and-paas-part-2"">Microservices and PaaS Architecture</a>. In that article, about a third of the way down, the author states (under <strong>Denormalize like Crazy</strong>):</p>&#xA;&#xA;<blockquote>&#xA;  <p>Refactor database schemas, and de-normalize everything, to allow complete separation and partitioning of data. That is, do not use underlying tables that serve multiple microservices. There should be no sharing of underlying tables that span multiple microservices, and no sharing of data. Instead, if several services need access to the same data, it should be shared via a service API (such as a published REST or a message service interface).</p>&#xA;</blockquote>&#xA;&#xA;<p>While this <em>sounds</em> great in theory, in practicality it has some serious hurdles to overcome. The biggest of which is that, often, databases are tightly coupled and every table has <em>some</em> foreign key relationship with at least one other table. Because of this it could be impossible to partition a database into <em>n</em> sub-databases controlled by <em>n</em> microservices.</p>&#xA;&#xA;<p>So I ask: <strong>Given a database that consists entirely of related tables, how does one denormalize this into smaller fragments (groups of tables) so that the fragments can be controlled by separate microservices?</strong></p>&#xA;&#xA;<p>For instance, given the following (rather small, but exemplar) database:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;user_id&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;product_id&#xA;order_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p>Don't spend too much time critiquing my design, I did this on the fly. The point is that, to me, it makes logical sense to split this database into 3 microservices:</p>&#xA;&#xA;<ol>&#xA;<li><code>UserService</code> - for CRUDding users in the system; should ultimately manage the <code>[users]</code> table; and</li>&#xA;<li><code>ProductService</code> - for CRUDding products in the system; should ultimately manage the <code>[products]</code> table; and</li>&#xA;<li><code>OrderService</code> - for CRUDding orders in the system; should ultimately manage the <code>[orders]</code> and <code>[products_x_orders]</code> tables</li>&#xA;</ol>&#xA;&#xA;<p>However all of these tables have foreign key relationships with each other. If we denormalize them and treat them as monoliths, they lose all their semantic meaning:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p><strong>Now there's no way to know who ordered what, in which quantity, or when.</strong></p>&#xA;&#xA;<p>So is this article typical academic hullabaloo, or is there a real world practicality to this denormalization approach, and if so, what does it look like (bonus points for using my example in the answer)?</p>&#xA;"
22513893,Microservices and SOA using messaging,2014-03-19 17:39:26,<architecture><messaging><soa><microservices>,5,5075,0,8.0,21,"<p>I've been very interested in trying out microservices/SOA as an architecture and am having a hard time conceptualizing how the integration between services would actually be done.</p>&#xA;&#xA;<p>I like the idea of using messaging to decouple the clients from the services, but don't understand how a system could utilize it exclusively. The typical async operations and pub/sub stuff obviously makes sense - scenarios like creating a new order, broadcasting data for reporting, etc. What I don't understand is whether people typically try to use messaging for common request/reply scenarios - for example, a user hits their ""profile"" page and part of the data that needs to get rendered on the page is from a user service.</p>&#xA;&#xA;<p>I know common messaging implementations provide REST-like reply/request functionality but is that often used for simple data requests? It seems more likely that microservices would both expose REST endpoints and also register with a message broker for different types of communication it will participate in, but all these presentations I watch of SOA and microservice architecture seem to suggest they only use one or the other..</p>&#xA;&#xA;<p>Thanks for any elaboration/experiences!</p>&#xA;"
28942614,Should I use forever/pm2 within a (Docker) container?,2015-03-09 13:00:16,<node.js><docker><coreos><microservices>,2,10713,0,13.0,37,"<p>I am refactoring a couple of node.js services. All of them used to start with <code>forever</code> on virtual servers, if the process crashed they just relaunch.</p>&#xA;&#xA;<p>Now, moving to containerised and state-less application structures, I think the process should exit and the container should be restarted on a failure.</p>&#xA;&#xA;<p>Is that correct? Are there benefits or disadvantages?</p>&#xA;"
25600580,Sharing code and schema between microservices,2014-09-01 07:13:19,<architecture><microservices>,4,8717,1,9.0,40,"<p>If you go for a <strong>microservices architecture</strong> in your organization, they can share configuration via <a href=""http://zookeeper.apache.org/"">zookeeper</a> or its equivalent. However, how should the various services share a common db schema? common constants? and common utilities?</p>&#xA;&#xA;<p>One way would be to place all the microservices in the same code repository, but that would contradict the decoupling that comes with microservices...</p>&#xA;&#xA;<p>Another way would be to have each microservice be completely independent, however that would cause code duplication and data duplication in the separate databases each microservice would have to hold.</p>&#xA;&#xA;<p>Yet another way would be to implement functional microservices with no context\state, but that's usually not realistic and would push the architecture to having a central hub that maintains the context\state and a lot of traffic from\to it.</p>&#xA;&#xA;<p><strong>What would be a scalable, efficient practical and hopefully beautiful way to share code and schema between microservices?</strong> </p>&#xA;"
25595492,Single Sign-On in Microservice Architecture,2014-08-31 19:26:54,<security><cloud><single-sign-on><microservices><paas>,2,13805,3,22.0,37,<p>I'm trying to design a green-field project that will have several services (serving data) and web-applications (serving HTML). I've read about microservices and they look like good fit.</p>&#xA;&#xA;<p>The problem I still have is how to implement SSO. I want the user to authenticate once and have access to all the different services and applications.</p>&#xA;&#xA;<p>I can think of several approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p>Add Identity service and application. Any service that has protected resources will talk to the Identity service to make sure the credentials it has are valid. If they are not it will redirect the user for authentication.</p></li>&#xA;<li><p>Use a web-standard such as OpenID and have each service handle it own identities. This means the user will have to authorize individually each service/application but after that it will be SSO.</p></li>&#xA;</ol>&#xA;&#xA;<p>I'll be happy to hear other ideas. If a specific PaaS (such as Heroku) has a proprietary solution that would also be acceptable.</p>&#xA;
26331854,Micro services and .NET,2014-10-13 01:45:35,<.net><microservices>,5,43797,1,7.0,25,"<p>How to build micro service oriented application in .NET world? Are there any platforms where we can write micro service oriented apps in .NET world? How to envision architecture that includes Micro services, Event store and some of NoSQL databases?&#xA;Thanks.</p>&#xA;"
30422184,Where does Elixir/erlang fit into the microservices approach?,2015-05-24 09:54:33,<architecture><erlang><docker><elixir><microservices>,1,8742,7,26.0,88,"<p>Lately I've been doing some experiments with docker compose in order to deploy multiple collaborating microservices. I can see the many benefits that microservices provide, and now that there is a good toolset for managing them, I think that it's not extremely hard to jump into the microservices wagon.</p>&#xA;&#xA;<p>But, I have been experimenting with Elixir too, and I am quite fond of the benefits that provides by itself. Given that it encourages packing your code into multiple decoupled applications, and supports hot code upgrades, how would you mix docker with elixir (or erlang, for that matter)?</p>&#xA;&#xA;<p>For example, if I want to use docker because it provides dev-prod parity, how does elixir fit in that? Given that docker containers are immutable, I lose the ability to do hot-code upgrades, right? What about blue/green deployments or canary releases?</p>&#xA;&#xA;<p>I mean, I could just write microservices with Elixir and use them as if they were written in any other language, polyglotism is one of the benefits of microservices anyway, but then I'm not getting the full benefits of using the OTP platform, I guess that pure collaborative erlang applications are way more optimal that using intermediate queues to communicate between microservices written in different (or not) languages.</p>&#xA;"
31342583,How to manage/balance semi persistent jobs over service instances,2015-07-10 13:54:10,<php><load-balancing><apache-zookeeper><microservices>,3,261,0,4.0,17,"<p>I see a common pattern for services that we try to develop and I wonder if there are tools / libraries out there that would help here. While the default jobs as discussed in microservice literature is from the REQUEST -> RESPONSE nature, our jobs are more or less assignments of semi permanent tasks.</p>&#xA;&#xA;<p>Examples of such tasks</p>&#xA;&#xA;<ul>&#xA;<li>Listen on the message queue for data from source X and Y, correlate the data that comes in and store it in Z.</li>&#xA;<li>Keep an in-memory buffer that calculates a running average of the past 15 mins of data everytime a new data entry comes in.</li>&#xA;</ul>&#xA;&#xA;<p>Currently our services are written in PHP. Due to the perceived overhead of PHP processes and connections to the message queue we'd like a single service process to handle multiple of those jobs simultanously.</p>&#xA;&#xA;<p>A chart that hopefully illustrated the setup that we have in our head:&#xA;<img src=""https://i.stack.imgur.com/HHDls.png"" alt=""services_setup""></p>&#xA;&#xA;<ul>&#xA;<li>Service Workers are currently deamonized PHP scripts</li>&#xA;<li>For the Service Registry we are looking at Zookeeper</li>&#xA;</ul>&#xA;&#xA;<p>While Zookeeper (and Curator) do loadbalancing, I did not find anything around distributing permanent jobs (that are updatable, removable, and must be reassigned when a worker dies)</p>&#xA;&#xA;<p>Proposed responsibilities of a Job Manager</p>&#xA;&#xA;<ul>&#xA;<li>Knows about jobs</li>&#xA;<li>Knows about services that can do these jobs</li>&#xA;<li>Can assign jobs to services</li>&#xA;<li>Can send job updates to services</li>&#xA;<li>Can reassign jobs if a worker dies</li>&#xA;</ul>&#xA;&#xA;<p>Are there any libraries / tools that can tackle such problems, and can thus function as the Job Manager? Or is this all one big anti pattern and should we do it some other way?</p>&#xA;"
31313170,How to route in between microservices using Spring Cloud & Netflix OSS,2015-07-09 09:17:06,<spring-cloud><microservices><netflix-eureka><netflix-zuul><blue-green-deployment>,1,2730,2,16.0,17,"<p>During our development of microservices using Spring Cloud, we started out using Zuul as a proxy for any connection from the outside to microservices, and for any microservice needing to contact another microservice.</p>&#xA;&#xA;<p>After some time we made the conclusion that Zuul was designed to be an edge service (only proxying traffic from the outside to the microservices), and shouldn't be used for intermicroservices communication. Especially the way Spring Cloud recommends the use of eureka to make a direct (potentially load balanced) connection to another service made us go against having Zuul in between everything.</p>&#xA;&#xA;<p>Of course everything works nicely as expected (as it always does with Spring Cloud), but we are clueless on how to perform a certain use case with this setup.</p>&#xA;&#xA;<p>When deploying a new version of a microservice, we'd like to have a <a href=""http://martinfowler.com/bliki/BlueGreenDeployment.html"" rel=""noreferrer"">blue/green deployment</a> with the old and the new version.&#xA;However, having no Zuul in between the microservices, the communication between two separate services will continue to go to the old version until it is removed from eureka.</p>&#xA;&#xA;<p>We are thinking of how we can achieve this. In the picture below I have drawn what I think might be an option.</p>&#xA;&#xA;<p>In the first part of the picture, Zuul calls eureka to get the registry to create the routes. Also service 1 is calling eureka to get the registry to route to service 2. Since service 2 is in the eureka registry, the routing is done successfully.</p>&#xA;&#xA;<p>In the second part of the picture, an update of service 2 (service 2.1) is deployed. It registers with eureka as well, which makes service 1 now route to both service 2 and service 2.1. This is not wanted with the blue/green deployment.</p>&#xA;&#xA;<p>In the third part a potential solution to this issue is showcased with another instance of eureka being deployed just for this purpose. This instance isn't peer aware and won't sync with the first eureka instance. As opposed to the first instance, this one's only purpose is to facilitate the blue/green deployment. Service 2.1 registers with the second eureka instance, and service 1 his configuration is changed to fetch its registry not from the first but from the second eureka instance.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/V9lpR.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>The main question we are facing is whether this is a viable solution. Having the flexibility of Zuul to route is a big plus which we don't have in this scenario. Should we move back to routing every service-to-service call through Zuul or is there another solution (maybe ribbon configuration of some sort) more appropriate? Or is the second eureka instance the best solution for this type of deployments?</p>&#xA;&#xA;<p>Any feedback would be greatly appreciated.</p>&#xA;&#xA;<p>Kind regards,&#xA;Andreas</p>&#xA;"
29591967,"Microservice architecture, what is a service in this case",2015-04-12 16:52:49,<java><web-services><rest><microservices>,6,4110,1,3.0,9,"<p>I'm reading some documentation about the micro-services architecture (through  <a href=""http://microservices.io/patterns/microservices.html"" rel=""noreferrer"">this link for example</a>) and I was wondering what is exactly a service in this case.</p>&#xA;&#xA;<p>In IT, everything could be called a service:&#xA;- a SPRING REST application launched through the java command like:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java -jar build/libs/gs-rest-service-0.1.0.jar</p>&#xA;</blockquote>&#xA;&#xA;<ul>&#xA;<li>It could also be a classes corresponding to the business layer in a DDD </li>&#xA;<li>It could be simply something related to the domain studied, like providing something to somebody</li>&#xA;<li>and many others... (android background running services etc...)</li>&#xA;</ul>&#xA;&#xA;<p>But in microservices, what does it mean? And what kind of technologies / tools are used to create a ""service running by himself"" in the Java EE stack for example? It's only related to webservices?</p>&#xA;"
29460485,Microservices Architecture: Cross Service data sharing,2015-04-05 18:03:50,<web-services><architecture><microservices>,3,7356,2,17.0,22,"<p>Consider the following micro services for an online store project:<br>&#xA;Users Service keeps account data about the store's users (including first name, last name, email address, etc')</p>&#xA;&#xA;<p>Purchase Service keeps track of details about user's purchases.</p>&#xA;&#xA;<p>Each service provides a UI for viewing and managing it's relevant entities.&#xA;The Purchase Service index page lists purchases. Each purchase item should have the following fields:<br>&#xA;id, full name of purchasing user, purchased item title and price.<br>&#xA;Furthermore, as part of the index page, I'd like to have a search box to let the store manager search purchases by purchasing user name.</p>&#xA;&#xA;<p>It is not clear to me how to get back data which the Purchase Service does not hold - for example: a user's full name.&#xA;The problem gets worse when trying to do more complicated things like search purchases by purchasing user name.</p>&#xA;&#xA;<p>I figured that I can obviously solve this by syncing users between the two services by broadcasting some sort of event on user creation (and saving only the relevant user properties on the Purchase Service end). That's far from ideal in my perspective. How do you deal with this when you have millions of users? would you create millions of records in each service which consumes users data?</p>&#xA;&#xA;<p>Another obvious option is exposing an API at the Users Service end which brings back user details based on given ids. That means that every page load in the Purchase Service, I'll have to make a call to the Users Service in order to get the right user names. Not ideal, but I can live with it.</p>&#xA;&#xA;<p>What about implementing a purchase search based on user name? Well I can always expose another API endpoint at the Users Service end which receives the query term, perform a text search over user names in the Users Service, and then return all user details which match the criteria. At the Purchase Service, map the relevant ids back to the right names and show them in the page. This approach is not ideal either.</p>&#xA;&#xA;<p>Am I missing something? Is there another approach for implementing the above? Maybe the fact that I'm facing this issue is sort of a code smell? would love to hear other solutions.</p>&#xA;"
33399988,Microservices: datasource per instance or per microservice?,2015-10-28 19:31:53,<database><design><architecture><microservices>,5,2501,1,4.0,12,"<p>Building microservice architecture I faced the problem of data sharing between instances of the same microservice.</p>&#xA;&#xA;<p>I have microservice, that massively uses it's datasource - every request to service cause database request (usually insert). This service will be used very heavily and I plan to hide multiple instances behind Load Balancer. And here rises a question: shall these instances use ONE database (will the database be a bottleneck?) or MULTIPLE (datasource per instance) have?</p>&#xA;"
33465577,How to manage secrets in a Microservice / Container / Cloud environment?,2015-11-01 18:21:40,<git><docker><microservices><secret-key>,1,2735,4,8.0,16,"<p>Microservices and Cloud is a thing. Everyone is talking and writing about. Personally i am thinking a lot about this topics: How this can be used to benefit from? What are possible challenges? How can this speedup the daily development? And how to manage all things?&#xA;One question that bothers me since a few days is ""How to manage secrets in a Microservice / Cloud environment?"".</p>&#xA;&#xA;<p>Imagine a company with 150 software engineers and various teams with various products. Every team is creating a software and every service needs various amounts of secrets (API-Keys, Passwords, SSH-Keys, whatever).&#xA;The ""old fashion"" way was to create a few configuration files in a ini / yaml / txt format and read it from. 12Factor apps say: Do it per env vars.</p>&#xA;&#xA;<p>Env vars can be set per machine and the config files can be placed there as well.&#xA;This works if you got a hand full of machines and the deployment is done by a few system admins.&#xA;One of the general rules say: ""Don`t store secrets in a Git repo."".</p>&#xA;&#xA;<p>Now the new world comes in.&#xA;Ever team is responsible for the application they produce itself.&#xA;They should be deployed and run by the team.&#xA;So our company is moving to a container and self-service way (e.g. Mesos and Marathon or Kubernetes).</p>&#xA;&#xA;<p>Of course, Dockerfiles can set env vars as well. And yes, you can ADD your config file into the Docker container during build.&#xA;But with this everyone can access the secrets (e.g. from other teams). And no one knows who uses this secrets and do something dangerous.</p>&#xA;&#xA;<p>You want to versionize your Dockerfiles as well. And applications you want to run on Marathon should be versionized (Git or whatever) as well (and applied by REST API). So where to store and manage all the secrets for this containers / apps?&#xA;Because with scheduler frameworks like Swarm and Machine (for Docker), Mesos and Marathon (usable for Docker as well) or Kubernetes you don`t know where your app will be running. This will be scheduled over several machines.&#xA;And most of this tools have no authentification (by default, of course this can be added by a Nginx proxy or something).</p>&#xA;&#xA;<p>One idea to manage secrets is using a tool like <a href=""https://vaultproject.io/"">Vault</a>. But i never saw ""native"" support in an app. The same applies for <a href=""https://github.com/StackExchange/blackbox"">Blackbox</a>. And i don`t know how configuration management can solve this. I know that Chef supports encrypted databags, but afaik it is not possible to use Chef to setup/build Docker containers.</p>&#xA;&#xA;<p>How do you manage secrets in a multi team env with several engineers in a Microservice / Container / Cloud environment?</p>&#xA;"
28767707,How to deal with shared state in a micro-service architecture?,2015-02-27 14:44:20,<deployment><architecture><integration-testing><microservices><test-environments>,3,4043,8,13.0,17,"<p>In our company we are transitioning from a huge monolithic application to a micro-service architecture. The main technical drivers for this decision were the need to be able to scale services independently and the scalability of development - we've got ten scrum teams working in different projects (or 'micro-services').</p>&#xA;&#xA;<p>The transition process is being smooth and we've already started to benefit from the advantages of this new technical and organizational structures. Now, on the other hand, <strong>there is a main point of pain that we are struggling with: how to manage the 'state' of the dependencies between these micro-services</strong>. </p>&#xA;&#xA;<p>Let's put an example: one of the micro-services deals with users and registrations. This service (let's call it X) is responsible for maintaining identity information and thus is the main provider for user 'ids'. The rest of the micro-services have a strong dependency on this one. For example, there are some services responsible for user profile information (A), user permissions (B), user groups (C), etc. that rely on those user ids and thus there is a need for maintaining some data sync between these services (i.e. service A should not have info for a userId not registered in service X). We currently maintain this sync by notifying changes of state (new registrations, for example) using RabbitMQ. </p>&#xA;&#xA;<p>As you can imagine, there are <em>many</em> Xs: many 'main' services and many more complicated dependencies between them.</p>&#xA;&#xA;<p>The main issue comes when managing the different dev/testing environments. Every team (and thus, every service) needs to go through several environments in order to put some code live: continuous integration, team integration, acceptance test and live environments. </p>&#xA;&#xA;<p>Obviously we need all services working in all these environments to check that the system is working as a whole. Now, this means that in order to test dependent services (A, B, C, ...) we must not only rely on service X, but also on its state. <strong>Thus, we need somehow to maintain system integrity and store a global &amp; coherent state</strong>.</p>&#xA;&#xA;<p>Our current approach for this is getting snapshots of all DBs from the live environment, making some transformations to shrink and protect data privacy and propagating it to all environments before testing in a particular environment. This is obviously a tremendous overhead, both organizationally and in computational resources: we have ten continuous integration environments, ten integration environments and one acceptance test environment that all need to be 'refreshed' with this shared data from live and the latest version of the code frequently. </p>&#xA;&#xA;<p>We are struggling to find a better way to ease this pain. Currently we are evaluating two options: </p>&#xA;&#xA;<ol>&#xA;<li>using docker-like containers for all these services </li>&#xA;<li>having two versions of each service (one intended for development of that service and one another as a sandbox to be used by the rest of the teams in their development &amp; integration testing)</li>&#xA;</ol>&#xA;&#xA;<p><strong>None of these solutions ease the pain of shared data between services</strong>. We'd like to know how some other companies/developers are addressing this problem, as we think this must be common in a micro services architecture. </p>&#xA;&#xA;<p>How are you guys doing it? Do you also have this problem? Any recommendation?</p>&#xA;&#xA;<p>Sorry for the long explanation and thanks a lot!</p>&#xA;"
26616962,Microservices: What are smart endpoints and dumb pipes?,2014-10-28 19:33:01,<architecture><soa><messaging><distributed><microservices>,6,13620,0,7.0,15,"<p>I have read an article ""<a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""noreferrer"">Microservices</a>"" by Martin Fowler and find it difficult to understand <strong>smart endpoint</strong>s and <strong>dumb pipes</strong>. Please explain these terms, examples are welcome.</p>&#xA;"
30027545,Vert.x 3 and Microservices,2015-05-04 10:10:47,<architecture><vert.x><microservices>,3,2637,0,4.0,20,"<p>Microservices are gaining traction as an software architecture style that will better support continuous delivery, provide a model for rapid deployment and separation of concerns.</p>&#xA;&#xA;<p>Vert.x 3 and Vert.x-Apex provide an interesting model for building a microservices. As one of the examples shows, a simple verticle can expose an HTTP service, so a REST service is available. The verticle binds its own tcp port.</p>&#xA;&#xA;<p>When scaling up to multiple micro-services to support a full application you end up with a number of choices. Any thoughts on what style could eventually support continuous delivery, and minimizing downtime on upgrades?</p>&#xA;&#xA;<h2>Options</h2>&#xA;&#xA;<ol>&#xA;<li>Run multiple verticles could be a solution, all containing there own routing, so http handling is contained in the verticle. A request/response can be handled completely by the verticle. This could mean that every verticle runs on it's own tcp port. </li>&#xA;<li>Using a router you can expose all paths on a single port, and handle them accordingly. Data will be handled by the verticle that contains the router, possible passing it on to other verticles. This then starts to look like a more monolithic approach.</li>&#xA;<li>Run separate instances of vert.x containing the service (possible cluster them). This could make it easier use continuous delivery, because the whole thing is self-contained.</li>&#xA;<li>Other possible options?</li>&#xA;</ol>&#xA;&#xA;<h2>Deployment</h2>&#xA;&#xA;<p>On the deployment side rapid deployment of new services would be desirable, without bringing the whole application down. </p>&#xA;&#xA;<ul>&#xA;<li>Option 3. could provide a way for this, but can also cause overhead, especially when there is a DB verticle running in every verticle. </li>&#xA;<li>Option 1. could be easier, but what about reloading the new and updated verticles.</li>&#xA;</ul>&#xA;&#xA;<p>Separate micro-services offer an interesting way of development, but offers some challenges in orchestration and deployment.</p>&#xA;&#xA;<p>Any thoughts?</p>&#xA;"
29117570,Orchestrating microservices,2015-03-18 08:52:57,<http><orchestration><hypermedia><microservices>,7,41902,0,115.0,132,"<p>What is the standard pattern of orchestrating microservices?</p>&#xA;&#xA;<p>If a microservice only knows about its own domain, but there is a flow of data that requires that multiple services interact in some manner, what's the way to go about it?</p>&#xA;&#xA;<p>Let's say we have something like this:</p>&#xA;&#xA;<ul>&#xA;<li>Invoicing</li>&#xA;<li>Shipment</li>&#xA;</ul>&#xA;&#xA;<p>And for the sake of the argument, let's say that once an an order has been shipped, the invoice should be created. </p>&#xA;&#xA;<p>Somewhere, someone presses a button in a GUI, ""I'm done, let's do this!""&#xA;In a classic monolith service architecture, I'd say that there is either an ESB handling this, or the Shipment service has knowledge of the invoice service and just calls that.</p>&#xA;&#xA;<p>But what is the way people deal with this in this brave new world of microservices?</p>&#xA;&#xA;<p>I do get that this could be considered highly opinion-based. but there is a concrete side to it, as microservices are not supposed to do the above.&#xA;So there has to be a ""what should it by definition do instead"", which is not opinion-based.</p>&#xA;&#xA;<p>Shoot.</p>&#xA;"
35065875,How to bring a gRPC defined API to the web browser,2016-01-28 15:44:56,<javascript><node.js><protocol-buffers><microservices><grpc>,7,21905,0,25.0,49,"<p>We want to build a Javascript/HTML gui for our gRPC-microservices. Since gRPC is not supported on the browser side, we thought of using web-sockets to connect to a node.js server, which calls the target service via grpc. &#xA;We struggle to find an elegant solution to do this. Especially, since we use gRPC streams to push events between our micro-services.&#xA;It seems that we need a second RPC system, just to communicate between the front end and the node.js server. This seems to be a lot of overhead and additional code that must be maintained.</p>&#xA;&#xA;<p>Does anyone have experience doing something like this or has an idea how this could be solved?</p>&#xA;"
35113957,Running multiple projects using docker which each runs with docker-compose,2016-01-31 12:42:12,<docker><development-environment><docker-compose><microservices>,3,6126,0,5.0,12,"<p>We are using microservices approach to build our product. We are using some projects which each uses docker-compose to run. The problem is that in development environment, if we want to change codes in multiple projects and test developed codes, we must run projects separately and link them together manually.</p>&#xA;&#xA;<p>Now we want to create a development kit which clones projects and runs them together and handles links. Can docker-compose handle multiple docker-compose file? If not is there any sufficient tool to do that for us? Or is there any recommended approach for our goal?</p>&#xA;&#xA;<p>EDIT: For example we have two projects: PROJECT_A and PROJECT_B. Each one has its own docker-compose.yml and each one needs postgresql to run. We have docker-compose.yml in PROJECT_A like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_a:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>And we have docker-compose.yml in PROJECT_B like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_b:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>Each project can run separately and works fine. But if we want to change the api between PROJECT_A and PROJECT_B we need to run both projects and link them together to test our code. Now we want to write a development kit project which can run both projects and link them if needed. What is the best approach to do this?</p>&#xA;"
33041733,Microservices vs Monolithic Architecture,2015-10-09 15:11:34,<microservices>,3,26144,2,37.0,60,"<p>I did some reading about microservices, and I'm little bit intrigued.Seems like it is interesting concept. But I wonder, what are advantages and disadvantages using microservices over monolithic architecture, and vice versa.</p>&#xA;&#xA;<p>When microservices suitable better, and where better to go with monolithic architecture.</p>&#xA;"
26866479,Architecture of a microservice based web app,2014-11-11 13:53:31,<web-applications><soa><microservices>,4,6863,0,6.0,25,"<p>I am confused about the point at which a web application diverges into microservices - is it at url level or models level?&#xA;As an example, Suppose I have a monolithic app that serves 3 pages. Say each page serves a separate usecase and i want to back eack of them with their own microservices. Now, which of these is the correct way of implementing a microservice based architecture:</p>&#xA;&#xA;<ul>&#xA;<li>I create three different apps(microservices), each containing the (route, controller, models, templates) for one of the pages. And then based on which ever page is requested, I route the request to that particular app. This means that the whole page from database to HTML is served by a separate app. Basically, different pages in the same website are being completely served by different apps on the backend.</li>&#xA;<li>The 3 microservices do not handle the UI stuff but only the data for their usecases(models, controller, no templates) and expose it over a REST api. I have one public facing app. This app queries the three different apps(microservices) only for the data and then builds the html pages to be returned to browser. All the pages in a web app in this case are being served by a single app which internally makes use of three different microservices.</li>&#xA;</ul>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/b62O1.png"" alt=""enter image description here""></p>&#xA;"
28500066,How to deploy SpringBoot Maven application with Jenkins ?,2015-02-13 12:51:45,<maven><tomcat><jenkins><spring-boot><microservices>,4,19550,5,5.0,16,"<p>I have a Spring Boot application which runs on embedded Tomcat servlet container <code>mvn spring-boot:run</code> . And I don’t want to deploy the project as separate war to standalone Tomcat. </p>&#xA;&#xA;<p>Whenever I push code to BitBucket/Github, a hook runs and triggers Jenkins job (runs on Amazon EC2) to deploy the application. </p>&#xA;&#xA;<p>The Jenkins job has a post build action: <code>mvn spring-boot:run</code>, the problem is that the job hangs when post build action finished. </p>&#xA;&#xA;<p>There should be another way to do this. Any help would be appreciated.</p>&#xA;"
33125508,Service discovery vs load balancing,2015-10-14 12:36:39,<web-services><amazon-web-services><cloud><distributed-computing><microservices>,3,5816,1,3.0,21,"<p>I am trying to understand in which scenario I should pick a service registry over a load balancer.</p>&#xA;&#xA;<p>From my understanding both solutions are covering the same functionality.</p>&#xA;&#xA;<p>For instance if we consider <strong>consul.io</strong> as a feature list we have:</p>&#xA;&#xA;<ul>&#xA;<li>Service Discovery</li>&#xA;<li>Health Checking</li>&#xA;<li>Key/Value Store</li>&#xA;<li>Multi Datacenter</li>&#xA;</ul>&#xA;&#xA;<p>Where a load balancer like <strong>Amazon ELB</strong> for instance has:</p>&#xA;&#xA;<ul>&#xA;<li>configurable to accept traffic only from your load balancer</li>&#xA;<li>accept traffic using the following protocols: HTTP, HTTPS (secure HTTP), TCP, and SSL (secure TCP)</li>&#xA;<li>distribute requests to EC2 instances in multiple Availability Zones</li>&#xA;<li>The number of connections scales with the number of concurrent requests that the load balancer receives</li>&#xA;<li>configure the health checks that Elastic Load Balancing uses to monitor the health of the EC2 instances registered with the load balancer so that it can send requests only to the healthy instances</li>&#xA;<li>You can use end-to-end traffic encryption on those networks that use secure (HTTPS/SSL) connections</li>&#xA;<li>[EC2-VPC] You can create an Internet-facing load balancer, which takes requests from clients over the Internet and routes them to your EC2 instances, or an internal-facing load balancer, which takes requests from clients in your VPC and routes them to EC2 instances in your private subnets. Load balancers in EC2-Classic are always Internet-facing.</li>&#xA;<li>[EC2-Classic] Load balancers for EC2-Classic support both IPv4 and IPv6 addresses. Load balancers for a VPC do not support IPv6 addresses.</li>&#xA;<li>You can monitor your load balancer using CloudWatch metrics, access logs, and AWS CloudTrail.</li>&#xA;<li>You can associate your Internet-facing load balancer with your domain name. </li>&#xA;<li>etc.</li>&#xA;</ul>&#xA;&#xA;<p>So in this scenario I am failing to understand why I would pick something like <code>consul.io</code> or <code>netflix eureka</code> over <code>Amazon ELB</code> for service discovery.</p>&#xA;&#xA;<p>I have a hunch that this might be due to implementing <strong>client side service discovery</strong> vs <strong>server side service discovery</strong>, but I am not quite sure.</p>&#xA;"
33202053,Product Versioning Microservices,2015-10-18 19:08:57,<architecture><docker><domain-driven-design><soa><microservices>,2,6086,2,6.0,15,"<p>I go into microservices architecture based on docker and I have 3 microservices, which together create one product for example ""CRM system"".</p>&#xA;&#xA;<p>Now I want my client to be able to upgrade his product, whenever he wants to. &#xA;I have 3 different versions of my microservices, which one should client see? &#xA;I guess product version should be independent of microservices, because copying one of the microservices version would make me go into more trouble than having no version at all. </p>&#xA;&#xA;<p>So is there any pattern, idea to handle such situation? </p>&#xA;&#xA;<p>The only thing that comes to my mind is to have another repository which will be versioned whenever one of the microservices will produce production ready package. However, I now have a version, which none of my Product Owners (PO) would ever know about.</p>&#xA;"
36896418,Why would I choose a Windows Service over a Web API service?,2016-04-27 17:07:15,<c#><web-services><asp.net-web-api><microservices>,1,586,1,0.0,-4,"<p>For me, Windows Services are inconvenient and cumbersome enough to question their validity in all apps that aren't ""Watch this folder for a change, react to this change.""</p>&#xA;&#xA;<p>I understand that this oversimplification is ignorant, why would one choose a windows service over the Web API.</p>&#xA;"
27865238,Parent pom and microservices,2015-01-09 16:45:49,<java><maven><microservices>,3,5502,2,4.0,14,"<ul>&#xA;<li>We have several projects that are microservices, every project is independent (running on separate spring boot server, exposing rest services, using separate DB schema...)</li>&#xA;<li>We use maven to manage the dependencies.</li>&#xA;</ul>&#xA;&#xA;<p>Is it a good idea to have a parent pom declaring each microservices as modules? And so helping to manage the common dependencies (like the lib servlet-api witch is used in every project, to remove it of all of them and declare it in only the parent pom)</p>&#xA;"
34640611,How do I use an API Gateway in conjunction with microservices and JWTs?,2016-01-06 18:54:39,<api><security><jwt><microservices><kong>,1,2748,0,7.0,16,"<p>Afternoon y'all,</p>&#xA;&#xA;<p>Just looking for someone to double check my work. Is the below an effective way to secure microservices?</p>&#xA;&#xA;<h2>Premise</h2>&#xA;&#xA;<p>Breaking up our monolithic application and monolithic Partner API into microservices oriented around specific business functions. They'll most likely be small expressjs applications running in a docker container, on elastic beanstalk, who knows. They'll live somewhere :)</p>&#xA;&#xA;<p>I'm looking into either standing up <a href=""https://getkong.org"">Kong</a> as my API Gateway or using AWS API Gateway to encapsulate the details of my microservices. Also, it just feels good. </p>&#xA;&#xA;<p>The <a href=""https://getkong.org/plugins/jwt/"">JWT plugin</a> for Kong will verify the signature of the JWT and then pass the <code>customer_id</code> along in the header to the microservice. I should also mention that we have 3rd party developers that will be partaking in the integration fun as well. Here's a basic sketch of what I see happening:</p>&#xA;&#xA;<h2>Implementation</h2>&#xA;&#xA;<ol>&#xA;<li>Generate ""consumers"" for each platform and 3rd party developer we have. (Web app, mobile app, and the current integration partners we have. Note: I'm not looking to create consumers for every user that logs in. While certainly more secure, this adds a lot of work. Also, if you figure out how to get the secret out of my API Gateway I clearly have other issues)</li>&#xA;<li>Let Kong verify the request for me. Kind of like a bouncer at the door, there's no authorization, just authentication. </li>&#xA;<li>I don't need to know that the token is valid once it gets to the microservice, I can just use some middleware to decode it and use custom logic to decide if this user <em>really</em> should be doing whatever is they're trying to do. </li>&#xA;</ol>&#xA;&#xA;<h2>Extra Stuff</h2>&#xA;&#xA;<ul>&#xA;<li><p>There's a nice access control plugin for Kong. Our application and mobile app would run with ""God"" privileges, but I could definitely lock down the developers to specific routes and methods. </p></li>&#xA;<li><p>Revoking 3rd party access will be easy, revoking end users access won't be so simple unless I'm willing to invalidate all JWTs at once by generating a new secret. Perhaps I can limit token time to 10 minutes or so and make our applications check if they're expired, get a new token, and then get on with the original request. This way I can ""flag"" them in the database or something and not let the JWT be generated. </p></li>&#xA;<li><p>SSL used everywhere, JWT is stored in an SSL only cookie in the web browser and there's no sensitive information stored in any of the claims. </p></li>&#xA;</ul>&#xA;&#xA;<p>Thanks guys. </p>&#xA;"
47793065,Angular and Micro-Frontends,2017-12-13 12:29:00,<javascript><html><angular><microservices>,6,3468,5,14.0,36,"<p>I am doing some research on how to split a huge single-page-monolith into a micro-frontend architecture.</p>&#xA;&#xA;<h1>The idea:</h1>&#xA;&#xA;<ul>&#xA;<li>the page consists of several components which would be running autonomously</li>&#xA;<li>each component is managed by one dev-team</li>&#xA;<li>each team can change, update and deploy their components without breaking components of other teams</li>&#xA;<li>each team chooses its own toolstack</li>&#xA;</ul>&#xA;&#xA;<h1>The reason</h1>&#xA;&#xA;<p>To efficiently develop large applications you need to have many people working on it. However the number of developers per app/team does not scale well. Parallel development of multiple independent apps by independent teams however can be scaled arbitrarily</p>&#xA;&#xA;<p>With this in mind it is imperative that teams can choose their own toolstack and especially perform independent version-upgrades of third party-libraries (like angular, react, jquery). If this was not the case a framework-update would need to be compatible with every single component before you could deploy it to production.</p>&#xA;&#xA;<h1>Does this work with Angular?</h1>&#xA;&#xA;<p>While independent version-upgrades are necessary, it would be reasonable to restrict the teams to a few supported frameworks (Angular, React, Vue, Polymer...) and for now I try to build a demo purely consisting of Angular-Apps.</p>&#xA;&#xA;<p>However even though Angular 5 is supposedly a platform-framework which supports huge multi-module apps, it seems to be almost impossible to have several independent angular-apps running in the same browser window.</p>&#xA;&#xA;<p>I managed to bootstrap several Angular-Apps (different versions, each hosted on its own server) on a single webapp by utilizing HTML-Imports. However there are several <code>global</code> dependencies which need to be shared between apps</p>&#xA;&#xA;<ul>&#xA;<li>zone.js can only be started once</li>&#xA;<li>routing requires url-changes</li>&#xA;<li>Browser-stuff like cookies, sessionstorage, etc...</li>&#xA;</ul>&#xA;&#xA;<p>There are several articles in the net on how to bootstrap multiple angular-modules but they all refer to multiple modules in the same core-app, which in turn means they all are running on the same framework-version and an update means you have to rebuild and deploy the whole monolith.</p>&#xA;&#xA;<p><strong>Is there any solution other than ""<code>iframes</code>"" to get multiple Angular (5) Apps running on the same Page?</strong></p>&#xA;"
31044380,Microservices authentication,2015-06-25 07:53:17,<rest><microservices>,4,3308,0,4.0,9,"<p><strong>Context</strong></p>&#xA;&#xA;<p>I have multiple services like :</p>&#xA;&#xA;<ul>&#xA;<li>User (LDAP or active directory etc...)</li>&#xA;<li>Billing</li>&#xA;<li>Planning</li>&#xA;<li>etc...</li>&#xA;<li>Authentication</li>&#xA;</ul>&#xA;&#xA;<p>I need to connect on my microservices Using OAuth2.0, for beginning, using the standard login / password (I use my own data, and not gettint a third leg server)</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>According to these pictures :</p>&#xA;&#xA;<p><em>Step 1</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/csUn0.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p><em>Step 2</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/xmohK.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p>How can I handle access_token control or authorization control, in my other services than authmicroservice ?</p>&#xA;"
31031865,How do you manage per-environment data in Docker-based microservices?,2015-06-24 16:20:31,<deployment><configuration><architecture><docker><microservices>,1,6770,1,17.0,21,"<p>In a microservice architecture, I'm having a hard time grasping how one can manage environment-specific config (e.g. IP address and credentials for database or message broker).</p>&#xA;&#xA;<p>Let's say you have three microservices (""A"", ""B"", and ""C""), each owned and maintained by a different team.  Each team is going to need a team integration environment... where they work with the latest snapshot of their microservice, along with stable versions of all dependency microservices.  Of course, you'll also need QA/staging/production environments as well.  A simplified view of the big picture would look like this:</p>&#xA;&#xA;<p><strong>""Microservice A"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice B"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice C"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (<strong>SNAPSHOT</strong>)</li>&#xA;</ul>&#xA;&#xA;<p><strong>QA / Staging / Production</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice B (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice C (STABLE, RELEASE, etc)</li>&#xA;</ul>&#xA;&#xA;<p>That's a lot of deployments, but that problem can be solved by a continuous integration server and perhaps something like Chef/Puppet/etc.  The <strong><em>really</em></strong> hard part is that each microservice would need some environment data particular to each place in which it's deployed.  </p>&#xA;&#xA;<p>For example, in the ""A"" Team Environment, ""A"" needs one address and set of credentials to interact with ""B"".  However, over in the ""B"" Team Environment, <em>that</em> deployment of ""A"" needs a different address and credentials to interact with <em>that</em> deployment of ""B"".</p>&#xA;&#xA;<p>Also, as you get closer to production, environmental config info like this probably needs security restrictions (i.e. only certain people are able to modify or even view it).</p>&#xA;&#xA;<p>So, with a microservice architecture, how to you maintain environment-specific config info and make it available to the apps?  A few approaches come to mind, although they all seem problematic:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Have the build server bake them into the application at build-time</strong> - I suppose you could create a repo of per-environment properties files or scripts, and have the build process for each microservice reach out and pull in the appropriate script (you could also have a separate, limited-access repo for the production stuff).  You would need a <em>ton</em> of scripts, though.  Basically a separate one for every microservice in every place that microservice can be deployed.</li>&#xA;<li><strong>Bake them into base Docker images for each environment</strong> - If the build server is putting your microservice applications into Docker containers as the last step of the build process, then you could create custom base images for each environment.  The base image would contain a shell script that sets all of the environment variables you need.  Your Dockerfile would be set to invoke this script prior to starting your application.  This has similar challenges to the previous bullet-point, in that now you're managing a ton of Docker images.</li>&#xA;<li><strong>Pull in the environment info at runtime from some sort of registry</strong> - Lastly, you could store your per-environment config inside something like Apache ZooKeeper (or even just a plain ol' database), and have your application code pull it in at runtime when it starts up.  Each microservice application would need a way of telling which environment it's in (e.g. a startup parameter), so that it knows which set of variable to grab from the registry.  The advantage of this approach is that now you can use the <em>exact</em> same build artifact (i.e. application or Docker container) all the way from the team environment up to production.  On the other hand, you would now have another runtime dependency, and you'd still have to manage all of that data in your registry anyway.</li>&#xA;</ul>&#xA;&#xA;<p>How do people commonly address this issue in a microservice architecture?  It seems like this would be a common thing to hear about.</p>&#xA;"
31104540,DB consistency with microservices,2015-06-28 20:42:03,<database><soa><microservices>,4,4038,1,10.0,29,"<p>What is the best way to achieve DB consistency in microservice-based systems?</p>&#xA;&#xA;<p>At the <a href=""https://www.youtube.com/watch?v=wgdBVIX9ifA"" rel=""noreferrer"">GOTO in Berlin</a>, Martin Fowler was talking about microservices and one ""rule"" he mentioned was to keep ""per-service"" databases, which means that services cannot directly connect to a DB ""owned"" by another service.</p>&#xA;&#xA;<p>This is super-nice and elegant but in practice it becomes a bit tricky. Suppose that you have a few services:</p>&#xA;&#xA;<ul>&#xA;<li>a frontend</li>&#xA;<li>an order-management service</li>&#xA;<li>a loyalty-program service</li>&#xA;</ul>&#xA;&#xA;<p>Now, a customer make a purchase on your frontend, which will call the order management service, which will save everything in the DB -- no problem. At this point, there will also be a call to the loyalty-program service so that it credits / debits points from your account.</p>&#xA;&#xA;<p>Now, when everything is on the same DB / DB server it all becomes easy since you can run everything in one transaction: if the loyalty program service fails to write to the DB we can roll the whole thing back.</p>&#xA;&#xA;<p>When we do DB operations throughout multiple services this isn't possible, as we don't rely on one connection / take advantage of running a single transaction.&#xA;What are the best patterns to keep things consistent and live a happy life?</p>&#xA;&#xA;<p>I'm quite eager to hear your suggestions!..and thanks in advance!</p>&#xA;"
30296587,Using Amazon SQS with multiple consumers,2015-05-18 06:40:40,<amazon-web-services><amazon-sqs><microservices><event-based-programming>,1,10770,0,5.0,17,"<p>I have a service-based application that uses Amazon SQS with multiple queues and multiple consumers. I am doing this so that I can implement an event-based architecture and decouple all the services, where the different services react to changes in state of other systems. For example:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Registration Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'registration-new' when a new user registers.</li>&#xA;</ul></li>&#xA;<li><strong>User Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'user-updated' when user is updated.</li>&#xA;</ul></li>&#xA;<li><strong>Search Service</strong>: &#xA;<ul>&#xA;<li>Reads from queue 'registration-new' and indexes user in search.</li>&#xA;<li>Reads from queue 'user-updated' and updates user in search.</li>&#xA;</ul></li>&#xA;<li><strong>Metrics Service</strong>:&#xA;<ul>&#xA;<li>Reads from 'registration-new' queue and sends to Mixpanel.</li>&#xA;<li>Reads from queue 'user-updated' and sends to Mixpanel.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I'm having a number of issues:</p>&#xA;&#xA;<ul>&#xA;<li>A message can be received multiple times when doing polling. I can design a lot of the systems to be idempotent, but for some services (such as the metrics service) that would be much more difficult.</li>&#xA;<li>A message needs to be manually deleted from the queue in SQS. I have thought of implementing a ""message-handling-service"" that handles the deletion of messages when all the services have received them (each service would emit a 'message-acknowledged' event after handling a message).</li>&#xA;</ul>&#xA;&#xA;<p>I guess my question is this: what patterns should I use to ensure that I can have multiple consumers for a single queue in SQS, while ensuring that the messages also get delivered and deleted reliably. Thank you for your help.</p>&#xA;"
30286443,Microservices: How to store source code of many microservices?,2015-05-17 11:30:44,<git><microservices>,3,6232,0,8.0,29,"<p>Currently, I have <strong>20 microservices</strong> for one project. And every microservice stored in separate GIT reposotiry. &#xA;Subsequently, the number of services will increase <strong>to 200 (or more)</strong>.</p>&#xA;&#xA;<p>Every service has unit tests and integration tests. Every service has build in TeamCity (Continuous integration server). </p>&#xA;&#xA;<p>Question: How to store source code of 200 microservices for one project? In one repository or in separate repositories? </p>&#xA;"
30213456,Transactions across REST microservices?,2015-05-13 11:27:25,<rest><architecture><transactions><microservices>,10,43100,6,79.0,120,"<p>Let's say we have a User, Wallet REST microservices and an API gateway that glues things together. When Bob registers on our website, our API gateway needs to create a user through the User microservice and a wallet through the Wallet microservice. </p>&#xA;&#xA;<p>Now here are a few scenarios where things could go wrong:</p>&#xA;&#xA;<ul>&#xA;<li><p>User Bob creation fails: that's OK, we just return an error message to the Bob. We're using SQL transactions so no one ever saw Bob in the system. Everything's good :)</p></li>&#xA;<li><p>User Bob is created but before our Wallet can be created, our API gateway hard crashes. We now have a User with no wallet (inconsistent data).</p></li>&#xA;<li><p>User Bob is created and as we are creating the Wallet, the HTTP connection drops. The wallet creation might have succeeded or it might have not.</p></li>&#xA;</ul>&#xA;&#xA;<p>What solutions are available to prevent this kind of data inconsistency from happening? Are there patterns that allow transactions to span multiple REST requests? I've read the Wikipedia page on <a href=""http://en.wikipedia.org/wiki/Two-phase_commit_protocol"">Two-phase commit</a> which seems to touch on this issue but I'm not sure how to apply it in practice. This <a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"">Atomic Distributed Transactions: a RESTful design</a> paper also seems interesting although I haven't read it yet.</p>&#xA;&#xA;<p>Alternatively, I know REST might just not be suited for this use case. Would perhaps the correct way to handle this situation to drop REST entirely and use a different communication protocol like a message queue system? Or should I enforce consistency in my application code (for example, by having a background job that detects inconsistencies and fixes them or by having a ""state"" attribute on my User model with ""creating"", ""created"" values, etc.)?</p>&#xA;"
36407520,Spring Cloud/Boot vs Wildfly Swarm,2016-04-04 16:02:13,<java><spring-boot><microservices><wildfly-9><wildfly-swarm>,1,5675,4,4.0,12,"<p>I have doing some analysis of modern Container less Java Stack on net, two Major promising things i came about was:</p>&#xA;&#xA;<ol>&#xA;<li>Spring Boot/Cloud (Packed in Tomcat or Jetty,...)</li>&#xA;<li>Wildfly Swarm (Moduler Wildfly 9 Server with minimum possible components)</li>&#xA;</ol>&#xA;&#xA;<p>Yes both have their own features but i have not been able to find out a good comparison of both as both thing are in my point of view better then each other but still i have to decide what good for implementing,</p>&#xA;&#xA;<ol>&#xA;<li>Good for Developer health</li>&#xA;<li>Complex Enterprise logic</li>&#xA;<li>Scalability</li>&#xA;<li>Hot deployments</li>&#xA;<li>Microservice Approach</li>&#xA;<li>Enterprise Integration Patterns</li>&#xA;<li>Continuous Delivery Pipeline.</li>&#xA;</ol>&#xA;&#xA;<p>Thanks for your thoughts</p>&#xA;&#xA;<p>Zaheer  </p>&#xA;"
33726653,Service Fabric Reliable Services Pipeline design,2015-11-16 00:03:44,<c#><azure><pipeline><microservices><azure-service-fabric>,1,2574,0,10.0,14,"<p>I need to implement pipeline if Service Fabric's Reliable Services, and I need some guidelines about what of these approaches is preferable from the viewpoint of reliability simplicity and simple good design:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pWFql.png""><img src=""https://i.stack.imgur.com/pWFql.png"" alt=""enter image description here""></a></p>&#xA;"
34903605,Microservices: what are pros and cons?,2016-01-20 15:08:36,<architecture><microservices>,2,9224,0,7.0,20,<p>What are pros and cons of using microservices in comparison with alternative architectures?&#xA;Is there a rule of thumb when microservices should be used?</p>&#xA;
35381163,Best practice to organize authorization in microservice architecture?,2016-02-13 14:34:27,<authentication><architecture><authorization><microservices>,1,3241,8,3.0,9,"<p>For example, I have 3 services:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Seller</li>&#xA;<li>Buyer</li>&#xA;</ul>&#xA;&#xA;<p>Each of them got their own databases, models, services... etc</p>&#xA;&#xA;<p>Authentication service knows about users, user-groups, roles, permissions and creates token.</p>&#xA;&#xA;<p>Where should I store sellers/buyers entities? On Authentication service, or on Seller/Buyer services?</p>&#xA;&#xA;<p>How should Seller/Buyer services interact to create new seller/buyer entity?</p>&#xA;&#xA;<p>How should Seller/Buyer services check permissions?</p>&#xA;&#xA;<p>Seller and Buyer entities have some common fields: name, password, email..., but also each of them have their own additional fields.</p>&#xA;&#xA;<p>Seller and Buyer interact with each other.</p>&#xA;"
41640621,Data Sharing between micro services,2017-01-13 17:52:49,<design-patterns><architecture><microservices><aws-api-gateway><data-sharing>,4,6060,9,11.0,24,"<p><strong>Current Architecture:</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qlrIu.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qlrIu.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Problem:</strong></p>&#xA;&#xA;<p>We have a two-step flow between frontend and backend layers.  </p>&#xA;&#xA;<ul>&#xA;<li>First step:&#xA;The frontend validates an input <strong>I1</strong> from the user on microservice 1 (MS1)</li>&#xA;<li>Second step:&#xA;The frontend submits <strong>I1</strong> and more information to the microservice 2</li>&#xA;</ul>&#xA;&#xA;<p>The micro service 2 (MS2) needs to validates the integrity of <strong>I1</strong> as it is coming from the frontend. How to do avoid a new query to MS1? What's the best approach?</p>&#xA;&#xA;<p><strong>Flows that I'm trying to optimize removing the steps 1.3 and 2.3</strong></p>&#xA;&#xA;<p>Flow 1:</p>&#xA;&#xA;<ul>&#xA;<li>1.1 The User X requests data (MS2_Data) from MS2</li>&#xA;<li>1.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>1.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>1.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p>Flow 2:</p>&#xA;&#xA;<ul>&#xA;<li>2.1 The User X already has data (MS2_Data) stored on local/session storage</li>&#xA;<li>2.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>2.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>2.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Approach</strong></p>&#xA;&#xA;<p>One possible approach is to use a B2B HTTP request between MS2 and MS1 but we would be duplicating the validation in the first step.&#xA;Another approach will be duplicating data from MS1 to MS2. however this is prohibitive due to the amount of data and it's volatility nature. Duplication does not seem to be a viable option.</p>&#xA;&#xA;<p>A more suitable solution is my opinion will the frontend to have the responsibility to fetch all the information required by the micro service 1 on the micro service 2 and delivered it to the micro service 2. This will avoid all this B2B HTTP requests.</p>&#xA;&#xA;<p><strong>The problem is how the micro service 1 can trust the information sent by the frontend. Perhaps using <a href=""https://jwt.io/introduction/"" rel=""noreferrer"">JWT</a> to somehow sign the data from the micro service 1 and the micro service 2 will be able to verify the message.</strong></p>&#xA;&#xA;<p><strong>Note</strong>&#xA;Every time the micro service 2 needs information from the micro service 1 a B2B http request is performed. (The HTTP request use <a href=""https://en.wikipedia.org/wiki/HTTP_ETag"" rel=""noreferrer"">ETAG</a> and <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control"" rel=""noreferrer"">Cache Control: max-age</a>). How to avoid this? </p>&#xA;&#xA;<p><strong>Architecture Goal</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FR7E7.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FR7E7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The micro service 1 needs the data from the micro service 2 on demand to be able to persist MS1_Data and MS2_Data on MS1 database, so the ASYNC approach using a broker does not apply here.</strong></p>&#xA;&#xA;<p>My question is if exists a design pattern, best practice or a framework to enable this kind of thrust communication. </p>&#xA;&#xA;<p>The downside of the current architecture is the number of B2B HTTP requests that are performed between each micro services. Even if I use a cache-control mechanism the response time of each micro service will be affected. The response time of each micro services is critical. The goal here is to archive a better performance and some how use the frontend as a gateway to distribute data across several micro services but using a <strong>thrust communication</strong>. </p>&#xA;&#xA;<p>MS2_Data is just an Entity SID like product SID or vendor SID that the MS1 must use to maintain data integrity. </p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qSYQY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qSYQY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The idea is to use the gateway as an api gateway request processing that will cache some HTTP response from MS1 and MS2 and use them as a response to MS2 SDK and MS1 SDK. This way no communication (SYNC OR ASYNC) is made directly between MS1 and MS2 and data duplication is also avoided.</p>&#xA;&#xA;<p>Of course the above solution is just for shared UUID/GUID across micro services. For full data, an event bus is used to distribute events and data across micro services in an asynchronous way (Event sourcing pattern). </p>&#xA;&#xA;<p>Inspiration: <a href=""https://aws.amazon.com/api-gateway/"" rel=""noreferrer"">https://aws.amazon.com/api-gateway/</a> and <a href=""https://getkong.org/"" rel=""noreferrer"">https://getkong.org/</a></p>&#xA;&#xA;<p><strong>Related questions and documentation:</strong></p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://stackoverflow.com/questions/41445442/how-to-sync-the-database-with-the-microservices-and-the-new-one/41475346"">How to sync the database with the microservices (and the new one)?</a></li>&#xA;<li><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""noreferrer"">https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/30213456/transactions-across-rest-microservices"">Transactions across REST microservices?</a></li>&#xA;<li><a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></li>&#xA;<li><a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"" rel=""noreferrer"">http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf</a></li>&#xA;<li><a href=""https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/"" rel=""noreferrer"">https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/</a></li>&#xA;</ul>&#xA;"
42096392,Is it possible to combine different language in one application?,2017-02-07 17:38:09,<java><php><node.js><microservices>,1,46,5,0.0,-3,"<p>first of all, i dont want to make things a bit ambiguous.</p>&#xA;&#xA;<p>is it possible to to use different language such node.js, php for developing a Web service?</p>&#xA;&#xA;<p>for instance the node.js will be responsible for user authentication and PHP and responsible messaging .&#xA;mainly the idea of the app will be in Microservice architecture.&#xA;The Node.js will have the authentication service&#xA;and the PHP will have the messaging service.&#xA;is that a good idea&#xA;because i am learning microservices architecure and i got the user authentication and i was thinking of use PHP to complete the rest of my project.&#xA;Obviously they will have a different DB.&#xA;thanks in advance</p>&#xA;"
31842622,Microservices: How to integrate the UI?,2015-08-05 20:54:01,<microservices>,1,3595,3,3.0,13,"<p>today I started reading about Microservice architectures - and it seems to be very interesting!&#xA;But I have one doubt I need some exlanation on:&#xA;Assume I want to create a blog and would build 4 microservices for that: User/login Service, Article Service, Comments Service and Reporting/analytics Service(not a realistic example, I know...).&#xA;The Reporting/Analytics service is purely backend - no issue here for my understanding.&#xA;But the three others involve some UI part - and as to my understanding this UI part should also be part of the microservice itself, right?&#xA;How would the UI integration work? Would I then have a 5th ""front door"" service that collects the user requests, forwards them to the other services which then answer with HTML/CSS and the front door service would then compose the individual responses into what is returned to the user?</p>&#xA;&#xA;<p>Any change you have an example/use case for such a scenario?</p>&#xA;&#xA;<p>Thanks and regards!</p>&#xA;"
31786040,Spring Cloud: Canary Deployments with Zuul,2015-08-03 11:27:35,<spring-cloud><microservices><netflix-eureka><netflix-zuul><canary-deployment>,1,2173,0,8.0,15,"<p>I am getting started with Spring Cloud using Eureka and Zuul and had some questions around structuring blue/green and Canary deployments. So far, I have the basics worked out and have Eureka, Zuul, and a config server working as expected. What I am trying to accomplish is set up a service that has two versions, say 1.0 and a 1.1. For a subset of specific users, I want to route them to the 1.1 version and everyone else should go to the 1.0 version. </p>&#xA;&#xA;<p>The Zuul filter API is a little light on documentation and I'm struggling a bit to grok some of the concepts, so I thought I'd ask a few questions here. I have also have some basic filters running, which don't do a whole lot a the moment other than getting the identity of the principal and the service they are requesting. Where I am hitting a wall is understanding how to expose two different versions of the same service to Eureka and Zuul. A few things I'm curious about:</p>&#xA;&#xA;<ul>&#xA;<li>Between documentation, posts, and other stack overflow, the term ""service"" and ""cluster"" seem to be used interchangeably. Is this correct?</li>&#xA;<li>With that said if I have a service named <code>/simpleservice</code> do I expose two different serviceIDs (i.e. <code>simpleservice</code> and <code>simpleservice-1.1</code> )? And If I do that, when one of the targeted users requests <code>/simpleservice</code>, I'm having Zuul send them to <code>/simpleservice-1.1</code></li>&#xA;<li>Or, do you add another node to the existing service ID and add additional metadata to each node so that Zuul and distinguish versions 1.0 and 1.1?</li>&#xA;<li>Is the correct answer ""all of the above?"" :)</li>&#xA;</ul>&#xA;"
38071714,GraphQL and Microservice Architecture,2016-06-28 09:04:42,<architecture><microservices><graphql>,5,14892,0,48.0,86,"<p>I'm trying to understand where GraphQL is most suitable to use within a Microservice architecture. </p>&#xA;&#xA;<p>There is some debate about having only 1 GraphQL schema that works as API Gateway proxying the request to the targeted microservices and coercing their response. Microservices still would use REST / Thrift protocol for communication thought.</p>&#xA;&#xA;<p>Another approach is instead to have multiple GraphQL schemas one per microservice. Having a smaller API Gateway server that route the request to the targeted microservice with all the information of the request + the GraphQL query.</p>&#xA;&#xA;<p><strong>1st Approach</strong></p>&#xA;&#xA;<p>Having 1 GraphQL Schema as an API Gateway will have a downside where every time you change your microservice contract input/output, we have to change the GraphQL Schema accordingly on the API Gateway Side.</p>&#xA;&#xA;<p><strong>2nd Approach</strong></p>&#xA;&#xA;<p>If using Multiple GraphQL Schema per microservices, make sense in a way because GraphQL enforces a schema definition, and the consumer will need to respect input/output given from the microservice.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>Where do you find GraphQL the right fit for designing microservice architecture? </p></li>&#xA;<li><p>How would you design an API Gateway with a possible GraphQL implementation?</p></li>&#xA;</ul>&#xA;"
42648060,Unauthorized in spring boot admin,2017-03-07 12:15:20,<spring><spring-boot><microservices><netflix-eureka><spring-boot-admin>,2,11214,0,3.0,11,"<p>I wanted to control the microservices that are running in the Eureka server. I used spring-boot-admin for this, but I am getting the error on accessing the information about the Trace,Log etc...</p>&#xA;&#xA;<p>The error I am getting is </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: {""timestamp"":1489052472862,""status"":401,""error"":""Unauthorized"",""message"":""Full authentication is required to access this resource."",""path"":""/metrics""}</p>&#xA;</blockquote>&#xA;&#xA;<p>My dependencies are</p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>and none of the below properties worked</p>&#xA;&#xA;<pre><code>endpoints.info.id=information&#xA;endpoints.info.sensitive=false&#xA;endpoints.info.enabled=true&#xA;information.app.name=Actuator Example&#xA;information.app.description=Actuator Example&#xA;information.app.version=1.0.0&#xA;</code></pre>&#xA;&#xA;<p>and the same thing is happening with all the end points like mappings, env and all accept health</p>&#xA;"
38633023,What are the disadvantages of Spring Boot for Java web applications?,2016-07-28 09:57:24,<java><spring><spring-boot><microservices>,1,8337,2,1.0,19,"<p>[This needs to be voted to be reopened to answer.]</p>&#xA;&#xA;<p>Spring boot is tipped as being the default go to when making a new spring application as it makes set up easier and automatically wires in common dependencies. </p>&#xA;&#xA;<p>I am yet in industry to see spring-boot used in the manner advertised.</p>&#xA;&#xA;<p>Factually and concisely, what are the disadvantages that are faced by developers on adoption of Spring boot as the de facto Spring go to?</p>&#xA;&#xA;<p>The advantages of Spring Boot <a href=""https://stackoverflow.com/questions/28831479/advantage-of-spring-boot"">question</a> shows advantages of which I agree there are many, but believe there should be a rounder view. </p>&#xA;&#xA;<p>An example non opinion based point would be:</p>&#xA;&#xA;<ul>&#xA;<li><p>Spring boot may unnecessarily increase the deployment binary size with unused dependencies.</p></li>&#xA;<li><p>Not being able to customize logging easily as shown <a href=""https://stackoverflow.com/questions/29609996/spring-boot-loggingapplicationlistener-interfering-with-application-server-logg"">here</a>.</p></li>&#xA;</ul>&#xA;"
48906817,2PC vs Sagas (distributed transactions),2018-02-21 13:10:40,<transactions><cloud><microservices><distributed-computing><saga>,1,361,1,2.0,15,"<p>I'm developing my insight about distributed systems, and how to maintain data consistency across such systems, where business transactions covers multiple services, bounded contexts and network boundaries.</p>&#xA;&#xA;<p>Here are two approaches which I know are used to implement distributed transactions:</p>&#xA;&#xA;<ul>&#xA;<li>2-phase commit (2PC)</li>&#xA;<li>Sagas</li>&#xA;</ul>&#xA;&#xA;<p>2PC is a protocol for applications to <em>transparently</em> utilize global ACID transactions by the support of the platform. Being embedded in the platform, it is transparent to the business logic and the application code as far as I know.</p>&#xA;&#xA;<p>Sagas, on the other hand, are series of local transactions, where each local transaction mutates and persist the entities along with some flag indicating the phase of the global transaction and commits the change. In the other words, state of the transaction is part of the domain model. Rollback is the matter of committing a series of ""inverted"" transactions. Events emitted by the services triggers these local transactions in either case.</p>&#xA;&#xA;<p>Now, when and why would one use sagas over 2PC and vice versa? What are the use cases and pros/cons of both? Especially, the brittleness of sagas makes me nervous, as the inverted distributed transaction could fail as well.</p>&#xA;"
36701111,Communication between two microservices,2016-04-18 17:58:51,<java><spring><spring-boot><jhipster><microservices>,4,13403,5,9.0,29,"<p>I am creating a project with microservices architecture. And I created two microservices.</p>&#xA;&#xA;<p>One of them is for product entity, the other is for bill entity. They have their own endpoints and they are connected together with the gateway (i am using jhipster microservices architecture). </p>&#xA;&#xA;<p>The bill-ms should access to list of products. I'm wondering how I can communicate between those two ms. I have three approaches in my mind:</p>&#xA;&#xA;<ol>&#xA;<li><p>Send a request from bill-ms to queue - like rabbitMQ, to get these products with these ids from product-ms (I don't know what is bottleneck of this)</p></li>&#xA;<li><p>Send a request to gateway for product service and get the product from there (I'm worried about the latency because of the data size between them and in this way I'm not touching the database directly so I always depend on the gateway)</p></li>&#xA;<li><p>I can duplicate the repositories, services and entities in bill-ms (it's an ugly way, and I think it breaks the rule of ms-architecture and the maintenance is very difficult)</p></li>&#xA;</ol>&#xA;&#xA;<p>If you have any other approaches, I appreciate you to share it with me.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<ol>&#xA;<li>Now I know what the bottleneck is: say that there are 3 instance of bill-ms and how does rabbitMQ decide which instance to respond? or how should I say to ribbon ""<strong>give me the free instance of bill-ms to subscribe to the request from rabbitMQ</strong>"" for load balancing.</li>&#xA;</ol>&#xA;"
44579396,In microservices should i use pub/sub instead RPC to get more loosely couple architecture?,2017-06-16 01:24:56,<architecture><rpc><publish-subscribe><microservices>,2,1806,0,2.0,9,"<p>I current using a RPC call to another microservice via TCP and getting the response, but I think I can do it in this way:</p>&#xA;&#xA;<p>whithout make a RPC call, can I use a pub/sub to send to one service, publishing some channel like <em>request_user</em> and subscribed to a channel like  <em>object_user_response</em>, and then the other service that is subscribed to this <em>request_user</em>, publish <em>object_user_response</em>.</p>&#xA;&#xA;<p>Like that:</p>&#xA;&#xA;<pre><code>Service A &lt;-- (sub)object_user_response &lt;------  Redis&#xA;Service A --&gt; (pub)request_user -------------&gt;   Redis&#xA;&#xA;Service B &lt;-- (sub)request_user &lt;--------------- Redis&#xA;Service B --&gt; (pub) object_user_response ------&gt; Redis&#xA;</code></pre>&#xA;&#xA;<p>On receive a object_user_response, the service A checks if the id of user is the same that the function have requested. </p>&#xA;&#xA;<p>Should I use RPC or Pub/sub for that?&#xA;What is the most correct way to send data to a microservice and get response from there in terms of loosely coupled architecture, is using a RPC call or using two pub/sub, on for the request and another for the response?  </p>&#xA;"
37749087,"How to restore state in an event based, message driven microservice architecture on failure scenario",2016-06-10 13:06:04,<messaging><reactive-programming><microservices><event-based-programming>,3,1771,0,7.0,12,"<p>In the context of a microservice architecture, a message driven, asynchronous, event based design seems to be gaining popularity (see <a href=""http://blog.christianposta.com/microservices/why-microservices-should-be-event-driven-autonomy-vs-authority/"" rel=""noreferrer"">here</a> and <a href=""https://www.nginx.com/blog/event-driven-data-management-microservices/"" rel=""noreferrer"">here</a> for some examples, as well as the <a href=""http://www.reactivemanifesto.org/#message-driven"" rel=""noreferrer"">Reactive Manifesto - Message Driven trait</a>) as opposed to a synchronous (possibly REST based) mechanism.</p>&#xA;&#xA;<p>Taking that context and imagining an overly simplified ordering system, as depicted below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Xtttg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Xtttg.png"" alt=""ordering system""></a></p>&#xA;&#xA;<p>and the following message flow:</p>&#xA;&#xA;<ul>&#xA;<li>Order is placed from some source (web/mobile etc.)</li>&#xA;<li>Order service accepts order and publishes a <code>CreateOrderEvent</code></li>&#xA;<li>The InventoryService reacts on the <code>CreateOrderEvent</code>, does some inventory stuff and publishes a <code>InventoryUpdatedEvent</code> when it's done</li>&#xA;<li>The Invoice service then reacts to the <code>InventoryUpdatedEvent</code>, sends an invoice and publishes a <code>EmailInvoiceEvent</code></li>&#xA;</ul>&#xA;&#xA;<p>All services are up and we happily process orders... Everyone is happy.&#xA;Then, the Inventory service goes down for some reason </p>&#xA;&#xA;<p>Assuming that the events on the event bus are flowing in a ""non blocking"" manor. I.e. the messages are being published to a central topic and do not pile up on a queue if no service is reading from it (what I'm trying to convey is an event bus where, if the event is published on the bus, it would flow ""straight through"" and not queue up - ignore what messaging platform/technology is used at this point). That would mean that if the Inventory service were down for 5 minutes, the <code>CreateOrderEvent</code>'s passing through the event bus during that time are now ""gone"" or not seen by the Inventory service because in our overly simplified system, no other system is interested in those events.</p>&#xA;&#xA;<p>My question then is: How does the Inventory service (and the system as a whole) restore state in a way that no orders are missed/not processed?</p>&#xA;"
44870461,Microservices: how to handle foreign key relationships,2017-07-02 11:45:53,<database><microservices>,2,6194,0,11.0,26,"<p>Microservices architecture suggest that each service should handle it's own data. Hence any service (Service A) dependent on data owned by other service (service B) should access such data not by making direct DB calls but through the api provided by the second service (service B).</p>&#xA;&#xA;<p><strong>So what does microservices best practices suggest on checking foreign key constrains.</strong> </p>&#xA;&#xA;<p>Example: I am developing a delivery feature (microservice 1) for products and certain products are deliverable to only certain locations as mentioned in the products table accessible to only products micro service (mircoservice 2).</p>&#xA;&#xA;<p>How do I make sure that microservice 1 (i.e delivery feature) does not take an order to a unserviced location. I have this question because delivery feature can not directly access products database, so there is no constraints applicable at DB level when a delivery order is place in to delivery data base (no check is possible to see if a foreign key match exists in products database or table).</p>&#xA;"
44195150,How can we keep an java application running forever,2017-05-26 06:37:24,<java><web-services><microservices>,2,72,4,0.0,-4,"<p>I want to write an java application, which should be running forever. &#xA;Webservice is a way to do so, but i don't want to run it as webservice. &#xA;I just want to run some threads inside application running forever, I don't want to process any webRequest as such.</p>&#xA;&#xA;<p>Can you please tell what are other ways to do so ?</p>&#xA;"
35756663,API gateway vs. reverse proxy,2016-03-02 19:44:32,<nginx><reverse-proxy><microservices><aws-api-gateway><tyk>,2,17931,0,23.0,47,"<p>In order to deal with the microservice architecture, it's often used alongside a Reverse Proxy (such as nginx or apache httpd) and for cross cutting concerns implementation  <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">API gateway pattern is used</a>. Sometimes Reverse proxy does the work of API gateway. <br>&#xA;It will be good to see clear differences between these two approaches.&#xA;It looks like the potential benefit of API gateway usage is invoking multiple microservices and aggregating the results. All other <a href=""https://auth0.com/blog/2015/09/13/an-introduction-to-microservices-part-2-API-gateway/"" rel=""noreferrer"">responsibilities</a> of API gateway can be implemented using Reverse Proxy.Such as:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication (It can be done using nginx LUA scripts);</li>&#xA;<li>Transport security. It itself Reverse Proxy task;</li>&#xA;<li>Load balancing</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>So based on this there are several questions:</p>&#xA;&#xA;<ol>&#xA;<li>Does it make sense to use API gateway and Reverse proxy simultaniously (as example request->Api gateway-> reverse proxy(nginx)-> concrete mictoservice)? In what cases ?</li>&#xA;<li>What the other differences that can be implemented using API gateway and can't be implemented by Reverse proxy and vice versa ?</li>&#xA;</ol>&#xA;"
40900818,Querying / Pagination Across Microservices,2016-12-01 00:48:57,<web-services><rest><integration><soa><microservices>,1,836,3,0.0,11,"<p>Our shop has recently started taking on an SOA approach to application development.  We are seeing some great benefits with the separation of concerns, reusability, and other benefits of SOA/microservices.</p>&#xA;&#xA;<p>However, one <strong>big</strong> item we're stuck on is aggregating, filtering, and paginating results across services.  Let me describe the issue with a scenario.</p>&#xA;&#xA;<p>Say we have 3 services:</p>&#xA;&#xA;<ol>&#xA;<li><strong>PersonService</strong> - Stores information on people (names, addresses, etc)</li>&#xA;<li><strong>ItemService</strong> - Stores information on items that are purchasable.</li>&#xA;<li><strong>PaymentService</strong> - Stores information regarding payments that people have made for different items.</li>&#xA;</ol>&#xA;&#xA;<p>Now, say we want to build a reporting/admin tool that can display / report on multiple services in aggregate.  For instance, we want to display a paginated list of Payments, along with the Person and Item that each payment was for.  This is pretty straightforward:  Grab the list of payments, then query PersonService and ItemService for the respective Person and Item records.</p>&#xA;&#xA;<p>However, the issue comes into play when we want to then filter down that data:  For instance, displaying a paginated list of payments made by people with the first name 'Bob', who have purchased the item 'Car'. This makes things much more complicated, because we need to filter results from 3 different services without knowing how many results each service is going to return.  </p>&#xA;&#xA;<p>From a performance perspective, querying all of the services over and over again to narrow down the results would be costly, so I've been researching better solutions.  However, I cannot find concrete solutions to this problem (or at least a ""best practice"").  In a monolithic application, we'd simply use SQL joins across the different tables.  I'm having a ton of trouble figuring out how/if something similar is possible across services.</p>&#xA;&#xA;<p>My question to the community is:  What would your approach be?  Things I've considered:</p>&#xA;&#xA;<ol>&#xA;<li>Using some sort of search index (<strong>Elasticsearch</strong>, <strong>Solr</strong>) that contains all data for all services (updated via events pushed out by services), and then querying the search index for results.</li>&#xA;<li>Attempting to understand how projects like <strong>GraphQL</strong> and <strong>Neo4j</strong> may assist us with these issues.</li>&#xA;</ol>&#xA;"
43950808,Data Consistency Across Microservices,2017-05-13 08:13:05,<design-patterns><akka><microservices><data-consistency>,5,3656,0,9.0,12,"<p>While each microservice generally will have its own data - certain entities are required to be consistent across multiple services. </p>&#xA;&#xA;<p>For such data consistency requirement in a highly distributed landscape such as microservices architecture, what are the choices for design? Of course, I do not want shared database architecture, where a single DB manages the state across all the services. That violates isolation and shared-nothing principles. </p>&#xA;&#xA;<p>I do understand that, a microservice can publish an event when an entity is created, updated or deleted. All other microservices which are interested in this event can accordingly update the linked entities in their respective databases. </p>&#xA;&#xA;<p>This is workable, however it leads to a lot of careful and coordinated programming effort across the services.</p>&#xA;&#xA;<p>Can Akka or any other framework solve this use case? How?</p>&#xA;&#xA;<p><strong>EDIT1:</strong><br/>&#xA;Adding the below diagram for clarity. &#xA;<br/>Basically, I am trying to understand, if there are available frameworks today that can solve this data consistency problem. </p>&#xA;&#xA;<p>For the queue I can use any AMQP software such as RabbitMQ or Qpid etc. &#xA;For the data consistency framework, I am not sure if presently Akka or any other software can help. Or is this scenario so uncommon, and such an anti-pattern that no framework should be ever needed?<br>&#xA;<a href=""https://i.stack.imgur.com/9hIo9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9hIo9.png"" alt=""enter image description here""></a></p>&#xA;"
51942114,Why we need to write business logic in separate service layer instead of writing in controller itself?,2018-08-21 05:28:49,<spring><spring-mvc><spring-boot><microservices>,2,46,3,0.0,-5,<p>Whats the use of creating different layer i.e. Service layer for business logic implementation instead of implementing that business logic in Controller itself</p>&#xA;
37180375,Using Zuul as an authentication gateway,2016-05-12 07:42:05,<spring-boot><spring-cloud><microservices><gateway><netflix-zuul>,3,14024,3,14.0,18,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I want to implement the design presented in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""noreferrer"">article</a>.</p>&#xA;&#xA;<p>It can be summarised by the diagram below:&#xA;<a href=""https://i.stack.imgur.com/viaL4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viaL4.png"" alt=""Security Architecture""></a></p>&#xA;&#xA;<ol>&#xA;<li>The client first authenticate with the IDP (OpenID Connect/OAuth2)</li>&#xA;<li>The IDP returns an access token (opaque token with no user info)</li>&#xA;<li>The client makes a call through the API gateway use the access token in the Authorization header</li>&#xA;<li>The API gateway makes a request to the IDP with the Access Token</li>&#xA;<li>The IDP verifies that the Access Token is valid and returns user information in JSON format</li>&#xA;<li>The API Gateway store the user information in a JWT and sign it with a private key. The JWT is then passed to the downstream service which verifies the JWT using the public key</li>&#xA;<li>If a service must call another service to fulfil the request it passes the JWT along which serves as authentication and authorisation for the request</li>&#xA;</ol>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have most of that done using:</p>&#xA;&#xA;<ul>&#xA;<li>Spring cloud as a global framework</li>&#xA;<li>Spring boot to launch individual services</li>&#xA;<li>Netflix Zuul as the API gateway</li>&#xA;</ul>&#xA;&#xA;<p>I have also written a Zuul PRE filter that checks for an Access Token, contacts the IDP and create a JWT. The JWT is then added to the header for the request forwarded to the downstream service.</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>Now my question is quite specific to Zuul and its filters. If authentication fails in the API gateway for any reason, how can I can stop the routing and respond directly with a 401 without continuing the filter chain and forwarding the call?</p>&#xA;&#xA;<p>At the moment if authentication fails the filter won't add the JWT to the header and the 401 will come from the downstream service. I was hoping my gateway could prevent this unnecessary call.</p>&#xA;&#xA;<p>I tried to see how I could use <code>com.netflix.zuul.context.RequestContext</code>to do this but the documentation is quite poor and I couldn't find a way. </p>&#xA;"
41036545,How to pass through properties in JSON messages with Jackson and MongoDB?,2016-12-08 09:58:46,<java><json><spring><jackson><microservices>,7,731,7,0.0,9,"<p>We have a microservice which gets some JSON data from the queue, processes it a little bit and sends the result of processing further on - again via queue. In the microservice we don't work with <code>JSONObject</code> an likes directly, we map JSON onto Java classes using Jackson.</p>&#xA;&#xA;<p>When processing, the microservice is only interested in a some properties of the incoming message, not all of them. Imagine it just receives</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And sends:</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    ""multiplicationResult"": 15,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>How can I tunnell or pass-through other properties of the message which I'm not interested in this service without explicitly mapping them in my classes?</strong></p>&#xA;&#xA;<p>For the purposes of this microservice it would be enough to have a structure like:</p>&#xA;&#xA;<pre><code>public class Task {&#xA;   public double operand1;&#xA;   public double operand2;&#xA;   public double multiplicationResult;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However if I don't map all of the <em>other properties</em>, they will be lost.</p>&#xA;&#xA;<p>If I do map them then I'll have to update the model of this microservice every time the structure of the message changes which takes effort and is error-prone.</p>&#xA;"
46031939,How to manage read requests in an event sourced application,2017-09-04 07:07:54,<domain-driven-design><microservices><cqrs><event-sourcing><event-store>,2,109,2,2.0,9,"<p>I was asked to do some exploration in event sourcing. my objective is to create a tiny API layer that satisfies all the traditional CRUD operation. I am now using a package called 'sourced' and trying to play around with it (Using Nodejs).</p>&#xA;&#xA;<p>However, I came to realize that the event sourcing is not quite useful when it is used alone. usually, it is coupled with CQRS.</p>&#xA;&#xA;<p>My understanding of the CQRS is, when the UI sends a write command to the server. the app does some validation towards the data. and saves it in the event store(I am using mongoDB), for example: here is what my event store should look like:</p>&#xA;&#xA;<pre><code>{method:""createAccount"",name:""user1"", account:1}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""withdraw"",name:""user1"",account1,amount:250}&#xA;</code></pre>&#xA;&#xA;<p>It contains all the audit information rather than the eventual status.&#xA;however, I am confused how can I handle the read operation. what if I want to read the balance of an account. what exactly will happen?&#xA;here are my questions:</p>&#xA;&#xA;<ol>&#xA;<li>If we can not query the event store(database) directly for reading operation, then where should we query? should it be a cache in memory?</li>&#xA;<li>If we query the memory. is the eventual status already there or I have to do a replay (or left-fold) operation to calculate the result. for example, the balance of the account 1 is 50.</li>&#xA;<li>I found some bloggers talked about 'subscribe' or 'broadcast'. what are they and broadcast to who?</li>&#xA;</ol>&#xA;&#xA;<p>I will be really appreciated for any suggestion and please corret me if my understanding is wrong.</p>&#xA;"
45869766,How to get docker toolbox to work with .net core 2.0 project,2017-08-24 19:46:40,<c#><docker><asp.net-core><visual-studio-2017><microservices>,2,4412,3,14.0,20,"<p>I'm getting an error trying to use the Docker functionality with my .NET core 2.0 project. I've been getting an error message saying </p>&#xA;&#xA;<blockquote>&#xA;  <p>Visual Studio Container Tools requires Docker to be running before&#xA;  building, debugging or running a containerized project. For more info,&#xA;  please see: <a href=""http://aka.ms/DockerToolsTroubleshooting"" rel=""noreferrer"">http://aka.ms/DockerToolsTroubleshooting</a></p>&#xA;</blockquote>&#xA;&#xA;<p>I followed the link, and upon realizing I have Windows 10 Home x64, and had to install Docker Toolbox, instead of Docker For Windows. Now it installed this executable called </p>&#xA;&#xA;<blockquote>&#xA;  <p>Docker Quickstart Terminal</p>&#xA;</blockquote>&#xA;&#xA;<p>Is this the way one is supposed to start up that docker services? I have tried running this executable, and it seems to be working. My containers are running, but the error for Visual Studio Container Tools still persists. </p>&#xA;&#xA;<p>What am I missing? Is having a version of windows higher than Home required in order to use the Docker Container Support within Visual Studio 2017?</p>&#xA;&#xA;<p>UPDATE:</p>&#xA;&#xA;<p>I tried to follow Quetzcoatl's suggestion, and I am still getting the same error within visual studio about those tools. Here is what I ran in the Docker Quick Start Terminal. I tried building the project after Visual Studio successfully opened the project, and was still getting the aforementioned error regarding the container tools.</p>&#xA;&#xA;<p>My devenv.exe file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\devenv.exe</p>&#xA;</blockquote>&#xA;&#xA;<p>and my solution file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>D:\Development\Visual Studio\Musify2\Musify2\Musify2.sln</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/epqfT.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/epqfT.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>UPDATE 2:</strong></p>&#xA;&#xA;<p>I ran some of the suggested commands to try in the docker quickstart terminal and here were the results of those commands quetz<a href=""https://i.stack.imgur.com/nowpc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/nowpc.png"" alt=""enter image description here""></a></p>&#xA;"
40448015,Microservices Architecture in NodeJS,2016-11-06 09:54:11,<node.js><microservices>,2,3310,3,8.0,12,"<p>I was working on a side project and i deiced to redesign my Skelton project to be as Microservices, so far i didn't find any opensource project that follow this pattern. After a lot of reading and searching i conclude to this design but i still have some questions and thought.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N265s.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N265s.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Here are my questions and thoughts:</p>&#xA;&#xA;<ul>&#xA;<li>How to make the API gateway smart enough to load balnce the request if i have 2 node from the same microservice?</li>&#xA;<li>if one of the microservice is down how the discovery should know?</li>&#xA;<li>is there any similar implementation? is my design is right?</li>&#xA;<li>should i use Eureka or similar things?</li>&#xA;</ul>&#xA;"
29669180,"Microservice, service registry, API gateway and data sharing",2015-04-16 08:22:16,<java><web-services><rest><microservices>,1,3736,1,9.0,14,"<p>I m actually reading tones of articles concerning microservices architecture, but, it seems that they are dealing the things the easiest way possible, without going deeper in explanations.</p>&#xA;&#xA;<p>To explain you my questions, I will show you my actual little architecture :</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/0hqf5.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>So, here's what I want to use. Before making anything technically, I need more theorical informations.</p>&#xA;&#xA;<p><strong>Description of my domain</strong></p>&#xA;&#xA;<p>I have some mobile and browser based customers, able to connect themselves on an application, getting their user informations and able to consult billing informations about what they bought. </p>&#xA;&#xA;<p>On a monolithic application, I would use this architecture :&#xA;- Presentation layer with Mobile / Angular-Ember&#xA;- Business layer with a REST API with NGINX in front of that&#xA;- DAL with a standard MySQL database&#xA;- Scalability would be applied only on X-axis</p>&#xA;&#xA;<p>I want to use a microservice architecture in this case, because it's ""domain scalable"" and really flexible (and to learn a bit more about it of course).</p>&#xA;&#xA;<p>On the schema, in each service, there is the only HTTP URL exposed by the API concerned.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<p><strong>a/</strong> In the (1) flux, ""mobile"" send an http request on <a href=""http://myDomain.or/auth"" rel=""noreferrer"">http://myDomain.or/auth</a>.</p>&#xA;&#xA;<p>In my mind, the APIGateway is able to ask a standard Service Registry (Eureka, ZooKeeper, or something else) is able to find if a AuthSrv is accessible and can retrieve his network adress. Then the ApiGateway can request the AuthSrv and respond to the server</p>&#xA;&#xA;<p>Is that a good way to make it work ? Isn't there a latency problem when dealing with X machines to access a data ?</p>&#xA;&#xA;<p><strong>b/</strong> The flux (2) consults the service registry. How can the service registry understand that every requests on /auth, even on children url like /auth/other (if it was exposed) are related to this service on this address ip:port ?</p>&#xA;&#xA;<p><strong>c/</strong> The flux (3) is showing that the service registry has an available AuthSrv. The (3 bis) show the other : no AuthSrv is available. In a little application, we can admit that we lose sometime of disponibility, but in a big system, where hundred of services are linked, how can we handle service defficience ?</p>&#xA;&#xA;<p><strong>d/</strong> In an other post, I was asking how to store a billing information because it's related to a user, from another service, and another database.</p>&#xA;&#xA;<p>In a standard architecture I would have : </p>&#xA;&#xA;<pre><code>{&#xA;   billingInformations:{...},&#xA;   billingUser:ObjectId(""userId"")&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In a microservice architecture, somebody recommended to use :</p>&#xA;&#xA;<pre><code>{&#xA;    billingInformations:{...},&#xA;    billingUser:""/user/12365"" // URL corresponding the the user Ressource in the other service&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Is this the best way to handle ""service data sharing"" and not couple the services ?</p>&#xA;&#xA;<p><strong>e/</strong> When should I prefer using AMQP protocol instead of HTTP protocol in this specific case ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
29761872,Microservices and database joins,2015-04-21 02:34:10,<database><integration><microservices>,5,10558,2,18.0,55,"<p>For people that are splitting up monolithic applications into microservices how are you handling the connundrum of breaking apart the database.  Typical applications that I've worked on do a lot of database integration for performance and simplicity reasons.</p>&#xA;&#xA;<p>If you have two tables that are logically distinct (bounded contexts if you will) but you often do aggregate processing on a large volumes of that data then in the monolith you're more than likely to eschew object orientation and are instead using your database's standard JOIN feature to process the data on the database prior to return the aggregated view back to your app tier.</p>&#xA;&#xA;<p>How do you justify splitting up such data into microservices where presumably you will be required to 'join' the data through an API rather than at the database.</p>&#xA;&#xA;<p>I've read Sam Newman's Microservices book and in the chapter on splitting the Monolith he gives an example of ""Breaking Foreign Key Relationships"" where he acknowledges that doing a join across an API is going to be slower - but he goes on to say if your application is fast enough anyway, does it matter that it is slower than before?</p>&#xA;&#xA;<p>This seems a bit glib?  What are people's experiences?  What techniques did you use to make the API joins perform acceptably?</p>&#xA;"
29644916,Microservice Authentication strategy,2015-04-15 08:10:33,<authentication><architecture><microservices>,4,35930,7,47.0,92,"<p>I'm having a hard time choosing a decent/secure authentication strategy for a microservice architecture. The only SO post I found on the topic is this one: <a href=""https://stackoverflow.com/questions/25595492/single-sign-on-in-micro-service-architecture"">Single Sign-On in Microservice Architecture</a></p>&#xA;&#xA;<p>My idea here is to have in each service (eg. authentication, messaging, notification, profile etc.) a unique reference to each user (quite logically then his <code>user_id</code>) and the possibility to get the current user's <code>id</code> if logged in.</p>&#xA;&#xA;<p>From my researches, I see there are two possible strategies:</p>&#xA;&#xA;<h3>1. Shared architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/po7Qr.png"" alt=""Shared architecture""></p>&#xA;&#xA;<p>In this strategy, the authentication app is one service among other. But each service must be able to make the conversion <code>session_id</code> => <code>user_id</code> so it must be dead simple. That's why I thought of Redis, that would store the key:value <code>session_id:user_id</code>.</p>&#xA;&#xA;<h3>2. Firewall architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/NHGjh.png"" alt=""Firewall architecture""></p>&#xA;&#xA;<p>In this strategy, session storage doesn't really matter, as it is only handled by the authenticating app. Then the <code>user_id</code> can be forwarded to other services. I thought of Rails + Devise (+ Redis or mem-cached, or cookie storage, etc.) but there are tons of possibilities. The only thing that matter is that Service X will never need to authenticate the user.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How do those two solutions compare in terms of:</p>&#xA;&#xA;<ul>&#xA;<li>security</li>&#xA;<li>robustness</li>&#xA;<li>scalability</li>&#xA;<li>ease of use</li>&#xA;</ul>&#xA;&#xA;<p>Or maybe you would suggest another solution I haven't mentioned in here?</p>&#xA;&#xA;<p>I like the solution #1 better but haven't found much default implementation that would secure me in the fact that I'm going in the right direction.</p>&#xA;&#xA;<p>I hope my question doesn't get closed. I don't really know where else to ask it.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
41731704,Use docker-compose with multiple repositories,2017-01-19 00:16:29,<docker><docker-compose><microservices>,1,3197,0,1.0,11,"<p>I'm currently struggling with the deployment of my services and I wanted to ask, what's the proper way when you have to deal with multiple repositories. The repositories are independent, but to run in production, everything needs to be launched.</p>&#xA;&#xA;<p>My Setup:</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Backend:&#xA;&#xA;<ul>&#xA;<li>Backend Project Rails</li>&#xA;<li>docker-compose: backend(expose 3000), db and redis</li>&#xA;</ul></li>&#xA;<li>Git Repository Frontend&#xA;&#xA;<ul>&#xA;<li>Express.js server</li>&#xA;<li>docker-compose: (expose 4200)</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>Both can be run independently and test can be executed by CI</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Nginx for Production&#xA;&#xA;<ul>&#xA;<li>Needs to connect to the other two services (same docker network)</li>&#xA;<li>forwards requests to the right service</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I have already tried to include the two services as submodules into the Nginx repository and use the docker-compose of the nginx repo, but I'm not really happy with it.  </p>&#xA;"
41795612,How to deploy microservices on Heroku,2017-01-22 20:09:47,<heroku><architecture><jhipster><microservices>,1,3183,1,4.0,11,"<p>I have read a lot about microservices, and would like to build my app with that approach. What I know so far is that I nead some services like:</p>&#xA;&#xA;<ul>&#xA;<li><strong>load balancer</strong> - to deal with every request, and push it forward to another services</li>&#xA;<li><strong>authorization service</strong> - to authorize my users</li>&#xA;<li><strong>database</strong> - for my microservices. I would like to use one instance of DB with different schemas for every service.</li>&#xA;<li><strong>service A</strong> - for functionality A</li>&#xA;<li><p><strong>service B</strong> - for functionality B</p></li>&#xA;<li><p>etc. etc. etc.</p></li>&#xA;</ul>&#xA;&#xA;<p>I found out, that Heroku is interesting place to deploy applications. My problem is that I completely don't understand they ideology. What I have done so far, is creation/registration of few ""apps"":</p>&#xA;&#xA;<ul>&#xA;<li>my-app-auth</li>&#xA;<li>my-app-load-balancer</li>&#xA;<li>etc. etc.</li>&#xA;</ul>&#xA;&#xA;<p>I see, that Heroku gives me some public hostname for every of that app, and this is where my concerns starts. Should I deploy my internal services with public hostnames? I don't think so. And here my question comes:</p>&#xA;&#xA;<p>Can anyone provide me some guidelines, how to deal with microservices on Heroku? How should i deploy them? How should I define my load balancer, and hook internal services to it? What is JHipster? Do I need it? How can I use it? Should I use Heroku tools (for example CLI) or can I stay with my gitlab repo? I can't find any point of grasp on the Internet, about that.</p>&#xA;"
50986816,How to handle HTTP requests in a Microservice / Event Driven Architecture?,2018-06-22 11:20:06,<node.js><rest><websocket><apache-kafka><microservices>,6,455,1,8.0,16,"<p><strong>Background:</strong></p>&#xA;&#xA;<p>I am building an application and the proposed architecture is Event/Message Driven on a microservice architecture. </p>&#xA;&#xA;<p>The monolithic way of doing thing is that I've a <code>User/HTTP request</code> and that actions some commands that have a direct <code>synchronous response</code>. Thus, to respond to the same User/HTTP request is 'hassle free'.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rP5nf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rP5nf.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The problem:</strong></p>&#xA;&#xA;<p>The user sends an <code>HTTP request</code> to the <strong>UI Service</strong> (there are multiple UI Services) that fires some events to a queue (Kafka/RabbitMQ/any). a N of services picks up that Event/Message do some magic along the way and <strong>then at some point that same UI Service should pick that up a response and give that back to the user that originated HTTP request.</strong> Request processing is <code>ASYNC</code> but the <code>User/HTTP REQUEST-&gt;RESPONSE</code> is <code>SYNC</code> as per your typical HTTP interaction.</p>&#xA;&#xA;<p><strong>Question:</strong>&#xA;How do I send a response to the same UI Service that originated the action (The service thats interacting with the user over HTTP) in this Agnostic/Event driven world?</p>&#xA;&#xA;<p><strong>My research so far</strong> &#xA;I've been looking around and it seems that some people are solving that problem using WebSockets.</p>&#xA;&#xA;<p>But the layer of complexity is that there needs to be some table that maps <code>(RequestId-&gt;Websocket(Client-Server))</code> which is used to ‘discover’ which node in the gateway has the websocket connection for some particular response. But even if I understand the problem and complexity I'm stuck that I can't find any articles that would give me info on how to solve this problem at the implementation layer. <strong>AND</strong> this still is not a viable option because of 3rd party integrations such as payments providers(WorldPay) that expect <code>REQUEST-&gt;RESPONSE</code> - specially on the 3DS validation.</p>&#xA;&#xA;<p>So I am somehow reluctant to think that WebSockets is an option. But even if WebSockets are ok for Webfacing apps, for API that connects to external systems is not a great architecture.</p>&#xA;&#xA;<p>** ** ** <strong>Update:</strong> ** ** ** </p>&#xA;&#xA;<p>Even if long polling is an possible solution for a WebService API with a <code>202 Accepted</code> a <code>Location header</code> and a <code>retry-after header</code> it wouldn't be performant for a high concurrency &amp; high ability website. &#xA;Imagine a huge number of people trying to get the transaction status update on EVERY request they make and you have to invalidate CDN cache (go and play with that problem now! ha).</p>&#xA;&#xA;<p>But most important and relatable to my case I've 3rd party APIs such as payment systems where the 3DS systems have automatic redirects that are handled by the payment provider system and they expect a typical <code>REQUEST/RESPONSE flow</code>, thus this model would not work for me nor the sockets model would work. </p>&#xA;&#xA;<p>Because of this use-case the <code>HTTP REQUEST/RESPONSE</code> should be handled in the typical fashion where i have a dumb client that expect that the complexity of the precessing is handled in back-end.</p>&#xA;&#xA;<p><strong>So i am looking for a solution where externally I have a typical <code>Request-&gt;Response</code>(SYNC) and the complexity of the status(ASYNCrony of the system) is handled internally</strong> </p>&#xA;&#xA;<p>An example of the long polling, but this model wouldn't work for 3rd party API such as payments provider on <code>3DS Redirects</code> that are not within my control.</p>&#xA;&#xA;<pre><code> POST /user&#xA;    Payload {userdata}&#xA;    RETURNs: &#xA;        HTTP/1.1 202 Accepted&#xA;        Content-Type: application/json; charset=utf-8&#xA;        Date: Mon, 27 Nov 2018 17:25:55 GMT&#xA;        Location: https://mydomain/user/transaction/status/:transaction_id&#xA;        Retry-After: 10&#xA;&#xA;GET &#xA;   https://mydomain/user/transaction/status/:transaction_id&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rznNC.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rznNC.png"" alt=""enter image description here""></a></p>&#xA;"
42487685,How to inject module from different app in Node.js,2017-02-27 14:02:36,<javascript><node.js><express><amd><microservices>,4,434,3,4.0,9,"<p>I've two node apps/services that are running together, &#xA;1. main app&#xA;2. second app</p>&#xA;&#xA;<p>The main app is responsible to show all the data from diffrent apps at the end. Now I put some code of the second app in the main app and now its working, but I want it to be decoupled. I mean that the code of the secnod app will not be in the main app (by somehow to inject it on runtime )</p>&#xA;&#xA;<p>like the second service is registered to the main app in inject the code of it.&#xA;the code of it is just two modules ,is it possible to do it in nodejs ?</p>&#xA;&#xA;<pre><code>const Socket = require('socket.io-client');&#xA;const client = require(""./config.json"");&#xA;&#xA;module.exports =  (serviceRegistry, wsSocket) =&gt;{&#xA;    var ws = null;&#xA;    var consumer = () =&gt; {&#xA;        var registration = serviceRegistry.get(""tweets"");&#xA;        console.log(""Service: "" + registration);&#xA;        //Check if service is online&#xA;        if (registration === null) {&#xA;            if (ws != null) {&#xA;                ws.close();&#xA;                ws = null;&#xA;                console.log(""Closed websocket"");&#xA;            }&#xA;            return&#xA;        }&#xA;        var clientName = `ws://localhost:${registration.port}/`&#xA;        if (client.hosted) {&#xA;            clientName = `ws://${client.client}/`;&#xA;        }&#xA;        //Create a websocket to communicate with the client&#xA;        if (ws == null) {&#xA;            console.log(""Created"");&#xA;            ws = Socket(clientName, {&#xA;                reconnect: false&#xA;            });&#xA;            ws.on('connect', () =&gt; {&#xA;                console.log(""second service is connected"");&#xA;            });&#xA;            ws.on('tweet', function (data) {&#xA;                wsSocket.emit('tweet', data);&#xA;            });&#xA;            ws.on('disconnect', () =&gt; {&#xA;                console.log(""Disconnected from blog-twitter"")&#xA;            });&#xA;            ws.on('error', (err) =&gt; {&#xA;                console.log(""Error connecting socket: "" + err);&#xA;            });&#xA;        }&#xA;    }&#xA;    //Check service availability&#xA;    setInterval(consumer, 20 * 1000);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In the main module I put this code and I want to decouple it by inject it somehow on runtime ? example will be very helpful ... </p>&#xA;"
37915326,How to keep DB in sync when using microservices architecture?,2016-06-20 05:47:00,<architecture><microservices>,3,3503,0,3.0,9,"<p>Im about to learn how microservices architecture work. So far i unserstood that each microservice need its own database, which make sense. </p>&#xA;&#xA;<p>So lets say we have a customer microservice which is responsible for creating a customer and returning a list of customers. The service will ofcource have it own customer DB. </p>&#xA;&#xA;<p>Lets say we have very high load on this ervice, so we chooce to scale out 20x. </p>&#xA;&#xA;<p>Så we have 20 microservices and each have its own DB, and all the services is behind a load balancer. </p>&#xA;&#xA;<p>Now a client wants to create a customer, load balancer sends client request to service 9/20, and the customer is created. </p>&#xA;&#xA;<p>On the next request the same client wants to be sure that customer is created and want to view the list of the customers, on the request LB sends him to service 11/20. </p>&#xA;&#xA;<p>Now how do i make sure that service 9/20 synced the newly created customer to the db of service 11/20?</p>&#xA;&#xA;<p>In MSSQL there are functionality to keep DB in sync by before alowing the initial commit, to save the data in all the other databases first, but this approach will give problems in the long run, because the more services there are the longer time it will take to make a commit?</p>&#xA;"
37897058,"How to properly setup documentation for Restful services in a micro-service architecture (HAL, ALPS)",2016-06-18 12:39:04,<java><spring><spring-data><spring-data-rest><microservices>,2,391,1,0.0,9,"<p>I have been reading a lot about how to setup Microservices properly and I have been getting hung up with some of the more recent concepts including: HAL, ALPS, and the HAL Browser.  I have historically documented things leveraging Swagger UI, however, I am coming to understand that URL centric isn't the proper way and I should be organizing documentation around resources and links which is what the newer technologies are for.  I have quite a few knowledge gaps around these newer concepts, so I wanted to get a proper understanding of how these technologies work together so as I learn about each I can fit them into the puzzle.</p>&#xA;&#xA;<p>My current understanding is:</p>&#xA;&#xA;<p><b>HAL</b> - Is an additional format on top of JSON that will let you navigate through your API via links.</p>&#xA;&#xA;<p><b>ALPS</b> - It is an additional format on top of JSON that can let me provide English based descriptions to help describe my resources</p>&#xA;&#xA;<p><b>HAL Browser</b> - Swagger UI replacement for Resource and Link centric documentation.  Works with both HAL and ALPS together?</p>&#xA;&#xA;<p>Would my current understanding of these technologies be accurate or lacking in some areas?  Also implementation wise I am not fully understanding how the ALPS and HAL are interacting together.  I was aware of a hal+json format and a alps+json format, but I haven't seen a hal+alps+json format.</p>&#xA;&#xA;<p>The last area I would like to clear up is how I should be exposing these resources.  Typically I always had a focus on very lean json messages is sending the hal+json format around the expected or should I be hosting those endpoints at another URL specifically for documentation similar to swagger / HAL browser?</p>&#xA;"
45208766,Microservices Why Use RabbitMQ?,2017-07-20 07:57:56,<rabbitmq><microservices>,2,5165,1,3.0,9,<p>I haven't found an existing post asking this but apologize if I missed it. </p>&#xA;&#xA;<p>I'm trying to get my head round microservices and have come across articles where RabbitMQ is used. I'm confused why RabbitMQ is needed. Is the intention that the services will use a web api to communicate with the outside world and RabbitMQ to communicate with each other?</p>&#xA;
51541318,How do I resolve the authors names of books in microservice world?,2018-07-26 14:30:41,<node.js><amazon-web-services><aws-lambda><microservices>,4,165,1,1.0,11,"<p>So I'm starting a journey down the road of microservices. I've spent some hours online trying immerse myself into this topic. </p>&#xA;&#xA;<p>One concept I'm not quite grasping yet is the idea of <strong>not using SQL joins</strong> and therefore having a small independent database for authors and the same for books.</p>&#xA;&#xA;<p>So I understand the following SQL:</p>&#xA;&#xA;<pre><code>BooksTable - id, name, authorid&#xA;AuthorsTable - id, name&#xA;&#xA;select book.name, author.name from book &#xA;join author on book.authorId = author.id&#xA;</code></pre>&#xA;&#xA;<p>In Node.js world</p>&#xA;&#xA;<p><strong>index.js</strong></p>&#xA;&#xA;<pre><code>app.get('/api/books' bookDomain.get());&#xA;</code></pre>&#xA;&#xA;<p><strong>bookDomain.js</strong></p>&#xA;&#xA;<pre><code>exports.get = () =&gt; {&#xA;  const books = bookService.get();&#xA;&#xA;  const authors = authorService.get();&#xA;&#xA;  /*&#xA;    This is where I'm lost: how do you achieve the simple SQL &#xA;    above? I'm assuming in the domain is where this information is &#xA;    ""joined""? am I correct?&#xA;  */&#xA;};&#xA;</code></pre>&#xA;&#xA;<p><strong>Services</strong></p>&#xA;&#xA;<pre><code>Database1&#xA;**bookService.js**&#xA;database context&#xA;&#xA;Database2&#xA;**authorService.js**&#xA;database context&#xA;</code></pre>&#xA;&#xA;<p><strong>expected data</strong> (something like it, basically i'm saying JSON should be the return type)</p>&#xA;&#xA;<pre><code>[{&#xA;  book {&#xA;    ""name"": ""Book 1"",&#xA;    ""author"": ""Author Name 1""&#xA;  }&#xA;},&#xA;{&#xA;  book {&#xA;    ""name"": ""Book 2"",&#xA;    ""author"": ""Author Name 2""&#xA;  }&#xA;}]&#xA;</code></pre>&#xA;"
45625886,REST vs gRPC: when should I choose one over the other?,2017-08-11 02:09:34,<rest><kubernetes><microservices><docker-swarm><grpc>,3,3474,1,3.0,14,"<p>I see more and more software organizations using gRPC in their service-oriented architectures, but people are also still using REST. In what use cases does it make sense to use gRPC, and when does it make sense to use REST for inter-service communication?</p>&#xA;&#xA;<p>Interestingly, I've come across open source projects that use both REST and gRPC. For instance, Kubernetes and Docker Swarm all employ gRPC to some extent for cluster coordination, but also expose REST APIs for interfacing with master/leader nodes. Why not use gRPC up and down?</p>&#xA;"
31468806,Identity management with multiple spring boot micro services,2015-07-17 05:17:05,<spring><spring-boot><single-sign-on><microservices><identity-management>,2,918,1,0.0,0,"<p>I have multiple spring boot applications for difference purposes. &#xA;For example, mobile clients send their GPS coordinates to one spring boot micro service and at the same time, these mobile client access another spring boot micro service to do their CRUD operations. </p>&#xA;&#xA;<p>I'm facing with a problem of authenticating clients. I don't want do the authentication at all the services. Rather I would like to do this by using another identity management server (ex: Kerberos)  which produce a SSO token for all these micro services.</p>&#xA;&#xA;<p>OR a proxy which authenticates all the incoming requests and delegates them to relevant micro service.</p>&#xA;&#xA;<p>I searched couple of hours and I couldn't find any solid information on securing micro services even in general.</p>&#xA;&#xA;<ol>&#xA;<li>The design or architecture I'm taking is correct? </li>&#xA;<li>What is the best approach for this kind of a situation?</li>&#xA;<li>How can I implement this identity server/proxy who does the authentication?</li>&#xA;<li>Any technology, known identity mgmt servers which can easily integrate with Spring, known design patterns are there?</li>&#xA;</ol>&#xA;&#xA;<p>One question more,&#xA;It is OK to implement same authentication layer at each of these services?&#xA;(Because I think it is bad and I may wrong with that)</p>&#xA;&#xA;<p>I would like to stick with Spring.</p>&#xA;&#xA;<p>Highly appreciate if someone can direct me to a correct path.</p>&#xA;"
33431076,Environment variables inheritance with microservices (Laravel & Lumen),2015-10-30 07:52:01,<php><laravel><inheritance><environment-variables><microservices>,1,399,6,0.0,0,"<p>Recently I ran into a problem while deploying a <strong>Lumen</strong> microservice next to a <strong>Laravel</strong> app. On the same machine I have a Laravel app and a Lumen app both with different <code>.env</code> file and the default environment variables (<code>APP_ENV</code>, <code>DB_HOST</code>, <code>DB_DATABASE</code>, etc).</p>&#xA;&#xA;<p>My <strong>Laravel</strong> app needs to make a request the the <strong>Lumen</strong> app to get some data. That's when the problem occures. When the <strong>Lumen</strong> app receives the request it also inherits the <strong>Laravel</strong>'s environment variables, making it impossible to do it's job (to connect to the database or other services that have the environment variables set in the <code>.env</code> file because all the variables are inherited from the parent request).</p>&#xA;&#xA;<p>Has anyone encountered this problem before? Am I using the microservices architecture the right way?</p>&#xA;&#xA;<p><strong>Update</strong> with code.</p>&#xA;&#xA;<p><em>Laravel app - UsersController.php</em> </p>&#xA;&#xA;<pre><code>/**&#xA; * Makes a request to the Core API and fills properties with the response data&#xA; *&#xA; * @param $method&#xA; * @param $uri&#xA; * @param array|null $data&#xA; */&#xA;public function request($method, $uri, array $data = null)&#xA;{&#xA;    $this-&gt;api = new Client(['base_uri' =&gt; 'http://127.0.0.1/']);&#xA;&#xA;    if (property_exists($this, 'uriPrefix')) $uri = $this-&gt;uriPrefix . $uri;&#xA;    $requestOptions = [&#xA;        'http_errors'   =&gt; false,&#xA;        'headers' =&gt; ['Accept' =&gt; 'application/json']&#xA;    ];&#xA;    if (session('api_cookie')) $requestOptions['headers']['Cookie'] = implode(';', session('api_cookie'));&#xA;    if ($data) {&#xA;        if ($method == 'GET') $requestOptions['query'] = $data;&#xA;        else if (($method == 'POST') || ($method == 'PUT')) $requestOptions['form_params'] = $data;&#xA;    }&#xA;&#xA;    $response = $this-&gt;api-&gt;request($method, $uri, $requestOptions);&#xA;&#xA;    session(['api_cookie' =&gt; $response-&gt;getHeader('Set-Cookie')]);&#xA;&#xA;    $this-&gt;responseCode = $response-&gt;getStatusCode();&#xA;    $this-&gt;responseReasonPhrase = $response-&gt;getReasonPhrase();&#xA;    $this-&gt;responseData = $response-&gt;getBody();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I make this request the <strong>Lumen</strong> app can't connect to the database because it inherits the <code>DB_</code> environment variables from the parent <strong>Laravel</strong> app.</p>&#xA;"
29148547,Spring Security OAuth2 AuthorizationServer,2015-03-19 15:22:41,<spring-security><spring-security-oauth2><microservices>,1,854,0,0.0,0,"<p>I'm playing around with spring-security-oauth2. I try to build some microservices with an authentication backend. </p>&#xA;&#xA;<p>I set up an simple spring boot project with the following dependencies</p>&#xA;&#xA;<pre><code>    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.2.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>and one Configuration Class</p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class SecurityConfiguration {&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""clientDetailsServiceBean"")&#xA;    private ClientDetailsService clientDetailsService;&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""userDetailsServiceBean"")&#xA;    private UserDetailsService userDetailsService;&#xA;&#xA;    @Configuration&#xA;    @EnableWebSecurity&#xA;    @EnableGlobalMethodSecurity(jsr250Enabled = true, securedEnabled = true, prePostEnabled = true)&#xA;    public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {&#xA;&#xA;        @Override&#xA;        @Bean(name = ""authenticationManagerBean"")&#xA;        public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;            return super.authenticationManagerBean();&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;            auth.userDetailsService(userDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(HttpSecurity http) throws Exception {&#xA;            http.authorizeRequests().anyRequest().permitAll().and().userDetailsService(userDetailsService).formLogin().and().httpBasic();&#xA;        }&#xA;    }&#xA;&#xA;    @Configuration&#xA;    @EnableAuthorizationServer&#xA;    public class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;        @Autowired&#xA;        @Qualifier(""authenticationManagerBean"")&#xA;        private AuthenticationManager authenticationManager;&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;            endpoints.authenticationManager(authenticationManager).tokenStore(tokenStore());&#xA;        }&#xA;&#xA;        @Bean&#xA;        public ApprovalStore approvalStore() throws Exception {&#xA;            TokenApprovalStore store = new TokenApprovalStore();&#xA;            store.setTokenStore(tokenStore());&#xA;            return store;&#xA;        }&#xA;&#xA;        @Bean&#xA;        public TokenStore tokenStore() {&#xA;            return new InMemoryTokenStore();&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;            clients.withClientDetails(clientDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {&#xA;            security.checkTokenAccess(""permitAll()"");&#xA;            security.allowFormAuthenticationForClients();&#xA;        }&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>My Implementation of Client- and UserDetailsService are very simple and always returns an object</p>&#xA;&#xA;<pre><code>@Service(""clientDetailsServiceBean"")&#xA;public class ClientDetailsServiceBean implements ClientDetailsService {&#xA;&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(ClientDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public ClientDetails loadClientByClientId(String clientId) throws ClientRegistrationException {&#xA;        LOGGER.info(""Load client {}"", clientId); &#xA;        BaseClientDetails details = new BaseClientDetails();&#xA;        details.setClientId(clientId);&#xA;        details.setAuthorizedGrantTypes(Arrays.asList(""password"", ""refresh_token"", ""client_credentials""));&#xA;        details.setScope(Arrays.asList(""trust""));&#xA;        details.setAutoApproveScopes(Arrays.asList(""trust""));&#xA;        details.setAuthorities(Arrays.asList(new SimpleGrantedAuthority(""client_role2"")));&#xA;        details.setResourceIds(Arrays.asList(""clients""));&#xA;        details.setClientSecret(""secret"");&#xA;&#xA;        return details;&#xA;    }&#xA;&#xA;}&#xA;@Service(""userDetailsServiceBean"")&#xA;public class UserDetailsServiceBean implements UserDetailsService {&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(UserDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {&#xA;        LOGGER.info(""Load user {}"", username);&#xA;        return new User(username, ""password"", Arrays.asList(new SimpleGrantedAuthority(""ROLE_USER"")) );&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But, when i try to receive an accessToken via</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Full authentication is required to access this resource"" and when i try</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret --user web_client:secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Bad credentials"". From my point of view both should work, but it seems like my configuration is missing. </p>&#xA;&#xA;<p>There are other things with OAuth that unclear to me:&#xA;I try to build an spring-mvc application with spring-security and a custom login form. It's possible to handle token request and refresh cycles by spring security without redirect to the authentication app?</p>&#xA;&#xA;<p>In case of event driven application, it's possible to ensure the token is valid? In case of failure, the user clicks on button and an event is written but the processing of this will be hours later. How can i process the event with the user credentials?</p>&#xA;"
35179495,Spring Boot Microservices Deployment,2016-02-03 14:16:51,<spring-boot><microservices>,3,542,0,0.0,0,"<p>Has anyone deployed multiple instances of the same microservice? If so, how are you managing such deployments?</p>&#xA;"
33033834,how do I migrate a Java interface to a microservice?,2015-10-09 08:47:54,<java><rest><microservices>,3,764,0,0.0,0,"<p>I am looking at microservices, and the possibility of migrating some of our code to this architecture.  I understand the general concept but am struggling to see how it would work for our example.</p>&#xA;&#xA;<p>Supposing I have an interface called <code>RatingEngine</code> and an implementation called <code>RatingEngineImpl</code>, both running inside my monolithic application.  The principle is simple - The <code>RatingEngineImpl</code> could run in a different machine, and be accessed by the monolithic application via (say) a REST API, serializing the DTOs with json over http.  We even have an interface to help with this decoupling.</p>&#xA;&#xA;<p>But how do I actually go about this?  As far as I can see, I need to create a new implementation of the interface for the rump monolith (ie now the client), which takes calls to the interface methods, converts them into a REST call, and sends them over the network to the new 'rating engine service'.  Then I also need to implement a new http server, with an endpoint for each interface method, which then deserializes the DTOs (method parameters) and routes the call to our original <code>RatingEngineImpl</code>, which sits inside the server.  Then it serializes the response and sends it back to the client.  </p>&#xA;&#xA;<p>So that seems like an awful lot of plumbing code.  It also adds maintenance overhead, since if you tweak a method in the interface you need to make changes in two more places.</p>&#xA;&#xA;<p>Am I missing something?  Is there some clever way we can automate this boilerplate code construction?</p>&#xA;"
30800908,Dropwizard Jersey Client Sample,2015-06-12 10:32:45,<jersey><dropwizard><microservices>,2,1941,3,0.0,0,"<p>Dropwizard <strong><a href=""http://www.dropwizard.io/manual/client.html"" rel=""nofollow"">official documentation</a></strong> jersey Client isn't testable, someone have a dropwizard jersey client sample?</p>&#xA;"
28581644,Protect Kafka against flood,2015-02-18 10:45:27,<security><apache-kafka><microservices>,3,174,0,0.0,0,"<p>I use Kafka in production. Many services send and read messages into it.</p>&#xA;&#xA;<p>All work fine but I had a bug in one service.&#xA;For a weird reason this one sends millions messages by second to Kafka.</p>&#xA;&#xA;<p>Due to this bug, my Kafka crashes.</p>&#xA;&#xA;<p>It's not a Kafka bug but how can I protect it against potential flood ?</p>&#xA;"
33180090,Spring security Post Requests,2015-10-16 21:50:29,<spring><spring-security><microservices>,1,1204,0,0.0,0,"<p>Im following this guide <code>https://spring.io/guides/gs/securing-web/guide</code> to set up spring security for my microservice</p>&#xA;&#xA;<p>Im just sending basic POST and GET requests. I can do GET requests but when I try for POST requests I get a 403 error.(""Expected CSRF token not found. Has your session expired?"")&#xA;Im trying to set up basic authentication for my microservice</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
33194778,Keyword Search in microservices based architecture,2015-10-18 05:51:39,<search><solr><microservices>,1,1009,0,2.0,0,<p>I need some advice as to how a search needs to be implemented to search keywords within relational databases owned by microservices.&#xA;I have some microservices with their own relational DB. These microservices are likely to be deployed in a docker container.&#xA;What would be the best way to use a search engine like Apache SOLR so that each of the microservices' database can be indexed and we can achieve keyword search</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;
32750861,Using search in grails 3.x web-micro rest call does not work,2015-09-23 23:03:17,<grails><microservices>,1,80,3,0.0,0,"<p>I'm using the web-micro profile from Grails 3.x to write microservices.  I need to be able to search on one of the fields.  I believe in previous versions of grails, you could add the fields to the query string. </p>&#xA;&#xA;<p><a href=""http://localhost:3141/zipcode?zip=55509"" rel=""nofollow"">http://localhost:3141/zipcode?zip=55509</a> would return just the zipcode object(s) that had that value for zip.</p>&#xA;&#xA;<p>This does not seem to work in Grails 3.x web-micro.</p>&#xA;&#xA;<pre><code>@Entity &#xA;@Resource(uri=""/zipcode"") &#xA;class ZipCode { &#xA;    static belongsTo = [kingdomGroup : KingdomGroup] &#xA;    String zip &#xA;&#xA;    static constraints = { &#xA;    }&#xA;&#xA;    String toString() { zip } &#xA;}&#xA;</code></pre>&#xA;"
49113488,Distributed Database Design style for micro service-oriented architecture,2018-03-05 15:09:55,<spring-boot><microservices><distributed-database>,3,246,0,1.0,0,"<p>I am trying to convert one monolithic application into micro service oriented architecture style. Back end I am using spring , spring boot frameworks for development. Front-end I am using angular 2. And also using postgreSQL as database. &#xA;        Here my confusion is that , when I am designing my databases as distributed, according to functionalities it may contain  5 databases. Means I am designing according to vertical partition. Then I am thinking to implement inter-microservice communication services to achieve the entire functionality. </p>&#xA;&#xA;<p>The other way I am thinking that to horizontally partition the current structure. So my domain is based on some educational university. So half of university go under one DB and remaining will go under another DB. And deploy services according to Two region(two for two set of university). </p>&#xA;&#xA;<p>Currently I am decided to continue with the last mentioned approach. I am new to these types of tasks, since it referring some architecture task. Also I am beginner to this microservice and distributed database world. So Can anyone help me to confirm that my approach will give solution to my issue? Can I continue with my second approach - Horizontal partitioning of databases according to domain object? </p>&#xA;"
49226015,How to isolate services in choreography service composition,2018-03-11 22:58:24,<architecture><microservices><distributed-computing><service-composition>,1,55,1,2.0,0,"<p>I always encourage to design each service without knowing other services exists (isolated). </p>&#xA;&#xA;<p>Few days ago, i was reading about the cons and pros of choreography over orchestration in micro service architecture, i came across this topic that, &#xA;Lets say we have a system which consist of 3 services: ordering, payment, shipment. if i use a orchestrator, the orchestrator knows when and how to call each service. in fact its duty is to know how and when call what service, but in choreography, i have no idea when payment service does not know the ordering service exists how its gonna subscribe to its event (for sure at least ordering system needs to have payment models)?</p>&#xA;&#xA;<p>i become more confuse when i start to think that, if we have a method in ordering service which returns the ordering information followed by payment data and shipping data. how its going to return payment and shipping data?</p>&#xA;"
33869866,Microservice architecture implementation of CRM HRM and Domain design problems,2015-11-23 11:22:57,<architecture><domain-driven-design><crm><erp><microservices>,2,988,8,0.0,0,"<p>We are building a enterprise platform that consists of CRM, HRM, SALE, PROPERTY etc.&#xA;We are working on the microservice architecture.</p>&#xA;&#xA;<p><strong>The real question is:</strong>&#xA;CRM and HRM will be deployed as separate independent microservices but often these two microservices need to talk to each other. A HRM user creates a company contact employee and the HRM microservice API saves the information related to HRM inside HRM module in 'hrm' database while the employee details like name, surname, address etc will be saved to CRM database calling the CRM microservice APIs i.e. the Contact API saves the above info as contact of type 'Internal' or 'Employee'.&#xA;So basically what I am trying to do here is separating the data related to each microservices. </p>&#xA;&#xA;<p><strong>Is this way of domain design correct?</strong> or should I have to process and store all the information (entered by a HRM permissioned user) inside HRM module and 'hrm' database? such that we don't care CRM. And if so, CRM only seems to manage EXTERNAL contacts only? Will this have any future problems?</p>&#xA;"
36988921,What is a good event store/stream middleware for service-oriented/ microservice-architectures,2016-05-02 18:14:06,<events><soa><microservices><event-driven><event-stream>,2,196,4,0.0,0,"<p>I am building a microservice-architecture and I am looking for a good way to stream events.</p>&#xA;&#xA;<p>Currently I have a service that publishes an event that three other services need to react to in a certain way, however the reaction to this event shall happen only once. </p>&#xA;&#xA;<p>At the moment I am using RabbitMQ and my service publishes three messages in seperate queues, and each subscribing service listens to one queue. So, only one service instance can actually take the message and react to it. </p>&#xA;&#xA;<p>However, I do not like this approach, because if I want to add a new subscriber I have to add a new queue for the publishing service.</p>&#xA;&#xA;<p>I am basically looking for some kind of middleware on an event stream, that lets multiple services listen to one event, but makes sure that only one instance of each service actually reacts to the event.</p>&#xA;&#xA;<p>I haven't found anything yet, so I would appreciate suggestions.</p>&#xA;"
36920620,fastest mechanism to return large data from a micro-service,2016-04-28 16:38:11,<json><rest><http><redis><microservices>,1,323,6,1.0,0,"<p>I am new to the micro-service world.</p>&#xA;&#xA;<p>My micro-service has to return a large data (ballpark of 10-20 Mb).&#xA;The returned data contains <strong>large 2D arrays</strong> (""images"") and <strong>small structured data</strong> that can easily be represented with Json.</p>&#xA;&#xA;<p>Important: Both client and server are <strong>on the same machine</strong>.</p>&#xA;&#xA;<p>I have few options to return the data: </p>&#xA;&#xA;<ol>&#xA;<li>Encode the data to bytes array and send in the <strong>post</strong> body.</li>&#xA;<li>Encode only the ""images"" to binary and <strong>""multi-part"" post</strong> json + binary image1 + ... + binary imageN.</li>&#xA;<li>Write the data to a <strong>server resources</strong> (memory?)&#xA;and send the urls to client. The client will fetch the data with&#xA;few <strong>GET</strong> commands.</li>&#xA;<li>Write the data to <strong>Redis DB</strong> and send the client the&#xA;Redis address and data keys. The client will fetch the data with few&#xA;Redis readings.</li>&#xA;</ol>&#xA;&#xA;<p>What is <strong>fastest</strong> and the industry <strong>best known method</strong> to send back the results?</p>&#xA;"
40216362,Microservices and Messaging: Message Content,2016-10-24 10:39:10,<java><spring><rabbitmq><microservices>,3,112,0,0.0,0,"<p>I'm building an application that consists out of several microservices. One of the microservices, which is called Hera, manages users. Another microservice manages authorization and authentication. This microservice is called Zeus and is an implementation of Spring OAuth 2.0. </p>&#xA;&#xA;<p>When a user is created, updated or deleted in Hera, I'd like to replicate certain information to Zeus via RabbitMQ. This information includes the username, the user type (an enum) and a flag to indicate whether the user is enabled. </p>&#xA;&#xA;<p>I've already set up RabbitMQ and everything is working properly. The only thing I'm not certain about is the message body content. How should this information be packaged in the message? For instance, should I create a maven project containing the POJO with the required properties which will be marshalled and send via RabbitMQ and add dependency to this project in both Hera and Zeus? Or should I just add this information as a list of plain properties? </p>&#xA;&#xA;<p>I could not find any best practices or guidelines on this subject, so I'm asking you.</p>&#xA;&#xA;<p>Thank you in advance!</p>&#xA;"
40170212,how to add content-length to response headers when i use spring cloud to build my micro service,2016-10-21 06:56:58,<spring-boot><spring-cloud><microservices><netflix-zuul>,1,965,0,0.0,0,"<p>I have used spring cloud to build a multiple microservice,and i use a API-Gateway implemented using Spring Cloud Netfix's Zuul Server to route the requests to our micro services ,the gateway config like this:</p>&#xA;&#xA;<p>application.yml:</p>&#xA;&#xA;<pre><code>server:&#xA;port: 8021&#xA;&#xA;ribbon:&#xA;ConnectTimeout: 3000&#xA;ReadTimeout: 60000&#xA;&#xA;zuul:&#xA;ignoredServices: ""*""&#xA;add-proxy-headers: true&#xA;#prefix: /v1&#xA;&#xA;routes:&#xA;m_test:&#xA;path: /api/testService/**&#xA;sensitiveHeaders: ""*""&#xA;url: http://127.0.0.1:4008/testService/  &#xA;&#xA;eureka:&#xA;instance:&#xA;hostname: gateway&#xA;client:&#xA; registerWithEureka: true&#xA; fetchRegistry: true&#xA;serviceUrl:&#xA;  defaultZone: http://127.0.0.1:8761/eureka/&#xA;</code></pre>&#xA;&#xA;<p>CorsFilter.java:</p>&#xA;&#xA;<pre><code>@Component&#xA;@Order(Ordered.HIGHEST_PRECEDENCE)&#xA;public class CorsFilter implements Filter {&#xA;public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {&#xA;&#xA;    HttpServletResponse response = (HttpServletResponse) res;&#xA;    HttpServletRequest request = (HttpServletRequest) req;&#xA;    response.setHeader(""Access-Control-Allow-Origin"", ""*"");&#xA;    response.setHeader(""Access-Control-Allow-Methods"", ""POST, PUT, GET, OPTIONS, DELETE"");&#xA;    response.setHeader(""Access-Control-Allow-Headers"", ""Origin, X-Requested-With, Content-Type, Accept, Authorization,Content-length"");&#xA;    response.setHeader(""Access-Control-Max-Age"", ""1800"");&#xA;    Map&lt;String, String&gt; map = getHeadersInfo(request);&#xA;&#xA;    if (request.getMethod().equalsIgnoreCase(""OPTIONS"")) {&#xA;        response.setStatus(HttpServletResponse.SC_OK);&#xA;    } else {&#xA;        chain.doFilter(request, response);&#xA;    }&#xA;}&#xA;&#xA;public void init(FilterConfig filterConfig) {&#xA;}&#xA;&#xA;public void destroy() {&#xA;}&#xA;&#xA;private Map&lt;String, String&gt; getHeadersInfo(HttpServletRequest request) {&#xA;    Map&lt;String, String&gt; map = new HashMap&lt;&gt;();&#xA;    Enumeration headerNames = request.getHeaderNames();&#xA;    while (headerNames.hasMoreElements()) {&#xA;        String key = (String) headerNames.nextElement();&#xA;        String value = request.getHeader(key);&#xA;        map.put(key, value);&#xA;    }&#xA;&#xA;    return map;&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>GatewaySystemApplication.java:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableZuulProxy&#xA;@EnableEurekaClient&#xA;public class GatewaySystemApplication {&#xA;&#xA;public static void main(String[] args) throws Exception {&#xA;    //SpringApplication.run(GatewaySystemApplication.class, args);&#xA;    new SpringApplicationBuilder(GatewaySystemApplication.class).web(true).run(args);&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The browser response headers are like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jeFDo.png"" rel=""nofollow noreferrer"">passing through gateway layer response headers</a></p>&#xA;&#xA;<p>and the response header of my request miss the content-length,&#xA;but it has the content-length when i directly invoke backend service.<a href=""https://i.stack.imgur.com/2IYfM.png"" rel=""nofollow noreferrer"">directly response headers</a></p>&#xA;"
40132631,SocketTimeoutException : null while opening New Spring Starter Project,2016-10-19 13:21:23,<spring><web-services><spring-boot><microservices><eclipse-jee>,1,1497,0,0.0,0,"<p>SocketTimeoutException : null while opening New Spring Starter Project</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/uWW5K.png"" alt=""enter image description here""></p>&#xA;&#xA;<pre><code>JAVA_HOME=C:\Program Files (x86)\Java\jdk1.7.0_40&#xA;Path=%JAVA_HOME%\bin;C:\..&#xA;</code></pre>&#xA;"
40208887,"When utilizing a microservices architecture, will the underlying read/write database become a bottleneck?",2016-10-23 23:36:41,<sql><amazon-web-services><scalability><microservices>,3,348,1,0.0,0,"<p>As I described in the question, if I were to implement a microservices architecture, would the centralized read/write database become a bottleneck?</p>&#xA;&#xA;<p>To expand with an example, let's say I have three microservices: <code>users</code>, <code>teams</code>, and <code>team_members</code>. Each has its own microservice, but they all rely on each other in the database, so exclusive, parallel databases wouldn't be appropriate. Since microservices is meant to distribute the work to several different servers, doesn't the central database ultimately defeat the purpose of these microservices, as they all end up calling to the same server?</p>&#xA;"
40108015,Microservice's High availability concern on cloud,2016-10-18 12:15:58,<cloud><microservices>,1,230,3,0.0,0,"<p>I was reading about Microservices and everything makes sense to me but I have one little doubt.</p>&#xA;&#xA;<p>On cloud, every component has a availability SLA (lets assume 99.9%). So, if we have a single component to do a job, our application SLA would be the same (approx.). But if we create multiple components to do one job, our application's SLA would be reduced because all the components can go down at different time. In microservices, one service can communicate to other services to complete a task. Now, any of the participant service can be down at different time, So our application availability will be lesser compared to monolithic service?</p>&#xA;"
35914674,Cascading microservices using Meteor,2016-03-10 11:06:08,<meteor><package><cluster-computing><microservices>,1,169,11,1.0,0,"<p>I've been looking into scaling Meteor, and had an idea by using the <a href=""https://www.google.co.uk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi3z66g-7XLAhWDRhQKHS_qBwsQFggkMAA&amp;url=https%3A%2F%2Fgithub.com%2Fmeteorhacks%2Fcluster&amp;usg=AFQjCNEy9N5lo-9TmjFYvjgmCCO93mAwmg"" rel=""nofollow"">Meteor Cluster package</a>;</p>&#xA;&#xA;<ul>&#xA;<li>Create a super-service*, which the user connects to, containing general core packages to be used by every micro-service (api, app, salesSite, etc. would make use of its package),</li>&#xA;<li>The super-service then routes to the appropriate micro-service (e.g., the app), providing it with the functionality of its own packages.</li>&#xA;</ul>&#xA;&#xA;<p>(* - as in super- and sub-, not that it's awesome... I mean it is but...)</p>&#xA;&#xA;<p>The idea being that I can cascade each service as a superset of the super-service. This would also allow me to cleverly inherit functionality for other services in a cascading service style. E.g.,</p>&#xA;&#xA;<p>unauthedApp > guestApp > userApp > modApp > adminApp, </p>&#xA;&#xA;<p>for the application, where the functionality of the previous service are inherited to the preceding service (e.g., the further right along that chain, the more extra functionality is added and inherited).</p>&#xA;&#xA;<p>Is this possible?</p>&#xA;&#xA;<p>EDIT: If possible, is there a provided example of how to implement such a pattern using micro-services?</p>&#xA;&#xA;<p><strong>[[[[[ BIG EDIT #2: ]]]]]</strong></p>&#xA;&#xA;<p>Think I'm trying to make a solution fit the problem, so let me re-explain so this question can be answered based on the issue rather than the solution I'm trying to implement.</p>&#xA;&#xA;<p>Basically, I want to ""inherit"" (for lack of a better word) the packages depended on needed functionality, so that no code is unnecessarily sent through the wire. </p>&#xA;&#xA;<p>So starting with the core packages, which has libraries I want all of my services to have, I then want to further ""add"" the functionality as needed. Then I want to add page packages if serving a page-based service (instead of, say, the API service, which doesn't render pages), then the appropriate role-based page packages, etc., until the most specific packages are added.</p>&#xA;&#xA;<p>My thought was that I could make the services chain in such a way that I could traverse through from the most generic to most specific service, and that would finally end with a composition of packages from multiple services. So, for e.g., the guestApp, that might be the core packages + generic page packages + generic app packages + unauthApp packages + guestApp packages, so no unneccessary packages are added.</p>&#xA;&#xA;<p>Also with this imaginary pattern I'm describing, I don't need to add all my core packages to each microservice - I can deal with them all within the core package right at the top of the package traversal I've discussed above and not have to worry about forgetting to add the packages to the ""inherited"" packages.</p>&#xA;&#xA;<p>Hope my reasoning here makes sense, and I hope you guys know of a best practice for doing this. Thank you!</p>&#xA;"
32398245,Node.js + RabbitMQ + Socket.io,2015-09-04 12:35:57,<javascript><node.js><socket.io><rabbitmq><microservices>,1,728,3,1.0,0,"<p>We're in a project with a few microservices.<br>&#xA;We've got a microservice (A) that get's and saves data and publishes a message to RabbitMQ, stating new data has come in (with the CouchDB _id), so that another microservice(b) can process it.</p>&#xA;&#xA;<p>The problem lies in a third service where we've got a frontend that needs to be updated in 'real-time'.<br>&#xA;We're using Socket.io for the client updates, but the node.js instance get's the updates from A as well.</p>&#xA;&#xA;<p>The later is as followed:  </p>&#xA;&#xA;<pre><code>- RabbitMQ message comes in&#xA;- Order is being retrieved from A (HTTP Request)&#xA;- Data is processed (remapping for user interface, bla bla bla)&#xA;- Data is sent through Socket.io to the client.&#xA;</code></pre>&#xA;&#xA;<p>My problem is, how do I do this cleanly in node?</p>&#xA;&#xA;<p>I want to split the files (ofcourse), make each their own module and create a handler which 'knows' RabbitMQ and Socket.io, so it can process the data and send a message back up the queue when the client has done something with the data that needs to be processed and the other way around.</p>&#xA;&#xA;<p>If more info is needed, please tell me.</p>&#xA;"
32364506,Monolithic (vs) Micro-services ==> Threads (vs) Process,2015-09-02 22:58:59,<multithreading><process><docker><microservices>,1,1584,4,0.0,0,"<p>I have a monolithic application with single process having 5 threads. Each thread accomplishes certain specific task. Thinking to move this application to microservices using dockers. If I look at the architecture, each worker thread would become a docker process. So, in some way Monolithic vs Microservices becomes more like Thread vs Process discussion in my case. </p>&#xA;&#xA;<p>The original thinking of having the monolithic was to have threads for performance and share the same memory. Now with microservices arch, I am pushed to a process model that may not suit from performance point of view.</p>&#xA;&#xA;<p>I am kind of stuck on how to approach this problem.</p>&#xA;"
35589008,Advice on how to monitor (micro)services?,2016-02-23 21:54:58,<service><spring-boot><monitoring><microservices><spring-boot-actuator>,1,851,2,0.0,0,"<p>We are transitioning from building applications on monolith application servers, to more microservices oriented applications on Spring Boot. We will publish health information with SB Actuator through HTTP or JMX.</p>&#xA;&#xA;<p>What are the options/best practices to monitor services, that will be around 30-50 in total? Thanks for your input!</p>&#xA;"
35600997,ejabberd in a microservice network,2016-02-24 11:31:54,<xmpp><ejabberd><microservices><mongoose-im>,2,287,6,0.0,0,<p>I'm willing to use ejabberd / mongooseIm in a microservice network. XMPP should be our chat protocol aside from a REST API network. I want to send messages incoming at the xmpp server downstream to worker services. Has anybody done this or could lead me into the right direction? </p>&#xA;&#xA;<p>My first thoughts are using RabbitMQ for sending the new incoming messages to the workers.</p>&#xA;
39721025,microservices for very small enterprise,2016-09-27 09:28:42,<api><web-applications><architecture><microservices>,2,699,2,0.0,0,"<p>Presently i'm working as web developper in a small company and i'm in charge to create a new web software to manage our business.&#xA;We cannot hire new developpers yet and we must deliver a first version as soon as posible.&#xA;In this context, i'm thinking about microservices architecture and i don't know if we should spend some time and resources to start our project with this kind of architecture.&#xA;Somebody has some experience about this subject?</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
39338259,Dropwizard: Microservice Architecture,2016-09-05 22:15:30,<dropwizard><microservices>,1,235,7,0.0,0,"<p>This is similar to <a href=""https://stackoverflow.com/questions/6994054/how-to-deserialize-from-a-file-to-different-class"">How to deserialize from a file to different class</a>. But, I'm developing micro-services using Dropwizard. </p>&#xA;&#xA;<p>I have two services, service A and service B. I have a message queue (RabbitMQ) setup between the two services. </p>&#xA;&#xA;<p>I am trying to send an object of type Class A (defined in service A) from service A to service B. I have not imported class A in service B. However in service B i have Class B defined which is exactly same as Class A. </p>&#xA;&#xA;<p>I am getting a ClassNotFoundException: Class A in service B when service B tries to deserialize and typecast the object to Class B.  </p>&#xA;&#xA;<p>I want the two jars to be as independent as possible. &#xA;Is there a way to do this. </p>&#xA;"
49849813,Node js microservice,2018-04-16 04:49:43,<node.js><spring><microservices>,1,53,3,0.0,0,<p>Can anyone please tell how to consume a node js based microservice from spring based web application?can restful API be the best choice to be used by the application to message the microservices based on nodejs ?</p>&#xA;
49823345,What is the best way to host a MicroService .net core web api in Docker?,2018-04-13 18:41:49,<docker><asp.net-core><microservices>,1,384,3,0.0,0,<p>I have several micro services that I would like to dockerized them. Is it better to build them in a self-hosted console application or build asp.net web application?</p>&#xA;&#xA;<p>Which one is faster?</p>&#xA;&#xA;<p>My MicroServices are only simple Web Api.</p>&#xA;
49777963,How to best handle shared services using docker-compose for local development in microservice architecture?,2018-04-11 14:38:16,<docker><docker-compose><microservices>,1,110,4,0.0,0,"<p>Trying to set up an effective pattern that allows communication between all of my services and allows for local development on multiple services simultaneously. I am currently setting up local development for my application using docker compose. The basic idea of my <code>docker-compose.yml</code> looks something like this. </p>&#xA;&#xA;<pre><code>version: '3'&#xA;services:&#xA;  web: &#xA;    &lt;web_config&gt;&#xA;  worker:&#xA;    &lt;worker_config&gt;&#xA;  service-a:&#xA;</code></pre>&#xA;&#xA;<p>I'm questioning how to handle <code>service-a</code>. </p>&#xA;&#xA;<p><code>service-a</code> is required by any local applications I am running. So if I am running this application and another at the same time, they will both need to communicate with <code>service-a</code>. </p>&#xA;&#xA;<p>Should <code>service-a</code> be running in its own compose instance? If so, are <code>networks</code> the best way for all my apps to communicate with <code>service-a</code>? From my understanding, this used to be the job of <code>links</code>, but <code>networks</code> are now preferred. I have already tried running with <code>network_mode</code> host, but am running into issues, as I am using Docker for Mac. </p>&#xA;&#xA;<p>I've seen a lot of opinions and solutions out there, but I'm honestly unsure which of these approaches is best. Some of the solutions I've seen include:</p>&#xA;&#xA;<ul>&#xA;<li>creating a shared <code>network</code> for all my services and run them separately in their own docker composes</li>&#xA;<li>using <code>network_mode: 'host'</code> and run everything on my host (Sadly I couldn't get this working)</li>&#xA;<li>running a separate compose of all my shared services that all other services depend on</li>&#xA;</ul>&#xA;&#xA;<p>Let me know if you've run into this and have any advice to share, thanks!</p>&#xA;"
44394119,monolithic or microservice concept,2017-06-06 15:30:08,<django><microservices>,2,610,0,0.0,0,"<p>I have a very large django project with many features that uses django as backend framework. My project lets users use both a website and a iOS app.</p>&#xA;&#xA;<p>I am researching using a monolithic app (currently using monolithic) vs micro services, I watched this <a href=""https://www.youtube.com/watch?v=OuhCYGLByJg"" rel=""nofollow noreferrer"">video</a> but one part really throws me off. At 1:05, he previews his 'monolithic' app before he changes to micro services, which to me looks like a single project with a bunch of different apps. </p>&#xA;&#xA;<p>1) Are these technically just folders and not apps? These (what i would assume he calls folders) all have a models.py and views.py and most have a admin.py.</p>&#xA;&#xA;<p>2) What makes this a monolithic app? Is it just because he doesn't simply use django-admin startapp in the terminal to create these 'folders'?</p>&#xA;&#xA;<p>3) Or are microservices multiple projects connected and not simply multiple apps in a single project?</p>&#xA;&#xA;<p>My biggest confusion is with the previewed project in the video because before then I thought I had a good grasp on these concepts. I was simply looking to change to microservices, after this part in the video I'm not sure I even know what a monolithic app really is.</p>&#xA;"
44265295,Caching layer for different microservices,2017-05-30 14:40:03,<caching><design><varnish><microservices><vert.x>,1,447,3,0.0,0,"<p>We have different microservices which makes duplicate calls to internal and external services. We need to cache these calls between services to improve latency. We are thinking of introducing an API gateway whose major aim would be caching the data between services. &#xA;Some other objectives are -</p>&#xA;&#xA;<p>i) Would be calling different micro-services to aggregate their response.</p>&#xA;&#xA;<p>ii) Would also be avoiding multiple calls to external services across micro services.</p>&#xA;&#xA;<p>iii) Would be taking care of cache miss &amp; hit for external API calls.</p>&#xA;&#xA;<p>iv) High throughput, performance and low latency.</p>&#xA;&#xA;<p>We have vert.x based tech stack.&#xA;What would be the best way to implement such a system. I had following questions -</p>&#xA;&#xA;<p>1) Implement it as a library or a service ?</p>&#xA;&#xA;<p>2) Which data store to be used ( we are considering Redis/Hazelcast) ?</p>&#xA;&#xA;<p>3) Can libraries such as Varnish/Squid/Nginx help here ?</p>&#xA;&#xA;<p>4) How to handle cache invalidation ?</p>&#xA;"
36573857,Consistency with partitioned Service Fabric stateful service,2016-04-12 12:51:14,<architecture><microservices><consistency><azure-service-fabric>,4,319,0,0.0,0,"<p>Let's take a simple example. I have a stateful service that manages users. It has a reliable dictionary that maps UserID to some data, including User Name.</p>&#xA;&#xA;<p>In this service's RegisterUser method, we want to check that the user name has not already been used. This is quite straightforward when the service is a singleton, but when it's partitioned we end up with several problems:</p>&#xA;&#xA;<ol>&#xA;<li>We have to ask all partitions if the user already exists. We could possibly introduce another singleton service that maps user name to user id to overcome this problem.</li>&#xA;<li>There's a race condition. Two users could try to register the name user name at the same time. It's possible that both users could succeed.</li>&#xA;</ol>&#xA;&#xA;<p>I'm looking for general advice for possible ways to deal with situations such as this. I can imagine that this sort of problem would occur regularly with partitioned data.</p>&#xA;"
36569703,how to set local path in yaml configuration file in microservice,2016-04-12 09:51:32,<config><microservices><netflix-eureka>,1,1374,0,0.0,0,"<p>Here all the properties file are in github location,so that I am able to read using uri path ,how I will read if It's in my local system.Can anybody please guide ?</p>&#xA;&#xA;<pre><code>server:&#xA;  port: 8888&#xA;&#xA;eureka:&#xA;  instance:&#xA;    hostname: configserver&#xA;  client:&#xA;    registerWithEureka: true&#xA;    fetchRegistry: true&#xA;    serviceUrl:&#xA;      defaultZone: http://discovery:8761/eureka/&#xA;&#xA;spring:&#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: https://github.com/****/******&#xA;</code></pre>&#xA;"
36422243,spring security oauth2 authorization server without any UI,2016-04-05 09:25:47,<spring-security><spring-boot><spring-security-oauth2><microservices>,2,951,0,0.0,0,"<p>I have implemented a spring security oauth2 authorization server as a spring boot microservice.  I'm trying to allow our main (non-java) application to migrate to oauth2 using this new service.  </p>&#xA;&#xA;<p>One thing I can't get around my head is how to set this up so that the authorization server never shows any UI.  In particular, is there any way to have the /oauth/authorize UI hosted on our main application, but still accept proxied authorization approvals?  Or does that UI need to be served directly by the authorization server?</p>&#xA;"
33659658,Service Fabric Reliable Services: proccessing parallel request with CPU-bound methods,2015-11-11 20:56:00,<c#><azure><microservices><azure-service-fabric>,2,1663,0,0.0,0,"<p>Azure <strong>Service Fabric</strong>'s Reliable Actors turn-based concurrency is described in official documentation.As If I get it right, <strong>Reliable Services</strong>, can serve multiple requests simultaneously.&#xA;Lets say I have a Reliable Service with single CPU-bounded method.&#xA;Method is async as expected, so Service can handle multiple requests.&#xA;My local cluster is hosted on 2-core machine, when I call Service from 2 different console-app clients, CPU 100% utilized as expected. So there is no reason to handle more than 2 request simultaneously. How can I limit this?&#xA;And if I move to real cluster, I don't know anything about machine Service hosted on, what should I do then?</p>&#xA;&#xA;<pre><code>public async Task&lt;bool&gt; CpuBoundAsync(int value)&#xA;&#xA;    {&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK IN PROGRESS"");&#xA;        int z;&#xA;        await Task.Run(() =&gt;&#xA;        {&#xA;            for (int i = 0; i &lt; int.MaxValue; i++)&#xA;            {&#xA;                z++;&#xA;                z--;&#xA;            }&#xA;        });&#xA;&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK COMPLETED"");&#xA;        return true;&#xA;    }&#xA;</code></pre>&#xA;"
33706599,Where to store configuration retrieved from etcd in nodejs,2015-11-14 08:34:03,<node.js><soa><microservices><etcd>,1,245,3,0.0,0,"<p>I'm getting config from http call. </p>&#xA;&#xA;<p>Where I can store that config, Serialize to <strong>filesystem or attach to GLOBAL</strong> or any other</p>&#xA;&#xA;<p>I'm implementing service discovery with nodejs. <a href=""http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/"" rel=""nofollow"">http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/</a></p>&#xA;&#xA;<p>I'm getting the service registry. I want to store it for using application wide.</p>&#xA;"
34889229,Recreating Docker images instead of reusing - for microservices,2016-01-20 00:02:48,<docker><microservices>,2,102,3,0.0,0,"<p>One microservice stays in one docker container. Now, let's say that I want to upgrade the microservice - for example, some configuration is changed, and I need to re-run it.</p>&#xA;&#xA;<p>I have two options:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can try to re-use existing image, by having a script that runs on containers startup and that updates the microservice by reading new config (if there is) from some shared volume. After the update, script runs the microservice. </p></li>&#xA;<li><p>I can simply drop the existing image and container and create the new image (with new name) and new container with updated configuration/code.</p></li>&#xA;</ol>&#xA;&#xA;<p>Solution #2 seems more robust to me. There is no 'update' procedure, just single container creation.</p>&#xA;&#xA;<p>However, what bothers me is if this re-creation of the image has some bad side-effects? Like a lot of dangling images or something similar. Imagine that this may happens very often during the time user plays with the app - for example, if developer is trying out something, he wants to play with different configurations of microservice, and he will re-start it often. But once it is configured, this will not change. Also, when I say <em>configuration</em> I dont mean just config files, but also user code etc.</p>&#xA;"
51697673,"Microservice design with Kubernetes - API gateway, communication, service discovery and db issues",2018-08-05 19:42:13,<node.js><database><rest><kubernetes><microservices>,1,69,1,2.0,0,"<p>Recently I have been researching about microservices and kubernetes. All the tutorial and article I read online talks about general staff. I have several specific questions about building a microservices app on kubernetes.</p>&#xA;&#xA;<ol>&#xA;<li><strong>API gateway:</strong> Is API gateway a microservice I built for my app that can automatically scale? Or is it already a built-in function of kubernetes? The reason I ask is because a lot of the articles are saying that load-balancing is part of the API gateway which confuse me since in kubernetes, load-balancing is handled by <code>service</code>. Also, is this the same as the API gateway on AWS, why don't people use the AWS API gateway instead?</li>&#xA;<li><strong>Communication within services:</strong> from what I read only, there are <em>Rest/RPC</em> way and <em>Message queue</em> way. But why do people say that the <em>Rest</em> way is for sync operation? Can we build the services and have them communicate with rest api with <code>Nodejs async/await</code> functions? </li>&#xA;<li><strong>Service Discovery:</strong> Is this a problem with kubernetes at all? Does kubernetes automatically figure out this for you?</li>&#xA;<li><strong>Databases:</strong> What is the best practice to deploy a database? Deploy as a microservice on one of the node? Also, some articles say that each service should talk to a different db. So just separate the tables of one db to several dbs?</li>&#xA;</ol>&#xA;"
51679363,multi-module Maven project on Dockers,2018-08-03 19:57:38,<java><maven><docker><pom.xml><microservices>,1,43,3,0.0,0,"<p>I have a multi-module maven project where the single modules are all runnable microservice applications containing their own Dockerfile, so in production every module will be a containerized application.</p>&#xA;&#xA;<p>The parent project, which contains the child-modules only contains the parent pom.xml and the docker-compose.yml</p>&#xA;&#xA;<p>I have tried to use the following Dockerfile (on sub-module level):</p>&#xA;&#xA;<pre><code>FROM sgrio/java-oracle&#xA;&#xA;RUN apt-get update&#xA;&#xA;RUN apt-get install -y maven&#xA;&#xA;COPY ../pom.xml /usr/local/service/Oogaday/pom.xml&#xA;&#xA;COPY pom.xml /usr/local/service/Oogaday/OogadayApi/pom.xml&#xA;&#xA;COPY src /usr/local/service/Oogaday/OogadayApi/src&#xA;&#xA;WORKDIR /usr/local/service/Oogaday/OogadayApi/&#xA;&#xA;RUN mvn package -DskipTests&#xA;&#xA;CMD [""java"",""-jar"",""org.oogaday.api-1.0-SNAPSHOT-jar-with-dependencies.jar""]&#xA;</code></pre>&#xA;&#xA;<p>But I am getting a security error because I am  trying to copy the parent pom.xml file (which is not placed in the directory from which I am running the build).</p>&#xA;&#xA;<p>So is there a way to build a maven based sub-module with parent pom?</p>&#xA;"
51566509,In Microservices is it acceptable to have an API returning an Aggregate Root that was replicated?,2018-07-27 22:56:45,<domain-driven-design><microservices><multiple-databases><aggregateroot>,3,72,7,0.0,0,"<p>Imagine we have a microservice M1 with an aggregate root called <code>Player</code> and a microservice M2 with an aggregate root called <code>Classification</code>, now in the M1 we need to do some logic based on some property from <code>Classification</code>, now some steps to do that are:</p>&#xA;&#xA;<ol>&#xA;<li>Replicate the list of possible Classifications to M1 via asynchronous messaging;</li>&#xA;<li>Do what is asked by the business in M1;</li>&#xA;</ol>&#xA;&#xA;<p>Ok, now imagine we have a view to add Players, and in that view is possible to choose the <code>Classification</code> of the new <code>Player</code> from a dropdown list. Now the question:</p>&#xA;&#xA;<p>Should the dropdown list be populated with the Classifications that were replicated into M1 or from M2?</p>&#xA;&#xA;<p>As you can see, by using the data from M1 we would have to expose the <code>Classification</code> from M1 via an API, thus the title of the question.</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>The replications happens through async messaging using events, so I'm not exposing the entire aggregate to M1 just some properties like an Id and the Description of the classification.</p>&#xA;"
35286730,How to execute efficient communication for multiple (micro)services?,2016-02-09 08:01:49,<php><rest><restful-architecture><microservices>,1,574,1,1.0,0,"<p><strong>Case:</strong> Software build with many microservices and internal services.</p>&#xA;&#xA;<p><strong>The doubt</strong> is how to manage performance issues (network latency, size of resource) getting multiple resources from many microservices at once.</p>&#xA;&#xA;<p>I Just can not imagine making 20 HTTP requests to access all necessary resources.</p>&#xA;"
43018514,"AWS Lambda + Spring, how to load application.yml",2017-03-25 15:55:04,<java><spring><amazon-web-services><aws-lambda><microservices>,1,695,0,1.0,0,"<p>I have problem with customizing API gateway domain, for my restful app deployed on AWS lambda. Customized domain, works this way, that depending on basePath it chooses different APIs which finally touches Lambda. For example:</p>&#xA;&#xA;<p><code>api.mycustomdomain.com/view/ping</code> -> goes to application <code>view</code> with path <code>/view/ping</code>&#xA;<code>api.mycustomdomain.com/admin/ping</code> -> goes to application <code>admin</code> with path <code>/admin/ping</code></p>&#xA;&#xA;<p>I am using this example as boilerplate: <a href=""https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store</a></p>&#xA;&#xA;<p>What I would like to achieve is handler which depending on <code>Host</code> header strips prefix from request path.</p>&#xA;&#xA;<p>I have prepared following application.yml file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: ""/view""&#xA;  productionHost: ""api.mycustomdomain.com""&#xA;</code></pre>&#xA;&#xA;<p>The problem/question is. How can I now load those into my Lambda function? Here is my naive try:</p>&#xA;&#xA;<pre><code>public class LambdaHandler implements RequestHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; {&#xA;    SpringLambdaContainerHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; handler;&#xA;    boolean isinitialized = false;&#xA;&#xA;    @Value(""${server.contextPath}"")&#xA;    private String prefix;&#xA;&#xA;    @Value(""${server.productionHost}"")&#xA;    private String productionHost;&#xA;&#xA;    public AwsProxyResponse handleRequest(AwsProxyRequest awsProxyRequest, Context context) {&#xA;        if(awsProxyRequest.getHeaders().get(""Host"").equals(productionHost))&#xA;            awsProxyRequest.setPath(awsProxyRequest.getPath().substring(prefix.length()));&#xA;&#xA;        if (!isinitialized) {&#xA;            isinitialized = true;&#xA;            try {&#xA;                handler = SpringLambdaContainerHandler.getAwsProxyHandler(PingPongApp.class);&#xA;            } catch (ContainerInitializationException e) {&#xA;                e.printStackTrace();&#xA;                return null;&#xA;            }&#xA;        }&#xA;        return handler.proxy(awsProxyRequest, context);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Obviously this doesn't work, LambdaHandler is working out of Spring context.</p>&#xA;&#xA;<p>Any ideas how can I deal with that?</p>&#xA;"
42928059,Request per second and performance limit of Spring rest backend,2017-03-21 13:06:03,<spring><performance><rest><microservices>,2,3308,0,0.0,0,"<p>I would like to develop a Spring REST backend application with tomcat.&#xA;I expect 1000-5000 active users. The users will create requests from clients(Android, web, Ios) to backend. Most of requests will create a simple db select.</p>&#xA;&#xA;<ul>&#xA;<li>How to calculate the limit of requests per second?</li>&#xA;<li>How to estimate the performance limits?</li>&#xA;<li>Should I use Microservice architecure or monolithic?</li>&#xA;</ul>&#xA;&#xA;<p>Thanks</p>&#xA;"
43032883,How could authentication work across microservices?,2017-03-26 18:31:33,<javascript><node.js><authentication><jwt><microservices>,3,111,3,0.0,0,"<p>I have two separate Node.js services.</p>&#xA;&#xA;<p>Service <code>A</code> is responsible for authenticating users.  If a user successfully logs in, the user is redirected to Service <code>B</code> (hosted on a <strong>subdomain</strong> of the domain Service <code>A</code> is hosted on).</p>&#xA;&#xA;<p>I am using <a href=""https://jwt.io/"" rel=""nofollow noreferrer"">JWT</a> for authentication.</p>&#xA;&#xA;<p><strong>Question:</strong> How can Service <code>B</code> be aware if a user is or is not authenticated?</p>&#xA;&#xA;<p>I imagine one way that Service <code>B</code> could be aware if they are or aren't authenticated is by asking Service <code>A</code> to check the JWT on each  Request to Service <code>B</code>. But how is Service <code>A</code> supposed to send the JWT to the client when the client is going to be redirected to a new origin?</p>&#xA;&#xA;<p>Is it safe to do something like:</p>&#xA;&#xA;<pre><code>window.location.href = 'https://b.example.com?jwt=tokenhere'&#xA;</code></pre>&#xA;&#xA;<p>I don't believe storing the JWT on <code>localStorage</code> since it does not allow cross origin access.</p>&#xA;"
36176403,Spring boot microservice with OAuth 2 and JWT for Security,2016-03-23 11:04:25,<oauth-2.0><spring-boot><jwt><microservices><api-management>,1,1343,0,0.0,0,"<p>I am developing a Spring boot application for payment using microservices, which will be consumed by mobile application and web application. </p>&#xA;&#xA;<p>1) Users need to be authenticated for accessing the mobile app</p>&#xA;&#xA;<p>2) Third party mobile apps using my services need to be authenticated (with my app)</p>&#xA;&#xA;<p>3) Web applications using my services need to be authenticated. </p>&#xA;&#xA;<p>My user details will be there in DB or LDAP. I have plans for integrating IBM API management and the deployment will be in on-premise servers. Based on this requirement how I need to design and implement my solution? </p>&#xA;&#xA;<p>After going through different blogs I am confused now. So a proper guidance will be very helpful for me.</p>&#xA;"
36318795,Example of Sidecar Application for Microservices,2016-03-30 20:12:22,<spring><spring-boot><spring-cloud><microservices>,1,1501,1,0.0,0,<p>Is Spring cloud config server an example of sidecar application for microservices?</p>&#xA;
50663047,Microservices and Rest services deployed as jar file?,2018-06-03 03:35:19,<java><rest><war><microservices>,3,66,0,0.0,0,"<p>Let's take the simple example, where I have multiplication service as part of single monolithic MathService(deployed as war).</p>&#xA;&#xA;<p>Now I need to deploy multiplication service as separate service(rest service) which MathService can call. The concept of dividing the single monolithic&#xA;in to small maintainable service is microservice.</p>&#xA;&#xA;<p>But I am not sure is it mandatory to deploy Multiplication service as war file? Can it be still deployed as jar file on the web server?</p>&#xA;&#xA;<p>My understanding is that it should be war file as rest calls(HTTP call) needs to be handled by the servlet. Including servlet means it has to be war file.&#xA;Is that correct?</p>&#xA;"
50647694,Why using Eureka?,2018-06-01 16:33:00,<kubernetes><microservices><spring-cloud><netflix-eureka>,2,138,0,3.0,0,"<p>I was setting up microservices based on <a href=""https://github.com/Netflix/eureka"" rel=""nofollow noreferrer"">Netflix Eureka</a> and experimenting on top of <a href=""https://cloud.spring.io/spring-cloud-netflix/"" rel=""nofollow noreferrer"">spring-cloud</a> and after weeks of research and development the question rose! </p>&#xA;&#xA;<p>Why do I need the Eureka and spring-cloud?</p>&#xA;&#xA;<p>Why not developing your independent containers and deploy them on <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> as pods and maintain everything from there?</p>&#xA;&#xA;<p>You can support load balancing, service registery, monitoring, containerization, etc. from <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> too.</p>&#xA;&#xA;<p>Here are some points that I can think of:</p>&#xA;&#xA;<ul>&#xA;<li>developer friendly</li>&#xA;<li>lower server costs for the complete stack</li>&#xA;<li>less OPS dependent</li>&#xA;<li>more resources on developer communities and tutorials</li>&#xA;<li>gradual learning curve</li>&#xA;</ul>&#xA;"
50506101,Spring Boot - how to communicate between microservices?,2018-05-24 09:45:18,<spring-boot><microservices>,2,721,1,0.0,0,"<p>I'm currently working on a Spring Boot microservices project. I have created services and each service is running separately. With this, I need some services to communicate with other services. How can i achieve that?</p>&#xA;&#xA;<p>I saw some blogs about this which use Netflix, Eureka cloud servers to achieve this. Is there any way I can achieve this in my local environment without using cloud servers?</p>&#xA;"
50627087,"If my users are stored in another database, should I duplicate them in my service that uses SQL database?",2018-05-31 14:48:42,<mysql><sql><postgresql><microservices>,2,39,5,0.0,0,"<p>If my users are stored in some other database, but I am building posts in my SQL database, should I create another table <code>users</code>?</p>&#xA;&#xA;<p>If I did, I would be duplicating all of my users and would have to make sure this stays in sync with the other database, but on the other hand, my posts tables could save space by referring to fk instead of full id string each time.</p>&#xA;&#xA;<p>What is the recommendation? Create another table <code>users</code> or just pass in the user ids to query? </p>&#xA;"
46934916,Microserivce Using Spring Boot to Consume SOAP,2017-10-25 14:20:55,<java><rest><spring-boot><soap><microservices>,3,632,0,0.0,0,"<p>I need to create a REST service that first consumes SOAP. What would the best way to go about this?</p>&#xA;&#xA;<p>I would like to use Spring Boot to create a microservice, but I have a few questions for those with experience:</p>&#xA;&#xA;<ul>&#xA;<li>What other architectures or technologies should I look into using&#xA;(with spring boot)?  </li>&#xA;<li>Is there a standard technology stack for this?</li>&#xA;<li>Are there pitfalls I should be aware of?</li>&#xA;</ul>&#xA;"
47042162,Where in S3 my Lambda code stored,2017-10-31 18:21:25,<amazon-web-services><amazon-s3><aws-lambda><microservices>,2,703,0,0.0,0,<p>I have read the Lambda FAQ and it says it stores my code in S3 and it is encrypted.</p>&#xA;&#xA;<p>Where in S3 is it stored and can I decrypt it to edit my code?</p>&#xA;
47017875,Scheduler in a java spring boot microservice,2017-10-30 14:34:41,<java><spring-boot><scheduler><microservices>,1,601,3,0.0,0,"<p>We have a microservice written using Spring boot which has its own NoSQL datastore. We are working on functionality whereby we want to delete some old data (in magnitude of 0.5 million documents) and want to do it on a regular basis(once a day) based on presence of records of particular type in data store. </p>&#xA;&#xA;<p>Is having a scheduler which runs once everyday and does the deletion, a correct approach for it ? Also since its a microservice and several instances of it will be running, how do we control that this scheduler runs on only 1 instance ?</p>&#xA;"
47061556,Microservice Setup,2017-11-01 18:39:46,<node.js><docker-compose><microservices>,3,55,4,0.0,0,"<p>I have a several git repo that I want to manage via docker-compose. I also want the project where the docker-compose resides to be a git repo. So I have the following organization:</p>&#xA;&#xA;<p><code>&#xA;UI-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Server-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Local-Development-Repo&#xA;  --&gt; .git&#xA;  --&gt; docker-compose.yml&#xA;</code></p>&#xA;&#xA;<p>Unfortunately, I cannot seem to access the UI-Repo and Server-Repo dockerfiles due to limitations in Docker. Having a sym link for the UI-Repo and Server-Repo inside the Local-Development-Repo does not work either. So I can think of two options.</p>&#xA;&#xA;<ol>&#xA;<li><p>Git Submodules</p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I will need to copy package.json and perform a <code>npm install</code> inside my dockerfiles since <code>node_modules</code> is on my .gitignore. I want this purely for development and ideally, should just use volumes instead of installing dependencies inside the docker container. </li>&#xA;</ul></li>&#xA;<li><p>House UI-Repo and Server-Repo inside a parent directory, which contains the docker-compose.yml file. </p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I want this parent to be tracked via Git as well. I do not think having .git in the parent directory that houses two more git repo will work. </li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>What is the suggested practice to set up microservices architecture having several independent git repos and manage these projects for local development using docker-compose?</p>&#xA;"
46947956,"MQ - How to guarantee message delivery in a non-transacted, lightweight environment?",2017-10-26 07:14:35,<transactions><zeromq><microservices><mq><2phase-commit>,2,96,11,0.0,0,"<p>How to guarantee message delivery in a non-transacted, lightweight environment?</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<ul>&#xA;<li>Normal situation: Write to database, commit, <strong>send message to ZeroMQ|Redis|OtherMQ</strong>, consumer pulls the message to continue processing...</li>&#xA;<li>0,05% situation: Write to database, commit, <strong>application dies!</strong>, no message sent, no consumer pull the message, incomplete processing.</li>&#xA;</ul>&#xA;&#xA;<p>How to not loose the message (avoid not send the message) in this situation?</p>&#xA;&#xA;<p><strong>Edit</strong>: The message must be delivery exactly once.</p>&#xA;"
42046797,"New to Microservices - refactoring a monolith ""Marketplace"" database",2017-02-04 23:20:58,<oop><microservices>,1,180,3,0.0,0,"<p>I am new to microservices and have been struggling to wrap my brain around it. On the surface they sound like a good idea, but from a practical standpoint, I can't break away from my centralized database background. For an example, I have this real-world Marketplace example that I cannot figure out if microservices would help or hurt. This site was working well until the PO asked for ""Private Products."" Now it is fragile and slow so I need to do a major refactor. A good time to implement microservices. I feel like many systems have this type of coupling, so that deconstructing this example would be very instructive. </p>&#xA;&#xA;<p><strong>Current State</strong> </p>&#xA;&#xA;<p>This is a b2b marketplace where users belong to companies that are buying products from each other. Currently, there exists a monolithic database: User, Company, Catalog, Product, and Order. (This is a simplification, the actual scenario is much more complicated, users have roles, orders have header/detail, products have inventories, etc.)</p>&#xA;&#xA;<ul>&#xA;<li>Users belong to Companies</li>&#xA;<li>Companies have a Catalog of their Products</li>&#xA;<li>Companies have Orders for Products from other Companies </li>&#xA;</ul>&#xA;&#xA;<p>So far so good. I could see breaking the app into microservices on the major entity boundaries. </p>&#xA;&#xA;<p><strong>New Requirement</strong></p>&#xA;&#xA;<p>Unfortunately for my architectural aspirations, the product owner wants more features. In this case: Private Products.</p>&#xA;&#xA;<ul>&#xA;<li>Products are Public or Private</li>&#xA;<li>Companies send time-bound Invitations to Products or Catalogs to Users of other Companies</li>&#xA;</ul>&#xA;&#xA;<p>This seemingly simple request all the suddenly complicated everything.</p>&#xA;&#xA;<p><strong>Use Case - User displays a list of products</strong></p>&#xA;&#xA;<p>For example, listing or searching products was once just a simple case of asking the Products to list/search themselves. It is one of the top run queries on the system. Unfortunately, now what was a simple use case just got messy.</p>&#xA;&#xA;<ul>&#xA;<li>A User should be able to see all public Products (easy)</li>&#xA;<li>A User should be able to see all their own Company's private Products (not horrible)</li>&#xA;<li>A User can see any Product that their Company has Ordered in the past regardless of privacy (Uh oh, now the product needs to know about the User Company's Order history) </li>&#xA;<li>A User can see any private Product for which they have an active Invitation (Uh oh, now the product needs to know about the User's Product or Catalog Invitations which are time dependent)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Initial Monolithic Approach</strong></p>&#xA;&#xA;<p>This can be solved at the database level, but the SQL joins basically ALL of the tables together (and not just master data tables, all the transactions as well.) While it is a lot slower than before, since a DBMS is designed for big joins it seems like the appropriate tool. So I can start working on optimizing the query. However, as I said, for this and other reasons the system is feeling fragile.</p>&#xA;&#xA;<p><strong>Initial Design Thoughts... and ultimately my questions</strong></p>&#xA;&#xA;<p>So considering a Microservices architecture as a potential new direction, I began to think about how to start. Data redundancy seems necessary. Since, if I translate my major entities into services, asking to get a list of products without data redundancy would just have all of the services calling each other and a big slow mess. </p>&#xA;&#xA;<p>Starting with a the idea of carving out ""Product and Catalog"" as its own microservice. Since Catalogs are just collections of Products, they seem to belong together - I'll just call the whole thing the ""Product Service"". This service would have an API for managing both products and catalogs and, most importantly, to search and list them.</p>&#xA;&#xA;<p>As a separate service, to perform a Product search would require a lot of redundant data as it would have to subscribe to any event that affected product privacy, such as:</p>&#xA;&#xA;<ul>&#xA;<li>Listen for Orders and keep at least a summary of the relationship between purchased Products and Purchasing Companies</li>&#xA;<li>Listen to Invitations and maintain a list of <strong>active</strong> User/Product/Time relationships </li>&#xA;<li>Listen to User and Company events to maintain a User to Company relationship</li>&#xA;</ul>&#xA;&#xA;<p>I begin to worry about keeping it all synchronized. </p>&#xA;&#xA;<p>In the end, a Product Service would have a large part of the current schema replicated. So I begin to think, maybe Microservices won't work for this situation. Or am I being melodramatic and the schema will be simpler enough to be more managable and faster so it is worth it?</p>&#xA;&#xA;<p>Overall, am I thinking about this whole approach properly? Is this how microservice based designs are intended to be thought through? If not, can somebody give me a push in a different direction?</p>&#xA;"
42061684,Microservice redundancy issue in our architecture,2017-02-06 06:36:51,<microservices>,1,246,4,0.0,0,"<p>We have 12 microservices deployed in our application server. Problem is, since we have a microservice for each specific function, a lot of libraries are being repeated in each microservice instead of if they are shared in larger monolithic services or app. This causes each .ear file to be large per microservice. with this, out of memory errors start to happen more often.</p>&#xA;&#xA;<p>Is there any way to get around this? or better ways to do this?</p>&#xA;"
38121112,.NET Core Authorize attribute with external JWT authentication microservice?,2016-06-30 10:57:14,<asp.net-web-api><authorization><asp.net-core><jwt><microservices>,2,1615,0,1.0,0,"<p>So I'm just having a bit of trouble getting my head round the .NET Core [Authorize] attribute.</p>&#xA;&#xA;<p>I have an authentication service running (let's say <code>authapi.com</code>) which when provided with valid authentication details will return a JWT.  When this JWT is given back to it, it will validate the JWT and return a message indicating such.</p>&#xA;&#xA;<p>So, I'm now building another WebAPI (let's say <code>genericapi.com</code>)which will require authorization for some of the actions/controllers.  The idea being, the JWT will be passed in the headers of the request to <code>genericapi</code> which then needs to pass those on to <code>authapi.com</code> to validate them.</p>&#xA;&#xA;<p>I tried adding a Policy but it got convoluted really quick, and I had to write <code>[Authorize(Policy=""TokenValid"")]</code> on everything, when I'd rather just the default <code>[Authorize]</code> did this, since ALL authorization will have to hit <code>authapi</code>.</p>&#xA;&#xA;<p>How would I go about getting that JWT from the header and passing it to the <code>authapi</code> as standard behaviour for <code>[Authorize]</code>?</p>&#xA;&#xA;<p>Bear in mind: I don't want to do anything with the JWTs on <code>genericapi</code>, all authentication is to be handled by <code>authapi</code>.</p>&#xA;"
38178208,Can CakePhp 2.x or 3.x be used to develop web app based on micro service architecture,2016-07-04 06:35:33,<rest><cakephp><cakephp-3.0><microservices><cakephp-2.8>,1,447,5,0.0,0,<p>I was evaluating PHP based frameworks for development of highly available and scalable applications based on micro service architecture. </p>&#xA;&#xA;<p>I have not seen any documentation for using CakePhp 2.x or 3.0 for design and development of micro services. Where as Laravel ( which is another PHP MVC framework based on Symphony) seems to have these capabilities based on its Lumen modules or components.</p>&#xA;&#xA;<p>It appears that CakePhp frameworks are only suited for design and development of big gigantic monolithic app. </p>&#xA;&#xA;<p>Can anyone point me to a documentation or example about how to use CakePhp 2.x or 3.x for designing web apps based on Micro service architecture ? </p>&#xA;
42642688,Spring Cloud Zuul as API gateway,2017-03-07 07:35:12,<spring><spring-security><microservices><spring-cloud><netflix-zuul>,1,929,2,0.0,0,"<p>I'm new to Spring Cloud and about to kick start a new project in micro-service fashion using Spring Cloud stack i.e. Eureka, Zuul, Ribbon and Hystrix.</p>&#xA;&#xA;<p>The application will have a dumb UI which will interact with back-end services to get job done, the back-end services are rest in nature and will use token based authentication (using JWT) backed by Spring security, so following will be the flow of application </p>&#xA;&#xA;<ol>&#xA;<li><strong>Authentication service</strong>:- Authentication service will take care of authenticating user and validating access token.</li>&#xA;<li><strong>Rest services</strong>: Other services will have their own authorization mechanism, i.e. whether given user (identified from JWT token) has access to requested resource or not.</li>&#xA;</ol>&#xA;&#xA;<p>I've used JWT and Spring security filters to achieve same but not able to map how Zuul will fit into this picture, while going through documentation I encountered ZuulFilters, which can be used to achieve this but using this I need to have my authentication/authorization mechanism at same place i.e. Zuul, but I want my authentication piece at Zuul and have distributed authorization this will save me from configuring every rest resource to role mapping in DB and have that loaded/read at zuul for every request.</p>&#xA;&#xA;<p>I've gone through some blogs/example but most of them talk about SSO stuff, Can someone please enlighten me with a blog post or example, any help is appreciated. </p>&#xA;"
42691892,Microservices Per DB table,2017-03-09 09:47:19,<domain-driven-design><microservices>,3,200,2,0.0,0,"<p>I ran into the microservices architecture for e-commerce application where each table has it's own micro service basically with CRUD operations (something like rest client for each table). &#xA;Now I am thinking about combine and model them around business domains, before that I wanted to know does anyone encountered such situation and is it right architecture or not.&#xA;Any suggestions will be very helpful.&#xA;Thanks.</p>&#xA;"
42711116,Service Fabric - DeleteServiceAsync timing out,2017-03-10 05:45:34,<azure><microservices><azure-service-fabric><service-fabric-stateful>,1,62,3,0.0,0,"<p>I am spawning several ASF microservices to run some process. Once the process is done, I am deleting those services using <code>DeleteServiceAsync</code> by using following code. Almost 98% of the time, everything works fine. However, 2% of the time, I run into timeout issue and the microservices stucks in deleting state with Idle Secondary replica. Thanks in advance for any suggestions to resolve this issue.</p>&#xA;&#xA;<pre><code>using (FabricClient fc = new FabricClient())&#xA;{&#xA;    fc.ServiceManager.DeleteServiceAsync(deleteServiceDescription, TimeSpan.FromMinutes(5), cancellationToken);&#xA;}&#xA;</code></pre>&#xA;"
42778151,Integrating with Auth0,2017-03-14 05:10:33,<publish-subscribe><microservices><cqrs><eventual-consistency>,1,38,4,0.0,0,"<p>I'm in the process of implementing a user management Microservice (MS) and wanted to find out whether what I'm doing is ok. Users are created from the UI, which interacts with an API. The API makes an RPC call to the user management MS, and publishes a CreateUserCommand to an InMem-bus. The consumer then handles the command by then creating a user in the DB, but then I need this user also registered within Auth0 - would the way to go about this be to send a different command to a persistent queue, for a subscriber to pick it up and register that user with Auth0 (persistent queue in case can't reach Auth0). Once that completes successfully, I could then publish a UserCreatedEvent? </p>&#xA;&#xA;<p>Any help with this would be much appreciated.</p>&#xA;"
38461294,How to send JSON as a Input parameter from one Microservice to another using RestTemplate in Spring Boot,2016-07-19 14:24:45,<java><spring-boot><resttemplate><microservices>,3,1356,0,1.0,0,"<p>I want to send <code>JSON</code> as an <code>input</code> from Microservice M1 to a Microservice M2.</p>&#xA;&#xA;<p>M1 and M2 both are on different machines.&#xA;I am new to Spring Boot,</p>&#xA;&#xA;<p>I found some <a href=""https://spring.io/guides/tutorials/bookmarks/"" rel=""nofollow"">code</a> but I am unable to get it.&#xA;Please help.</p>&#xA;"
38380827,Microservices Maven Project Structure,2016-07-14 17:43:39,<java><spring><maven><microservices>,2,2112,2,0.0,0,"<p>I am working on a project in which we'll deploy a full Spring Boot microservices architecture, along with supporting services like load balancing, service registry, edge server, and centralized monitoring.</p>&#xA;&#xA;<p>I have a single project that will be shared among all core microservices which contains DAOs and all the dependencies for the core microservices. I am hoping to be able to release one ~60Mb jar, and have the other Spring Boot core microservices be very lightweight (&lt;1Mb). At runtime the core microservices will reference the shared jar on their classpath.</p>&#xA;&#xA;<p>The way I've set the project up is to have separate project, with a structure like so:</p>&#xA;&#xA;<pre><code>|shared_project&#xA;|pom.xml&#xA;&#xA;|ms-1&#xA;|pom.xml&#xA;&#xA;|ms-2&#xA;|pom.xml&#xA;</code></pre>&#xA;&#xA;<p>The shared project uses maven-assembly-plugin to create a big jar and copies it to my local .m2 repo. The ms-1 and ms-2 poms use maven-jar-plugin to create their jars and have one dependency, the shared project. </p>&#xA;&#xA;<p>I'm sure this is not the best way to handle this. It's creating issues during unit tests and I have to imagine it'll create issues down the line. I've seen this done using parents in the pom file, nesting the project inside another directory, and other ways. </p>&#xA;&#xA;<p>What I am wondering is what is the best practice regarding keeping your Spring Boot projects' dependencies and shared code centralized and externalized through use of Maven, such that the projects that you are frequently rolling are kept lightweight and decoupled? </p>&#xA;&#xA;<p>Bonus questions: </p>&#xA;&#xA;<ol>&#xA;<li><p>Does the fact that we'll be using Jenkins/TeamCity for CI and automated testing affect the answer?</p></li>&#xA;<li><p>Does having one shared jar on the filesystem which each project references in its classpath during startup pose any challenges? Depending on demand, we may flexibly spin up 10 instances of microservice-1 and only 3 of microservice-2. </p></li>&#xA;</ol>&#xA;&#xA;<p>EDIT: I think this already has a good answer here: &#xA;<a href=""https://stackoverflow.com/questions/27865238/parent-pom-and-microservices"">Parent pom and microservices</a></p>&#xA;"
38297333,Sharing data among Microservices‏,2016-07-10 23:27:59,<rest><design-patterns><enterprise><restful-architecture><microservices>,2,774,4,1.0,0,"<p>I'm seeking an answer to a design question that I didn't find an answer to in any literature on this matter. Allow me to explain the use case, my solution to it and, ask for your opinion as a subject matter expert.</p>&#xA;&#xA;<p><strong>Use Case</strong>:&#xA;We've several Microservices that all return some form of content from different business domains. We're using Spring Cloud Netflix, so a gateway service routes traffic to the content services. Some, if not all, of these services require data that is derived from the request, and is immutable. A trivial example is locale, although there are other proprietary information too.</p>&#xA;&#xA;<p><strong>Solution</strong>:&#xA;I'm currently deriving the shared data in the gateway service and persisting as JSON in a NoSQL database with a unique key. Then I'm adding the key as a request header before routing the request. I've a shared library that the content services include at build time, and includes a Spring bean that reads the key from the request header, fetches the stored data using the key and initializes itself. This makes it possible for the content services to access the shared data (by simply injecting the previously mentioned bean) without knowing the underlying mechanism.&#xA;If a content service invokes another one, it's responsible for adding the unique key as a request header.</p>&#xA;&#xA;<p><strong>Debate</strong>:&#xA;The debate I've with my colleagues is that whether using a shared datastore for this purpose is appropriate. I contend that it is bad for a service to leak it's domain specific data to others, but the data in question isn't domain specific, so there's nothing wrong with having a shared database and passing the key around. The alternative would be to pass all the shared data around which I consider redundant.</p>&#xA;&#xA;<p>What is your thought?</p>&#xA;&#xA;<p><strong>Edit</strong>: I see someone voted to close the question. Unless they can point me to a reference that discusses data sharing among Microservices, such policing is a hindrance to meaningful discussion. Not every question is a boolean yes/no answer, some require deeper thoughts.</p>&#xA;"
38352227,What is the name of this 'intermediary' pattern?,2016-07-13 12:48:52,<java><web-services><design-patterns><microservices>,1,99,5,0.0,0,"<p>I've got an intermediary java web service application application (built using Spark Java - but that is incidental) that takes an http parameter - from it generates a URL - calls the URL and then returns the result to the original caller. </p>&#xA;&#xA;<pre><code>Original Client -&gt; My Application -&gt; Http Web Service Producer&#xA;</code></pre>&#xA;&#xA;<p>This is kind of a MicroServices pattern - but I'm looking for a more specific term. I think it is a 'pipeline', 'solicitor' or a 'mediator'. </p>&#xA;&#xA;<p>My question is: <strong>What is the name of this 'intermediary' pattern?</strong></p>&#xA;"
38397672,Multiple database management,2016-07-15 13:44:30,<mongodb><haxe><microservices>,1,174,6,0.0,0,"<p>I'm currently working on a multiplayer game which will be using two databases(MONGODB). One for authentication(login) and one to contain all game-specific data.&#xA;What I've done is to separate the user and game specific data. This way i'll be able to build micro services around the user in the future.</p>&#xA;&#xA;<p>I'm a bit uncertain on how to handle/validate the game-specific database operations tho.&#xA;When i log into my game, i perform a POST request to my rest api, which validates the user and returns some data.</p>&#xA;&#xA;<p>The game itself however, is using a TCP socket connection to handle real-time gameplay and will be saving game-specific data to the database on the authoritative server(all game logic is done on the server) . How would you go about to link the data on the game-specific database to a specific user found in the authentication database?</p>&#xA;"
40044128,Fetch Configuration from Spring Cloud Config over SSL,2016-10-14 13:14:30,<java><ssl><spring-boot><microservices><spring-cloud-config>,2,1658,0,0.0,0,"<p>I am building microservices using Spring Boot where configuration is distributed using Spring Cloud Config. Config application has SSL enabled.</p>&#xA;&#xA;<p>I want my spring boot application to communicate to Config server over https. Problem is that before loading SSL configuration from bootstrap.yml, application initiates a rest call to Config Server to fetch the configuration and fails miserably with error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""https://host:8888/abcd/development,production"": sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; nested exception is javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: &#xA;</code></pre>&#xA;&#xA;<p>I have configured a truststore with CA certificate in bootstrap.yml:</p>&#xA;&#xA;<pre><code># MicroServices Properties&#xA;spring:&#xA;  application:&#xA;     name: abcd&#xA;  profiles:&#xA;    active: development,production&#xA;  cloud:&#xA;    config:&#xA;      uri: https://&lt;host&gt;:8888 &#xA;      fail-fast: true&#xA;      password: abc@123&#xA;      username: user&#xA;server:&#xA;  ssl:&#xA;    trust-store: D:/Certs/caCert/server.p12&#xA;    trust-store-password: keystore&#xA;    key-store-provider: PKCS12&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions what should I do to create successful SSL communication with Config Server?</p>&#xA;"
39941660,Which could be the best way for communication of Micro-services without any HARD-CODE,2016-10-09 08:43:40,<spring-boot><microservices><netflix-eureka>,2,153,0,2.0,0,"<p>I having a bunch of microservices which communicates with each other using <code>RestTemplate</code>. All the communication of microservices is from API gateway.</p>&#xA;&#xA;<p>I am doing as following,</p>&#xA;&#xA;<pre><code>    public List&lt;ServiceInstance&gt; serviceInstancesByApplicationName(String applicationName) {&#xA;            return this.discoveryClient.getInstances(applicationName);&#xA;        }&#xA;&#xA;    //some Other logic &#xA;&#xA;    List&lt;ServiceInstance&gt; apigatewaymsInstanceList = discoveryClient.getInstances(apigatewaymsName);&#xA;            ServiceInstance apigatewaymsInstance = apigatewaymsInstanceList.get(0);&#xA;&#xA;    //and&#xA;&#xA;    restTemplate.exchange(apigatewaymsInstance.getUri().toString() + plmpayloadprocessmsResource, HttpMethod.POST,&#xA;                                entity, String.class);&#xA;</code></pre>&#xA;&#xA;<p>But here it appears like a hard code. Is there some another approach I am missing? What could be the best way ?</p>&#xA;&#xA;<p>Likewise, I am asking is there any method available so that I can pass the name of application and eureka return me its full URI no need to do <code>applicationgetInstaceId(0);</code></p>&#xA;"
40082248,Handle message dependency when using evening environment(MessageMQ),2016-10-17 09:00:38,<spring-boot><rabbitmq><message><microservices>,1,28,3,0.0,0,"<p>I am developing a micro service platform using Spring technologies. I am facing some problem when consuming message from Rabbit MQ.</p>&#xA;&#xA;<p>Scenario:</p>&#xA;&#xA;<p>I have two message queue, <strong>student</strong> and <strong>enrollment</strong>. In my one microservice I put the student and enrollment creation request to message queue. </p>&#xA;&#xA;<p>But, since the message queue order not guaranteed, enrollment message comes <strong>before</strong> the students come. &#xA;On that time my relation database fail. </p>&#xA;&#xA;<p>What is the best way to handle this kind of scenario(message ordring) when using message mq in microservice platform? </p>&#xA;"
49579074,Cache Implementation in Microservices best practises,2018-03-30 17:54:05,<caching><microservices>,1,28,4,0.0,0,<p>I want to ask one design related question as we have multiple micro-services and we want to implement cache for them. </p>&#xA;&#xA;<p>There is a possibility of having different services accessing the same cache for setting and fetching data from this cache So what should be the best way of doing it. </p>&#xA;&#xA;<p>Assuming we have customer service which updates the cache with customer data and we have a cart cache which do needs this data to set in cart object which contains this customer data so for this kind of scenario what would be the best way of implementing this.</p>&#xA;
38872460,How to share a host directory between multiple docker container?,2016-08-10 11:41:31,<node.js><docker><dockerfile><microservices>,3,294,1,0.0,0,"<p>This is my directory structure <a href=""http://i.stack.imgur.com/yaANi.png"" rel=""nofollow"">for docker microservices </a>. What I need to do  is to share certain files from my lib folder which is on my host machine to containers. These are lib files which are required to run the application in both of the containers.This is the content from one of my docker file inside one of the container propinfo-finder</p>&#xA;&#xA;<pre><code>FROM alpine:3.3&#xA;&#xA;RUN apk add --update nodejs&#xA;&#xA;RUN mkdir -p /usr/src/app&#xA;WORKDIR /usr/src/app&#xA;&#xA;COPY . /usr/src/app&#xA;RUN npm install&#xA;&#xA;EXPOSE 3000&#xA;&#xA;WORKDIR /usr/src/app&#xA;CMD node index.js&#xA;</code></pre>&#xA;&#xA;<p>I build the docker images using this command <code>docker build -t nodeapp/premcal .</code> The build process is successful . Then i use this command to map/mount the directory <code>bin</code> to the container to make it run&#xA;from the parent directory where bin folder is located </p>&#xA;&#xA;<p><code>docker run -v $PWD/lib:/usr/src/app -p 3010:3000 -i nodeapp/premcal&#xA;</code>&#xA;after running it I am getting this error </p>&#xA;&#xA;<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">&#xD;&#xA;<div class=""snippet-code"">&#xD;&#xA;<pre class=""snippet-code-html lang-html prettyprint-override""><code>module.js:328&#xD;&#xA;    throw err;&#xD;&#xA;    ^&#xD;&#xA;&#xD;&#xA;Error: Cannot find module '/usr/src/app/index.js'&#xD;&#xA;    at Function.Module._resolveFilename (module.js:326:15)&#xD;&#xA;    at Function.Module._load (module.js:277:25)&#xD;&#xA;    at Function.Module.runMain (module.js:442:10)&#xD;&#xA;    at startup (node.js:136:18)&#xD;&#xA;    at node.js:966:3</code></pre>&#xD;&#xA;</div>&#xD;&#xA;</div>&#xD;&#xA;</p>&#xA;&#xA;<p>The host is a physical Ubuntu machine . </p>&#xA;&#xA;<p>can anybody please tell me how to make this go away . All I have is 2 hrs of experience with node.js and docker environment . &#xA;Thank you .</p>&#xA;"
38764797,Get AccessToken from spring cloud zuul API Gateway,2016-08-04 10:26:02,<wso2is><spring-cloud><microservices><oauth2><netflix-zuul>,1,301,4,0.0,0,<p>We are using zuul as API gateway in spring cloud. Now we want to extract access token from zuul for further implementation.Please provide suggestion how we want to implement. Thank you</p>&#xA;
51224374,Microservice requests,2018-07-07 15:04:26,<microservices>,2,40,3,0.0,0,"<p>I'm trying to start a little microservice application, but I'm a little bit stuck on some technicalities.</p>&#xA;&#xA;<p>I'm trying to build an issue tracker application as an example.</p>&#xA;&#xA;<p>It has 2 database tables, issues and comments. These will also be separate microservices, for the sake of the example.</p>&#xA;&#xA;<p>It has to be a separate API that can be consumed by multiple types of clients e.g. mobile, web etc..</p>&#xA;&#xA;<p>When using a monolitic approach, all the codebase is coupled together, and when making a request to let's say the REST API, I would handle for example the '/issues/19' request&#xA;to fetch the issue with the id '19' and it's corresponding comments by means of the following pseudocode.</p>&#xA;&#xA;<pre><code>on_request_issue(id) # handler for the route '/issues/&lt;id&gt;'&#xA;    issue = IssuesModel.findById(id)&#xA;    issue.comments = CommentsModel.findByIssueId(id)&#xA;    return issue&#xA;</code></pre>&#xA;&#xA;<p>But I'm not sure on how I should approach this with microservices. Let's say that we have microservice-issues and microservice-comments.</p>&#xA;&#xA;<p>I could either let the client send a request to both '/issues/19' and '/comments/byissueid/19'. But that doesn't work nice in my point of view, since if we're having multiple things&#xA;we're sending alot of requests for one page.</p>&#xA;&#xA;<p>I could also make a request to the microservice-issues and in that one also make a request to the microservice-comments, but that looks even worse to me than the above, since from what&#xA;I've read microservices should not be coupled, and this couples them pretty hard.</p>&#xA;&#xA;<p>So then I read about API gateways, that they could/should receive a request and fan out to the other microservices but then I couldn't really figure out how to use an API gateway. Should&#xA;I write code in there for example to catch the '/issues/19' request, then fan out to both the microservice-issues and microservice-commetns, assemble the stuff and return it? &#xA;In that case, I'm feeling I'm doing the work double, won't the API gateway become a new monolith then?</p>&#xA;&#xA;<p>Thank you for your time</p>&#xA;"
51280734,Spring boot application stopping without any error on console,2018-07-11 08:30:13,<maven><spring-boot><amazon-ec2><microservices><aws-regions>,4,149,3,0.0,0,"<p>I have created spring boot application using maven. Where I built a executable jar for application the tried to run it on EC2 instance free tier windows using following command<br>&#xA;java -jar com-spring-boot-apps-0.0.1-SNAPSHOT.jar  --server.port=8181 -Xdebug</p>&#xA;&#xA;<p>Some it application does not run, it exists with following logs on console. </p>&#xA;&#xA;<pre><code>log4j:WARN No appenders could be found for logger (org.springframework.web.context.support.StandardServletEnvironment).&#xA;log4j:WARN Please initialize the log4j system properly.&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v2.0.3.RELEASE)&#xA;&#xA;2018-07-11 13:55:50.762  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]&#xA;2018-07-11 13:55:50.768  INFO 2784 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.31&#xA;2018-07-11 13:55:50.800  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : Loaded APR based Apache Tomcat Native library [1.2.17] using APR version [1.6.3].&#xA;2018-07-11 13:55:50.803  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true].&#xA;2018-07-11 13:55:50.805  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR/OpenSSL configuration: useAprConnector [false], useOpenSSL [true]&#xA;2018-07-11 13:55:52.060  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : OpenSSL successfully initialized [OpenSSL 1.0.2o  27 Mar 2018]&#xA;2018-07-11 13:55:52.402  INFO 2784 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext&#xA;2018-07-11 13:55:52.532  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]&#xA;</code></pre>&#xA;&#xA;<p>Exception :- </p>&#xA;&#xA;<pre><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'regionProvider': Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.aws.core.region.StaticRegionProvider]: Constructor threw exception; nested exception is java.lang.IllegalArgumentException: The region 'ap-south-1a' is not a valid region!&#xA;</code></pre>&#xA;"
51238009,Create endpoint to get multiple records in microservice,2018-07-09 03:52:33,<java><c#><design-patterns><microservices>,3,64,4,0.0,0,"<p>Currently, we have an API endpoint (microservice called supplier service) like this: <code>/suppliers/{supplierNumber}</code>, which will return a single supplier information. </p>&#xA;&#xA;<p>In the UI, there is a screen to display a list of suppliers for different products. It looks something like this:  </p>&#xA;&#xA;<pre><code>product1 -&gt; supplier1&#xA;product2 -&gt; supplier2&#xA;product3 -&gt; supplier3&#xA;</code></pre>&#xA;&#xA;<p>To display suppliers for a list of products, we need a for loop which calls the end point on each iteration.</p>&#xA;&#xA;<p>My concern is that this is inefficient from a performance stand point. Why is it not possible to design an endpoint that takes in a list of supplier numbers and returns a list of supplier information?</p>&#xA;&#xA;<p>Other people have said that it's not microservice design, and I'm not sure why it's not a proper design. Does anyone know the reasoning behind this?</p>&#xA;"
51300620,Strange error with a JHipster app in a microservices architecture and Docker up,2018-07-12 08:22:11,<docker><docker-compose><microservices><jhipster>,2,66,4,0.0,0,"<p>I have generated an app with JHipster 5.0.1 version. The app has 4 components:</p>&#xA;&#xA;<ul>&#xA;<li>UAA app for user accounting and authorizing</li>&#xA;<li>JHipster Registry app</li>&#xA;<li>A gateway app </li>&#xA;<li>A simple microservice</li>&#xA;</ul>&#xA;&#xA;<p>I have followed all the steps in the documentation, including the steps to create docker compose file. But, then when I want to run docker-compose up I get some errors with pull permisions with my custom components.</p>&#xA;&#xA;<p>Here are the logs</p>&#xA;&#xA;<blockquote>&#xA;  <p>compose.cli.verbose_proxy.proxy_callable: docker inspect_image &lt;- ('chipagames')&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""GET /v1.22/images/chipagames/json HTTP/1.1"" 404 60&#xA;  compose.service.pull: Pulling chipagames-app (chipagames:)...&#xA;  compose.cli.verbose_proxy.proxy_callable: docker pull &lt;- ('chipagames', tag='latest', stream=True, platform=None)&#xA;  docker.auth.get_config_header: Looking for auth config&#xA;  docker.auth.resolve_authconfig: Using credentials store ""osxkeychain""&#xA;  docker.auth._resolve_authconfig_credstore: Looking for auth entry for '<a href=""https://index.docker.io/v1/"" rel=""nofollow noreferrer"">https://index.docker.io/v1/</a>'&#xA;  docker.auth.get_config_header: Found auth config&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""POST /v1.22/images/create?tag=latest&amp;fromImage=chipagames HTTP/1.1"" 404 91</p>&#xA;</blockquote>&#xA;&#xA;<p>I have docker service running, I have created a repository in docker hub too, but I don't understand the error.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Here is my docker-compose.yml</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;    appuaa-app:&#xA;        image: appuaa&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATA_MONGODB_URI=mongodb://appuaa-mongodb:27017&#xA;            - SPRING_DATA_MONGODB_DATABASE=appuaa&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=appuaa-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    appuaa-mongodb:&#xA;        image: mongo:3.6.3&#xA;    appuaa-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    chipagames-app:&#xA;        image: chipagames&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://chipagames-postgresql:5432/chipagames&#xA;            - JHIPSTER_SLEEP=30&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;        ports:&#xA;            - 8080:8080&#xA;    chipagames-postgresql:&#xA;        image: postgres:9.6.5&#xA;        environment:&#xA;            - POSTGRES_USER=chipagames&#xA;            - POSTGRES_PASSWORD=&#xA;&#xA;    users-app:&#xA;        image: users&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://users-postgresql:5432/users&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=users-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    users-postgresql:&#xA;        image: postgres:10.4&#xA;        environment:&#xA;            - POSTGRES_USER=users&#xA;            - POSTGRES_PASSWORD=&#xA;    users-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    jhipster-registry:&#xA;        extends:&#xA;            file: jhipster-registry.yml&#xA;            service: jhipster-registry&#xA;&#xA;    jhipster-elasticsearch:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-elasticsearch&#xA;    jhipster-logstash:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-logstash&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-console:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-console&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-import-dashboards:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-import-dashboards&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-zipkin:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-zipkin&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;</code></pre>&#xA;"
49284804,Understanding Microservice Architecture,2018-03-14 18:02:37,<spring><mongodb><docker><jar><microservices>,3,74,0,0.0,0,"<p>Since I am trying hard to understand the microservice architecture pattern for some work, I came across the following question:</p>&#xA;&#xA;<p>It's always said that a microservice usually has its own database. But does this mean that it always has to be on the same server or container (for example having <strong>one</strong> docker container that runs a MongoDB and my JAR)? Or can this also mean that on one server my JAR is running while my MongoDB is located somewhere else (so <strong>two</strong> containers for example)?</p>&#xA;&#xA;<p>If the first one is correct (JAR <strong>and</strong> database within <strong>one</strong> container), how can I prevent that after some changes regarding my application and after a new deployment of my JAR my data of the MongoDB is resetted (since a whole new container is now running)?</p>&#xA;&#xA;<p>Thanks a lot already :-)</p>&#xA;"
49349235,"Micro-services architecture, need advise",2018-03-18 14:48:43,<microservices>,5,104,0,1.0,0,"<p>We are working on a system that is supposed to 'run' jobs on distributed systems.</p>&#xA;&#xA;<p>When jobs are accepted they need to go through a pipeline before they can be executed on the end system.</p>&#xA;&#xA;<p>We've decided to go with a micro-services architecture but there one thing that bothers me and i'm not sure what would be the best practice.</p>&#xA;&#xA;<p>When a job is accepted it will first be persisted into a database, then - each micro-service in the pipeline will do some additional work to prepare the job for execution.</p>&#xA;&#xA;<p>I want the persisted data to be updated on each such station in the pipeline to reflect the actual state of the job, or the its status in the pipeline.</p>&#xA;&#xA;<p>In addition, while a job is being executed on the end system - its status should also get updated.</p>&#xA;&#xA;<p>What would be the best practice in sense of updating the database (job's status) in each station:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each such station (micro-service) in the pipeline accesses the database directly and updates the job's status</p></li>&#xA;<li><p>There is another micro-service that exposes the data (REST) and serves as DAL, each micro-service in the pipeline updates the job's status through this service</p></li>&#xA;<li><p>Other?....</p></li>&#xA;</ol>&#xA;&#xA;<p>Help/advise would be highly appreciated.</p>&#xA;&#xA;<p>Thanx a lot!!</p>&#xA;"
49353369,Microservices and messaging,2018-03-18 22:16:25,<microservices><messaging>,1,43,3,0.0,0,<p>I'm in the process of restructuring my first application to use microservices and messaging using an event driven architecture. I will have a content microservice to retrieve content from various sources and add to a message queue for processing. My query is that should the content microservice store the content in its own database as well or is that redundant as I am using messaging?  </p>&#xA;
49390064,Is it possible to create an exposed kubernetes service based on a new deployment in one command?,2018-03-20 16:57:44,<kubernetes><containers><cluster-computing><microservices>,1,23,5,0.0,0,<p>I feel this must be possible but haven't managed to find docs on how to do this.</p>&#xA;&#xA;<p>I would ideally like to add service exposure details in a deployment yaml file and the service would come up with a host name and port upon the issuing of a create command with the deployment yaml. </p>&#xA;
46813736,Microservices are compatible with existing SQL database?,2017-10-18 15:21:30,<sql><database-design><architecture><rabbitmq><microservices>,3,260,0,0.0,0,"<p>I'm creating a microservice architecture with Core, rabbitMQ, strangler pattern ... but I have to use an existing SQL database (Transaction requeriment).</p>&#xA;&#xA;<p>Doing a research I don't found a lot of information about how implement SQL database, but I think it's impossible to do a transactional operation on different services at the same time.</p>&#xA;&#xA;<p>1- Every service must have access to entirely database?</p>&#xA;&#xA;<p>2- Is a good idea do a service exclusive to do transactionals operations?</p>&#xA;&#xA;<p>3- SQL with microservices it's maybe too much slow?</p>&#xA;&#xA;<p>I don't know if exist a standard for this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46725906,Spring boot micro services rest API security,2017-10-13 08:43:38,<rest><security><spring-boot><oauth><microservices>,1,691,0,0.0,0,<p>Am newbie to spring boot micro services. I have 3 micro service that are</p>&#xA;&#xA;<pre><code>1. Login authentication&#xA;2. User service&#xA;3. Account service.&#xA;4. UI Service&#xA;</code></pre>&#xA;&#xA;<p>UI Service contains UI part this micro service will calls other API's. First 3 services should validate every rest api calls. I need to implement security for rest api calls that need to be global and shared across all micro services. What would be the best approach without using oauth. Because OAuth need server. Hence without this is there any way to achieve this. I googled and not getting clear view. how to resolve this</p>&#xA;
46717204,Microservices sequential data processing,2017-10-12 19:10:19,<multithreading><microservices><partitioning><seq>,1,31,3,0.0,0,"<p>Suppose I am receiving a stream of unordered sequential data in time.</p>&#xA;&#xA;<p>For example, input could be:</p>&#xA;&#xA;<pre><code>[&#xA;    {id:1, timestamp:1},&#xA;    {id:2, timestamp:1},&#xA;    {id:2, timestamp:2},&#xA;    {id:1, timestamp:2},&#xA;    {id:3, timestamp:1}&#xA;] &#xA;</code></pre>&#xA;&#xA;<p>Each entity is identified by 'id' field. There could be a large amount of entities and processing for each input could take some time. &#xA;The problem is that I need to process each of those events in order it was received for each entity. </p>&#xA;&#xA;<p>I was considering some solutions as to put messages to Kafka topic with partitions and receive parallelism?&#xA;Or create local storage of received messages and marking each processed message for each entity after successful processing (on other machine or on the same in Thread pool)?</p>&#xA;&#xA;<p>Questions:&#xA;Is it is a good solution? &#xA;How can I reach this functionality while scaling data consumers (having fixed number of services/ creating new instances)? &#xA;Maybe there is a better way to solve such kind of problem?</p>&#xA;"
46764158,"Design an application with multiple request sources: WS(SOAP\REST), MQ, batch",2017-10-16 06:29:57,<java><java-ee><design-patterns><microservices><enterprise-architecture>,1,41,3,1.0,0,"<p>I have to design an application which gets requests from multiple sources like Web service (can be SOAP or REST), online system, Message Queue or some batch job. Application needs to interface with 2 more applications for getting results. I understand that this can be done using microservices. This application needs to be built in Java. I am looking for some framework which can help me with accepting input from multiple sources as mentioned above.</p>&#xA;"
46782161,User preferences with microservice architecture,2017-10-17 03:49:05,<amazon-web-services><microservices><user-preferences>,1,178,4,0.0,0,"<p>Me and my team are implementing a product based on microservices architecture(<strong><em>every microservice has it's own data storage</em></strong>). We already have a couple of services deployed on AWS and we need to add an ability to save user preferences like:</p>&#xA;&#xA;<ol>&#xA;<li>Saved filters to query data</li>&#xA;<li>UI widget settings</li>&#xA;<li>Columns order</li>&#xA;<li>etc</li>&#xA;</ol>&#xA;&#xA;<p><strong>I think that we have the following options to implement saving user-preferences in my case:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Extend user profile(it is used to store companies and users, roles) service and add new items there</li>&#xA;<li>Create new microservice for keeping only user preferences</li>&#xA;<li>Use some of AWS services for that(I am still checking what is the best)</li>&#xA;</ol>&#xA;&#xA;<p><strong>What we use for security:</strong></p>&#xA;&#xA;<ul>&#xA;<li>AWS Cognito</li>&#xA;<li>SAML IDP</li>&#xA;<li>JWT tokens</li>&#xA;</ul>&#xA;&#xA;<p>We also have user-profile microservice(I mentioned earlier). It contains data received from other products like admin service.</p>&#xA;&#xA;<p>What do you think? What is the best option for my case?</p>&#xA;"
46786169,How to check the request body parameters type validation in akka http micro-services?,2017-10-17 08:52:38,<scala><akka><microservices><akka-http>,1,326,6,1.0,0,"<p>my Object is</p>&#xA;&#xA;<pre><code>case class  Request(id:Int,name:String,phone:String)&#xA;</code></pre>&#xA;&#xA;<p>my request in postman is</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"":   ""1205"", **here i have changed the request body parameter type Int to String**&#xA;    ""name"":     ""sekhar"",&#xA;    ""phone"":""1234567890""&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>how can I check the request parameter is valid or invalid when my request body field is the wrong data type</p>&#xA;&#xA;<p>I have used</p>&#xA;&#xA;<pre><code>implicit def myRejectionHandler = RejectionHandler.newBuilder()&#xA;    .handle {&#xA;      case MissingQueryParamRejection(param) =&gt;&#xA;        println("" Test1  "")&#xA;        val errorResponse = ErrorResponse(BadRequest.intValue, ""Missing Parameter"", s""The required $param was not found."")&#xA;        var json:JsValue=Json.toJson(errorResponse)&#xA;        complete(HttpResponse(BadRequest, entity = HttpEntity(ContentTypes.`application/json`, json.toString())))&#xA;    }&#xA;    .handle { case MissingFormFieldRejection(msg) =&gt;&#xA;      println("" Test2  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handle { case MalformedQueryParamRejection(msg,error,cause) =&gt;&#xA;      println("" Test3  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handleAll[MethodRejection] { methodRejections =&gt;&#xA;    val names = methodRejections.map(_.supported.name)&#xA;     println("" Test4  "")&#xA;    complete((MethodNotAllowed, s""Can't do that! Supported: ${names mkString "" or ""}!""))&#xA;    }&#xA;    .handleNotFound { complete((NotFound, ""Not here!"")) }&#xA;    .result()&#xA;&#xA;val routes: Route = handleRejections(myRejectionHandler) {&#xA;    //Routes &#xA;  }&#xA; Http().bindAndHandle(routes, ""localhost"", 8090)&#xA;</code></pre>&#xA;&#xA;<p>it's, again and again, takes only handleAll[MethodRejection] when being changed the query params(for the false parameter too) on that time too.</p>&#xA;"
38647186,In a microservices based architecture how would i go about database access?,2016-07-28 21:40:04,<database><hibernate><microservices>,1,714,0,0.0,0,<p>I am trying to push myself into developing a set of microservices for a personal project that will essentially:</p>&#xA;&#xA;<p>Use elastic search&#xA;Poll various data stores&#xA;place data and read data from a data store&#xA;Expose a rest api to users</p>&#xA;&#xA;<p>for the purposes of this example lets say I had a bookings MS and a Sales MS</p>&#xA;&#xA;<p>The first thing that occurred to me was how to handle data storage.</p>&#xA;&#xA;<ol>&#xA;<li>Should each MS have its own data store?</li>&#xA;<li>Should I introduce a Persistence MS which handles all data from all other micro services (seems odd to do this).</li>&#xA;<li>Should each MS share a database but handle its own transactions.</li>&#xA;</ol>&#xA;&#xA;<p>In the case where you have each service handling its own persistence will that not significantly bloat a micro service to the point where you have a lot of boilerplate code and a large overall footprint of libraries (as an example hibernate would be a required library across every project and it seems terrible to have every MS having to load the same set of libraries).</p>&#xA;&#xA;<p>So I suppose the overriding question is what is the accepted methodology for managing database connectivity across a micro service architecture.</p>&#xA;
38492639,Auditing Microservices,2016-07-20 23:52:50,<java><web-services><microservices>,1,892,2,0.0,0,<p>I have list of microservices I am calling multiple services from same controller.&#xA;I want to track the change of the object state before and after service.</p>&#xA;&#xA;<p>How the design should be or there any standards to audit microservices?</p>&#xA;&#xA;<p>Thanks Vijay</p>&#xA;
44965110,How to call other REST APIs from your node micro-service and send the result as a response?,2017-07-07 07:35:37,<node.js><backend><microservices><es6-promise><request-promise>,2,1166,0,0.0,0,"<p>I am currently trying to implement a BFF (backend for front end architecture).</p>&#xA;&#xA;<p>Using <code>request-promise</code> library I can successfully hit the other microservice but not able to return the result as a response from BFF microservice.</p>&#xA;&#xA;<p>Each time it is returning this result <code>Promise { pending }</code> pending state, could somebody please help me out on this?</p>&#xA;&#xA;<p>My main issue is to know how to receive data into BFF microservice from the other microservice that we are hitting and returning the result from microservice which is hitting other one.</p>&#xA;&#xA;<p>Or if somebody could help me to let know how to access the result from inside <code>.then</code> of any promise?</p>&#xA;&#xA;<p>The flow is like this:</p>&#xA;&#xA;<pre><code>client(ios/android)===(sends request)==&gt;BFF Microservice==&gt;BP microservice&#xA;</code></pre>&#xA;&#xA;<p>(BFF Microservice handles the request and returns the response on the basis of result received from other microservice)</p>&#xA;&#xA;<p>Microservice code which is calling another microservice:</p>&#xA;&#xA;<pre><code>import yagmodel from '../../lib/models/yag-model'&#xA;import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;import config from 'config'&#xA;&#xA;//template below to call the REST APIs of other microservices.&#xA;&#xA;export async function getAllBP (req,res) {&#xA;    let yagresponse// this varaible is defined to get data from inside(rs.then )&#xA;&#xA;    const username= req.swagger.params.username.value&#xA;    const authheader= req.swagger.params.Authorization.value&#xA;    console.log(""Authorization:""+authheader)&#xA;&#xA;    let rs= await yagmodel.bp(username,authheader)&#xA;    console.log(rs)&#xA;&#xA;    rs.then((response)=&gt;{&#xA;        // console.log(response.body)&#xA;        yagresponse=response.body&#xA;        //console.log(rsp)&#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;&#xA;    res.status(200).send(yagresponse) &#xA;}&#xA;</code></pre>&#xA;&#xA;<p><code>yag-model.js</code> code:</p>&#xA;&#xA;<pre><code>import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;&#xA;module.exports.bp = async function getBP(username,authheader){&#xA;    const options={&#xA;        uri: `http://localhost:4000/Health/BP/`+username,&#xA;        json: true,&#xA;        resolveWithFullResponse: true,&#xA;        headers: {&#xA;            'Content-Type': 'application/json; charset=utf-8',&#xA;            'Accept': 'application/json; charset=utf-8',&#xA;            'Authorization':authheader&#xA;        },&#xA;        method: 'GET'&#xA;    }&#xA;&#xA;    return request(options).then ((response)=&gt;{&#xA;        return response.body        &#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;}&#xA;</code></pre>&#xA;"
45058457,How to Auto Scale Microservices in Local server without cloud using JAVA,2017-07-12 13:03:10,<spring-boot><microservices><spring-boot-maven-plugin>,1,1697,0,0.0,0,"<p>Hi I am new to the microservices. I have created spring boot(maven) microservices (2 services, 1 gateway and service registry). How can I scale (auto scaling) 2 services without cloud technology. Is it possible in the local configuration? </p>&#xA;"
45085790,"Spring cloud DiscoveryClient. getLocalServiceInstance() deprecated, how to use Registration?",2017-07-13 15:57:59,<java><spring><microservices><spring-cloud><auto-registration>,1,734,1,0.0,0,"<p>I have a requirement to get the current instance-id of the running microservice, the problem is that I have the requirement that if the process is not registered a ""random generated"" instance id has to be provided.</p>&#xA;&#xA;<p>I'm trying to get the service instance id from the DiscoveryClient but as the code points out the <code>getLocalServiceInstance</code> is deprecated and I can't use it.</p>&#xA;&#xA;<p>I tried to use the <code>Registration</code> as stated in the javadoc but coudn't find a way to get it initialized.</p>&#xA;&#xA;<p>Is there a conventional/specific way to get a service own registration?</p>&#xA;&#xA;<p>Btw, I cannot use a direct implementation because it is a starter that does not know what DiscoveryService implementation will be available at runtime.</p>&#xA;&#xA;<pre><code>/**&#xA; * @deprecated use the {@link org.springframework.cloud.client.serviceregistry.Registration} bean instead&#xA; *&#xA; * @return ServiceInstance with information used to register the local service&#xA; */&#xA;@Deprecated&#xA;ServiceInstance getLocalServiceInstance();&#xA;</code></pre>&#xA;"
44977364,How does Microservices in practice work?,2017-07-07 18:20:26,<web><architecture><microservices>,2,165,2,2.0,0,"<p>In theory I understand how Microservices work and why they can be helpful in various cases but I still don´t get how it works in practice.</p>&#xA;&#xA;<p>Let´s say there´s an online shop based on a CMS as a monolith application.</p>&#xA;&#xA;<p>And there´s now the need to run the online shop in a MIcroservices architecture. </p>&#xA;&#xA;<p>How would this Microservices architecture differ technically from the current, monolith, architecture?</p>&#xA;&#xA;<p>For example, I pick out the productsearch.php. If i want to scale this function, normally I had to set up a new server and copy the whole CMS ressources folder to it for loadbalancing. </p>&#xA;&#xA;<p>And with Microservices, productsearch.php would be a single Microservice I guess, and I would have to just copy this php file to scale without the need to copy other ressources?</p>&#xA;"
45031529,Create service instances with parameters in Service Fabric,2017-07-11 10:09:01,<c#><azure><microservices><azure-service-fabric><azure-iot-hub>,1,171,3,0.0,0,"<p>I'm using Service Fabric on Azure for a project at work where, put simply, I have a service whose function is to read data from IoT Hub.</p>&#xA;&#xA;<p>As it stands, that service is reading data from 32 partitions at the same time (multiple threads), but I'm trying to refactor it into one service intance per partition. The problem is I can't find a way to create 32 instances of a service and inform each instance of the Hub partition it should read (paramethers perhaps?).</p>&#xA;&#xA;<p>I can provide code samples if needed, but I feel the problem is pretty self-explanatory.</p>&#xA;"
45023334,How to efficiently handle spring boot microservices?,2017-07-10 23:55:58,<java><spring><spring-boot><dns><microservices>,2,192,4,0.0,0,"<p>I have bunch of spring boot microservices running in unique ports. How do we handle these microservices in production ?</p>&#xA;&#xA;<p>In production, we only need the DNS, how do we handle the DNS mapping.</p>&#xA;&#xA;<p>For ex:&#xA;<em>example-microservice-1 (port: 8001)<br>&#xA;example-microservice-2 (port: 8002)<br>&#xA;example-microservice-3(port: 8003)<br>&#xA;example-microservice-4 (port: 8004)<br>&#xA;example-microservice-5 (port: 8005)</em>  </p>&#xA;&#xA;<p>I would want something like below,<br>&#xA;<em>myprod.com/example-microservice-1<br>&#xA;myprod.com/example-microservice-2</em>   ...</p>&#xA;&#xA;<p>Instead of,<br>&#xA;<em>myprod:8001/example-microservice-1<br>&#xA;myprod:8002/example-microservice-2</em>  </p>&#xA;&#xA;<p>(removed ""https/http"" above due to less reputation) </p>&#xA;&#xA;<p>All the microservices exists in a different codebase and when build will create individual runnable jars.</p>&#xA;"
44936115,Authorization in microservice architecture,2017-07-05 21:15:11,<scope><authorization><microservices>,1,695,8,1.0,0,"<p>currently I develop a backend based on the microservice architecture.&#xA;Unfortunately, I have a problem how to realize the authorization.</p>&#xA;&#xA;<p>So let me explaine my system - there are the following services:</p>&#xA;&#xA;<ul>&#xA;<li>OAuth 2.0 Service (issuing JWT)</li>&#xA;<li>Group Service</li>&#xA;<li>Some Ressource Services (e.g. ToDos Service)</li>&#xA;</ul>&#xA;&#xA;<p>Every user is in one or many groups.&#xA;Each resource (like a ToDo list) also belongs to a group.&#xA;That means if some user creates a todo list, that list gets stored in the name of the group.</p>&#xA;&#xA;<p>Szenario:</p>&#xA;&#xA;<ul>&#xA;<li>User A is in group A</li>&#xA;<li>User B is in group A and B</li>&#xA;<li>User C is in group C</li>&#xA;<li>User A creats a ToDo list in group A.</li>&#xA;<li>User B modifies this ToDo list (he is allowed to do this since he is also in group A)</li>&#xA;<li>User C also tries to modify this ToDo list, but he shouldn't allowed to do this since he is only in group C.</li>&#xA;</ul>&#xA;&#xA;<p>Has any body a great idea how I could realize this in a microservice architecture and keep the dependencies between the services on a minimum?</p>&#xA;&#xA;<p>Certainly, I could ask on every request the Group Service if the user is in the group to which the resource belongs to. But so I get a really hard dependency between the Resource Services and the existence of a Group Service - I like to avoid this dependency.&#xA;Another option would be to store all groups, to which the user belongs to, in the access token. But with this option the client has to ask every time the OAuth Service for a new token when the user gets a member of a new group.</p>&#xA;&#xA;<p>So is there any other option how I could realize this szenario?</p>&#xA;"
49013500,OAuth 2.0 Flows for Microservice Architectures,2018-02-27 16:31:08,<oauth-2.0><authorization><microservices><auth0>,3,248,0,0.0,0,"<p>I'm trying to understand how to best apply the OAuth 2.0 grant types to a microservice architecture I am working on. Here's the situatation...</p>&#xA;&#xA;<p>I have a Single-Page Application/Mobile App acting as a client running in a web browser (browser acting as the user agent) or mobile phone. I use the <strong>Implicit Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.2"" rel=""nofollow noreferrer"">RFC 6749, section 4.1</a> to authenticate a user and acquire an access token that the app uses to access some externally exposed API.</p>&#xA;&#xA;<p>The architecture I am dealing with is a collection of microservices that call on one another. For example, consider an externally exposed API <code>serviceA</code> and internal APIs <code>serviceB</code> and <code>serviceC</code>. Let's say <code>serviceA</code> depends on <code>serviceB</code> which subsequently depends on <code>serviceC</code> (<code>A</code> --> <code>B</code> --> <code>C</code>). </p>&#xA;&#xA;<p>My question is, what is the typical authorization flow for this situation? Is it standard to use Implicit Grant for the SPA to acquire an access token and then use the <strong>Client Credentials Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.4"" rel=""nofollow noreferrer"">RFC 6749, section 4.4</a> to acquire an access token for the machine to machine interaction between <code>serviceB</code> and <code>serviceC</code>?</p>&#xA;"
48956086,Patterns to segregate Models and DbContext on ASP.NET Core microservices,2018-02-23 20:55:05,<design-patterns><asp.net-core><.net-core><microservices><ef-core-2.0>,1,79,3,0.0,0,"<p>I'm trying to make my services to deploy individually without depending on each other.</p>&#xA;&#xA;<p>All services will be using the same SQL database using EF Core (same DbContext).</p>&#xA;&#xA;<p>I'm using a separate project (MyServices.Data) that has all my models and the DbContext, but I'm really dependent on this and if there is any change on this Data project, all services needs to be redeployed.</p>&#xA;&#xA;<p>Is there any pattern/approach to this situation so I can have my project not dependant on it?</p>&#xA;"
36719045,kafka + storm topology vs microservices,2016-04-19 12:53:41,<java><apache-kafka><apache-storm><microservices>,2,724,1,1.0,0,"<p>what's the benefit of using storm topology when one can use microservices that connect to kafka directly. the microservice approach seems to offer much better solution for:</p>&#xA;&#xA;<ul>&#xA;<li>tools (every possible library, IoC container etc)</li>&#xA;<li>continuous deployment (existing tools and best practices)</li>&#xA;</ul>&#xA;&#xA;<p>while storm topology seems to use plain java with need of static functions. </p>&#xA;&#xA;<p>so what are the benefits of using storm topology instead of microservices?</p>&#xA;"
36775802,Sharing huge data between microservices,2016-04-21 16:42:08,<microservices>,2,2005,1,0.0,0,"<p>I am designing an review analysis platform in microservices architecture. </p>&#xA;&#xA;<p>Application is works like below;</p>&#xA;&#xA;<ul>&#xA;<li>all product reviews retrieved from ecommerce-site-a ( site-a ) as an excel file </li>&#xA;<li>reviews are uploaded to system with excel </li>&#xA;<li>Analysis agent can list all reviews, edit some of them, delete or approve</li>&#xA;<li>Analysis agent can export all reviews for site-a</li>&#xA;<li>Automated regexp based checks are applied for each review on upload and editing. </li>&#xA;</ul>&#xA;&#xA;<p>I have 3 microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Reviews: Responsible for Review Crud operations plus operations similar to approve/reject..</li>&#xA;<li>Validations: Responsible for defining and applying validation rules on review.</li>&#xA;<li>Export/Import: Export service exports huge files given site name (like site-a)</li>&#xA;</ul>&#xA;&#xA;<p><strong>The problem is</strong> at some point, validation service requires to get all reviews for site-a, apply validation rules and generate errors if is there any. I know sharing database schema's and entities breaks micro-services architecture.</p>&#xA;&#xA;<p>One possible solution is</p>&#xA;&#xA;<ul>&#xA;<li>Whenever validation service requires reviews for a site, it requests gateway, gateway redirects request to Reviews service and response taken. </li>&#xA;</ul>&#xA;&#xA;<p>Two <strong>possible drawbacks</strong> of this approach is</p>&#xA;&#xA;<ul>&#xA;<li>validation service <strong>knows</strong> about gateway? Is it brings a dependency?</li>&#xA;<li>in case I have 1b reviews for a site, getting all reviews via rest request may be a problem. ( or not, I can make paginated requests from validation service to gateway..)  </li>&#xA;</ul>&#xA;&#xA;<p>So what is the best practice for sharing huge data between micro-services without </p>&#xA;&#xA;<ul>&#xA;<li>sharing entity</li>&#xA;<li>and dublicating data</li>&#xA;</ul>&#xA;&#xA;<p>I read lot about using messaging queues but I think in my case it is not good to use messaging queue to share gigabytes of data.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>edit 1: Instead of sharing entity, using data stores with rest API can be a solution? Assume I am using mongodb, instead of sharing my entity object between microservices, I can use rest interface of mongo (<a href=""http://restheart.org/"" rel=""nofollow"">http://restheart.org/</a>) and query data whenever possible.  </p>&#xA;"
36760694,Working example of spring watchservicedirectoryscanner,2016-04-21 05:50:13,<java><spring><spring-mvc><spring-boot><microservices>,2,1137,2,0.0,0,"<p>I'm struggling to implement a <code>WatchServiceDirectoryScanner</code>. I want to use the scanner to monitor new file uploads to a directory + sub directories. This will exist as part of a Spring boot MVC microservice. I can do this using Java 7's <code>WatchService</code> but would prefer a spring file integration style, AOP style</p>&#xA;&#xA;<p>I have it registered as a <code>@Bea</code>n in my app config but I'm struggling to figure out how to have it poll and scan a directory and then call... something (a message endpoint?) when a file is detected. Is anyone able to point me in the right direction for even conceptually how this is done. I cannot find an example implementation of this anywhere.</p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner"" rel=""nofollow"">http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner</a></p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-"" rel=""nofollow"">http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-</a></p>&#xA;&#xA;<p>here is my Spring appConfig:</p>&#xA;&#xA;<pre><code>public class appConfig {&#xA;    @Bean&#xA;    public DirectoryScanner scanner() {&#xA;        return new WatchServiceDirectoryScanner(""/uploads/test"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
36694873,Token/stateless auth in Silex application with a Microservice architecture?,2016-04-18 13:05:31,<php><session><authentication><silex><microservices>,1,710,2,0.0,0,"<p>I would like to use Silex as a base framework for couple of services. It would be used by different clients and apis (mobile, web etc.) so I'm generally trying to avoid cookies/session and 'do it' using headers.</p>&#xA;&#xA;<p>Setup/flow of what I'm trying to achieve:</p>&#xA;&#xA;<ol>&#xA;<li><p>user logins in his mobile app/on webpage producing request to authservice.domain.com, gets back new token as a response which is as well registered in token store</p></li>&#xA;<li><p>when user access from web or mobile app products.domain.com the token is read from the headers and checked in store</p></li>&#xA;</ol>&#xA;&#xA;<p>Everything looks beautiful, but somehow I cannot make Silex add headers to requests following the login step, I'm able to add it to response, but not to request (i tried using before/after middleware so 1st auth, then add token in $app->after/before)... btw. im not sure if I understand it right, but if a user press a refresh page button when setting headers this way won't the custom header get lost? if that's the case is it possible to keep token persisted in headers without cookies/sessions after all?</p>&#xA;&#xA;<p>Here's example code I'm running after getting token, it gets sets on response (and i can see it in chrome), but it won't get set on request - I tried as well using with before middleware</p>&#xA;&#xA;<pre><code>    $this-&gt;after(function(Request $request, Response $response) {&#xA;        $response-&gt;headers-&gt;set(""X-token"",""2"");&#xA;        $request-&gt;headers-&gt;set(""X-token"",""2"");&#xA;    });&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions on how I can achieve this? So... stateless auth using  headers over multiple services in plain (Silex : )) php without keeping token in cookies or (api gateway) sessions? </p>&#xA;"
36638486,Unable to run node js seneca microservice,2016-04-15 04:50:05,<node.js><api><microservices>,1,258,5,0.0,0,"<p>I am new in node js. I try to run my first node microservice using seneca framework. But it shows following error</p>&#xA;&#xA;<pre><code>&gt; npm ERR! Linux 4.2.0-16-generic&#xA;&gt; &#xA;&gt; npm ERR! argv ""/usr/local/bin/node"" ""/usr/bin/npm"" ""start""&#xA;&gt; &#xA;&gt; npm ERR! node v5.10.1&#xA;&gt; &#xA;&gt; npm ERR! npm  v3.8.6&#xA;&gt; &#xA;&gt; npm ERR! code ELIFECYCLE&#xA;&gt; &#xA;&gt; npm ERR! myproject@0.0.1 start: `node server.js`&#xA;&gt; &#xA;&gt; npm ERR! Exit status 2&#xA;&gt; &#xA;&gt; npm ERR! &#xA;&gt; &#xA;&gt; npm ERR! Failed at the myproject@0.0.1 start script 'node server.js'.&#xA;&gt; &#xA;&gt; npm ERR! Make sure you have the latest version of node.js and npm &#xA;&gt; installed.&#xA;&gt; &#xA;&gt; npm ERR! If you do, this is most likely a problem with the myproject&#xA;&gt; package,&#xA;&gt; &#xA;&gt; npm ERR! not with npm itself.&#xA;&gt; &#xA;&gt; npm ERR! Tell the author that this fails on your system:&#xA;&gt; &#xA;&gt; npm ERR!     node server.js&#xA;&gt; &#xA;&gt; npm ERR! You can get information on how to open an issue for this&#xA;&gt; project with:&#xA;&gt; &#xA;&gt; npm ERR!     npm bugs myproject&#xA;&gt; &#xA;&gt; npm ERR! Or if that isn't available, you can get their info via:&#xA;&gt; &#xA;&gt; npm ERR!     npm owner ls myproject&#xA;&gt; &#xA;&gt; npm ERR! There is likely additional logging output above.&#xA;&gt; &#xA;&gt; &#xA;&gt; npm ERR! Please include the following file with any support request:&#xA;&gt; &#xA;&gt; npm ERR!     ~/Desktop/micro services/myproject/npm-debug.log&#xA;</code></pre>&#xA;&#xA;<p>i use Seneca.js Yeoman generator to create this project. Please anyone help me.</p>&#xA;&#xA;<p>my project directry looks like the following structure</p>&#xA;&#xA;<pre><code>        test-seneca&#xA;        |&#xA;        |-- client&#xA;        |   |-- css&#xA;        |   |-- js&#xA;        |   |-- partials&#xA;        |   |-- index.html&#xA;        |-- server&#xA;        |   |-- api.js&#xA;        |-- test&#xA;        |   |-- functional&#xA;        |-- bower.json&#xA;        |-- package.json&#xA;        |-- server.js &#xA;</code></pre>&#xA;&#xA;<p>my package.json is</p>&#xA;&#xA;<pre><code>{&#xA;&#xA;  ""name"": ""myproject"",&#xA;&#xA;  ""version"": ""0.0.1"",&#xA;&#xA;  ""scripts"": {&#xA;&#xA;    ""postinstall"": ""./node_modules/.bin/webdriver-manager update --standalone &amp;&amp; ./node_modules/.bin/bower install"",&#xA;&#xA;    ""test"": ""./node_modules/.bin/protractor test/functional/protractor.conf.js""&#xA;&#xA;  },&#xA;&#xA;  ""dependencies"": &#xA;{&#xA;&#xA; ""async"": ""^0.9.0"",&#xA;&#xA;    ""hapi"": ""~8.2.0"",&#xA;&#xA;    ""hapi-seneca"": ""^1.0.3"",&#xA;&#xA;    ""seneca"": ""git://github.com/rjrodger/seneca.git"",&#xA;&#xA;    ""seneca-account"": ""^0.1.8"",&#xA;&#xA;    ""seneca-auth"": ""git://github.com/rjrodger/seneca-auth.git"",&#xA;&#xA;    ""seneca-card"": ""^0.1.3"",&#xA;&#xA;    ""seneca-project"": ""^0.1.4"",&#xA;&#xA;    ""seneca-user"": ""~0.2.10""&#xA;&#xA;  },&#xA;&#xA;  ""devDependencies"": {&#xA;&#xA;    ""protractor"": ""~1.7.0"",&#xA;&#xA;    ""bower"": ""~1.3.12""&#xA;&#xA;  }&#xA;&#xA;}&#xA;</code></pre>&#xA;"
44535853,Security considerations for API Gateway clustering?,2017-06-14 05:06:37,<api><security><microservices><api-gateway>,1,63,0,2.0,0,"<p><a href=""https://i.stack.imgur.com/lWDTz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lWDTz.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>Clients that communicate against a single point of entry via an API Gateway over HTTPS against a RESTful API</li>&#xA;<li>API Gateway: API Keys for tracking and analytics, oAuth for API platform authentication</li>&#xA;<li>User Micro service provides user authentication and authorization, generates JWT that is signed and encrypted (JWS,JWE)</li>&#xA;<li>Other micro services determine permissions based on claims inside JWT</li>&#xA;<li>Micro services communicate internally via PUB/SUB using JWT in the message and other info. Each micro service could be scaled out with multiple instances (cluster with a load balancer).</li>&#xA;</ol>&#xA;&#xA;<p><strong>Question</strong>: <em>Can I cluster the the API Gateway and have the load balancer in front of it.  What do I need to consider with respect to managing authentication?  ie: sharing of API Keys across the API Gateway cluster?</em>  </p>&#xA;&#xA;<p>Extra notes, I'm planning on terminating SSL at the gateway and the use of bcrypt for passwords in the db.</p>&#xA;&#xA;<p>Any feedback would be great, thank you.</p>&#xA;"
44502869,How to load a zip file in java servlet and expose as URL,2017-06-12 15:11:58,<java><url><servlets><microservices><embedded-jetty>,2,98,5,0.0,0,"<p>My requirement is loading a zip file from file system in java servlet and expose as URL (without extracting the zip file).</p>&#xA;&#xA;<p>For example, a zip file is located in C:\temp\example.zip. Content of this zip file is </p>&#xA;&#xA;<ol>&#xA;<li>example.html and its dependent files</li>&#xA;<li>one.js</li>&#xA;<li>two.js.</li>&#xA;</ol>&#xA;&#xA;<p>How to construct URL like ""<a href=""http://localhost:8080/app/example.zip/example.html"" rel=""nofollow noreferrer"">http://localhost:8080/app/example.zip/example.html</a>""? &#xA;Server could be jetty. Any help is highly appreciated. Thanks.</p>&#xA;&#xA;<p>I can even change the server or can use some other approach also to achieve the above solution. As said earlier, the only constraint is ""should not be extracted"".</p>&#xA;"
44585239,Splitting monolith to microservices database issues,2017-06-16 09:08:05,<database><oracle><join><microservices>,1,227,6,0.0,0,"<p>I am splitting monolith application to microservices and I was able to split it to three microservices, for easier explanation suppose these are:</p>&#xA;&#xA;<ul>&#xA;<li>Users (CRUD)</li>&#xA;<li>Messages (CRUD)</li>&#xA;<li>Other things (CRUD)</li>&#xA;</ul>&#xA;&#xA;<p>All of these are distinct bounded contexts and I'm using database table for microservice. So in DB i have:</p>&#xA;&#xA;<pre><code>USERS table&#xA;id&#xA;surname&#xA;lastname&#xA;...&#xA;&#xA;OTHER_THINGS table&#xA;id&#xA;col1&#xA;col2&#xA;...&#xA;&#xA;MESSAGES table&#xA;id&#xA;title&#xA;created_time&#xA;USER_ID&#xA;OTHER_THING_ID&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>Now my web page needs searching/filtering of messages by all of the specified columns of all of these tables. For example:</p>&#xA;&#xA;<p>Web page user can enter:</p>&#xA;&#xA;<ul>&#xA;<li>surname of USER, </li>&#xA;<li>col2 of OTHER_THINGS </li>&#xA;<li>title of messages </li>&#xA;</ul>&#xA;&#xA;<p>And I should return only filtered rows.</p>&#xA;&#xA;<p>With monolith I have used simple database JOINS, but in this situation I can't find the best option. Can you suggest me possible options and which ones are better?</p>&#xA;"
44484346,bash command to wait until TCP port is opened,2017-06-11 13:24:50,<java><linux><bash><microservices>,1,981,7,0.0,0,"<p>I want my micro services to open in a new command line and run it from there one after the other. below is my bash script</p>&#xA;&#xA;<pre class=""lang-bash prettyprint-override""><code>################ first SERVER #####################&#xA;gnome-terminal -x sh -c 'java -jar server/target/first-server.jar; exec bash'&#xA;&#xA;################ second SERVER #####################&#xA;export service_port=8771&#xA;export host_name=firstdomain&#xA;gnome-terminal -x sh -c 'java -Dservice.port=""${service_port}"" -Dhost.name=""${host_name}"" -jar eureka/target/second-server.jar; exec bash'&#xA;</code></pre>&#xA;&#xA;<p>The problem is it that i want to start my <strong>""second-server.jar""</strong> after successfully started the <strong>""first-server.jar""</strong>. I can detect that by checking if the service is listening to network port. Is there any way to archive this? <strong>sleep</strong> bash command is not a option for me.</p>&#xA;"
37684678,"Integration Tests with Microservices (NodeJS), Jenkins and Docker",2016-06-07 16:31:18,<node.js><git><jenkins><docker><microservices>,1,599,0,0.0,0,"<p>How would you typically configure Jenkins to build microservices (multiple NodeJS services, Rabbit, Mongo, etc), then test those services all together ?</p>&#xA;&#xA;<p>Let's say I've the following services:</p>&#xA;&#xA;<ul>&#xA;<li>RabbitMQ</li>&#xA;<li>Mongo</li>&#xA;<li>NodeJS Service 1</li>&#xA;<li>NodeJS Service 2</li>&#xA;</ul>&#xA;&#xA;<p>Each of them has their own tests (unit and integration) and their Dockerfile.</p>&#xA;&#xA;<p>I want to configure Jenkins in a way that it would enable me to clone all theses services, run them all at the same time in different containers with Rabbit and Mongo containers along them. It would then run the tests for each of those services (they do generate TAP and coverage reports). Then take those reports for the TAP/Coverage Jenkins plugins. If it works out, commit the image and push it to the docker registry.</p>&#xA;&#xA;<p>I've been lying around Stack and Google and I don't really see an easy way to get there that would not imply tons of bash.</p>&#xA;&#xA;<p>Maybe I see it in the wrong way, any input is more than welcome!</p>&#xA;"
37715757,Trade-offs of microservices and modularity architectural design?,2016-06-09 02:09:10,<design><osgi><polymorphic-associations><microservices><modularity>,1,124,3,0.0,0,"<p><a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow"">Microservices</a> and <a href=""https://en.wikipedia.org/wiki/Modular_programming"" rel=""nofollow"">Modular Programming</a> has proved to be a proper choice when design a software system. Benefits of it includes reusability, distributability, readability, etc.</p>&#xA;&#xA;<p>We are a MOOC site using OSGI as modularity implementation:</p>&#xA;&#xA;<ul>&#xA;<li>Each feature have its own database, service, and standalone web application</li>&#xA;<li>Direct access to database of other feature is prohibited</li>&#xA;</ul>&#xA;&#xA;<p>Take 3 features as a example:</p>&#xA;&#xA;<pre><code>     course               project         Q&amp;A(question&amp;answer)&#xA;&#xA;+---------------+    +---------------+    +---------------+&#xA;|     web       |    |     web       |    |     web       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     service   |    |     service   |    |     service   |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     dao       |    |     dao       |    |     dao       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     Database  |    |     Database  |    |     Database  |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;</code></pre>&#xA;&#xA;<p>Requirements:</p>&#xA;&#xA;<ol>&#xA;<li>Every course/project has Q&amp;A module, user that participated-in can ask question about this course/project here.</li>&#xA;<li>A standalone global(or common) Q&amp;A entry, listing questions that aggregated from all courses/projects, and user can ask context-independent(aka, not related to any course/project) question here.</li>&#xA;</ol>&#xA;&#xA;<p>I do not know if this design or architecture(<strong>completely isolation from top to bottom of every feature</strong>) is good or not, but I'm facing some inconveniences indeed:</p>&#xA;&#xA;<ol>&#xA;<li><p>modular web application</p>&#xA;&#xA;<p>Q&amp;A feature is either a standalone feature and part of course/project.  Currently I'm think both embed Q&amp;A module as web component of standalone course-webapp/project-webapp, and standalone qa-webapp itself, but I have no idea what's the best way to reuse controllers to avoid duplicated code on web layer</p></li>&#xA;<li><p>rational database <a href=""https://en.wikipedia.org/wiki/Polymorphic_association"" rel=""nofollow"">Polymorphic Association</a> problem</p>&#xA;&#xA;<p>A question maybe belong to course/project, or context-independent, and id of course/project came from another database, polymorphic association is inevitable. Currently I'm using a extra column post_to_type on table question to tackle with this.</p></li>&#xA;<li><p>Let me say course/project can be private or public. questions listed under global Q&amp;A entry only include questions that belong to public course/project, not private. But again, since each feature have its own database and direct access to database of other feature is prohibited, I do not have any idea what's the elegant and efficient way to deal with this.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is something wrong with our modular design when using OSGI, or its just me thinking so uncomfortable with this? and what's the best practices to design a microservices / modular architecture, specifically in object-oriented language like Java?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
44781219,Atomic insert of data in micro service architecture + NoSql database [Data consistency in Micro service architecture],2017-06-27 13:12:50,<database-design><cassandra><architecture><microservices><nosql>,2,132,3,0.0,0,"<p>I have 3 services A, B, C. </p>&#xA;&#xA;<p>Service A receives a request from client. Then A prepares a data for its own database, service B and C. Basically A is coo-ordinator.</p>&#xA;&#xA;<ol>&#xA;<li>A insert data in its database</li>&#xA;</ol>&#xA;&#xA;<p>If it is success </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>post request B's data to service B and B insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If it is success</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>then post request C's data to service C and C insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If anything fails at any step, we have to revert all data inserted.</p>&#xA;&#xA;<p>I am using Cassandra NoSQL DB.</p>&#xA;&#xA;<p><strong>Now i need a generic solution for all cases that could happen like :</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I.</p>&#xA;&#xA;<p>Suppose C is inserting data (in progress), in the mean time, some read query R on A-database reads the inserted data. After few millisec, C fails to insert, but R already read the false data which would be reverted soon.</p></li>&#xA;</ul>&#xA;&#xA;<p>What to do in this case? &#xA;--> change the DB design, such that this kind of condition would never happen??</p>&#xA;&#xA;<ul>&#xA;<li><p>II.</p>&#xA;&#xA;<p>What if service C data insert fails, and service B have application server downtime so it couldn't revert??</p></li>&#xA;</ul>&#xA;"
44692442,Https config dosn't work in zuul routing,2017-06-22 07:07:19,<https><routing><microservices><spring-cloud><netflix-zuul>,2,943,4,0.0,0,"<p>I have a router application with zuul and many services that are run in the backend and requests from client are routed to their services by zuul.</p>&#xA;&#xA;<p>Everything is working well over http but when I configure the router and all services to https the following error is raised:</p>&#xA;&#xA;<pre><code>javax.net.ssl.SSLPeerUnverifiedException: Certificate for &lt;127.0.0.1&gt; doesn't match any of the subject alternative names: []&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:467) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.createLayeredSocket(SSLConnectionSocketFactory.java:397) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:355) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;</code></pre>&#xA;&#xA;<p>The zuul yml file :</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredPatterns: /reza,/we&#xA;  routes:&#xA;    trp:&#xA;      path: /micro1/**&#xA;      sensitiveHeaders:&#xA;      url: https://127.0.0.1:8080/micro1&#xA;server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 80&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234  &#xA;</code></pre>&#xA;&#xA;<p>And the yml file of one of those services:</p>&#xA;&#xA;<pre><code>server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 8080&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234&#xA;</code></pre>&#xA;&#xA;<p>First I want to know that the concept of https over zuul works properly and secondly I want to know how I fix my problem.</p>&#xA;&#xA;<p>Note: I don't have Eureka server registration.</p>&#xA;"
48296421,Docker Microservice Architecture - Communication between different containers,2018-01-17 08:16:40,<azure><docker><microservices><docker-container>,1,130,1,2.0,0,"<p>I've just started working with docker and I'm currently trying to work out how to setup a project using microservice architecture.</p>&#xA;&#xA;<p>My goal is to move out different services from the api and instead have each one in their own container.</p>&#xA;&#xA;<p><strong>Current architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ewRMg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ewRMg.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Desired architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/mCKD7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mCKD7.png"" alt=""To""></a></p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ol>&#xA;<li>How does the API gateway communicate with the internal services? Should all microservices have their own API which only accept communication from the API gateway? Any other means of communications?</li>&#xA;<li>What would be the ideal authentication between the gateway and the microservices? JWT token? Basic Auth?</li>&#xA;<li>Do you see any problems with this architecture if hosted in Azure?</li>&#xA;<li>Is integration testing even possible in the desired architecture? For example, I use EF SQlite inmemory for integration testing and its easily accessible within the api, but I don't see this working if the database is located in it's own container.</li>&#xA;<li>Anything important here that i've missed?</li>&#xA;</ol>&#xA;"
48190148,What is the difference between SOA and Microservices,2018-01-10 14:56:32,<web><microservices><distributed-computing><soa>,1,344,3,0.0,0,"<p>Ok, as far as I've understood both in SOA and in Microservices modules should be independant and reusable. But what really differs SOA and Microservices ?</p>&#xA;"
48374452,Dao as a Seperate Module in Monolithic Considering Extendable to microservice in future,2018-01-22 03:54:23,<java><spring><microservices>,1,114,3,0.0,0,"<p>I am actually creating one project where we are having 2 or more database. I will use Spring Boot. I would like to know:</p>&#xA;&#xA;<ol>&#xA;<li><p>Why do we have Client of the Gateways while code as we already have REST endpoint in server (May be i am wrong )?</p></li>&#xA;<li><p>My project currently will be monolithic but I want to make it possible to change to a microservice architecture in the future. Should I have the DAO as separate module which will be dependency for other module considering I can have more than one database (RDBMS and NoSQL)?</p></li>&#xA;</ol>&#xA;&#xA;<p>Hope I am asking work question, but I am confused right now, while starting the project.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
37445823,Force an Asynchronous call to behave Synchronously,2016-05-25 19:16:46,<javascript><asynchronous><reactjs><microservices>,2,250,3,0.0,0,"<p>In my React app, I'm trying to calculate a value based on three other values. I've contained all of the calculation logic to the back end, which is a microservice I make asynchronous calls to. The function in which I am asynchronously trying to get that calculated value is in the middle of many synchronous hooks. </p>&#xA;&#xA;<p>In the UI layer, I call the function which I want to return the end result (returned asynchronously). That called function calls another function, which calls another function, which returns a new Promise. See code below:</p>&#xA;&#xA;<pre><code>// DateUI.js (layer 1)&#xA;selectDate(dateField, flight, idx, saved, momentTime, e) {&#xA;    if (moment(momentTime).isValid()) {&#xA;        if (dateField == ""StartDate"") {&#xA;            // The initial problematic function call, need to set endDate before I continue on&#xA;            let endDate = PlanLineActions.calculateFlightEndDate(periodTypeId, numberOfPeriods, momentTimeUnix);&#xA;&#xA;            flight.set(""EndDate"", endDate);&#xA;        }&#xA;&#xA;        this.theNextSyncFunction(..., ..., ...);&#xA;    }&#xA;}&#xA;&#xA;&#xA;// DateActions.js (layer 2)&#xA;calculateFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let plan = new Plan();&#xA;&#xA;    plan.getFlightEndDate(periodTypeId, numberOfPeriods, startDate).then(function(response) {&#xA;        // response is JSON: {EndDate: ""12/05/2016""}&#xA;        response.EndDate;&#xA;    }, function(error) {&#xA;        log.debug(""There was an error calculating the End Date."");&#xA;    });&#xA;}&#xA;&#xA;&#xA;// DateClass.js (layer 3)&#xA;getFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let path = '/path/to/microservice';&#xA;    return this.callServer(path, 'GET', {periodTypeId: periodTypeId, numberOfPeriods: numberOfPeriods, startDate: startDate});&#xA;}&#xA;&#xA;&#xA;// ServerLayer.js (layer 4)&#xA;callServer(path, method = ""GET"", query = {}, data, inject) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        super.callServer(uri.toString(),method,data,inject).then((data) =&gt; {&#xA;            resolve(data);&#xA;        }).catch((data) =&gt; {&#xA;            if (data.status === 401) {&#xA;                AppActions.doRefresh();&#xA;            }&#xA;            reject(data);&#xA;        });&#xA;    });&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am under the impression that, because ServerLayer.js (layer 4) returns a <code>new Promise</code> (and thus DateClass.js (layer 3)), calling <code>plan.getFlightEndDate(...).then(function(response) {...</code> will not complete until the response comes back resolved or rejected. This is not currently happening, as the code in DateUI.js (layer 1) will continue on to call <code>this.theNextSyncFunction</code>, and then resolve ~50ms later with the proper data.</p>&#xA;&#xA;<p>How do I force PlanLineActions.calculateFlightEndDate(...) in DateUI.js (layer 1) to complete with a response before I continue on with selectDate()?</p>&#xA;"
37403682,A real world project using microservices architecture,2016-05-24 03:01:00,<node.js><architecture><microservices>,1,483,5,0.0,0,"<p>Anyone knows an open source project that is on microservices architecture? I need a more real app that has addressed cross-cutting concerns,etc not just an educational sample.</p>&#xA;&#xA;<p>Please introduce if you know any. Especially if it's on Node.js or C#.net stack.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37457765,Access microservice using Spring Boot,2016-05-26 10:09:12,<java><spring><spring-boot><microservices>,1,614,10,0.0,0,"<p>I have to implement my project as microservice arch. For that I am doing one sample app using Spring Boot of adding two no. I have three services. Here is my registration-server.yml.Similarly I have <code>account-server.yml</code> and <code>user-service.yml</code>. I want to call <code>add()</code> using <code>UserService.java</code> without RMI concept, since I am using Spring Boot. Also I don't want REST call since it will be costly for my project. How can I manually write code for <code>lookup()</code> in <code>UserService</code> so that it can call Adder?</p>&#xA;&#xA;<pre><code>@EnableAutoConfiguration&#xA;@EnableDiscoveryClient&#xA;public class AddService {&#xA;&#xA;public static int add(int x,int y){&#xA;    int z=x+y;&#xA;    System.out.println(""The sum of no. is ""+z);&#xA;    return z;&#xA;}&#xA;&#xA;public static void main(String[] args) {&#xA;    System.setProperty(""spring.config.name"", ""add-service"");&#xA;    SpringApplication.run(AddService.class, args);&#xA;}&#xA;&#xA;@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class RegistrationService {&#xA;&#xA;public static void main(String[] args) {&#xA;    // Tell server to look for registration.properties or registration.yml&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(RegistrationService.class, args);&#xA;}&#xA;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;public class UserService {&#xA;public static void main(String[] args) {&#xA;&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(UserService.class, args);&#xA;}&#xA;&#xA;&#xA;&#xA;&#xA;    eureka:&#xA;   instance:&#xA;    hostname: localhost&#xA;    client:  # Not a client, don't register with yourself&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;  server:&#xA;  port: 1111   # HTTP (Tomcat) port&#xA;</code></pre>&#xA;"
44105840,How to embed images and attach files from spring boot resources folder,2017-05-22 06:18:18,<rest><spring-boot><resources><microservices><amazon-ses>,1,932,0,0.0,0,"<p>Not able to embed images and attach files from spring boot resources folder</p>&#xA;&#xA;<p>I have created a Restful web service using Spring Boot (Jar file and not a War file). Some of the services will send emails and some of them will send emails with attachments (Will be created dynamically). Web part (Angular) resides in Apache server which is deployed in different server.</p>&#xA;&#xA;<p>I am using Freemarker template to compose email and using Amazon SES to send emails. </p>&#xA;&#xA;<p>from freemarker template</p>&#xA;&#xA;<pre><code>&lt;IMG src=""cid:gridEmailHeaderImage""&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Code to add image</strong></p>&#xA;&#xA;<pre><code>MimeBodyPart inlineImage = new MimeBodyPart();&#xA;DataSource fds = new FileDataSource(imagePath.getAbsolutePath());&#xA;inlineImage.setDataHandler(new DataHandler(fds));&#xA;inlineImage.setHeader(""Content-ID"", ""&lt;"" + contentId + ""&gt;"");&#xA;inlineImage.setFileName(fds.getName());&#xA;content.addBodyPart(inlineImage);&#xA;</code></pre>&#xA;&#xA;<p>I am able to embed and attach files if I provide absolute path. But if provide relative path it is not working. </p>&#xA;&#xA;<p><strong>My folder structure</strong></p>&#xA;&#xA;<pre><code>C:\workspace\service-1.0\src\main\resources\images\header.png&#xA;C:\workspace\service-1.0\src\main\resources\attachements\test-attachment-1.txt&#xA;</code></pre>&#xA;&#xA;<p>I tried the following with no sucess</p>&#xA;&#xA;<p><strong>Approach 1</strong></p>&#xA;&#xA;<pre><code>ServletContext context;&#xA;String path = context.getRealPath(""/resources/images"")+""/header.png"";&#xA;</code></pre>&#xA;&#xA;<p>It is looking for images in the following folder but the images is not available in that folder.</p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Users\username\AppData\Local\Temp\tomcat-docbase..\resources\images/header.png</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Approach 2</strong></p>&#xA;&#xA;<pre><code>basePath = this.getClass().getClassLoader().getResource(""/images/"").getPath();&#xA;</code></pre>&#xA;&#xA;<p>C:\workspace\service-1.0\src\main\resources\images\header.png</p>&#xA;&#xA;<p>/C:/workspace/service-1.0/build/libs/service-1.0.jar!/BOOT-INF/classes!/images/&#xA;(Works only from eclipse but not from command prompt java -jar build\lib\myapp.jar)</p>&#xA;&#xA;<p><strong>Approach 3</strong></p>&#xA;&#xA;<pre><code>ClassPathResource file = new ClassPathResource(""header.png"");&#xA;String mypath = file.getFile().getAbsolutePath();&#xA;</code></pre>&#xA;&#xA;<p>(This also didn't work)</p>&#xA;&#xA;<p>If I place the image in images folder under resource. I am able to view the image via the following URL.</p>&#xA;&#xA;<pre><code>http://localhost:7075/myservice/v1/images/header.png&#xA;</code></pre>&#xA;&#xA;<p>is it fine to load images from resource folder? Will spring boot jars get exploded at runtime. What is the correct way to load images from spring boot jar file.</p>&#xA;"
44129347,Microservices for job/cron tasks,2017-05-23 08:14:47,<cron><scalability><microservices>,2,989,0,0.0,0,"<p>For example I want to have a microservice to send notifications(email, sms, push notification). Everything is ok for few users. After some time our application have a lot of users, so, this microservice doe not manage, and email a sent after 1 hour. </p>&#xA;&#xA;<p>So, how to handle this situation? Deploy another instance of microservice, but how to handle that only one microservice process one email and user don't receive multiple emails?</p>&#xA;"
44021110,Resource-based vs. Entity-based structure,2017-05-17 09:40:09,<data-structures><microservices>,1,66,3,0.0,0,"<p>When it comes to designing the architecture of a system and the underlying services (consider a SOA), the database models can be designed it some ways, right... The general one is <code>entity-based</code>, which speaks for itself - the business logic is built around the entities (f.e. <code>user</code>, <code>company</code>, <code>product</code>). But when <code>resource-based</code> comes in the picture, it gets confusing. And the problem continues when I get results with very abstract or ambiguous information in google.</p>&#xA;&#xA;<p>My focus here is on a CRM service (Customer Relations Management). But I deem it better for me to understand resource-based structure in general, in order to be able to design a service in such a way.</p>&#xA;&#xA;<p>Can someone provide a concise explanation of resource-based structure and maybe compare it with entity-based?</p>&#xA;"
44148076,Mail notification from denormalized view in CQRS,2017-05-24 02:44:16,<email><microservices><cqrs>,1,69,3,0.0,0,"<p>I want to develop a mail notification service to send order approval to customer. The order data is in the denormalized view (query side) and it should be filled to the mail template. Then, we send the email in html string format via mail notification service. But, the order status should be changed to ""order approval email sent"". </p>&#xA;&#xA;<p>I also try to implement the CQRS, ES, and DDD concept in microservices architecture.&#xA;Is this procedure correct and still align with the concept?</p>&#xA;&#xA;<ol>&#xA;<li>Develop HTTP POST API in order command to send approval mail so the order status could be changed in command-side.</li>&#xA;<li>The command side generate the event ""order approval mail processed""</li>&#xA;<li>The event processor process the event. It should get the order data from query-side / denormalized view. </li>&#xA;<li>The event processor generates the approval mail from the data and fill the data to the template. </li>&#xA;<li>The event processor call HTTP POST to the mail notification service with mail body (html format) in the payload.</li>&#xA;<li>The event processor call HTTP PUT to the order service (command-side) to change the order status to ""order approval mail sent"".</li>&#xA;</ol>&#xA;&#xA;<p>But, if this procedure is applied, the user can't get the response ""mail sent"" in real-time. How to trigger the client / front-end side that the mail is successfully sent? So, the client side don't have a need to refresh or retry many calls to the API.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44084744,Microservice architecture Flaws,2017-05-20 10:25:34,<architecture><microservices><restful-architecture>,1,189,3,1.0,0,"<p>We are facing performance related issues with microservice architecture.</p>&#xA;&#xA;<p>Let's say there is microservice for user and account management. which have api's like </p>&#xA;&#xA;<pre><code>GET /users/{id} &#xA;GET /users       (arrount 6 million users)&#xA;&#xA;GET /accounts/{accountId}&#xA;GET /accounts &#xA;and Other Operations on user and account&#xA;</code></pre>&#xA;&#xA;<p>We have other microservice which track's user activities and list all the activities done by the user in his last login.</p>&#xA;&#xA;<pre><code>GET /user/activity/{userId}  (on an average 1000 to 10000 records)&#xA;</code></pre>&#xA;&#xA;<p>We have protal for sales and marketing team to show individual user activities and  user info and account info based on search criteria,</p>&#xA;&#xA;<pre><code>let's say search criteria is like : get all user activies who are located in colombia&#xA;Algorithm : &#xA;&#xA;1)Get /users ? location = colombia&#xA;2)then for individual user Get /user/activity/{userId}&#xA;</code></pre>&#xA;&#xA;<p>it is like joining two tables from different databases.</p>&#xA;&#xA;<p>it is very slow and creating lot of performance issues.</p>&#xA;&#xA;<p>what i though of is replicating user table in other microservice by a job which makes sure it is up to date and using only one api like</p>&#xA;&#xA;<pre><code>GET /user/activities?location=colombia.&#xA;</code></pre>&#xA;&#xA;<p>but replicating a table(user) is breaking the micro-service architecture main fundamentals</p>&#xA;&#xA;<p>is there any other way to do it or support this type of filter criteria which join's tables from different micro-services.</p>&#xA;"
44198061,Decision path for Azure Service Fabric Programming Models,2017-05-26 09:25:59,<azure><microservices><azure-service-fabric>,1,225,4,1.0,0,"<p><strong>Background</strong></p>&#xA;&#xA;<p>We are looking at porting a 'monolithic' 3 tier Web app to a microservices architecture. The web app displays listings to a consumer (think Craiglist).</p>&#xA;&#xA;<p>The backend consists of a REST API that calls into a SQL DB and returns JSON for a SPA app to build a UI (there's also a mobile app). Data is written to the SQL DB via background services (ftp + worker roles). There's also some pages that allow writes by the user.</p>&#xA;&#xA;<p><strong>Information required:</strong></p>&#xA;&#xA;<p>I'm trying to figure out how (if at all), Azure Service Fabric would be a good fit for a microservices architecture in my scenario. I know the pros/cons of microservices vs monolith, but i'm trying to figure out the <em>application</em> of various microservice programming models to our current architecture.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is Azure Service Fabric a good fit for this? If not, other recommendations? Currently i'm leaning towards a bunch of OWIN-based .NET web sites, split up by area/service, each hosted on their own machine and tied together by an API gateway.</li>&#xA;<li>Which Service Fabric programming model would i go for? Stateless services with their own backing DB? I can't see how Stateful or Actor model would help here.</li>&#xA;<li>If i went with Stateful services/Actor, how would i go about updating data as part of a maintenance/ad-hoc admin request? Traditionally we would simply login to the DB and update the data, and the API would return the new data - but if it's persisted in-memory/across nodes in a cluster, how would we update it? Would i have to expose this all via methods on the service? Similarly, how would I import my existing SQL data into a stateful service? </li>&#xA;<li>For Stateful services/actor model, how can I 'see' the data visually, with an object Explorer/UI. Our data is our Gold, and I'm concerned of the lack of control/visibility of it in the reliable services models</li>&#xA;</ul>&#xA;&#xA;<p>Basically, is there some documentation on the <em>decision path</em> towards which programming model to go for? I could model a ""listing"" as an Actor, and have millions of those - sure, but i could also have a Stateful service that stores the listing locally, and i could also have a Stateless service that fetches it from the DB. How does one decide as to which is the best approach, for a given use case?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44050579,EntityFramework Core Loadbalanced,2017-05-18 14:27:33,<c#><entity-framework><asp.net-core><microservices>,1,78,9,0.0,0,"<p>I know this is a pretty general question, but please bear with me:</p>&#xA;&#xA;<p>I just tripped over the entityframework cache aka ChangeTracker.</p>&#xA;&#xA;<p>What we have is a small microservice using net core with entity core.  This microservice is loadbalanced (RoundRobin) behind an IIS (so far nothing to incommon I would guess).  Lets call them Instance1 and Instance2.</p>&#xA;&#xA;<p>Now what happens:</p>&#xA;&#xA;<p>I have one entry in the db, for example (Represented as JSON here for simplicity):</p>&#xA;&#xA;<p><code>&#xA;{ Name: ""Test"", FirstName: ""T."" }&#xA;</code></p>&#xA;&#xA;<p>Now I load this into a form (answer from Instance1) and modify the FirstName to Thomas and save it via a PUT, which is done by Instance2.  Now I do another request to get that entry.  This request is answered by Instance1, which will load this from cache (since the changetracker says it is unchanged).  And thus I get</p>&#xA;&#xA;<p><code>&#xA;{Name: ""Test"", FirstName: ""T.""}&#xA;</code></p>&#xA;&#xA;<p>There seems to be many people having problems with the change tracker and one common answer is to rebuild the dbcontext with every request, which to me seems utterly wrong, because this is a very ""expensive"" operation.</p>&#xA;&#xA;<p>Also I noticed that the inserting of new data gets slower and slower over time, because the change tracker is filling up, so I would have to recycle the microservice every once and a while.</p>&#xA;&#xA;<p>So my question is:&#xA;How can I get around this Problem without reinitialising the dbcontext with every request?&#xA;I also found some answers that allow to disable the caching, but only for a single db operation, which means I would have to add this option to every DB operation, which to me feels almost as wrong as reinitialising the db context with every request.&#xA;What did I overlook, there has to be a simple solution!</p>&#xA;"
35890054,Test automation for microservices architecture,2016-03-09 11:16:13,<automated-tests><microservices>,3,609,2,0.0,0,"<p>I am in charge of implementing QA processes and test automation for a project using microservices architecture.</p>&#xA;&#xA;<p>Project has one public api that makes some data available. So I will automate API tests. Tests will live in one repository. This part is clear to me, I did this before in other monolith projects. I had one repo for API tests. And possibly another repo for selenium tests.</p>&#xA;&#xA;<p>But then here the whole poduct consists of many microservices that communicate via restful apis and/or rabbit queues. How would I go about automating tests for each of these individual servicess? Would tests for each individual service be in a separate repo? Note: services are written in Java or PHP. I will automate tests with Python. It seems to me that I will end up with a lot of repos for tests/stubs/mocks.</p>&#xA;&#xA;<p>What suggestions or good resources can community offer? :)</p>&#xA;"
46434569,How can I make my .NET Core microservice do a recursive health check?,2017-09-26 19:42:53,<asp.net-core><microservices><health-monitoring>,1,586,0,0.0,0,"<p><a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/monitor-app-health"" rel=""nofollow noreferrer"">As described</a> I can do:</p>&#xA;&#xA;<pre><code>checks.AddUrlCheck(Configuration[""OrderingUrl""])&#xA;</code></pre>&#xA;&#xA;<p>to make my health check dependant on the health of other Microservices. However,I do not just want to do an url check. I want to do a full health check on the other Microservice (so it will also check the database dependencies etc of the other Microservice). This could be something like,</p>&#xA;&#xA;<p><code>checks.AddFullMicroserviceIncludingDatabaseAndUrlCheck(Configuration[""OrderingUrl""])</code> (hypothically).</p>&#xA;&#xA;<p>How can I do such a recursive health check in my .NET Core microservice?</p>&#xA;"
40807126,Run powershell script as microservice,2016-11-25 14:25:28,<windows><powershell><automation><microservices>,1,343,6,0.0,0,"<p>Is it possible to make my powershell script, run as a microservice?</p>&#xA;&#xA;<pre><code>Param(&#xA;    $a,&#xA;    $b&#xA;)&#xA;&#xA;$x = [int]$a + [int]$b&#xA;&#xA;echo $x&#xA;</code></pre>&#xA;"
50400384,"In the microservices architecture, why they say is bad to share REST Client libraries?",2018-05-17 20:57:09,<java><spring><microservices>,3,60,3,0.0,0,"<p>We have 15 services build with Java Spring, they talk each other using REST .</p>&#xA;&#xA;<p>Each time we add a new service to the pool we create from scratch all the code, including rest client code that will talk to other Services and the POJO classes used to map the resource(s) being requested.</p>&#xA;&#xA;<p>We end up copy and pasting from the source code of other services into the new service.</p>&#xA;&#xA;<p>I think it would be better to put all these POJO's and rest client code into a library for all the services to consume it, it would save us a lot of work coding, but ""they"" we should not do that with microservices.</p>&#xA;&#xA;<p>So, why is that?&#xA;We end up copy and pasting the exactly same code over and over again, I don't see the difference.</p>&#xA;"
50427036,Certificate Discovery Service,2018-05-19 15:54:30,<rest><ssl><ssl-certificate><microservices><keystore>,1,32,4,0.0,0,"<p><br/>&#xA;I'm designing a microservice architecture and I've already setted up the https protection by using SSL certificates generated with <a href=""https://letsencrypt.org/"" rel=""nofollow noreferrer"">Let's Encrypt and certbot</a>.</p>&#xA;&#xA;<p>The provided certificates are periodically regenerated and then I've to re-import the new certificates into the keystores of all my services.</p>&#xA;&#xA;<p>In order to avoid this, I'm trying to implement a set of <strong>REST APIs</strong> that may allow the services to <strong>programmatically and automatically retrieve the new certificates</strong> and import them into their own keystore or simply use it programmatically. </p>&#xA;&#xA;<p>As the title says: a sort of <em>""Certificate discovery service""</em> or, if you prefer, a <em>""Remote certificate repository""</em>.</p>&#xA;&#xA;<p>I know that there is the java.security.* package that allows me to deal with this kind of things, but I've two questions for all of you:</p>&#xA;&#xA;<ol>&#xA;<li>Do you think that, from a architectural point of view, this is the best approach to face my problem?</li>&#xA;<li>Which king of Serialization/Deserialization process do you recommend? Is already there any library/framework/tool that does something similar that I can exploit?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you.&#xA;Bye Bye</p>&#xA;"
50401105,How to implement TLS between microservices,2018-05-17 22:01:19,<ssl><microservices><pki>,2,309,5,1.0,0,"<p>Can someone please comment on, vet, critique, or otherwise blast holes in the microservices security design I’m considering?</p>&#xA;&#xA;<p>Let’s say I have three microservices, each of which talks to the other two via REST endpoints. Each microservice contains a keystore. In this keystore is the containing microservice’s private/public keypair, signed by a trusted certificate authority. Also in this keystore is the other two microservices’ public key certificates, exported from the source microservice’s signed/trusted keypair.</p>&#xA;&#xA;<p>This implementation works, but something doesn’t quite smell right about it.</p>&#xA;&#xA;<p>Namely, every time I introduce a new microservice I must add a) each existing microservice’s public key certificate to its keystore, and b) the new microservice’s public key certificate to every other microservice (the assumption being the new microservice must communicate bi-directionally, and securely, with each existing microservice).</p>&#xA;&#xA;<p>Now, repeat the above pattern for a second keypair, this one used to sign/verify authentication tokens supplied in REST calls.</p>&#xA;&#xA;<p>I am wondering if, instead of the above, it is a) advisable and b) safe to share a single trusted public key certificate between all microservices? Something completely different?</p>&#xA;&#xA;<p>Please be polite. I am by no means an expert it this area.</p>&#xA;&#xA;<p><strong>EDIT:</strong>&#xA;It occurred to me, after reading replies/comments to my original post, that I omitted detail that might have made the problem more clear, and therefore the commenters better able to address it:</p>&#xA;&#xA;<ol>&#xA;<li><p>The microservices in question exist within a private intranet, and will only ever be accessible by clients (browsers or other microservices) within that intranet.</p></li>&#xA;<li><p>There is in fact a trusted CA—namely, the company that owns this intranet—and it is that CA that signs the microservices’ keypairs.</p></li>&#xA;</ol>&#xA;&#xA;<p>The resolution to this problem, it seems, is implied in @Andreas first comment, in which he wrote, ""As long as the CA that issued them is trusted, they will be trusted too.”</p>&#xA;&#xA;<p>As long as each new microservice is deployed with a) its own keypairs, signed by the CA (one for signing and the other for encryption), and b) the CA’s certificate, I can deploy new microservices with reasonable assurance they will communicate securely with all other microservices (reasonable because of other potential vulnerabilities I am not even aware of).</p>&#xA;&#xA;<p>Somehow I got it into my head that I would have to create a brand new certificate for each microservice’s keypair, and include these in the other microservices' keystores (repeat for every new microservice). Instead all I need is one certificate, that of the CA that signs the keypairs, in each microservice’s keystore.</p>&#xA;"
50350198,Run Git commands in microservice,2018-05-15 12:26:47,<git><microservices><spring-cloud><jgit>,1,57,7,0.0,0,"<p>I'm implementing microservice (in Spring Cloud) which acts as facade for Git operations invoked by UI layer. I'm trying to use jgit, but the problem is that it requires filesystem. So I have to clone remote repository to local filesystem. Problem is that then microservice is not stateless, and also other problems arises:</p>&#xA;&#xA;<ul>&#xA;<li>cloning before every operation takes too much time so is not an option </li>&#xA;<li>having multiple instances of such microservice can lead to different repositories (push take some time) </li>&#xA;<li>commits on different nodes at the same time can lead to conflicts</li>&#xA;</ul>&#xA;&#xA;<p>I would like to treat Git repository in similar way to database, so all operations should be done without using filesystem, cloning etc. - just invoke command on remote and it's done.</p>&#xA;&#xA;<p>I would like to add that it's quite hard to search for solution, because ""Git microservice"" phrase is quite common but in other sense (storing sources in repository).</p>&#xA;&#xA;<p>Edit: I've just found&#xA;<a href=""https://stackoverflow.com/questions/9442788/are-there-any-restful-interfaces-to-git"">Are there any restful interfaces to git?</a>&#xA;but any other ideas would be nice</p>&#xA;"
43979597,ELK logging in microservices architecture,2017-05-15 12:28:44,<elasticsearch><indexing><microservices><elastic-stack>,1,225,3,0.0,0,"<p>I am implementing centralized logging for all of my microservices using ELK. My doubt is whether I will have to create separate index for each microservice or a single index for all the microservices logs. My research so far shows that single common index for all the microservices make sense for centralized logging to achieve searches across microservices. Also I learnt that too many indices are a bit of overhead in elasticsearch. So I would like to hear from someone experienced</p>&#xA;&#xA;<p>I have already this question in Software recommendations  <a href=""https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture"">https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture</a></p>&#xA;"
43892712,Merge Microservice Frontends Together,2017-05-10 12:35:58,<microservices>,1,186,6,0.0,0,"<p>I want to merge serveral frontend parts of different microservices together to an whole website. My idea behind this was to have a <strong>frontend</strong>, <strong>backend</strong> and <strong>database</strong> part in each microservice.</p>&#xA;&#xA;<p>I already familiar with microservices but I never used them to create a website, especially the frontend part.&#xA;Are there any articles about that or something like tutorials or maybe someone at stackoverflow can explain me more in depth how or with which ""tool"" I could put the microservices together.</p>&#xA;"
43821553,What is the best way to run npm packages on demand as mircoservices without installing it locally?,2017-05-06 14:20:55,<node.js><npm><microservices>,1,86,8,0.0,0,"<p>Let's say I have these npm packages published to npm:&#xA;<code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;each package has a single function:</p>&#xA;&#xA;<pre><code>function run(extraStr) {&#xA;  return 'package_name_and_version' + extraStr; // i.e. service1 v1.0 extraStr&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I want to write nodejs code that use the packages without installing it locally</p>&#xA;&#xA;<pre><code>var server = require(""my-server-sdk"");&#xA;  // get(package_name, version, function_in_package, arguments, callback)&#xA;  server.get('service1', '2.0', 'run', ['app1'], (err, result) =&gt; {&#xA;  console.log(result); // this should print service1 v2.0 app1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>where <code>my-server-sdk</code> is an sdk that interface with my server's api where it <strong>install the required packages and cache it for later use</strong>.&#xA;What is the best way to do that? what the security concerns and how to prevent any?</p>&#xA;&#xA;<p>this is a simple diagram for what I want&#xA;<a href=""https://i.stack.imgur.com/aTdeG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aTdeG.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>NOTE: <code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;are just examples to any packages in npm i.e. <code>lodash</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Caching example:</strong></p>&#xA;&#xA;<p>Let's say we have TTL equal <strong>60 minutes</strong>.</p>&#xA;&#xA;<p><strong>client1</strong> requested a function from <code>lodash</code> and another function from <code>underscore</code> at 01:00.&#xA;Now in the server <code>lodash</code> and <code>underscore</code> are installed with timestamp <strong>01:00</strong>.</p>&#xA;&#xA;<p><strong>client2</strong> requested a function from <code>underscore</code> at <strong>01:30</strong> which get used instantly because <code>underscore</code> is installed before but it timestamp got updated to <strong>1:30</strong>.</p>&#xA;&#xA;<p>At <strong>02:01</strong> <code>lodash</code> get deleted because it didn't get used on the past TTL <code>currenttime - lodash_timestamp &gt; TTL</code> but <code>underscore</code> stays because <code>currenttime - underscore_timestamp &lt; TTL</code></p>&#xA;&#xA;<p>So when <strong>client3</strong> request <code>lodash</code> at <strong>02:30</strong> it get <code>intsalled</code> again with <strong>02:30</strong> as a <code>timestamp</code>.</p>&#xA;"
50039099,Separate one module from JSF application,2018-04-26 09:10:09,<rest><jsf><java-ee><architecture><microservices>,1,47,4,0.0,0,"<p>We have big JSF monolithic application. We want to change the architecture of this application. Currently, my goal - change one module in our application. I need to move the logic from one module to another application which will be implemented on another stack of technologies (it will be rest-service with some js-framework on frontend).</p>&#xA;&#xA;<p>The application should work in the same way. We should have the link to the page as it was earlier but this page should be rendered by another service. We should have the same session between these 2 applications. The user should be able to go throw the pages without an additional step of authentification.</p>&#xA;&#xA;<p>We are planning to move also other modules, not only this one. I need a help. Do you have any thoughts how it should be implemented? any examples?</p>&#xA;"
34376576,Best architecture to share large files among microservices,2015-12-19 23:42:44,<nfs><microservices><data-sharing>,1,1629,0,0.0,0,"<p>I am about to start re-designing an old monolithic software with a microservices-oriented architecture (educational purposes). To give a bit of context, the old software runs on a powerful server that performs the following operations:</p>&#xA;&#xA;<ol>&#xA;<li>Receives batch data (binary file) from a producer.</li>&#xA;<li>Accumulates batch data from each producer.</li>&#xA;<li>Periodically, execute a batch operation over each producer's accumulated data, and store the result (another binary file).</li>&#xA;</ol>&#xA;&#xA;<p>Now, I want to create a separated microservice for this batch operation.  I would like to have this microservice executed in dozens of machines in paralell, so that I can process a big amount of producers.</p>&#xA;&#xA;<p>Each microservice instance will receive a binary file with each producer's data and output another binary file. The problem is that these files can be big (e.g. each producer may produce 20Mb of accumulated data). I came across several ways of dealing with this but I am not convinced by any of them:</p>&#xA;&#xA;<ol>&#xA;<li>Send the binary data among microservices using HTTP calls. I did not try it but it does not seem reasonable.</li>&#xA;<li>Store all the data in a central data repository from where each microservice can download it. Maybe I could use some sort of NFS, but I am not sure if that's a good option. Also, doesn't this go against the microservices philosophy?</li>&#xA;<li>Have a copy of all the data near each microservice. I am afraid I'll eventually run into consistency problems.</li>&#xA;</ol>&#xA;&#xA;<p>What do you believe is the best option (if any)? Thanks!</p>&#xA;"
34424706,How to access meteor collection through the database,2015-12-22 21:28:48,<meteor><microservices>,3,154,1,0.0,0,"<p>I want to have my application's admin code hosted on a completely different app that shares the same database. However, that means that my collections are defined, at least in the code, in the global namespace of my main application and not my admin application. How can I access my collections, that are in the database, without having the global variables defined in a file shared between the meteor server/client? For reference, I am using this article as the idea to set up my admin tools this way. <a href=""http://joshowens.me/building-an-admin-app-as-a-microservice-with-meteor-js/"" rel=""nofollow"">admin article</a></p>&#xA;"
47379427,How to consume response of one rest api in another rest API java Microservices?,2017-11-19 16:54:09,<java><rest><spring-mvc><microservices>,2,1458,0,0.0,0,"<p>I have 2 micro services running :-</p>&#xA;&#xA;<pre><code>1] user &#xA;   running on tomcat port :8081,&#xA;   database name:  user.&#xA;2] order&#xA;   running on tomcat port :8082,&#xA;   database name:  order.&#xA;</code></pre>&#xA;&#xA;<p>I have a REST API in order micro service as shown below:-</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/order/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;    public List registerCustomer() {&#xA;    List list=new ArrayList();&#xA;    list.add(""aaa"");&#xA;    list.add(""aab"");&#xA;    return list;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>now How can I consume this micro in user</p>&#xA;&#xA;<pre><code>  @RequestMapping(value = ""/user/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;&#xA;   // need to call REST API /order/getdetail and return list&#xA;    }   &#xA;</code></pre>&#xA;&#xA;<p>As I am new to micro services I am not aware of to communicate between micros?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47348422,Throw Exception through multiple services,2017-11-17 10:24:01,<spring><rest><spring-boot><microservices>,1,65,4,0.0,0,<p>I have a little microservice architecture with 3 depending services. Each service represents a seperate Spring Boot project. If an exception occurs on the lowest level of the architecture I would like to throw it through all other services up to the highest/user endpoint service.</p>&#xA;&#xA;<p>Each service API returns a <strong>HttpEntity(Response Entity)</strong> including a specific object. I found a lot of possible solutions like <strong>ResponseEntityExceptionHandlers</strong> but all examples shown for a single service architecture without multiple depending services.</p>&#xA;&#xA;<p>Are there any best practices how to throw an Exception through multiple services with Spring Boot?</p>&#xA;
52105225,"In a microservice architecture, when use webservice as data provider vs direct db",2018-08-30 20:55:03,<architecture><microservices><soa>,3,21,0,0.0,0,"<p>We are developing a system which is spread in about 7 microservices.</p>&#xA;&#xA;<p>One of them (a-service) it's a CRUD that allows a mobile client to get some data required to operate. Turns out that another microservice needs the same data to perform some checks before processing a request.</p>&#xA;&#xA;<p>We don't implement one-database-per-microservice, instead we have a sharded MongoDB for all applications (not my fault, my company set it).</p>&#xA;&#xA;<p>Should I in this b-service that also needs the data exposed by a-service consume that service or should I connect directly to the database and retrieve it?</p>&#xA;&#xA;<p>My current considerations:</p>&#xA;&#xA;<ul>&#xA;<li>Putting load on the micro-service and the db vs loading only the database.</li>&#xA;<li>Possible encapsulation of data if it's served by the micro-service for future changes.</li>&#xA;</ul>&#xA;&#xA;<p>Maybe someone can give me some 'best practices' in the matter? Thanks!</p>&#xA;"
51980596,How to Map specific fields of an object to another object?,2018-08-23 07:37:30,<java><spring><spring-boot><microservices>,4,62,0,0.0,0,"<p>I have a situation where I have an object(obj1) which I have to map to another object(obj2) but in this Mapping some of obj2's fields are already having some values while other fields are null, so I have to pick only those fields which are null in obj2 and then send data from obj1 to those fields. I am not sure if ModelMapper will be useful in this case. </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
52057828,How to Create a MicroService in .Net Core / Visual Studio,2018-08-28 12:23:28,<asp.net-core><.net-core><microservices>,3,38,1,0.0,0,"<blockquote>&#xA;  <p>This buzzword is making me pull my hair... I have been asked to create&#xA;  a <strong>microservice</strong> using <strong>.net core</strong>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Googled a lot, different definitions and samples, but still, I don't know what makes a vs project a microservice / how can I create a microservice in VS. For example, I have asked to create a microservice where a user will input two latitude and longitude values and they will get the distance between them.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Cool, I can do this as a web project in no time. But here I need this as a microservice where the rest of the projects in our firm can use it.&#xA;What really makes a VS project into a Microservice or can I convert a project into a micro service? Microservice experts are welcome ...!!! I looking for that step by process in which a microservice is created in .net core. </p>&#xA;"
52041354,microservice: How to do validations from other microservice,2018-08-27 14:18:08,<validation><microservices>,1,22,3,1.0,0,<p>If there are 2 micro services and if you want a validation to be performed against other micro service. What would be the best scenario to handle these cases?</p>&#xA;
52098392,Consuming RESTful services orchestrated by Kubernetes,2018-08-30 13:33:31,<rest><kubernetes><microservices>,1,26,3,0.0,0,"<p>How do you consume a service that is being orchestrated by Kubernetes?&#xA;What does the calling statement look like.&#xA;When consuming a normal RESTful web service, you might use RestTemplate (for Java) and specify the URL.&#xA;How does this differ when Kubernetes creates and destroys occurrences of the service?</p>&#xA;"
43142821,"Kubernetes: single POD with many container, or many Pod with single container",2017-03-31 14:11:28,<kubernetes><microservices>,5,420,0,0.0,0,"<p>I've rather a teoretical question which I can't answer  with the reousrces found online. The question is: <strong>what's the rule to decide how to compose containers in POD?</strong> . Let me explain with an example.</p>&#xA;&#xA;<p>I've these microservices:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Authorization </li>&#xA;<li>Serving content</li>&#xA;<li>(plus) OpenResty to forward the calls form one to the other and orhcestarate the flow. (is there a possibility to do so natively in K8?, it seems to have services base on nginx+lua, but not sure how it works)</li>&#xA;</ul>&#xA;&#xA;<p><em>For the sake of the example I avoid Databases and co, I assume they are external and not managed by kubernetes</em></p>&#xA;&#xA;<p>Now, what's the correct way here <em>LEFT</em> or <em>RIGHT</em> of the image?&#xA;<a href=""https://i.stack.imgur.com/b0VwE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b0VwE.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>LEFT</em> : this seems easier to make it working, everything works on ""localhost"" , the downside is that it looses a bit the benefit of the microservices. For example, if the auth become slows and it would need more instances, I've to duplicate the whole pod and not just that service.</p>&#xA;&#xA;<p><em>RIGHT</em> seems a bit more complex, need services to expose each POD to the other PODs. Yet, here, I could duplicate auth as I need without duplicating the other containers. On the other hand I'll have a lot of pods since each pod is basically a container.</p>&#xA;"
43144337,The right way to define an API's base path in Api Connect,2017-03-31 15:22:29,<spring-boot><ibm-cloud><microservices><apiconnect>,1,269,5,0.0,0,"<p><strong>Problem:</strong></p>&#xA;&#xA;<p>I have two micro services (in Spring Boot) published in <a href=""https://en.wikipedia.org/wiki/Bluemix"" rel=""nofollow noreferrer"">Bluemix</a>'s Api Connect. I want to assign a base path to each one so that we have a way to separate them. I.E.:</p>&#xA;&#xA;<p>Path to API 1: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api1/[endpoint-of-api1]</code>&#xA;Path to API 2: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api2/[endpoint-of-api2]</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>My solution:</strong></p>&#xA;&#xA;<p>Assign a context path to each Api in their <strong>application.yml</strong> file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: /api1&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Even though this works, it doesn't seem right to have a base path for the entire server, when the microservice shouldn't be aware of its external context (the reason for a base path is exclusively to have a separation in Api Connect)</p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
37213471,Best Practices when Migrating to Microservices,2016-05-13 15:05:28,<refactoring><microservices>,3,145,0,0.0,0,"<p>To anyone with real world experience breaking a monolith into separate modules and services.</p>&#xA;&#xA;<p>I am asking this question having already read the <a href=""http://martinfowler.com/bliki/MonolithFirst.html"" rel=""nofollow"">MonolithFirst</a> blog entry by Martin Fowler. When taking a monolith and breaking it into microservices the ""size"" element of the equation is the one that I ponder over the most.  Specifically, how to approach breaking a monolith application (we're talking 2001: A Space Oddessy; as in it is that old and that large) into micro services without getting overly fine grained or staying too monolithic.  The end goal is creating separate modules that can be upgraded indepenently and scaled independently.</p>&#xA;&#xA;<p>What are some recommended best practices based on personal experience of breaking a monolith into microservices?</p>&#xA;"
43328943,Data-specific user permissions model / schema design,2017-04-10 16:57:21,<permissions><domain-driven-design><database-schema><acl><microservices>,1,111,3,0.0,0,"<p>My app manages user data that is shared between users, with different permissions such as read-only, edit, superuser, rename, delete etc. </p>&#xA;&#xA;<p>I'm weighing up two approaches to modelling the user permissions, the first is the simpler approach, the second involves more work but is more extensible, refactorable, <em>I think</em>. </p>&#xA;&#xA;<p>(1) quick solution, hard-coding against <code>user permission</code> properties:</p>&#xA;&#xA;<pre><code>-- basic data&#xA;CREATE TABLE symbol (&#xA;    id INT,&#xA;    name VARCHAR(255)&#xA;);&#xA;&#xA;CREATE TABLE user (&#xA;    id CHAR(10) &#xA;);&#xA;&#xA;CREATE TABLE user_permission (&#xA;    symbol_id INT,&#xA;    user_id CHAR(10),&#xA;    readable BIT,&#xA;    writable BIT,&#xA;    owner BIT,&#xA;    rename BIT,&#xA;    deletion BIT&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>(2) complete solution, hard-coding against <code>entitlements</code>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/boRWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/boRWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The areas I'm considering are:</p>&#xA;&#xA;<ol>&#xA;<li>extensibility - need or not to change model &amp; schema</li>&#xA;<li>microservices - possibilities to spin off into a separate DB?</li>&#xA;<li>performance - filter algos, number of joins in queries</li>&#xA;<li>no-sql caching - no idea but denormalising user permissions sounds crazy</li>&#xA;<li>admin for users - need good UX</li>&#xA;<li>admin for DBAs/Support - don't want complaints and endless support requests</li>&#xA;<li>web services API simplicity / complexity using Spring Data REST - HAL</li>&#xA;</ol>&#xA;&#xA;<p>I'd like to go with the more complex solution since it is unlikely to require re-working in the future, but I'm a bit concerned about both performance and the admin tasks involved in the UI to allow users to manage it. </p>&#xA;&#xA;<p>A utopian solution would be a third-party Java-based webapp providing a user interface to allow admin.</p>&#xA;&#xA;<p>EDIT: interesting to see other people tackling the same problem: <a href=""https://stackoverflow.com/questions/41161769/authorisation-in-microservices-how-to-approach-domain-object-or-entity-level-a"">Authorisation in microservices - how to approach domain object or entity level access control using ACL?</a></p>&#xA;"
43306842,.NET Microservices authorization,2017-04-09 12:46:57,<.net><authorization><microservices>,1,190,4,0.0,0,"<p>I am about to start a project that consists of several microservices and I was researching how can I implement authorization of each microservice.&#xA;My architecture is the following:&#xA;A web project that consists of an asp.net core site with angular 2. Each module (menu item and its submenus) will be communicating with a microservice (each microservice will have a database).&#xA;Each microservice will have its own permissions. e.g MS1 will have CRUD Products, MS2 will have CRUD Orders etc..&#xA;My questions are:</p>&#xA;&#xA;<ol>&#xA;<li>As I mentioned above each microservice will have its own database (e.g MS1 will hold the products database, MS1 the order database etc..). What about the permissions? Where these are better to be stored?</li>&#xA;<li>A microservice should not share code with other microservices but I was thinking that the code that does the actual auth checking ( IsAlllowed(PermissionType) ) would be repeated in each microservice. This will cause code redundancy.</li>&#xA;</ol>&#xA;"
43326844,swagger2 for springboot microservice do no produce response on ui,2017-04-10 15:11:06,<spring-boot><microservices><swagger-ui>,1,75,5,0.0,0,"<p>I created one micro service with spring boot, I don't have resource folder and i wanted to add swagger support. So I followed as per <a href=""http://www.baeldung.com/swagger-2-documentation-for-spring-rest-api"" rel=""nofollow noreferrer"">document</a></p>&#xA;&#xA;<p>So </p>&#xA;&#xA;<ol>&#xA;<li>Added swagger dependency.</li>&#xA;<li>Added docker class as it is </li>&#xA;<li>Added swagger's ui dependency</li>&#xA;</ol>&#xA;&#xA;<p>Results</p>&#xA;&#xA;<ol>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><p>But &#xA;<a href=""http://localhost:port/myservice/swagger-ui.html"" rel=""nofollow noreferrer"">http://localhost:port/myservice/swagger-ui.html</a> ->&#xA;Not expected response, on browser console i am getting error</p>&#xA;&#xA;<p>GET <a href=""http://localhost:port/myservice/configuration/ui"" rel=""nofollow noreferrer"">http://localhost:port/myservice/configuration/ui</a> 404 (Not Found)</p></li>&#xA;</ol>&#xA;&#xA;<p>As its microservice, I don't have <code>@EnableWebMvc</code> class. </p>&#xA;&#xA;<p>What Am I missing ? </p>&#xA;"
43460615,How to execute docker commands after a process has started,2017-04-17 22:25:10,<docker><docker-compose><dockerfile><microservices><consul>,2,112,5,0.0,0,"<p>I wrote a Dockerfile for a service (I have a CMD pointing to a script that starts the process) but I cannot run any other commands after the process has started? I tried using '&amp;' to run the process in the background so that the other commands would run after the process has started but it's not working? Any idea on how to achieve this?</p>&#xA;&#xA;<p>For example, consider I started a database server and wanted to run some scripts only after the database process has started, how do I do that?</p>&#xA;&#xA;<p><strong>Edit 1:</strong></p>&#xA;&#xA;<p>My specific use case is I am running a Rabbitmq server as a service and I want to create a new user, make him administrator and delete the default guest user once the service starts in a container. I can do it manually by logging into the docker container but I wanted to automate it by appending these to the shell script that starts the rabbitmq service but that's not working.</p>&#xA;&#xA;<p>Any help is appreciated!</p>&#xA;&#xA;<p>Regards</p>&#xA;"
48062134,Connection refused with two microservices in Docker,2018-01-02 13:44:21,<java><docker><spring-boot><microservices>,1,1008,2,0.0,0,"<p>I have two microservices and I want that one consumes of the other but I'm obtaining this mistake: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path&#xA;  [] threw exception [Request processing failed; nested exception is&#xA;  org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  GET request for ""<a href=""http://localhost:8080/testMicroservicio"" rel=""nofollow noreferrer"">http://localhost:8080/testMicroservicio</a>"": Connection&#xA;  refused (Connection refused); nested exception is&#xA;  java.net.ConnectException: Connection refused (Connection refused)]&#xA;  with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused (Connection refused)</p>&#xA;</blockquote>&#xA;&#xA;<p>However if I execute the url in the browser, it works perfectly but if a microservice wants to access to the other microservice, I have this mistake.</p>&#xA;&#xA;<p>Does someone kown why?</p>&#xA;&#xA;<p>I'm consuming with: RestTemplate</p>&#xA;&#xA;<p>I put some of code:</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class MicroServiceController {&#xA;&#xA;&#xA;    private final AddressService service;&#xA;&#xA;    private static final String URL_API_INFO = ""http://localhost:8080/testMicroservicio"";&#xA;&#xA;    private RestTemplate restTemplate = new RestTemplate();&#xA;&#xA;    private final static Logger log = Logger.getLogger(""com.bernanetwork.web.controller.MicroServiceController"");&#xA;&#xA;    @Autowired&#xA;    public MicroServiceController(AddressService service) {&#xA;        this.service = service;&#xA;    }&#xA;&#xA;    @RequestMapping(value = ""/micro-service-test"")&#xA;    public String consumidor() throws Exception {&#xA;&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;        log.info(""-------------------------Iniciando método consumidor------------------------------------"");&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;&#xA;        ResponseEntity &lt;PruebasMicroservicio[]&gt; response = restTemplate.getForObject(URL_API_INFO, PruebasMicroservicio[].class);&#xA;&#xA;        Arrays.asList(response.getBody()).forEach(info -&gt; log.info(""---""+info));&#xA;&#xA;        return ""ok"";&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>These microservices are running in Docker</p>&#xA;&#xA;<p>Thanks so much.</p>&#xA;"
48153334,Microservices Monitoring Using Status Code,2018-01-08 15:30:31,<amazon-web-services><microservices>,1,34,3,0.0,0,"<p>We are using Amazon ECS for micro-services based architecture. We are right now using ALB service monitoring with target-group associated with each service in an ECS cluster. </p>&#xA;&#xA;<p>Right now, We are facing difficulty to monitor the microservices as they are hosted under route 53 private hosted zone. </p>&#xA;&#xA;<p>We have tried to monitor Route 53 health monitoring but route 53 doesn't allow to monitor the health of the endpoints with a simple routing policy. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Ref:&#xA;  <a href=""https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html</a></p>&#xA;</blockquote>&#xA;&#xA;<p>We need to monitor the status code of each microservice at any interval of time. </p>&#xA;&#xA;<p>We have also setup health-check for each microservice. Example: service-a.domain/ping. We need a status-page which represent the health of all available service we add using the status code we add. Also, any way if we can monitor them from application load balancer target group).</p>&#xA;&#xA;<p>What will be the best way to monitor every microservice. ?</p>&#xA;"
48030343,Microservice deployment --- simple jars vs docker containers,2017-12-30 02:14:56,<java><docker><war><microservices><continuous-deployment>,1,470,3,0.0,0,"<p>I am about to deploy a set of JAVA based microservices.&#xA;I am confused as to whether:</p>&#xA;&#xA;<ol>&#xA;<li>Run them as simple jars via ""java -jar [JAR_NAME]""</li>&#xA;<li>Run them in a JAVA based docker container.</li>&#xA;<li>Run them as a war.</li>&#xA;</ol>&#xA;&#xA;<p>Please offer me pros and cons of each implementation as this will save me a lot of headache if I use the suggested best approach :)</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
48095718,No service dependencies found in Jaeger UI,2018-01-04 12:50:20,<spring-boot><kubernetes><microservices><minikube><jaeger>,1,218,3,0.0,0,"<p>I am new to jaeger and I am facing issues with finding the services list in the jaeger UI.</p>&#xA;&#xA;<p>Below are the .yaml configurations I prepared to run jaeger with my spring boot app on Kubernetes using minikube locally.</p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/production-elasticsearch/elasticsearch.yml --namespace=kube-system</code></p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/jaeger-production-template.yml --namespace=kube-system</code></p>&#xA;&#xA;<p>Created deployment for my spring boot app and jaeger agent to run on the same container</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;    name: tax-app-deployment&#xA;spec:&#xA;    template:&#xA;      metadata:&#xA;        labels:&#xA;          app: tax-app&#xA;          version: latest&#xA;      spec:&#xA;        containers:&#xA;        - image: tax-app&#xA;          name: tax-app&#xA;          imagePullPolicy: IfNotPresent&#xA;          ports:&#xA;          - containerPort: 8080&#xA;        - image: jaegertracing/jaeger-agent&#xA;          imagePullPolicy: IfNotPresent&#xA;          name: jaeger-agent&#xA;          ports:&#xA;          - containerPort: 5775&#xA;            protocol: UDP&#xA;          - containerPort: 5778&#xA;          - containerPort: 6831&#xA;            protocol: UDP&#xA;          - containerPort: 6832&#xA;            protocol: UDP&#xA;          command:&#xA;          - ""/go/bin/agent-linux""&#xA;          - ""--collector.host-port=jaeger-collector.jaeger-infra.svc:14267""&#xA;</code></pre>&#xA;&#xA;<p>And the spring boot app service yaml</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: tax&#xA;  labels:&#xA;    app: tax-app&#xA;    jaeger-infra: tax-service&#xA;spec:&#xA;  ports:&#xA;  - name: tax-port&#xA;    port: 8080&#xA;    protocol: TCP&#xA;    targetPort: 8080&#xA;  clusterIP: None&#xA;  selector:&#xA;    jaeger-infra: jaeger-tax&#xA;</code></pre>&#xA;&#xA;<p>I am getting </p>&#xA;&#xA;<blockquote>&#xA;  <p>No service dependencies found</p>&#xA;</blockquote>&#xA;"
47975940,NodeJs micro services shared dependencies,2017-12-26 08:36:28,<node.js><npm><microservices><dependency-management>,1,66,7,0.0,0,"<p>i have built a microservices application using NodeJs . i have building this app for 4 month now and it starts to be big. i have used private modules to share code between the services but now i face anther problem. </p>&#xA;&#xA;<p>i am getting duplicate code for requiring this modules(and public modules) as many of them are being used in all the services and are called in my index file.</p>&#xA;&#xA;<p>so what i have try to do is build anther private module that it`s purpose is to include all this modules dependencies and control all the updates .</p>&#xA;&#xA;<p>that works good, the problem is the IDE ""phpstorm"" screams on me because now those dependencies are not in the service package.json  and also i dont have autocomplete on them(same reason) .</p>&#xA;&#xA;<p>is there a way to let the package json to use this dependencies from that package , or maybe anther technique to achieve this </p>&#xA;"
42332938,What is the difference between Service Fabric Applications and Services,2017-02-19 21:12:26,<azure><microservices><azure-service-fabric>,3,387,2,0.0,0,<p>What is the reasoning behind Applications concept in Service Fabric? What is the recommended relation between Applications and Services? In which scenarios do Applications prove useful?</p>&#xA;
48473966,Authentication/Authorization mechanism for microservices,2018-01-27 08:21:12,<authentication><authorization><microservices>,2,707,0,0.0,0,<p>I have project with many micro services each one doing its job. One of them responsible for authentication and authorization. But its not clear how other services should check users permissions. Is there any mechanism to deal with this task?</p>&#xA;
48457264,Integrating SignalR for microservice with API Gateway,2018-01-26 07:31:45,<architecture><signalr><microservices><asp.net-core-signalr>,1,630,2,0.0,0,"<p>I'm designing a microservice system based on .Net core. The architecture system will look like as the following picture.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eIee4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eIee4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The problem is: There is a requirement which have to integrate SignalR (real-time) for notification&#xA;I've read about SignalR on Microsoft's website. But I consider that where should I put the Hub (API Gateway?, microservice? ...)? How can I apply signalR for this system.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48440783,Is it possible to have 2 different services with the same application name?,2018-01-25 10:35:36,<spring><microservices><netflix-eureka><netflix-zuul>,1,40,3,0.0,0,"<p>Let's say I have a service named ""FooService"" running in a docker container and a second service named ""BarService"" running in a second docker container. Both services register with Eureka (running in another docker container). Is it possible to have the same application name for both services? E.g. <a href=""http://localhost/myservice/foo"" rel=""nofollow noreferrer"">http://localhost/myservice/foo</a> should call the FooService and <a href=""http://localhost/myservice/bar"" rel=""nofollow noreferrer"">http://localhost/myservice/bar</a> should call the BarService. Development environment is Spring Boot and the services are implemented as Spring RestControllers. Just put ""spring.application.name=myservice"" in both bootstrap.properties files and then put @RequestMapping(""${spring.application.name}"") in the RestController will not work, of course. But is it somehow possible to register the services with a unique identifier and still call them with a common URL path?</p>&#xA;"
48604664,How to share database connection between in spring cloud,2018-02-04 04:20:22,<spring><microservices>,3,389,3,0.0,0,<p>How can I share database connection aong in spring cloud module microservices. If there are many microservices how can i use same db connection or should i use db connection per microservices?</p>&#xA;
48493849,Should API and message consumer be in the same microservice?,2018-01-29 03:11:48,<apache-kafka><microservices><distributed-system>,1,96,4,1.0,0,"<p>My team is torn with how we should architect our microservices with using a message bus.</p>&#xA;&#xA;<p>We currently have an API Gateway with many microservices behind it all communicating over http.</p>&#xA;&#xA;<p>After looking into implementing Message Buses (Kafka) the team is torn on whether the consumer and API should live in the same service or if they should be two separate services.</p>&#xA;&#xA;<p>Some think they should be separate as they have different scaling concerns, while others think they should be in the same service since they are communicating with the same database and have the same domain concerns. IE) Not duplicating code between two services.</p>&#xA;&#xA;<p>What are your thoughts?</p>&#xA;"
46131443,"java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing with microservices",2017-09-09 13:55:44,<java><microservices>,4,4903,0,0.0,0,"<p>I am new to the microservices + Spring Boot combinations and getting the below error while running the code from the link: <a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a> . Please guide me what is the nissue ?</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89) ~[spring-cloud-context-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at com.piggymetrics.statistics.StatisticsApplication.main(StatisticsApplication.java:34) [classes/:na]&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://config:8888/statistics-service/default"": config; nested exception is java.net.UnknownHostException: config&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    ... 7 common frames omitted&#xA;Caused by: java.net.UnknownHostException: config&#xA;    at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.PlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.SocksSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.NetworkClient.doConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.&lt;init&gt;(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:80) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:93) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$BasicAuthorizationInterceptor.intercept(ConfigServicePropertySourceLocator.java:179) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:85) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:69) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:596) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    ... 11 common frames omitted&#xA;&#xA;2017-09-09 19:19:34.861  INFO 4968 --- [           main] .b.l.ClasspathLoggingApplicationListener : Application failed to start with classpath: [file:/C:/Learnings/micro-services/PiggyMetrics/statistics-service/target/classes/, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-security/1.3.5.RELEASE/spring-boot-starter-security-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter/1.3.5.RELEASE/spring-boot-starter-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot/1.3.5.RELEASE/spring-boot-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.3.5.RELEASE/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-aop/4.2.6.RELEASE/spring-aop-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-config/4.0.4.RELEASE/spring-security-config-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-web/4.0.4.RELEASE/spring-security-web-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-expression/4.2.6.RELEASE/spring-expression-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-config/1.1.0.RELEASE/spring-cloud-starter-config-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter/1.1.0.RELEASE/spring-cloud-starter-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-context/1.1.0.RELEASE/spring-cloud-context-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-rsa/1.0.1.RELEASE/spring-security-rsa-1.0.1.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.47/bcpkix-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.47/bcprov-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-config-client/1.1.0.RELEASE/spring-cloud-config-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.6/jackson-annotations-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.6/jackson-databind-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.6/jackson-core-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/oauth/spring-security-oauth2/2.0.9.RELEASE/spring-security-oauth2-2.0.9.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-beans/4.2.6.RELEASE/spring-beans-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-core/4.2.6.RELEASE/spring-core-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-context/4.2.6.RELEASE/spring-context-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-webmvc/4.2.6.RELEASE/spring-webmvc-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-core/4.0.4.RELEASE/spring-security-core-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.3.5.RELEASE/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.3.5.RELEASE/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.0.33/tomcat-embed-core-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.0.33/tomcat-embed-el-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-logging-juli/8.0.33/tomcat-embed-logging-juli-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.0.33/tomcat-embed-websocket-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-validation/1.3.5.RELEASE/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/hibernate/hibernate-validator/5.2.4.Final/hibernate-validator-5.2.4.Final.jar, file:/C:/Users/pashtikar/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/org/jboss/logging/jboss-logging/3.3.0.Final/jboss-logging-3.3.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/classmate/1.1.0/classmate-1.1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-web/4.2.6.RELEASE/spring-web-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-feign/1.1.0.RELEASE/spring-cloud-starter-feign-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-core/1.1.0.RELEASE/spring-cloud-netflix-core-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-commons/1.1.0.RELEASE/spring-cloud-commons-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-crypto/4.0.4.RELEASE/spring-security-crypto-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-core/8.16.2/feign-core-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/jvnet/animal-sniffer-annotation/1.0/animal-sniffer-annotation-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-slf4j/8.16.2/feign-slf4j-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-hystrix/8.16.2/feign-hystrix-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-ribbon/1.1.0.RELEASE/spring-cloud-starter-ribbon-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon/2.1.5/ribbon-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-transport/2.1.5/ribbon-transport-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-contexts/0.4.9/rxnetty-contexts-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-servo/0.4.9/rxnetty-servo-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty/0.4.9/rxnetty-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec-http/4.0.27.Final/netty-codec-http-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec/4.0.27.Final/netty-codec-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-handler/4.0.27.Final/netty-handler-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport-native-epoll/4.0.27.Final/netty-transport-native-epoll-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-common/4.0.27.Final/netty-common-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-buffer/4.0.27.Final/netty-buffer-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport/4.0.27.Final/netty-transport-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-core/2.1.5/ribbon-core-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-httpclient/2.1.5/ribbon-httpclient-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-commons-util/0.1.1/netflix-commons-util-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-loadbalancer/2.1.5/ribbon-loadbalancer-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-statistics/0.1.1/netflix-statistics-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxjava/1.1.5/rxjava-1.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-archaius/1.1.0.RELEASE/spring-cloud-starter-archaius-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/archaius/archaius-core/0.7.4/archaius-core-0.7.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/commons-configuration/commons-configuration/1.8/commons-configuration-1.8.jar, file:/C:/Users/pashtikar/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-eureka/1.1.0.RELEASE/spring-cloud-starter-eureka-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-eureka-client/1.1.0.RELEASE/spring-cloud-netflix-eureka-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-client/1.4.6/eureka-client-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jettison/jettison/1.3.7/jettison-1.3.7.jar, file:/C:/Users/pashtikar/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-eventbus/0.3.0/netflix-eventbus-0.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-core/0.10.1/servo-core-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-internal/0.10.1/servo-internal-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-core/1.19.1/jersey-core-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-client/1.19.1/jersey-client-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/contribs/jersey-apache-client4/1.19.1/jersey-apache-client4-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-api/1.12.10/governator-api-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-core/1.4.6/eureka-core-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-core/1.10.30/aws-java-sdk-core-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-ec2/1.10.30/aws-java-sdk-ec2-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-autoscaling/1.9.3/aws-java-sdk-autoscaling-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-sts/1.9.3/aws-java-sdk-sts-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-route53/1.9.3/aws-java-sdk-route53-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator/1.12.10/governator-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-core/1.12.10/governator-core-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/woodstox-core-asl/4.4.1/woodstox-core-asl-4.4.1.jar, file:/C:/Users/pashtikar/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-eureka/2.1.5/ribbon-eureka-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/thoughtworks/xstream/xstream/1.4.2/xstream-1.4.2.jar, file:/C:/Users/pashtikar/.m2/repository/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar, file:/C:/Users/pashtikar/.m2/repository/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-data-mongodb/1.3.5.RELEASE/spring-boot-starter-data-mongodb-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/mongodb/mongo-java-driver/2.13.3/mongo-java-driver-2.13.3.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-mongodb/1.8.4.RELEASE/spring-data-mongodb-1.8.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tx/4.2.6.RELEASE/spring-tx-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-commons/1.11.4.RELEASE/spring-data-commons-1.11.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.21/jcl-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/1.3.5.RELEASE/spring-boot-starter-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-actuator/1.3.5.RELEASE/spring-boot-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-bus-amqp/1.1.0.RELEASE/spring-cloud-starter-bus-amqp-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-stream-rabbit/1.0.0.RELEASE/spring-cloud-starter-stream-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-binder-rabbit/1.0.0.RELEASE/spring-cloud-stream-binder-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-codec/1.0.0.RELEASE/spring-cloud-stream-codec-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-amqp/1.3.5.RELEASE/spring-boot-starter-amqp-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-rabbit/1.5.6.RELEASE/spring-rabbit-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-amqp/1.5.6.RELEASE/spring-amqp-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/http-client/1.0.0.RELEASE/http-client-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/amqp-client/3.5.7/amqp-client-3.5.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-amqp/4.2.5.RELEASE/spring-integration-amqp-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-jmx/4.2.5.RELEASE/spring-integration-jmx-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-bus/1.1.0.RELEASE/spring-cloud-bus-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-core/4.2.5.RELEASE/spring-integration-core-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-hystrix-stream/1.1.0.RELEASE/spring-cloud-netflix-hystrix-stream-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.3.5.RELEASE/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-classic/1.1.7/logback-classic-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-core/1.1.7/logback-core-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jul-to-slf4j/1.7.21/jul-to-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.21/log4j-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream/1.0.0.RELEASE/spring-cloud-stream-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-messaging/4.2.6.RELEASE/spring-messaging-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tuple/1.0.0.RELEASE/spring-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-tuple/1.0.0.RELEASE/spring-integration-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/retry/spring-retry/1.1.2.RELEASE/spring-retry-1.1.2.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/hystrix/hystrix-core/1.5.2/hystrix-core-1.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.7/HdrHistogram-2.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar]&#xA;</code></pre>&#xA;"
46193708,How To Make Relations Between Two Entities From Different Microservices In Spring Boot?,2017-09-13 09:26:15,<spring-boot><spring-data><spring-data-jpa><microservices>,1,588,1,0.0,0,"<p>I am trying to make a simple <strong>Spring Boot</strong> web app using <strong>Microservice Architecture</strong>.</p>&#xA;&#xA;<p>I have two microservices with entities as defined below:</p>&#xA;&#xA;<pre><code>Microservice 1 :&#xA;&#xA;@Entity&#xA;public class Article {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and</p>&#xA;&#xA;<pre><code>Microservice 2 :&#xA;&#xA;@Entity&#xA;public class Tag {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I want to have a <strong>Many To Many</strong> relation between these two entities in my <strong>Gateway</strong>.</p>&#xA;&#xA;<p>I had tried to use feign client as below:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@FeignClient(value = ""article-service"")&#xA;public interface ArticleClient {&#xA;&#xA;    @RequestMapping(value = ""/articles/"", method = RequestMethod.GET)&#xA;    Set&lt;Article&gt; getArticleById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;&#xA;@FeignClient(value = ""tag-service"")&#xA;public interface TagClient {&#xA;&#xA;    @RequestMapping(value = ""/tags/"", method = RequestMethod.GET)&#xA;    Tag getTagById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And defined <strong>Article</strong> and <strong>Tag</strong> entities in my <strong>Gateway</strong> like this:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Entry {&#xA;&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;    @ManyToMany(cascade = CascadeType.ALL)&#xA;    @JoinTable(name = ""article_tag"",&#xA;        joinColumns = @JoinColumn(name = ""article_id"", referencedColumnName = ""id""),&#xA;        inverseJoinColumns = @JoinColumn(name = ""tag_id"",&#xA;                referencedColumnName = ""id""))&#xA;    private Set&lt;Tag&gt; tags;&#xA;}&#xA;&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Tag {&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    @ManyToMany(mappedBy = ""tags"")&#xA;    private Set&lt;Article&gt; articles;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have a table named <strong>article_tag</strong> in my database (<strong>Postgres</strong>).</p>&#xA;&#xA;<p>Now how can I define my repositories in the <strong>Gateway</strong>?&#xA;How to write getArticlesByTagId() or getTagsByArticleId() functions?&#xA;I did whatever I could to make this relation work but I think they are not going to get along with each other :)</p>&#xA;"
46092604,event-driven microservices id generation,2017-09-07 09:21:30,<java><microservices>,2,203,3,0.0,0,"<p>I'm a newbie with microservices. I'm trying to create a microservices architecture where there is an API gateway that should just receive the request and create an event accordingly. Then the event will be intercepted by a microservice that stores the needed data into a database. </p>&#xA;&#xA;<p>Maybe I'm making a mistake with the design but I expect that after a client calls the API gateway the request proceeds asynchronously and the data consistency won't be guaranteed. </p>&#xA;&#xA;<p>So how the client knows if the resource has been created and its id?</p>&#xA;&#xA;<p>Should the client listen to the events as well?</p>&#xA;&#xA;<p>Is this the right architecture or am I going through the wrong path?</p>&#xA;&#xA;<p>Thank you in advance for your comments!</p>&#xA;&#xA;<p>Note: I'm not using any structured framework. I like them but this is mostly an experiment and I'd like keep everything simple. Anyway I'm opened if your suggestion involve spring or whatever java framework. </p>&#xA;&#xA;<p>(Edit)</p>&#xA;&#xA;<p>Another interesting point. Let's give that the API response is asynchronous, if the client has to insert an aggregated data made by two resources (identified by their own id), how this can be achieved through an event-driven architecture?</p>&#xA;"
46190467,CQRS + Microservices Handling event rollback,2017-09-13 06:37:37,<domain-driven-design><microservices><cqrs><event-store>,3,223,3,1.0,0,"<p>We are using microservices, cqrs, event store using nodejs cqrs-domain, everything works like a charm and the typical flow goes like:</p>&#xA;&#xA;<ol>&#xA;<li>REST->2. Service->3. Command validation->4. Command->5. aggregate->6. event->7. eventstore(transactional Data)->8. returns aggregate with aggregate ID-> 9. store in microservice local DB(essentially the read DB)-> 10. Publish Event to the Queue</li>&#xA;</ol>&#xA;&#xA;<p>The problem with the flow above is that since the transactional data save i.e. persistence to the event store and storage to the microservice's read data happen in a different transaction context if there is any failure at step 9 how should i handle the event which has already been propagated to the event store and the aggregate which has already been updated?</p>&#xA;&#xA;<p>Any suggestions would be highly appreciated.</p>&#xA;"
46171136,"All my microservices have their own db's, should I create common microservice to handle connections?",2017-09-12 08:08:00,<database><architecture><microservices>,1,95,4,1.0,0,"<p>I have a number of microservices that maintain their own databases (mongodb, elastic, mysql) and each of the microservices I have to set-up a new connection constantly. </p>&#xA;&#xA;<p>I was considering would it be wise if I created another microservice, that could handle these connections for the microservices, before they start up.</p>&#xA;&#xA;<p>Example:&#xA;My API Gateway microservice gets a request for search, it then calls search microservice, which before the search starts, calls the database setup miscroservice and returns an established connection back to it, based on what microservice called it (in this case - the search microservice).</p>&#xA;&#xA;<p>Would it be better, if I just found out what connection is needed inside the API Gateway? Or should I just leave the logic separately in each microservice.</p>&#xA;"
48667874,Authentication in microservices,2018-02-07 15:47:13,<.net><authentication><asp.net-core><jwt><microservices>,3,347,0,0.0,0,"<p>I am developing a microservice system for my company using ASP.NET Core. But a have faced with the following problem: when authenticated user is requesting some service, how should it check if the token is an actual (not blacklisted). I mean the case when user takes a new token but his old token is not expired yet thus the last one is an actual and could be used for accessing the resource services. So I gonna make all ofthe microservices ask the authentication service whether the token is an actual at each request. Perhaps there are any elegant ways to do it?</p>&#xA;"
48699742,How to handle user authentication with microservices in AWS?,2018-02-09 06:10:16,<node.js><amazon-web-services><authentication><microservices>,3,374,0,0.0,0,"<p>I'm reading a tutorial provided by AWS explaining how to break up a monolithic NodeJS application into a microservice architectured one.</p>&#xA;&#xA;<p><a href=""https://aws.amazon.com/getting-started/container-microservices-tutorial/"" rel=""nofollow noreferrer"">Here is a link to it.</a></p>&#xA;&#xA;<p>One important piece is missing from <a href=""https://github.com/awslabs/amazon-ecs-nodejs-microservices/tree/master/3-microservices"" rel=""nofollow noreferrer"">the simple application example they've provided</a> and that is <strong>user authentication</strong>.</p>&#xA;&#xA;<p>My question is, where does authentication fit into all this? &#xA;How do you allow users to authenticate to all these services separately? </p>&#xA;&#xA;<p>I am specifically looking for an answer that <strong>does not</strong> involve AWS Cogntio. I would like to have my own service perform user authentication/management.</p>&#xA;"
48699765,UI with microservices,2018-02-09 06:12:15,<angular><web-services><web-applications><frontend><microservices>,2,1456,0,0.0,0,<p>I have fornt end Web application written in JSF with Richfaces. Its a kind of dashboard application. We are trying to move this in Angular 2 with Spring Boot rest api. &#xA;I want to write microservices where each functionality would be independent. There are total 10 functionality so i will write 10 different rest services and each one would have its own build process. But i am confused with fornt end part. Should i create separate artifacts or separate build for each UI as well ? Or should i bundle in each respective rest api? how should i take care of front end part in microservices?</p>&#xA;
48810786,is putting sqs-consumer to detect receiveMessage event in sqs scalable,2018-02-15 15:30:43,<microservices><amazon-sqs>,1,78,3,0.0,0,"<p>I am using aws sqs as message queue. After <code>sqs.sendMessage</code> sends the data , I want to detect <code>sqs.receiveMessage</code> via either infinite loop or event triggering in scalable way. Then I came accross <a href=""https://www.npmjs.com/package/sqs-consumer"" rel=""nofollow noreferrer"">sqs-consumer</a> &#xA;to handle <code>sqs.receiveMessage</code> events, the moment it receives the messages. But I was wondering , is it the most suitable way to handle message passing between microservices or is there any other better way to handle this thing?</p>&#xA;"
48760583,How to refresh request token with microservice multiple instances,2018-02-13 06:18:32,<java><microservices><access-token><spring-cloud>,1,177,3,0.0,0,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<p>When the request token expires and multiple requests happen from different service instances, that all request a new request token via the remote HTTP call, at the same time, the latter request token will make the former request token invalid. Because each request to get a new token will make the previous one invalid. The service to generate request token is a third party one, we can't change it.</p>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Our application architecture is microservice based, each service will have multiple instances, how can I reuse the request token between each service?(maybe store it in an external Redis is an option)</p></li>&#xA;<li><p>During the service starting up, how can we make sure only one refresh token request sent to the third party service?</p></li>&#xA;<li><p>Afterwards, when the request token expires, how can we renew it?</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>Tech Stack:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Java 8</li>&#xA;<li>SpringCloud</li>&#xA;<li>Redis</li>&#xA;<li>Rancher</li>&#xA;<li>MySQL</li>&#xA;</ul>&#xA;"
41188108,How to enable automatic routing in Netflix/Zuul and Netflix/Ribbon with discovery information from Netflix/Eureka Service?,2016-12-16 15:58:41,<java><spring-boot><microservices><netflix-zuul><netflix-eureka>,2,847,0,0.0,0,"<p>I'm quite new in things with the netflix cloud Microservice architecture.</p>&#xA;&#xA;<p>There are three Microservices running in my Network:</p>&#xA;&#xA;<ul>&#xA;<li><p>Zuul/Ribbon Service: localhost:8765</p>&#xA;&#xA;<p><code>Application.yml:&#xA;  ===============&#xA;  eureka:&#xA;   client:&#xA;    serviceUrl:&#xA;     defaultZone: http://localhost:8761/eureka/</code></p></li>&#xA;<li><p>Eureka Service: localhost:8761</p></li>&#xA;<li>RentCarService: localhost:8888</li>&#xA;</ul>&#xA;&#xA;<p>Now, my request is: <strong>localhost:8765/RentCarService/getAllAvailableCars</strong></p>&#xA;&#xA;<p>This request should automatically routed forward to the right Microservice (RentCarService with Port 8888) like <strong>localhost:8888/getAllAvailableCars</strong></p>&#xA;&#xA;<p>I have seen much tutorials and the most of them are forwarding the requests programmatically like in this tutorial:</p>&#xA;&#xA;<p><a href=""http://www.disasterarea.co.uk/blog/microservice-discovery-with-spring-boot-and-eureka/"" rel=""nofollow noreferrer"">Microservice discovery with spring boot and eureka</a></p>&#xA;&#xA;<p><a href=""https://github.com/callistaenterprise/blog-microservices/blob/B1/microservices/composite/product-composite-service/src/main/java/se/callista/microservices/composite/product/service/Util.java"" rel=""nofollow noreferrer"">Or here by a method called getServiceURL</a></p>&#xA;&#xA;<p>Do i have to code the forwarding by my own or is <strong>this possible automatically by Ribbon</strong>?</p>&#xA;&#xA;<p>Beste regards&#xA;lars</p>&#xA;"
41027573,Ansible playbook to find particular java process and kill,2016-12-07 21:20:12,<java><jar><find><ansible><microservices>,1,1195,0,0.0,0,"<p>I'm working on deploying microservices with ansible-playbook right now. And all of the microservices uses <code>java -jar</code> command to deploy. Right now I'm trying to write an ansible playbook to find and kill dependent java -jar process before deploying other one.</p>&#xA;&#xA;<p>I'm running out of ideas here. I was thinking of creating a script in init.d for java deamon. But, if i do that and stop service, it would stop all the java processes which i wouldn't want. </p>&#xA;&#xA;<p><strong>Output for</strong> <code>ps -ef | grep java</code></p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>root</strong>     28330     1  1 13:52 ?        00:00:56 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config /opt/app/microservices/deploy/dal-core/enrollment-vehicle-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29143     1  2 14:22 ?        00:00:49 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-vehicle-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29879     1  2 14:23 ?        00:00:48 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-account-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     31093     1  3 14:28 ?        00:01:04 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/listener/config  /opt/app/microservices/deploy/listener/enrollment-account-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p>asadmin  31208 18879  0 14:57 pts/1    00:00:00 grep --color=auto java</p>&#xA;</blockquote>&#xA;&#xA;<p>In the above scenario, If i happen do deploy enrollment-account-dal-core again, I should 1st kill enrollment-account-listener (pid:31093) and then enrollment-account-dal-core (pid:29879).</p>&#xA;&#xA;<p>I have one playbook for all of the microservices so I won't be able to hard code it either.</p>&#xA;"
41123857,How to publish an event in the microservice world?,2016-12-13 14:44:03,<amazon-web-services><events><microservices><grpc>,1,149,3,0.0,0,"<p>There are many books and blogs detailing how event-based communication between microservices is easier to maintain than services calling eachother directly. </p>&#xA;&#xA;<p>However how would this be implemented in the AWS world? I was considering Topics, but it is far from ideal.</p>&#xA;&#xA;<p>How is this patter usually implemented to give guarantees on latency, durability, guaranteed delivery, idempotency etc.</p>&#xA;"
46021905,"microservices, server-sent events, and browser limitations",2017-09-03 09:15:10,<rest><microservices><server-sent-events>,1,110,3,0.0,0,"<p>In a micro-service oriented architecture, where each micro-service offers an SSE endpoint to stream events to the client, an HTTP connection is opened and kept alive between the client and the service. Unfortunately, this approach is almost unpractical when the client runs within a Web Browser because Web Browsers have a limitation on the number of HTTP connections that can be opened simultaneously on the same server (by domain name if I'm not wrong).</p>&#xA;&#xA;<p>It's a pity because SSE is a great technology for streaming events.</p>&#xA;&#xA;<p>What's the best approach for streaming events in a micro-service oriented architecture then, when the client runs in a browser?</p>&#xA;"
45964527,Microservice passing entity id guid or unique code,2017-08-30 15:35:26,<rest><wcf><domain-driven-design><microservices>,1,169,3,0.0,0,"<p>We have two different microservices Customer service and Order service. Customer service store information about customer i.e. Name, DOB, etc. The Order service will mange the order that a customer has place i.e order number, cost etc. Which is the best way to passing customer unique reference/ ID to order services.</p>&#xA;&#xA;<p>Solution 1:&#xA;Customer ID is a GUID uniquely in Customer service. This will be passed to the Order service</p>&#xA;&#xA;<p>Solution 2:&#xA;Generate a business/human friendly unique code in Customer service and pass it to Order service</p>&#xA;&#xA;<p>Solution 3:&#xA;Something else?</p>&#xA;"
45855433,Microservices Config and eureka service which one to start first?,2017-08-24 07:27:40,<spring-boot><intellij-idea><microservices><netflix-eureka><netflix>,1,577,4,0.0,0,"<p>I am creating a simple project in microservices using spring boot and netflix OSS to get my hands dirty. I have created two services</p>&#xA;&#xA;<ol>&#xA;<li>config service which has to register itself in discovery(eureka)&#xA;service. </li>&#xA;<li>discovery service which requires config service to be running to get its configuration.</li>&#xA;</ol>&#xA;&#xA;<p>Now when I am starting these services, both services fails due to inter dependency. What are the best practices resolve this issue and which one to start first.</p>&#xA;&#xA;<p>PS:- I know I am creating circular dependency, But what is the way to deal with situation like this where I want to keep eureka configuration also with the config server</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45996858,Self-contained microservices with Docker,2017-09-01 09:14:22,<docker><docker-compose><microservices>,1,92,5,0.0,0,"<p>I'm trying to setup a project built up of several microservices orchestrated with Docker. Here is the simplified schema of my project:</p>&#xA;&#xA;<pre><code>- Main-project&#xA;  - Dockerfile&#xA;  - docker-compose.yml (bundles Microservice1 and Microservice2)&#xA;&#xA;- Microservice1&#xA;  - Dockerfile&#xA;&#xA;- Microservice2&#xA;  - Dockerfile&#xA;</code></pre>&#xA;&#xA;<p>Now, each component has many dependencies such as RabbitMQ managed by the docker-compose.yml file. I manage to make the whole project run on Docker by using the compose file.</p>&#xA;&#xA;<p>However, I'm having problems in running the individual components by itself. The problem is that Microservice1 depends on rabbitMQ but it does not have a compose file to manage this dependency, and the same goes for all other components. So when I try to run any individual component by itself (for unit-tests, for instances) I have a problem of missing dependencies.</p>&#xA;&#xA;<p>Should I add all the dependencies also on the Dockerfile of each component? &#xA;Should I have one docker-compose file per component?&#xA;What are the best practices to setup a system like this?</p>&#xA;&#xA;<p>Thanks a lot!</p>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>As an important note, I forgot to mention that each microservice has its own repo.</p>&#xA;"
40525468,Java 8 LocalDate displaying in swagger,2016-11-10 10:36:57,<java><documentation><swagger><microservices><swagger-2.0>,1,1693,0,0.0,0,"<p>I have a DTO which contains field of Java 8 LocalDate type. With Jackson annotations it's possible to set format to <code>ISO.DATE</code> and everything works good. But Swagger (I have version 2.+) see the <code>LocalDate.class</code> as object</p>&#xA;&#xA;<pre><code>LocalDate {&#xA;month (integer, optional),&#xA;year (integer, optional)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(That's true but...) I want to dipsay this as string with format as it works with <code>util.Date</code>.&#xA;How can I solve it?</p>&#xA;"
40436389,using entity in other jhipster microservice,2016-11-05 08:53:23,<jhipster><microservices>,2,673,0,0.0,0,"<p>I have problem to use entities between Microservices ,I have microservice1 has Team entity I need to use Team entity in microservice2 ,I mean I need to import TeamRepository.java in microservice2,How can do that with jhipster?</p>&#xA;"
40467382,how to use role authorization for micro services architecture?,2016-11-07 14:17:51,<ruby-on-rails><microservices><rails-api>,3,205,0,0.0,0,<p>I wrote an API in rails which is of micro services architecture.&#xA;In my API i need to implement Role authorization to authorize each and every user using their roles.&#xA;Is there any gem that fits into micro services architecture or should I write my own logic to authorize users.&#xA;i was using gem authorization gem but it does provide much capability that fits into micro services architecture.(rolify)&#xA;Is there any other that suits micro services architecture?</p>&#xA;&#xA;<p>Thanks in Advance.</p>&#xA;
40469391,"Wait for condition in Enzyme and Jest (eventual consistency, assert with timeout)",2016-11-07 16:00:53,<reactjs><microservices><jestjs><enzyme>,1,431,4,0.0,0,"<p>I have a simple test:</p>&#xA;&#xA;<pre><code>import React from 'react';&#xA;import GenericButton from 'components/buttons/GenericButton';&#xA;import { shallow } from 'enzyme';&#xA;import { shallowToJson } from 'enzyme-to-json';&#xA;&#xA;describe('Generic Button', () =&gt; {&#xA;    test('Button action called when clicked', () =&gt; {&#xA;        var clicked = false;&#xA;        const component = shallow(&#xA;            &lt;GenericButton action={() =&gt; {&#xA;                clicked = true;&#xA;            }}&#xA;            id=""testComponent""/&gt;&#xA;        );&#xA;&#xA;        component.find('testComponent').first().simulate('click');&#xA;        expect(clicked).toBeTruthy();&#xA;    });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However this will fail as the action is done eventually,</p>&#xA;&#xA;<p>If i set the assertion to happen eventually (using setTimeout for example) it will work</p>&#xA;&#xA;<p>however it would be better if i do something of the following before the assert (found this on examples using jasmine)</p>&#xA;&#xA;<pre><code>        waitsFor(() =&gt; {&#xA;            return clicked;&#xA;        }, ""the value to change"", 1000);&#xA;</code></pre>&#xA;&#xA;<p>What is the equivalent call for enzyme/jest?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Edit: Content of component</p>&#xA;&#xA;<pre><code>render() {&#xA;    return &lt;Button id={this.props.id}&#xA;                   key={this.props.id}&#xA;                   onClick={() =&gt; this.props.action()}&#xA;                   bsStyle={this.props.style}&gt;&#xA;               {this.props.text}&#xA;           &lt;/Button&gt;;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(Button is a 3rd party library component)</p>&#xA;"
29731394,dependency management on micro services architecture,2015-04-19 14:46:29,<git><dependencies><microservices>,2,836,0,0.0,0,"<p>I build an app based on the micro services architecture, i have now two services with some common code to both.</p>&#xA;&#xA;<p>What is the conventional way to do that? (different projects, modules etc)&#xA;I would also like a refernece on how to handle them in a git repository (for all? for each?)</p>&#xA;"
29821391,Spring @RequestMapping redirect to same path with additional info,2015-04-23 10:57:01,<java><spring><spring-mvc><spring-boot><microservices>,2,861,3,0.0,0,"<p>A somewhat unusual scenario perhaps, but we need to redirect in a Spring MVC controller from:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html&#xA;</code></pre>&#xA;&#xA;<p>to:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html#/some_path/&#xA;</code></pre>&#xA;&#xA;<p>All my attempted solutions to date have resulted in a redirect loop, as Spring performs the redirect but is then repeatedly matching /browser.html in the redirect URL, regardless of the additional info.  What I need to say is 'match /browser.html ONLY if it's the end of the path'.</p>&#xA;&#xA;<p>I have tried <code>setUseSuffixPatternMatch(Boolean.FALSE);</code> on the <code>PathMatchConfigurer</code> to no avail, also tried the following URI template regex pattern in the request mapping itself:</p>&#xA;&#xA;<pre><code>""/js/hal-browser/{file:browser\\.html$}""&#xA;</code></pre>&#xA;&#xA;<p>..but still get a redirect loop. Ideas appreciated - this is Spring 4.1.6 in a SpringBoot 1.2.3 microservice, by way of context.</p>&#xA;&#xA;<p><strong>Update:</strong>&#xA;On further investigation and a better understanding of the URL fragment in use by the HAL browser to determine which path it will make a request to within the microservice itself, I believe the solution may lie not in trying to redirect off <code>browser.html</code>, as Spring will map this to the same controller method on every request regardless of the fragment value, but instead either reverting to the default context path for the application (<code>/</code>), which the HAL browser has set as its default entry point, or finding a way to configure the embedded tomcat container to respond with something sensible (not just a 404) on the default context path even though the app is mapped to /some_path.</p>&#xA;&#xA;<p>As further context, we can redirect no problem at all from a convenience path of <code>/browser</code> (or whatever) into the HAL browser with the correct entry point fragment as the context path of the service - that works fine. The issue is the browser itself has a 'Go to entry point' button which, when pulling it in as a <a href=""https://github.com/Product-Foundry/hal-browser-webjar"" rel=""nofollow"">webjar</a>, is hardcoded to <code>/</code>. The other alternative is to ditch the webjar and just copy in the static files for the browser and update the entry point.</p>&#xA;"
29610354,Discovery pattern for REST API endpoint,2015-04-13 16:27:09,<java><node.js><rest><microservices>,1,674,3,0.0,0,"<p>I m actually studying Microservice architecture pattern and it seems that the API Gateway pattern uses the Discovery pattern, but with REST API endpoints.</p>&#xA;&#xA;<p>Can anybody explain me how it works for example if my API Gateway is NodeJS based and my REST APIs are Java written ?</p>&#xA;&#xA;<p>I dont really know how can I implement this pattern and I dont find any code or schema to help me understand a bit more.</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
41783283,RabbitMQ embedded broker is not starting from spring boot application,2017-01-21 19:02:28,<java><spring-boot><microservices><spring-rabbitmq><embedded-server>,1,1037,0,0.0,0,"<p>I am unable to send message in ""CustomerQ"" queue of rabbitmq broker. I have configured rabbitmq broker as embedded server through spring boot.</p>&#xA;&#xA;<pre><code> package com.testlab.chapter2;&#xA;&#xA;  import org.springframework.amqp.core.Queue;&#xA;  import org.springframework.amqp.rabbit.core.RabbitMessagingTemplate;&#xA;  import org.springframework.beans.factory.annotation.Autowired;&#xA;  import org.springframework.context.annotation.Bean;&#xA;  import org.springframework.context.annotation.Lazy;&#xA;  import org.springframework.stereotype.Component;&#xA;&#xA;&#xA;&#xA;  @Component &#xA;  @Lazy&#xA; class Sender {&#xA;&#xA;  RabbitMessagingTemplate template;&#xA;&#xA;  @Autowired&#xA;  Sender(RabbitMessagingTemplate template){&#xA;    this.template = template;&#xA;  }&#xA;&#xA;  @Bean&#xA;  Queue queue() {&#xA;    return new Queue(""CustomerQ"", false);&#xA;   }&#xA;&#xA;   public void send(String message){&#xA;    System.out.println(template.getRabbitTemplate().getConnectionFactory());&#xA;&#xA;    template.convertAndSend(""CustomerQ"", message);&#xA;    }&#xA;  }&#xA;&#xA; **application.properties file configuration:**&#xA;&#xA;  spring.rabbitmq.host=localhost&#xA;  spring.rabbitmq.port=5672&#xA;  spring.rabbitmq.username=guest&#xA;  spring.rabbitmq.password=guest&#xA;</code></pre>&#xA;&#xA;<p>I am getting below error when code is trying to connect/put any message in queue&#xA;<strong>Error:</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.messaging.MessagingException: java.net.ConnectException: Connection refused: connect; nested exception is org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused: connect] with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused: connect&#xA;      at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_25]&#xA;      at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:345) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_25]&#xA;      at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_25]&#xA;      at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_25]&#xA;      at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_25]</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate your help on this.</p>&#xA;"
41880524,Microservices based architecture and individual cache for each node,2017-01-26 18:35:24,<java><hibernate><caching><architecture><microservices>,1,764,0,0.0,0,"<p>Is it considered bad practice to use separated, local cache for each node in distributed microservice application? I've heard that in monolithic application it's OK to use local EHCache as 2nd level cache provider for Hibernate, but in distributed environment it's common practice to use distributed caches, such as Memcached, Redis or Hazelcast. What are the consequences of using separated cache for each node?</p>&#xA;"
41783704,How can we route a request to every pod under a kubernetes service on Openshift?,2017-01-21 19:42:36,<kubernetes><microservices><restful-architecture><application-design><openshift-enterprise>,1,307,3,0.0,0,"<p>We are building a Jboss BRMS application with <em>two microservices in spring-boot</em>, one for <strong>rule generation (SRV1)</strong> and one for <strong>rule execution (SRV2)</strong>.&#xA;The idea is to <strong><em>generate the rules</em></strong> using the generation microservice (SRV1) and <strong><em>persist them in the database with versioning</em></strong>. The next part of the process is having the execution microservice <strong><em>load these persisted rules into each pods memory</em></strong> by querying the information from the shared database.</p>&#xA;&#xA;<p>There are two following scenarios when this should happen :</p>&#xA;&#xA;<blockquote>&#xA;  <ul>&#xA;  <li><p>When the rule execution service pod/pods <strong>starts up</strong>, it queries the db for the lastest version and every pod running the execution application loads those rules from the shared db.</p></li>&#xA;  <li><p>The second senario is we <strong>manually</strong> want to trigger the loading of a <strong>specific version</strong> of rules on every pod running the execution application preferably via a rest call.</p></li>&#xA;  </ul>&#xA;</blockquote>&#xA;&#xA;<p><strong><em>Which is where the problem lies!</em></strong> </p>&#xA;&#xA;<p>Whenever we try and issue a rest request to the api, since it is load balanced under a kubernetes service, the request hits only one of the pods and the rest of them do not load the specific rules.</p>&#xA;&#xA;<p>Is there a programatic or design change that may help us achieve that or is there any other way we construct our application to achieve a capability to load a certain version of rules on all pods serving the execution microservice.</p>&#xA;"
51122354,Coupling in microservices architecture,2018-07-01 10:11:20,<microservices><coupling>,1,33,3,0.0,0,"<p>When working on an application in microservices architecture I stumbled upon issues concerning coupling between services.</p>&#xA;&#xA;<p>This a typical application for ordering products. It seams reasonable to have a service that will operate as a product catalog. Our JavaScript client can ask this service for available products and show them in browser. When user clicks on a product we have to create an order. We would like to manage orders in another service. So an order is created - it means that user X ordered product Y. On the technical level we are simply persisting user id and product id in a database.</p>&#xA;&#xA;<p>To sum up we have:</p>&#xA;&#xA;<h3>Products service</h3>&#xA;&#xA;<p>Product class:<br/>&#xA;Product ID, Product Name </p>&#xA;&#xA;<h3>Orders service</h3>&#xA;&#xA;<p>Order class:<br/>&#xA;Order ID, Product ID,  User ID,   Order date  </p>&#xA;&#xA;<p>Now let's imagine following scenario - in JavaScript client we would like to list all products that user have ordered. Orders service provides a list of products ids for a given user. But user cares about product name, not the id. Unfortunately Orders service doesn't know anything about products names.</p>&#xA;&#xA;<p>We could tackle this in couple of ways:</p>&#xA;&#xA;<ul>&#xA;<li><p>Simply assume that the client is responsible for getting the information it needs. So after it calls Orders service and gets a list of products ids, it performs another call to Products service, passing products ids and getting corresponding products names in response. Then the client assembles both responses into something useful. This approach keeps our services clean, without leaking of domain knowledge from one service to another. But it requires more work on the client side.</p></li>&#xA;<li><p>Orders service when asked for ordered products makes a call on the backend to the Products service. It retrieves product names, assembles a response that contains orderDate and  productName and sends that to client. All that's left for client to do is to present the data. Downside of this approach is that Orders service now gains more knowledge about products than neccessary.</p></li>&#xA;<li><p>Duplicate information about product name in Orders service. When an order is created, we pass not only product id but also product name. That means that Order class will look like this:&#xA;Order class:<br/>&#xA;Order ID, Product ID, Product name, User ID, Order date<br/>&#xA;Now we can easly provide full information about order without additional call to Products service. Also this time Orders service has too much knowledge about products. What's beneficial tough is that Orders service can provide relevant data even if Products service is down.</p></li>&#xA;</ul>&#xA;&#xA;<p>Could any of these approaches be considered best practice? Or are there different solutions?</p>&#xA;"
51120978,Is REST a good fit for microservices?,2018-07-01 06:33:36,<rest><microservices><synchronous>,2,48,3,0.0,0,"<p>I am exploring micorservices architecture through books, blogs etc. </p>&#xA;&#xA;<p>What I have seen is that mostly people implement microservices using REST. Isn't it contradictory?</p>&#xA;&#xA;<p>Microservices are supposed to decouple services to achieve scalability, but REST communication protocol is synchronous. </p>&#xA;&#xA;<p>So how can these two go together?</p>&#xA;"
42395345,Service fabric reliable collections data loss after service upgrade,2017-02-22 15:13:29,<.net><azure><microservices><azure-service-fabric><service-fabric-stateful>,1,395,0,2.0,0,"<p>Why reliable collections is empty after micro-service upgrade and not invoking event OnDataLossAsync to restore state from external backup?</p>&#xA;&#xA;<p>We have large scale system based on stateful services</p>&#xA;&#xA;<pre><code>&lt;StatefulServiceType ServiceTypeName=""UserServiceType"" HasPersistedState=""true"" /&gt;&#xA;</code></pre>&#xA;&#xA;<p>HasPersistedState is set as true, and data replicated across replicas, in case of VM failure data still valid and recovering with OnDataLossAsync but after upgrade collections is empty.</p>&#xA;&#xA;<p>I have tried all upgrade options (remove, keep, auto ugrade) application, result the same - collections is empty.</p>&#xA;&#xA;<p>For now we decided to replicate data to blob storage and recover it after service update which is not perfect solution, data recovery takes a few minutes and it makes some service unavailable/inconsistent for that time.</p>&#xA;&#xA;<p>So we are looking for solution that allows to save data after upgrade.</p>&#xA;"
42458964,logback settings and spring config-server,2017-02-25 17:03:42,<java><spring><spring-boot><cloud><microservices>,1,1272,0,0.0,0,"<p>There are many of microservices, all of them should write logs to  the same graylog server. In every of microservices is used a GelfLogbackAppender which has several settings like host, post and etc. These setting are the same for all of services and i want to store them in one place like a spring config-server. How can i do that? How can i get and use GELF_ADDRESS from config-server?</p>&#xA;&#xA;<pre><code>&lt;appender name=""gelf"" class=""biz.paluch.logging.gelf.logback.GelfLogbackAppender""&gt;&#xA;    &lt;host&gt;udp:${GELF_ADDRESS}&lt;/host&gt;&#xA;    &lt;port&gt;${GELF_PORT}&lt;/port&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>UPDATE</strong> I've decided to show simple example what i want to, let's imagine i want to change log level for all microservices through config-server. i make next things:</p>&#xA;&#xA;<p><strong>logback-spring.xml</strong></p>&#xA;&#xA;<pre><code>&lt;configuration&gt;&#xA;    &lt;property name=""LEVEL"" value=""${log_level}""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/defaults.xml""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/console-appender.xml""/&gt;&#xA;    &lt;root level=""${LEVEL}""&gt;&#xA;         &lt;appender-ref ref=""CONSOLE""/&gt;&#xA;    &lt;/root&gt;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong> is being in config-server</p>&#xA;&#xA;<pre><code>eureka:&#xA;  client:....&#xA;feign:&#xA;  hystrix:....&#xA;log_level: info&#xA;</code></pre>&#xA;&#xA;<p>it doesn't work, i always see DEBUG level, if i write</p>&#xA;&#xA;<pre><code>&lt;property name=""LEVEL"" value=""info""/&gt; &#xA;</code></pre>&#xA;&#xA;<p>manualy into  logback-spring.xml, the level will be changed, but i want to do that through central config-serverer</p>&#xA;"
42462663,Microservice depends on other one to do anything,2017-02-25 23:02:54,<dependencies><microservices><relationships>,1,316,3,0.0,0,"<p>At the moment I deal with micro-services and ran into a few questions (regarding relations between services), I have a hard time to find a good answer/best practices for. It would be really great if you could give me a hint or an advice how you would handle this.</p>&#xA;&#xA;<p>Because these question are not directed to a specific project, I try to make it as clear as possible with the following example:</p>&#xA;&#xA;<p>Let‘s assume you want to build some kind of Youtube channel observer, that logs different kinds of channel‘s (meta-)data (videos, hourly views/sub count, currently subscribed to), that are imported in a specific time interval.</p>&#xA;&#xA;<p>So there are two major features the app has to offer, which should form a microservice each:</p>&#xA;&#xA;<ul>&#xA;<li>Add/remove channels to be watched (=> manager service)</li>&#xA;<li>import information (=> import service)</li>&#xA;</ul>&#xA;&#xA;<p>Both services provide an API to communicate with each other.</p>&#xA;&#xA;<p>The manager service is connected to a database which contains the channels that need to be watched, with their basic information (name, contact, ...) and the channels these observed channels are currently subscribed to, whereas the import service has a database containing all the other more time-series oriented information (videos, hourly views/sub count).</p>&#xA;&#xA;<p>To add a channel only the channel url has to specified. All the other information (name, contact, ...) are added by the import service (but can also be modified by the user).</p>&#xA;&#xA;<p>All in all the import service is totally useless without the information of the manager service, but also the manager service can only show the user specified channel information (worst case: only channel url) if no import service is available. In total: they depend heavily on each other.</p>&#xA;&#xA;<p>So much for the general architecture. </p>&#xA;&#xA;<p>The problem I have here is, that the import service depends on the data in the manager service database to such a great degree and also modifies it:</p>&#xA;&#xA;<ol>&#xA;<li>Would it be a good idea to share the manager service database between these two services or should it only be accessible by the provided API?</li>&#xA;<li>No matter if database is shared or not: both services need model classes for the channel. Is it fine to share those? </li>&#xA;<li>Is this architecture even a good idea at all (if we assume that there are also other services that need the basic channel information)? </li>&#xA;</ol>&#xA;"
42611968,"I have multiple flask microservices that all communicate with each other, how would I configure docker?",2017-03-05 18:02:18,<python><docker><flask><dockerfile><microservices>,1,480,6,0.0,0,<p>I have multiple flask microservices (this is obviously obfuscated to protect IP)</p>&#xA;&#xA;<pre><code>├── README.md&#xA;├── api_starter.py&#xA;├── app_api.py&#xA;├── service1&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service1.py&#xA;├── service2&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   ├── service2.py&#xA;├── dags&#xA;│   ├── airflow_pipeline_runner.py&#xA;├── service3&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   ├── service3.py&#xA;├── service4&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service4.py&#xA;├── service5&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service5.py&#xA;├── service6&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service6.py&#xA;├── requirements.txt&#xA;└── service7&#xA;    ├── __init__.py&#xA;    ├── api.py&#xA;    └── service7.py&#xA;</code></pre>&#xA;&#xA;<p>Each one of these microservices are being run by the api_starter. Each of these microservices communicate with each other. What's the best way to dockerize this application? Do I give each microservice a docker file and then have a docker-compose.yml in the root of the directory? Each of these microservices communicate with each other. Any and all </p>&#xA;
39405067,org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization,2016-09-09 06:23:48,<java><spring-boot><microservices>,1,14900,0,2.0,0,"<p>I'm developing <strong>spring boot microservices</strong> example from the link: <a href=""https://dzone.com/articles/spring-boot-creating"" rel=""nofollow"">https://dzone.com/articles/spring-boot-creating</a>. In this project I simply updated the parent dependency to its latest version and other code files are unchanged. I faced the following error when I click <strong><a href=""http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4"" rel=""nofollow"">http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4</a></strong></p>&#xA;&#xA;<pre><code>2016-09-09 11:46:20.888 ERROR 14152 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : StandardWrapper.Throwable&#xA;&#xA;org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization.&#xA;[[FATAL] A resource model has ambiguous (sub-)resource method for HTTP method GET and input mime-types as defined by""@Consumes"" and ""@Produces"" annotations at Java methods public java.util.List br.com.alexandreesl.handson.rest.ProductRest.getProducts() and public java.util.List br.com.alexandreesl.handson.rest.CustomerRest.getCustomers() at matching regular expression /. These two methods produces and consumes exactly the same mime-types and therefore their invocation as a resource methods will always fail.; source='org.glassfish.jersey.server.model.RuntimeResource@14c14bf']&#xA;    at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:555) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.access$500(ApplicationHandler.java:184) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:350) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:315) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:297) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.processWithException(Errors.java:255) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.&lt;init&gt;(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.WebComponent.&lt;init&gt;(WebComponent.java:392) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:177) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:369) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at javax.servlet.GenericServlet.init(GenericServlet.java:158) ~[tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1194) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.allocate(StandardWrapper.java:806) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:133) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:522) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:1110) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:785) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1425) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_102]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_102]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_102]&#xA;</code></pre>&#xA;&#xA;<p>the updated <strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;junit&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;junit&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Application.java</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;public class Application {&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(Application.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ApplicationConfig.java</strong></p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class ApplicationConfig {&#xA;    @Named&#xA;    static class JerseyConfig extends ResourceConfig {&#xA;        public JerseyConfig() {&#xA;            this.packages(""br.com.alexandreesl.handson.rest"");&#xA;        }&#xA;    }&#xA;&#xA;    @Bean&#xA;    public RestTemplate restTemplate() {&#xA;        RestTemplate restTemplate = new RestTemplate();&#xA;        return restTemplate;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Order.java</strong></p>&#xA;&#xA;<pre><code>public class Order {&#xA;    private long id;&#xA;    private long amount;&#xA;    private Date dateOrder;&#xA;    private Customer customer;&#xA;    private Product product;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>OrderRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class OrderRest {&#xA;    private long id = 1;&#xA;&#xA;    @Inject&#xA;    private RestTemplate restTemplate;&#xA;&#xA;    @GET&#xA;    @Path(""order"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Order submitOrder(@QueryParam(""idCustomer"") long idCustomer,&#xA;            @QueryParam(""idProduct"") long idProduct,&#xA;            @QueryParam(""amount"") long amount) {&#xA;&#xA;        Customer customer = restTemplate.getForObject(""http://localhost:8080/customer?id={id}"", Customer.class, idCustomer);&#xA;        Product product = restTemplate.getForObject(""http://localhost:8080/product?id={id}"", Product.class,idProduct);&#xA;&#xA;        Order order = new Order();&#xA;        order.setCustomer(customer);&#xA;        order.setProduct(product);&#xA;        order.setId(id);&#xA;        order.setAmount(amount);&#xA;        order.setDateOrder(new Date());&#xA;        id++;&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Customer.java</strong></p>&#xA;&#xA;<pre><code>public class Customer {&#xA;    private long id;&#xA;    private String name;&#xA;    private String email;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>CustomerRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class CustomerRest {&#xA;    private static List&lt;Customer&gt; customers = new ArrayList&lt;Customer&gt;();&#xA;&#xA;    static {&#xA;        Customer customer1 = new Customer();&#xA;        customer1.setId(1);&#xA;        customer1.setNome(""Customer 1"");&#xA;        customer1.setEmail(""customer1@gmail.com"");&#xA;&#xA;        Customer customer2 = new Customer();&#xA;        customer2.setId(2);&#xA;        customer2.setNome(""Customer 2"");&#xA;        customer2.setEmail(""Customer2@gmail.com"");&#xA;&#xA;        Customer customer3 = new Customer();&#xA;        customer3.setId(3);&#xA;        customer3.setNome(""Customer 3"");&#xA;        customer3.setEmail(""Customer3@gmail.com"");&#xA;&#xA;        Customer customer4 = new Customer();&#xA;        customer4.setId(4);&#xA;        customer4.setNome(""Customer 4"");&#xA;        customer4.setEmail(""Customer4@gmail.com"");&#xA;&#xA;        Customer customer5 = new Customer();&#xA;        customer5.setId(5);&#xA;        customer5.setNome(""Customer 5"");&#xA;        customer5.setEmail(""Customer5@gmail.com"");&#xA;&#xA;        customers.add(customer1);&#xA;        customers.add(customer2);&#xA;        customers.add(customer3);&#xA;        customers.add(customer4);&#xA;        customers.add(customer5);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Customer&gt; getCustomers() {&#xA;        return customers;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""customer"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Customer getCustomer(@QueryParam(""id"") long id) {&#xA;        Customer cli = null;&#xA;        for (Customer c : customers) {&#xA;            if (c.getId() == id)&#xA;                cli = c;&#xA;        }&#xA;        return cli;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Product.java</strong></p>&#xA;&#xA;<pre><code>public class Product {&#xA;    private long id;&#xA;    private String sku;&#xA;    private String description;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ProductRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class ProductRest {&#xA;    private static List&lt;Product&gt; products = new ArrayList&lt;Product&gt;();&#xA;&#xA;    static {&#xA;        Product product1 = new Product();&#xA;        product1.setId(1);&#xA;        product1.setSku(""abcd1"");&#xA;        product1.setDescription(""Product1"");&#xA;        Product product2 = new Product();&#xA;        product2.setId(2);&#xA;        product2.setSku(""abcd2"");&#xA;        product2.setDescription(""Product2"");&#xA;        Product product3 = new Product();&#xA;        product3.setId(3);&#xA;        product3.setSku(""abcd3"");&#xA;        product3.setDescription(""Product3"");&#xA;        Product product4 = new Product();&#xA;        product4.setId(4);&#xA;        product4.setSku(""abcd4"");&#xA;        product4.setDescription(""Product4"");&#xA;        products.add(product1);&#xA;        products.add(product2);&#xA;        products.add(product3);&#xA;        products.add(product4);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Product&gt; getProducts() {&#xA;        return products;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""product"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Product getProduct(@QueryParam(""id"") long id) {&#xA;        Product prod = null;&#xA;        for (Product p : products) {&#xA;            if (p.getId() == id)&#xA;                prod = p;&#xA;        }&#xA;        return prod;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please guide on this issue.</p>&#xA;"
39425569,Spring Boot Java8 Microservice Simple Message Subscription service,2016-09-10 11:27:38,<spring-boot><java-8><jms><microservices>,2,659,0,0.0,0,<p>I am new to Microservice and JMS likes to know how can I</p>&#xA;&#xA;<ul>&#xA;<li>create a subscription      </li>&#xA;<li>read the subscription </li>&#xA;</ul>&#xA;&#xA;<p>Using Spring Boot and JMS </p>&#xA;
39622142,resilient microservices design pattern,2016-09-21 16:42:31,<reactive-programming><microservices><resiliency>,2,154,0,2.0,0,"<p>in reactive programming Resilience is achieved by replication, containment, isolation and delegation.</p>&#xA;&#xA;<p>two of the famous design patterns are Bulkheads with supervisor and circuit breaks. are these only for reaching isolation and containment?</p>&#xA;&#xA;<p>what are the most famous design patterns for microservices and specially the ones give resiliency?  </p>&#xA;"
39416301,Microservices - API Gateway Layer,2016-09-09 16:48:40,<spring-boot><cloudfoundry><microservices><pivotal-cloud-foundry>,1,1395,1,0.0,0,"<p>I have read few details of use of api gateway in microservices architecture. I have read that it basically helps with security , transformation , throttling etc. Is orchestration also one of it responsibilities? When I read about microservices , I saw that it should have dumb pipes and smart endpoints and services must be choreographed and not orchestrated. So my assumption is that orchestration is not a responsibility  of api gateway.</p>&#xA;"
47178056,Spring boot Kubernetes Service Discovery,2017-11-08 11:04:17,<spring><spring-boot><kubernetes><microservices>,1,844,3,1.0,0,"<p>I am running into issues with Kubernetes Service Discovery on Spring Boot applications. </p>&#xA;&#xA;<p>I should be able to discover the services whether my spring boot application is running within or out of Kubernetes cluster. Our local development won't be on k8s cluster.</p>&#xA;&#xA;<p>I am using Service Discovery via DNS. I tried using <a href=""https://github.com/spring-cloud-incubator/spring-cloud-kubernetes"" rel=""nofollow noreferrer"">spring-cloud-starter-kubernetes</a></p>&#xA;&#xA;<pre><code>    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-kubernetes&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.2.0.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>As per documentation you should be able to autowire DiscoveryClient and good to go</p>&#xA;&#xA;<pre><code>@Autowire&#xA;private DiscoveryClient discoveryClient;&#xA;</code></pre>&#xA;&#xA;<p>DiscoveryClient is part of spring-cloud-commons. spring-cloud-starter-kuberenetes doesn't have it. </p>&#xA;&#xA;<p>Anyone solved similar problem using the same library or a different one? Please share the solution</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
37864255,Security between microservices,2016-06-16 16:07:44,<spring-security><microservices><spring-cloud-feign><spring-cloud-security>,2,1835,3,0.0,0,"<p>I have two microservices, for example, A and B. The microservice B has the rest enpoint that must be accessible only from the microservice A.&#xA;How can I limit access between microservices? What is the best practice if at all possible?</p>&#xA;&#xA;<p>I'm using spring cloud security (oauth2, jwt).</p>&#xA;"
50128046,How should I design my Spring Microservice?,2018-05-02 06:02:52,<spring><spring-boot><microservices>,3,78,0,0.0,0,"<p>I am trying to create a <code>Microservice architecture</code> for a hobby project and I am confused about some decisions. Can you please help me as I never worked using Microservice before?</p>&#xA;&#xA;<ol>&#xA;<li>One of my requirements is that my <code>AngularJS</code> GUI will need to show some drop-down or List of values (example: a list of countries). This can be fetched using a <code>Microservice</code> REST call, but where should the values come from? Can I fetch these from my <code>Config Server</code>? or should it come from <code>Database</code>? If the latter, then should each of the Microservice have their own Database for lookup value or can it be a common one?</li>&#xA;<li>How would server-side validation work in this case? I mean, there will certainly be a Microservice call the GUI will make for validation but should the validation service be a common Microservice for all Use Cases/Screens or should it be one per GUI page or should the <code>CRUD</code> Microservice be reused for validation as well?</li>&#xA;<li>How do I deal with a use-case where the back-end is not a Database but a Web-service call? Will I need some local <code>DB</code> still to maintain some state in between these calls (especially to take care of scenario where the Web-service call fails) and finally pass on the status to GUI?</li>&#xA;</ol>&#xA;"
50289914,Deal with enumeration in Microservices architecture,2018-05-11 10:06:16,<architecture><microservices><enumeration>,2,41,3,1.0,0,"<p>I recently faced a problem when I designed the microservices architecture of our new system. &#xA;To give more context on that, let's suppose that we have two different services. </p>&#xA;&#xA;<ul>&#xA;<li><p>A service is responsible to make payments and the other one </p></li>&#xA;<li><p>B service is responsible to keep track of the orders. </p></li>&#xA;</ul>&#xA;&#xA;<p>We have a use case that we need to update an order state from the service A. </p>&#xA;&#xA;<p>We have these states in an enumeration list inside the service B. </p>&#xA;&#xA;<p>How can I avoid the sharing of this enumeration between two services? &#xA;I need to have decoupled services.</p>&#xA;&#xA;<p>Please feel free to ask for clarifications. </p>&#xA;"
50270206,Linking Microservices to test/dev/prod environments with ingress,2018-05-10 09:55:58,<kubernetes><microservices><kubernetes-ingress>,1,47,3,0.0,0,"<p>Let's consider we have three environments:</p>&#xA;&#xA;<ul>&#xA;<li><code>test.website.com</code></li>&#xA;<li><code>dev.website.com</code></li>&#xA;<li><code>prod.website.com</code></li>&#xA;</ul>&#xA;&#xA;<p>Each of the environment consists of the following microservices: webapp, service1, service2. I want to be able to easily call all the services from JS frontend without having to deal with domains. It would be great if I could just call <code>/services/service1/</code> and the fact I am on the same domain would keep me in the same environment.</p>&#xA;&#xA;<p>So let's consider dev environment:</p>&#xA;&#xA;<ul>&#xA;<li><code>dev.website.com/</code> -> goes to webapp</li>&#xA;<li><code>dev.website.com/services/service1/</code> -> goes to service1</li>&#xA;<li><code>dev.website.com/services/service1/</code> ...</li>&#xA;</ul>&#xA;&#xA;<p>To be able to do that, I configured ingress as follows:</p>&#xA;&#xA;<pre><code>    - path: /services/service1/*&#xA;      backend:&#xA;        serviceName: service1&#xA;        servicePort: 8080&#xA;    - path: /services/service2/*&#xA;      backend:&#xA;        serviceName: service2&#xA;        servicePort: 8080&#xA;    - path: /*&#xA;      backend:&#xA;        serviceName: webapp&#xA;        servicePort: 8080&#xA;</code></pre>&#xA;&#xA;<p>This would work great, but it doesn't.</p>&#xA;&#xA;<ol>&#xA;<li>First issue is that the <code>service1</code> receives full path (<code>/services/service1</code>) instead of just <code>/</code> when being called. For that I found this: <code>ingress.kubernetes.io/rewrite-target: /</code> - But I also foudn that this feature is not implemented, which is contradictory and doesn't make much sense.</li>&#xA;<li>Second problem is that, the order of the services is not followed and call on <code>/services/service1/</code> ends up in <code>webapp</code>.</li>&#xA;</ol>&#xA;&#xA;<p>Is this even a good approach? What is the best practice to do this?</p>&#xA;&#xA;<p><strong>Edit</strong>:</p>&#xA;&#xA;<p>According to suggestions I removed <code>*</code> from the path, which helped, but also removed necessary functionality. I need to be able to use:</p>&#xA;&#xA;<ul>&#xA;<li><code>/en/</code> -> <code>webapp</code></li>&#xA;<li><code>/services/service1/method1</code> -> <code>service1</code></li>&#xA;</ul>&#xA;&#xA;<p>This doesn't work without the <code>*</code> in path.</p>&#xA;"
43700905,Microservices - how to find DNS IP?,2017-04-29 22:05:26,<dns><microservices><service-discovery>,4,266,0,0.0,0,<p>In the world of microservices endpoints should not (must not) be hardcoded. One of the best ways to do this is to have a DNS and let each microservice register while starting. By doing this whenever microservice A wants to communicate with microservice B it just asks DNS for endpoints where B currently listens.</p>&#xA;&#xA;<p>What I do not understand is: <strong>How microservices know where the DNS lives?</strong></p>&#xA;&#xA;<p>Basically DNS is just a 'special' service and I can have one or multiple instances of it right? So I should not hardcode it's endpoint too or should I? And let's say I do - what if DNS instnace is moved to different location? Do I have to manually change it's location in configuration?</p>&#xA;&#xA;<p>Does anyone happen to know how to design this? (or can anyone just point me to any document where this is explained since although there are many information about microservices and dns I can not find this particular information anywhere - maybe it's just too trivial and I am the only one who does not get it)</p>&#xA;
43567411,PACT: java-maven,2017-04-23 04:32:40,<maven><microservices><pact><pact-java>,1,785,0,1.0,0,"<p>I need few answer for my doubt:</p>&#xA;&#xA;<ol>&#xA;<li>Pact-mock-service Vs pact-jvm-server, is both are same? Pls describe this.</li>&#xA;<li>Am implementing the PACT in java-maven</li>&#xA;</ol>&#xA;&#xA;<p>I can able to run this:</p>&#xA;&#xA;<p><a href=""https://github.com/anha1/microservices-pact-maven"" rel=""nofollow noreferrer"">https://github.com/anha1/microservices-pact-maven</a></p>&#xA;&#xA;<p><a href=""https://github.com/warmuuh/pactbroker-maven-plugin"" rel=""nofollow noreferrer"">https://github.com/warmuuh/pactbroker-maven-plugin</a></p>&#xA;&#xA;<p>Help me to understand this with pact-mock-service and pact-jvm-server</p>&#xA;"
43753039,Openshift Container Platform V3.X vs. Fabric8,2017-05-03 06:49:48,<containers><openshift><kubernetes><microservices><fabric8>,1,660,0,0.0,0,"<p>I took a look at Fabric8 Microservices Platform and searched for some alternatives for comprehension. I found Red Hats Openshift Container Platform, which seems to be the same as Fabric8, but not Open-Source. &#xA;I tried to figure out what are the major benefits of Red Hats solution.&#xA;I am already on the Openstack. </p>&#xA;"
43607751,How to create SPARK/Flink Stream Data Processing as a Microservice (REST API),2017-04-25 10:11:30,<apache-spark><playframework-2.0><microservices><apache-flink><lagom>,1,224,0,2.0,0,"<p>I am creating streaming analytics application using Spark, Flink &amp; Kafka. Each analytics/functionality will implement as a Microservice so that this analytics can able to use in the different project later.</p>&#xA;&#xA;<p>I run my Spark/Flink job perfectly in Simple Scala application and submit this job over Spark &amp; Flink cluster respectively. But I have to start/run this job when REST POST startJob() request invoke to my web service.</p>&#xA;&#xA;<p>How can I integrate my Spark &amp; Flink data processing functionality in a web service oriented application? </p>&#xA;&#xA;<p>Till now I tried <a href=""http://www.lagomframework.com/"" rel=""nofollow noreferrer"">Lagom Microservice</a> but i found so many issues you can check </p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/43255302/best-approach-to-ingest-streaming-data-in-lagom-microservice"">Best approach to ingest Streaming Data in Lagom Microservice&#xA;</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/43570899/java-io-notserializableexception-using-apache-flink-with-lagom"">java.io.NotSerializableException using Apache Flink with&#xA;Lagom</a></li>&#xA;</ol>&#xA;&#xA;<p>I think i am not taking the right direction for Stream Processing Microservice Application. Looking for right direction to implement this analytics over REST Service.</p>&#xA;"
43689879,How does one pass user context between an API and a microservice?,2017-04-28 22:50:00,<rest><microservices><azure-service-fabric>,2,412,3,1.0,0,"<p>I am trying to setup audit logging and we were wanting the log event to happen as close to the action as possible, while also knowing which user performed the action. This means we need to pipe in the user info.  What are best practices for this?</p>&#xA;"
43674924,What is the best way to manage microservice issue or bug on git,2017-04-28 07:51:48,<git><microservices><issue-tracking>,2,208,4,0.0,0,"<p>Micro-Service is about having many projects on git within different repositories.</p>&#xA;&#xA;<p>So, what is the best way to manage an issue, when there is a bug which needed to fix the code on multiple services?</p>&#xA;"
43682155,Sharing entity ID between microservices,2017-04-28 14:04:31,<rest><microservices><hateoas>,1,342,5,2.0,0,"<p>Let's say I have a <code>Users</code> microservice. Its data is consumed via REST API following HATEOAS ""pattern"", so a common request/response would be something like this:</p>&#xA;&#xA;<pre><code>GET /users&#xA;&#xA;{&#xA;  results: 5,&#xA;  data :[&#xA;    {&#xA;      name: ""John Doe"",&#xA;      email: ""whatever"",&#xA;      ...,&#xA;      links : [&#xA;        {&#xA;          rel: ""self"",&#xA;          href: ""/users/1""&#xA;        }&#xA;      ]&#xA;    },&#xA;    ...&#xA;  ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As HATEOAS says, the users' ID is not returned, but a link to ""self"". </p>&#xA;&#xA;<p>So far, so good. Now, I want another microservice to manage users' pictures. In that new microservice there is a relationship between one user an her pics, so I will need a user identifier.</p>&#xA;&#xA;<p>Should I use ""/users/1"" (""self"" link) as user ID in the pics microservice? </p>&#xA;&#xA;<p>If not, how can I approach this?</p>&#xA;"
47555732,How to correctly handle inter-service exception in a spring-based microservices architecture,2017-11-29 14:58:24,<java><exception-handling><microservices><spring-cloud-feign>,1,612,0,2.0,0,"<p>I have an application developed with a microservices architecture. Each microservice is a spring-boot application that communicates with others via FeignClient interface.</p>&#xA;&#xA;<p>Let A, a microservice (RestAPI) that calls microservice B. In normal conditions, B replies with an Object X, that is the JSON-response that A serves to client.</p>&#xA;&#xA;<p>But, if B throws an exception, I obtain a chinese-box exception to the client like this:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051071,&#xA;    ""status"": 500,&#xA;    ""error"": ""Internal Server Error"",&#xA;    ""exception"": ""Exception"",&#xA;    ""message"": { ""\""timestamp\"":1511965051052,\""status\"":422,\""error\"":\""Unprocessable Entity\"",\""exception\"":\""java.lang.MyException\"",\""message\"":\""Error message from B\"",\""path\"":\""PATH-OF-B-SERVICE\""}"",&#xA;    ""path"": ""PATH-OF-A-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In other words, MyException (status 422) is ""embedded"" in A Exception (status 500).</p>&#xA;&#xA;<p>I would like to reply the client with the inner JSON, that is:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051052,&#xA;    ""status"": 422,&#xA;    ""error"": ""Unprocessable Entity"",&#xA;    ""exception"": ""java.lang.MyException"",&#xA;    ""message"": ""ErrormessagefromB"",&#xA;    ""path"": ""PATH-OF-B-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How can I do that?</p>&#xA;"
47736658,Restricting access to api from another application ruby,2017-12-10 07:04:02,<ruby><api><http><ip><microservices>,1,33,4,0.0,0,"<p>I have a Grape API application built in Ruby. &#xA;And also some other microservices built in Python, Java etc.&#xA;I have to restrict some of these microservices from accessing a particular API in this grape application. </p>&#xA;&#xA;<p>Now, this is implemented using IP whitelisting. But every time the IP of other microservices gets changed, the code of grape application has also to be changed which is not stable. </p>&#xA;&#xA;<p>Is there any better solution for this? Please help.</p>&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;"
45526675,Async HTTP request vs HTTP requests on new thread,2017-08-05 21:48:09,<java><multithreading><rest><asynchronous><microservices>,3,533,0,0.0,0,"<p>I have 2 microservices (A and B).</p>&#xA;&#xA;<p>A has an endpoint which accepts POST requests. When users make a POST request, this happens:</p>&#xA;&#xA;<ol>&#xA;<li>Service A takes the object from the POST request body and stores it in a database.</li>&#xA;<li>Service A converts the object to a different object. And the new object gets sent to service B via Jersey HTTP client.</li>&#xA;</ol>&#xA;&#xA;<p>Step 2 takes place on a Java thread pool I have created (Executors.newCachedThreadPool). By doing step 2 on a new thread, the response time of service A's endpoint is not affected.</p>&#xA;&#xA;<p>However, if service B is taking long to respond, service A can potentially create too many threads when it is receiving many POST requests. To help fix this, I can use a fixed thread pool (Exectuors.newFixedThreadPool).</p>&#xA;&#xA;<p>In addition to the fixed thread pool, should I also use an asynchronous non-blocking HTTP client? Such as the one here: <a href=""https://hc.apache.org/httpcomponents-asyncclient-dev/"" rel=""nofollow noreferrer"">https://hc.apache.org/httpcomponents-asyncclient-dev/</a>. The Jersey HTTP client that I use is blocking.</p>&#xA;&#xA;<p>It seems like it is right to use the async HTTP client. <strong>But if I switch to a fixed thread pool, I think the async HTTP client won't provide a significant benefit - am I wrong in thinking this?</strong></p>&#xA;"
45530657,What is the correct way of sharing common yet versioned infrustructural code between microservices?,2017-08-06 09:40:12,<.net><nuget><versioning><microservices>,1,59,0,2.0,0,<p>We'd like to extract some infrastructure related code (mostly extension methods or small helper classes) into separate NuGet packages. </p>&#xA;&#xA;<p>These packages in no way contain business logic pertaining to either of the services.</p>&#xA;&#xA;<p>But as soon as as we end up having a hierarchy of dependencies between packages we are probably asking for troubles with versioning:</p>&#xA;&#xA;<p>Service1 references package Av1.1 directly and Av2.0 indirectly via referenced package B.<br/></p>&#xA;&#xA;<p>ServiceN references package Av1.5 directly and Av1.3 indirectly via referenced package C.<br/></p>&#xA;&#xA;<p>NuGet does not support side-by-side versions and only one version is used per project. This problem of versioning is relevant for monolithic applications as well though with seemingly significantly fewer possible integration issues.</p>&#xA;&#xA;<p>There are some ideas like not extracting common code and letting it be duplicated across services or just not changing the version of the package forcing every service to work with the same version.</p>&#xA;&#xA;<p>Are there any good recommendations concerning code reuse between services which go well with versioning?</p>&#xA;
45559979,Access Token/Authorization Between Microservices,2017-08-08 05:30:47,<spring-security><oauth-2.0><microservices><spring-cloud><spring-security-oauth2>,3,670,0,0.0,0,"<p>I'm creating an online store REST API that will mainly be used by a mobile app. The plan is for a microservices architecture using the Spring Cloud framework and Spring Cloud OAuth for security.</p>&#xA;&#xA;<p>My question is really on best practices for communication between microservices: Should I have each service register for their own token, or should they just pass the user's token around?</p>&#xA;&#xA;<p>For example, I have 3 services: user-service, account-service, order-service.&#xA;I've been able to implement two procedures for creating an order: One passes the user's token around, and in the other each service gets their own token. I use Feign for both approaches.</p>&#xA;&#xA;<p>So for option 1: order-service -> GET account-service/account/current</p>&#xA;&#xA;<p>order-service calls the account-service which returns the account based on a userId in the token. Then the order-service creates an order for the account.</p>&#xA;&#xA;<p>Or for option 2: order-service -> GET account-service/account/user-id/{userId}</p>&#xA;&#xA;<p>order-service gets the userId from the sent token, calls the account-service with it's own token, then creates the order with the retrieved account.</p>&#xA;&#xA;<p>I'm really not sure which option is best to use. One better separates information but then requires two Feign Clients. However the other doesn't require the 2 clients and it becomes easier to block off end certain endpoints to outside clients, however it requires extra endpoints to be created and almost every service to go digging into the Authentication object.</p>&#xA;&#xA;<p>What are all your thoughts? Has anyone implemented their system in one way or another way entirely? Or perhaps I've got the completely wrong idea.</p>&#xA;&#xA;<p>Any help is appreciated.</p>&#xA;"
45533748,version management in microservices,2017-08-06 15:47:08,<version-control><cloud><microservices><service-discovery>,2,1982,0,1.0,0,"<p>Suppose that I have a UserService in my <strong>Microservice Architecture</strong> deployed on the cloud. There is a <strong>Service Discovery</strong> for routing the requests to different host of UserService. </p>&#xA;&#xA;<p>If I have two different versions of UserService. Lets say <em>user-service-1.0</em> and <em>user-service-2.0</em> and part of clients should still use older version, then how this can be managed in Microservice Architecture. </p>&#xA;"
45579511,A/B testing. Routing Clients in a gateway API,2017-08-08 23:34:40,<microservices><ab-testing><api-gateway><canary-deployment>,3,760,0,0.0,0,"<p>I am working on a new project that will be based on microservices. It's an internal app and only about 10 microservices. We will be using a gateway API for authentication and possibly some microservice aggregation. (Probably Netflix zuul with Spring Boot)</p>&#xA;&#xA;<p>What I'm not clear on is how we do the routing for A/B testing and Canary testing. Lets assume I have 100 clients and we want to A/B test a new version of a microservice. The client app needs no changes, it's just internal changes to the function that the microservice provides.</p>&#xA;&#xA;<p>I understand we would stand up a new microservice which is (say) v2. What I'm puzzled on is how do I direct (say) clients 1-10 to the new version. We need to be able to configure this centrally and not change anything on the client.</p>&#xA;&#xA;<p>We know their mac addresses (as well as other identifying attributes) and can insert any kind of header we want to identify their messages.</p>&#xA;&#xA;<p>So how would I direct these to v2 of the API for the A/B test or Canary deployment?</p>&#xA;"
45426194,Message format/specification for distributed REST services?,2017-07-31 22:23:26,<rest><message-queue><microservices><messages>,1,28,3,0.0,0,"<p>I have a growing number of REST services that talk to each other with JSON. Right now, the communication is direct, but it's possible that a broker might process and distribute later on. </p>&#xA;&#xA;<p>This is the only one I've found so far:&#xA;<a href=""https://github.com/cjus/umf/blob/master/umf.md"" rel=""nofollow noreferrer"">https://github.com/cjus/umf/blob/master/umf.md</a></p>&#xA;&#xA;<p>Are there others that would be better suited? Thanks.</p>&#xA;"
45325062,Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams?,2017-07-26 11:03:53,<jvm><microservices><datacontract><pact>,3,117,1,1.0,0,<p>Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams ?</p>&#xA;
45174699,jwt - Django-rest-framework-jwt authentication in microsevices,2017-07-18 18:42:36,<jwt><microservices>,1,163,3,0.0,0,"<p>I am newbie in JSON web token and micro services. I read in an articles that if i share the private, all services can verify user on their own. Then i tried to implement an application to practice.&#xA;Basically, I have two services A and B. A is used for authentication. Then, I tried implement a API that required authentication in service B. But when I used a token generated by authentication A in API, 401 status code and ""Invalid signature."" were returned. &#xA;So anyone can explain to me what I did wrong?</p>&#xA;"
51855075,Django microservices within Docker,2018-08-15 08:08:19,<django><docker><nginx><docker-compose><microservices>,3,44,0,0.0,0,"<p>I have the following <code>docker-compose.yml</code>:</p>&#xA;&#xA;<pre><code>version: '3.6'&#xA;&#xA;services:&#xA;  db:&#xA;    image: postgres:10.4&#xA;    volumes:&#xA;      - postgres_data:/var/lib/postgresql/data/&#xA;  cache:&#xA;    image: redis:4.0.10&#xA;    volumes:&#xA;      - redis_data:/data&#xA;  web:&#xA;    build: .&#xA;    image: dockerdjangoexample&#xA;    command: bash -c ""gunicorn demosite.wsgi:application -b 0.0.0.0:8000""&#xA;    volumes:&#xA;      - .:/code&#xA;    depends_on:&#xA;      - db&#xA;      - cache&#xA;  nginx:&#xA;    image: nginx:1.15.2-alpine&#xA;    ports:&#xA;      - ""8000:8000""&#xA;    volumes:&#xA;      - ./docker-config/nginx:/etc/nginx/conf.d&#xA;    depends_on:&#xA;      - web&#xA;&#xA;volumes:&#xA;  postgres_data:&#xA;  redis_data:&#xA;</code></pre>&#xA;&#xA;<p>The <code>Dockerfile</code> is:</p>&#xA;&#xA;<pre><code>FROM python:3.6.5&#xA;&#xA;ENV PYTHONDONTWRITEBYTECODE 1&#xA;ENV PYTHONUNBUFFERED 1&#xA;&#xA;WORKDIR /code&#xA;COPY . /code/&#xA;&#xA;RUN pip install --upgrade pip&#xA;RUN pip install pipenv&#xA;RUN pipenv install --deploy --system --skip-lock --dev&#xA;</code></pre>&#xA;&#xA;<p>The <code>Nginx</code> config file is:</p>&#xA;&#xA;<pre><code>upstream web {&#xA;  ip_hash;&#xA;  server web:8000;&#xA;}&#xA;&#xA;server {&#xA;  location / {&#xA;         proxy_pass http://web/;&#xA;  }&#xA;  listen 8000;&#xA;  server_name localhost;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This all works perfectly. What im trying to figure out now is how I can add a second <code>Django</code> app into the mix so I can create a microservice environment.</p>&#xA;&#xA;<p>For example, the existing web app from above would be an API that handles user registration / sign in etc. I would like to add another <code>Django</code> API into the mix that would do something else and would also use its own database.</p>&#xA;&#xA;<p>If this were to theoretically ever be put into a production environment, then the first API would be used through urls starting with <code>www.demosite.com/api/users</code> and the second API could be used through urls starting with <code>www.demosite.com/api/widgets</code>.</p>&#xA;&#xA;<p>Im not sure how to accomplish this from a <code>Docker</code> and <code>Nginx</code> perspective.</p>&#xA;&#xA;<p>Also, if im doing anything completely wrong so far, please correct me as I am new to this.</p>&#xA;"
51781316,Unable to login through gateway jhipster 4.9.0 microservice architechture,2018-08-10 07:33:01,<java><microservices><jhipster><jhipster-registry>,1,33,4,0.0,0,"<p>I've generated microservice application through jHipster 4.9.0.&#xA;My UAA server is running on port 9999 and gateway on 8080 these microservices are connected through jHipster registry. When I try to log in through the gateway <strong>it's giving me 404 for /auth/login</strong> although gateway has this endpoint in AuthResource.java file.&#xA;I have just generated these microservices and trying to log in but unfortunately, I'm unable to log in. Please guide me if there is something wrong I do not want to use the latest version of jHipster. JHipster registry version is 3.3. war download from github. It would be great if you can help me in any way. Thanks in advance. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/LzYgn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LzYgn.png"" alt=""enter image description here""></a></p>&#xA;"
51911797,How to manage microservices that are live,2018-08-18 19:12:13,<java><spring><spring-boot><microservices>,3,68,5,0.0,0,"<p>I have been testing out microservices lately using springboot to create microservice projects. The more i understand about the setup the more questions i am confronted with. </p>&#xA;&#xA;<ol>&#xA;<li>How are all the microservices that are running, managed? How do developers manage, deploy or update microservices via a central location?</li>&#xA;<li>When deploying multiple instances of a microservice, do you leave the port to be decided during runtime, or should it be predefined?</li>&#xA;</ol>&#xA;&#xA;<p>I am sure there will be much more questions popping up later.&#xA;Links used:</p>&#xA;&#xA;<ul>&#xA;<li><a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started</a></li>&#xA;<li><a href=""https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/"" rel=""nofollow noreferrer"">https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/</a></li>&#xA;</ul>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
51419192,Using microservices architecture in spring,2018-07-19 09:36:33,<spring-boot><microservices><spring-cloud-netflix>,3,47,3,0.0,0,"<p>I'm building a project which based on microservices architecture in spring boot.The project was divided multiple modules and I used maven dependency management.</p>&#xA;&#xA;<p>Now I want to use services from one module in other module. I have many spring applications. For example, I have 2 application which is named A and B. I want to use classes from A in B and classes of B in A. In this case I used maven dependencies but it is not completely way to using services in one another because I faced with circular dependency. </p>&#xA;&#xA;<p>What should do to use for solve this problem?</p>&#xA;"
51463258,Call some different restful services from front-end,2018-07-22 08:20:05,<domain-driven-design><microservices><dbcontext><restful-architecture>,1,56,3,0.0,0,"<p>Imagine I have an angular project as a front-end which communicates with some other projects which are restful services.</p>&#xA;&#xA;<p>In some pages I need to fetch some data from different restful services, &#xA;Is that okay to request any restful service individually in angular?&#xA;Or call one restful service which itself call other restful services in back-end?</p>&#xA;&#xA;<p>Or I have to call one restful service but add other entities to this DbContext which I need here just to query?</p>&#xA;"
51515839,Nodejs not able to connect to mongodb on cloud shell,2018-07-25 09:47:36,<node.js><mongodb><google-app-engine><google-cloud-platform><microservices>,3,163,7,0.0,0,"<p>My MongoDB server is hosted on google-cloud VM. I wish to create App Engine microservice. to test connectivity,  </p>&#xA;&#xA;<p>my server.js looks like </p>&#xA;&#xA;<pre><code>const MongoClient = require('mongodb').MongoClient;&#xA;const test = require('assert');&#xA;// Connection url&#xA;const url = 'mongodb://testmongodb:27017';&#xA;// Database Name&#xA;const dbName = 'test';&#xA;// Connect using MongoClient&#xA;MongoClient.connect(url, { useNewUrlParser: true },function(err, client) {&#xA;if(err){console.log(err)}&#xA;else {console.log(""Connected successfully"")}&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>it works perfectly if i connect via another vm. But does not work when trying to execute (npm start) the same code via <strong>Google Cloud Shell</strong>. I get the error </p>&#xA;&#xA;<pre><code>{ MongoNetworkError: failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]&#xA;    at Pool.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/topologies/server.js:562:11)&#xA;    at emitOne (events.js:116:13)&#xA;    at Pool.emit (events.js:211:7)&#xA;    at Connection.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/pool.js:316:12)&#xA;    at Object.onceWrapper (events.js:317:30)&#xA;    at emitTwo (events.js:126:13)&#xA;    at Connection.emit (events.js:214:7)&#xA;    at Socket.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/connection.js:245:50)&#xA;    at Object.onceWrapper (events.js:315:30)&#xA;    at emitOne (events.js:116:13)&#xA;  name: 'MongoNetworkError',&#xA;  message: 'failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]',&#xA;  errorLabels: [ 'TransientTransactionError' ],&#xA;  [Symbol(mongoErrorContextSymbol)]: {} }&#xA;</code></pre>&#xA;&#xA;<p>i get exactly the same error when deployed the service [gcloud app deploy]</p>&#xA;&#xA;<p>please help. </p>&#xA;"
40733857,Using Nginx as micro service API gateway,2016-11-22 04:37:08,<node.js><nginx><docker><kubernetes><microservices>,2,674,7,0.0,0,"<p>We are splitting our monolith API into micro services.</p>&#xA;&#xA;<p>We do not need rate-limiting, auth, caching or any other gateway like abilities. </p>&#xA;&#xA;<p>Would it be a valid approach to use very simple stateless Nginx containers that route to the underlying services?</p>&#xA;"
46571540,Java Spring-boot micro-services Exception handling,2017-10-04 18:14:18,<java><spring-mvc><spring-boot><microservices><netflix>,1,1080,1,0.0,0,"<p>Java exception handling is sub divided in to Errors, checked exceptions and unchecked exceptions. This question is about exceptions.</p>&#xA;&#xA;<p>Normal Java exception handling is to extend the Exception class for checked exceptions and handle those as you need by considering exception hierarchy.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionA extends Exception {}&#xA;&#xA;public class RunClass {&#xA;&#xA;    public static void main() {&#xA;        try {&#xA;            RunClass runClass = new RunClass();&#xA;            runClass.doSomething();&#xA;        } catch(ExceptionA eA) {&#xA;            // Do ExceptionA related resolutions.&#xA;        } catch(Exception e) {&#xA;            // Do Exception related resolutions.&#xA;        }&#xA;    }&#xA;&#xA;    public doSomething() throws ExceptionA {&#xA;        throw new ExceptionA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I saw major Spring books and even on the Internet tutorials mentioned with Spring-boot and in the context of micro-services always extend from RuntimeException class even with the @ControllerAdvice.</p>&#xA;&#xA;<p>This is clear violation of Java exception handling basics. But still there is an argument saying that, it is extended with RuntimeException because of this exception is handled by @ExceptionHandler method and it is generated and handled both in runtime.</p>&#xA;&#xA;<p>Still, because of this extension from RuntimeException makes compile time exception handling trail not visible and makes hard to trace back how exception is thrown up. Due to these reasons, I still believe, follow the basic Java checked and unchecked exception handling concept still with @ExceptionHandler method.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionRA extends RuntimeException {}&#xA;&#xA;@ContollerAdvice&#xA;public class ExceptionHandler {&#xA;&#xA;    @ExceptionHandler(ExceptionRA.class)&#xA;    public String handleException (Exception exception, Model model) {&#xA;        return ""exception"";&#xA;    }&#xA;&#xA;}&#xA;&#xA;@Controller&#xA;public class RunClass {&#xA;&#xA;    @RequestMapping(""/url1"")&#xA;    public doSomething() {&#xA;        throw new ExceptionRA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Should I follow the extending RuntimeException for all exception scenarios with @ExcpetionHadler or follow the basic Java checked and unchecked mechanism with @ExceptionHaldler? Ideas, suggestions and corrections are welcome.</p>&#xA;"
46660853,How to run micro services using docker,2017-10-10 07:25:37,<docker><spring-boot><cassandra><docker-compose><microservices>,3,216,1,1.0,0,"<p>Am newbie to Spring boot. I need to create micro services and need to run by docker. I have attached my project structure here. Problem which is every time i need to up the micro services manually. For example am having 4 micro services and i just up this services manually. But all micro services should be started itself when deploying into docker. How to achieve this. <a href=""https://i.stack.imgur.com/QZFMw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QZFMw.png"" alt=""Project Structure""></a></p>&#xA;&#xA;<p>Also am using Cassandra database.</p>&#xA;"
46586380,Securing micro-service spring cloud security Oauth2,2017-10-05 13:05:29,<java><spring><security><spring-boot><microservices>,1,327,3,1.0,0,"<p>I am using Spring cloud security and Oauth2 to secure my micro- service. Now the Pom is as follows:</p>&#xA;&#xA;<p>&#xA;http://maven.apache.org/xsd/maven-4.0.0.xsd"">&#xA;    4.0.0</p>&#xA;&#xA;<pre><code>&lt;groupId&gt;com.oreilly.cloud&lt;/groupId&gt;&#xA;&lt;artifactId&gt;spring-microservices-oauth-server&lt;/artifactId&gt;&#xA;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;name&gt;spring-microservices-oauth-server&lt;/name&gt;&#xA;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;&#xA;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;    &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;spring-cloud.version&gt;Dalston.SR3&lt;/spring-cloud.version&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.hsqldb&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;hsqldb&lt;/artifactId&gt;&#xA;        &lt;scope&gt;runtime&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;dependencyManagement&gt;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;            &lt;type&gt;pom&lt;/type&gt;&#xA;            &lt;scope&gt;import&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&lt;/dependencyManagement&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;&#xA;&lt;repositories&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-snapshots&lt;/id&gt;&#xA;        &lt;name&gt;Spring Snapshots&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;true&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;        &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;false&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;&lt;/repositories&gt;&#xA;</code></pre>&#xA;&#xA;<p></p>&#xA;&#xA;<p>The Spring-boot main class is as below:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.security.access.prepost.PreAuthorize;&#xA;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;@SpringBootApplication&#xA;@EnableAuthorizationServer&#xA;@EnableResourceServer&#xA;@RestController&#xA;@EnableGlobalMethodSecurity(prePostEnabled=true)&#xA;public class SpringMicroservicesOauthServerApplication {&#xA;&#xA;    @RequestMapping(""/resource/endpoint"")&#xA;    @PreAuthorize(""hasRole('ADMIN')"")&#xA;    public String endpoint(){&#xA;        return ""This message is protected by the resource server."";&#xA;    }&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(SpringMicroservicesOauthServerApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The authorization server configuration is as follows:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;&#xA;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;&#xA;&#xA;@Configuration&#xA;public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;    @Autowired&#xA;    private AuthenticationManager authManager;&#xA;&#xA;    @Override&#xA;    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;        endpoints.authenticationManager(authManager);&#xA;    }&#xA;&#xA;    @Override&#xA;    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;        clients.inMemory().withClient(""webapp"").secret(""websecret"").authorizedGrantTypes(""password"")&#xA;                .scopes(""read,write,trust"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Note the Authentication manager is auto wired into the Authorization config</strong> </p>&#xA;&#xA;<p>In the below class The Authentication Manager is configured and returned as abean so that it can be autowired to the above class:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.context.annotation.Bean;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;&#xA;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;&#xA;&#xA;@Configuration&#xA;public class WebSecurityConfig extends WebSecurityConfigurerAdapter {&#xA;&#xA;    @Bean&#xA;    public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;        return super.authenticationManagerBean();&#xA;    }&#xA;&#xA;    @Override&#xA;    protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;        auth.inMemoryAuthentication().withUser(""user1"").password(""password1"").roles(""USER"").and().withUser(""admin"")&#xA;                .password(""password2"").roles(""ADMIN"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now the application.properties is as below:</p>&#xA;&#xA;<pre><code>server.port=9090&#xA;</code></pre>&#xA;&#xA;<p>Now i run the Spring boot application as below:</p>&#xA;&#xA;<p>mvn spring-boot:run</p>&#xA;&#xA;<p>The application starts successfully and is ready to accept request on port 9090 on localhost</p>&#xA;&#xA;<p>Now using postman i am sending a post request to get the access_token. A little background is that the Aoauth2 flow being used here is the password grant. So in the AuthorizationServerConfig class above i have defined a password grant flow and registered a simple web app with client name and secret. As can be seen the client configuration is in memory.</p>&#xA;&#xA;<p>The post man request to get access token from authorization server is as follows: Its post request, with Basic auth header header having the &#xA;username as webapp and password as websecret.</p>&#xA;&#xA;<p><a href=""http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1"" rel=""nofollow noreferrer"">http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1</a></p>&#xA;&#xA;<p>This request returns successfully with a access token json as follows:</p>&#xA;&#xA;<pre><code>{&#xA;    ""access_token"": ""2d632e54-17c3-41f7-af3b-935ca3022d78"",&#xA;    ""token_type"": ""bearer"",&#xA;    ""expires_in"": 43199,&#xA;    ""scope"": ""read,write,trust""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now when i try to access the /resourse/endpoint with the above access token as follows:</p>&#xA;&#xA;<p><a href=""http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78"" rel=""nofollow noreferrer"">http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78</a></p>&#xA;&#xA;<p>Rather than returning the text which is returned from the service /resourse/endpoint it returns the login page as below:</p>&#xA;&#xA;<pre><code>&lt;html&gt;&#xA;    &lt;head&gt;&#xA;        &lt;title&gt;Login Page&lt;/title&gt;&#xA;    &lt;/head&gt;&#xA;    &lt;body onload='document.f.username.focus();'&gt;&#xA;        &lt;h3&gt;Login with Username and Password&lt;/h3&gt;&#xA;        &lt;form name='f' action='/login' method='POST'&gt;&#xA;            &lt;table&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;User:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='text' name='username' value=''&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;Password:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='password' name='password'/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td colspan='2'&gt;&#xA;                        &lt;input name=""submit"" type=""submit"" value=""Login""/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;input name=""_csrf"" type=""hidden"" value=""8dbc1c38-6f89-43c5-a8f8-797c920722a1"" /&gt;&#xA;            &lt;/table&gt;&#xA;        &lt;/form&gt;&#xA;    &lt;/body&gt;&#xA;&lt;/html&gt;&#xA;</code></pre>&#xA;&#xA;<p>Can anyone please help what i am missing here?????. </p>&#xA;&#xA;<p><strong>NOTE</strong> I have both authorization server and resourse server configured in same application. this is a POC so i am trying out the Spring-cloud security, later i will separate the two ...but thats for later. </p>&#xA;"
46575898,What the hell is microservice?,2017-10-04 23:59:02,<architecture><microservices>,2,913,3,0.0,0,"<p>Microservice for this, microservice for that, but explain to a simple person what is microservice? I'm a simple programmer with a little almost none theoretical background. But I don't need a term microservice to do what I do. Could someone explain me in easy-peasant words what microservice is? Amazon AWS = microservice?</p>&#xA;&#xA;<p>I read this: <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Microservices</a> but apparently I'm too stupid to understand what is this.</p>&#xA;"
46522304,File upload spring cloud feign client,2017-10-02 08:50:39,<java><microservices><spring-cloud><multipart><feign>,2,1140,5,2.0,0,"<p>When make a post request from one microservice to another using feign client of spring cloud netflix, I get the following error in Postman :</p>&#xA;&#xA;<pre><code>{&#xA;""timestamp"": 1506933777413,&#xA;""status"": 500,&#xA;""error"": ""Internal Server Error"",&#xA;""exception"": ""feign.codec.EncodeException"",&#xA;""message"": ""Could not write JSON: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS); nested exception is com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile[\""inputStream\""]-&gt;java.io.FileInputStream[\""fd\""])"",&#xA;""path"": ""/attachments""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And my eclipse console shows the following exception :</p>&#xA;&#xA;<blockquote>&#xA;  <p>com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.io.FileDescriptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile[""inputStream""]->java.io.FileInputStream[""fd""])&#xA;      at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:284) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.SerializerProvider.mappingException(SerializerProvider.java:1110) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.SerializerProvider.reportMappingProblem(SerializerProvider.java:1135) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:69) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:32) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:704) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:689) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:704) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:689) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:292) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1429) ~[jackson-databind-2.8.9.jar:2.8.9]&#xA;      at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:951) ~[jackson-databind-2.8.9.jar:2.8.9]</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>UPDATE 1</strong></p>&#xA;&#xA;<p>This is my  feign interface :</p>&#xA;&#xA;<pre><code>@FeignClient(name=""attachment-service"", fallback=AttachmentHystrixFallback.class)&#xA;public interface AttachmentFeignClient {&#xA;&#xA;@RequestMapping(""upload"")&#xA;void upload(@RequestPart(name=""file"") MultipartFile file, @RequestParam(name=""attachableId"") Long attachableId, &#xA;        @RequestParam(name=""className"") String className, @RequestParam(name=""appName"") String appName);&#xA;</code></pre>&#xA;&#xA;<p>And this is the main microservice controller : </p>&#xA;&#xA;<pre><code>@RestController&#xA;public class AttachmentController implements Serializable {&#xA;&#xA;/**&#xA; * &#xA; */&#xA;private static final long serialVersionUID = -4431842080646836475L;&#xA;&#xA;@Autowired&#xA;AttachmentService attachmentService;&#xA;&#xA;@RequestMapping(value = ""attachments"", method = RequestMethod.POST, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)&#xA;public void upload(@RequestPart MultipartFile file, @RequestParam Long attachableId, @RequestParam String className, @RequestParam String appName) throws Exception {&#xA;    attachmentService.uploadFile(file, attachableId, className, appName);&#xA;}&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm certainly missing some kind of serializer here<br>&#xA;Any suggestion would be appreciated ! <br>&#xA;Thanks</p>&#xA;"
45789168,What is the difference between an API and Microservice?,2017-08-21 04:08:14,<api><microservices>,2,1331,0,1.0,0,"<p>I create my API rest with Django, but I don't understand how convert an API to micro services, I don't understand the real difference between these.&#xA;I see an API like a micro service, but I don't know convert an entire API in micro service, I need create micro web servers? </p>&#xA;&#xA;<p>Please, I can't understand a micro services, and I need understand this.</p>&#xA;"
45729153,Spring Sleuth Logback Integration logs not displaying the service name,2017-08-17 07:35:57,<logstash><logback><microservices><spring-cloud-sleuth>,1,741,1,1.0,0,"<p>In my microservice i have added spring -sleuth 1.2.1 and i have received the logs as i expected, which is shown in below</p>&#xA;&#xA;<p>2017-08-16 09:58:51.864  INFO [microServiceName,9434118b965d573e,9434118b965d573e,true] 1328 --- [io-8081-exec-10] com.cibc.icap.MyController       : Eligible for Vote</p>&#xA;&#xA;<p>As per my requirement I need to pass the logs from my application to logstash server so i have created logback.xml and added dependency logstash-logback-encoder-4.5.1 and added the appender in logback.xml net.logstash.logback.appender.LogstashTcpSocketAppender my logback.xml looks like&#xA;now the logs are passing from my application to logstash but the problem is in the log I am not getting my microservice name as expected, The log looks like below after adding the logback.xml </p>&#xA;&#xA;<p>2017-08-17 12:35:27.781  INFO [bootstrap,0e26cf339a6e69bc,0e26cf339a6e69bc,true] 4884 --- [nio-8081-exec-7] com.cibc.icap.AssessmentController</p>&#xA;&#xA;<p>link for my logback.xml </p>&#xA;"
45762128,Microservice architectural clarification,2017-08-18 17:36:48,<c#><microservices>,1,75,3,0.0,0,"<p>I have a microservice architectured application. Where i have a CompanyService, an OrderService and a TransactionSevice. A user logs in and he can load all orders for his company. So the order has a CompanyId. Then it loads all Transactions for that order, so the transaction has an OrderId. I am going through some security thoughts. How can i make sure that the user only loads or saves transactions for the orders that belong to his company. I mean the TransactionService should not need to know about the Company (CompanyId). Is it something i should check just before saving? Eg check that the orderid belongs to the company or is there some other pattern?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50790960,Seperation of Concerns - How to separate GET/PUT/PATCH/POST/DELETE/ETC into one Microservice that gets its models and DTOs externally,2018-06-11 05:26:36,<c#><rest><.net-core><microservices><separation-of-concerns>,1,56,3,0.0,0,"<p>Lets say you have a typical C# .netcore webapi you are wanting to use in a microservices architecture environment. It uses entity framework connects to a SQL database, has models and DTOs.</p>&#xA;&#xA;<p>If you want to separate the 'restfulness', the actions of actually responding to the individual GET/PUT/PATCH/POST/DELETE/ETC methods, from the data models (and into microservices) what approach would you take? </p>&#xA;&#xA;<p>IE instead of having to create 100 microservices that each expose the same exact RESTful functionality within the APIs but each have their own specific data models and DTOs, id want to create 1 API that exposes restful GET/PUT/PATCH/POST/DELETE/ETC and separate it from static models, dtos and entitybuilder configurations.  So i'd have 100 microservices concerned with passing data to the 1 REST microservice to get whatever job I need to do done in a dynamic fashion.</p>&#xA;&#xA;<p>I am not super experienced with object oriented programming methods and I thought maybe it would be possible to have my CRUD microservice that my child microservice talks to (through an API gateway or some other method that I haven't worked out yet) pass a set of models, DTOs and entity framework entitybuilder parameters into the CRUD microservices Program.cs's Main method? </p>&#xA;&#xA;<p>I am on the right path here? </p>&#xA;&#xA;<p>Thank you in advance for any advise or helpful examples!!!</p>&#xA;"
50810342,Spring Java Microservice war size is too large,2018-06-12 06:16:18,<java><spring><microservices>,1,59,3,0.0,0,"<p>Every time when we release on our production server, we need to copy 3-4 war(microservice war) file of size approx 150-200 MB. Even though we simply change a small thing in our code, but all maven dependency are combined to the war so the file size is very big.  </p>&#xA;&#xA;<p>Is there any way to reduce the size of war or how can we simply deploy our code not all the dependency with them?</p>&#xA;"
50814965,Getting connection timed out error in Java microservice,2018-06-12 10:29:31,<spring><spring-boot><postman><microservices>,2,119,5,1.0,0,"<p>I have built a microservice using Java 8 and SpringBoot 2. From this microservice, I'm trying to consume another REST API service. However, I'm getting the following error on Chrome</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: The underlying HTTP client completed&#xA;  without emitting a response.</p>&#xA;  &#xA;  <p>2018-06-12 15:21:29.300 ERROR 17996 --- [ctor-http-nio-3]&#xA;  .a.w.r.e.DefaultErrorWebExceptionHandler : Failed to handle request&#xA;  [GET <a href=""http://localhost:8080/category/search]"" rel=""nofollow noreferrer"">http://localhost:8080/category/search]</a>&#xA;  io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection&#xA;  timed out: no further information: test.usdemo.xyz.com/92.54.41.24:443&#xA;                  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.8.0_171]&#xA;                  at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)&#xA;  ~[na:1.8.0_171]&#xA;                  at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:325)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)&#xA;  ~[netty-common-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_171] Caused by: java.net.ConnectException: Connection timed&#xA;  out: no further information&#xA;                  ... 10 common frames omitted</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm able to consume the same service successfully using PostMan but not through my microservice.</p>&#xA;&#xA;<p>Please assist to advise on this.</p>&#xA;"
27489124,Connecting two Node/Express apps with streaming JSON,2014-12-15 16:58:01,<node.js><rest><stream><microservices>,1,311,1,2.0,1,"<p>I currently have two apps running...</p>&#xA;&#xA;<p>One is my REST API layer that provides a number of services to the frontend. &#xA;The other is a 'translation app', it can be fed a JSON object (over http POST call) , perform some data translation and mappings on that object and return it to the REST layer </p>&#xA;&#xA;<p>My situation is I want to do this for a large number of objects. The flow i want is: </p>&#xA;&#xA;<p><strong><em>User requests 100,000 objects in a specific format -> REST layer retrieves that from the database -> passes each JSON data object to&#xA;translation service to perform formatting -> pass each one back to the&#xA; REST layer -> REST layer returns new objects to the user.</em></strong></p>&#xA;&#xA;<p>What I don't want to do is call tranlate.example.com/translate on 100,000 different calls, or pass megabytes of data through 1 single huge POST request. </p>&#xA;&#xA;<p>So the obvious answer is streaming data to the translate app, and then streaming data back. </p>&#xA;&#xA;<p>There seems to be a lot of solutions to stream data across apps: open a websocket (socket.io) , open a raw TCP connection between the two, or since the HTTP request and response data of Node is actually a stream I could utilize that then emit a JSON object when its successfully translated</p>&#xA;&#xA;<p>My question is Is there a best practice here to stream data between two apps? It seems I should use http(req, res) stream and keep a long-lived connection open to preserve the 'REST' model. Any samples that could be provided would be great. </p>&#xA;"
27470721,How can I avoid duplication of business logic when batch processing?,2014-12-14 15:19:48,<java><batch-processing><spring-batch><microservices>,2,626,0,0.0,1,"<p>I have a web application dedicated to batch processing (batch service here on out, api driven) and I have the main web application that is dedicated to everything else. I've been struggling with making a decision on what the best way is to avoid duplication of business logic in the batch service. Both applications are clustered. The separation for batch processing has been okay for simple jobs, but I have more complex jobs where it would just cause chaos if the business logic were duplicated. Here's my use case for the purposes of this question.</p>&#xA;&#xA;<ol>&#xA;<li>Customer schedules a cron job for user updates.</li>&#xA;<li>Batch service is given a CSV file with 20,000 user records.</li>&#xA;<li>The batch service rips through the file performing validation on the records, basically a dry run.</li>&#xA;<li>The batch service will check the allowable change and error thresholds (percentages are counts)</li>&#xA;<li>If validation thresholds pass, the batch service will begin creating/updating users.</li>&#xA;<li>When users are created or updated, there are a number of modules/features that need to know about these events.</li>&#xA;<li>Job progress is tracked and customer can view progress, logs, and status of job.</li>&#xA;</ol>&#xA;&#xA;<p>Here are a few solutions I have been thinking about:</p>&#xA;&#xA;<ul>&#xA;<li>Jar up the business logic and share it across the two applications. This wouldn't necessarily be easy because the main application is a Grails application and it's got GORM littered throughout.</li>&#xA;<li>Have the batch service hit APIs on the main application for the create and updates and possibly the more complex validation scenarios. Worried about the toll this would take on tomcat, but calls would be going through the load balancer so they would be distributed.</li>&#xA;<li>Have the batch service hit APIs on the main application for validation, then queue create/update requests and let the main application retrieve them. Same as above, queue would help reduce http calls. Also would need a queue to report status back to batch service.</li>&#xA;<li>Duplicate some logic by having batch service do it's own validation and inserts/updates, but then fire a user created event or user updated event so modules/features in the main app can deal with the changes.</li>&#xA;<li>Embed the batch processing service into the main application</li>&#xA;</ul>&#xA;&#xA;<p>Other details:</p>&#xA;&#xA;<ul>&#xA;<li>The batch service and web application are both clustered</li>&#xA;<li>Both are running on AWS, so I have tools like SQS and SNS easily accessible</li>&#xA;<li>Java 1.7 applications</li>&#xA;<li>Tomcat containers</li>&#xA;<li>Main application is Grails</li>&#xA;<li>Batch service uses Spring Batch and Quartz at it's core</li>&#xA;</ul>&#xA;&#xA;<p>So my question is what are accepted ways to avoid duplication of business logic based on the details above? Can/Should the architecture be changed to better accommodate this?</p>&#xA;&#xA;<p>Another idea to consider is what would this look like and a ""microservices"" architecture. That word has been tossed around a number of times in the office and we have been considering the idea of breaking up the main web application into services. So for example, we may end up with a service for user management.</p>&#xA;"
34180115,How to register service in Consul without address declaration,2015-12-09 13:33:02,<java><microservices><service-discovery><consul>,1,1620,2,0.0,1,"<p>Using Consul, I want a service to register itself with the Consul Agent, using the HTTP endpoint <code>/v1/agent/service/register</code>. The only problem is that the service may bind to different IP addresses (1st instance 10.0.0.1, 2nd 10.0.0.2, etc) and I want Consul to set the address automatically basing on the IP address of the request.</p>&#xA;&#xA;<p>For example,</p>&#xA;&#xA;<p>""Service instance 1 (10.0.0.1)"" sends <code>{name:'svs', id:'svs-01'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-01', Address: 10.0.0.1}</code></p>&#xA;&#xA;<p>""Service instance 2 (10.0.0.2)"" sends <code>{name:'svs', id:'svs-02'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-02', Address: 10.0.0.2}</code></p>&#xA;&#xA;<p>According to <a href=""https://consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow"" title=""Consul Agent Service Documentation"">Consul Agent Service Documentation</a> if the Address field is missing in service register query, the Address will default to that of the agent if not provided. But it is not what I need.</p>&#xA;&#xA;<p>I've tried to detect service's ip address at runtime but it may have several network interfaces and it's hard to distinguish them.</p>&#xA;"
30496218,How to avoid Undertow Connection RESET in apache benchmark test?,2015-05-28 02:27:41,<nio><microservices><undertow><sysctl>,3,587,2,0.0,1,"<h2>Using apache benchmarking 100K request 20K concurrent users:</h2>&#xA;&#xA;<pre><code>   $ ab -n 100000 -c 20000 http://localhost:8080/mrs/ping&#xA;    Completed 10000 requests&#xA;    Completed 20000 requests&#xA;    Completed 30000 requests&#xA;    Completed 40000 requests&#xA;    Completed 50000 requests&#xA;    Completed 60000 requests&#xA;    Completed 70000 requests&#xA;    Completed 80000 requests&#xA;    Completed 90000 requests&#xA;    apr_socket_recv: Connection reset by peer (104)  &lt;&lt;&lt; HOW to overcome??&#xA;</code></pre>&#xA;&#xA;<h2>Below is the Undertow (version 1.2.6 + xnio-api 3.3.1) PingServer:</h2>&#xA;&#xA;<pre><code>public class UndertowPingServer {&#xA;&#xA;    private static Logger log = Logger.getLogger(UndertowPingServer.class);&#xA;&#xA;    public static void main(String[] args) throws ServletException {&#xA;&#xA;        PathHandler path = Handlers.path()&#xA;                .addPrefixPath(""/mrs/ping"", new HttpHandler() {&#xA;                    @Override&#xA;                    public void handleRequest(HttpServerExchange exchange) throws Exception {&#xA;                        exchange.getResponseHeaders().put(&#xA;                                Headers.CONTENT_TYPE, ""text/plain"");&#xA;                        exchange.getResponseSender().send(""Server Time:"" + new Date().toString() + ""\n\n"");&#xA;                    }&#xA;                });&#xA;Undertow.Builder builder = Undertow.builder()&#xA;   .setHandler(path)&#xA;   .addHttpListener(8080, ""0.0.0.0"")&#xA;   .setBufferSize(1024 * 16)&#xA;//this seems slightly faster in some configurations&#xA;  .setIoThreads(Runtime.getRuntime().availableProcessors() * 2) &#xA;                    .setSocketOption(Options.BACKLOG, 500000)&#xA;                    .setWorkerThreads(2000)&#xA;//don't send a keep-alive header for HTTP/1.1 requests, as it is not required&#xA;                    .setServerOption(UndertowOptions.ALWAYS_SET_KEEP_ALIVE, false); &#xA;            Undertow server = builder.build();&#xA;            server.start();&#xA;            log.info(""micro-service running!"");&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>All the needed linux kernel sockets and thread settings via sysctl are already done. That is why it can do the first 90K request with 20k users without issue.</p>&#xA;"
31295897,Should I use FrisbyJS for my REST API testing?,2015-07-08 14:37:41,<microservices><frisby.js>,1,328,0,2.0,1,"<p>I am developing a complicated project with microservice architecture (only provides Rest API). So I need to make sure that the system works stably in development, staging, and production after having a deployment.</p>&#xA;&#xA;<p>I think that a testing framework as Frisby can help me prevent issues. Do you have any suggestion for my case?</p>&#xA;&#xA;<p>Thank you in advance.</p>&#xA;"
31404820,Service locator - why not use DNS?,2015-07-14 11:04:07,<dns><soa><microservices>,3,144,1,0.0,1,"<p>There are a lot of applications that can take role of Service Locator in distributed environment AKA SOA. For example, Zookeeper and Consul. Why not use DNS instead?</p>&#xA;&#xA;<ul>&#xA;<li>Standard, well-known, stable</li>&#xA;<li>Distributed, fault-tolerant</li>&#xA;<li>Can assign multiple IPs to the same name for load balancing in homogeneous clusters</li>&#xA;<li>Can serve additional metadata</li>&#xA;</ul>&#xA;&#xA;<p>So... why not?</p>&#xA;"
26611387,"DDD: Can anyone explain the diffrences between DTO, Aggregate Root and Detached Entity?",2014-10-28 14:51:52,<java><jpa><domain-driven-design><microservices>,2,707,3,0.0,1,"<p>I'm a bit puzzled in figuring out the differences between these three. Presumed I have a Customer -> Address relation the (JPA) Detached Entity will have this as well (Eager Loading presumed). Where is the need to have an additional Aggregate Root? Where is the need to have a DTO? Is it all more or less the same?</p>&#xA;&#xA;<p>One of the reasons might be that the JPA compliant Entity has some info the client is simply not interested in, e.g. <code>@Entity</code>, <code>@Id</code>, <code>@OneToMany</code>.</p>&#xA;&#xA;<p>I can convert it easily to JSON/XML using JAX-RS/-WS and almost every client can deal with it, so where is the need for having it? Is it all almost the same or do I miss something important?</p>&#xA;"
35039565,Collate several micro-services into a single swagger 2.0 spec/collection,2016-01-27 14:07:00,<swagger><swagger-ui><microservices><swagger-2.0><akka-http>,1,732,0,1.0,1,"<p>I am developing microservices using akka-http (scala). At the moment, I couldn't find any direct integration of swagger into akka-http. Nevertheless, I am starting my microservices with swagger 2.0 specs.  </p>&#xA;&#xA;<p>Now one of the challenge is to show a consolidated API spec to the consuming applications. I don't want to share multiple specs to the consumers and hence want to aggregate multiple swagger specs into one single spec (if this can be done on the fly, it would be great). Also how would this work with swagger-ui?</p>&#xA;"
32945623,Load balancing in distributed system,2015-10-05 09:49:56,<soa><distributed><distributed-computing><microservices>,1,116,5,0.0,1,"<p>Given:</p>&#xA;&#xA;<ul>&#xA;<li>n producers and m consumers, n >> m</li>&#xA;<li>consumers make requests to producers for data</li>&#xA;<li>any producer can be used by only one consumer at a time i.e. consumer can work with multiple producers but producer must work with single consumer</li>&#xA;</ul>&#xA;&#xA;<p>Needed:</p>&#xA;&#xA;<ul>&#xA;<li>Consumers need to coordinate so every consumer can own subset of producers.</li>&#xA;<li>If consumer goes down, other consumers should take his producers.</li>&#xA;<li>Consumers should exchange producers to ensure equal load on consumers.</li>&#xA;</ul>&#xA;&#xA;<p>Question:</p>&#xA;&#xA;<p>Are there papers/algorithms/libraries for that case or should I invent another wheel?</p>&#xA;"
30915043,Setting up rabbitMQ on docker with python,2015-06-18 12:13:32,<python><docker><localhost><rabbitmq><microservices>,1,1325,0,1.0,1,"<p>I am fairly new to docker and I am learning about rabbitMQ. So far I have been able to run rabbitMQ, in the form of the python libary pika, on my ubuntu vm. This worked with no problems at all but I have now put it onto a small app in docker and does not work.</p>&#xA;&#xA;<p>The problem seems to be in the set up and it all ways fails this line of code:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>The Variables being imported:</p>&#xA;&#xA;<pre><code>USER = ""test""&#xA;PASS = ""testpass1""&#xA;HOST = ""dockerhost""&#xA;</code></pre>&#xA;&#xA;<p>The file:</p>&#xA;&#xA;<pre><code>import pika&#xA;from settings import USER, PASS, HOST&#xA;&#xA;def send(message):&#xA;&#xA;    message = str(message)&#xA;    print 'trying: credentials = pika.PlainCredentials(username=USER, password=PASS)'&#xA;    try:&#xA;        credentials = pika.PlainCredentials(username=USER, password=PASS)&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: credentials = pika.PlainCredentials(username=USER, password=PASS) \n' + str(Exception.message)&#xA;&#xA;    print 'trying: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials))'&#xA;    try:&#xA;        connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;            host=HOST, port=80, credentials=credentials))&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials)) \n' + str(Exception.message)&#xA;&#xA;    channel = connection.channel()&#xA;&#xA;    channel.queue_declare(queue='hello')&#xA;&#xA;    channel.basic_publish(exchange='',&#xA;                      routing_key='hello',&#xA;                      body=message)&#xA;    connection.close()&#xA;&#xA;    return ""Message Sent""&#xA;</code></pre>&#xA;&#xA;<p>Within this code it always fails on the line:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>And finally the Dockerfile:</p>&#xA;&#xA;<pre><code>FROM ubuntu&#xA;MAINTAINER Will Mayger&#xA;RUN echo ""deb http://archive.ubuntu.com/ubuntu/ $(lsb_release -sc) main universe"" &gt;&gt; /etc/apt/sources.list&#xA;RUN apt-get update&#xA;RUN apt-get install -y tar git curl nano wget dialog net-tools build-essential&#xA;RUN apt-get install -y python python-dev python-distribute python-pip&#xA;RUN git clone https://github.com/CanopyCloud/microservice-python&#xA;RUN pip install -r /microservice-python/requirements.txt&#xA;EXPOSE 80&#xA;WORKDIR /microservice-python/&#xA;CMD sudo rabbitmqctl add_user test testpass1&#xA;CMD sudo rabbitmqctl add_vhost myvhost&#xA;CMD sudo rabbitmqctl set_permissions -p myvhost test "".*"" "".*"" "".*""&#xA;CMD sudo rabbitmq-server&#xA;&#xA;CMD python /microservice-python/server.py&#xA;</code></pre>&#xA;&#xA;<p>For any additional information all the files are located on:&#xA;<a href=""https://github.com/CanopyCloud/microservice-python"" rel=""nofollow"">https://github.com/CanopyCloud/microservice-python</a></p>&#xA;"
33291874,"Microservices: Worker roles, APIs or both?",2015-10-22 22:32:19,<microservices>,1,976,1,0.0,1,"<p>I have seen mixed examples of Microservices implemented as worker roles processing requests off a queue and/or as APIs (REST). </p>&#xA;&#xA;<p>Supporting asynchronous scenarios, a queue can be utilized, with a simple dumb queue listener forwarding the request to a Microservice REST API, where as synchronous scenarios would  call the REST API directly. </p>&#xA;&#xA;<p>The term Microservice is vaguely defined I think; do people consider them APIs (e.g. RESTful services) or as any abstract service processing requests, however that request was provided ?</p>&#xA;"
33287495,Netflix OSS/ Spring cloud on Weblogic,2015-10-22 17:55:36,<oracle><weblogic><spring-cloud><microservices><netflix>,1,1177,3,0.0,1,"<p>We do currently have an infrastructure with Weblogic 11g, Java 6, Apache WL plugin and ZXTM. Our traffic flows as follows:</p>&#xA;&#xA;<pre><code>ZXTM &gt;&gt; Apache httpd (WL plugin) &gt;&gt; WL cluster &gt;&gt; Oracle DB (RAC)&#xA;</code></pre>&#xA;&#xA;<p>We want to start microservices and evaluating Netflix OSS/ Spring cloud. Are there any complexities having spring netflix cloud on Weblogic with the infrastructure explained above? Following are our findings.</p>&#xA;&#xA;<ol>&#xA;<li>Turbine needs Java 8, so we have to upgrade to Java 8.</li>&#xA;<li>WL 11g does not support Java 8, so WL needs be upgraded to 12.1.3.</li>&#xA;</ol>&#xA;&#xA;<p>And we are fine with above upgardes.</p>&#xA;&#xA;<ol>&#xA;<li>Along with WL upgrade, is orcale DB (currently 11g) upgrade required?</li>&#xA;<li>Any issues/ complexities with running Netflix cloud on Weblogic 12c?</li>&#xA;<li>Does WL 12c supports JDBC 4.1 and 4.2 and any dependency for Netflix OSS products on these JDBC versions?</li>&#xA;<li>How can Eureka and Ribbon be used along with WL cluster load balancing?</li>&#xA;<li>Is Apache WL plugin required anymore? at-least for session stikiness?</li>&#xA;</ol>&#xA;&#xA;<p>Appreciate if you could share your experience, thoughts.&#xA;(Doesn't matter if you do not answer all the queries above, please share what you know of :) )</p>&#xA;"
33335786,What is the best way for applications to communicate in micro-service architectures,2015-10-25 22:23:36,<python><json><xml-rpc><microservices><amp>,1,273,6,0.0,1,"<p>I have to design and implement a service delivery platform.  I have various services in my current design and all of those tools are using different technologies.  Some are erlang based concurrent map-reduce functions and some are simple bash scripts to aggregate some text files. </p>&#xA;&#xA;<p>I heared about <strong>XML/RPC</strong>, <strong>Protocol Buffer</strong>, <strong>message-pack</strong>, <strong>soup</strong> and <strong>AMQP</strong>.  currently I use <strong>JSON</strong>, but loading and dumping large json files are a bit time/memory consuming.  Is there any new or robust way to make a bridge between various technologies on HTTP infrastructure with wide range programming language support and well documentation?</p>&#xA;&#xA;<p>EDIT1: I also need to mention that i believe complexity is much more corrosive than latency problems or other connection related issues.  So the JSON replacement must not add complexity to design.  </p>&#xA;&#xA;<p>Thanks in advanced.</p>&#xA;"
32838312,Architecture for microservices,2015-09-29 07:37:32,<node.js><express><microservices>,2,2619,0,0.0,1,"<p>I've recently started to work with node.js and I have to build an architecture that should use multiple express.js services. Some of these services will have to be located on one server, anothers - on other server machines. I want to build a base service (like API Gateway), but I don't know what the proper way to communicate between this Gateway and microservices, or between two microservices.</p>&#xA;&#xA;<p>Currently I'm working with a solution based on this:</p>&#xA;&#xA;<pre><code># inside Gateway server I call another service:&#xA;http.get('http://127.0.0.1:5001/users', (service_res) -&gt;&#xA;  data = ''&#xA;  service_res.on 'data', (chunk) -&gt;&#xA;    data += chunk&#xA;&#xA;  service_res.on 'end', -&gt;&#xA;    # some logic on data&#xA;&#xA;).end() &#xA;</code></pre>&#xA;&#xA;<p>I have a strong feeling that this approach is not right. What the proper way to build communication logic between API Gateway and microservices?</p>&#xA;"
32831192,microservices and domain logic joins,2015-09-28 20:24:19,<join><architecture><microservices>,3,160,0,1.0,1,"<p>Microservices are deployed hosting their own database.</p>&#xA;&#xA;<p>What strategies do you employ when business requirements necessitate joins across data in multiple services?</p>&#xA;&#xA;<p>Example problem:  You are implementing a movie review site.  You have a movie microservice that holds the movie DB.  You also have a review microservice that manages reviews in its own separate DB.  Reviews are linked to movies via a GUID; but as these are implemented as separate data stores, not a key constraint.</p>&#xA;&#xA;<p>You would like to have available, accurate to the last minute, a report that tells you the total number of reviews for each review level grouped by the first letter of the movie having a review word count > 25 words.  You currently host 5 million reviews for 40,000 movies.</p>&#xA;&#xA;<p>E.G.   Reviews with more than 25 words:</p>&#xA;&#xA;<ul>&#xA;<li>A  [8457 ""1 star""] [16615 ""2 star""] [...</li>&#xA;<li>B  [98445 ""1 star""] [80210 ""2 star""] [...</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Having chosen a microservice architecture for your project, what strategies would you now employ to implement this feature? </p>&#xA;"
49176544,Hystrix and Turbine does not work with Spring boot 2 and Spring cloud Finchley.M8,2018-03-08 15:18:49,<spring-boot><microservices><spring-cloud><hystrix><turbine>,2,684,0,1.0,1,"<p>I tried turbine + hystrix  dashboard with Spring boot 2 and latest versions of Spring cloud, seems exist some problem and turbine could not get stream from reactive service. I just uploaded simple microservices to github</p>&#xA;&#xA;<p><a href=""https://github.com/armdev/reactive-spring-cloud"" rel=""nofollow noreferrer"">https://github.com/armdev/reactive-spring-cloud</a></p>&#xA;&#xA;<p>Exception like this:</p>&#xA;&#xA;<pre><code>com.netflix.turbine.monitor.instance.InstanceMonitor$MisconfiguredHostException: [{""timestamp"":""2018-03-08T17:22:05.809+0000"",""status"":404,""error"":""Not Found"",""message"":""No message available"",""path"":""/hystrix.stream""}]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.init(InstanceMonitor.java:318) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.access$100(InstanceMonitor.java:103) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:235) [turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:229) [turbine-core-1.0.0.jar:na]&#xA;    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_101]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]&#xA;</code></pre>&#xA;&#xA;<p>Or broken PIPE.</p>&#xA;&#xA;<p>Any one tried full spring cloud stack with Spring webflux? Any suggestions?</p>&#xA;"
49171571,Search queries in microservice architecture,2018-03-08 11:04:16,<architecture><microservices>,2,137,1,2.0,1,"<p>Assuming I have a microservice architecture where I have a Book microservice holding all book details and a Author microservice holding all author details, e.g.</p>&#xA;&#xA;<pre><code>Book Service&#xA;GET /     get all books&#xA;GET /id   get book details, including author_ids&#xA;POST /    create new book&#xA;etc.&#xA;&#xA;Author Service&#xA;GET /     get all authors&#xA;GET /id   get author details, including book_ids&#xA;POST /    create new author&#xA;etc.&#xA;</code></pre>&#xA;&#xA;<p>The real services are much more enterprise grade, I just choose Books and Authors with their own data storage option as a easy understandable example. </p>&#xA;&#xA;<p>Assuming, there will be millions of calls to the services and I have to uphold specific availability and throughput of systems. How can I efficiently search for authors where name starts with 'A' and all books written by the authors where book title starts with 'B'?</p>&#xA;&#xA;<p>I see following options, which all are not perfect:</p>&#xA;&#xA;<ol>&#xA;<li><p>I create a search endpoint in Author service, fetch all authors matching the search criteria, follow each book_id and filter for the books. -> This requires a lot of calls on the Book service.</p></li>&#xA;<li><p>Same as 1. but I create a search endpoint in Book service, fetch all books matching the search criteria, follow each author_id and filter for the authors. -> This requires a lot of calls on the Author service. In worst case, same load as in 1.</p></li>&#xA;<li><p>I create a new microservice Search. Search will have its own database which is optimized for searches. Search will return me the books and authors and can give me the search result with one call. -> This requires Search to frequently sync with Book and Author service.</p></li>&#xA;<li><p>I merge Book and Author into one service which defeats the purpose of mircroservices?</p></li>&#xA;</ol>&#xA;&#xA;<p>Maybe someone with more microservice experience can help me out how to best architect this.</p>&#xA;"
34049118,Tracking Issues across multiple repositories,2015-12-02 17:26:04,<github><jira><microservices>,1,493,6,1.0,1,"<p>We often have epic stories which span multiple repositories.  I am looking for a mechanism to track all the work that is associated with a single story.  GitHub has Issues which is a close to the solution I seek.  The problem with Issues is they do not span multiple repositories. On deployment day I still need to scan ~10 repositories (there are 100 repo's, 10 are commonly used) to discover which ones have commits related to the story.</p>&#xA;&#xA;<p>As a manual workaround I create multiple Issues.  One Issue for each repository.  Then I manually list the Issue#'s related to the epic story in Jira.</p>&#xA;&#xA;<p>Is there a tool or alternative technique I can use to automatically combine these issues and treat them as one?</p>&#xA;"
36948775,Managing data-store concurrency as microservices scale,2016-04-29 23:04:45,<concurrency><scalability><microservices><data-consistency>,1,979,2,0.0,1,"<p>I am still trying to find my way around micro-services. I have a fundamental question.</p>&#xA;&#xA;<p>In an enterprise scenario, micro-services would probably have to write to a persistent data-store - be it a RDBMS or some kind of NoSQL. In most cases the  persistent data-store is enterprise grade, but a single entity (ofcourse replicated and backed up).</p>&#xA;&#xA;<p>Now, let's consider the case of a single micro-service deployed to private/public cloud environment having it's own persistent data-store (say enterprise grade RDBMS). As I scale my micro-service, there will be multiple instances of the micro-service trying to read/write from the same data-store. A traditional data-store can probably be tuned to handle ~50-200 concurrent connections. How do I handle a situation when my microservices has to be scaled much beyond that?</p>&#xA;&#xA;<p>What are the best practices in such a scenario? Any patterns that can be used?</p>&#xA;"
36954140,How to create JAX-RS Sub Resources with WSO2 MSf4J,2016-04-30 11:13:24,<java><wso2><jax-rs><microservices><msf4j>,1,195,4,0.0,1,"<p>I have create a sample micro service using WSO2 MSF4J. But i can't access the sub resources (services). Following are my service classes. </p>&#xA;&#xA;<p>Message Resource - </p>&#xA;&#xA;<pre><code>@Path(""/messages"")&#xA;@Consumes(MediaType.APPLICATION_JSON) &#xA;@Produces(MediaType.APPLICATION_JSON) &#xA;public class MessageResource {&#xA;&#xA;    @Path(""/{messageId}/comments"")&#xA;    public CommentResource getCommentResource(){&#xA;&#xA;        System.out.println(""inside the getCommentResource method"");&#xA;        return new CommentResource();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Comment Resource - </p>&#xA;&#xA;<pre><code>@Path(""/"") &#xA;public class CommentResource {&#xA;&#xA;    @GET&#xA;    @Path(""/{commentId}"")&#xA;    public String test2(@PathParam(""messageId"") long messageId, @PathParam(""commentId"") long commentId){&#xA;&#xA;        System.out.println(""method to return comment Id : "" + commentId + "" for message : "" + messageId);&#xA;        return ""method to return comment Id : "" + commentId + "" for message : "" + messageId;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have used following URI to access this service.</p>&#xA;&#xA;<p>GET : <a href=""http://localhost:8080/messages/1/comments/5"" rel=""nofollow"">http://localhost:8080/messages/1/comments/5</a></p>&#xA;&#xA;<p>But i got following result to my REST client.</p>&#xA;&#xA;<pre><code>404 Not Found&#xA;&#xA;Problem accessing: /messages/1/comments/5. Reason: Not Found&#xA;</code></pre>&#xA;&#xA;<p>Please help to resolve this. </p>&#xA;"
40201069,Not able to connect mongodb with Rails container using Docker compose,2016-10-23 08:38:33,<ruby-on-rails><mongodb><docker><docker-compose><microservices>,1,984,3,1.0,1,"<p>Getting this error when inserting values in Model through rails console .</p>&#xA;&#xA;<blockquote>&#xA;  <p>""Mongo::Error::NoServerAvailable: No server is available matching&#xA;  preference: # using server_selection_timeout=30 and local_threshold=&#xA;  0.015 ""</p>&#xA;</blockquote>&#xA;&#xA;<p>Both containers are running fine, but Rails not able to connect mongodb .&#xA;I have only one Dockerfile.</p>&#xA;&#xA;<p>My docker-compose.yml file contents are:</p>&#xA;&#xA;<pre><code> version: '2'&#xA;&#xA;services:&#xA;  mongo:&#xA;    image: mongo:3.0&#xA;    command: mongod --smallfiles --quiet&#xA;    environment:&#xA;      - RAILS_ENV=production&#xA;      - RACK_ENV=production&#xA;    ports:&#xA;      - ""27017:27017""&#xA;&#xA;  app:&#xA;    depends_on:&#xA;      - 'mongo'&#xA;      # - 'redis'&#xA;    build: .&#xA;    ports:&#xA;      - '3000:3000'&#xA;    volumes:&#xA;      - '.:/app'&#xA;    command: rails s -b '0.0.0.0'&#xA;    env_file:&#xA;      - '.env'&#xA;&#xA;volumes:&#xA;  mongo:&#xA;</code></pre>&#xA;&#xA;<p>My Dockerfile :</p>&#xA;&#xA;<pre><code>FROM ruby:2.3.0&#xA;RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs&#xA;&#xA;ENV APP_HOME /app&#xA;&#xA;RUN mkdir $APP_HOME  &#xA;WORKDIR $APP_HOME&#xA;&#xA;&#xA;ADD Gemfile* $APP_HOME/ &#xA;RUN bundle install&#xA;&#xA;&#xA;ADD . $APP_HOME&#xA;</code></pre>&#xA;"
38989659,"Getting error using mvn spring-boot:run ""A child container fail to start""",2016-08-17 06:37:27,<spring-boot><microservices>,3,5088,2,0.0,1,"<p>If I am run using my spring tool suites, then it's working fine, but while running using command prompt <strong>mvn spring-boot:run</strong> I am getting these error:</p>&#xA;&#xA;<pre><code>8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) [na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_71]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;Caused by: java.lang.SecurityException: class ""javax.servlet.http.HttpSessionIdListener""'s signer information does not match signer information of other classes in the sa&#xA;ackage&#xA;        at java.lang.ClassLoader.checkCerts(ClassLoader.java:895) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.preDefineClass(ClassLoader.java:665) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.defineClass(ClassLoader.java:758) ~[na:1.8.0_71]&#xA;        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.access$100(URLClassLoader.java:73) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:368) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:362) ~[na:1.8.0_71]&#xA;        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.findClass(URLClassLoader.java:361) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4752) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) [spring-boot-1.2.8.RELEASE.j&#xA;.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) [spring-boot-1.2.8.RELEASE.jar:1&#xA;.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) [spring-boot-1.2&#xA;ELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) [spring-boot-1.2.8.RELEASE.jar:1.2.8.&#xA;ASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) [spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RE&#xA;E]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_71]&#xA;        ... 1 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: WARN  AnnotationConfigEmbeddedWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.&#xA;icationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to st&#xA;embedded Tomcat&#xA;8564: ERROR SpringApplication - Application startup failed&#xA;org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServlet&#xA;ainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.R&#xA;SE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) ~[spring-boot-1.2.8.RELEASE.jar:&#xA;8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) ~[spring-boot-1.&#xA;RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        ... 13 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        ... 18 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 20 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 22 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 24 common frames omitted&#xA;[WARNING]&#xA;java.lang.reflect.InvocationTargetException&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;        at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.Embe&#xA;ServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133)&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118)&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959)&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23)&#xA;        ... 6 more&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130)&#xA;        ... 13 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89)&#xA;        ... 18 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 20 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 22 more&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924)&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 24 more&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD FAILURE&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 10.858 s&#xA;[INFO] Finished at: 2016-08-16T16:33:40+05:30&#xA;[INFO] Final Memory: 50M/521M&#xA;[INFO] ------------------------------------------------------------------------&#xA;[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project core.eventhub: An exception occurred while run&#xA;. null: InvocationTargetException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Un&#xA; to start embedded Tomcat: Failed to start component [StandardServer[-1]]: Failed to start component [StandardService[Tomcat]]: Failed to start component [StandardEngine[&#xA;at]]: A child container failed during start -&gt; [Help 1]&#xA;[ERROR]&#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>This is the pom.xml I am using ,</p>&#xA;&#xA;<pre><code>&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;    &lt;groupId&gt;com.hm.msp.services&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;sample.springboot&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0.0&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;    &lt;name&gt;sample-server&lt;/name&gt;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;Angel.SR6&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;start-class&gt;com.hm.msp.event.Main&lt;/start-class&gt;&#xA;        &lt;mstack.version&gt;2.0.1&lt;/mstack.version&gt;&#xA;        &lt;json-lib.version&gt;2.4&lt;/json-lib.version&gt;&#xA;        &lt;msp.blp.version&gt;0.2.0&lt;/msp.blp.version&gt;&#xA;        &lt;msp.collection.version&gt;2.0.1&lt;/msp.collection.version&gt;&#xA;        &lt;msp.bundle.version&gt;0.2.0&lt;/msp.bundle.version&gt;&#xA;        &lt;camel.version&gt;2.17.0&lt;/camel.version&gt;&#xA;        &lt;xbean-spring-version&gt;4.5&lt;/xbean-spring-version&gt;&#xA;        &lt;!--following activemq version has dependencies. If you upgrade activemq &#xA;            libs make sure to pick up the right version --&gt;&#xA;        &lt;activemq-version&gt;5.11.1&lt;/activemq-version&gt;&#xA;        &lt;activemq-pool-version&gt;5.7.0&lt;/activemq-pool-version&gt;&#xA;        &lt;logback-version&gt;1.1.3&lt;/logback-version&gt;&#xA;        &lt;storm.version&gt;0.10.0&lt;/storm.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;&#xA;            &lt;!-- &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt; --&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-context&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.5&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;commons-logging&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Testing starter --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Setup Spring Data JPA Repository support --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;&#xA;        &lt;!-- Spring Cloud starter --&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;mysql&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&#xA;            &lt;version&gt;5.1.38&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;!-- Swagger dependency for mIDAS webservice --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.swagger&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;swagger-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.5.8&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storm-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${storm.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-spring-boot-starter&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-kafka&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;netty&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;io.netty&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&#xA;    &lt;/dependencies&gt;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;finalName&gt;${project.name}&lt;/finalName&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;"
39096701,DDD User-Domain specific settings,2016-08-23 08:57:59,<domain-driven-design><microservices>,1,150,12,1.0,1,"<p>I am currently developing micro service responsible for authentication (bounded context responsible for identity and permissions). We have specific settings based on user roles which are tied to another domains, but used to generate tokens</p>&#xA;&#xA;<p>(something like this <a href=""https://developer.zendesk.com/rest_api/docs/core/custom_roles"" rel=""nofollow"">https://developer.zendesk.com/rest_api/docs/core/custom_roles</a>)</p>&#xA;&#xA;<p>For an example</p>&#xA;&#xA;<pre><code>role_can_write_booking: true,&#xA;fetch_products_type : ""all/forUsersCompanyOnly""&#xA;</code></pre>&#xA;&#xA;<p>etc.</p>&#xA;&#xA;<p>Should I persist this information as a part of Identity BC, or each domain should persist it's part of settings.&#xA;Example:&#xA;<code>role_can_write_booking : true</code> inside Booking Bounded Context,&#xA;<code>fetch_products_type : ""all/forUsersCompanyOnly""</code> inside Booking products bounded context. ?</p>&#xA;"
41431506,Zuul routing : One endpoint with multiple microservices,2017-01-02 18:14:51,<java><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1829,2,0.0,1,"<p>I would like to setup zuul and the underlying microservices in a way that all services will be under the '/gateway' context.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>Microservice 1 has : <a href=""http://localhost:8081/api/hello"" rel=""nofollow noreferrer"">http://localhost:8081/api/hello</a></p>&#xA;&#xA;<p>Microservice 2 has : <a href=""http://localhost:8082/api/bye"" rel=""nofollow noreferrer"">http://localhost:8082/api/bye</a></p>&#xA;&#xA;<p>I would want to be able to access the microservices via zuul as follows:</p>&#xA;&#xA;<p>Microservice 1 : <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice1/api/hello</p>&#xA;&#xA;<p>Microservice 2: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice2/api/bye</p>&#xA;&#xA;<p>I have tried to set this up, although it seems the requests are not getting routed correctly.</p>&#xA;&#xA;<p>The reason I would like the front end to route all client side REST calls to server that begin with '/gateway' is that it provides simpler maintenance to the front end.</p>&#xA;&#xA;<p>My application.yml:</p>&#xA;&#xA;<pre><code>zuul:&#xA; prefix: /gateway&#xA;   routes:&#xA;     microservice1:&#xA;        path: /microservice1/**&#xA;        serviceId: microservice1&#xA;        strip-prefix: true&#xA;     microservice2:&#xA;        path: /microservice2/**&#xA;        serviceId: microservice2&#xA;        strip-prefix: true&#xA;</code></pre>&#xA;&#xA;<p>Thank you </p>&#xA;"
36129008,How to Send a Response Using Seneca and Express,2016-03-21 10:48:12,<node.js><express><microservices>,2,1982,0,1.0,1,"<p>I'm using Seneca to route API calls and express to serve my files.&#xA;The problem is I can't seem to find a way to send a response back to the client after getting my data from the API.&#xA;With express, I would just use <code>res.send</code>, but since I'm in the Seneca context I can't. Haven't found any reference to this issue in the documentation.</p>&#xA;&#xA;<pre><code>""use strict""; &#xA;const bodyParser  = require('body-parser');&#xA;const express = require('express');&#xA;const jsonp = require('jsonp-express');&#xA;const Promise = require('bluebird');&#xA;const path = require('path');&#xA;const seneca = require('seneca')();&#xA;const app = express();&#xA;&#xA;module.exports = (function server( options ) {   &#xA;&#xA;    seneca.add('role:api,cmd:getData', getData);&#xA;&#xA;    seneca.act('role:web',{use:{&#xA;        prefix: '/api',&#xA;        pin: {role:'api',cmd:'*'},&#xA;        map:{&#xA;            getData: {GET:true}          // explicitly accepting GETs&#xA;        }&#xA;     }});&#xA;&#xA;     app.use( seneca.export('web') )&#xA;&#xA;     app.use(express.static(path.join(__dirname, '../../dist/js')))&#xA;     app.use(express.static(path.join(__dirname, '../../dist/public')))&#xA;&#xA;     app.listen(3002, function () {&#xA;         console.log('listening on port 3002');&#xA;     });&#xA;&#xA;    function getData(arg, done){&#xA;        //Getting data from somewhere....&#xA;&#xA;        //Here I would like to send back a response to the client.            &#xA;     }&#xA; }())    &#xA;</code></pre>&#xA;"
36049030,golang workspaces in practice,2016-03-16 23:37:52,<go><workspace><microservices>,3,314,2,0.0,1,"<p>According to the Go documentation they would like you to have a workspace that one should put all their projects in.<sup>1</sup> However, as far as I can tell, this all falls apart as soon as you want to make a project that does not use Go exclusively. </p>&#xA;&#xA;<p>Take a project where it is made up of many micoservices for example. Lets say that it is structured like this:</p>&#xA;&#xA;<pre><code>app/&#xA;    authentication/ (Using rust)&#xA;    users/ (Using NodeJS)&#xA;    posts/ (Using Go)&#xA;</code></pre>&#xA;&#xA;<p>Only one part of the app would be written in Go, and that part is nested in a subdirectory of the app. How would I apply the Go workspace philosophy to this situation?</p>&#xA;&#xA;<hr>&#xA;&#xA;<ol>&#xA;<li><a href=""https://golang.org/doc/code.html#Workspaces"" rel=""nofollow"">https://golang.org/doc/code.html#Workspaces</a></li>&#xA;</ol>&#xA;"
35501600,How to config spring cloud oauth2 in docker container,2016-02-19 09:20:34,<spring><docker><spring-cloud><microservices><oauth2>,1,841,0,0.0,1,"<p>I met some problems with micro-spring-docker , i think maybe the sso token-url is not correct.</p>&#xA;&#xA;<p>The demo https://github.com/keryhu/micro-oauth2-docker</p>&#xA;&#xA;<p>In local computer , sso service and auth-service works fine .</p>&#xA;&#xA;<p>But not  in docker container , </p>&#xA;&#xA;<blockquote>&#xA;  <p>the problem is that redirecting to auth-server Timeout .</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>SSO(pc-gateway service) application.yml:</strong></p>&#xA;&#xA;<pre><code>security:&#xA;  user:&#xA;    password: none&#xA;  oauth2:&#xA;    client:&#xA;      accessTokenUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/token&#xA;      userAuthorizationUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/authorize&#xA;</code></pre>&#xA;&#xA;<p><strong>docker-compose.yml</strong></p>&#xA;&#xA;<pre><code>eureka:&#xA;  image: eureka:0.0.1-SNAPSHOT&#xA;  container_name: eureka&#xA;  hostname: eureka&#xA;  ports:&#xA;   - ""8761:8761""&#xA;&#xA;configserver:&#xA;  image: config-server:0.0.1-SNAPSHOT&#xA;  container_name: configserver&#xA;  hostname: configserver&#xA;  links:&#xA;    - eureka&#xA;  ports:&#xA;    - ""8888:8888""&#xA;&#xA;authserver:&#xA;  image: auth-server:0.0.1-SNAPSHOT&#xA;  container_name: authserver&#xA;  hostname: authserver&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;  ports:&#xA;    - ""9999:9999""&#xA;&#xA;pcgateway:&#xA;  image: pc-gateway:0.0.1-SNAPSHOT&#xA;  container_name: pcgateway&#xA;  hostname: pcgateway&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;    - authserver&#xA;  ports:&#xA;    - ""8080:8080""&#xA;</code></pre>&#xA;&#xA;<p>After starting in docker container :         </p>&#xA;&#xA;<p><a href=""http://192.168.99.100:8761/"" rel=""nofollow"">http://192.168.99.100:8761/</a> showing :</p>&#xA;&#xA;<pre><code>Instances currently registered with Eureka&#xA;Application   AMIs     Availability Zones   Status&#xA;AUTHSERVER   n/a(1)           (1)           UP (1) - authserver:authserver:9999&#xA;CONFIGSERVER n/a(1)           (1)           UP (1) - configserver:configserver:8888&#xA;PCGATEWAY    n/a(1)           (1)           UP (1) - pcgateway:pcgateway:8080&#xA;</code></pre>&#xA;&#xA;<p>But when open the auth page: <a href=""http://192.168.99.100:8080"" rel=""nofollow"">http://192.168.99.100:8080</a> </p>&#xA;&#xA;<p>It should be redirected to  auth-server login page , but it opened Timeout ， the Address Bar is: </p>&#xA;&#xA;<pre><code>http://172.17.0.4:9999/uaa/oauth/authorize?client_id=clientapp&amp;redirect_uri=http://192.168.99.100:8080/login&amp;response_type=code&amp;state=cdXhfg&#xA;</code></pre>&#xA;&#xA;<p>I don't know why , maybe the above sso tokenurl is not correct . How to resolve ?</p>&#xA;"
35639882,JWT Authentication within a Micro Service architecture,2016-02-25 22:42:00,<php><node.js><rest><authentication><microservices>,2,682,2,0.0,1,"<p><strong>Question</strong></p>&#xA;&#xA;<p>Question how is it possible to create an authentication service within a micro-service application and have other services check against that token (JWT) and retrieve a user?</p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p>My current thinking is based around the auth service inserting <code>{ token, user }</code> into Redis once a user is authenticated. All other service can check against the user's <code>Authorization: Bearer kdI8$dj$nD&amp;...</code> header token within Redis. </p>&#xA;&#xA;<ul>&#xA;<li>If <code>token</code> is present in Redis, user is authenticated.</li>&#xA;<li>If <code>token</code> is not present in Redis, user is not authenticated.</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/7fsl7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7fsl7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>User sends <code>{ username, password }</code> to auth service</li>&#xA;<li>Auth service authenticates credentials and retrieves <code>{ token, user }</code></li>&#xA;<li>Auth service inserts <code>{ token, user }</code> into Redis</li>&#xA;<li>User makes request to <code>Service-1</code> with <code>{ token }</code></li>&#xA;<li><code>Service-1</code> loooks for <code>{ token }</code> in Redis and retrieves <code>{ token, user }</code></li>&#xA;<li><code>Service-1</code> does its thing and sends back <code>{ data }</code></li>&#xA;</ol>&#xA;&#xA;<p>Are there any possible security, logic or architectural problems with this approach? </p>&#xA;"
39721791,Can you reference other aggregates in a factory when implementing domain driven design?,2016-09-27 10:03:52,<java><domain-driven-design><microservices>,3,46,0,0.0,1,"<p>I have two aggregates, <code>Employee</code> and <code>Company</code>.  An <code>Employee</code> stores a reference to the <code>Company</code> via it's <code>UUID</code>.</p>&#xA;&#xA;<p>If I want to create an employee, I need to provide it with the company ID:</p>&#xA;&#xA;<pre><code>new Employee(name, companyId)&#xA;</code></pre>&#xA;&#xA;<p>What I can't get my head around is how to get the <code>id</code> of the <code>Company</code> if the client provides only the company name.  In other words, I see this happening:</p>&#xA;&#xA;<pre><code>Employee buildEmployee(String name, String companyName) {&#xA;    Company company = companyRepository.findByName()&#xA;    return new Employeee(name, company.getGUID())&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Something feels wrong to me, as now I've introduced a dependency on the <code>Company</code> aggregate in order to create an <code>Employee</code>.  Even worse would be that if these were two were separate microservices, as I'd have to make a rest call to get the company name.</p>&#xA;&#xA;<p>Is there a way to avoid this coupling, or are my entities modelled incorrectly?</p>&#xA;"
39791667,Context mapping - relations,2016-09-30 12:34:52,<domain-driven-design><microservices><bounded-contexts>,2,264,3,0.0,1,"<p>Is it considered a bad idea that 2 bounded contexts can have upstream communication between them?</p>&#xA;&#xA;<p>Example for, order BC will publish event, and inventory BC will subscribe for that event and in the same time, inventory BC can publish events and order BC will subscribe</p>&#xA;"
39690815,java.lang.IllegalArgumentException: Only the target location may be specified,2016-09-25 19:16:30,<java><spring><spring-mvc><spring-boot><microservices>,2,330,4,0.0,1,<p>I'm writing my first spring boot application. on running the following command i'm getting the exception.</p>&#xA;&#xA;<pre><code>spring init --build maven --groupId com.redhat.examples\ --version 1.0 --java-version 1.8 --dependencies web\ --name hola-springboot hola-springboot&#xA;java.lang.IllegalArgumentException: Only the target location may be specified&#xA;    at org.springframework.util.Assert.isTrue(Assert.java:68)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.createProjectGenerationRequest(InitCommand.java:218)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.generateProject(InitCommand.java:209)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.run(InitCommand.java:189)&#xA;    at org.springframework.boot.cli.command.options.OptionHandler.run(OptionHandler.java:84)&#xA;    at org.springframework.boot.cli.command.OptionParsingCommand.run(OptionParsingCommand.java:54)&#xA;    at org.springframework.boot.cli.command.CommandRunner.run(CommandRunner.java:219)&#xA;    at org.springframework.boot.cli.command.CommandRunner.runAndHandleErrors(CommandRunner.java:171)&#xA;    at org.springframework.boot.cli.SpringCli.main(SpringCli.java:63)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)&#xA;    at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58)&#xA;</code></pre>&#xA;
34586306,Is it possible to implement microservices with oData.net,2016-01-04 07:14:16,<c#><.net><architecture><odata><microservices>,2,799,0,1.0,1,"<p>I've been reading about the <a href=""http://microservices.io/patterns/microservices.html"" rel=""nofollow"">Microservice Architecure</a> and with the limited valuable information available on internet, I believe, I have a fair understanding of it from the theory point of view. I understand that on a high level this architecture suggests to move away from <a href=""http://microservices.io/patterns/monolithic.html"" rel=""nofollow"">monoliths</a> and have small, independent services. However, all the examples that I see on the internet are suggesting to write loosely coupled windows services (daemons in case of non MS implementations) connected to an <a href=""https://en.wikipedia.org/wiki/Enterprise_service_bus"" rel=""nofollow"">ESB</a>. I understand that writing small, loosely coupled web services that adhere to <a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow"">SRP</a> also fits the bill of micro services.</p>&#xA;&#xA;<p>That said, oData.Net services, where all oData controllers (micro services?) are deployed as a monolith, is a clear violation of the Microservices Architecure pattern. Is it a correct statement to make that oData.net is not designed to work as micro services? If your answer is no then please explain with help of a an example. Also, help me understand, how to have the API gateway pattern in the mix.</p>&#xA;"
34637868,Mobile App with microservices (on Microsoft Azure service fabric),2016-01-06 16:25:43,<microservices><azure-service-fabric><azure-api-apps><azure-api-management><azure-mobile-services>,1,720,0,1.0,1,"<p>I am planning to build an enterprise grade mobile application that requires full offline capability. It would be used worldwide. For the backend application, I intend to realise it as microservices using Azure Service fabric. The backend application would be leveraged by both a web admin UI as well as by the above mobile app. For the mobile app, I intend to use Azure App service's the new mobile app service. This would provide me the capability to do offline data sync and also carry out the functions when network reachability is there.</p>&#xA;&#xA;<p>MobileApp --> Azure MobileApp service --> Azure API app service --> Azure Service Fabric (cluster of nodes hosting microservices). </p>&#xA;&#xA;<p>Following are some questions &amp; observations on which I require advice:</p>&#xA;&#xA;<ol>&#xA;<li><p>The reason I am putting in Azure API service in the middle is because I intend to do API management (I understand Azure has a separate API management offering - any pointers on how I can do true API management in the above architecture would be very helpful. Would API management replace API app service ? )</p></li>&#xA;<li><p>I intend to use Swagger generated code out of API app service, so that both the web admin UI layer and the Azure Mobile App service layer can leverage. Your thoughts ?</p></li>&#xA;<li><p>Here I am using 2 paradigms - App Service (for mobile &amp; API) and App Service fabric. I believe this is the only option given the fact that I have a mobile app requiring heavy duty offline feature.</p></li>&#xA;<li><p>Data Sync from mobile: How do you think I can sync data between Mobile App service and the microservice specific data stores ? Do I need to go via the APIs or I can easily do a data sync with the data stores of individual microservices. Your thoughts please ? </p></li>&#xA;</ol>&#xA;"
47860278,Best practice to share domain model between two microservices,2017-12-17 22:59:00,<microservices>,1,376,3,0.0,1,"<p>Are there any best practices or guidelines on how to share the domain model between two micro-services?</p>&#xA;&#xA;<p>I have a micro-service (1) which provides end points to interact with a resource (e.g, Order) all CRUD and the other micro-service (2) which performs a specific non CRUD task on the resource (Order). The micro-service (2) almost needs all the order attributes to perform its operation. In this case, does it make sense to create a common shared lib of the domain model and share between the two services? I could technically combine 1 and 2 together but the micro-service (2) needs to support scalability as it is quite memory and CPU intensive.</p>&#xA;"
31135664,Has anyone tested Akka-http-testkit?,2015-06-30 10:20:53,<scala><akka><karma-jasmine><microservices><akka-testkit>,1,678,0,0.0,1,"<p>I'm working in a microservice architecture based in akka-http and akka clustering . I have seen in akka documentation this library <a href=""http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala/http/index-testkit.html"" rel=""nofollow"">akka-http-testkit</a>. Actually, it's in an experimental state , but haven't found any documentation . Seems it's on progress . </p>&#xA;&#xA;<p>Has anyone used this library ? Can anyone suggest me any way to test rest microservices ? . My first option is using <a href=""http://karma-runner.github.io/0.12/index.html"" rel=""nofollow"">Karma</a>, and do the testing via javascript, but it would be great to hear different opinion and options (as Akka-http-testkit ... maybe ... :))</p>&#xA;"
31141688,Deployment methods for docker based micro services architecture on AWS,2015-06-30 14:53:50,<amazon-web-services><docker><elastic-beanstalk><microservices><ec2-container-service>,1,371,1,2.0,1,"<p>I am working on a project using a microservices architecture.&#xA;Each service lives in its own docker container and has a separate git repository in order to ensure loose coupling.</p>&#xA;&#xA;<p>It is my understanding that AWS recently announced support for <a href=""http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_v2config.html"" rel=""nofollow"">Multi-Container Docker environments in ElasticBeanstalk</a>. This is great for development because I can launch all services with a single command and test everything locally on my laptop. Just like Docker Compose.</p>&#xA;&#xA;<p>However, it seems I only have the option to also deploy all services at once which I am afraid defies the initial purpose of having a micro services architecture.</p>&#xA;&#xA;<p>I would like to be able to deploy/version each service independently to AWS. What would be the best way to achieve that while keeping infrastructure management to a minimum?</p>&#xA;"
31161436,How to use Apache ZooKeeper with Spring Cloud service discovery and load balancing?,2015-07-01 12:32:33,<java><apache-zookeeper><spring-cloud><service-discovery><microservices>,1,969,2,2.0,1,"<p>I'm new to Apache ZooKeeper concept to implement the service discovery and load balancing with netflix ribbon client. I seen some examples in github (<a href=""https://github.com/spring-cloud/spring-cloud-zookeeper"" rel=""nofollow"">https://github.com/spring-cloud/spring-cloud-zookeeper</a> ). Could anyone help me to know how to set-up the ZooKeeper and service discovery implementation on app service instances. I'm very curious to know about this concept.</p>&#xA;&#xA;<p>Thanks in advance..,</p>&#xA;"
31088764,Design strategy for Microservices in .NET,2015-06-27 12:28:35,<microservices>,3,591,3,0.0,1,<p>What would be a good way for Microservices .NET to communicate with each other? Would a peer to peer communication be better (for performance) using NETMQ (port of ZeroMQ) or would it be better via a Bus (NServiceBus or  RhinoBus)?&#xA;Also would you break up your data access layer into microservices too?</p>&#xA;&#xA;<p>-Indu</p>&#xA;
30209442,Cross-Microservice Authorization and Authentication,2015-05-13 08:23:41,<authentication><authorization><microservices>,1,760,4,1.0,1,"<p>Suppose we have a number of (stateless, HTTP-based) (micro)services and a bunch of ""daemons"", which do all kinds of background processing by actually using said services.</p>&#xA;&#xA;<p>Now, I want to have a way for services and daemons to be able to mutually authenticate and authorize. For example, a daemon that performs full-text indexing of Orders needs:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Read-only</strong> access to the <em>Orders</em>, <em>Customers</em> (which itself needs read-only access to <em>Companies</em> service) and <em>Inventory</em> services </li>&#xA;<li><strong>Read and write</strong> access to the <em>OrdersSearch</em> service in order to be able to update the full-text index.</li>&#xA;</ul>&#xA;&#xA;<p>There are also applications, which operate ""on behalf"" of the user. For example, Inventory web app needs <strong>read and write</strong> access to the <em>Inventory</em> service, but the <em>Inventory</em> service itself needs to verify permissions of the user operating the application.</p>&#xA;&#xA;<p>All that said, how do I achieve what I just described? I'd prefer not to use gigantic enterprisey frameworks or standards. From what I've read, Two-Legged OAuth2 is what I need, but I'm not exactly sure.</p>&#xA;&#xA;<p>I was thinkinking of establishing an <em>Authorization</em> service which will be used to answer questions like ""Hey, I'm <em>Inventory</em> service. What permissions the <em>Customer</em> service that is calling me right now has for me?"", but that has two major weak with distributing shared secrets.</p>&#xA;"
44416904,Use KONG as API Gateway to GraphQL/REST services,2017-06-07 15:27:36,<microservices><graphql><kong>,2,1594,0,0.0,1,<p>I'm trying to understand if it's possible to use KONG as API Gateway to microservices implementing REST and/or GraphQL interfaces</p>&#xA;&#xA;<p>As API Gateway will expose a GraphQL API and will request to our microservices currently implemented in REST/GraphQL and grpc coming soon.</p>&#xA;
44301997,"Spring netflix eureka, zuul vs Spring cloud data flow",2017-06-01 08:10:23,<spring><microservices><spring-cloud-netflix><spring-cloud-stream>,2,1527,0,2.0,1,"<p>I am new to the microservice world. Would like to know when to use Spring eureka, zuul vs spring data flow. </p>&#xA;&#xA;<p>I am building a service which in turns will consume multiple granular services(aka micro service), aggregate all the data and returns aggregated data to the consumer. All the services will run in local intranet within company infrastructure. Also, I would like to load balance individual microservices.</p>&#xA;&#xA;<p>What should be the choice of technology for microservices deployment?</p>&#xA;&#xA;<p>I am using Spring 4.3, Spring boot, Rest, Spring data.</p>&#xA;"
44313956,Microservices: model sharing between bounded contexts,2017-06-01 17:42:16,<mean-stack><microservices><bounded-contexts>,2,217,4,2.0,1,"<p>I am currently building a microservices-based application developed with the mean stack and am running into several situations where I need to share models between bounded contexts.  </p>&#xA;&#xA;<p>As an example, I have a User service that handles the registration process as well as login(generate jwt), logout, etc.  I also have an File service which handles the uploading of profile pics and other images the user happens to upload.  Additionally, I have an Friends service that keeps track of the associations between members.  </p>&#xA;&#xA;<p>Currently, I am adding the guid of the user from the user table used by the User service as well as the first, middle and last name fields to the File table and the Friend table.  This way I can query for these fields whenever I need them in the other services(Friend and File) without needing to make any rest calls to get the information every time it is queried.  </p>&#xA;&#xA;<p>Here is the caveat: </p>&#xA;&#xA;<p>The downside seems to be that I have to, I chose seneca with rabbitmq, notify the File and Friend tables whenever a user updates their information from the User table.  </p>&#xA;&#xA;<p>1) Should I be worried about the services getting too chatty?</p>&#xA;&#xA;<p>2) Could this lead to any performance issues, if alot of updates take place over an hour, let's say?</p>&#xA;&#xA;<p>3) in trying to isolate boundaries, I just am not seeing another way of pulling this off.  What is the recommended approach to solving this issue and am I on the right track?</p>&#xA;"
33780962,Versioning services,2015-11-18 13:09:31,<microservices><azure-service-fabric>,1,308,0,2.0,1,"<p>We are trying to do Microservices with MS' ServiceFabric.</p>&#xA;&#xA;<p>The scenario:&#xA;We have a Service1 running version1 and getting ready to upgrade to v2.</p>&#xA;&#xA;<p>Three other services depend on the interface of Service1. We want to be able to release v2 of Service1, but keep v1 running until we have upgraded and tested the three services against v2.</p>&#xA;&#xA;<p>All the examples I have found, v2 replaces v1 immediately. Can this be configured? And is there a method to tell the service discovery mechanism that I rely on a specific version of a given service?</p>&#xA;"
33805449,How to store shared-by-same-instances data in spring microservices architecture,2015-11-19 13:35:55,<jpa><database-design><architecture><spring-cloud><microservices>,3,452,0,0.0,1,"<p>following situation: I am building a system that requires redundant microservices for failover or loadbalancing. So I am starting two (or more instances of a service) of for example a simple core rest service that provides data.</p>&#xA;&#xA;<p>My Question is: How would you store the data? Using two JPA-instances to access the same database (both writing and reading) will result in problems, especially in layer 2 caching and in consistency. Since the database must be redundent itself (requirement) it might be possible to make each service instance accessing its own database, but how would you synchronize them? Is there any common solution for this?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
33798965,Microservices advice concern to share state between two services,2015-11-19 08:45:43,<java><design><redis><datasource><microservices>,2,179,4,0.0,1,"<p>I am following the microservice architecture where we got two independed services</p>&#xA;&#xA;<p>(UserService, OtherService)</p>&#xA;&#xA;<p>UserService writes to it's own datasource (mysql and Redis)</p>&#xA;&#xA;<p>Clients writing updates to UserService</p>&#xA;&#xA;<p>In other hand Client's getting data from OtherService which need some user-state from UserService.</p>&#xA;&#xA;<p>Latency and throughput of OtherService are very important.</p>&#xA;&#xA;<p>few options: </p>&#xA;&#xA;<ol>&#xA;<li><p>UserService will update OtherService when state changes (than I break the domain responsibility of OtherService since it shouldnt maintenance users states</p></li>&#xA;<li><p>OtherService will ask UserService (via api) for the user states (adding lots of latency which is critical for me. I could cache but still.. not sure thats the right way)</p></li>&#xA;<li><p>having shared datastore while UserService write and OtherService reads.. breaking also the microservice principle when sharing same datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What do you guys think would be right to do?&#xA;Thank you,&#xA;ray.</p>&#xA;"
51593335,best managing microservice dependencies,2018-07-30 11:50:02,<microservices>,3,28,0,0.0,1,"<p>I need some advise on how to best manage microservices and their dependencies.</p>&#xA;&#xA;<p>Assuming I have a microservice ""pages"" that manages article pages with operations to create/delete/edit pages.</p>&#xA;&#xA;<p>Assume I have built on top a microservice ""books"" that manages a collection of pages, with operations to add/delete/edit pages that calls the downstream endpoints of pages service.</p>&#xA;&#xA;<p>If I want to build another microservice that needs to edit a certain page in a book, would it be best to call the edit pages endpoint of books or pages directly?</p>&#xA;"
41548676,Running Lagom in Production,2017-01-09 13:00:59,<java><akka><actor><microservices><lagom>,1,1214,0,1.0,1,"<p>I am working on setting up a Lagom application in production. I have tried contacting Lightbend for ConductR license but haven't heard back in ages. So, now I am looking for an alternative approach. I have multiple questions.</p>&#xA;&#xA;<p>Since the scale of the application is pretty small right now, I think using a static service locator works for me right now (open to other alternatives). Also, I am using MySQL as my event store instead of the default configuration of Cassandra (Reasons not relevant to this thread).</p>&#xA;&#xA;<p>To suppress Cassandra and Lagom's Service Locator, I have added the following lines to my build.sbt:</p>&#xA;&#xA;<pre><code>lagomCassandraEnabled in ThisBuild := false&#xA;</code></pre>&#xA;&#xA;<p>I have also added the following piece to my application.conf with service1-impl module.</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For the dev environment, I have been able to successfully run my application using <code>sbt runAll</code> in a tmux session. With this configuration, there is no service locator running on the default 8000 port but I can individually hit service1 on 8080 port. (Not sure if this is the expected behaviour. Comments?)</p>&#xA;&#xA;<p>I ran <code>sbt dist</code> to create a zip file and then unzipped it and ran the executable in there. Interestingly, the zip was created within the service1-impl folder. So, if I have multiple modules (services?), will sbt dist create individual zip files for each of the service?</p>&#xA;&#xA;<p>When I run the executable created via <code>sbt dist</code>, it tries to connect to Cassandra and also launches a service locator and ignores the static service locator configuration that I added. Basically, looks like it ignores the lines I added to build.sbt. Anyone who can explain this?</p>&#xA;&#xA;<p>Lastly, if I were to have 2 services, service1 and service2, and 2 nodes in the cluster with node 1 running service1 and node 2 running both the services, how would my static service locator look like in the application.conf and since each of the service would have its own application.conf, would I have to copy the same configuration w.r.t. static service locator in all the application.confs?</p>&#xA;&#xA;<p>Would it be something like this?</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;    service1 = ""http://1.2.3.4:8080""&#xA;    service2 = ""http://1.2.3.4:8081""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Since each specific actor would be spawned on one of the nodes, how would it work with this service locator configuration?</p>&#xA;&#xA;<p>Also, I don't want to run this in a tmux session in production. What would be the best way to finally run this code in production?</p>&#xA;"
41624628,How do you develop a microservice in isolation when it depends on other microservices?,2017-01-12 23:03:45,<microservices>,2,196,1,2.0,1,"<p>We are evaluating a move to microservices.  Each microservice would be its own project developed in isolation.  During planning, we have determined that some of the microservices will communicate with other via REST calls, pub/sub, messaging (ie. a order service needs product information from product service).</p>&#xA;&#xA;<p>If a microservice depends on retrieving data from another microservice, how can it be run in isolation during development?  For example, what happens when your order service requests product details, but there is nothing to answer that request?</p>&#xA;"
42918707,What are the disadvantages of using Kerberos authentication for secure micro-service to micro-service communication?,2017-03-21 04:53:18,<kerberos><microservices>,1,404,4,0.0,1,"<p>Sam Newman's ""Building Microservices"" book has described several methods that can be used to perform secure service to service communication. Such as</p>&#xA;&#xA;<ol>&#xA;<li>HTTPS Basic Authentication</li>&#xA;<li>Client Certificates</li>&#xA;<li>HMAC API Keys</li>&#xA;</ol>&#xA;&#xA;<p>I think Kerberos protocol can also be used for service to service authentication. But I found less references of using Kerberos protocol. Are there any disadvantages of using kerberos protocol in microservice architecture than other methods? </p>&#xA;"
36265833,Microservices & Versioning,2016-03-28 15:50:24,<cloud><versioning><microservices><semantic-versioning><continuous-delivery>,3,353,0,0.0,1,"<p>I'm building a cloud-native application using microservices. Eventually I have arrived at the point where I must implement proper versioning for my microservices. In most places where I've looked everyone is talking about semantic versioning these days (in general, not just for microservices).</p>&#xA;&#xA;<p>One of the principals of a microservices architecture is to <em>never deliver a breaking changeset</em>. On the other hand, semantic versioning says that one should increase the major version number when a non-backwards compatible (read ""breaking"") changeset is delivered. How are these compatible?</p>&#xA;&#xA;<p>It seems to me that semantic versioning <em>might be</em> overkill for a microservices architecture. If all public APIs are versioned (example /api/v3/getSomething) then do I really need full semantic versioning? I'm considering a scheme whereby I use a single number to identify the API version currently available (v1, v2, v3 etc.) together with a build number (or perhaps date/timestamp) that identifies the continuous integration pipeline that produced the build. Note that v3 would also still support v2 API calls until everyone using the service has moved to using v3, so v3 is the ""target version"" in a sense. So my microservice foo would look like ""foo-v3-20160503142209.jar""</p>&#xA;&#xA;<p>Are there any obvious pitfalls to this? The way I see it, clients will be guaranteed that the API is compatible if I enforce <em>never delivering breaking changeset</em> (if it changes, it is a new API version). And clients can be sure of all latest bug fixes by using the latest build number/timestamp.</p>&#xA;"
50555353,How to handle in Event Driven Microservices if the messaging queue is down?,2018-05-27 18:40:54,<multithreading><reactive-programming><message-queue><microservices><event-driven-design>,1,51,0,2.0,1,"<p>Assume there are two services <strong>A</strong> and <strong>B</strong>, in a microservice environment.</p>&#xA;&#xA;<p>In between A and B sits a messaging queue <strong>M</strong> that is a broker.</p>&#xA;&#xA;<p><strong>A&lt;---->'M'&lt;----->B</strong></p>&#xA;&#xA;<p>The problem is what if the broker M is down?</p>&#xA;&#xA;<p>Possible Solution i can think of:&#xA;Ping from Service A at regular intervals to check on Messaging queue <strong>M</strong> as long as it is down. In the meantime, service <strong>A</strong> &#xA;stores the data in a local DB and dumps it into the queue once the broker M is up.</p>&#xA;&#xA;<p>Considering the above problem, if someone can suggest whether threads or reactive programming is best suited for this scenario and ways it could be handled via code, I would be grateful.</p>&#xA;"
50634072,Observer pattern in microservice,2018-05-31 23:14:13,<java><design-patterns><microservices><observer-pattern>,1,118,6,0.0,1,"<p>Currently I am reading the book called: Head First Pattern Design, there is one design pattern called: Observer pattern, like this: <a href=""https://www.tutorialspoint.com/design_pattern/observer_pattern.htm"" rel=""nofollow noreferrer"">https://www.tutorialspoint.com/design_pattern/observer_pattern.htm</a></p>&#xA;&#xA;<p>While I was reading that design pattern, I was feeling that currently we often use queuing system to publish and subscribe tasks between each microservices. Got a feeling that the Observer pattern is not quite often be used currently.  <strong>Please correct me if I am not right, if could provide some example about using observer pattern in mircoservice will be excellent!</strong></p>&#xA;"
47077380,Spring Cloud Services - Eureka,2017-11-02 14:10:53,<angular><spring-boot><microservices><spring-cloud>,1,630,1,0.0,1,"<p>I am trying to learn microservices using spring and spring boot , and learning to deploy into cloud platform. I am planning to create a angular 2 front-end application which communicates with my deployed microservice. Now I just going through spring cloud services eureka, Zuul , circuit breakers etc. </p>&#xA;&#xA;<ol>&#xA;<li>When I reading I found that Eureka is using for service registry for finding services each other. Here My doubt is that , When I am communicating from my angular 2 http request, I need to use these service registering?? What cloud configuration I need to follow to make a ReST API to microservice?? I am totally getting confusing what i need to push my sample microservice to cloud,Since I am a beginner. Can anyone help me to clarify these doubts??</li>&#xA;</ol>&#xA;"
42002512,Running multiple instance microservice using spring cloud config,2017-02-02 12:39:10,<spring><spring-boot><microservices><spring-cloud-config>,2,1485,2,0.0,1,"<p>I am developing a <strong>microservice, using <a href=""https://projects.spring.io/spring-boot/"" rel=""nofollow noreferrer"">Spring Boot</a></strong>, that exposes REST Endpoint. </p>&#xA;&#xA;<p>To meet the scalability constrains, <strong>multiple instance of the [same] service</strong> will be deployed (basically scale up when needed and scale down when not needed). </p>&#xA;&#xA;<p>I am using the <strong><a href=""https://cloud.spring.io/spring-cloud-config/spring-cloud-config.html"" rel=""nofollow noreferrer"">Spring Cloud Config Server</a></strong> to supply the configuration (such as port to bound, and other configurations) to this service. </p>&#xA;&#xA;<p><strong>Since the service exposing REST api, How can configure the config server to supply a unique port to each instance of the microservice?</strong></p>&#xA;&#xA;<p>One possible solution could be, running the service in individual machine/VM or create a docker container and deploy the service. This could be my solution if there is no way to supply random port to the service from cloud config server.</p>&#xA;"
38099204,Session management using json web tokens in microservices,2016-06-29 12:13:43,<json><session><token><jwt><microservices>,1,808,0,0.0,1,"<p>I am trying to figure out how I will manage sessions using json web tokens in a microservice architecture. </p>&#xA;&#xA;<p>Looking at the design in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""nofollow"">article</a> what I currently have in mind is that the client will send a request that first goes through a firewall. This request will contain an opaque/reference token which the firewall sends to an authorization server.  The authorization server responds with a value token containing all the session information for the user.  The firewall then passes the request along with the value token to the API, and the value token will then get propagated to all the different microservices required to fulfill the request. </p>&#xA;&#xA;<p>I have 2 questions:</p>&#xA;&#xA;<ol>&#xA;<li>How should updates to the session information in the value token be handled? To elaborate, when the session info in a token gets updated, it needs to be updated in the authorization server.  Should each service that changes the token talk to the authorization server? </li>&#xA;<li>Should all the microservices use this single token to store their session info? Or would it be better for each service to have a personalized token? If it's the latter, please explain how to adjust the design.</li>&#xA;</ol>&#xA;"
38164006,How To Delay Observable emission in RxJava,2016-07-02 20:00:14,<rx-java><haproxy><microservices>,2,1410,0,0.0,1,"<p>We have Micro services architecture, where we make inter-service calls over a network.&#xA;We are using RxJava in top level service, which is resulting in creation of large no of parallel requests to bottom service.&#xA;Because of this i am getting ""No Route to Host error"" or ""connection error"".&#xA;For that purpose i want to slow down emission from RxJava Observable, so that earlier connection will get closed before creating new one.&#xA;Below is the sample code:</p>&#xA;&#xA;<pre><code>    package com.demo.rxjava.rxjaxa.creation;&#xA;    import rx.Observable;&#xA;    import rx.Subscriber;&#xA;    import rx.schedulers.Schedulers;&#xA;&#xA;    public class Delay {&#xA;&#xA;        public static void main(String[] args) throws InterruptedException {&#xA;            Observable.just(1, 2, 3, 4, 5).subscribeOn(Schedulers.io())&#xA;                    .flatMap(integer -&gt; {&#xA;                        return function1(integer);&#xA;                    }).observeOn(Schedulers.io())&#xA;                    .subscribe(new Subscriber&lt;String&gt;() {&#xA;                        @Override&#xA;                        public void onNext(String item) {&#xA;                            System.out.println(""Next: "" + item);&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onError(Throwable error) {&#xA;                            System.err.println(""Error: "" + error.getMessage());&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onCompleted() {&#xA;                            System.out.println(""Sequence complete."");&#xA;                        }&#xA;                    });&#xA;        }&#xA;&#xA;     public Observable&lt;String&gt; function1(String id) {&#xA;                // This is where we make network call&#xA;                Observable&lt;Response&gt; response = Rx.newClient(RxObservableInvoker.class)&#xA;                        .target(""http://example.com/resource"")&#xA;                        .request()&#xA;                        .queryParam(""id"", id)&#xA;                        .rx()&#xA;                        .get();&#xA;                response.obserOn(Schedulers.from(threadExecutor)).flatMap(response-&gt;{&#xA;                    return response.extractResponse();&#xA;                });&#xA;   }&#xA;}&#xA;</code></pre>&#xA;"
38172510,How to handle network calls in Microservices architecture,2016-07-03 17:25:50,<networking><architecture><rx-java><haproxy><microservices>,1,889,3,0.0,1,"<p>We are using Micro services architecture where top services are used for exposing REST API's to end user and backend services does the work of querying database.</p>&#xA;&#xA;<p>When we get <strong>1 user request we make ~30k requests to backend service</strong>. We are using RxJava for top service so all 30K requests gets executed in parallel.&#xA;We are using haproxy to distribute the load between backend services.&#xA;However when we get 3-5 user requests we are getting network connection Exceptions, No Route to Host Exception, Socket connection Exception.</p>&#xA;&#xA;<p>What are the best practices for this kind of use case?</p>&#xA;"
42641804,Authentication approach for REST API used by frontend app and another backend service,2017-03-07 06:39:04,<javascript><java><rest><microservices>,2,583,1,0.0,1,<p>I have a rest api backend service <strong>A</strong> which is used by two other services:</p>&#xA;&#xA;<ul>&#xA;<li><strong>B</strong> service which is web app running in a browser (separate node server)</li>&#xA;<li><strong>C</strong> service which is also backend service (separate server too)</li>&#xA;</ul>&#xA;&#xA;<p>My initial approach was to use basic auth for A-B communication but this does not make sense for A-C since there is no way to safely keep credentials in a browser. On the other hand introducing session and tokens seems weird for A-B communication.</p>&#xA;&#xA;<p>No matter what I do it seems like tug of war.</p>&#xA;&#xA;<p>What do you think might be reasonable solution for such setup?</p>&#xA;
42653725,In which microservice should I store a liaison table,2017-03-07 16:45:01,<relational-database><relationship><microservices>,2,117,3,0.0,1,"<p>I'm splitting my zoo-management application into micro-services.&#xA;I have the following domain : animals, caretakers, cages </p>&#xA;&#xA;<p>I thinking about where I should store the relationships. </p>&#xA;&#xA;<p>For exemple a cage contain several animals :&#xA;Should I store the cage_animals table into the cages services database or into the animals database ?</p>&#xA;&#xA;<p>And several caretakers are attributed to several animals :&#xA;Should I store the caretakers_animals table into the caretakers service's database or into the animals service's database ?</p>&#xA;"
38460678,Architecture Microservices Jhipster,2016-07-19 13:57:51,<java><jwt><jhipster><microservices>,1,1781,0,0.0,1,"<p>I want to start an architecture with microservices of Jhipster but I have doubts.&#xA;I have 4 pieces.</p>&#xA;&#xA;<ul>&#xA;<li>""HR"" &lt;- front and backend application</li>&#xA;<li>""SELECTION"" &lt;- front and backend application</li>&#xA;<li>Validation &lt;- Only one database for all front</li>&#xA;<li>Customers &lt;- is shared between ""HR"" and ""SELECT"" back in front in microservice and ""HR"" and ""SELECT"".</li>&#xA;</ul>&#xA;&#xA;<p>Both applications must be validated against the same database (JWT).&#xA;Both applications must share a microservicio ""CUSTOMER"" which will have the backend, but the front will be in each of the two applications.</p>&#xA;&#xA;<ul>&#xA;<li>1 - ""HR"" It would be a gateway?</li>&#xA;<li>2 - ""SELECTION"" It would be a gateway?</li>&#xA;<li>3 - How to implement security that is both against the same database (JWT) validated</li>&#xA;<li>4 - ""CUSTOMER"" It would be a microservicio?</li>&#xA;</ul>&#xA;&#xA;<p>Sorry for my English.</p>&#xA;"
40010594,Consul deregister 'failing' services,2016-10-13 00:51:04,<microservices><mesos><mesosphere><consul><consul-template>,2,836,0,0.0,1,<p>I have consul running on Consul v0.5.2 version &amp; services running in Mesos. Services keep moving from 1 server to another.</p>&#xA;&#xA;<p>Is there way to deregister services in consul that are in 'failing' state? I am able to get the list of services in failing state using this curl</p>&#xA;&#xA;<pre><code>curl http://localhost:8500/v1/health/state/critical&#xA;</code></pre>&#xA;&#xA;<p>Issue that we are seeing is over a period of time in consul UI we have stale data &amp; making the whole UI unusable</p>&#xA;
39888380,"Spring Boot Microservice: dynamic role, permission based security",2016-10-06 05:47:33,<java><spring><spring-security><spring-boot><microservices>,1,1120,0,0.0,1,"<p>We have created application using Spring Boot Microservices,&#xA;application contains jsp pages and rest uri.</p>&#xA;&#xA;<p>For this type of architecture expect suggestions to secure pages and uri.&#xA;I want role and permission based access, where permission contains all pages and uri listed and role_permission_mapping has mapping of uri/pages against role.</p>&#xA;&#xA;<p>Admin have rights to add Role, Permission and Mapping dynamically using some UI. </p>&#xA;&#xA;<p>Image below shows sample table structure.</p>&#xA;&#xA;<p>Suggest me if we have built-in mechanism which provides out of box support for this type of requirement.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eBgNL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBgNL.png"" alt=""enter image description here""></a></p>&#xA;"
39998701,throw new TypeError('app.use() requires middleware functions');,2016-10-12 12:31:23,<javascript><node.js><express><microservices><seneca>,1,302,5,0.0,1,"<p>I'm just trying to run sample codes from Developing Microservices with Node js, and it says:</p>&#xA;&#xA;<pre><code>var express = require('express')&#xA;var bodyParser = require('body-parser')&#xA;var cookieParser = require('cookie-parser')&#xA;var methodOverride = require('method-override')&#xA;var seneca = require('seneca')()&#xA;var argv = require('optimist').argv&#xA;var app = express()&#xA;var cors = require('cors')&#xA;var routes = require('./../routes/index')&#xA;let path = require('path')&#xA;var webpack = require('webpack')&#xA;var webpackMiddleware = require('webpack-dev-middleware')&#xA;var config = require('./../webpack.config.js')&#xA;&#xA;var compiler = webpack(config)&#xA;&#xA;var conf = {&#xA;   port: argv.p || 7770&#xA;}&#xA;&#xA;app.engine('jsx', require('express-react-views').createEngine())&#xA;app.set('port', conf.port)&#xA;app.use(cors())&#xA;app.use('/public', express.static(path.join(__dirname,'./../public')))&#xA;app.use('/views', express.static(path.join(__dirname, './../views')))&#xA;app.use(webpackMiddleware(compiler));&#xA;app.use(cookieParser())&#xA;app.use(express.query())&#xA;app.use(bodyParser.urlencoded({extended: true}))&#xA;app.use(methodOverride())&#xA;app.use(bodyParser.json())&#xA;app.use(express.static('public'))&#xA;app.use(seneca.export('web'))  // Error line&#xA;&#xA;seneca.use('./../lib/registerAPI')&#xA;&#xA;app.use('/', routes)&#xA;&#xA;module.exports = app&#xA;</code></pre>&#xA;&#xA;<p>but Im getting an error that says:</p>&#xA;&#xA;<pre><code>/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177&#xA;     throw new TypeError('app.use() requires middleware functions');&#xA;     ^&#xA;TypeError: app.use() requires middleware functions &#xA;     at EventEmitter.use (/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177:11)&#xA;     at Object.&lt;anonymous&gt; (/home/quocdinh/workspace/ECommerce/ass-ECommerce/src/app.js:33:5) // --&gt; line: app.use(seneca.export('web'))&#xA;</code></pre>&#xA;&#xA;<p>I have tried to find solutions but ineffective.</p>&#xA;&#xA;<p>I tried adding</p>&#xA;&#xA;<pre><code> app.use(require('seneca-web'))&#xA;</code></pre>&#xA;&#xA;<p>but still not be</p>&#xA;&#xA;<p>I tried to lower the version of the node version that I have to 4.0 from 6.0, but still got the same error</p>&#xA;"
49606124,Neo4J In Microservices Architecture,2018-04-02 06:05:19,<java><spring><neo4j><microservices><spring-data-neo4j-5>,4,176,0,0.0,1,"<p>To keep in line with DDD and Bounded Contexts, its well known that when you create your microservices you should keep separation of concerns.</p>&#xA;&#xA;<p>One of the main benefits of Neo4J is keeping your ""connected"" data in Neo4J so relationships between them are efficiently queried.</p>&#xA;&#xA;<p>These two opposing forces seem to make an microservice architecture decision difficult when choosing to use Neo4J.</p>&#xA;&#xA;<p>Do you have multiple microservices connect to Neo4J db and persist their own domain accordingly?</p>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<p>Do you have one microservice with a db connection to Neo4J that controls persistance and querying?</p>&#xA;&#xA;<p>Both dont seem quite right...</p>&#xA;"
49469599,Authentication and authorisation in microservice architecture,2018-03-24 20:28:44,<authentication><jwt><graphql><microservices><go-micro>,1,322,2,2.0,1,"<p>I have multiple services:</p>&#xA;&#xA;<ul>&#xA;<li>User</li>&#xA;<li>Post</li>&#xA;<li>Comment</li>&#xA;<li>Authentication</li>&#xA;<li>GraphQL endpoint</li>&#xA;</ul>&#xA;&#xA;<p>And lets say they are connected together like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GAyiV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GAyiV.png"" alt=""example 1""></a></p>&#xA;&#xA;<p>All services are communicating through gRPC on a closed nettwork and the Authorization is done using jwt tokens</p>&#xA;&#xA;<p>Approach 1:&#xA;The graphql service is responsible for user authentication and making sure that the user is authorised to run the specified procedure. There is no user authentication between the services, but there is TLS authentication. There is no authorisation checks done by the services.</p>&#xA;&#xA;<p>Approach 2:&#xA;Each individual service makes sure that the user is authorised to run a specific procedure. An example could be voting on a post where you wold need to be signed in and have over 15 in reputation. Here it would be the Post service responsibility to check whether the user is signed in or not (authenticated) and whether it's authorised to vote. This will result in large overhead since every procedure call needs to check user authentication and authorisation through the Auth service. </p>&#xA;&#xA;<p>Is there a better approach that still preserves the security of approach 2, but creates a small overhead like approach 1?</p>&#xA;&#xA;<p><strong>-----Update-----</strong></p>&#xA;&#xA;<p>Approach 3:&#xA;Same as approach 2, but user authentication is only done in the GraphQL service using the Auth service. Authorisation is done by checking metadata passed arround. And there is TLS authentication between the services. </p>&#xA;"
49580394,sending millions of short messages over tcp socket in golang,2018-03-30 19:37:25,<go><tcp><microservices>,1,324,2,2.0,1,"<p>I'm writing two services in golang that need to send to each other about 2 million messages per second. Each message is about 50 bytes, so throughput should only be about 100MB/s. I want to use tcp for this. However, results are very slow. I configured SetNoDelay(false) to make sure that data is buffered before sending, but that didn't make any difference. </p>&#xA;&#xA;<p>I can only send about 50k messages per second, and message size doesn't matter too much, so I assume the code is blocking somewhere. Here's my test code:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import ""net""&#xA;import ""fmt""&#xA;import ""bufio""&#xA;import (&#xA;    //""strings""&#xA;    ""time""&#xA;)&#xA;&#xA;func startserver() {&#xA;    fmt.Println(""Launching server..."")&#xA;    ln, _ := net.Listen(""tcp"", "":8081"")&#xA;    conn, _ := ln.Accept()&#xA;&#xA;    for {&#xA;        bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Println(message)&#xA;        //newmessage := strings.ToUpper(message)&#xA;        //conn.Write([]byte(newmessage + ""\n""))&#xA;    }&#xA;}&#xA;&#xA;func startclient() {&#xA;    time.Sleep(time.Second) // so that server has time to start&#xA;    servAddr := ""127.0.0.1:8081""&#xA;    tcpAddr, _ := net.ResolveTCPAddr(""tcp"", servAddr)&#xA;    conn, _ := net.DialTCP(""tcp"", nil, tcpAddr)&#xA;    conn.SetNoDelay(false)&#xA;    conn.SetWriteBuffer(10000)&#xA;    msg := ""abc\n""&#xA;    start := time.Now()&#xA;    for i := 0; i &lt; 1000000; i++ {&#xA;        conn.Write([]byte(msg))&#xA;        //bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Print(""Message from server: "", response)&#xA;    }&#xA;    fmt.Println(""took:"", time.Since(start))&#xA;}&#xA;&#xA;func main() {&#xA;    go startserver()&#xA;    startclient()&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestion?</p>&#xA;"
49637598,"Getting an error ""Cause: AMQ119031: Unable to validate user"" in Spring-Boot app",2018-04-03 19:16:24,<spring-boot><microservices><spring-jms><jboss-eap-7><activemq-artemis>,1,167,3,0.0,1,"<p>I'm getting the following error when trying to connect to ActiveMQ Artemis Queue deployed on JBoss EAP 7.1. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: DefaultMessageListenerContainer: Could not refresh JMS&#xA;  Connection for destination 'jms/queue/QueueA' - retrying using&#xA;  FixedBackOff{interval=5000, currentAttempts=139,&#xA;  maxAttempts=unlimited}. Cause: AMQ119031: Unable to validate user</p>&#xA;</blockquote>&#xA;&#xA;<p>Here is the code I'm using:</p>&#xA;&#xA;<pre><code>@Bean public DefaultMessageListenerContainer myFactory() throws NamingException { &#xA;   DefaultMessageListenerContainer listenerContainer = new DefaultMessageListenerContainer();&#xA;   listenerContainer.setConnectionFactory(getConnectionFactory());&#xA;   listenerContainer.setDestinationName(""jms/queue/QueueA"");&#xA;   listenerContainer.setMessageListener(new MessageReceiver());&#xA;   return listenerContainer; &#xA;}&#xA;&#xA;private ConnectionFactory getConnectionFactory() throws NamingException { &#xA;   final Properties env = new Properties();&#xA;   env.put(Context.INITIAL_CONTEXT_FACTORY, org.wildfly.naming.client.WildFlyInitialContextFactory); &#xA;   env.put(Context.PROVIDER_URL, ""http-remoting://localhost:8080""); &#xA;   env.put(Context.SECURITY_PRINCIPAL, ""Username""); &#xA;   env.put(Context.SECURITY_CREDENTIALS, ""Password""); &#xA;   InitialContext ic = new InitialContext(env); &#xA;   return (ConnectionFactory) ic.lookup(""jms/RemoteConnectionFactory"");&#xA;}&#xA;</code></pre>&#xA;"
49610008,Swagger with spring boot microservice,2018-04-02 11:01:07,<spring-boot><filter><swagger><microservices><swagger-ui>,1,98,5,0.0,1,<p>I have a <strong>microservice-A</strong> which gets the token as a header from another <strong>microservice-B</strong>. Now I want to implement <strong>swagger2 in microservice-A</strong>. The problem is every request <strong>flows through microservice-B</strong>. So <strong>swagger-ui throws error</strong> in local as </p>&#xA;&#xA;<blockquote>&#xA;  <p>it is not able to get those header parameter which microservice-B is&#xA;  trying to fetch.</p>&#xA;</blockquote>&#xA;
49659871,Java circuit breaker running in request thread,2018-04-04 20:28:50,<java><microservices><hystrix><circuit-breaker>,1,110,7,1.0,1,"<p>I have been considering Netflix OSS circuit breaker solution - Hystrix.</p>&#xA;&#xA;<p>Everything sounds good but I think that having the command run in a different thread does not make sense in my use case scenario. </p>&#xA;&#xA;<p>That is because the work done by my request handler requires very little computation before calling the remote service. Also, there is nothing I can do while waiting for the response.</p>&#xA;&#xA;<p>Example in Pseudo code:</p>&#xA;&#xA;<p>@post(""/token"")&#xA;token(@body authResult){&#xA;  Validate authResult&#xA;  Get id from authResult &#xA;  Call a remote service to get authz token&#xA;  Return authz token&#xA;}</p>&#xA;&#xA;<p>I would like to do the remote call using hystrix but I do not think it makes sense to execute the command in a separate thread since I would be blocked anyway. </p>&#xA;&#xA;<p>Any suggestions? Is it possible to run hystrix command in the same thread as the caller?</p>&#xA;"
38889466,How to run multiple Spring Boot application sharing same context?,2016-08-11 07:04:23,<spring><spring-security><spring-boot><microservices>,2,1676,0,1.0,1,"<p>I want to run multiple micro-services app sharing same context so that I can run my custom security filter for multiple spring boot(micro-services) app.</p>&#xA;&#xA;<p>Example: </p>&#xA;&#xA;<p>User services : <a href=""https://ip:port/myapp/user"">https://ip:port/myapp/user</a></p>&#xA;&#xA;<p>Product services : <a href=""https://ip:port/myapp/product"">https://ip:port/myapp/product</a></p>&#xA;&#xA;<p>Comment services : <a href=""https://ip:port/myapp/comment"">https://ip:port/myapp/comment</a></p>&#xA;&#xA;<p>And I should run  a common filter(Custom Security Filter) for all micro-services.</p>&#xA;"
38711908,How many database in a Microservices Event Driven architecture?,2016-08-02 04:42:50,<cqrs><microservices><event-sourcing><eventsource>,3,1161,4,1.0,1,"<p>I've read tons of documentation, blog posts and examples about CQRS with EventSource as a useful architecture in a Microservice system.</p>&#xA;&#xA;<p>A popular example is the banking transfer app:&#xA;<a href=""https://i.stack.imgur.com/zmxrc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zmxrc.jpg"" alt=""banking transfer app""></a></p>&#xA;&#xA;<p>It's clear there are four microservices, but I don't understand becouse the ""command side"" microservices don't have their own database.</p>&#xA;&#xA;<p>By this image all Microservices are using the same eventStore database, that's should be against the microservice pattern?</p>&#xA;&#xA;<p>And how should be the EventStore db? Single table? One table for each service&#xA;?</p>&#xA;"
51282761,Microservices Scalable Deployment,2018-07-11 10:09:21,<spring-boot><google-cloud-platform><microservices><google-kubernetes-engine>,1,49,3,0.0,1,"<p>I have recently developed REST API. My project is developed with microservices using SpringBoot. I have used Zuul API Gateway and Eureka Discovery server in the project. I deployed it on a google kubernetes cluster. When I do a load test for the Rest API calls it shows me, it can handle only a few requests per second. &#xA;What I need to know is, how to autoscale the kubernetes pods for my services. What parameter should I look into? Ram usage or CPU usage or any other ???</p>&#xA;"
49252691,Microservice relationship/dependency strategy,2018-03-13 09:37:06,<architecture><microservices>,2,60,3,0.0,1,"<p>I'd like some feedback on couple different solutions to handling data dependencies and relations across micro services.</p>&#xA;&#xA;<p>Consider these services:&#xA;<a href=""https://i.stack.imgur.com/Y7Qx8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y7Qx8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Briefly explained, there is a bank service and an account service. The account service holds the accounts and are always connected to a bank using a bankId.</p>&#xA;&#xA;<p>The dilemma is how to handle and validate this relationship and bankId and the pros and cons that comes with each decision.</p>&#xA;&#xA;<p><strong>Option 1:</strong></p>&#xA;&#xA;<p>Ignore validating completely. POST/PATCH against Accounts will never validate if the given BankId is an existing ID.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>Services don't know about each other and there are no hard dependencies between them, if one service goes down, the other doesn't stop working. (Which is a BIG one)</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>If the BankId is incorrect, accounts are ""lost"" and can't be accessed.</li>&#xA;<li>The reporting service and/or any reader has to account for missing or incorrect banks and present whatever data it has without crashing.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>The services are completely decoupled which will benefit performance, up time and complexity. All readers and applications need to be ""reactive"" and able to handle when cross service relationships are ""broken"".</p>&#xA;&#xA;<p><strong>Option 2:</strong></p>&#xA;&#xA;<p>Always validate using synchronous REST-call. POST/PATCH against Accounts will fail if BankId does not exist or if in anyway BankService can't respond or is broken.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Services are tightly dependent, you could argue that they are no longer proper micro services and might as well be a single service.</li>&#xA;<li>Performance impacted negatively</li>&#xA;<li>AccountService POST/PATCH won't work if BankService is down, GET will still work.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>Services are tightly dependent which is really bad, this is more like the ""old ways"" and generally I feel like it's the wrong way to do it. Merging the services in this case is even worse, if you start fixing problems by merging you'd probably keep doing it and soon end up with massive services and you've failed with the whole micro service principle. Sure, reads will still work but that's a far fetched excuse.</p>&#xA;&#xA;<p><strong>Option 3:</strong></p>&#xA;&#xA;<p>Keep a readonly copy of BankEntity in AccountService. AccountService keeps this updated via the event bus. Validate against this on POST/PATCH.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;<li>No measurable negative performance impact</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Complexity increased</li>&#xA;<li>Due to the asynchronous nature of events we cannot assume that the readonly copy of Banks are 100% updated. POST/PATCH on Account in rapid succession after creating a BankEntity might fail.</li>&#xA;<li>AccountService gets more knowledge of other services, even though it's a loose dependency</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>This is the most complex way, readers won't need to handle broken relationships and the performance / up time-issues are resolved, however, instead you would have to handle the fact that the readonly copy of Banks might not be updated yet and try again later. Comparing this to Option 1 means you'd still have to deal with it in some way, and since this will be more complex across the board I'd say its not the most favourable one.</p>&#xA;&#xA;<p><strong>End Thoughts</strong></p>&#xA;&#xA;<p>The general goal that would be nice to achieve is that the services do not synchronously talk to each other and that data integrity is a good as possible.</p>&#xA;&#xA;<p>However, in a micro service architecture I'm under the impression that relationship integrity simply might be one of those things you accept to lose going to this way.</p>&#xA;&#xA;<p>Our decision is leaning towards Option 1, actually just ignoring it, and anytime where you need to use it, you have to expect and handle that it might not be correct. This seems like it is the most ""micro services"" solution, the services don't really know about each other, the only ones that do are applications and reporting services that need to do cross-service operations.</p>&#xA;&#xA;<p>Any of the services need to take full responsibility that they, at any given time, has all the data they need to fully function themselves. Let's say for arguments sake that AccountEntity NEEDED a location for whatever reason to be a usable and complete domain entity, you can't expect to rely on BankId, you'd have to store Location on AccountEntity and maybe if it changes, you'd get an event and you can update it.</p>&#xA;&#xA;<p><strong>TL;DR</strong>&#xA;What are your experiences, opinions and thoughts on this? What would you do? Which strategy would you go for?</p>&#xA;"
49302010,What are the benefits of splitting a big monolithic application into 2 applications?,2018-03-15 14:24:18,<java><web-services><java-ee><weblogic><microservices>,3,113,3,1.0,1,<p>We currently have a big monolithic J2EE application (weblogic / DB2).  It is a typical OLTP application.  We are considering to split this application into 2 applications where each application has its own database which is not directly accessible by the other application.  This also means that each application need to expose an interface for the functionality that is needed by the other application.</p>&#xA;&#xA;<p>So what are potentially the major benefits of splitting such an existing application into 2 applications ?</p>&#xA;
38466167,Microservice in Google App engine,2016-07-19 18:40:32,<python><google-app-engine><google-cloud-platform><microservices>,1,730,8,0.0,1,"<p>I plan to switch from a single app on a project to multiple apps on a project.&#xA;One being the current non-UI app and one will be based on Django.&#xA;I'm writing the code in Python2.7</p>&#xA;&#xA;<p>I saw google example of app.yaml, but there is no examples for 2 or more apps.&#xA;There is already a similar question. but still with no example (<a href=""https://stackoverflow.com/questions/38125926/run-google-app-engine-application-with-microservice"">Run Google App Engine application with microservice</a>)</p>&#xA;&#xA;<p>How do i call Django microservice/module and how do i call the other app (microservice/module)?</p>&#xA;&#xA;<p>My current structure is:</p>&#xA;&#xA;<pre><code>main_app directory&#xA;- dj (django app)&#xA;-- dj.yaml&#xA;-- manage.py&#xA;-- __init__.py (empty)&#xA;-- polls (from django tutorial)&#xA;-- mysite (from django tutorial)&#xA;- otherapp&#xA;-- otherapp.yaml&#xA;-- something.py&#xA;- app.yaml&#xA;- cron.yaml&#xA;</code></pre>&#xA;&#xA;<p>Here is a part of my app.yaml (that should control both apps):</p>&#xA;&#xA;<pre><code>runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;&#xA;handlers:&#xA;- url: /.*&#xA;  script: main.app&#xA;- url: /uploadcsv/.*&#xA;  script: main.app&#xA;&#xA;&#xA;libraries:&#xA;- name: MySQLdb&#xA;  version: ""latest""&#xA;</code></pre>&#xA;"
45047011,Microservice architecture for ETL,2017-07-12 01:48:20,<web-services><architecture><etl><microservices><restful-architecture>,3,1201,2,2.0,1,"<p>I am redesigning a small monolith ETL software written in Python. I find a microservice architecture suitable as it will give us the flexibility to use different technologies if needed (Python is not the nicest language for enterprise software in my opinion). So if we had three microservices (call them Extract, Transform, Load), we could use Java for Transform microservice in the future.</p>&#xA;&#xA;<p>The problem is, it is not feasible here to pass the result of a service call in an API response (say HTTP). The output from Extract is going to be gigabytes of data.</p>&#xA;&#xA;<p>One idea is to call Extract and have it store the results in a database (which is really what that module is doing in the monolith, so easy to implement). In this case, the service will return only a yes/no response (was the process successful or not).</p>&#xA;&#xA;<p>I was wondering if there were a better way to approach this. What would be a better architecture? Is what I'm proposing reasonable?</p>&#xA;"
45095183,Low Level Protocol for Microservice Orchestration,2017-07-14 05:18:57,<rest><redis><network-programming><apache-zookeeper><microservices>,1,109,3,2.0,1,"<p>Recently I started working with Microservices, I wrote a library for service discovery using Redis to store every service's url and port number, along with a TTL value for the entry. It turned out to be an expensive approach since for every cross service call to any other service required one call to Redis. Caching didn't seem to be a good idea, since the services won't be up all the times, there can be possible downtimes as well.</p>&#xA;&#xA;<p>So I wanted to write a separate microservice which could take care of the orchestration part. For this I need to figure out a really low level network protocol to take care of the exchange of heartbeats(which would help me figure out if any of the service instance goes unavailable). How do applications like zookeeperClient, redisClient take care of heartbeats?</p>&#xA;&#xA;<p>Moreover what is the industry's preferred protocol for cross service calls? &#xA;I have been calling REST Api's over HTTP and eliminated every possibility of Joins across different collections.</p>&#xA;&#xA;<p>Is there a better way to do this?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44927532,How to get newly created resource to client with CQRS and event sourcing based microservices,2017-07-05 13:23:43,<microservices><cqrs><event-sourcing>,1,275,4,0.0,1,"<p>I'm experimenting with microservices, event sourcing and CQRS. However, I'm a little bit confused about how I go from issuing a command to performing a query to return the new state, specifically with regard to interactions with a web API gateway.</p>&#xA;&#xA;<p>As an example, the simple application I am attempting to write (which probably doesn't actually need any of these; it is just something to aid my learning) creates a random-graph and then performs some long-running calculations on the graph. I've modelled this as two separate services: the <code>GraphService</code> and the <code>ComputationService</code>. The imagined process flow is as follows:</p>&#xA;&#xA;<ol>&#xA;<li>User requests new random graph.</li>&#xA;<li>API gateway constructs <code>CreateGraph</code> command and sends it to the&#xA;<code>graph service</code>.</li>&#xA;<li><code>GraphService command handler</code> creates a graph and publishes a&#xA;<code>GraphCreated</code> event.</li>&#xA;<li><code>GraphService event handler</code> subscribes to topic for graph events,&#xA;processes <code>GraphCreated</code> event and stores graph in persistent read&#xA;storage.</li>&#xA;<li><strong>Client somehow gets the newly created graph.</strong></li>&#xA;<li><code>ComputationService event handler</code> subscribes to topic for graph&#xA;events, processes <code>GraphCreated</code> event and begins potentially&#xA;long-running computation, e.g. calculate diameter.</li>&#xA;<li><code>ComputationService</code> publishes <code>DiameterComputed</code> event.</li>&#xA;<li><code>GraphService</code> event handler subscribes to topic for computation&#xA;events, processed <code>DiameterComputed</code> event and updates the graph in&#xA;persistent read storage.</li>&#xA;<li>Client somehow gets updated - easier than getting the new graph, since already have an ID and can poll for changes / websockets / SSE, etc.</li>&#xA;</ol>&#xA;&#xA;<p>That seems relatively simple. However, my confusion lies in how to go about informing the API gateway, and thus the web client, of the new graph (as highlighted in bold above). In a typical CRUD process, the result of the <code>POST request</code> to create a new graph would be to return the URL of the new resource, for instance. However, with CQRS, commands should return nothing or an exception.</p>&#xA;&#xA;<p>How do I pass information back to the client of the service (in this case the API gateway) about the ID of the new graph so that it can perform a query to get the representation of the new resource and send it to the user? Or at least get an ID so that the web client can ask the API gateway, etc?</p>&#xA;&#xA;<p>As I see it at the moment, after sending a command, everyone is just left hanging. There needs to be some sort of subscription model that can be interrogated for the status of the graph creation. I considered having the API gateway generate a request ID which gets embedded with the <code>CreateGraph</code> command, but this then couples the service to the API.</p>&#xA;&#xA;<p>I'm obviously missing something, but have no idea what. None of the examples I've looked at or discussions I've read address this issue and assume that the ID of whatever resource is already known. I couldn't find any discussions here addressing this issue, but if I've just missed them, please point me there rather than duplicating questions. Any pointers would be hugely welcomed.</p>&#xA;"
48942153,Do we really need Event Sourcing and CQRS in microservices?,2018-02-23 06:11:21,<microservices><cqrs><event-sourcing>,3,1173,0,1.0,1,"<p>In my understanding when database transactions span across microservices ,we can solve this problem with using message-broker(kafka,RabbitMQ etc) by publishing events so that Subscriber Microservices can update their database by listening to these events.</p>&#xA;&#xA;<p>In case of exception we can send event for failure ,so that Subscriber services can update their state.</p>&#xA;&#xA;<p>Is this not sufficient? What is the problem with this approach?</p>&#xA;&#xA;<p>why and when we need event sourcing?</p>&#xA;&#xA;<p>Do we need really event sourcing ?</p>&#xA;"
48914388,Separating Node.js applications into multiple,2018-02-21 19:55:11,<node.js><mongodb><web-applications><passport.js><microservices>,1,37,1,2.0,1,"<p>So me being stupid didn't think about that I build my whole application front to back on one Node.js application instance. Now I have to figure out how to make each thing its own service. My current application has the front end (main site), front end (application/software part) and the backend all together. I need to figure out how best to separate these into front/main, auth, front/app and backend/app</p>&#xA;&#xA;<p>How would I even go about doing this? I would post code examples but I am sure that is too long and would not let me thanks to a code to word ratio on here. The git repo is not public either so can't post that.  </p>&#xA;&#xA;<p>My stack is mongo, node.js and express, I am using passport.js to go with it also.</p>&#xA;"
48838101,How to perform validation across services in microservices,2018-02-17 05:13:31,<domain-driven-design><microservices>,3,316,1,0.0,1,"<p>Suppose there are two microservices: Order and Intentory. There is an API in order service that takes ProductId, Qty etc and place the order.</p>&#xA;&#xA;<p>Ideally order should only be allowed to place if inventory exists in inventory service. People recommend to have Saga pattern or any other distributed transactions. That is fine and eventually consistency will be utilized.</p>&#xA;&#xA;<p>But what if somebody wants to abuse the system. He can push order with productid which are either invalid (or which are out of inventory). System will be taking all these orders and place these orders in queue and Inventory service will be handling these invalid order.</p>&#xA;&#xA;<p>Shouldn't this be handled upfront (in order service) rather than pushing these invalid orders to the next level (specially where productId is invalid)</p>&#xA;&#xA;<p>What are the recommendations to handle these scenarios?</p>&#xA;"
36812791,Doing compex reports with microservices,2016-04-23 15:36:11,<report><microservices>,1,1655,0,0.0,1,"<p>I'm starting a new project and am interested in architecting it as microservices. I'm trying to wrap my head around it:</p>&#xA;&#xA;<p>Say that I have an order service and a product service. Now I want to make a report service that gives me all orders that contain a product from a certain product category. </p>&#xA;&#xA;<p>Since order's dont know about products that means that I would need to fetch all orders, loop them and fetch products for each order and then return those how match. </p>&#xA;&#xA;<p>Is this assumption correct or is there any more efficient way of doing this with microservices?</p>&#xA;"
36715395,Clustering Microservices Components,2016-04-19 10:15:07,<cluster-computing><microservices>,1,10957,1,1.0,1,"<p>I have a Microservice that is realised as a Play framework based HTTP service. We now want to add fault tolerance to this service by having another instance that picks up the requests when one instance goes down. Now I understand that Microservices are not designed from the ground up to be clustered as they are purely stateless, self sustaining components that are meant to simply run.</p>&#xA;&#xA;<p>Are there ways wherein I could add failover support? I'm thinking of some external component that checks for the status of the service and reacts upon failures by starting another instance on some other host. Any suggestions?</p>&#xA;"
36660279,Microservice grouping of modules,2016-04-16 04:55:50,<soa><microservices>,1,116,4,1.0,1,"<p>I'm developing an Employee Management System and following a microservice-style architecture. Initially, I have created the ERD and designed several master maintenance tables like Department, Project, Position etc...</p>&#xA;&#xA;<p>My question is do I have to create a single service for each of these tables? or should I create a single service called master maintenance for all these tables?</p>&#xA;&#xA;<p>Please help me to decide. Thank you in advance.</p>&#xA;"
36716838,Microservice architecturs and layers,2016-04-19 11:18:52,<architecture><microservices>,1,483,5,1.0,1,"<p>Let's discuss the architecture of a microservice environment. We are having a discussion internally at our company and I'd like some feedback. What I'm having serious thoughts about are an orchestration layer (code duplication, more moving parts changing an api).</p>&#xA;&#xA;<h2>Option one - with orchestration layer:</h2>&#xA;&#xA;<p>webapp -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>In this case services are not allowed to talk to each other. Aggregated services in orchestration layer</p>&#xA;&#xA;<h2>Option one - without orchestration layer:</h2>&#xA;&#xA;<p>webapp -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> service -> persistance</p>&#xA;&#xA;<p>Here services are allowed to talk to each other, aggregated services exist here.</p>&#xA;&#xA;<h3>Specific questions:</h3>&#xA;&#xA;<ul>&#xA;<li>Where does billing belong?</li>&#xA;<li>Which solution do you prefer? Pros/cons.</li>&#xA;<li>Other suggestions?</li>&#xA;</ul>&#xA;"
36645517,REST api service context and resources url,2016-04-15 11:08:33,<java><rest><jersey><jax-rs><microservices>,3,910,7,1.0,1,"<p>We have serveral services running on an application server and every service has a context. The name of the service is automatically added to the url, since there can be multiple services on the same application server.<br>&#xA;Now we are creating a new service, which is called Draws, meaning the url will be</p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws"" rel=""nofollow"">http://url:port/Draws</a></p>&#xA;</blockquote>&#xA;&#xA;<p>However, now the discussion is the api paths (Resources) to this service. Since we are getting draws, in my mind this should be draws.&#xA;Which means it will have the url   </p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws/draws/"" rel=""nofollow"">http://url:port/Draws/draws/</a>{gameNo}</p>&#xA;</blockquote>&#xA;&#xA;<p>2x draws - <strong>Thoughts?</strong> </p>&#xA;&#xA;<p>There are thoughts here that the service does only have draws and therefor Draws/{gameNo} is enough.<br>&#xA;But in my mind, draws resource is the api interface of the service, like Draws is the book in a library, draws is the chapter... And it should be possible to add more chapters to the book.</p>&#xA;&#xA;<p>Then to implementation, we are using Jersey. That would mean we would have a resource with @Path(""{gameNo}"").</p>&#xA;&#xA;<p><strong>Edit 1:</strong><br>&#xA;There are gateways in front of our services, so the context will never be exposed to end users, it's only there to point to an specific service. Since multiple services can run on the same host:port</p>&#xA;&#xA;<p><strong>Edit 2:</strong><br>&#xA;Context part of the url is part of the service discovery lookup</p>&#xA;&#xA;<p><strong>Edit 3:</strong><br>&#xA;We are actually not versioning in url, but in Accept header, so actually my url is the same as clementinos but the version part of the url</p>&#xA;"
36744042,"REST, Pagination with filters dependent on external system and sql",2016-04-20 12:37:23,<rest><design><architecture><pagination><microservices>,2,163,7,0.0,1,"<p>I have a REST web-service which is expected to expose a paginated GET call.</p>&#xA;&#xA;<p>For eg: I have a list of students( ""Name"" , ""Age"" , ""Class"" ) in my sql table. And I have to expose a paginated API to get all students given a class. So far so good. Just a typical REST api does the job and pagination can be achieved by the sql query.</p>&#xA;&#xA;<p>Now suppose we have the same requirement just that we need to send back students who are from particular state. This information is hosted by a web-service, S2. S2 has an API which given a list of student names and a state ""X"" returns the students that belong to state X. </p>&#xA;&#xA;<p>Here is where I'm finding it difficult to support pagination. </p>&#xA;&#xA;<p>eg: I get a request with page_size 10, a class C and a state X which results in 10 students from class C from my db. Now I make a call to S2 with these 10 students and state X, in return, the result may include 0 students, all 10 students, or any number students between 0 and 10 from state 'X'.</p>&#xA;&#xA;<p>How do I support pagination in this case?</p>&#xA;&#xA;<p>Brute force would be to make db calls and S2 calls till the page size is met and then only reply. I don't like this approach .</p>&#xA;&#xA;<p>Is there a common practice followed for this, a general rule of thumb, or is this architecture a bad service design?</p>&#xA;&#xA;<p>(EDIT): Also please tell about managing the offset value. &#xA;if we go with the some approach and get the result set , how can I manage the offset for next page request ?</p>&#xA;&#xA;<p>Thanks for reading :)</p>&#xA;"
44642751,AWS Kinesis for Microservice Choreography,2017-06-20 02:15:51,<amazon-web-services><domain-driven-design><microservices><cqrs><event-sourcing>,1,614,0,0.0,1,"<p>I am trying to develop microservices for online shop using CQRS, DDD, and Event sourcing concept. I looked to AWS Kinesis as event stream. I think it would be good for choreographed microservices. I have 2 services, service for customer data and service for ordering system. I want to see total number of unpaid orders and the total amount of orders for each customer. So, I should send orderCreated event and orderPaid event to the service for customer data and recalculate the total unpaid orders and total amount of orders for related customer.</p>&#xA;&#xA;<p>Could I put the ordering system events to AWS Kinesis and listen it in command-side service for customer? Should I persist the events (orderCreated and orderPaid event) from AWS Kinesis to database in customer command-side service? Or is it ok to just update the customer query-side service only? Should I use AWS Lambda as event processor? Could you give me some best practices for this model?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
44554638,How do I guarantee that the interface between two microservices is not broken?,2017-06-14 20:58:56,<java><microservices>,3,160,2,0.0,1,"<p>Imagine we have two microservices: client and server. One of the most fundamental features of microservice architecture is an ability to have a separated pipelines for each microservice meaning that we have to be able to deploy them to production independently. </p>&#xA;&#xA;<p>This implies that different microservices may be developed by different teams and some of the features are developed faster on one microservice than on the another. This quite often ends up with the contract (interface) being broken between client and server, so the JSON that the client sends to the server is no more valid.</p>&#xA;&#xA;<p><strong>The question is how to prevent cases where communication between two microservices is broken due to a broken contract between them? What is the best strategy to handle such issues?</strong></p>&#xA;"
37699062,API vs Event in Microservice approach,2016-06-08 09:50:34,<soa><cqrs><microservices><event-sourcing><eda>,1,721,0,1.0,1,"<p>What about <a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""nofollow"">Smart endpoints and dumb pipes</a> in terms of different type of requests?</p>&#xA;&#xA;<p>After reading that I was thinking that it's enough to subscribe for some events and deal with that. But now I've realised that sometimes you should have opened API (maybe not for the end customers, but for the API Gateway etc). Is this ok? Or you should ""eventize"" (transform into event) any request which coming to Microservices cloud?</p>&#xA;&#xA;<p>So, for instance, you have Invoice and Order services.&#xA;It's clear that when order created you might use an event which might be consumed by Invoice service to create an invoice. It's clear that for receiving list of last user's orders you may use CQRS on Order service side or even just make new service LastOrders which will keep just projection of required data. But should this request transformed into event or LastOrders should provide API for that and listen for events to update it's own DB? </p>&#xA;"
37711051,Example open source microservices applications,2016-06-08 19:16:46,<microservices>,3,729,1,1.0,1,"<p>I'm looking for open source applications that demonstrate the <a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow"">microservices</a> pattern. In particular, I'd like to find one or more applications that can be spun up on real cloud environment up (but with fake data and requests) to demonstrate real-world deployment mechanics.</p>&#xA;&#xA;<p>Unfortunately, I haven't found any good options yet. I'll note that <a href=""https://www.discourse.org/"" rel=""nofollow"">Discourse</a> is a modern 3-tier application, using Rails API, Ember.js, Postgres, and Redis, but it still is much closer to a monolith than an example of microservices. The closest I've found so far is <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">https://github.com/kbastani/spring-cloud-microservice-example</a> but that is more of a framework than an actual application that delivers data.</p>&#xA;"
37679132,Load Balancing in Spring Cloud / Netflix OSS,2016-06-07 12:15:56,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-ribbon>,2,767,1,0.0,1,"<p>I am looking  at Spring Boot / Cloud and Netflix FWs (Eureka, Ribbon). I am working through this example:</p>&#xA;&#xA;<p><a href=""https://spring.io/blog/2015/07/14/microservices-with-spring"" rel=""nofollow"">https://spring.io/blog/2015/07/14/microservices-with-spring</a>&#xA;Basically it is about some small Spring Boot microservices that use the Eureka Service Registry. </p>&#xA;&#xA;<p>I now want to start several instances of the same service (in this example the AccountService, on different ports). Everything I read (above article, <a href=""http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/"" rel=""nofollow"">http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/</a> etc) suggests that if I do this, all instances get registered with Eureka redundantly and when I call the service, client-side load balancing is applied and the service to call is dynamically chosen.</p>&#xA;&#xA;<p>However, this is NOT what happens. When I start the first service instance, it gets registered and shows up in the Eureka Dashboard. When I start the same service on a different port, it also registers, but it seems to REPLACE the previous service instance: The Eureka Dashboard still only shows one instance with Availability Zones = 1 (should be 2?) and ALL calls to this service are handled by the second instance. When I query the registry, only this instance is applied.</p>&#xA;&#xA;<p>When I stop the second instance, after some time Eureka switches back to the first one and it still works. So it seems to keep all instances, but only ever uses the instance that was registered latest.</p>&#xA;&#xA;<p>Do I miss anything important? I thought all instances should be used simultaneously?</p>&#xA;&#xA;<p>==========&#xA;Application Properties are (those are practically unchanged to the example from the Spring Site):</p>&#xA;&#xA;<p><strong>EurekaServer</strong>  </p>&#xA;&#xA;<pre><code>eureka:  &#xA;  instance:  &#xA;    hostname: localhost  &#xA;  client:    &#xA;    registerWithEureka: false  &#xA;    fetchRegistry: false  &#xA;&#xA;server:  &#xA;  port: 1111     &#xA;&#xA;spring:  &#xA;  thymeleaf:  &#xA;    enabled: false  &#xA;</code></pre>&#xA;&#xA;<p><strong>AccountsServer</strong>  </p>&#xA;&#xA;<pre><code>spring:  &#xA;  application:  &#xA;    name: accounts-service  &#xA;  freemarker:  &#xA;    enabled: false           &#xA;  thymeleaf:  &#xA;    cache: false             &#xA;    prefix: classpath:/accounts-server/templates/      &#xA;&#xA;eureka:  &#xA;  client:  &#xA;    serviceUrl:  &#xA;      defaultZone: http://localhost:1111/eureka/  &#xA;&#xA;server:  &#xA;  port: 4444   # HTTP (Tomcat) port, for the second instance this is changed to a different port&#xA;</code></pre>&#xA;"
48251083,Deploying Spring boot application in AWS lambda,2018-01-14 15:24:55,<java><spring-boot><aws-lambda><microservices>,2,2243,0,0.0,1,"<p>I have an existing web application built in Javascript, Spring Boot and MySQL. I want to deploy the application (frontend + backend) in AWS Lambda. Please advise how can this be achieved, as I am not sure how each restful API call should be mapped to API gateway, that will in turn invoke the lambda functions (which should be the existing java methods from RestConroller).</p>&#xA;&#xA;<p>Thanks and appreciate your advise.</p>&#xA;"
48271493,Relation of Microservices and DDD CQRS and ES,2018-01-15 22:21:43,<domain-driven-design><microservices>,3,206,2,0.0,1,"<p>For the last couple of weeks I've been starting and trying to understand DDD CQRS, ES and Microservices. &#xA;I think I've understood them individually but not as a single unit so this is why I have some misunderstandings that I hope to clarify.</p>&#xA;&#xA;<p>So first what is the relation between Microservices and DDD, can you do one without the other?&#xA;And secondly, does Bounded Contexts translate in the end into a microservice ?</p>&#xA;"
37427976,How do micro services in Cloud Foundry communicate?,2016-05-25 04:41:47,<rest><communication><cloudfoundry><microservices><predix>,2,1076,0,0.0,1,"<p>I'm a newbie in Cloud Foundry. In following the reference application provided by Predix (<a href=""https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600"" rel=""nofollow"">https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600</a>), the application consisted of several modules and each module is implemented as micro service.</p>&#xA;&#xA;<p>My question is, how do these micro services talk to each other? I understand they must be using some sort of REST calls but the problem is:</p>&#xA;&#xA;<ol>&#xA;<li><p>service registry: Say I have services A, B, C. How do these components 'discover' the REST URLs of other components? As the component URL is only known after the service is pushed to cloud foundry.</p></li>&#xA;<li><p>How does cloud foundry controls the components dependency during service startup and service shutdown? Say A cannot start until B is started. B needs to be shutdown if A is shutdown.</p></li>&#xA;</ol>&#xA;"
37528335,Splitting monolith into microservices,2016-05-30 14:39:57,<spring><rest><spring-boot><microservices>,1,691,1,1.0,1,"<p>I have an existing web service that supports ordering and it has multiple operations (approximately 20). This is a single webservice that support the ordering function. It interacts with multiple other services to provide ordering capability. </p>&#xA;&#xA;<p>Since there is a lot of business functionality within this app and it is supported by a 10 member team , I believe it is a monolith (though I assume there is no hard and fast rule to define what a monolith is). </p>&#xA;&#xA;<p>We are planning to get the application deployed in cloud foundry environment and we are planning to split the app into 2-3 microservices , primarily to enable them scale independently. </p>&#xA;&#xA;<p>The first few apis which enable searching for a product typically have more number of hits whereas the api that support actual order submission receives less that 5% of the hits. So the product search api should have significantly larger number of instances as compared to order submission api. </p>&#xA;&#xA;<p>Though I am not sure if we could split is based on sub-domains (which I have read should be the basis) , we are thinking of splitting them based on the call sequence as explained earlier. </p>&#xA;&#xA;<p>I have also read that microservices should be choreographed and not orchestrated. However in order to ensure our existing consumers are not impacted , I believe we should expose a api layer which would orchestrate the calls to these microservices. Is providing an api gateway , the normal approach that is followed to ensure consumers do not end up calling multiple microservices and also provides a layer of abstraction? </p>&#xA;&#xA;<p>This seems to be orchestration more than choreography - though I am not hung up on the theoretical aspects , I would like to understand the different solutions that are pursued for this problem statement in an enterprise world.</p>&#xA;"
44060464,Managing table which is frequently updated and queried,2017-05-19 02:27:17,<mysql><sql><scalability><microservices><bigdata>,5,44,0,0.0,1,"<p>So far, I and my friend have made a small system which is for collecting weather data from sensors placed around our area.&#xA;Here is one of table in our database:</p>&#xA;&#xA;<pre><code>CREATE TABLE `Measurement` (&#xA;  `Id` varchar(255) COLLATE utf8_unicode_ci NOT NULL DEFAULT '',&#xA;  `SensorId` varchar(16) COLLATE utf8_unicode_ci NOT NULL,&#xA;  `Time` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',&#xA;  `Battery` double DEFAULT NULL,&#xA;  `Rain` double DEFAULT NULL,&#xA;  `Humidity` double DEFAULT NULL,&#xA;  PRIMARY KEY (`Id`,`Time`)&#xA;) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;&#xA;</code></pre>&#xA;&#xA;<p><strong>Environment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>ASP.Net Framework 4.6.</li>&#xA;<li>Web API 2.</li>&#xA;<li>MySQL Community edition.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Deployment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There is one database for storing user information, weather measurement and sensor information deployed onto a single server.</li>&#xA;<li>There is one WEB API to help client app to connect to and obtain data.</li>&#xA;</ul>&#xA;&#xA;<p>Our situation is:</p>&#xA;&#xA;<p>This table is for storing climate element measurements each 10 second from 60 sensors.&#xA;For now, we are facing a problem that data is increasing drammatically, just do the simple calculation:</p>&#xA;&#xA;<p><strong>1</strong> (record each 10 second) * <strong>6</strong> (records in one hour) * <strong>24</strong> (hours a day) * <strong>365</strong> (days a year) = <strong>52 560</strong> (records a year)</p>&#xA;&#xA;<p><strong>52 560</strong> (records a year) * <strong>60</strong> (sensors) = <strong>3 153 000</strong> (records)</p>&#xA;&#xA;<p>So, after a year of collecting data from <strong>60</strong> sensors, we have <strong>3 153 000</strong> records. That is too many records to store into one table (in my opinion).&#xA;That's why I'm thinking about a solution that:&#xA;- Divide measurement data of sensors into many database and deploy onto many servers. Each sensor will have one small PC to store its information (by using API)&#xA;- When user want to query database to search for their needed information, base on the information of sensor that they provide, Web server will make calls to different API endpoint to obtain data and summarize information then display them to UI.</p>&#xA;&#xA;<p>My question is:</p>&#xA;&#xA;<ul>&#xA;<li>Exclude the cost of PC we use to deploy our database and micro service of whether measurement. Is this deployment an efficient practise ?</li>&#xA;<li>Are there any way to manage this kind of Measurement table ? (Data is increasing each 10 second and can be queried many times) ?</li>&#xA;<li>If there is a way to optimize my table, please let me know ?</li>&#xA;<li>Should I deploy sensor measurement collecting function as micro services to increase performance and scalability ?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you,</p>&#xA;"
44114755,How to do 2 phase commit between two micro-services(Spring-boot)?,2017-05-22 13:55:56,<spring-boot><microservices><distributed-transactions><2phase-commit>,2,892,0,0.0,1,"<p>I Have two mico-serives A and B where they connect to seperate database, From Mico-serives A i need to persist(save) objects of both A and B in same transtation how to achive this.</p>&#xA;&#xA;<p>I am using Spring micro-servies with netflix-oss.Please give suggestions on best way to do achive 2 phase commit.</p>&#xA;"
44000812,consul - connect client to server,2017-05-16 11:56:48,<service><microservices><consul><service-discovery>,1,663,0,0.0,1,"<p>I'm new at consul and I try to setup a server-client environment. I have started my server with the following command and configuration:</p>&#xA;&#xA;<pre><code>consul.exe agent -ui -config-dir=P:\Consule\config&#xA;</code></pre>&#xA;&#xA;<p>The config file looks the following (""P:\Consule\config\server.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""bootstrap"": false,&#xA;    ""server"": true,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""P:\\Consule\\data"",&#xA;    ""log_level"": ""INFO""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Output when I start consul from commandline with above command:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Consul agent running!&#xA;       Version: 'v0.8.3'&#xA;       Node ID: '1a244456-e725-44be-0549-33603ea7087d'&#xA;       Node name: 'MYCOMPUTERNAMEA'&#xA;       Datacenter: 'myservices'&#xA;       Server: true (bootstrap: false)&#xA;       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600)&#xA;       Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)&#xA;       Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false&#xA;       Atlas: &lt;disabled&gt;&#xA;</code></pre>&#xA;&#xA;<p>Now, at another computer in my domain I try to run an consul client with follwoing commandline and config-file:</p>&#xA;&#xA;<pre><code>consul.exe agent -config-dir C:\Consul -bind=127.0.0.1&#xA;</code></pre>&#xA;&#xA;<p>Config file (""C:\Consul\client.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""server"": false,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""C:\\TEMP"",&#xA;    ""log_level"": ""INFO"",&#xA;    ""start_join"": [""MYCOMPUTERNAMEA""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I always get follwing output/error message:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Joining cluster...&#xA;==&gt; 1 error(s) occurred:&#xA;&#xA;* Failed to join &lt;IP_OF_MYCOMPUTERNAMEA&gt;: dial tcp &lt;IP_OF_MYCOMPUTERNAMEA&gt;:8301: connectex: No connection could be made because the target machine actively refused it.&#xA;</code></pre>&#xA;&#xA;<p>Does anyone know what I'm doing wrong?</p>&#xA;&#xA;<p>Thanks and best regards</p>&#xA;"
44169046,How to manage microservice failure?,2017-05-24 21:49:57,<microservices>,4,227,1,0.0,1,"<p>Let's say, I have several micro-services (REST API), the problem is, if one service is not accessible (let's call service ""A"" ) the data which was sending to service ""A"" will be saved in temporary database. And after service worked, the data will be sent again. &#xA;Question:&#xA;1. Should I create the service which pings to service ""A"" in every 10 seconds to know service works or not? Or is it possible to do it by task queue? Any suggestions? </p>&#xA;"
44063886,How to achieve orchestration with spring boot micro service?,2017-05-19 07:21:59,<spring-boot><microservices><orchestration>,1,1793,2,0.0,1,<p>what is best way to orchestrate micro services in spring boot.</p>&#xA;
44186109,Share Domain DLL between webjob and web api?,2017-05-25 17:09:14,<c#><azure><domain-driven-design><microservices>,1,208,4,0.0,1,<p>I use webjob to process messages queue and web API to process REST request.&#xA;What is the solution for share domain between this two application types that have the same bounded context? &#xA;Can I reference the same Domain DLL or it is a bad design choose?</p>&#xA;
35684313,Run all microservices in a multi-project gradle build,2016-02-28 15:22:47,<gradle><microservices>,1,616,1,0.0,1,"<p>I have a multi-project gradle build that's roughly set up like this:</p>&#xA;&#xA;<pre><code>RootProject&#xA;- ServiceA&#xA;- ServiceB&#xA;- ServiceC&#xA;- UI&#xA;</code></pre>&#xA;&#xA;<p>Each of these subprojects is using the Spark framework and runs an embedded web server.  It's basically a microservices setup, so they all need to be up and running for the system as a whole to work.</p>&#xA;&#xA;<p>They each have a task defined like this:</p>&#xA;&#xA;<pre><code>task runApp(type: JavaExec) {&#xA;    main = 'App'&#xA;    classpath = sourceSets.main.runtimeClasspath&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I know I can manually start each service either through my IDE or by opening a different terminal for each sub-project and running <code>gradlew ServiceA:runApp</code>, but what I'd like to do is create a <code>runSystem</code> task at the root level that will fire up everything to make it easy to run the whole system during development.</p>&#xA;&#xA;<p>How can I do this with Gradle?</p>&#xA;"
46283367,What are Hystrix benefits over normal exception handling?,2017-09-18 15:45:14,<microservices><hystrix>,4,600,0,0.0,1,"<p>I'm really new to Hystrix topic and concept of resilient services. I was going through some course and this question came into my mind. In Hystrix I need to define fallback method for a gracefull degradation. This method is then called when circuit is broken. But I can imagine to just wrap code with try and catch and when particular exceptions appear (for timeout for instance) and then call fallback method in catch clause. When called service is up then normal code would be called. Of course with Hystrix I can additionally monitor this, but what else it gives me ?. I'm pretty sure that I don't understand whole concept. </p>&#xA;"
46462610,monorepo VS. github submodules,2017-09-28 06:45:22,<git><github><microservices>,1,1447,0,0.0,1,"<p>Our app is built in microservice architecture, one service one repo. We are exploring whether we should create a monorepo, as many companies are following this practice. There are plenty of discussions about the pros and cons for mono vs. many. If we want to find an alternative to allow us have some cons from both options, should we use git submodules to provide 'looks-alike' mono structure? </p>&#xA;"
46432262,How to achieve Statefullness in Microservices,2017-09-26 17:12:03,<microservices><stateful>,2,644,4,1.0,1,"<p>I have two microservices 1) Product Microservices 2) Checkout Microservices both are spring boot projects. In Checkout Microservice , i should get all the products that i have shopped, means my microservices should be STATEFUL to know what happend previously. Please suggest examples on how to achieve the statefulness it can be like Asyncronous with event source with Kafka/RabbitMQ. But please suggest architecture, code, example in detail how to get product details in checkout service.</p>&#xA;"
46451544,C++ MicroServices with desktop application,2017-09-27 15:16:38,<c++><microservices><desktop>,1,807,7,1.0,1,<p>I got a desktop application and it's getting bigger and bigger. And i wonder if i can make something like microservices with desktop application? I want to application for now stays desktop. Application it's written in C++.&#xA;I can exclude some of the modules with some preparations.&#xA;But is it possible and if anybody have idea how to start with this?</p>&#xA;
40832097,MockMvc returns null instead of object,2016-11-27 18:00:32,<spring><spring-mvc><junit><mockito><microservices>,1,2210,2,1.0,1,"<p>I am developing a microservice application and I need to test a post request &#xA;to a controller. Testing manually works but the test case always returns null.</p>&#xA;&#xA;<p>I've read many similar questions here in Stackoverflow and documentation but haven't figured out yet what I am missing.</p>&#xA;&#xA;<p>Here is what I currently have and what I tried in order to make it work:</p>&#xA;&#xA;<pre><code>//Profile controller method need to be tested&#xA;@RequestMapping(path = ""/"", method = RequestMethod.POST)&#xA;public ResponseEntity&lt;Profile&gt; createProfile(@Valid @RequestBody User user, UriComponentsBuilder ucBuilder) {&#xA;    Profile createdProfile = profileService.create(user); // line that returns null in the test&#xA;    if (createdProfile == null) {&#xA;        System.out.println(""Profile already exist"");&#xA;        return new ResponseEntity&lt;&gt;(HttpStatus.CONFLICT);&#xA;    }&#xA;    HttpHeaders headers = new HttpHeaders();&#xA;    headers.setLocation(ucBuilder.path(""/{name}"").buildAndExpand(createdProfile.getName()).toUri());&#xA;    return new ResponseEntity&lt;&gt;(createdProfile , headers, HttpStatus.CREATED);&#xA;}&#xA;&#xA;//ProfileService create function that returns null in the test case&#xA;public Profile create(User user) {&#xA;    Profile existing = repository.findByName(user.getUsername());&#xA;    Assert.isNull(existing, ""profile already exists: "" + user.getUsername());&#xA;&#xA;    authClient.createUser(user); //Feign client request&#xA;&#xA;    Profile profile = new Profile();&#xA;    profile.setName(user.getUsername());&#xA;    repository.save(profile);&#xA;&#xA;    return profile;&#xA;}&#xA;&#xA;// The test case&#xA;@RunWith(SpringRunner.class)&#xA;@SpringBootTest(classes = ProfileApplication.class)&#xA;@WebAppConfiguration&#xA;public class ProfileControllerTest {&#xA;&#xA;    @InjectMocks&#xA;    private ProfileController profileController;&#xA;&#xA;    @Mock&#xA;    private ProfileService profileService;&#xA;&#xA;    private MockMvc mockMvc;&#xA;&#xA;    private static final ObjectMapper mapper = new ObjectMapper();&#xA;&#xA;    private MediaType contentType = MediaType.APPLICATION_JSON;&#xA;&#xA;    @Before&#xA;    public void setup() {&#xA;        initMocks(this);&#xA;        this.mockMvc = MockMvcBuilders.standaloneSetup(profileController).build();&#xA;    }&#xA;    @Test&#xA;    public void shouldCreateNewProfile() throws Exception {&#xA;&#xA;        final User user = new User();&#xA;        user.setUsername(""testuser"");&#xA;        user.setPassword(""password"");&#xA;&#xA;        String userJson = mapper.writeValueAsString(user);&#xA;&#xA;        mockMvc.perform(post(""/"").contentType(contentType).content(userJson))&#xA;                .andExpect(jsonPath(""$.username"").value(user.getUsername()))&#xA;                .andExpect(status().isCreated());&#xA;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Tried to add <code>when</code>/<code>thenReturn</code> before post but still returns 409 response with null object.</p>&#xA;&#xA;<pre><code>when(profileService.create(user)).thenReturn(profile);&#xA;</code></pre>&#xA;"
40840470,MYSQL primary key strategy for microservices architecture,2016-11-28 09:02:37,<mysql><microservices>,2,169,5,0.0,1,"<p>We are currently using auto-generated primary keys and we would like to switch to an approach which is more suitable for microservices-based applications: either we are going to use business defined primary key (a tax code for persons) or global unique identifiers.</p>&#xA;&#xA;<ul>&#xA;<li>In the past, MySQL had performance issues when using alphanumeric primary keys instead of autoincrement, is it still the case? </li>&#xA;<li>Is it possible, if we go for the UUID approach, to use a strong uuid generator which will guarantee the uuid will be unique even across different servers?</li>&#xA;</ul>&#xA;"
43870576,Batch - Get Requests from different Microservices,2017-05-09 13:01:35,<rest><get><microservices>,2,368,3,0.0,1,"<p>I am dividing a monolithic service to a microservice architecture. What I have done is separate the services and now the REST call is distributed but the problem is if I call a <code>service A</code> which returns 10000 instances and it is dependent on some other <code>service B</code>, so call comes to <code>service A</code> and for each instance, call goes to <code>service B</code> to get its data, so converting a single call to 10000 additional calls so now the call takes alot of time. </p>&#xA;&#xA;<p>I want to make multiple Get Requests in a single request. </p>&#xA;&#xA;<p>What I have searched is to use batch requests to POST different instances, but this is recommended on Creating &amp; Updating multiple instances together. Can this be done for getting information as well? </p>&#xA;&#xA;<p>And is there any other way to do it?</p>&#xA;&#xA;<p>Edit: A similar use case as to mine e.g. There are two services one service gets the details of students and the other gets the details of teachers. In teachers table there is student's ID that it teaches not as a foreign key but a simple key, Now in the UI for the teacher, it shows the teacher details and the student ID and student names and class it belongs to, so for getting the student name and class details, I would have to call the student's service with the student's ID.</p>&#xA;"
43910795,Microservices async operation HTTP response,2017-05-11 08:53:19,<http><asynchronous><architecture><microservices><event-driven>,1,182,9,1.0,1,"<p>We're building a microservice app where clients can create <em>projects</em>. The following diagram shows the technical flow of this process:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/UWDMy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UWDMy.png"" alt=""Create Project Flow""></a></p>&#xA;&#xA;<p>My question: <strong>what HTTP response should the API gateway return to the client (step 1.)?</strong> </p>&#xA;&#xA;<p>My initial idea was to give back a 202, but the problem there is that I don't know the <code>Location</code> yet (<code>/projects/{id}</code>), because the id of the <em>project</em> will be created at the Project Management Service.</p>&#xA;"
49992237,"If there are multiple microservices, how should I integration test them?",2018-04-24 01:42:04,<docker><go><microservices>,3,110,0,0.0,1,"<p>I am learning microservice architecture, but now there is some confusion.</p>&#xA;&#xA;<h3>situation</h3>&#xA;&#xA;<ul>&#xA;<li>there are 4 projects written in <code>golang</code>&#xA;&#xA;<ol>&#xA;<li><strong>orderService</strong></li>&#xA;<li><strong>userService</strong></li>&#xA;<li><strong>tools</strong></li>&#xA;<li><strong>web</strong> ( forward <code>HTTP</code> request )</li>&#xA;</ol></li>&#xA;<li><code>orderService</code> , <code>userService</code>, <code>web</code> communicate via <code>grpc</code></li>&#xA;<li>all api requests through <code>web</code> forwarding to <code>orderService</code> or <code>userService</code></li>&#xA;<li><code>orderService</code> and <code>userService</code> have their own independent database</li>&#xA;<li>they are all in <code>docker</code> containers</li>&#xA;</ul>&#xA;&#xA;<h3>confusion</h3>&#xA;&#xA;<p>when I want to test a request, I have to do the following steps:</p>&#xA;&#xA;<pre><code>cd orderService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd userService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd web&#xA;govender update +vendor&#xA;go build&#xA;&#xA;docker-compose build&#xA;docker-compose up&#xA;</code></pre>&#xA;&#xA;<p>when I changed some code, I have to do this steps again.<br>&#xA;I think this is unscientific and abnormal.  I want to know whether all of these steps are necessary to integration test four microservices in docker.</p>&#xA;"
49985156,Aggregates in Event Sourcing Pattern,2018-04-23 15:50:51,<java><aggregate><microservices><event-sourcing>,1,128,4,0.0,1,"<p>I am dipping my feet into event sourcing pattern and trying to make sense of aggregates.I have read a few blogs and now I am more confused than ever before.</p>&#xA;&#xA;<p>From what I inferred aggregates should somehow enable user to run different queries on the event store to retrieve different stream of events.</p>&#xA;&#xA;<p>Use case :</p>&#xA;&#xA;<ol>&#xA;<li><p>I want to <strong>replay</strong> events on an invoice where the I want to see all actions done by  a specific employee on the balance.</p></li>&#xA;<li><p>I want to <strong>replay all</strong> events on an invoice </p></li>&#xA;</ol>&#xA;&#xA;<p>I hope these are valid use cases.</p>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | EmployeeId | Event            | Payload |&#xA;|----------|------------|------------|------------------|---------|&#xA;| 1        | 12345      | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | 45567      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | 77341      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | 98421      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status of invoice&#xA;Status is(Review,Billed,Paid)</p>&#xA;&#xA;<p>So from my understanding there needs to be 5 components . </p>&#xA;&#xA;<ol>&#xA;<li>Event- A specific event.</li>&#xA;<li>Event Source - The service that calls repo to get related events</li>&#xA;<li>Event Stream - A list of events</li>&#xA;<li>Command - A request operation on invoice</li>&#xA;<li>Aggregate -  An api to decide on inputs to load events </li>&#xA;</ol>&#xA;&#xA;<p>I understand how other things play but having a hard time wrapping my head around Aggregate. What is it ?</p>&#xA;&#xA;<p>Will I have two aggregate classes </p>&#xA;&#xA;<ul>&#xA;<li>AggregateEventsByInvoice</li>&#xA;<li>AggregateEventsByInvoiceEmployee</li>&#xA;</ul>&#xA;&#xA;<p>I really am having a hard time figuring out the need and use of aggregate . All the examples I have seen use UUID which does not make sense to me at all? Any help will be greatly appreciated.</p>&#xA;"
50041559,How to share common Data over several Microservices,2018-04-26 11:15:02,<domain-driven-design><microservices>,2,87,5,1.0,1,"<p>I'm writing a Bachelors-Thesis about Microservices.</p>&#xA;&#xA;<p>I'm trying to split a monolith into Microservices and now I ran into a problem that there are some tables in a Database, that are relevant for more than one Microservice.&#xA;There is no chance to split this data into domain specific views.</p>&#xA;&#xA;<p>My approach is that I will create a new Database Schema with that specific tables and let all Microservices read from it.&#xA;That would be a shared kernel approach which is not recommended by the experts of Microservices.</p>&#xA;&#xA;<p>Do you have any experience or recommendations about this problem?</p>&#xA;&#xA;<p>Do you have any recommendations about books which are about similar problems?</p>&#xA;"
47343439,microservice not able to locate zipkin service using discovery-server,2017-11-17 04:44:23,<spring-boot><microservices><spring-cloud><zipkin><eureka>,1,770,2,0.0,1,"<p>I have mircroservice environment based on spring-boot, where i am using zipkin server and discovery-server(eureka) and config-server. Now i have a rest-microservice which sends logs to zipkin server and this microservice is required to resolve where is zipkin server using discovery-server.</p>&#xA;&#xA;<p>following is zipkin configuration i have in my rest-microservice's application.properties(pulled from config-server).</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://MTD-ZIPKIN-SERVER/&#xA;spring.zipkin.locator.discovery.enabled=true&#xA;spring.zipkin.enabled=true&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>here MTD-ZIPKIN-SERVER is zipkin-server name in discovery-server.</p>&#xA;&#xA;<p>discovery-server dashboard.&#xA;<a href=""https://i.stack.imgur.com/SNliR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SNliR.png"" alt=""enter image description here""></a>&#xA;but it does not try to resolve zipkin from discovery-server, instead it tries to connect directly using spring.zipkin.baseUrl, and i get below exception.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Dropped 1 spans due to ResourceAccessException(I/O error on POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER)</p>&#xA;  &#xA;  <p>org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER     at&#xA;  org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:666)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.execute(RestTemplate.java:628)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:590)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.post(RestTemplateSender.java:73)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.sendSpans(RestTemplateSender.java:46)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$BoundedAsyncReporter.flush(AsyncReporter.java:245)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$Builder.lambda$build$0(AsyncReporter.java:166)&#xA;    at zipkin.reporter.AsyncReporter$Builder$$Lambda$1.run(Unknown&#xA;  Source)   at java.lang.Thread.run(Thread.java:745) Caused by:&#xA;  java.net.UnknownHostException: MTD-ZIPKIN-SERVER  at&#xA;  java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)&#xA;    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</p>&#xA;</blockquote>&#xA;&#xA;<p>if i provide exact zipkin url in property spring.zipkin.baseUrl like below</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://localhost:5555/&#xA;</code></pre>&#xA;&#xA;<p>then my rest-microservice is able to connect to zipkin-server.</p>&#xA;&#xA;<p>My goal here is to read zipkin-server location from discovery-srever. What am i doing wrong? Do i need to add some zipkin enabling annotation on my spring-boot rest-microservice?</p>&#xA;"
51993175,org.springframework.web.client.ResourceAccessException: I/O error on GET request for in Microservices,2018-08-23 19:39:44,<spring><spring-boot><microservices>,2,49,5,1.0,1,"<p>I am developing microservices code from the link : <a href=""https://github.com/sivaprasadreddy/spring-boot-microservices-series"" rel=""nofollow noreferrer"">https://github.com/sivaprasadreddy/spring-boot-microservices-series</a>. In this code base, I was successfully able to start the services like <code>""config-service""</code>, <code>""service-registry""</code>, <code>""shoppingcart-ui""</code>, <code>""zipkin-server""</code> etc, but when I tried to start the <code>""inventory-service""</code>, I got the below error. </p>&#xA;&#xA;<p><strong>Error below for reference:-</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8200/v1/secret/inventory-service"": Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:732) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:332) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.lambda$doRead$1(VaultTemplate.java:320) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doWithSession(VaultTemplate.java:307) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doRead(VaultTemplate.java:317) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.read(VaultTemplate.java:212) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.doGetSecrets(SecretLeaseContainer.java:545) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.start(SecretLeaseContainer.java:357) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.addRequestedSecret(SecretLeaseContainer.java:316) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.loadProperties(LeaseAwareVaultPropertySource.java:147) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.&lt;init&gt;(LeaseAwareVaultPropertySource.java:133) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:151) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:88) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.doCreatePropertySources(VaultPropertySourceLocatorSupport.java:170) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.createCompositePropertySource(VaultPropertySourceLocatorSupport.java:145) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.locate(VaultPropertySourceLocatorSupport.java:116) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94) [spring-cloud-context-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:636) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:376) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:328) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.sivalabs.inventoryservice.InventoryServiceApplication.main(InventoryServiceApplication.java:12) [classes/:na]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_162]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;</code></pre>&#xA;&#xA;<p><strong>I updated parent pom version to 2.0.4.RELEASE.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N574F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N574F.png"" alt=""enter image description here""></a></p>&#xA;"
52092546,Create Pub/Sub service WITHOUT third parties tool,2018-08-30 08:34:30,<c#><asp.net><microservices><publish-subscribe>,1,38,11,0.0,1,"<p>I would like to find a solution to create a pub/sub medium for 2 microservices to talk to each other,&#xA;I am aware i can use some third parties E.g Redis, RabbitMQ&#xA;<a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/multi-container-microservice-net-applications/integration-event-based-microservice-communications"" rel=""nofollow noreferrer"">Implementing event-based communication between microservices (integration events)</a></p>&#xA;&#xA;<p>The challenge lies on the client is unable to allow install any third parties tool due to security reason. &#xA;The messageQueue server in Windows won't be allowed to use too. &#xA;I can only use the applications that is only existed in the server.</p>&#xA;&#xA;<p>Therefore i am asking if there is anyway that i can create one simple app using windows service.&#xA;It is a one-to-many relationship. I have one service that will be dealing with data, once if there is any update, it will publish to those services that is subsribed to it.</p>&#xA;&#xA;<p>It seems my problem could be similar with </p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/9919804/net-scalable-pub-sub-service-implementation"">.NET Scalable Pub/Sub service implementation</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/391296/wcf-pub-sub-with-subscriber-caching"">WCF Pub/Sub with subscriber caching</a>(link is dead on the WCF pub-sub)</p>&#xA;&#xA;<p>but i dont see any critical solutions. </p>&#xA;&#xA;<p>I was thinking to use data notifications that MSSQL offers as last alternatives, but seems like it could cause a bottle neck when the applications get scale up. &#xA;The internet is so much flooded with articles using third parties tool. </p>&#xA;&#xA;<p>Thanks </p>&#xA;"
43132158,How to apply different policies to service and proxy service?,2017-03-31 03:54:03,<mule><microservices>,4,213,0,0.0,1,"<p>I have a mule service, named IS, deployed on mule runtime and proxied on API gateway. I'd like to set up different policies to the IS and its proxy service. How can I do it?</p>&#xA;&#xA;<p>My environment:</p>&#xA;&#xA;<ul>&#xA;<li>Mule runtime: 3.7.4</li>&#xA;<li>Mule API gateway: 2.1.1</li>&#xA;</ul>&#xA;"
43243883,"distributed transactions in microservice architecture, how to handle timeouts and failed commits",2017-04-06 00:49:46,<rest><rabbitmq><microservices><distributed-transactions>,1,787,2,0.0,1,"<p>Lets say you have a service <code>A</code> that is part of large microservice architecture, where those services communicate between each other either via REST APIs or via messaging where some broker is involved (RabbitMQ). Service <code>A</code> expose REST endpoint that needs to communicate with some 3rd party service (so with service that is not in our architecture) and to create some stuff there, when service <code>A</code> receives a response from 3rd party that everything went good there, it should persist some data from that response in its own database. </p>&#xA;&#xA;<p>What would be the best way of covering following issues, having in mind that 3rd party does not provide any idempotence mechanism.</p>&#xA;&#xA;<ol>&#xA;<li><p>Creation on 3rd party side went good, but DB write failed in service <code>A</code>. This would lead to inconsistent state, you created something on 3rd party side, but you don't have needed data about it in your own database.</p></li>&#xA;<li><p>You received timeout from 3rd party, so you can't just repeat the call, cause they are not providing any idempotence mechanism. If you repeat the call, potentially you can end with two (or more) created resources instead of one.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem number 1. could be solved having whatever retry mechanism that could retry DB call for whatever number of times. Problem with that approach is that, if service <code>A</code> instance that is repeating the DB call goes down suddenly. </p>&#xA;&#xA;<p>Presumably, better approach would be that service after successful creation on 3rd party side, publish a RabbitMQ message about successful creation. This service would listen to that message and it could do DB call when it receive the message. Having nice retry mechanism and taking benefit of ACKing messages, one could solve the issue about, <code>What if service instance goes down suddenly</code>. <strong>So in this solution service is publisher and consumer of its own message(s).</strong> Any better idea? This solution will also introduce <strong>eventual-consistency</strong>, because API caller (guy who is calling service <code>A</code> endpoint) will receive response <strong>right after</strong> successful creation on 3rd party side, <strong>but before</strong> anything is persisted in service database (what API client need actually)</p>&#xA;&#xA;<p>What about timeout problem? <strong>How one would handle timeouts from 3rd party in this case?</strong>. I don't see anything better than issuing GET calls to check do they created something. Still again that GET call can fail, but it can be repeated until it succeed. Here also marginal use case is what if service goes down in time of issuing GET calls.</p>&#xA;"
37176069,Docker container A dies after excuting query(insert/update) in cassandra running as another docker service B,2016-05-12 02:05:36,<python><docker><cassandra><microservices>,1,149,0,3.0,1,"<p>I am new to docker,Cassandra . &#xA;well I'm facing a weird issue, any help as how I could debug this issue would be great. I am using </p>&#xA;&#xA;<pre><code> Cassandra 3.3.0, &#xA;native Cassandra-driver for python- 3.3.0 &#xA;Docker 1.11.1&#xA;</code></pre>&#xA;&#xA;<p>I have two containers one is hosting cassandra service say container A and from the other container say B i'm performing an insert query to cassandra container.&#xA;here once B executes the query to A just after this container B which is my service container dies . </p>&#xA;&#xA;<p><strong>Logs that i see in container B</strong></p>&#xA;&#xA;<pre><code>[start] application exit with code 0, killing container&#xA;</code></pre>&#xA;&#xA;<p>i dont see any other relevant logs to debug further as what is the reason so that i am container dies right after insert.</p>&#xA;&#xA;<p>Just to make sure i am not missing  any exception i am catching all exceptions&#xA;i.e BaseException . i have added few loggers their to track my issue however even container dies it never comes to this except block.</p>&#xA;&#xA;<p><strong>What i suspect</strong>  </p>&#xA;&#xA;<p>it seems docker has error in memory and the moment it will write , it dies or something else.</p>&#xA;&#xA;<p><strong>what  i tried also</strong></p>&#xA;&#xA;<p>i tried to run my code without docker container to see offending lines  if any. here without docker it works and no exceptions  comes. I also make sure  to shutdown the cassandra session. </p>&#xA;&#xA;<p>Please advise .. </p>&#xA;"
43440170,ReflectionTestUtils.setfield is not overriding the local project property attribute,2017-04-16 17:44:38,<java><spring><microservices>,3,438,0,0.0,1,"<p>I am struggling with how to override a property file inside a .yml file</p>&#xA;&#xA;<p>We use the Spring framework and use annotations (eg. @InjectMocks).</p>&#xA;&#xA;<p>I have a an attribute declared in a configuration project YML file called ""one-platform-properties"" called paysafe-ss-fx-service.yml.  It sets a variable called <code>maxRecoveryAge=0</code>.  It is essentially a time to live buffer.</p>&#xA;&#xA;<pre><code>  oneplatform:&#xA;  environment: local&#xA;publisher:&#xA;  rates:&#xA;    maxRecoveryAge: 0&#xA;    interPublishDelay: 500&#xA;</code></pre>&#xA;&#xA;<p>The problem is that I want to be able to adjust this at run time in my tests.  Make the buffer to 1 hour, 5 hours and 24 hours.</p>&#xA;&#xA;<p>I am using the <code>ReflectionTestUtils.setfield(PublisherClass, ""maxDocumentAge"", 1, int.class)</code> call in my tests to adjust the timing, but the value is not being overridden.  When I do a watch on the variable it is working in my test harness, but once the test run penetrates into the micro service code, the overridden value is lost.  Any ideas on how to have the overridden value persist throughout all the tests?</p>&#xA;&#xA;<p>My goal is to use different variations on my test run:</p>&#xA;&#xA;<pre><code>ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",1,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",5,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",24,int.class);&#xA;</code></pre>&#xA;&#xA;<p>and essentially override the value as defined in the project defined properties file.</p>&#xA;"
43350278,SemVer and Microservices,2017-04-11 15:29:38,<architecture><microservices><semantic-versioning>,2,289,3,0.0,1,"<p>Are there any best practices/patterns for applying SemVer in a microservice'd product? Should there be SemVer for each microservice, and SemVer for the overall product?</p>&#xA;&#xA;<p>Example- I have a product called <code>SuperDatabase</code> with 3 microservices called <code>SuperDatabaseCore</code>, <code>SuperDatabaseReports</code>, and <code>SuperDatabaseSearch</code>.</p>&#xA;&#xA;<p>Initial Release:&#xA;<code>SuperDatabase v1.0.0</code>&#xA;<code>SuperDatabaseCore v1.0.0</code>&#xA;<code>SuperDatabaseReports v1.0.0</code>&#xA;<code>SuperDatabaseSearch v1.0.0</code></p>&#xA;&#xA;<p>Minor Update to Report:&#xA;<code>SuperDatabaseReport v1.1.0</code></p>&#xA;&#xA;<p>Should the product be <code>SuperDatabase v1.1.0</code> now?</p>&#xA;&#xA;<p>What if later there is a patch to Search:&#xA;<code>SuperDatabaseSearch v1.0.1</code></p>&#xA;&#xA;<p>Should the product versioning be changed again? Should the product version be completely independent of the microservice? Should it use SemVer at all? Or should it not have any versioning?</p>&#xA;"
43424176,How to send various command type by MassTransit and RabbitMQ?,2017-04-15 09:01:03,<c#><rabbitmq><microservices><masstransit>,1,1238,4,0.0,1,"<p>I’m a beginner in using message brokers.<br/>&#xA;We have a ticketing service which has multiple sub service. A supervisor service gets requests with help of a web API and sends them to sub services.<br/>&#xA;Any request has a header which is used to detect command type (such as Reserve, Refund, Availability or etc.). We use json for serializing objects.<br/>&#xA;Now, How to send various message types(different objects) by MassTransit from a publisher such as our supervisor system, in a way that consumer can use it easily?<br/>&#xA;In general, is it possible to send various message type in MassTransit and rabbitMQ?<br/>&#xA;Every consumer has only one queue for processing received messages.</p>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<blockquote>&#xA;  <h1>Update</h1>&#xA;</blockquote>&#xA;&#xA;<p><code>https://dotnetcodr.com/2016/08/02/messaging-with-rabbitmq-and-net-review-part-1-foundations-and-terminology/</code> <br/></p>&#xA;&#xA;<p>I read This posts suit to start in messaging with MassTransit and didn't see any example to using various message types on these and another resources:</p>&#xA;&#xA;<p>I have multiple commands and need various message types to send with them, but in examples only use a message type such as below:</p>&#xA;&#xA;<p><strong>Sender</strong></p>&#xA;&#xA;<pre><code>    private static void RunMassTransitPublisherWithRabbit()&#xA;    {&#xA;        string rabbitMqAddress = ""rabbitmq://localhost:5672/Ticket"";&#xA;        string rabbitMqQueue = ""mycompany.domains.queues"";&#xA;        Uri rabbitMqRootUri = new Uri(rabbitMqAddress);&#xA;&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            rabbit.Host(rabbitMqRootUri, settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;        });&#xA;&#xA;        Task&lt;ISendEndpoint&gt; sendEndpointTask = rabbitBusControl.GetSendEndpoint(new Uri(string.Concat(rabbitMqAddress, ""/"", rabbitMqQueue)));&#xA;        ISendEndpoint sendEndpoint = sendEndpointTask.Result;&#xA;&#xA;        Task sendTask = sendEndpoint.Send&lt;IRegisterCustomer&gt;(new&#xA;        {&#xA;            Address = ""New Street"",&#xA;            Id = Guid.NewGuid(),&#xA;            Preferred = true,&#xA;            RegisteredUtc = DateTime.UtcNow,&#xA;            Name = ""Nice people LTD"",&#xA;            Type = 1,&#xA;            DefaultDiscount = 0&#xA;        });&#xA;        Console.ReadKey();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><strong>Receiver</strong></p>&#xA;&#xA;<pre><code>        private static void RunMassTransitReceiverWithRabbit()&#xA;    {&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            IRabbitMqHost rabbitMqHost = rabbit.Host(new Uri(""rabbitmq://localhost:5672/Ticket""), settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;&#xA;            rabbit.ReceiveEndpoint(rabbitMqHost, ""mycompany.domains.queues"", conf =&gt;&#xA;            {&#xA;                conf.Consumer&lt;RegisterCustomerConsumer&gt;();&#xA;            });&#xA;        });&#xA;&#xA;        rabbitBusControl.Start();&#xA;        Console.ReadKey();&#xA;&#xA;        rabbitBusControl.Stop();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><code>IRegisterCustomer</code> is an interface and I can only get message content in  <code>rabbit.ReceiveEndpoint</code> and convert to usable object.</p>&#xA;&#xA;<p>Now, How to use various message types such as <code>IReserveTicket</code>, <code>IRefundTicket</code> and <code>IGetAvailability</code> to sending and receiving messages?</p>&#xA;&#xA;<p>Thanks again</p>&#xA;"
48043523,PACT provider verification against public APIs,2017-12-31 15:06:54,<microservices><pact><pact-jvm>,1,114,3,0.0,1,"<p>am trying to do test for consumer driver contract testing using pact jvm and able to generate consumer side contract file.During provider side verification, how to provide public API's instead of localhost most of the examples uses only localhost as provider, any help pls</p>&#xA;&#xA;<pre><code>@RunWith(PactRunner.class) // Say JUnit to run tests with custom Runner&#xA;@Provider(""WeatherProvider"") // Set up name of tested provider&#xA;@PactFolder(""D:\Workspace\pactConsumer\pactConsumer_v2\pacts"") // Point where to find pacts (See also section Pacts source in documentation)&#xA;@VerificationReports(value = {""markdown"",""json""}, reportDir = ""D:\Workspace\pactConsumer\pactConsumer_v2\target"")&#xA;&#xA;public class ProviderVerifyer {&#xA;@State(""Weather information is available for Chennai"") // Method will be run before testing interactions that require ""with-data"" state&#xA;public void getWeather() {&#xA;System.out.println(""Weather information is available for Chennai"" );&#xA;}&#xA;@TestTarget // Annotation denotes Target that will be used for tests&#xA;public final Target target = new HttpTarget(8114); // Out-of-the-box implementation of Target (for more information take a look at Test Target section)&#xA;&#xA;}&#xA;</code></pre>&#xA;"
42379365,How to see the output of a service in a docker stack?,2017-02-21 22:40:31,<docker><docker-compose><microservices><docker-swarm>,1,1050,0,0.0,1,"<p>With Docker Compose, when we run <code>docker-compose up</code> we see the output of all services being presented on the console, even with different colors to make it easier to distinguish them. Even if we have multiple instances of a service, the output of all of them appears there.</p>&#xA;&#xA;<p>Now, today I've tried deploying a stack to a swarm with Docker Compose v3 for the first time.</p>&#xA;&#xA;<p>After I do</p>&#xA;&#xA;<pre><code>docker deploy stack --compose-file=docker-compose.yml the_stack&#xA;</code></pre>&#xA;&#xA;<p>I can see the services running by using </p>&#xA;&#xA;<pre><code>docker service ls&#xA;</code></pre>&#xA;&#xA;<p>However, I'd like to see the output of the services as in Docker Compose.</p>&#xA;&#xA;<p>For instance, if I have a service <code>background_worker</code> with 3 replicas running in one node, I'd like to be able to see in that node the output of these replicas as I do with Docker Compose.</p>&#xA;&#xA;<p>How can I see the output of a replicated service deployed in a Docker Stack with Docker Swarm?</p>&#xA;&#xA;<p><strong>Edit</strong>: As answered, I need to enable experimental options on your docker daemon, however, I'm running this inside a docker-machine created with the hyperv driver, since it is not yet possible to run a multi-node swarm with Docker for Windows. How can I enable this inside the docker machine?</p>&#xA;"
42353292,Does Service Discovery microservice break idea of loose coupling?,2017-02-20 20:02:25,<microservices><service-discovery>,4,120,0,1.0,1,"<p>As a mechanism to connect microservices together and make them work it is usually suggested to use APIs and Service Discovery. But they usually work as their own microservices, but these ones should apparently be ""hard-coded"" into others, as every microservice is supposed to register with them and query for other microservices' locations. Doesn't this break the idea of loose coupling, since a loss of a discovery service implies others being unable to communicate?</p>&#xA;"
42230797,Spring Cloud Stream Kafka - Eventual consistency - Does Kafka auto retry unacknowledged messages (when using autocommitoffset=false),2017-02-14 16:02:42,<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,1,689,0,0.0,1,"<p>Implementing an eventually consistent distributed architecture has turned out to be a pain. There are tons of blog posts telling stories about how to do it, but not showing (code) how to actually do it.</p>&#xA;&#xA;<p>One of the aspects I'm suffering is having to deal with manual retries of the messages when they haven't been ack'd.</p>&#xA;&#xA;<p>For instance: my order service sends a pay event to Kafka. Payment Service is subscribed to it and processes it, answering with payment ok or payment failure</p>&#xA;&#xA;<ol>&#xA;<li><p>Ask for payment: <code>Order Service ----Pay event----&gt; Kafka ----Pay Event ----&gt; Payment Service</code></p></li>&#xA;<li><p>Payment OK: -> <code>Payment Service ----Payment ok event ----&gt; Kafka ----Payment ok Event ----&gt; Order Service</code></p></li>&#xA;<li><p>Payment Fail -> <code>Payment Service ----Payment failure event ----&gt; Kafka ----Payment failure Event ----&gt; Order Service</code></p></li>&#xA;</ol>&#xA;&#xA;<p>The point is: </p>&#xA;&#xA;<p>I know for sure when a message has been delivered to Kafka by using sync sendings. BUT, the only way I have to know that the payment has been processed by Payment Service is by expecting an answer event (Payment ok| Payment failure).</p>&#xA;&#xA;<p>This forces me to implement a retry mechanism in Order server. If it hasn't gotten an answer in some time, retry with a new Pay event.</p>&#xA;&#xA;<p>What's more, this also forces me to take care of duplicated messages in Payment Service in case they were actually processed but the answer didn't get to Order Service.</p>&#xA;&#xA;<p><strong>I was wondering if Kafka has a built in mechanism to send retries if the consumer didn't acknowledge the new offset of the messages</strong>.</p>&#xA;&#xA;<p>In Spring Cloud Stream we can set a <code>autoCommitOffset</code> property to false and handle the ack of the offset in the consumer:</p>&#xA;&#xA;<pre><code> @StreamListener(Sink.INPUT)&#xA; public void process(Message&lt;?&gt; message) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         System.out.println(""Acknowledgment provided"");&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p><strong>What happens if we don't execute <code>acknowledgment.acknowledge();</code> Will the message be automatically resent by Kafka to this consumer?</strong></p>&#xA;&#xA;<p>If it is possible we wouldn't need to retry manually any more and could do stuff like this:</p>&#xA;&#xA;<p>Paymen Service:</p>&#xA;&#xA;<pre><code> @Autowired&#xA; private PaymentBusiness paymentBusiness;&#xA;&#xA; @StreamListener(Sink.INPUT)&#xA; public void process(Order order) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         paymentBusiness(order);            &#xA;         //If we don't get here because of an exception &#xA;         //Kafka would retry...&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>If this were possible, how is the retry period configured in Kafka?</p>&#xA;&#xA;<p>In the worst case (and most likely) scenario, this isn't supported and we would have to retry manually. Do you know any real example of Spring Cloud Stream apps dealing with eventual consistency using Kafka?</p>&#xA;"
42311050,How to register spring boot microservices on spring cloud Netflix eureka?,2017-02-18 04:28:10,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix>,2,1029,1,0.0,1,"<p>We were planning to use spring cloud Netflix oss components. So I was doing a small sample project.&#xA;I developed 2 spring microservices and those services runs well on &#xA;<a href=""http://localhost:9000/microsvc-one"" rel=""nofollow noreferrer"">http://localhost:9000/microsvc-one</a> <a href=""http://localhost:9001/microsvc-two"" rel=""nofollow noreferrer"">http://localhost:9001/microsvc-two</a> </p>&#xA;&#xA;<p>And also wrote a sample spring cloud etflix eureka maven project which runs well on&#xA;<a href=""http://localhost:8761"" rel=""nofollow noreferrer"">http://localhost:8761</a></p>&#xA;&#xA;<p>I used annotations @EurekaDiscoveryClient and @SpringBootApplication on both the spring boot microservices main class</p>&#xA;&#xA;<p>I used annotation @EnableEurekaServer and @SpringBootApplication</p>&#xA;&#xA;<p>Now I am facing a problem in registering those services in eureka server. I referred some samples. I am not understanding those.&#xA; I did some changes in  application.yml files of microsvc-one and microsvc-two and also application.yml file of eureka server.&#xA;But still it shows empty. </p>&#xA;&#xA;<p>What all changes are required or missing or correct configuration to be done so that my services are being registered on eureka.</p>&#xA;&#xA;<p>I also have other question like do i need to create a separate project which has @EnableConfigServer and @SpringBootApplication Annotations other than the above 2 microservices and eureka server project module to register the services on eureka.&#xA;I see those in most of the examples.</p>&#xA;&#xA;<p>If yes..how do we link between all these?</p>&#xA;"
48482639,Node.js REST API wrapper for async messaging,2018-01-28 02:33:09,<node.js><rest><express><asynchronous><microservices>,3,130,3,1.0,1,"<p>Given an event driven micro service architecture with asynchronous messaging, what solutions are there to implementing a 'synchronous' REST API wrapper such that requests to the REST interface wait for a response event to be published before sending a response to the client?</p>&#xA;&#xA;<p>Example: POST /api/articles</p>&#xA;&#xA;<p>Internally this would send a CreateArticleEvent in the services layer, eventually expecting an ArticleCreatedEvent in response containing the ID of the persisted article.</p>&#xA;&#xA;<p>Only then would the REST interface response to the end client with this ID.</p>&#xA;&#xA;<p>Dealing with multiple simultaneous requests - is keeping an in-memory map of inflight requests in the REST api layer keyed by some correlating identifier conceptually a workable approach?</p>&#xA;&#xA;<p>How can we deal with timing out requests after a certain period?</p>&#xA;"
48438747,Jhipster microservices : How to create dynamic instances on microservices in production?,2018-01-25 08:40:53,<java><jhipster><microservices><production-environment>,2,210,5,0.0,1,"<p>I am using JHipster with 3 microservices (microservice1, microservice2, microservice3) applications, 1 JHipster registry application, and the API gateway. All applications are working as needed. I can  run my 5 applications in production without problem in mode one instance by application :</p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One instance</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>I want to have the following instance dynamically or with some automation : </p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One, two or more instances</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>But I wonder how to instance dynamically or manually more instance of microservice2. If I want to create a new instance of service what is the best practices? :&#xA; - In Jhipster configuration are set in application-prod.yml. The port is set are the creation of the application. I just avec one server.  So if I cannot create a new instance on the same server!  There is be a conflict IP/port because the port is configured in the application-prod.yml. How to solve it? I think it's not a good idea to create multiple configuration files with different ports in case I have to run others instances of my microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Is there another way to solve my problem?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading and for your ideas.</p>&#xA;"
48763985,Feasibility of Choosing EC2 + Docker As a Production Deployment Option,2018-02-13 09:59:48,<docker><amazon-ec2><microservices>,3,139,1,1.0,1,"<p>I am trying to deploy my microservice in EC2 machine. I already launched my Ec2 machine with Ubuntu 16.04 LTS AMI. And also I found that we can install docker and run containers through docker installation. Also I tried sample service deployment using docker in my ubuntu.I successfully run commands using -d option for running image in background also.</p>&#xA;&#xA;<ol>&#xA;<li>Here My confusion is that Can I choose this EC2 + Docker for deployment of my microservice for actual production environment? , Then I can deploy all my spring boot microservice in these option.</li>&#xA;</ol>&#xA;&#xA;<p>I know that ECS is another option for me.To be frank trying to avoid ECR, ECS optimized AMI and its burdens, Looking for machine with full control that only belongs to me. &#xA;                              But still I need to know about the feasibility of choosing EC2 + Docker through my Ubuntu machine.Also I am planning to deploy my angular 2. I don't need to install , deploy and manage any application server for both spring boot and angular.Since It will gives me about a serverless production environment to me.</p>&#xA;&#xA;<p>Can anyone help to clarify my doubts on choosing EC2 + Docker in production version for deploying my microservice? </p>&#xA;"
48743223,Sharing domain model classes (Aggregates) across two microservices,2018-02-12 09:34:50,<domain-driven-design><microservices>,1,138,3,0.0,1,"<p>Based on my limited knowledge, microservice can be designed at bounded context level or Aggregate level.</p>&#xA;&#xA;<p>If microservices are created at aggregate level, they might need to refer to an aggregate created in other microservices (as they share the same bounded context).</p>&#xA;&#xA;<p>Should we create the same aggregate multiple times in each microservice (if required)? Or there can never be a case, where we need to use one aggregate into other?</p>&#xA;"
48792602,Persistence layer as microservices?,2018-02-14 17:04:40,<spring-boot><microservices><netflix-eureka>,3,251,3,0.0,1,"<p>I'm a beginner in microservice architecture and I have read in a lot of blog that in a microservice architecture, it is mandatory that each micro service has its own database. In my case it may cost very expensive. </p>&#xA;&#xA;<p>My question is, is it possible to make the persistence layer as micro service in itself ? Which would have the function of allowing other microservices to have read/write access to the database.&#xA;Thanks</p>&#xA;"
41086281,MICROSERVICES - communication between them,2016-12-11 12:41:57,<java><rest><microservices>,2,712,4,0.0,1,"<p>I've got one question concerning microservices architecture. I am designing a system based on microservices. I've read few articles and I think I understand the idea. However, I don't how microservices should communicate with each other while they have separate business responsibilities....&#xA;What I mean is that if I have a system for booking train tickets, I would divide backend application into modules: </p>&#xA;&#xA;<ul>&#xA;<li>Client (login,logout,registration) </li>&#xA;<li>Reservations (booking a train seat for user,getting all reservations for user) </li>&#xA;<li>ConnectionsDetails&#xA;(searching for connections,getting connection details) </li>&#xA;<li>Trains&#xA;(information about trains- seats number,class etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Now, I can only think that if user search for connections module ConnectionsDetails communicate with Trains module and ask about particular train details. But how could other microservices communicate? If user wants to login - she/he asks directly Client module, if she/he wants to get all her reservations - asks Reservation module DIRECTLY etc... </p>&#xA;&#xA;<p>So my question is, how should modules communicate if they do different things? I'm sorry if my question is trivial or stupid, I'm just starting with microservices.</p>&#xA;&#xA;<p>EDIT:&#xA;I didn't mean what tools could I use for communication. My question is about logic. In the example I showed, why one microservice could ask another microservice about sth if client can directly ask the another one? As I said earlier, how they should communicate(about what should they ask each other exactly) if they do separate things?</p>&#xA;"
40447582,API Gateway handling Webservices in a Microservice Architecture,2016-11-06 08:58:30,<web-services><rest><architecture><microservices>,2,257,0,2.0,1,"<p>I have an architectural question. We are transforming an old Monolith to a Microservice Architecture. Therefore we have in plan to identify the bounded contexts and make Microservices out of these. </p>&#xA;&#xA;<p>To keep up with our public API we will have an API Gateway which routes the stuff properly. The internal communication will be done via REST (at the first shot). Unfortunatelly our existing public API is about WebServices most of the time.</p>&#xA;&#xA;<p>If we do transformation from Webservices to REST communication we already need to know stuff of the Domain Objects. Isn't that already a violation of the Microservice Design. In the end that means adding a field in the Microservice A implies also touching the API Gateway. Which I do not like.</p>&#xA;&#xA;<p>Am I wrong here? What is your opinion on this?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/9ZGGo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9ZGGo.png"" alt=""enter image description here""></a></p>&#xA;"
40413453,Aggregated Notification Microservice,2016-11-04 00:26:00,<microservices>,1,728,1,0.0,1,"<p><strong>The Problem</strong></p>&#xA;&#xA;<p>We are currently architecting our new Notification Microservice but having trouble with how to handle aggregated emails. What we need to do is instead of sending one email every action performed (could be 20+ in a few minutes), we would send an email after an hour summarising all the actions that were completed.</p>&#xA;&#xA;<p><strong>What We Have So Far</strong></p>&#xA;&#xA;<p>We so far propose that we have this type of messaging pattern, where Client Service is any service in our cluster and Messagebot is our Notification Microservice.</p>&#xA;&#xA;<ol>&#xA;<li>Client Service sends a notification to Messagebot that it will need to send something in the future</li>&#xA;<li>Messagebot stores the details in its database</li>&#xA;<li>Messagebot periodically checks its database for what needs to be sent</li>&#xA;<li>Messagebot gets the required data from another service (could be Client Service) via API</li>&#xA;<li>Messagebot sends email using the data from #3 and an HTML template</li>&#xA;</ol>&#xA;&#xA;<p><strong>The Debate</strong></p>&#xA;&#xA;<p>For the data that needs to be sent, we are less sure and it is what we need help with. So far we think this should be the structure of the JSON from Client Service to Notification Service (step #1):</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    objectid: SOME_OBJECT_ID&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>or</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    required_objects: { task_id: SOME_TASK_ID, document_id: SOME_DOCUMENT_ID }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Where task_id and document_id are just examples and it would change based on the template. It could just as easily be <code>{product_id: SOME_PRODUCT_ID}</code> for a different template.</p>&#xA;&#xA;<p><strong>Why The Debate</strong></p>&#xA;&#xA;<p>Our thoughts so far are that:</p>&#xA;&#xA;<ol>&#xA;<li>We only need template_id because the source of the data would be implied in the objects (like an ENV var). For example, the Task object would be at <a href=""http://taskservice/:id"" rel=""nofollow noreferrer"">http://taskservice/:id</a>. Otherwise, we can have problems with failing APIs or switching URLs in the future.</li>&#xA;<li>We should use userid instead of email and name because we prevent the issue of email/ name pairs not matching up over multiple messages</li>&#xA;<li>For the objects, we're still sceptical because it means that the client app service would need knowledge of the inner workings in Messagebot but a single objectid might not be very extensible. We could easily imagine many of our messages needing more than one object.</li>&#xA;</ol>&#xA;&#xA;<p><strong>In Conclusion</strong></p>&#xA;&#xA;<p>Thank you for reading. The design of this service is important because it will be central to our entire organisation. </p>&#xA;&#xA;<p>Which debated JSON structure is most appropriate in our situation? Also, knowing our requirements, what would be the proper setup for this type of service? (aka. Are we correct in our other assumptions?)</p>&#xA;"
41880229,Send a message from one microservice to another in Azure Service Fabric (APIs),2017-01-26 18:16:09,<asp.net-web-api><architecture><microservices><azure-service-fabric><service-fabric-stateful>,2,651,0,3.0,1,"<p><a href=""https://i.stack.imgur.com/Og0vb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Og0vb.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What is the best architecture, using Service Fabric, to guarantee that the message I need to send from Service 1 (mostly API) to Service 2 (mostly API) does not get ever lost (black arrow)?</p>&#xA;&#xA;<p>Ideas:</p>&#xA;&#xA;<h1>1</h1>&#xA;&#xA;<p>1.a. Make service 1 and 2 stateful services. Is it a bad call to have a stateful Web API?</p>&#xA;&#xA;<p>1.b. Use Reliable Collections to send the message from API code to Service 2.</p>&#xA;&#xA;<h1>2</h1>&#xA;&#xA;<p>2.a. Make Service 1 and 2 stateless services</p>&#xA;&#xA;<p>2.b. Add a third service</p>&#xA;&#xA;<p>2.c. Send the message over a queuing system (i.e.: Service Bus) from service 1</p>&#xA;&#xA;<p>2.d. To be picked up by the third service. Notice: this third service would also have access to the DB that service 2 (API) has access to. Not an ideal solution for a microservice architecture, right?</p>&#xA;&#xA;<h1>3</h1>&#xA;&#xA;<p>3.a. Any other ideas?</p>&#xA;&#xA;<p>Keep in mind that the goal is to never lose the message, not even when service 2 is completely down or temporary removed… so no direct calls.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
41837933,Accessing Kubernetes Web UI (Dashboard),2017-01-24 20:02:38,<docker><kubernetes><microservices><kubectl><kube-dns>,1,2484,0,0.0,1,"<p>I have installed a Kubernetes with Kubeadm tool, and then followed the <a href=""https://kubernetes.io/docs/user-guide/ui/"" rel=""nofollow noreferrer"">documentation</a> to install the Web UI (Dashboard). Kubernetes is installed and running in one node instance which is a taint master node. </p>&#xA;&#xA;<p>However, I'm not able to access the Web UI at <code>https://&lt;kubernetes-master&gt;/ui</code>. Instead I can access it on <code>https://&lt;kubernetes-master&gt;:6443/ui</code>.</p>&#xA;&#xA;<p>How could I fix this?</p>&#xA;"
41776814,Accessing Large files stored in AWS s3 using AWS Lambda functions,2017-01-21 07:29:07,<amazon-web-services><amazon-s3><aws-lambda><microservices>,1,1992,1,0.0,1,"<p>I have more than 30GB file stored in s3,and I want to write an Lambda function which will access that file, parse it and then run some algorithm on the same.&#xA;I am not sure if my lambda function can take that big file and work on it as Max execution time for Lambda function is 300 sec(5 min).&#xA;I found AWS S3 feature regarding faster acceleration, but will it help?</p>&#xA;&#xA;<p>Considering the scenario other than lambda function can any one suggest any other service to host my code as micro service and parse the file?</p>&#xA;&#xA;<p>Thanks in Advance</p>&#xA;"
41832273,Kuberenets Web UI (Dashboard) missing graphs,2017-01-24 15:41:14,<docker><kubernetes><microservices>,1,607,2,0.0,1,<p>I have installed Docker v1.13 and Kubernetes with Kubeadm v1.6. Then I installed Web UI (Dashboard). I can access it but its missing CPU/Memory usage graphs... Why could this happen? </p>&#xA;
41739975,What are the reason to decouple databases on microservices?,2017-01-19 10:51:46,<database><microservices><nosql>,1,435,3,0.0,1,"<p>Here I my current findings on this subject, are these correct or is there an aspect missing?</p>&#xA;&#xA;<p>There are two major principles for microservices: </p>&#xA;&#xA;<ul>&#xA;<li><strong>strong cohesion</strong> -> related code is gouped together, e.g. a class does on well defined job this is strong/hingh cohesion. </li>&#xA;<li><strong>loose coupling</strong> -> interconnect components in a system so that those  components, depend on each other as less as practicable. Coupling refers to the degree of direct knowledge that one element has of another. So a change to one service should not require a change to another.</li>&#xA;</ul>&#xA;&#xA;<p>With a shared database (as in not decoupled) architecture both these principles are not covered. This due to the following facts:</p>&#xA;&#xA;<ul>&#xA;<li>There is a fixed link between the users and the specific technology&#xA;choice as well as to the actual database implementation.</li>&#xA;<li>Businiess/application logic might be spread among multiple users.</li>&#xA;<li>Shared information which needs to be edited can trigger a change of&#xA;the behavior in multiple places.</li>&#xA;<li>Due to the more monolithic architecture which goes with shared&#xA;databases a failure can effect many serveries since they are all tied&#xA;together, even a compelte system failure can happen due to the&#xA;coupeling.</li>&#xA;</ul>&#xA;&#xA;<p>To avoid the above mentioned issues: decoupled databases can be used with microservices instead of shared databases. So each microservice should have its own database. This will also ease scaling of the system, provide much much more system availability, since ""only"" the one, really effected service will fail. </p>&#xA;&#xA;<p><strong>UPDATE</strong>: &#xA;One other benefit of microservices would be that it can improve the flexibility and speed of development. Since correctly decomposed microservices, can be developed and deployed e independently and in parallel with the other services.</p>&#xA;"
51040814,Micro services: shared library vs code duplication,2018-06-26 10:37:23,<.net><asp.net-core><architecture><microservices>,3,117,3,0.0,1,"<p>Similar questions were asked a few times, but as every use-case can be different I thought it worth to ask it again with the specific case I'm facing with.&#xA;So, we are developing micro-services using .netCore.  Let's call these services <strong>ServiceA</strong>, <strong>ServiceB</strong>, <strong>ServiceC</strong>.</p>&#xA;&#xA;<h2>Common entities</h2>&#xA;&#xA;<p>If <strong>ServiceA</strong> calls  <strong>ServiceC</strong>, then <strong>ServiceC</strong> responds with a JSON content which can be serialized into <strong>ResponseC</strong> object.</p>&#xA;&#xA;<p>This means, that both <strong>ServiceA</strong> and <strong>ServiceC</strong> should know <strong>ResponseC</strong> class.&#xA;At this point I see two possibilities. <strong>ResponseC</strong> class can be in a shared library and both <strong>ServiceA</strong> and <strong>ServiceC</strong> should have a reference to this shared library.&#xA;However I read statements like <strong>do not share libraries among micro-services</strong>. This leads to an other possible solution. Let's introduce <strong>ResponseC</strong> class in both micro-services, but then somehow I find this a bit against maintainability, because of code duplication.</p>&#xA;&#xA;<h2>Common logic</h2>&#xA;&#xA;<p>Both <strong>ServiceA</strong> and <strong>ServiceB</strong> communicates with <strong>ServiceC</strong>. When communicating with <strong>ServiceC</strong> we intend to have some policy regarding read and connection timeout and regarding the maximum number of retries. These values are configurable and there is also some common parts in the retry logic to be able to read the relevant values from the configuration file and to wrap the http calls. &#xA;The question is pretty much the same like in the previous case, because I either put these classes into a shared library or I basically introduce the same classes in both <strong>ServiceA</strong> and <strong>ServiceB</strong>. These classes are quite simple and generic, so at the moment I cannot imagine, that these classes will change frequently.</p>&#xA;&#xA;<p>So the question is, that what is better in these cases, duplicate code and having independent micro-services or introduce a shared library which makes these services dependent?</p>&#xA;"
42549749,"Micro-services, client-side discovery",2017-03-02 08:00:04,<microservices>,2,689,0,0.0,1,"<p>I am new to microservices, so while reading about it,I can't understand the below paragraph when talking about the load balancing, how the client will do something like this?</p>&#xA;&#xA;<p>""When using client‑side discovery, the client is responsible for determining the network locations of available service instances <strong>and load balancing requests across them.</strong>""</p>&#xA;"
42528718,CQRS + Microservices: How to handle relations / validation?,2017-03-01 10:06:11,<validation><relationship><one-to-many><microservices><cqrs>,3,462,0,0.0,1,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<ul>&#xA;<li>I have 2 Microservices (which both use CQRS + Event Sourcing internally)</li>&#xA;<li>Microservice 1 manages Contacts (= Aggregate Root)</li>&#xA;<li>Microservice 2 manages Invoices (= Aggregate Root)</li>&#xA;</ul>&#xA;&#xA;<p>The recipient of an invoice must be a valid contact. </p>&#xA;&#xA;<p><strong>CreateInvoiceCommand:</strong></p>&#xA;&#xA;<pre><code>{&#xA;  ""content"": ""my invoice content"",&#xA;  ""recipient"": ""42""&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>I now read lot's of times, that the write side (= the command handler) shouldn't call the read side.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Taking this into account, the Invoices Microservice must listen to all <code>ContactCreated</code> and <code>ContactDeleted</code> events in order to know if the given recipient id is valid.</p>&#xA;&#xA;<p>Then I'd have thousands of Contacts within the Invoices Microservice, even if I know that only a few of them will ever receive an Invoice.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Is there any best practice to handle those scenarios?</p>&#xA;"
42478361,How to login to Microservices ui app using jhipster,2017-02-27 05:24:39,<jhipster><microservices>,1,383,4,0.0,1,"<p>I am creating a <code>jhipster</code> application using microservices. I have created JHipster Registry, UAAserver, 2 microservices calling 2 Ui apps on 2 different url. Have added entities in 2 UI apps, using Mongodb for database. Have run all the above JHipster Registry, UAAserver, 2 microservices, 2 Uiapp's and i am able to see all running in Jhipster registry and tables being created in Mongodb but when i try to login to Uiapp1 or UiApp2 its throwing </p>&#xA;&#xA;<blockquote>&#xA;  <p>XMLHttpRequest cannot load <a href=""http://192.168.0.10:9999/login"" rel=""nofollow noreferrer"">http://192.168.0.10:9999/login</a>. No 'Access-Control-Allow-Origin' header is present on the requested resource. &#xA;  Origin '<a href=""http://192.168.0.10:8084"" rel=""nofollow noreferrer"">http://192.168.0.10:8084</a>' is therefore not allowed access.</p>&#xA;</blockquote>&#xA;"
42539505,How to get sorted data from one service to another over http,2017-03-01 18:42:22,<microservices><api-design>,2,313,6,1.0,1,"<p>I have service oriented architecture with couple services.</p>&#xA;&#xA;<ul>&#xA;<li><p>Product  - store list of products</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   price: number&#xA;}</code></p></li>&#xA;<li><p>Categories   - store category information + the list of product ids</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   parentCategory: number,&#xA;   productIds: number[]&#xA; }</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Lets assume that I have such category instance</p>&#xA;&#xA;<pre><code>{&#xA;   id: 1,&#xA;   parentCategory: null,&#xA;   productIds: [1, 3, 4, 5, ....]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I need to get 10 products from the category above sorted by product price. </p>&#xA;&#xA;<p>Category service processes that request and because it doesn't know anything about the price it has to make the request to Product service like that: </p>&#xA;&#xA;<pre><code>/api/products?&#xA;   ids=&lt;list of all product ids&gt;&#xA;   limit=10&#xA;   sortBy=price&#xA;</code></pre>&#xA;&#xA;<p>which won't work well when the category has a lot of products.</p>&#xA;&#xA;<p>What is the recipe in such case? &#xA;Thanks.</p>&#xA;"
39476480,microservices: C:\....m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature),2016-09-13 18:11:12,<java><maven><microservices>,1,665,0,1.0,1,"<p>I was looking to developed the <code>microservices</code> example by following the link: <a href=""https://github.com/bjedrzejewski/tasklist-service"" rel=""nofollow"">https://github.com/bjedrzejewski/tasklist-service</a>. When I simply compile the whole source code I faced compilation error, not sure why ? It looks to me something wrong with my .m2 home not so sure though.</p>&#xA;&#xA;<p>The error coming for reference:-</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure: Compilation failure:&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature)&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\eclipse\jetty\jetty-servlet\9.2.13.v20150730\jetty-servlet-9.2.13.v20150730.jar; invalid LOC header (bad signature)&#xA;[ERROR] -&gt; [Help 1]&#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)&#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)&#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)&#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)&#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)&#xA;Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure&#xA;        at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:656)&#xA;        at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:128)&#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)&#xA;        ... 20 more&#xA;[ERROR]&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException&#xA;</code></pre>&#xA;&#xA;<p>I only updated pom.xml to use Java version 8, nothing special</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;bjedrzejewski&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;tasklist-service&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;dropwizard.version&gt;0.9.1&lt;/dropwizard.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.dropwizard&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;dropwizard-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${dropwizard.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jersey-common&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.23.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;2.3.2&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;${java.version}&lt;/source&gt;&#xA;                    &lt;target&gt;${java.version}&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;archive&gt;&#xA;                        &lt;manifest&gt;&#xA;                            &lt;mainClass&gt;com.bjedrzejewski.tasklistservice.TaskListServiceApplication&lt;/mainClass&gt;&#xA;                        &lt;/manifest&gt;&#xA;                    &lt;/archive&gt;&#xA;                    &lt;descriptorRefs&gt;&#xA;                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;&#xA;                    &lt;/descriptorRefs&gt;&#xA;                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;&#xA;                &lt;/configuration&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;&#xA;                        &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;single&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>Also pom.xml dont have much entry of dependencies but still I see many jars files gets download why this so ?</p>&#xA;&#xA;<pre><code>E:\Advance Java\MicroServices\Git code\tasklist-service&gt;mvn dependency:tree&#xA;[INFO] Scanning for projects...&#xA;[INFO]&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building tasklist-service 1.0-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO]&#xA;[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ tasklist-service ---&#xA;[INFO] bjedrzejewski:tasklist-service:jar:1.0-SNAPSHOT&#xA;[INFO] +- io.dropwizard:dropwizard-core:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-util:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0:compile&#xA;[INFO] |  |  +- com.google.guava:guava:jar:18.0:compile&#xA;[INFO] |  |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile&#xA;[INFO] |  |  \- joda-time:joda-time:jar:2.9:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jackson:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-core:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk7:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-joda:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.slf4j:slf4j-api:jar:1.7.12:compile&#xA;[INFO] |  |  \- ch.qos.logback:logback-classic:jar:1.1.3:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-validation:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.hibernate:hibernate-validator:jar:5.2.2.Final:compile&#xA;[INFO] |  |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile&#xA;[INFO] |  |  |  +- org.jboss.logging:jboss-logging:jar:3.2.1.Final:compile&#xA;[INFO] |  |  |  \- com.fasterxml:classmate:jar:1.1.0:compile&#xA;[INFO] |  |  \- org.glassfish:javax.el:jar:3.0.0:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-configuration:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- org.yaml:snakeyaml:jar:1.15:compile&#xA;[INFO] |  |  \- org.apache.commons:commons-lang3:jar:3.4:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-logging:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-logback:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.slf4j:jul-to-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- ch.qos.logback:logback-core:jar:1.1.3:compile&#xA;[INFO] |  |  +- org.slf4j:log4j-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- org.slf4j:jcl-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-util:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-metrics:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jersey:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.core:jersey-server:jar:2.22.1:compile&#xA;[INFO] |  |  |  +- org.glassfish.jersey.core:jersey-client:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-metainf-services:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-bean-validation:jar:2.22.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jersey2:jar:3.1.2:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile&#xA;[INFO] |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-server:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-io:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-xml:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-continuation:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-servlets:jar:0.9.1:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-annotation:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jetty:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jetty9:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlet:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-security:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlets:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-http:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-lifecycle:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-servlets:jar:3.1.2:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-json:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-healthchecks:jar:3.1.2:compile&#xA;[INFO] |  +- net.sourceforge.argparse4j:argparse4j:jar:0.6.0:compile&#xA;[INFO] |  \- org.eclipse.jetty.toolchain.setuid:jetty-setuid-java:jar:1.0.3:compile&#xA;[INFO] \- org.glassfish.jersey.core:jersey-common:jar:2.23.2:compile&#xA;[INFO]    +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile&#xA;[INFO]    +- javax.annotation:javax.annotation-api:jar:1.2:compile&#xA;[INFO]    +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.23.2:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-api:jar:2.5.0-b05:compile&#xA;[INFO]    |  +- org.glassfish.hk2:hk2-utils:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2.external:javax.inject:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-locator:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.javassist:javassist:jar:3.20.0-GA:compile&#xA;[INFO]    \- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD SUCCESS&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 2.860 s&#xA;[INFO] Finished at: 2016-09-13T23:39:38+05:30&#xA;[INFO] Final Memory: 17M/309M&#xA;[INFO] ------------------------------------------------------------------------&#xA;</code></pre>&#xA;"
39435028,How to use micro-services into core application/framework?,2016-09-11 10:16:13,<rest><microservices>,1,120,5,0.0,1,"<p>For example I have two micro-services, how can I use those services in my core application?</p>&#xA;&#xA;<p>I know the communication will be through REST API. </p>&#xA;&#xA;<p>My question is, should I create those services as sub-modules?</p>&#xA;&#xA;<p>If my question seems not clear to you then assume I am not clear about micro-services. Thus better explanation will be very helpful.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
47162798,Decomposition into microservices,2017-11-07 16:25:12,<design><architecture><microservices><bounded-contexts>,3,86,0,2.0,1,"<p>I have a question regarding decomposition into microservices. Suppose we have 2 microservices: <strong>User</strong> and <strong>Product</strong>. Suppose we now have a requirement to add categories to the system. More specifically, a product has one or more categories (e.g the product red miniature ferrari belongs to categories toys and cars) and a user can have categories which she likes (e.g. toys and shoes). Now when we retrieve the full list of products we want them to be sorted such that the products that fall in the preferred user categories are at the top. </p>&#xA;&#xA;<p>Basically be have a concept that is shared between microservices (in this case category). How to best model this in a microarchitecture environment? I see two solutions:</p>&#xA;&#xA;<p><strong>Solution 1:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Make a separate “categories"" microservice which manages CRUD of categories</li>&#xA;<li>In the product service have an API call to link category ids to a product</li>&#xA;<li>In the user service have an API call to link category ids to a user</li>&#xA;<li>In the product service we have an API call to fetch products ordered on preference. To make this work the product service needs to call the user service to get the user categories (or listen to events emitted by user services)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong> </p>&#xA;&#xA;<ul>&#xA;<li><p>Make a separate “categories” microservice which manages CRUD of categories</p></li>&#xA;<li><p>The categories service also has an API call to link product ids to categories</p></li>&#xA;<li><p>The categories service also has an API call to link user ids to categories</p></li>&#xA;<li><p>In the product service we have an API call to fetch products ordered on preference (to make this work product service needs to call the categories service to get user and product categories (or listen to events)</p></li>&#xA;</ul>&#xA;&#xA;<p>What are the advantages/disadvantage to both solutions? </p>&#xA;"
47265946,Microservice Project Structure Using Spring boot and Spring Cloud,2017-11-13 13:53:05,<spring-boot><microservices>,3,1693,0,1.0,1,"<p>I am trying to convert a normal monolithic web application into microservices structure using spring boot and spring cloud. I am actually trying to create Angular 2 front-end application and calls these my developed microservices in the cloud. And I am already started to break the modules into independent process's structure for microservice architecture.</p>&#xA;&#xA;<ul>&#xA;<li>Here my doubt is that , When designing the flow of control and microservice structure architecture, Can I use only one single spring boot project using different controller for this entire web application back end process.? Somewhere I found that when I am reading develop all microservices using 2 different spring boot project. Actually I am new to spring and spring cloud. I have lot of confusions in my task. Can any one help to clarify that is possible to create all services in single project by using different modules ???</li>&#xA;</ul>&#xA;"
47184194,common POM based plugins across multiple microservice projects,2017-11-08 15:58:41,<maven><pom.xml><maven-plugin><microservices>,1,42,3,0.0,1,"<p>I am trying to figure out a way to import a set of common Maven plugins, across multiple microservice projects?</p>&#xA;&#xA;<p>Idea is to maintain a single place to manage all the common plugins - like jacoco, javadocs etc.</p>&#xA;&#xA;<p>We totally want to avoid the parent POM way of handling it.</p>&#xA;"
47309649,MicroService path /api/v1/ or /v1/api/,2017-11-15 14:12:46,<java><microservices><grizzly>,1,51,4,0.0,1,"<p>I'm building a MicroSerive and I was planning to publish services using this URI naming convention:</p>&#xA;&#xA;<pre><code>https://host:port/api/v1/service1&#xA;https://host:port/api/v1/service2&#xA;https://host:port/api/v2/service1&#xA;https://host:port/api/v2/service2&#xA;</code></pre>&#xA;&#xA;<p>But I've also seen URIs named like this (ie vx and api 'swapped'):</p>&#xA;&#xA;<pre><code>https://host:port/v1/api/service1&#xA;https://host:port/v1/api/service2&#xA;https://host:port/v2/api/service1&#xA;https://host:port/v2/api/service2&#xA;</code></pre>&#xA;&#xA;<p>In my opinion, the first approach is better. Are there any reasons to go for the second approach?</p>&#xA;"
37897876,Vert.x how to pass/get messages from REST to message bus?,2016-06-18 14:09:34,<java><rest><microservices><vert.x>,2,1175,0,0.0,1,"<p>I want to pass messages to bus via REST, and get it back. But I cant correctly setup the message bus receiver, it throws <code>java.lang.IllegalStateException</code>: Response has already been written. In real life message bus should receive messages from different sources and pass a message to another target. Therefore we just need to publish the message to the bus. But how to correctly read messages and handle all of them? For example from a REST interface: read that messages!&#xA;My simple app start:</p>&#xA;&#xA;<pre><code> public static void main(String[] args) {&#xA;        Vertx vertx = Vertx.vertx();&#xA;        vertx.deployVerticle(new RESTVerticle());&#xA;        vertx.deployVerticle(new Receiver());&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.registerDefaultCodec(MessageDTO.class, new CustomMessageCodec());&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>REST part</p>&#xA;&#xA;<pre><code>public class RESTVerticle extends AbstractVerticle {&#xA;&#xA;    private EventBus eventBus = null;&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        Router router = Router.router(vertx);&#xA;        eventBus = vertx.eventBus();&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.post(""/api/message"").handler(this::publishToEventBus);&#xA;       // router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9999);&#xA;        System.out.println(""Service running at 0.0.0.0:9999"");&#xA;&#xA;    }&#xA;&#xA;private void publishToEventBus(RoutingContext routingContext) {&#xA;        System.out.println(""routingContext.getBodyAsString() "" + routingContext.getBodyAsString());&#xA;        final MessageDTO message = Json.decodeValue(routingContext.getBodyAsString(),&#xA;                MessageDTO.class);&#xA;&#xA;        HttpServerResponse response = routingContext.response();&#xA;        response.setStatusCode(201)&#xA;                .putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                .end(Json.encodePrettily(message));&#xA;&#xA;        eventBus.publish(""messagesBus"", message);&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>And the Receiver: I move it to a different class, but it does not help</p>&#xA;&#xA;<pre><code>public class Receiver extends AbstractVerticle {&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        Router router = Router.router(vertx);&#xA;&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9998);&#xA;        System.out.println(""Service Receiver running at 0.0.0.0:9998"");&#xA;&#xA;private void getMessagesFromBus(RoutingContext routingContext) {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.consumer(""messagesBus"", message -&gt; {&#xA;            MessageDTO customMessage = (MessageDTO) message.body();&#xA;            HttpServerResponse response = routingContext.response();&#xA;            System.out.println(""Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "" + customMessage);&#xA;            if (customMessage != null) {&#xA;                response.putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                        .end(Json.encodePrettily(customMessage));&#xA;            }&#xA;            response.closed();&#xA;&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So if i post message to REST and handler publish it to the bus, when I am runtime get <a href=""http://localhost:9998/api/messagelist"" rel=""nofollow"">http://localhost:9998/api/messagelist</a>  it is return json, but second time it trow exception</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Response has already been written&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.checkWritten(HttpServerResponseImpl.java:561)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:154)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:52)&#xA;    at com.project.backend.Receiver.lambda$getMessagesFromBus$0(Receiver.java:55)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handleMessage(HandlerRegistration.java:207)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handle(HandlerRegistration.java:201)&#xA;    at io.vertx.core.eventbus.impl.EventBusImpl.lambda$deliverToHandler$127(EventBusImpl.java:498)&#xA;    at io.vertx.core.impl.ContextImpl.lambda$wrapTask$18(ContextImpl.java:335)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:358)&#xA;    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;&#xA;Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Message{username=Aaaewfewf2d, message=41414wefwef2d2}&#xA;</code></pre>&#xA;&#xA;<p>How to correctly get all messages from the receiver? Or if the bus received messages, should I immediately store them to the db? Can a message bus keep messages and not lost them?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37864491,"In a microservices architecture, how do you handle composite requests which must do minor data processing and call other services?",2016-06-16 16:19:04,<architecture><restful-architecture><microservices>,3,966,0,0.0,1,"<p>For example once the user gets to the payment step in our workflow a lot of different services need to be called (such as payment, email generation, content generation). Should the front-end handle that or should a service be designed to handle this type of request? If so, how should that service be designed so that it can handle doing composite requests without specifically hardcoding what those requests are composed of?</p>&#xA;"
37985551,Alternative to iframe for microservices ui composition,2016-06-23 08:01:54,<iframe><microservices>,2,1405,2,0.0,1,"<p>I'm currently integrating multiple microservices ui into a web portal. I have a navigation sidebar with link to microservices which will be loaded into an iframe in the central area.</p>&#xA;&#xA;<p>I have lot of issue with iframe (security with frame option header, window sizing, etc...)</p>&#xA;&#xA;<p>Do you know about a better alternative to an iframe?</p>&#xA;"
37801454,Is there a way to implement SSO in front of the microservices?,2016-06-14 01:10:36,<go><single-sign-on><cas><microservices><beego>,1,1127,5,1.0,1,"<p>Recently I have a project to implement <a href=""https://en.wikipedia.org/wiki/Single_sign-on"" rel=""nofollow noreferrer"">SSO(Single-Sign-On)</a> for multiple web applications based on <a href=""http://beego.me/"" rel=""nofollow noreferrer"">Beego Framework</a>. The most popular SSO project is <a href=""https://en.wikipedia.org/wiki/Central_Authentication_Service"" rel=""nofollow noreferrer"">CAS</a>, which needs a CAS Server in the center, and a CAS Client before each web application. Unfortunately, it seems that there's not any offical CAS clients written in Golang, except <a href=""https://github.com/go-cas/cas"" rel=""nofollow noreferrer"">go-cas/cas</a>, and <a href=""https://github.com/adanteng/cas"" rel=""nofollow noreferrer"">adanteng/cas</a>, which supports Beego.</p>&#xA;&#xA;<p>But the workflow of CAS is a little bit complicated: too many redirections, too many tickets transmitted among the CAS, web apps, and the user browser. I can't figure out why people deploy the Authentication Services in the center of all the web apps, rather than the front, like the following diagram:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/aqOmDm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aqOmDm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In this diagram, all the requests are forced to be processed in the Authenticate Service first, if authenticated successfully, then generate a session ID, saved in the cookies and Redis which is shared by other microservices. There's not any redirections or tickets at all, only requests transmittion.</p>&#xA;&#xA;<p>So is this diagram possible, or some critical problems I ignored?</p>&#xA;&#xA;<h1>Update 0</h1>&#xA;&#xA;<p>The session-sharing way is indeed not scalable and modular as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> counsels. How about transmitting user information, like name, email, etc., in the headers of requests between the auth service and downstream services, like the creative work of Heipei at <a href=""https://heipei.github.io/2015/09/23/nginx-sso-Simple-offline-SSO-for-nginx/"" rel=""nofollow noreferrer"">nginx-sso</a>? Is it possible to make it work as an SSO Gateway as Sam Newman sharing in the book <a href=""http://samnewman.io/books/building_microservices/"" rel=""nofollow noreferrer"">Building Microservices</a>?</p>&#xA;&#xA;<h1>Update 1</h1>&#xA;&#xA;<p>A more detailed diagram is shown as follows, in order to describe my childish idea a little bit clearly, hoping that there is not much misunderstanding from Heipei and Sam Newman. </p>&#xA;&#xA;<p>Rather than handling so many redirections and handshakes, all the requests are processed in the authentication service firstly, which writes user info from MySQL, into the Redis as the session provider, and the HTTP header to transmit to the downstream services, if the request is authenticated successfully.</p>&#xA;&#xA;<p>In this way, the user info is transmitted via HTTP header instead of the above shared-Redis as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> warning, and Redis can be depolyed with the auth service, or shared among auth instances only.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BeMFF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BeMFF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<h1>Update 2</h1>&#xA;&#xA;<p>It seems that Cookie and Session are old-school techs. The cross-domain problem of cookie, and the sharing problem of session are the primary barrier to the scalability and flexibility of the modern web applications. Fortunately, JSON Web Token comes to be the best Single Sign-on solution for multiple lightweight services nowadays, by moving the user info(maybe id is enough) storage from the server side to the client side, and transmitted only if necessary.</p>&#xA;"
50217813,Disable Microservice initial exposed port after configuring it in a gateway,2018-05-07 15:35:30,<security><microservices><firewall><kong><api-gateway>,3,41,0,0.0,1,"<p>Hello I've been searching everywhere and did not found a solution to my problem, which is how can I access my API through the gateway configured endpoint only, currently I can access to my api using localhost:9000, and localhost:8000 which is the Kong gateway port, that I secured and configured, but what's the point of using this gateway if the initial port is still accessible.&#xA;Thus I am wondering is there a way to disable the 9000 port and only access to my API with KONG.</p>&#xA;"
50139640,Architecture of microservices from a business approach or technical?,2018-05-02 16:43:36,<rest><docker><cloud><microservices>,3,50,0,1.0,1,"<p>Our team is trying to decouple a <strong>monolithic</strong> spring mvc administrative application <em>(create, update, delete)</em> and we want to adopt an architecture based on <strong>microservices</strong>. </p>&#xA;&#xA;<p>After a bit of research, it seems the best is create microservices <strong><em>according to the problem</em></strong> that a specific part of the software solves, for example, Managing Clients. </p>&#xA;&#xA;<p>The problem comes when we read some definitions, like the following from <strong><a href=""https://en.wikipedia.org/wiki/Monolithic_application"" rel=""nofollow noreferrer"">Wikipedia</a></strong>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In software engineering, a monolithic application describes a&#xA;  single-tiered software application in which the user interface and&#xA;  data access code are combined into a single program from a single&#xA;  platform.</p>&#xA;</blockquote>&#xA;&#xA;<p>Based on that definition, <em>my application is not monolithic</em>, because it is perfectly separated in layers, but it is not found in a micro-services architecture either, which is confusing to me since in the web everything is about <strong>Monolithic vs. Microservices</strong>.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/EIfHO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EIfHO.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>So, should the microservices architecture be designed based on the business problem it solves?</strong> </p>&#xA;&#xA;<p><strong>Should the microservices architecture be designed based on to the way in which the application is organized in layers?</strong></p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
50248560,spring-boot:run for multi module maven project,2018-05-09 08:14:42,<java><maven><spring-boot><microservices><netflix-eureka>,1,239,3,0.0,1,<p>I have a micro services setup of Eureka Server and multiple spring-boot applications as Eureka Clients. This is setup as maven multi module project at the parent (root) level. Below is the hierarchy:</p>&#xA;&#xA;<pre><code>parent (multi-module parent pom.xml)&#xA;  |_ eureka-server-spring-boot-app (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-1 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-2 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-3 (individual pom.xml)&#xA;  .&#xA;  .&#xA;</code></pre>&#xA;&#xA;<p>I was trying to run all the modules in the order defined in parent pom.xml. But when I run <code>mvn spring-boot:run</code> at parent level it only runs the first module (Eureka Server). Other modules are not deployed. I tried reading through SO but no relevant answers found.</p>&#xA;&#xA;<p>I want maven to run all the modules in order from parent directory. Is there any way this can be achieved?</p>&#xA;
43617787,What is the difference between workflow and dataflow?,2017-04-25 17:54:44,<spring><workflow><microservices><dataflow><spring-cloud-dataflow>,1,586,0,0.0,1,"<p>I'm looking at Spring Cloud Date Flow, before that I watched Activiti and Camunda(this is workflow engine). And I can't understand what is the difference between these concepts as workflow and dataflow? and сan we call Spring Cloud Data Flow the workflow engine?</p>&#xA;&#xA;<p>Sorry, I'm newer in this topic.</p>&#xA;&#xA;<p>I will be glad to any answer!</p>&#xA;"
43545080,Getting the different Content Type in the response of REST call done by REST client and Jersey Java Code,2017-04-21 14:19:51,<java><rest><jersey><microservices>,3,595,0,0.0,1,"<p>While working on a Micro-Service, I have to hit the REST api of the 3rd party. I am using the Spring Boot Application with Jersey library. &#xA;Now the problem is that I am getting the content type of the response as ""text/html; charset=utf-8"".</p>&#xA;&#xA;<p>If I hit the same call using the REST client, I get the right content type as application/json;charset=UTF-8. Why so ?</p>&#xA;&#xA;<p>Below is the Java source code for the same -</p>&#xA;&#xA;<pre><code>@Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;@POST&#xA;@Path(""/endPoint"")&#xA;@Consumes(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;public JSONObject getAccessToken(@FormParam(""item1"") String item1,@FormParam(""item2"") String item2,@FormParam(""item3"") String item3,@FormParam(""item4"") String item4) throws Exception {&#xA;  System.out.println(""Enter to test"");&#xA;&#xA;&#xA;    String extendedUrl = ""?item1=""+item1+""&amp;item2=""+item2+""&amp;item3=""+item3+""&amp;item4=""+item4;&#xA;&#xA;    JSONObject jObject = null;&#xA;    try {&#xA;      jObject = postCall(extendedUrl);&#xA;    }&#xA;    catch (Exception e) {&#xA;      // TODO Auto-generated catch block&#xA;      e.printStackTrace();&#xA;    }&#xA;&#xA;    System.out.println(""Box Auth Response :: ""+jObject.toJSONString());&#xA;&#xA;    return jObject;&#xA;}&#xA;// Short description of the logic to execute the request&#xA;public void postCall(String extendedUrl)&#xA;{ &#xA;String url = ""baseurl"";&#xA;url+=extendedUrl;&#xA;HttpsURLConnection conn = openConnection(apiUrl);&#xA;conn.connect();&#xA;status = conn.getResponseCode();&#xA;String responseContentType = conn.getContentType();&#xA;System.out.println(""responseContentType ::""+responseContentType);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So when I debug the code, responseContentType comes out as text/html; charset=utf-8. Is there any reason for the same ? How will get this as application/json;charset=UTF-8?</p>&#xA;&#xA;<p>Help would be appreciated. </p>&#xA;"
43665011,Microservice registration with Eureka replicas in docker swarm cluster,2017-04-27 18:05:23,<docker><microservices><netflix-eureka>,1,988,0,0.0,1,"<p>If I have a microservice for Eureka service discovery and I have 5 replicas for it in docker-compose.yml then, these 5 eureka containers would be spread across multiple swarm nodes available in swarm cluster.</p>&#xA;&#xA;<p>My question is, when a microservice wants to register itself with eureka,</p>&#xA;&#xA;<ol>&#xA;<li><p>Would it specify the ip address of the master node in the swarm cluster in its config for eureka server ?</p></li>&#xA;<li><p>When a microservice registers itself with eureka whichever way, does this registry get replicated across all the eureka containers in swarm cluster as who know which eureka node in swarm cluster would service a particular microservice.</p></li>&#xA;</ol>&#xA;"
43584079,How to split an existing webApi project?,2017-04-24 09:13:47,<.net><asp.net-web-api><architecture><microservices>,1,68,4,0.0,1,"<p>I have an existing legacy .Net webApi project with ~20 controllers and ~10 methods each.&#xA;The traffic is 15 requests per sec.&#xA;I'm wondering if it's a smart thing to do to take microServices approach and split it into few hosted projects.</p>&#xA;&#xA;<p>Since i don't have access to the clients (android, ios, WebSite and third parties) i will have to keep the existing API URL working (<a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a>).</p>&#xA;&#xA;<p>My quick and dirty architecture is:&#xA;1) Build new hosted API process <a href=""http://domainName/API1"" rel=""nofollow noreferrer"">http://domainName/API1</a>, <a href=""http://domainName/API2"" rel=""nofollow noreferrer"">http://domainName/API2</a>, <a href=""http://domainName/API3"" rel=""nofollow noreferrer"">http://domainName/API3</a>...&#xA;2) Ask kindly from the clients to use the new URLs&#xA;3) <a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a> will act as router to the new processes for background competitively </p>&#xA;&#xA;<p>Ideas ? Is there any existing pattern for that?  </p>&#xA;"
43559197,Shared signature key for JWT in various Microservices,2017-04-22 12:27:52,<security><spring-security><jwt><spring-cloud><microservices>,1,372,4,0.0,1,<p>I have various microservices. I have implemented security using JWT. Each service validates the JWT token by the key which is being shared across all the services.</p>&#xA;&#xA;<p><strong>Is it fine to share same signature key for JWT across all the microservices?</strong> </p>&#xA;&#xA;<p>I can't implement this at the API gateway as I have to use certain libraries which requires spring security to be triggered in every microservice.</p>&#xA;
43661844,Microservice - What does changing service without changing code really mean?,2017-04-27 15:21:00,<java><spring-boot><cloudfoundry><microservices>,2,113,7,0.0,1,"<p>I am trying to understand ""changing database without changing code"". Currently working with micro services using springboot, java, thymeleaf and cloud foundry.</p>&#xA;&#xA;<p>I have a spring boot application and attached a database as a service using cloud foundry.</p>&#xA;&#xA;<p>My problem is I am seeing that the purpose of micro service is allowing the ease to change services without changing code.</p>&#xA;&#xA;<p><strong>Here is where I got stuck</strong></p>&#xA;&#xA;<p>In java I have a sql script, ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>Images <a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">source</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/WDQmC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WDQmC.png"" alt=""Table sample""></a></p>&#xA;&#xA;<p>My database would be attached as a service on cloud foundry using CUPS &#xA;""jdbc:oracle:thin:username/password//host:port/servicename""</p>&#xA;&#xA;<p>So let say I want to change this database to CUSTOMER table(take it as a different database). This will throw an error because CUSTOMER table will not have ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>I've changed database, but wouldn't I still have to go back to my code and change the sql script?</p>&#xA;&#xA;<p><strong>My Attempt to resolve this issue</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>So instead of hard coding my sql script in java ""select * from ORDER where Status = 'ACCEPTED';""</p></li>&#xA;<li><p>I created a system environment variable and set it as sqlScript with value of select * from ORDER where Status = 'ACCEPTED'</p></li>&#xA;<li><p>Then in java I called the env variable String sqlScript= System.getenv(""sqlScript"");  </p></li>&#xA;<li><p>So now instead of going back into java to change sql script, user can change it through environment variables.</p></li>&#xA;</ol>&#xA;&#xA;<p>this is a very dirty method to go around my issue, what would be a better alternative?</p>&#xA;&#xA;<p>I know my logic of understanding is really wrong. Please guide me to the right path.</p>&#xA;"
47630168,Inter-service communication with Spring Boot and OAuth2,2017-12-04 09:30:19,<spring><oauth-2.0><microservices>,2,691,0,1.0,1,"<p>I am working on a micro-service architecture using Spring Boot. We have implemented OAuth2 in a Auth Server. </p>&#xA;&#xA;<p>My question is - If two microservices want to communicate what should be the best way?</p>&#xA;&#xA;<p>As of now, I have discovered below options:</p>&#xA;&#xA;<ol>&#xA;<li><p>If each microservice is verifying the token then we can pass the same token. But the problem is - in between same token can be expired.</p></li>&#xA;<li><p>If we use client_credentials grant then there we are having two issues: one is, we need to send the username in next microservice. Another one is, we need to request two times - first for getting the access token, next for actual call.</p></li>&#xA;<li><p>If we do the token verification in API gateway only (not in microservices) then from the API gateway we need to send the username in every microservices. And microservices implementation needs to be changed to accept that param/header.</p></li>&#xA;</ol>&#xA;&#xA;<p>Please suggest which option should I pick and if there is any better option please let me know.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47656406,"Are all the classes containing business logic, domain objects?",2017-12-05 14:49:15,<domain-driven-design><microservices><business-logic>,3,116,2,0.0,1,"<p>So I have few doubts regarding calling something as domain object (and eventually placing the class under domain package) or not.</p>&#xA;&#xA;<p>I have a micro-service whose responsibility is to do some calculations (without getting into actual business requirements, all it does is calculate some return of intereset based on given request). Now to achieve the calculations there are certain sub-calculations which need to take place and hence are composed in different classes respectively. But yes, these calculation do not need to be persisted in DB , and neither they have an ID (so definitely not an Entity or Aggregate). However these individual calculator classes (for the lack of terminology) do contain some complex business logic. Now, my question is, do these individual classes still qualify/classify as domain objects or should they be referred to as services ?</p>&#xA;&#xA;<p>Feel free to ask for more clarifications around use case if need be. </p>&#xA;&#xA;<p>Cheers ! </p>&#xA;"
45489456,connect docker container on local and other containers remotely,2017-08-03 16:07:48,<docker><docker-compose><microservices><docker-machine>,2,70,0,2.0,1,"<p>For our development debugging easiness and few issues over deployment we planned to containerize the services we have. For example.</p>&#xA;&#xA;<p>I have services such as <code>A</code>, <code>B</code>, <code>C</code> and <code>D</code>. where <code>A</code> is my development code(which changes frequently) , and B,C and D are the dependent services. </p>&#xA;&#xA;<p>Currently the <code>B</code>,<code>C</code> and <code>D</code> are planned to deploy remotely because they are just a dependency (Docker Container)&#xA;I would want a way  to debug/deploy so that </p>&#xA;&#xA;<ul>&#xA;<li><p>My service <code>A</code> could be on local and it could easily connect with the remote Docker Service <code>B</code>,<code>C</code>,<code>D</code></p></li>&#xA;<li><p>Or <code>A</code> could be somehow deployed to the remote cluster and it could be tested.</p></li>&#xA;</ul>&#xA;&#xA;<p>I thought of going with the push to registry but each developer with his own snapshot being pushed could not co-relate others images.</p>&#xA;&#xA;<p><strong>Note:</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I do not want Swarm kind of thing but want to keep it simple.</p></li>&#xA;<li><p>The Cluster is managed via Docker Machine. Can it be replaced?</p></li>&#xA;<li><p>The services are woven by Docker Compose.</p></li>&#xA;</ul>&#xA;&#xA;<p>Any suggestions on how I could drive this? Also preferred way is via Docker.</p>&#xA;"
45363163,what is the difference between netflix zuul server and netflix eureka server?,2017-07-28 00:46:18,<spring-boot><microservices><spring-cloud><spring-cloud-netflix>,2,2209,0,0.0,1,<p>i have created two java spring-boot micro services they are &#xA;1) producer &#xA;2) consumer &#xA;and i have used spring eureka server for service registration and discovery . it worked fine . then what is the use of Netflix Zuul.</p>&#xA;
45390260,What things should I consider to split my Monolithic nodeJs app to Microservice architecture?,2017-07-29 14:16:27,<node.js><microservices>,1,461,3,1.0,1,"<p>I'm trying to build Restful API's using NodeJs for a e-commerce application with a minimal functionality like User Accounts, Products, Inventory System, Cart/ Orders, Payments, Wallet/Credit, Delivery Management, Notifications etc.</p>&#xA;&#xA;<p>I wanted to implement this using a microservice architecture.</p>&#xA;&#xA;<p>I do not want to use a any framework, I want to explore and learn myself. </p>&#xA;&#xA;<p>How should I start?</p>&#xA;&#xA;<p>1) On what parameters should I choose a microservice architecture.</p>&#xA;&#xA;<p>2) How should I use the common ""terms"" like user model, or (products, inventory and orders).</p>&#xA;&#xA;<p>3) Should I build full monolithic App first and then take out the heavy parts out of it, one by one?</p>&#xA;&#xA;<p>A basic guideline that can put me in direction will be very helpful. I'll really appreciate and thank for helping on this subject.</p>&#xA;"
45486658,Is it bad practice to produce and consume messages from the same topic?,2017-08-03 14:09:23,<apache-kafka><activemq><messaging><microservices><tibco-ems>,1,363,4,1.0,1,"<p>Say you have a micro-service architecture where multiple services produce and consume <em>unit</em> statusses. </p>&#xA;&#xA;<p>There are multiple ways to design this, which one would you recommend?</p>&#xA;&#xA;<p>These are some options that come to mind:</p>&#xA;&#xA;<ol>&#xA;<li>Create a generic topic <code>unit-status</code> and make services consume and produce messages on this topic. This has the consequence that you consume your own messages and have to filter them. I would consider this a dirty solution, but easy for new new consumers to get all unit status events.</li>&#xA;<li>Create a specific topic for each status, for example <code>unit-status-created</code>, <code>unit-status-packaged</code>, <code>unit-status-loaded</code>, <code>unit-status-deleted</code>, etc. Each service produces only on it's own topic, but can consume from a list of topics, excluding it's own. For example the loading service would consume from list(<code>unit-status-created</code>, <code>unit-status-deleted</code>, <code>unit-status-packaged</code>). This allows services to show interest in only specific events, but it requires a code or config change in potentially all service when a new status topic is added. </li>&#xA;<li>Give each status it's own partition and consume from all partitions except the one you produce in. This design makes things more complicated (bookkeeping which partition contains a specific status), does not auto balance when partitions are added, adding partitions while live makes things a bit more risky, therefore does not have my preference. </li>&#xA;</ol>&#xA;"
45567201,User docker-compose to pull images from private repository,2017-08-08 11:32:44,<docker><docker-compose><microservices>,1,4064,6,0.0,1,<p>I'm using docker-compose command to run multiple containers. The problem is my docker-compose has to pull some images from the public repository and some from a private repository. What I'm planning to do is push all required images to the private repository but how can I make docker-compose pull the images from the private repository.</p>&#xA;&#xA;<p>In short -> How to point to a private repository when the images are only available there</p>&#xA;
45321939,Host a service with 2 endpoints in the same or separate processes?,2017-07-26 08:50:29,<web-services><iis><asp.net-web-api><nservicebus><microservices>,2,123,3,0.0,1,"<p>I'm building a microservice with both a synchronous REST endpoint (using WebAPI) and an asynchronous publish/subscribe endpoint (using NServiceBus on top of MSMQ) that will be processing data that is stored in a database shared by these endpoints.</p>&#xA;&#xA;<p>I'm trying to decide if I should host both endpoints in the same process, or if I should simply host them in separate processes and have them use the database as common ground to pass data between these processes. My gut feeling says the same process would be 'better', although it would also be more complex:</p>&#xA;&#xA;<ol>&#xA;<li><p>Hosting the endpoints in separate processes is simple: Host the WebAPI endpoint in IIS and host the NServiceBus endpoint as a Windows Service.</p></li>&#xA;<li><p>When hosting them in the same process, it's possible to self-host the NServiceBus endpoint in the WebAPI code but this is not recommended as IIS will shut down the worker process after a period of inactivity,&#xA;thereby also killing the NServiceBus part of the service and leaving it unable to handle incoming messages.<br>&#xA;So I figured I would have to host both the NServiceBus and the WebAPI endpoints in a Windows service, which appears to be possible when <a href=""https://docs.microsoft.com/en-us/aspnet/web-api/overview/hosting-aspnet-web-api/use-owin-to-self-host-web-api"" rel=""nofollow noreferrer"">using OWIN to self-host the WebAPI endpoint</a>.</p></li>&#xA;</ol>&#xA;&#xA;<p>Does anyone have experience with hosting a service with 2 endpoints in the same or different processes, and can tell me the problems/benefits associated with this choice?</p>&#xA;&#xA;<p><em>(<a href=""https://stackoverflow.com/questions/21202411/host-web-api-in-self-hosted-nservicebus"">This question</a> seemed to ask the same, but it never got a satisfactory answer)</em></p>&#xA;&#xA;<p><strong>Edit</strong> In response to @HadiEskandari, I'm not looking for a WebAPI facade for an NServiceBus endpoint. I'm planning to have the WebAPI endpoint to handle simple queries for information which it stores in the database that is shared between these endpoints.&#xA;Thse REST calls will be invoked AJAX-style from a web application, so I need this to execute quickly - forwarding each REST call through an MSMQ queue &#xA;to the NServiceBus endpoint and waiting for a response seems slow and wasteful in this case.</p>&#xA;&#xA;<p>Rather, I'm looking for a way to keep the data access code and business logic not just in the same assembly, but also in the same AppDomain so that both endpoints may share say, the same configuration or cached data.</p>&#xA;"
45300410,Django - How to implement authentication service in microservices architecture,2017-07-25 10:19:57,<django><jwt><microservices>,1,481,3,0.0,1,"<p>Basically, I have several independent services. I want to build a service for authentication. When client get a token from authentication service. Client use it for further request to others services. Client need to attach that token in header of request. The services receiving token need to verify the token by sending it to authentication server. So all requests that clients make to protected routes need to be verified by authentication service. The thing is I do not know the best place to put the code that automatically sends token to authentication service and receive the result. &#xA;Here is what i tried so far:&#xA;I implemented a middleware like that:</p>&#xA;&#xA;<pre><code>class VerifyTokenMiddleware(object):&#xA;&#xA;def process_request(self, request):&#xA;    if not request.META.get('HTTP_AUTHORIZATION'):&#xA;        return HttpResponse(status=404)&#xA;    auth_header = request.META.get('HTTP_AUTHORIZATION')&#xA;    token = auth_header[4:]&#xA;    response = requests.post(AUTH_URL, {""token"": token})&#xA;    if response.status_code == 400:&#xA;        return HttpResponse(status=403)&#xA;    return None&#xA;</code></pre>&#xA;&#xA;<p>However, the problem of my solution is every requests to services(not auth service) have to pass through that middleware. Therefore, client cannot access unprotected routes like before. &#xA;Any help is extremely appreciated. :D</p>&#xA;&#xA;<p>I used django restframework jwt <a href=""https://github.com/GetBlimp/django-rest-framework-jwt"" rel=""nofollow noreferrer"">https://github.com/GetBlimp/django-rest-framework-jwt</a>. </p>&#xA;"
45293123,How to design a multi-file processor using Golang?,2017-07-25 02:53:46,<go><design><microservices>,1,53,4,0.0,1,"<p>I'm trying to figure out how to design a service that can handle multiples files format, using micro-services for example:</p>&#xA;&#xA;<p>I have a customer using a file format A, another using format B and other using format C.</p>&#xA;&#xA;<p>After processing a specific format for each customer, I need to transform this format into an common format, and insert into database.</p>&#xA;&#xA;<p>The first thing I tried is to design one service per customer but all of them need to know the base format and if an update is needed in this base format, I need to update all of there services.</p>&#xA;&#xA;<p>I'm trying to decouple the service processor and have a single place to translate to base format.</p>&#xA;&#xA;<p>If my customer services know about the base format, if this format changes,  I need to update all of them. If I have a service that translate the format, this service needs to know all customer formats.</p>&#xA;&#xA;<p>How to design this solution?</p>&#xA;"
45168622,How to share constans between Rails microservices?,2017-07-18 13:45:07,<ruby-on-rails><ruby><microservices>,2,88,4,0.0,1,"<p>I have my main app and admin app built as a microservice, they are communicating via api. I want to share some constants between those two apps.</p>&#xA;&#xA;<p>For example I have User model that can have role Owner or Regular. In admin app I can search Users and in this search I have dropdown with hardcoded user type (Owner, Regular). This is okay, but when I change naming (e.g. Regular -> Standard) I have to update my Admin app also.</p>&#xA;&#xA;<p>To avoid changing admin app every time I change some core naming in my main app I want to somehow share those constants, so every change in main app will change Admin at the same time.</p>&#xA;&#xA;<p>For now I found 2 solutions, both with pros and cons:</p>&#xA;&#xA;<p>First is sending constants from main app to admin via json api. I have build a class that will fetch and store all constants in class variable, so it's available from every part of the the app. The good thing about this solution is performance (thanks to memoization it's only one api request) and it's easy to use later. The bad thing is I have no idea how to handle tests in this case. Of course I cannot let my tests make request to main app and stubbing this request makes the whole idea pointless, because after every change of constants in main app I will need to change tests in admin app. </p>&#xA;&#xA;<p>Second approach I thought of is building a gem that will store all constants. It's very easy to implement, but this means I will need to make changes to this repo every time I want to change constants in main app. Also I work with big team and they won't be happy that they have to work on 2 repos at the same time.</p>&#xA;&#xA;<p>What do you think about those solutions? First one seems to be perfect for me except tests, so maybe you have some ideas how to stub those constants without real values? I haven't tried gem solution yet so if you see some obstacles please let me know.&#xA;Maybe there is another better solution to this problem?</p>&#xA;"
45275679,Sharing code in Microservices,2017-07-24 08:28:19,<java-ee><architecture><jax-rs><microservices>,1,301,8,0.0,1,"<p>We have two services. However, in the past, these two services were one service, but have been split due to differing traffic requirements.</p>&#xA;&#xA;<p>The services are consumed by two kinds of clients; other services and UI clients (web, desktop and mobile).</p>&#xA;&#xA;<p>Consumers of service 1: Services, </p>&#xA;&#xA;<ol>&#xA;<li>Use a very limited number of exposed endpoints (<code>addInput</code>, <code>removeInput</code>).</li>&#xA;<li>Generates high traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Consumers of service 2: UI clients,</p>&#xA;&#xA;<ol>&#xA;<li>Using a large number of exposed endpoints</li>&#xA;<li>Generating less traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Currently, they are sharing code but as far as I can figure out micro-services should not share base code. Therefore we believe something is wrong using this approach.</p>&#xA;&#xA;<p>what are the key issues to understand in order to solve this kind of micro-services architecture issues?</p>&#xA;"
51863731,Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository,2018-08-15 17:38:33,<spring><microservices><spring-cloud>,1,87,3,1.0,1,"<p>I am developing <code>Microservices with Spring Boot 2.0, Eureka and Spring Cloud</code> taking a ref from : <a href=""https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/"" rel=""nofollow noreferrer"">https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/</a>. In this example, I am developing <code>config-service</code> with <code>spring-boot-starter-parent</code> version <code>2.0.4.RELEASE</code>. </p>&#xA;&#xA;<p>When I simply run this code I got the below error. No where steps mentioned to setup the local git or use remote git. Could anyone please guide me on this?</p>&#xA;&#xA;<p><strong>Error:</strong></p>&#xA;&#xA;<pre><code>Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.&#xA;23:04:07.774 [main] ERROR o.s.boot.SpringApplication - Application run failed&#xA;org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155)&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:544)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:398)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246)&#xA;    at com.prateek.ConfigServiceApplication.main(ConfigServiceApplication.java:12)&#xA;Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:126)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:413)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:174)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152)&#xA;    ... 8 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'servletEndpointRegistrar' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:226)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:214)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:91)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:80)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:250)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:237)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:54)&#xA;    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)&#xA;    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1421)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1411)&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)&#xA;    at java.lang.Thread.run(Unknown Source)&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 23 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1089)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBean(EndpointDiscoverer.java:143)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBeans(EndpointDiscoverer.java:132)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.discoverEndpoints(EndpointDiscoverer.java:122)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.getEndpoints(EndpointDiscoverer.java:116)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.servletEndpointRegistrar(ServletEndpointManagementContextConfiguration.java:75)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.CGLIB$servletEndpointRegistrar$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c$$FastClassBySpringCGLIB$$5ed0fb30.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.servletEndpointRegistrar(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 24 common frames omitted&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 48 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:732)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:474)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:514)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:502)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1198)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthIndicatorBeansComposite.get(HealthIndicatorBeansComposite.java:46)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration.healthEndpoint(HealthEndpointConfiguration.java:38)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.CGLIB$healthEndpoint$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444$$FastClassBySpringCGLIB$$c5cb8397.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.healthEndpoint(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 49 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:666)&#xA;    at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:91)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1341)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:572)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:818)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:724)&#xA;    ... 73 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1699)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:573)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1322)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1288)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1190)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1093)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:658)&#xA;    ... 96 common frames omitted&#xA;Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.util.Assert.state(Assert.java:73)&#xA;    at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.afterPropertiesSet(JGitEnvironmentRepository.java:245)&#xA;    at org.springframework.cloud.config.server.environment.MultipleJGitEnvironmentRepository.afterPropertiesSet(MultipleJGitEnvironmentRepository.java:69)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1758)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1695)&#xA;    ... 109 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;</code></pre>&#xA;"
51926575,Linking data in java microservices in a database per service implementation,2018-08-20 08:13:36,<java><spring><spring-boot><microservices><cqrs>,3,47,4,1.0,1,"<p>I am building a java / spring microservices where each service has it own database . Let's say i have a user service that stores user information in one of the table and a orders service that stores only the username of the person who orders as described below :-</p>&#xA;&#xA;<pre><code>User Service (UserService Database - User Table )&#xA;id     firstName    lastName     username     age &#xA;1       Chris        Brown       c.brown      20&#xA;2       John         Doe         j.doe        25&#xA;</code></pre>&#xA;&#xA;<p>And orders service as below</p>&#xA;&#xA;<pre><code> Order Service (OrderService Database - Order Table )&#xA;    id     username    productName     productPrice     OrderDate &#xA;    1      c.brown       Sony Mic       100$            20-08-2018&#xA;    2       j.doe       Television      j.doe           11-07-2018&#xA;</code></pre>&#xA;&#xA;<p>Question is what is the best approach to get firstName and lastName from user service while listing the orders . I am aware that microservices should communicate via Rest API , but if i have 1000 users with orders , i will have to loop 1000 times to get the firstName and lastName or take usernames as array , activity which might be expensive . </p>&#xA;&#xA;<p>I have read on using CQRS and event sourcing , but not sure how to best apply it in this scenario . </p>&#xA;"
51520654,Distributed transactions in microservices,2018-07-25 13:52:15,<microservices><distributed-transactions><saga>,3,55,0,0.0,1,"<p>I have 2 microservices <code>S1</code> and <code>S2</code>. <code>S1</code> invokes <code>S2</code> to update a data and then <code>S1</code> inserts another data,But let's consider <code>S1</code> fails,Then we need to rollback the data updated by <code>S2</code> or else we'll be in inconsistent state.</p>&#xA;&#xA;<p>I also gone through Saga patterns.will it satisfy this inconsistency</p>&#xA;&#xA;<p>Can anyone suggest any better solutions for this?</p>&#xA;"
40737349,Right place to do the service composition in API world?,2016-11-22 08:49:46,<microservices><aws-api-gateway><apigee><kong>,3,515,0,0.0,1,"<p>I am working in an environment where API is becoming a by default standard and we have a lot of micro services available... but still not able to meet the requirement of my customers...</p>&#xA;&#xA;<p>My customer demands a mix and match of data which I need to offer by writing new compositions and further host them as services.... </p>&#xA;&#xA;<p>1) What is the right platform to do this composition, gateways or host them on a dedicated paas instances?</p>&#xA;&#xA;<p>2) The moment I start going for composition, I end up paying for http overhead compared to get data directly from database</p>&#xA;&#xA;<p>Any help will be helpful</p>&#xA;"
40564595,Docker - run two processes in single container,2016-11-12 15:48:29,<ruby-on-rails><nginx><docker><docker-compose><microservices>,1,612,0,0.0,1,"<p>I've created Ruby on Rails project with Nginx. Rails app and Nginx runs in separate and linked containers. This configuration works fine. However...</p>&#xA;&#xA;<p><strong>1) Is it possible to run both together (Rails / Puma server + Nginx) in a single container?</strong> </p>&#xA;&#xA;<p><strong>2) How should the CMD command in Dockerfile look like?</strong></p>&#xA;&#xA;<p><strong>3) What command should I use as the ""command:"" attribute in docker-compose.yml?</strong></p>&#xA;&#xA;<p>I think that configuration to run them in separate containers is better solution, but I would like to get to know all possibilites.</p>&#xA;&#xA;<p><em>I use Puma as a Rails' app server and to run it I use command: bundle exec puma -C config/puma.rb</em></p>&#xA;"
40564979,Host WepAPI on Service Fabric,2016-11-12 16:25:29,<c#><asp.net-web-api><microservices><azure-service-fabric><devops>,3,755,0,1.0,1,"<p>We just stood up an on-premise MS Service Fabric cluster.  I have some WebAPI's i'd like to host in it.  I'm looking for resources on how to take our standard 4.5 WebAPI's and host them in Service Fabric without have to create a Service Fabric project and migrate it; that just seems too complex.</p>&#xA;&#xA;<p>I looked at some of the Service Fabric sample projects, and it seems all the projects are tightly coupled with Service Fabric.  My goal is keep these apps unaware of Service Fabric.</p>&#xA;&#xA;<p>Any links of information is greatly appreciated, thanks!</p>&#xA;"
46615008,Microservices: Service discovery/ circuit breaker for Event-driven architecture,2017-10-06 22:58:45,<spring-boot><microservices><event-driven><event-driven-design><circuit-breaker>,4,274,0,1.0,1,"<p>I'm fairly new to Microservices...</p>&#xA;&#xA;<p>I've taken an interest in learning more about two main patterns like <em><a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">service discovery</a></em> and <em><a href=""https://martinfowler.com/bliki/CircuitBreaker.html"" rel=""nofollow noreferrer"">circuit breaker</a></em> and I have conducted research on how these could be implemented. </p>&#xA;&#xA;<p>As a Java Developer, I'm using Spring Boot. From what I understand, these patterns are useful if microservices communicate via HTTP.</p>&#xA;&#xA;<p>One of the topics I've recently seen is the importance of event-driven architecture, which makes use of an event message bus that services would use to send messages to for other services, which subscribe to the bus&#xA;and process the message.</p>&#xA;&#xA;<p>Given this event-driven nature, how can service-discovery and circuit breakers be achieved/implemented, given that these are commonly applicable for services communicating via HTTP?</p>&#xA;"
46668418,Microservice return response first and then process the request,2017-10-10 13:46:12,<spring-boot><java-8><microservices>,2,582,5,1.0,1,<p>I am working on a solution for which i am trying to create a microservice which returns response immediately and then processes the request.</p>&#xA;&#xA;<p>I am trying to use Java 8 and Spring for this.</p>&#xA;
45661006,What is the difference between Monolith and n Layer?,2017-08-13 13:44:07,<architecture><microservices>,1,972,0,1.0,1,"<p>i have a few questions regarding <strong>monolith</strong> and <strong>n layer architecture</strong>.</p>&#xA;&#xA;<p>First, whats the difference between Monolith and n Layer architecture?</p>&#xA;&#xA;<p>Second, let's say I have a single Visual Studio solutions that consist of multiple projects such as:</p>&#xA;&#xA;<ol>&#xA;<li>Presentation Layer</li>&#xA;<li>Service Layer</li>&#xA;<li>Business Layer</li>&#xA;<li>Cross Layer</li>&#xA;<li>Data Layer</li>&#xA;<li>Unit Test</li>&#xA;</ol>&#xA;&#xA;<p>Is that considered as Monolith or n layer architecture?</p>&#xA;&#xA;<p>If I have microservices that consist (let's say) 3 Web API and I build each service in single separate Visual Studio solutions, <strong><em>it is ok</em></strong> to implement my previous project structure (service layer, business layer, data layer, etc)?</p>&#xA;&#xA;<p>Thank you very much and sorry for my bad english.</p>&#xA;"
45776238,Golang microservice project structure,2017-08-19 21:00:10,<go><microservices><directory-structure>,3,2271,0,2.0,1,"<p>I'm at an initial stage of creating a microservice application in Go, but due to the way that the import paths and directories are handled I'm not quite sure what's best way to structure the project files.</p>&#xA;&#xA;<p>Normally, the project would look something like this in Java:</p>&#xA;&#xA;<pre><code>|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>Now if I do it the same way in Go, the import paths become somewhat cumbersome:</p>&#xA;&#xA;<pre><code>import (&#xA;       ""fmt"" &#xA;       ""github.com/user/myproject/gateway_microservice/src/package1""&#xA;       ""github.com/user/myproject/gateway_microservice/src/package2""&#xA;)&#xA;</code></pre>&#xA;&#xA;<p>Additionally, I hear that the idiomatic way is to put all <code>main.go</code> files in a separate <code>cmd</code> directory, which adds to the confusion. Would it look something like this:</p>&#xA;&#xA;<pre><code>|-- cmd&#xA;   |-- gateway_microservice&#xA;      |-- main.go&#xA;   |-- config_microservice&#xA;      |-- main.go&#xA;   |-- recommendation_microservice&#xA;      |-- main.go&#xA;   |-- users_microservice&#xA;      |-- main.go&#xA;|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>What is the 'correct' or idiomatic way of structuring a project like this in Go?</p>&#xA;"
45751211,Automated tests on contracts between microservices?,2017-08-18 07:45:16,<c#><api><integration-testing><microservices><contract>,2,258,4,0.0,1,"<p>Say we have a CreditCardService microservice that depends on a ThreeDSecureService microservice, communicating using JSON.</p>&#xA;&#xA;<p>Minor changes in the API (or even implementation) of the ThreeDSecureService could silently break the CreditCardService (and other potential clients). So, we would like automated tests.</p>&#xA;&#xA;<p>I see two flawed approaches, and am wondering how to improve.</p>&#xA;&#xA;<ol>&#xA;<li>Integration testing in ThreeDSecureService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The accompanying test project of ThreeDSecureService could have an integration test with a fixed JSON input. Faking out any dependencies, it could run an otherwise complete call for that input, confirming that the service swallows the input.</p>&#xA;&#xA;<p>The problem here is that if someone fails to realize how their changes could break clients, they are almost as likely to 'fix' the tests to match their changes.</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Integration testing in CreditCardService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The <em>client</em> is the one that actually wants to test assertions about ThreeDSecureService's expected input. However, that would require the client solution to include the ThreeDSecureService project, as well as any projects it depends on. This would negate many of the advantages we get from using microservices!</p>&#xA;&#xA;<p><strong>How do we make assertions from the client (safeguarding the dependency) without breaking the loose coupling we get from using microservices?</strong></p>&#xA;"
45673863,Communication between Spring microservices,2017-08-14 11:49:01,<java><spring><api><spring-mvc><microservices>,2,664,4,0.0,1,"<p>I am still learning microservices and I am asking myself, how do we secure our rest-points? I use the famous framework Spring Boot which extends from Spring. What is the best or most used pattern to secure the endpoints of a rest API?</p>&#xA;&#xA;<p>When I use Spring Security with oAuth2, I always need to send the credentials in the body of the request. Is there an approach without the credentials and which is easier to implement? Like API-Tokens?</p>&#xA;&#xA;<p>I always prefer practical tutorials.</p>&#xA;"
45642575,microservices or SOA: how to respond one specific request,2017-08-11 19:32:36,<architecture><soa><microservices>,2,137,5,0.0,1,"<p>I am interested in microservices and SOA. I read some tutorials. This is my understanding SOA. The API gateway receives lots of requests (requestA, requestB, ...) and put requests in messaging queues. Micro-services will consume the events in the messaging queues and do some processing. My question is after processing, how the response can be returned to requests (responseA to requestA, responseB to requestB).</p>&#xA;&#xA;<p>I am not sure whether my understanding is right or wrong and whether messaging is used in every architecture. </p>&#xA;&#xA;<p>Anyone can give me more details/examples how to decouple/connect the API gateways and the microservices. How to respond to requests? should the connection between API gateways and clients kept alive?</p>&#xA;&#xA;<p>Sorry if my question is not clear. I am confused and have no idea how to understand each concept.</p>&#xA;&#xA;<p>Any comment welcomed. Thanks</p>&#xA;"
45791262,How to orchestrate multiple microservices on local env?,2017-08-21 07:14:59,<docker><development-environment><microservices><orchestration>,1,584,6,0.0,1,"<p>at the moment of speaking I have a bunch of services running each one on its own container&#xA;Every repo of code has its own Docker file and docker compose file in order to bring up the service on my local dev-machine</p>&#xA;&#xA;<p>Everything is fine and I'm able o access each service at</p>&#xA;&#xA;<p><a href=""http://localhost:[service"" rel=""nofollow noreferrer"">http://localhost:[service</a> mapped/exposed port]</p>&#xA;&#xA;<p>Problem is that services are augmenting and I'm thinking that could be a better idea to have everything in a local private network, where each service 's container has its own IP address.</p>&#xA;&#xA;<p>Is this a better approach to orchestrate containers locally?</p>&#xA;&#xA;<p>Where should I start from to make up my mind?</p>&#xA;"
50830715,REST-based services running as pods on Kubernetes in Azure with intermittent timeouts,2018-06-13 06:48:18,<azure><docker><kubernetes><microservices>,3,36,0,0.0,1,"<p>We have a number of different REST-based services running in Azure within a Kubernetes (version 1.9.6) cluster.  </p>&#xA;&#xA;<p>Two of the services, let's say A and B needs to communicate with each other using REST-calls.  Typically, something like the following:</p>&#xA;&#xA;<pre><code>Client calls A (original request)&#xA;A calls B (request 1)&#xA;B calls A (request 2)&#xA;A responds to B (request 2)&#xA;B responds to A (request 1)&#xA;A responds to the original request&#xA;</code></pre>&#xA;&#xA;<p>The above being a typical intertwined micro-services architecture.  Manually running the docker instances works perfectly on our local test servers.</p>&#xA;&#xA;<p>The moment we run this in Kubernetes on Azure we get intermittent timeouts (60+ seconds) on the micro-services calling each other through Kubernetes' networking services.  After a timeout, repeating the request would then often give correct responses in a few micro-seconds.</p>&#xA;&#xA;<p>I am stuck at this point as I have no idea what could be causing this.  Could it be the dynamic routing?  The virtualised network? Kubernetes configuration? </p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
50889657,Microservice synchronous communication - service to service or message broker,2018-06-16 16:26:32,<spring><spring-boot><apache-kafka><microservices>,2,53,0,2.0,1,"<p>I am developing a series of microservices using Spring Boot and Kafka. For asynchronous communication, I am using Kafka which is working well. </p>&#xA;&#xA;<p>I have a use case where I require synchronous communication between two microservices (a user registers a profile via the user profile service which needs to create an auth account in the auth microservice). </p>&#xA;&#xA;<p>Should I just call the auth service directly (service to service communication) or should I use Kafka?</p>&#xA;&#xA;<p>Any examples or best practise advice would be appreciated. </p>&#xA;"
50849415,What is the best way to do microservice REST API versioning?,2018-06-14 04:00:55,<spring><rest><microservices><aws-api-gateway><api-versioning>,1,233,3,0.0,1,"<p>I'm developing this project using Spring and hosting in AWS EC2 instances. As few new requirements coming up, I have to change  my API contracts. But I don't want to break the current clients. So, I'm trying to implement some REST APIs with versioning. So that whenever I update the endpoints the consumer applications won't crash. But I'm confused on how to do the API versioning. I thought of two ways. </p>&#xA;&#xA;<ol>&#xA;<li><p>Create a next version endpoint in the same server,(in spring using RequestMaping(""/v1/api1""),RequestMaping(""/v2/api1"") something like this.)</p></li>&#xA;<li><p>Other wise completely run the v2 APIs in new server instance but keep the same API endpoint footprint and use AWS APIGateway as a proxy and configure the versioning there, then route to old server and new server depending on the version number in the request.</p></li>&#xA;</ol>&#xA;&#xA;<p>But the first approach will lead to lot of code duplication and code management messy I believe. Because we are keeping the same functionality with variations.</p>&#xA;&#xA;<p>In the second approach I have to keep two set of instances for bot versions if me Version increases then It's hard to manage those instances, specially, when I will have around 15 micro-service instances. And it'll not be cost effective also. Because my company is a startup , so I need to consider this fact also.</p>&#xA;&#xA;<p>Is there any best practices regarding API versioning and managing multiple version of endpoints? I'm open for any suggestions and guidelines. If multiple server is the solution also, I'm open to reconsider the cost limitations. I need the best solution for this problem. </p>&#xA;"
50759872,Should I ignore the guidance and avoid putting validation in the command objects?,2018-06-08 11:41:08,<c#><domain-driven-design><microservices>,1,95,12,0.0,1,"<p>I am using CQRS.  Everywhere I read tells me to put validation logic in the command objects.  For example, see this link: <a href=""https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/"" rel=""nofollow noreferrer"">https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/</a></p>&#xA;&#xA;<p>Please see the command below (taken from the link):</p>&#xA;&#xA;<pre><code>public class ChangeNameCommand { &#xA;   [Required] &#xA;   public string FirstName { get; set; } &#xA;   [Required] &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and the Business Object below (also taken from the link - note that I have changed the the parameter passed to the Customer constructor from a class to an interface):</p>&#xA;&#xA;<pre><code>public class Customer &#xA;{ &#xA;   public string FirstName { get; private set; } &#xA;   public string LastName { get; private set; } &#xA;&#xA;   public void ChangeName(IChangeNameCommand command) { &#xA;     FirstName = command.FirstName; &#xA;     LastName = command.LastName; &#xA;   } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>In my case the commands are stored in one class library and the business objects in others (because the commands are shared by multiple microservice type projects).  If I follow the guidance (and put the validation in the commands) then I believe there is nothing to stop a developer doing this:</p>&#xA;&#xA;<pre><code>public class ChangeNameCommandWithoutValidation : IChangeNameCommand { &#xA;   public string FirstName { get; set; } &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and then passing the command (without the validation) to the domain object.  In this case I believe the Domain Object has no control what is passed to it?</p>&#xA;&#xA;<p>Therefore should I be going against all of the guidance I can find and do the validation in the domain object? I believe I should do this because the commands are in a separate class library to the domain objects.  Have I understood this correctly?</p>&#xA;&#xA;<p>I believe this question is also relevant when passing an event to the customer domain object (when using event sourcing).</p>&#xA;"
28114758,Microservices with spring integration and spring boot,2015-01-23 16:51:43,<spring-boot><spring-integration><microservices>,2,2113,0,1.0,2,<p>I'm a bit new with microservices (and SI) and want to make a POC following a microservices architecture style. I've seen that I can use Spring Boot for deployment and SI for the development but found little docs about how to combine them (just an example in Spring Boot home page). Do you know about best practices or recommendations on how to combine this two technologies? </p>&#xA;
25812816,How to shutdown dropwizard application?,2014-09-12 16:30:05,<java><dropwizard><microservices>,5,6562,2,0.0,2,"<p>I am trying to come up with a microservice using dropwizard. &#xA;The documentation tells how to start the application, but says nothing about terminating it gracefully. Fir example, apache tomcat has both startup <em>and</em> shutdown scripts. </p>&#xA;&#xA;<p>So does anyone know how to terminate a dropwizard application other than pressing <code>Ctrl+C</code> of <code>kill</code> ? </p>&#xA;"
30449278,Automation of releases of microservices-based application,2015-05-26 04:04:42,<git><automation><release-management><salt-stack><microservices>,4,894,0,0.0,2,"<p>We are working on the application that consists of many standalone services. It has advantages over the single monolithic application, but not when we do releases.</p>&#xA;&#xA;<p>We do weekly release cycles. Each service/component located in the separate git repository. 'A release' - is several features that we put into wild. Usually only several components should be updated. We manage servers using saltstack. To make a release salt scripts update component's versions using git.latest state. The problem is to specify right versions.</p>&#xA;&#xA;<p>This is where the manual work that I'd like to automate. To update versions I have to manually check each component's repository, merge development branch into master and tag according to symantec versioning rules. Then I write new version in salt scripts. We have over 10 components so this is rather boring and error prone process.</p>&#xA;&#xA;<p>Probably we doing it wrong, I'll be glad to hear any advices how to do it better, thanks.</p>&#xA;"
31973473,Message Bus versus Quasar/HTTP for internal Microservice Calls,2015-08-12 19:08:08,<java><microservices><message-bus><backpressure><quasar>,1,981,0,0.0,2,"<p>I am looking to optimize a microservice architecture that currently uses HTTP/REST for internal node-to-node communication.</p>&#xA;&#xA;<p>One option is implementing backpressure capability into the services, (eg) by integrating something like Quasar into the stack.  This would no doubt improve things.  But I see a couple challenges.  One is, the async client threads are transient (in memory) and on client failure (crash), these retry threads will be lost.  The second, in theory, if a target server is down for some time, the client could eventually reach OOM attempting retry because threads are ultimately limited, even Quasar Fibers.</p>&#xA;&#xA;<p>I know it's a little paranoid, but I'm wondering if a queue-based alternative would be more advantageous at very large scale.</p>&#xA;&#xA;<p>It would still work asynchronously like Quasar/fibers, except a) the queue is centrally managed and off the client JVM, and b) the queue can be durable, so that in the event client and or target servers go down, no in flight messages are lost.</p>&#xA;&#xA;<p>The downside to queue of course is that there are more hops and it slows down the system.  But I'm thinking there is probably a sweet spot where Quasar ROI peaks and a centralized and durable queue becomes more critical to scale and HA.</p>&#xA;&#xA;<p><strong>My question is:</strong>  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Has this tradeoff been discussed?  Are there any papers on using a&#xA;  centralized external queue / router approach for intraservice&#xA;  communication.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>TL;DR;</strong>  I just realized I could probably phrase this question as:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""When is it appropriate to use Message Bus based intraservice&#xA;  communication as opposed to direct HTTP within a microservice&#xA;  architecture.""</p>&#xA;</blockquote>&#xA;"
29387250,RESTful Microservice failover & load balancing,2015-04-01 09:30:10,<spring-boot><load-balancing><failover><microservices>,1,1748,0,2.0,2,<p>At the moment we have some monolithic Web Applications and try to transfer the projects to an microservices infrastructure. </p>&#xA;&#xA;<p>For the monolithic application is an HAProxy and Session Replication to have failover and load balancing. </p>&#xA;&#xA;<p>Now we build some RESTful microservices with spring boot but it's not clear for me what is the best way to build the production environment. &#xA;Of course we can run all applications as unix services and still have a reverse proxy for load balancing and failover. This solution seems very heavy for me and have a lot of configuration and maintenance. Resource Management and scaling up or down servers will be always a manually process. </p>&#xA;&#xA;<p>What are the best possibilities to setup production environment with 2-3 Servers and easy resource management? &#xA;Is there some solution the also support continuous deployment?</p>&#xA;
30000824,How to use kubernetes replication controllers to replicate message-based services,2015-05-02 09:50:02,<rabbitmq><kubernetes><microservices>,1,1121,0,0.0,2,"<p>We usually use message passing to send messages to decoupled services. This makes service discovery a non-issue, because (with AMQP in RabbitMQ for instance) you can use the broker's routing capability to dispatch messages to the right queues that feed the correct services. Load balancing is also handled by the message broker.</p>&#xA;&#xA;<p>Enter kubernetes.</p>&#xA;&#xA;<p>The use case that is usually laid out when talking about service replication and re-spawning failing services, is when your clients use some active protocol like http to contact a service, even if this service handles requests asynchronously. In this context, it is a natural fit to have replication controllers, that manage a group of services and a single entry point to load balance between them.</p>&#xA;&#xA;<p>I like kubernetes' intuitive concepts, like rolling deployments, but how to you control this beasts that don't have an http interface ?</p>&#xA;&#xA;<p><strong>UPDATE:</strong>&#xA;I am not trying to set up a cluster of message brokers. I am looking at message consumers as services. Service clients don't connect directly to the services, they send messages to the message broker. The message broker acts as a load balancer in a way, and dispatches the messages to the subscribed queue consumers. These consumers implement the service.</p>&#xA;&#xA;<p>My question gravitates around the fact that most usage patterns in demos handle services that are called via http, and kubernetes does a good job here to create a service proxy for these services, and a replication controller. Is it possible to create replication controllers for my kind of service, which does not have a http interface per se, and have all the benefits of rolling updates, and minimum instances?</p>&#xA;"
30053782,"Microservice architecture, authentication and other services",2015-05-05 13:02:18,<java><web-services><api><amqp><microservices>,1,648,0,0.0,2,"<p>I m studying the micro-services architecture, and I m have a question.</p>&#xA;&#xA;<p>Admitting that I have multiple services on different host like following :</p>&#xA;&#xA;<ul>&#xA;<li>Authentication service on <a href=""http://80.80.80.80:9000/"" rel=""nofollow"">http://80.80.80.80:9000/</a></li>&#xA;<li>Billing service on <a href=""http://90.90.90.90:1234/"" rel=""nofollow"">http://90.90.90.90:1234/</a></li>&#xA;<li>Planning service on <a href=""http://70.70.70.70:7412/"" rel=""nofollow"">http://70.70.70.70:7412/</a></li>&#xA;</ul>&#xA;&#xA;<p>My question is, when a user request on the gateway, he sends an access token (stateless, oauth2.0, whatever), then the gateway asks the authentication service, and if the user exists and has permissions, he access the ressources on another service.</p>&#xA;&#xA;<p>That's okay, but what if I try to call directly the BillingService from his host ? You can tell me that the port is closed, and I agree with that.</p>&#xA;&#xA;<p>But does it mean that they are port allowed only from a certain host to another ? Meaning that the billing service on port 1234 is allowed only from the gateway machine ?</p>&#xA;&#xA;<p>Am I missing something ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
30739851,How can microservices be truly independent when using an ESB (i.e. MassTransit)?,2015-06-09 18:20:33,<c#><esb><servicebus><masstransit><microservices>,1,611,0,0.0,2,"<p>I'm doing some initial investigation into decomposing a current monolithic system by using MassTransit.  My main reason for going with a queue-based ESB is that the set of features I'm tackling first are using a shared database as, essentially, a queue.</p>&#xA;&#xA;<p>I've also been reading ""Building Microservices"" and while I haven't yet finished it, one of the core tenets appears to be that microservices should essentially be standalone.</p>&#xA;&#xA;<p>How can I reconcile using MassTransit which by necessity shares a message library (or at least contracts) and the fact that these services shouldn't have to ""know"" anything about each other?</p>&#xA;"
30649582,Normalized or Denormalized Data in Microservices and Service Composition,2015-06-04 16:43:12,<domain-driven-design><soa><composition><microservices>,3,660,2,1.0,2,"<p>So our development team has been working towards Microservices for the past 6-8 months and have picked up a lot of steam. </p>&#xA;&#xA;<p>We have experienced several <code>gotcha</code> moments in that time, and are humble enough to know that we are in for many more as we move closer to moving our platform to production.</p>&#xA;&#xA;<p>One area that I can't quite put my finger on is how we are to treat our data between our service boundaries. I hear a lot of statements form large companies that have successfully implemented Microservices, but I can never seem to get straight advice and reasoning.</p>&#xA;&#xA;<p><strong>Specifically, given two service domains  <code>User</code> and <code>Contacts</code>,and assuming that a <code>User</code> has a <code>Contact</code> object associated with it, what are the options for each of these two service domains in regards to managing their own data?</strong></p>&#xA;&#xA;<p><strong>Should the <code>User</code> have a <code>ContactID</code> stored with it, or should it store the entire <code>Contact</code> object?</strong></p>&#xA;&#xA;<p>I have seen many reliable service oriented development teams (Netflix,Amazon,Nike,etc) make statements such as the following:</p>&#xA;&#xA;<p><strong>""Normalization is the root of all evil...""</strong></p>&#xA;&#xA;<p><strong>""Break all that is shared...""</strong></p>&#xA;&#xA;<p><strong>""Share nothing...""</strong></p>&#xA;"
30732982,What's the correct way to embed a remote AngularJS application into a webpage?,2015-06-09 13:10:16,<javascript><php><angularjs><html5><microservices>,1,695,2,0.0,2,"<p>I'm trying to work out the correct way to embed an AngularJS application into another web page (served by another app). I have two apps, running on different servers:</p>&#xA;&#xA;<p>App 1 - PHP app</p>&#xA;&#xA;<p>App 2 - AngularJS app (calendar widget of sorts)</p>&#xA;&#xA;<p>The PHP app is the primary app, into which I want to embed the calendar, which is served from a remote server. I have full access to both servers, and to both apps. The idea is that I want to be able to re-use the Angular app elsewhere, so it needs to be as loosely coupled as possible to the PHP app, preferably embedded in a single line of code. </p>&#xA;&#xA;<p>I am currently using a HTML5  tag, which seems to work well, but I was wondering if there's anything wrong with this approach, or if there's a better means of doing what I'm after.</p>&#xA;&#xA;<p>I should mention that I'm happy to use a HTML5-only solution, I'm no worried about backwards compatibility with older browsers.</p>&#xA;&#xA;<p>No iFrame solutions, unless there's a REALLY valid solution. My ultimate goal is to head towards a microservice-style architecture.</p>&#xA;&#xA;<p>Thanks in advance for your help.</p>&#xA;"
35140042,Django or Flask or Falcon for Microservices,2016-02-01 20:49:21,<django><flask><architecture><microservices><falconframework>,1,3874,2,1.0,2,"<p>Why is Microservice Architecture better than monolithic architecture? I know the answer will be because the microservice architecture is more scalable and each service is independent of each other etc.</p>&#xA;&#xA;<p>My following question is: should we build using Flask or Django REST Framework?</p>&#xA;&#xA;<p>I have also heard of a framework know as <a href=""http://falconframework.org"" rel=""nofollow"">Falcon</a> as per there documentation seems good enough.</p>&#xA;"
32996097,Single Sign On + Microservices,2015-10-07 15:17:12,<java><spring><oauth-2.0><microservices>,1,654,0,2.0,2,"<p>I have a couple web apps which I will try to convert in microservices (In the future maybe I will have more). Before this, I would like to create a microservice for authentication and authorization which permits SSO.</p>&#xA;&#xA;<p>I read a lot about <a href=""http://jasig.github.io/cas/4.1.x/index.html"" rel=""nofollow"">CAS</a> but I have the feeling that seems an old solution and I don't know if it is a good idea for microservices' architecture.</p>&#xA;&#xA;<p>On the other hand I have been researching about Oauth2, I know it is only for authorizations (but you need to be authenticated for that) so.. maybe it could be a good option. Also I have found a good guide for implement <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow"">Oauth2 SSO with Spring</a>. However Oauth2 is for third-party so.. neither know if it is the best solution.</p>&#xA;&#xA;<p>As you see, I'm a bit confused . Other terms and tecnologies are in my head like SAML, OpenId... But I don't know which choose.</p>&#xA;"
26706240,Why does 12factor recommend not to daemonize processes?,2014-11-03 00:41:11,<12factor><microservices>,3,244,0,0.0,2,"<p><a href=""http://12factor.net/concurrency"" rel=""nofollow"">12factor recommends not to daemonize processes</a>. What are the disadvantages of doing so?</p>&#xA;"
28387907,Push Data onto Queue vs Pull Data by Workers,2015-02-07 21:57:31,<message-queue><soa><microservices>,2,801,0,0.0,2,"<p>I am building a web site backend that involves a client submitting a request to perform some expensive (in time) operation. The expensive operation also involves gathering some set of information for it to complete.</p>&#xA;&#xA;<p>The work that the client submits can be fully described by a <code>uuid</code>. I am hoping to use a service oriented architecture (SOA) (i.e. multiple micro-services).</p>&#xA;&#xA;<p>The client communicates with the backend using RESTful communication over HTTP. I plan to use a queue that the workers performing the expensive operation can poll for work. The queue has persistence and offers decent reliability semantics.</p>&#xA;&#xA;<p>One consideration is whether I gather all of the data needed for the expensive operation upstream and then enqueue all of that data or whether I just enqueue the <code>uuid</code> and let the worker fetch the data.</p>&#xA;&#xA;<p>Here are diagrams of the two architectures under consideration:</p>&#xA;&#xA;<p><strong>Push-based (i.e. gather data upstream):</strong>&#xA;<img src=""https://i.stack.imgur.com/rxZQe.png"" alt=""Push-based (i.e. gather data upstream)""></p>&#xA;&#xA;<p><strong>Pull-based (i.e. worker gathers the data):</strong>&#xA;<img src=""https://i.stack.imgur.com/R9aJN.png"" alt=""Pull-based (i.e. worker gathers the data)""></p>&#xA;&#xA;<p>Some things that I have thought of:</p>&#xA;&#xA;<ol>&#xA;<li>In the push-based case, I would be likely be blocking while I gathered the needed data so the client's HTTP request would not be responded to until the data is gathered and then enqueued. From a UI standpoint, the request would be pending until the response comes back.</li>&#xA;<li>In the pull based scenario, only the worker needs to know what data is required for the work. That means I can have multiple types of clients talking to various backends. If the data needs change I update just the workers and not each of the upstream services.</li>&#xA;</ol>&#xA;&#xA;<p>Any thing else that I am missing here?</p>&#xA;"
28572202,Gradle + Dropwizard + Shadow -> Could not find or load main class,2015-02-17 22:18:56,<java><gradle><dropwizard><microservices>,2,1931,0,0.0,2,"<p>I'm trying to create a simple microservice using Dropwizard and Gradle as a build system. &#xA;No database, only REST endpoint to expose.</p>&#xA;&#xA;<p>So I have a controller: </p>&#xA;&#xA;<pre><code>@Path(""/domainurl/"")&#xA;@Produces(MediaType.APPLICATION_JSON)&#xA;public class SimpleController {&#xA;&#xA;    @GET&#xA;    public Example resourceExample() {&#xA;        return new Example(""something"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My application main class:</p>&#xA;&#xA;<pre><code>public class Application extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration configuration, Environment environment) throws Exception {&#xA;        final SimpleCOntroller controller = new SimpleController();&#xA;        environment.jersey().register(controller);&#xA;    }&#xA;&#xA;    public static void main(String[] args) throws Exception {&#xA;        new Application().run(args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Example is a simple value object with one string property, MyConfiguration is an empty class at this moment.</p>&#xA;&#xA;<p>And build.gradle:</p>&#xA;&#xA;<pre><code>buildscript {&#xA;    repositories {&#xA;        jcenter()&#xA;    }&#xA;&#xA;    dependencies {&#xA;        classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.0'&#xA;    }&#xA;}&#xA;&#xA;apply plugin: 'java'&#xA;apply plugin: 'groovy'&#xA;apply plugin: 'application'&#xA;apply plugin: 'com.github.johnrengelman.shadow'&#xA;&#xA;mainClassName = ""com.example.Application""&#xA;&#xA;//&#xA;dependencies&#xA;//&#xA;&#xA;run {&#xA;    args 'server', './src/config/microservice.yml'&#xA;}&#xA;&#xA;task wrapper(type: Wrapper) {&#xA;    gradleVersion = '2.1'&#xA;}&#xA;&#xA;jar {&#xA;    manifest {&#xA;        attributes 'Main-Class': mainClassName&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But after build, when I type:</p>&#xA;&#xA;<pre><code>java -jar MyApp.jar&#xA;</code></pre>&#xA;&#xA;<p>I'm still getting:</p>&#xA;&#xA;<pre><code>Error: Could not find or load main class com.example.Application&#xA;</code></pre>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
33308154,Blue green deployment on microservices - how to route 10% of traffic to one one instance and remaining 90% of traffic to other instance,2015-10-23 17:25:00,<cloud><ibm-cloud><cloudfoundry><microservices>,3,188,0,0.0,2,<p>I have two instances of the same microservice in Bluemix(cloud Foundry). I want to route 90% of the traffic to one service and remaining 10% of the traffic to other service. Can you tell me how to do this in Bluemix</p>&#xA;
32863771,SpringBoot RestController generic POST type,2015-09-30 10:27:41,<java><spring><rest><spring-boot><microservices>,2,1908,2,1.0,2,"<p>I'm experimenting with building microservices using Spring Boot.</p>&#xA;&#xA;<p>I have a back-end API that receives ResponseEntity POST requests and processes it (saving to database etc). Where Data is an Object of a self-created class.</p>&#xA;&#xA;<p>Now I have a top-level API (that handles authentication,..). The end-users will communicate with the back-end services through this top-level API. So this API basically just has to forward all the requests to the right back-end api's.</p>&#xA;&#xA;<p>In this top API I don't want to need to include all my classes (e.g. the Data class in this case) and I would rather just send it as String json data or something. So I tried this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;    ResponseEntity&lt;String&gt; createUnit(@RequestBody String data) {&#xA;        URI uri = util.getServiceUrl(""dataservice"");&#xA;        String url = uri.toString() + ""/data"";&#xA;&#xA;        ResponseEntity&lt;String&gt; result = restTemplate.postForEntity(url, data, String.class);&#xA;        return new ResponseEntity&lt;String&gt;(result.getBody(), HttpStatus.OK);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>But this results in an <code>org.springframework.web.client.HttpClientErrorException: 415 Unsupported Media Type</code>. </p>&#xA;&#xA;<p>So my question is, is there a way to forward these requests to my back-end without the need to include all my Object classes in my API? I figured this should be able since this is the same as when a web-browser sends requests in json format without knowing what kind of Object the data actually is.</p>&#xA;&#xA;<p>The back-end handling looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;ResponseEntity&lt;Data&gt; saveData(@RequestBody Data data) {&#xA;    //Some code that processes the data&#xA;    return new ResponseEntity&lt;Data&gt;(dataProcessed, HttpStatus.OK);&#xA;}&#xA;</code></pre>&#xA;"
32887039,How to implement HATEOAS in a Spring-Boot microservices project,2015-10-01 11:56:39,<java><spring><rest><microservices><spring-hateoas>,1,488,5,0.0,2,"<p>Lately I've been experimenting with building <strong>microservices</strong> using the Java <strong>Spring Boot</strong> framework. I currently have a working Microservices systeem with several resources (which all have its own independent service), e.g.: A Book service and a Review service.&#xA;Each service has its own <strong>RestController</strong> and uses a <strong>MongoRepository</strong> to interact with its database.</p>&#xA;&#xA;<p>The end-users of the application (web-clients) will not communicate with these independent services itself but with an API above them.</p>&#xA;&#xA;<p>This API calls the book and review services, merges the data and returns it back to the client. Note that all the communication is using <code>ResponseEntity&lt;T&gt;</code> (<code>T</code> can be <code>Book</code>, <code>Review</code>, <code>Iterable&lt;Book&gt;</code>, etc, ..)</p>&#xA;&#xA;<p>But after reading a while I learnt about <strong>HATEOAS</strong> and I would like to use it in my microservices set-up. Now my question is, what is the best way to implement this?</p>&#xA;&#xA;<p>Some examples I've found extend the entity classes (which in my case would be the Book entity or the Review entity with Spring's <code>ResourceSupport</code> class). But this causes errors since my entity's have an ID parameter and the <code>getId()</code> method clashes with the <code>getId()</code> method of the ResourceSupport class. </p>&#xA;&#xA;<p>Other examples contain a <code>MongoRepository</code> annotated with <code>@RestResource</code> instead of using a <strong>Controller</strong>.</p>&#xA;&#xA;<p>So my question is, what would in this case be the best way to implement HATEOAS? And e.g. when the Book service adds links (the HATEOAS way), how can the API above change these links? Since the end-users will only do calls to this API and the API just processes these requests and delegates it to the necesarry sub-services.</p>&#xA;"
36876367,Cloud Service to Service Fabric authentication?,2016-04-26 21:47:08,<c#><azure><microservices><azure-service-fabric>,1,1084,0,1.0,2,<p>What's the recommended way to authorize service-to-service traffic in Service Fabric?</p>&#xA;&#xA;<p>I have a Classic Cloud Service that I'd like to have call a Web API endpoint in a service fabric service. Is there a way to open up specific ports to specific IPs in a service fabric cluster? Or is there a better way to make sure my service fabric endpoints can not be called from the outside internet?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
36877722,Microservices per DB table?,2016-04-26 23:41:28,<microservices>,1,631,4,0.0,2,"<ul>&#xA;<li>Person</li>&#xA;<li>NativeCountry</li>&#xA;<li>SpokenLanguages</li>&#xA;</ul>&#xA;&#xA;<p>Had a query about MIcroservice granularity. Will try to explain my query with an example.</p>&#xA;&#xA;<p>Assume I have above 3 tables in database, with Many to one relationship between Person -> NativeCountry table. One to Many relationship between person -> LanguagesSpoken in database.</p>&#xA;&#xA;<p>Front end Application is suppose do CRUD operation on person entity and will also have capability to retrieve people based on nativecountry or spokenlanguage.</p>&#xA;&#xA;<p>Does it makes sense to develop 3 independent microservices for each of the entities and then use Aggregator Microservice at upper layer to build combined data for UX layer or I should think of combining those to build just single microservice?</p>&#xA;"
40296598,Micro-services approach: Isolation and decoupling,2016-10-28 01:27:44,<design><architecture><microservices>,1,163,3,0.0,2,"<p>I've to add a service to my Micro-services architecture and&#xA;my new services needs to compute data he's responsable of. These computations occurs at a relatively high frequency.</p>&#xA;&#xA;<p>In order to compute things, my new service needs to retrieve additional infos from another service (lets say from the same bounded context)</p>&#xA;&#xA;<p>The issue here is that all these calls on every computation might cause some performance issues.</p>&#xA;&#xA;<p>What do you think is the best approach to take here?&#xA;Is it a good idea to let my new service save a kind of snapshot of the additional infos it needs (asynchronous synchronisation with the other service) so that it doesn't have to perform all those calls every time it needs to compute. </p>&#xA;"
38964840,Text search for microservice architectures,2016-08-16 00:17:58,<elasticsearch><architecture><microservices>,1,1133,0,1.0,2,"<p>I am investigating into implementing text search on a microservice based system. We will have to search for data that span across more than one microservice. </p>&#xA;&#xA;<p>E.g. say we have two services for managing Organisations and managing Contacts. We should be able to search for organisations by contact details in one search operation.</p>&#xA;&#xA;<p>Our preferred search solution is Elasticsearch. We already have a working solution based on embedded objects (and/or parent-child) where when a parent domain is updated the indexing payload is enriched with the dependent object data, which is held in a cache (we avoid making calls to the service managing child directly for this purpose). </p>&#xA;&#xA;<p>I am wondering if there is a better solution. Is there a microservice pattern applicable to such scenarios?</p>&#xA;"
39134238,Client authentication in microservices using JWT and OpenID Connect,2016-08-24 22:57:09,<api><authentication><jwt><microservices>,1,994,0,1.0,2,"<p>I've some questions regarding authentication in a microservices architecture. I've right now a monolithic application and my goal is to split the application in small microservices.</p>&#xA;&#xA;<p>My bigest problem is for authentication (for now). After reading a LOT a documentation, It seems that the best solution is to use OpenID Connect to authenticate an user to retrieve a JWT that can by passed with the request to the microservices. </p>&#xA;&#xA;<p>Also, to avoid having multiple endpoints, you can deploy and API Gateway to have only one endpoint for the end user. Ok, so now I've two questions with this architecture.</p>&#xA;&#xA;<p>The standard flow for authentication will be :</p>&#xA;&#xA;<p>An user contact my identity server in OpenID Connect with the implicit flow and get the id_token (JWT) and also the access_token. The user can now contact my API with this access_token. The API Gateway will valide the access_token with the identity server and also retrieve the JWT to add it to the sub request to the microservice API. </p>&#xA;&#xA;<p>1/ How the API Gateway can get the JWT from the access_token? From what I red from the documentation (<a href=""http://openid.net/specs/openid-connect-core-1_0.html"" rel=""nofollow"">http://openid.net/specs/openid-connect-core-1_0.html</a>), It can contact the ""/userinfo"" endpoint but It will get just the JSON format not the JWT...</p>&#xA;&#xA;<p>2/ I want to allow authenticated calls between my microservices. So each microservice needs to be able to generate a JWT to contact other microservices directly. My first thought was to contact the identity server. But with the OAuth2 Client Credentials flow, I don't retrieve a id_token or a JWT. Just a classic OAuth2 access token without JWT. My second thought was that the microservice can directly sign its own JWT with a certificate issued by the same PKI as the one used by the identity server. That mean that a JWT can be sign by several certificats but from the same private PKI. When a microservice receives a JWT, It needs to be able to identify witch certificat was used to sign the JWT. I don't find anything on the RFC regarding this problem. I can add my own private claim in the token to have the certificate but after several days of browsing the web without seeing this kind of solution, I'm wondering if I'm not on the wrong path... To sum up, how can i perfom ""User to service"" authentication AND alors ""service to service"" authentication in JWT?</p>&#xA;&#xA;<p>Thank you very much!</p>&#xA;"
38966184,Should business logic be contained in individual services in a micro service ecosystem?,2016-08-16 03:26:29,<architecture><microservices>,2,1341,2,0.0,2,<p>Let's say I just have 2 services <strong>Billing</strong> and <strong>Orders</strong> and one API gateway which may fan out requests to these services for billing or creating orders. </p>&#xA;&#xA;<p>Given this new order scenario:</p>&#xA;&#xA;<ol>&#xA;<li>user creates an order (request -> Rest API)</li>&#xA;<li>User validation has to be done</li>&#xA;<li>Order entity has to be created</li>&#xA;<li>Billing entity has to be created </li>&#xA;<li>Notification has to be done to notify the user</li>&#xA;</ol>&#xA;&#xA;<p>Where should my application logic sit ? and should the calls to these services be done synchronously (within the rest api) ? or each service should be responsible for calling another ? eg:</p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> (if successful) Rest API -> (if successful) calls the billing service</p>&#xA;&#xA;<p><strong>Or</strong></p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> returns the response. Then order service takes of things from there on asynchronously ?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
41400158,Bitnami and Docker,2016-12-30 17:26:04,<docker><cloud><microservices><bitnami>,1,1792,1,0.0,2,"<p>How Bitnami and Docker are different from each other when it comes to container based deployments.</p>&#xA;&#xA;<p>I have been learning about microservices recently. I used Docker images to run my apps as containers. And, I noticed that Bitnami does something similar when it creates a virtual image on a cloud form its launchpad.</p>&#xA;&#xA;<p>From whatever links I could see on Internet, I could not visualize how these two - Docker and Bitnami - are different from each other.</p>&#xA;"
41285879,Microservice and RabbitMQ,2016-12-22 14:53:49,<asp.net-web-api><architecture><rabbitmq><microservices><easynetq>,3,711,2,2.0,2,"<p>I am new to Microservices and have a question with RabbitMQ / EasyNetQ. &#xA;I am sending messages from one microservice to another microservice.</p>&#xA;&#xA;<p> Each Microservice are Web API's. I am using CQRS where my Command Handler would consume message off the Queue and do some business logic. In order to call the handler, it will need to make a request to the API method. </p>&#xA;&#xA;<p>I would like to know without having to explicit call the API endpoint to hit the code for consuming messages. Is there an automated way of doing it without having to call the API endpoint ? &#xA;<p> Suggestion could be creating a separate solution which would be a Console App that will execute the RabbitMQ in order to start listening. Create a while loop to read messages, then call the web api endpoint to handle business logic every time a new message is sent to the queue. </p>&#xA;&#xA;<p>My aim is to create a listener or a startup task where once messages are in the queue it will automatically pick it up from the Queue and continue with command handler but not sure how to do the ""Automatic"" way as i describe it. I was thinking to utilise Azure Webjob that will continuously be running and it will act as the Consumer.&#xA;<br>Looking for a good architectural way of doing it. &#xA;<p> Programming language being used is C#  </p>&#xA;&#xA;<p>Much Appreciated</p>&#xA;"
27839789,How do I change these producer-consumer microservices to allow parallel processing?,2015-01-08 12:06:52,<ruby-on-rails><ruby><multithreading><parallel-processing><microservices>,3,429,2,0.0,2,"<p>I've got a couple microservices (implemented in ruby, although I doubt that is important for my question). One of them provides items, and the other one processes them, and then marks them as processed (via a DELETE call)</p>&#xA;&#xA;<p>The provider has an <code>/items</code> endpoint which lists a bunch of items identified with an id, in JSON format. It also has a <code>DELETE /items/id</code> endpoint which removes one item from the list (presumably because it is processed)</p>&#xA;&#xA;<p>The code (very simplified) in the ""processor"" looks like this:</p>&#xA;&#xA;<pre><code>items = &lt;GET provider/items&gt;&#xA;items.each do |item|&#xA;  process item&#xA;  &lt;DELETE provider/items/#{item.id}&gt;&#xA;end&#xA;</code></pre>&#xA;&#xA;<p>This has several problems, but the one I would like to solve is that it is not thread-safe, and thus I can't run it in parallel. If two workers start processing items simultaneously, they will ""step onto each other's toes"": they will get the same list of items, and then (try to) process and delete each item twice.</p>&#xA;&#xA;<p>What is the simplest way I can change this setup to allow for parallel processing?</p>&#xA;&#xA;<p>You can assume that I have ruby available. I would prefer keeping changes to a minimum, and would rather not install other gems if possible. <a href=""http://sidekiq.org/"" rel=""nofollow"">Sidekiq</a> is available as a queuing system on the consumer.</p>&#xA;"
31525237,how to get scope associated with access token in Spring OAuth while building microservices?,2015-07-20 19:56:35,<spring><spring-security><oauth-2.0><microservices>,1,733,0,0.0,2,"<p>I am in the process of spinning up a <code>microservices</code> system with a central <code>Authorization Server</code> that grants <code>tokens</code> with different scopes for accessing individual micro-service.</p>&#xA;&#xA;<p>Here is the picture explaining the various service calls.&#xA;The numbers marked are requests made in the chronological order.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/8R9CP.png"" alt=""enter image description here""></p>&#xA;&#xA;<p><strong>1)</strong> In a nut-shell, I want the auth Server to return <code>access-token</code> with a User identifer (id) and scope when controller makes a login call. just like the following example taken from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow noreferrer"">spring tutorial</a> (but this is missing id). how can I have the id retured with the token returned?. I prefer not to make another REST call as proposed in the tutorial.</p>&#xA;&#xA;<pre><code>$ curl acme:acmesecret@localhost:9999/uaa/oauth/token  \&#xA;-d grant_type=authorization_code -d client_id=acme     \&#xA;-d redirect_uri=http://example.com -d code=jYWioI&#xA;{""access_token"":""2219199c-966e-4466-8b7e-12bb9038c9bb"",""token_type"":""bearer"",""refresh_token"":""d193caf4-5643-4988-9a4a-1c03c9d657aa"",""expires_in"":43199,""scope"":""openid""}&#xA;</code></pre>&#xA;&#xA;<p><strong>2)</strong> How does the photo Service which receives the access token in the ""Authorization bearer"" header checks with Auth Server to see the token is valid and it has the scope required to access the photo. (for example, if Auth Server responds back with list of scopes this token is eligible for, Post service can check among the list of scopes, if it can provide access).</p>&#xA;&#xA;<p><strong>3)</strong> on a side note, I see the <code>-d code=jYWioI</code> is passed in above the request, but not sure why it is passed and whats the purpose of it?</p>&#xA;"
35632607,Is the HTTP method PURGE idempotent in Varnish?,2016-02-25 16:14:18,<rabbitmq><varnish><microservices><http-method><purge>,2,614,0,0.0,2,<p>Is the HTTP verb PURGE idempotent? &#xA;If I send the same PURGE request twice will I receive 200 the second time?</p>&#xA;&#xA;<p>I have a microservice that invalidates a Varnish cache before publishing a message into a rabbit queue. In case of purge failure our need is to just log and continue the execution.</p>&#xA;&#xA;<p>The queue consumer has to get the latest status of the resource from the Varnish cache.&#xA;Will a new purge request (before actually requesting the resource from varnish) from the second microservice return success in case the first purge from the first microservice succeeded?</p>&#xA;
35617996,Eureka registration of Https micro services,2016-02-25 03:57:15,<spring-boot><microservices><netflix-eureka>,2,1894,0,0.0,2,<p>Eureka does not recognized HTTPS endpoints like '/info' and '/health' and always points to HTTP endpoints after enabling HTTPS. How to enable HTTPS micro-service url registration at Eureka ? </p>&#xA;
35441660,Micro services with JBOSS,2016-02-16 19:42:39,<jboss><microservices>,3,1732,0,0.0,2,"<p>I am new to Jboss, want to know if micro services architecture is a right choice on JBOSS. I cannot change the application server as it is decided by client architect and I have no choice.&#xA;Want to know whether we can develop micro services with underlying JBOSS application server.</p>&#xA;&#xA;<p>I understand Spring boot comes with embedded tomcat container, which makes it flexible to stop and start, deploy individual service with no impact to other services.&#xA;However will that architecture works with JBoss too.</p>&#xA;&#xA;<p>Please suggest.</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
39686227,Handling database schema creation and migrations when launching multiple instances of a containerized microservice,2016-09-25 11:18:52,<docker><kubernetes><database-migration><microservices>,2,814,0,0.0,2,"<p>I want to deploy my microservices in docker containers. I want these microservices to be as stateless as possible, only persisting state to a database.</p>&#xA;&#xA;<p>This means that there are these requirements:</p>&#xA;&#xA;<ul>&#xA;<li>These services are deployed as docker containers and orchestrated using kubernetes.</li>&#xA;<li>Each service can be deployed and scaled to multiple instances.</li>&#xA;<li>Each instance of a service will be identical. This means that they must all have the same environment variables and configurations passed to it.</li>&#xA;<li>Each instances should not care or know about another instance.</li>&#xA;<li>The instances should be stateless and should not elect a leader or have a quorum.</li>&#xA;</ul>&#xA;&#xA;<p>That leads to my problem with handling schema creation and migrations:</p>&#xA;&#xA;<ol>&#xA;<li><p>If I have a service that uses MySQL or Postgres as the data store, how do I create the tables/schemas on first launch? Should I just use <code>CREATE IF NOT EXIST</code> statements and let the instances ""fight it out"" during boot? I am not able to set an environment variable to ask for table/schema creation for just 1 of the instances.</p></li>&#xA;<li><p>How do I handle schema migrations with the above constraints? There are numerous actions like dropping/adding columns that cannot be encapsulated in a transaction.</p></li>&#xA;</ol>&#xA;"
34578641,Is there a real need to adopt ssl transport layer in a microservice architecture for internal lan-only Service to Service communication?,2016-01-03 16:13:29,<ssl><https><microservices>,1,1355,1,0.0,2,<p>In a scenario where there are thousands of webservices are there reasons to use also a signed cert for each microservice or it's just going to add overhead? Services communicate via VPC sitting behind a firewall while Public endpoints are behind a nginx public facing a valid CA cert.</p>&#xA;&#xA;<p>Services are on multiple servers on aws.</p>&#xA;
39388560,OpenID Connect ID Token: What's the purpose of audience [aud] field validation,2016-09-08 10:28:45,<security><microservices><openid-connect>,1,573,0,0.0,2,"<p>I'm trying to implement <a href=""http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth"" rel=""nofollow"">OpenID Connect Implicit Flow</a>. The frontend Single Page App passes the ID Token down to the backend server (using Authorization header) where I need to validate it.</p>&#xA;&#xA;<p>The documentation requires me <a href=""http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation"" rel=""nofollow"">to check</a> that I trust the audience of the token (aud &amp; azp fields). I'm struggling to understand the significance of this validation step and what are the security implications of not doing so. Why should I distrust the token if I'm not the intended recipient?</p>&#xA;&#xA;<p>My reasoning is that if I trust the issuer it doesn't matter who was the token issued for. I would expect the claims to be the same for any clientId (is this wrong?). Ideally when I pass the ID Token around my microservices all they should know is what issuers to trust (and use <a href=""https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig"" rel=""nofollow"">discovery protocol</a> for figuring out the keys).</p>&#xA;&#xA;<p>What is the attack vector if I skip this validation step?</p>&#xA;"
39224930,jhipster 3 Migrate from monolithic to microservices,2016-08-30 10:24:52,<migration><jhipster><microservices>,2,635,0,2.0,2,"<p>Currently I've a JHipster 3.3 monolithic application and I would like to migrate to microservices architecture. I've already created the registry, the gateway and the uaa service. Now I need to migrate the core business of my application into a microservice. Is there a facility to perform it? Can I make it automatically?</p>&#xA;"
39364466,How to dockerized java microservices efficiently,2016-09-07 08:06:47,<java><docker><jvm><microservices><application-server>,1,383,1,2.0,2,"<p>While a java application server will extend a unique JVM to run several (micro)services, a dockerized java microservices architecture will run a JVM for each dockerized microservice.&#xA;Considering 20+ java microservices and a limited number of host it seems that the amount of resources consumed by the JVMs on each host is huge.</p>&#xA;&#xA;<p>Is there an efficient way to manage this problem ? Is it possible to tune each JVM to limit resources consumption ?&#xA;The aim is to limit the overhead of using docker in a java microservices architecture.</p>&#xA;"
31095177,Data replication in Micro Services: restoring database backup,2015-06-28 01:07:07,<microservices>,1,1124,0,0.0,2,"<p>I am currently working with a legacy system that consists of several services which (among others) communicate through some kind of Enterprise Service Bus (ESB) to synchronize data.</p>&#xA;&#xA;<p>I would like to gradually work this system towards the direction of micro services architecture. I am planning to reduce the dependency on ESB and use more of message broker like RabbitMQ or Kafka. Due to some resource/existing technology limitation, I don't think I will be able to completely avoid data replication between services even though I should be able to clearly define a single service as the data owner.</p>&#xA;&#xA;<p>What I am wondering now, how can I safely do a database backup restore for a single service when necessary? Doing so will cause the service to be out of sync with other services that hold the replicated data. Any experience/suggestion regarding this?</p>&#xA;"
30237292,Is the Microservices architectural Pattern similar to EJB 1.0?,2015-05-14 12:22:28,<ejb><components><microservices>,2,1834,0,0.0,2,"<p>What we see with microservices is an isolated component, communicating over a protocol over the wire to a parent consumer of that component. </p>&#xA;&#xA;<p>We see a very similar pattern with EJB 1.0. </p>&#xA;&#xA;<p>My question is: <strong>Is the Microservices architectural Pattern similar to EJB 1.0?</strong></p>&#xA;"
44392569,Will istio add support for docker swarm?,2017-06-06 14:19:18,<docker><microservices><docker-swarm>,2,650,0,1.0,2,"<p><a href=""https://github.com/istio/istio"" rel=""nofollow noreferrer"">istio</a> An open platform to connect, manage, and secure micro-services looks very interesting, but supports only Kubernetes. I couldn't find a roadmap or mention of future support for other container management platforms, specifically Docker Swarm</p>&#xA;"
44305351,Send data in Request body using HttpURLConnection,2017-06-01 10:41:06,<java><web-services><httpurlconnection><microservices><spark-java>,2,6350,0,1.0,2,"<p>I am using <code>HttpURLConnection</code> to make a POST request to a local service deployed in my local created using JAVA Spark.<strong>I want to send some data in request body when I make the POST call using the HttpURLConnection but every time the request body in JAVA Spark is null</strong>. Below is the code I am using for this</p>&#xA;&#xA;<h3>Java Spark POST Service Handler</h3>&#xA;&#xA;<p><code>post(""/"", (req, res) -&gt; {&#xA;        System.out.println(""Request Body: "" + req.body());&#xA;        return ""Hello!!!!"";&#xA;  });</code></p>&#xA;&#xA;<h3>HTTPClass Making the post call</h3>&#xA;&#xA;<pre><code>`public class HTTPClassExample{&#xA;   public static void main(String[] args) {&#xA;        try{&#xA;            URL url = new URL(""http://localhost:4567/"");&#xA;            HttpURLConnection httpCon = (HttpURLConnection) url.openConnection();&#xA;            httpCon.setDoOutput(true);&#xA;            httpCon.setRequestMethod(""POST"");&#xA;            httpCon.connect();&#xA;            OutputStream os = httpCon.getOutputStream();&#xA;            OutputStreamWriter osw = new OutputStreamWriter(os, ""UTF-8"");    &#xA;            osw.write(""Just Some Text"");&#xA;            System.out.println(httpCon.getResponseCode());&#xA;            System.out.println(httpCon.getResponseMessage());&#xA;            osw.flush();&#xA;            osw.close();  &#xA;        }catch(Exception ex){&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}`&#xA;</code></pre>&#xA;"
44274982,Spring Boot Application - what is default timeout for any rest API endpoint or a easy config to control all endpoint timeout,2017-05-31 03:08:28,<java><spring><rest><spring-boot><microservices>,4,10949,2,1.0,2,"<p>I am using current Spring boot version (1.4.x) and wondering if it has any default timeout for api calls. I have tested it by putting breakpoints but it was keep waiting and didn't time-out. &#xA;I was also trying to configure default timeout for all my spring-boot apps by using some annotation or yml settings. </p>&#xA;&#xA;<p>I found couple of alternatives (one of them <a href=""https://stackoverflow.com/questions/34852236/spring-boot-rest-api-request-timeout"">here</a>) but using callable actually adding extra non-business logic code where setting something in xml bean is out of fashion in latest spring boot applications.</p>&#xA;"
36582126,How Lagom services consume other services?,2016-04-12 19:15:41,<microservices><service-discovery><lagom>,1,1048,2,1.0,2,"<p>I cant think in three cases.</p>&#xA;&#xA;<ol>&#xA;<li>Lagom service consumes another Lagom service in the same cluster</li>&#xA;<li>Lagom service consumes another Lagom service in a different cluster</li>&#xA;<li>Lagom service consumes an external non-Lagom service</li>&#xA;<li>An external non-Lagom service consumes a Lagom service</li>&#xA;</ol>&#xA;&#xA;<p><strong>1. Lagom service consumes another Lagom service in the same cluster</strong></p>&#xA;&#xA;<p>For this case the approach is that ServiceAImpl depends on the ServiceB API, wich is binded to a concrete implementation that will be injected to ServiceAImpl.</p>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Binding-a-service-client"" rel=""nofollow"">ServiceB binding:</a></p>&#xA;&#xA;<pre><code>import com.google.inject.AbstractModule;&#xA;import com.lightbend.lagom.javadsl.server.ServiceGuiceSupport;&#xA;import docs.services.HelloService;&#xA;&#xA;public class Module extends AbstractModule implements ServiceGuiceSupport {&#xA;&#xA;    protected void configure() {&#xA;        bindClient(HelloService.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Using-a-service-client"" rel=""nofollow"">ServiceA implementation:</a></p>&#xA;&#xA;<pre><code>public class MyServiceImpl implements MyService {&#xA;  private final HelloService helloService;&#xA;&#xA;  @Inject&#xA;  public MyServiceImpl(HelloService helloService) {&#xA;    this.helloService = helloService;&#xA;  }&#xA;&#xA;  @Override&#xA;  public ServiceCall&lt;NotUsed, NotUsed, String&gt; sayHelloLagom() {&#xA;    return (id, msg) -&gt; {&#xA;      CompletionStage&lt;String&gt; response = helloService.sayHello().invoke(""Lagom"");&#xA;      return response.thenApply(answer -&gt;&#xA;          ""Hello service said: "" + answer&#xA;      );&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I understand it correctly, in order to consume the service API in this way, both clients must be in the same cluster.&#xA;However Lagom <a href=""http://www.lagomframework.com/documentation/1.0.x/Cluster.html#Cluster-composition"" rel=""nofollow"">says</a> that</p>&#xA;&#xA;<blockquote>&#xA;  <p>A cluster should only span nodes that are running the same service.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this case we have two different types of services. </p>&#xA;&#xA;<ul>&#xA;<li>""The same service"" means a top level service whose API is exposed to external services?</li>&#xA;<li>In Lagom 1 Microservice = 1 service with external API + n internal services?</li>&#xA;</ul>&#xA;&#xA;<p><strong>2. Lagom service consumes another Lagom service in a different cluster</strong></p>&#xA;&#xA;<p>The documentation <a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceLocator.html#Integrating-with-external-Lagom-projects"" rel=""nofollow"">says</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Note that if the service you want to communicate with is actually a Lagom service, you may want to read the documentation for <a href=""http://www.lagomframework.com/documentation/1.0.x/MultipleBuilds.html"" rel=""nofollow"">integrating with an external Lagom projects</a>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Why is only configured the dependency to the service API and not the IP and port of the external Lagom service also?</p>&#xA;&#xA;<p><strong>3. Lagom service consumes an external non-Lagom service</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>The first thing you will have to do is to register each external&#xA;  service in the Service Locator. Assume we want to register an external&#xA;  service named weather that is running on <a href=""http://localhost:3333"" rel=""nofollow"">http://localhost:3333</a>, here&#xA;  is what we would add to the build:</p>&#xA;&#xA;<pre><code> lagomUnmanagedServices in ThisBuild := Map(""weather"" -&gt; ""http://localhost:3333"")&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>What is the contract with that IP? What should be behind it?</p>&#xA;&#xA;<p><strong>4. An external non-Lagom service consumes a Lagom service</strong></p>&#xA;&#xA;<p>I have to use the <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow"">Third-Party Registration Pattern</a> until Lagom support the <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow"">self registration pattern</a>?</p>&#xA;"
33814080,Microservices with many repositories out of date,2015-11-19 20:47:51,<github><teamcity><microservices><octopus-deploy><devops>,2,220,3,1.0,2,<p>In a microservices architecture what is the best strategy for keeping many developer environments up-to-date across multiple source code repositories?</p>&#xA;&#xA;<p>Suppose there were 10 teams of 10 developers working on 200 microservices in git. Every developer would need to pull regularly from every repository. This could be done with scripts but is there a better way? Are we doing this wrong because it seems like a heavy overhead.</p>&#xA;
33712470,Api naming in microservices design,2015-11-14 19:34:07,<rest><design><microservices>,2,1342,4,0.0,2,"<p>Let's say that there are two microservices representing the resources orders(/orders) and customers(/customers). My requirement is to get all the orders made by a customer. &#xA;Had it been a monolithic application, I would have modeled my uri as /customers/{id}/orders. This would have hit the customers resource and made an in-memory service call to get the corresponding orders. &#xA;Now, in case of microservices, this isn't possible. So, is the only way to get the orders is to make a remote service call or is there a better way of doing it?&#xA;Can we create another resource with the representation /ordersByCustomers/{customerid}?</p>&#xA;"
34973165,How to share communication models between Akka microservices?,2016-01-24 07:12:41,<scala><akka><microservices>,1,327,0,2.0,2,"<p>We are using Akka as our microservice platform. We are not going to support non-JVM platforms for now, so we use direct messaging between Akka actors as communication platform.</p>&#xA;&#xA;<p>This way, our communication units are just <strong>case classes</strong>. Do we have to repeat ourselves and define the case classes for each microservice or we can put all message classes into a single project and share it between microservice projects?</p>&#xA;&#xA;<p>I know that sharing models between microservices is not recommended but as we use Akka communication protocol, I'm not sure if creating the same communication case class in multiple projects is correct. What if a microservice change it's model and the others don't? How can we handle versioning and upgrade to new versions of the communication models without breaking the whole system.</p>&#xA;"
34841789,microservices & service discovery with random ports,2016-01-17 18:09:16,<docker><microservices><service-discovery><consul>,3,598,0,3.0,2,"<p>My question is related to microservices &amp; service discovery of a service which is spread between several hosts.</p>&#xA;&#xA;<p>The setup is as follows:</p>&#xA;&#xA;<ul>&#xA;<li>2 docker hosts (host A &amp; host B)</li>&#xA;<li>a Consul server (service discovery)</li>&#xA;</ul>&#xA;&#xA;<p>Let’s say that I have 2 services: </p>&#xA;&#xA;<ul>&#xA;<li>service A</li>&#xA;<li>service B</li>&#xA;</ul>&#xA;&#xA;<p>Service B is deployed 10 times (with random ports): 5 times on host A and 5 times on host B.</p>&#xA;&#xA;<p>When service A communicates with service B, for example,  it sends a request to serviceB.example.com (hard coded).</p>&#xA;&#xA;<p>In order to get an IP and a port, service A should query the Consul server for an SRV record.</p>&#xA;&#xA;<p>It will get 10 ip:port pairs, for which the client should apply some load-balancing logic.</p>&#xA;&#xA;<ul>&#xA;<li>Is there a simpler way to handle this without me developing a client resolver (+LB) library for that matter ? </li>&#xA;<li>Is there anything like that already implemented somewhere ?</li>&#xA;<li>Am I doing it all wrong ?</li>&#xA;</ul>&#xA;"
34973135,Service Fabric Service vs. Service Fabric Actors for user representation,2016-01-24 07:06:53,<c#><.net><microservices><azure-service-fabric>,1,1445,0,0.0,2,"<p>In my application users can post events on a map. The entry point of the application is a stateless web api service. For representing the users internally, I want to have an user service. When should I use Reliable Stateful Actors and when Reliable Stateful Services to store the profile data and the posted events of each user? </p>&#xA;&#xA;<p>When a client creates a new user at the frontend, the actor or service should create a new user internally. And every time the user is logged in, the web api service should forward all user interactions to the internally representation of the user (Actor or Service). E.g. the user post a new event, the web api service find the user and forward the posted event to him. Because the posted event is public, I also want to have an reliable stateful event service. After storing the posted event inside the user, the user service should forward the event to the event service. </p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<pre><code>Client/User --&gt; WebApiService --&gt; UserService/UserActor --&gt; EventService&#xA;</code></pre>&#xA;&#xA;<p>And when a user want to see all the public events on a map the should be something like this: </p>&#xA;&#xA;<pre><code>Client/User &lt;-- WebApiService &lt;-- EventService&#xA;</code></pre>&#xA;&#xA;<p>Because the events have a geo reference, I want to partition the EventService based on geocodes or something like that. </p>&#xA;&#xA;<p>Which programming model (actor and/or service) should I prefer for such an application and why?</p>&#xA;"
34774290,Implications of implementing a microservice architecture,2016-01-13 18:26:26,<amazon-web-services><architecture><spring-boot><licensing><microservices>,2,598,1,1.0,2,"<p>I'm starting out on the journey of learning/implementing microservice architecture for the first time and I have some questions related to the implications that has.</p>&#xA;&#xA;<p>For some background, the techstack I intend on using is in a very over-arching sense is dockerized spring-boot microservices running on AWS. </p>&#xA;&#xA;<p>So what I want to know is...</p>&#xA;&#xA;<p>Firstly, given that each microservice is supposed to be full stack including separate databases does this mean I need 3 separate instances of whatever database I choose runnning? I'm guessing the answer is yes. So, I guess my real question is, isn't this consuming a lot more hardware resources than a monolithic application with a single database? Databases are pretty memory hungry...</p>&#xA;&#xA;<p>Not only that but the full amount of ram required for running a single spring-boot application will be required 5 times over if I'm running 5 microservices right? It seems to me this would require far, far more ram than the monolithic application, correct?</p>&#xA;&#xA;<p>What about if you are using Oracle as a database? What implications does it have for licencing? Wouldn't it get crazy expensive if you need a separate database for each microservice?</p>&#xA;&#xA;<p>Are there any other licencing pitfalls to consider? Or any other pitfalls of MSA in general that one should consider/be aware of before starting out on this journey?</p>&#xA;&#xA;<p>Edit:&#xA;Also, given each microservice is full-stack, what if I want a consist looking front-end for each of them (where a microservice requires a front-end)? I haven't seen any good advice around this. Especially given (if they are so called '12 factor') the codebase is supposed to be in separate repository for each microservice. How is this best managed/achieved?</p>&#xA;"
34790550,Threading configuration for microservices written in java/jersey/grizzly,2016-01-14 13:12:12,<java><multithreading><jersey><grizzly><microservices>,1,574,7,1.0,2,"<p>I am designing a micro-services based system. Most of the services are deployed as standalone Jersey processes with an embedded Grizzly web server.</p>&#xA;&#xA;<p>Assuming that many of those services will execute on the same machine, shall I change any threading configuration in Grizzly to prevent a situation of too many threads machine-wide?</p>&#xA;&#xA;<p>What is the default threading model for Grizzly? Is there a limit for number of threads that a single web server can create?</p>&#xA;"
50651256,microservices - is it one service per CRUD,2018-06-01 21:34:29,<node.js><amazon-web-services><aws-lambda><microservices>,4,76,0,1.0,2,"<p>Very new to microservices...  </p>&#xA;&#xA;<p>If I have an API that deals with CRUD for customers and orders, does this translate to 2 microservices one for customers and one for orders?</p>&#xA;&#xA;<p><strong>Customer API</strong></p>&#xA;&#xA;<pre><code>CreateCustomer&#xA;ReadCustomer&#xA;UpdateCustomer&#xA;DeleteCustomer&#xA;</code></pre>&#xA;&#xA;<p><strong>Order API</strong></p>&#xA;&#xA;<pre><code>CreateOrder&#xA;ReadOrder&#xA;UpdateOrder&#xA;DeleteOrder&#xA;</code></pre>&#xA;"
50672490,What's the right way to gather data from different microservices?,2018-06-04 01:37:39,<node.js><design><architecture><microservices>,2,64,1,2.0,2,"<p>I'm having a problem understanding how basic communication between microservices should be made and I haven't been able to find a good solution or standard way to do this in the other questions. Let's use this basic example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pOCGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pOCGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I have an invoice service that return <strong>invoices</strong>, every invoice will contain information(ids) about the user and the products. If I have a view in which I need to render the invoices for a specific user, I just make a simple request.</p>&#xA;&#xA;<pre><code>let url = ""http://my-domain.com/api/v2/invoices""&#xA;let params = {userId:1}&#xA;request(url,params,(e,r)=&gt;{&#xA;  const results = r // An array of 1000 invoices for the user 1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>Now, for this specific <strong>view</strong> I will need to make another request to get all the details for each product on each invoice.</p>&#xA;&#xA;<pre><code>results.map((invoice)=&gt;{&#xA;   invoice.items.map((itemId)=&gt;{&#xA;      const url=`http://my-domain.com/api/v2/products/${itemId}`&#xA;      request(url,(e,r)=&gt;{&#xA;       const product = r&#xA;       //Do something else.....&#xA;      });&#xA;   });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>I know the code example is not perfect but you can see that this will generate a huge number of requests(at least 1000) to the product service and just for 1 user, now imagine if I have 1000 users making this kind of requests.</p>&#xA;&#xA;<p>What is the right way to get the information off all the products without having to make this number of requests in order to avoid performance issues?.</p>&#xA;&#xA;<p>I found some workarounds for this kind of scenarios such as:</p>&#xA;&#xA;<ol>&#xA;<li>Create an API endpoint that accepts a list of IDs in order to make a single request.</li>&#xA;<li>Duplicate the information from the Product service within the invoice service and find a way to keep them in sync.</li>&#xA;</ol>&#xA;&#xA;<p>In a microservices architecture are these the right ways to deal with this kind of issues? For me, they look like simple workarounds.</p>&#xA;&#xA;<p><strong><em>Edit #1: Based on Remus Rusanu response.</em></strong></p>&#xA;&#xA;<p>As per Remus recommendation, I decided to isolate my services and describe them a little bit better.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BHosb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BHosb.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>As shown in the image above the microservices are now isolated(in specific the Billing-service) and they now are the owners of the data. By using this structure I ensure that Billing-service is able to work even if there are async jobs or even if the other two services are down.</p>&#xA;&#xA;<p>If I need to create a new invoice, I can call the other two microservices(Users, Inventory) synchronously and then update the data on the ""cache"" tables(Users, Inventory) in my billing service.</p>&#xA;&#xA;<p>Is it also good to assume these ""cache"" tables are read-only? I assume they are since only the user/inventory services should be able to modify this information to preserve isolation and authority over the information.</p>&#xA;"
50702676,How to solve two generals issue between event store and persistence layer?,2018-06-05 14:31:34,<microservices><distributed-system><event-store>,3,50,2,0.0,2,"<p><strong>Two General Problems - EventStore and persistence layer?</strong></p>&#xA;&#xA;<p>I would like to understand how industry is actually dealing with this problems! </p>&#xA;&#xA;<p>If a microservice 1 persists object X into Database A. In the same time, for micro-service 2 to feed on the data from micro-service 1, micro-service 1 writes the same object X to an event store B. </p>&#xA;&#xA;<p>Now, the question I have is, where do I write object X first? </p>&#xA;&#xA;<ol>&#xA;<li><p>Database A first and then to event store B, is it fair to roll back the thread at the app level if Database A is down? Also, what should be the ideal error handle if Database A is online and persisted object X but event store B is down?</p></li>&#xA;<li><p>What should be the error handle look like if we go vice-versa of point 1?</p></li>&#xA;</ol>&#xA;&#xA;<p>I do understand that in today's world of distributed high-available systems, systems going down is questionable thing. But, it can happen. I want to understand what needs to be done when either database or event store system/cluster is down?</p>&#xA;"
47017657,How to have lombok to create constructor for non null fields since @RequiredArgsConstructor seems not to work?,2017-10-30 14:25:32,<java><spring><microservices><lombok>,1,665,2,1.0,2,"<p>I am playing with the <strong>Lombok</strong> and already went through many link but none of them worked for me.</p>&#xA;&#xA;<p><strong>Person.java</strong></p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>PersonController.java</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/people"")&#xA;public class PersonController {&#xA;    @Autowired&#xA;    private PersonRepository personRepository;&#xA;&#xA;    @RequestMapping(value = """", method = RequestMethod.POST)&#xA;    @ResponseStatus(HttpStatus.CREATED)&#xA;    public void createPerson(@RequestBody Person person) {&#xA;        personRepository.save(new Person(person.getFirstName(), person.getLastName()));  //line-34&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But its not allowing me to create the two argument constructor</p>&#xA;&#xA;<pre><code>Multiple markers at this line&#xA;    - The constructor Person(String, String) is undefined&#xA;    - The method save(S) in the type CrudRepository&lt;Person,Long&gt; is not applicable for the arguments &#xA;     (Person)&#xA;</code></pre>&#xA;&#xA;<p><strong>On line No-34 its breaking...</strong></p>&#xA;&#xA;<p><strong>EDIT-1:</strong></p>&#xA;&#xA;<pre><code> @RequestMapping(value = ""/{id}"", method = RequestMethod.PUT)&#xA;    @ResponseStatus(HttpStatus.NO_CONTENT)&#xA;    public void updatePerson(@PathVariable(""id"") Long id, @RequestBody Person person) {&#xA;        Person existingPerson = personRepository.findOne(id);&#xA;        existingPerson.setFirstName(person.getFirstName());&#xA;        existingPerson.setLastName(person.getLastName());&#xA;        personRepository.save(existingPerson);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Here is the error</p>&#xA;&#xA;<pre><code>The method setFirstName(String) is undefined for the type Person&#xA;</code></pre>&#xA;&#xA;<p>The changes I made</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor()&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private final String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private final String lastName;&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>-===================</p>&#xA;&#xA;<p><strong>Edit-2</strong></p>&#xA;&#xA;<p>Here is the final result:</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;&#xA;    public Person(String firstName, String lastName){&#xA;        this.firstName = firstName;&#xA;        this.lastName = lastName;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
31845342,How does Spring Cloud Config download remote configurations for a service?,2015-08-06 01:24:32,<spring-boot><spring-cloud><microservices>,1,866,3,0.0,2,"<p>I have found this <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">example</a> about spring-cloud on GitHub a few days ago.</p>&#xA;&#xA;<p>I am having some problems getting the config service example working. I don't know how to use <code>config-microservice</code> correctly.</p>&#xA;&#xA;<p><a href=""http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html?mkt_tok=3RkMMJWWfF9wsRonuqTMZKXonjHpfsX57ukoWaC0lMI%2F0ER3fOvrPUfGjI4ATcdqI%2BSLDwEYGJlv6SgFQ7LMMaZq1rgMXBk%3D"" rel=""nofollow"">in this blog</a>,it said configurations for your microservice applications should be stored in the environment and not in the project.</p>&#xA;&#xA;<p>But I'm not sure how to do this. I don't know how one of the microservices, for instance a <code>movie-microservice</code> Spring Boot application gets a config file from <code>config-service</code>.</p>&#xA;"
38178535,How to share the web API controllers with microservice,2016-07-04 06:55:40,<c#><asp.net-web-api><microservices><asp.net5>,1,1301,0,0.0,2,<p>We have an existing Web API that is built using ASP.Net 5 framework. We plan to develop new micro services now. We are trying to re-use the code of existing API as far as possible. Our old API (monolithic) or our new micro services will be deployed based on customer need.</p>&#xA;&#xA;<p>We are finding it tough to share the Controllers between monolithic API and micro services. Thought of using 'add as link file' but that is not working in case of controller files. Any other ways to share the controllers?</p>&#xA;
38049334,Manage multiple dependencies between microservices using Maven,2016-06-27 08:39:27,<maven><dependencies><release><microservices>,1,760,0,0.0,2,<p>We are using Maven to define and manage our dependencies between our microservices. Here is an example:</p>&#xA;&#xA;<p><strong>Microservice 1</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-1&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.04-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice 2</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-3&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.28.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>The problem is that the release phase is taking a lot of time and is fully manual:</p>&#xA;&#xA;<ol>&#xA;<li>perform <code>mvn:release</code> for the first microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>change the version in <code>pom.xml</code> of the dependency</li>&#xA;<li>perform <code>mvn:release</code> for the second microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>and so on (actually on 15 microservices...)</li>&#xA;</ol>&#xA;&#xA;<p>I'm wondering if there is any automatized way to perform this release (in cascade)? </p>&#xA;&#xA;<p>Thanks</p>&#xA;
38049329,"DDD, Microservices and data direction",2016-06-27 08:39:06,<domain-driven-design><microservices>,2,170,3,1.0,2,"<p>Let's assume I have Identity Management bounded context and discussion bounded context. Each of those is a separate micro service.</p>&#xA;&#xA;<p>Identity has Users, Discussion has Moderators.</p>&#xA;&#xA;<p>If I update first and last name in the Identity bounded context, my plan is to publish a message to Amazon SQS, and have discussion bounded context to listen that queue for any changes, and update first and last name in discussion context via Anti-Corruption layer.</p>&#xA;&#xA;<p>My question is, what if I decide to change first name and last name in the Discussion BC? Should my Identity BS listen for that changes too, or having bi-directional communication is not considered a good practice, and I should always update that information inside Identity BC?</p>&#xA;"
38006427,Building a microservices application on. Net?,2016-06-24 05:53:13,<.net><f#><microservices>,1,1024,5,0.0,2,"<p>I plan to build an internal application for my company and want to implement it in micro services. All the servers in my company is Windows servers. </p>&#xA;&#xA;<p>I'm thinking build it using asp.net core, etc. Is there a good example available? What kind of tech stack it will need?</p>&#xA;"
38377156,How to stop a spring boot service from command line?,2016-07-14 14:38:40,<java><windows><spring><spring-boot><microservices>,1,4534,0,0.0,2,"<p>I’m a spring-boot newbie, so please go easy on me.</p>&#xA;&#xA;<p>I need to offer a way for an administrator to start and stop my spring-boot microservice from a job scheduler. If I can create <code>start.bat</code> and <code>stop.bat</code> files for the service, then the scheduler could call them.</p>&#xA;&#xA;<p>How do I stop a spring-boot microservice from command line without killing the process? I'd like a graceful exit, if possible.</p>&#xA;&#xA;<p>The host will be a Windows server.</p>&#xA;"
38453830,How defensive to be when interacting with another internal microservice?,2016-07-19 08:57:26,<microservices><defensive-programming>,2,54,3,0.0,2,"<p>In this scenario there are two HTTP microservices:</p>&#xA;&#xA;<ol>&#xA;<li>The public service that provides the client with data</li>&#xA;<li>The internal microservice that authenticates calls to the public service</li>&#xA;</ol>&#xA;&#xA;<p>Service 1 makes a call to Service 2 to ask it to authenticate the token provided to it by the client.</p>&#xA;&#xA;<p>The agreement (""contract"") is that Service 2 should reply with <code>200 OK</code> and JSON content about the authenticated user.</p>&#xA;&#xA;<p>In Service 1, if it receives the response <code>200 OK</code>, is it worth going any further to validate the response further?</p>&#xA;&#xA;<p>For example, the JSON body of the response is parsed into an object. Is there value in checking if that object was correctly instantiated instead of being set to null? Or alternatively should that be left to integration tests?</p>&#xA;"
38230495,Zuul spring security and adding Additional Params in Request,2016-07-06 17:48:01,<spring><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1545,7,0.0,2,"<p>I am building Microservices using Spring Microservices, I have 2 questions related to that.<br><br>1. I have spring security in the Api Gateway i.e <strong>Zuul server</strong>, now Zuul is not forwarding any request if I have already read the request from the stream once to Authenticate(to get username/pass from POST Request) <br>&#xA;<code>new ObjectMapper().readValue(request.getInputStream(), UserDto.class);</code> &#xA;<br><strong>How can I read the request and then again forward the same request to Downstream services?</strong><br><br>&#xA;2. Zuul is not forwarding <strong>request.setAttribute()</strong> to Downstream services, so a workaround is to use <strong>ctx.addZuulRequestHeader</strong>, which is making <code>Request Header</code> too huge, How can I acheive <strong>request.setAttribute</strong> and get in downstream services.</p>&#xA;&#xA;<pre><code> public Authentication getAuthentication(HttpServletRequest request) {&#xA;    final String token = request.getHeader(AUTH_HEADER_NAME);&#xA;    logger.info(""token=""+token);&#xA;    if (token != null) {&#xA;        logger.info(""Entering getAuthentication"");&#xA;        final UserToken userInfo = tokenHandler.validateToken(token);&#xA;        if (userInfo != null&#xA;                &amp;&amp; token.equals(String.valueOf(redisUtility.getValue(userInfo.getUsername()+""_""+userInfo.getUniqueId())))) {&#xA;            logger.info(""Validating token key=""+userInfo.getUsername()+""_""+userInfo.getUniqueId());&#xA;            User user=userDetailsService.loadUserByUsername(userInfo.getUsername());&#xA;            if(user!=null &amp;&amp; user.getUsername().equals(userInfo.getUsername())&#xA;                &amp;&amp; user.getLastPasswordResetTime()&lt;userInfo.getCreatedTime()){&#xA;                request.setAttribute(""username"",user.getUsername());//**Not able to fetch this in Downstream services**&#xA;                logger.info(""Token Authenticated for User ""+user.getUsername());&#xA;                return new UserAuthentication(user);&#xA;            }&#xA;        } &#xA;    }&#xA;    return null;&#xA;}&#xA;&#xA;&#xA;  public class SimpleFilter extends ZuulFilter {&#xA;&#xA;      private static Logger log = LoggerFactory.getLogger(SimpleFilter.class);&#xA;&#xA;      @Override&#xA;      public String filterType() {&#xA;        return ""pre"";&#xA;      }&#xA;&#xA;      @Override&#xA;      public int filterOrder() {&#xA;        return 1;&#xA;      }&#xA;&#xA;      @Override&#xA;      public boolean shouldFilter() {&#xA;        return true;&#xA;      }&#xA;&#xA;      @Override&#xA;      public Object run() {&#xA;        RequestContext ctx = RequestContext.getCurrentContext();&#xA;        HttpServletRequest request = ctx.getRequest();&#xA;        request.setAttribute(""test"", ""test"");// Not able to get this in services&#xA;        log.info(String.format(""%s request to %s"", request.getMethod(), request.getRequestURL().toString()));&#xA;&#xA;        return null;&#xA;      }&#xA;&#xA; @Bean&#xA;  public SimpleFilter simpleFilter() {&#xA;    return new SimpleFilter();&#xA;  }&#xA;&#xA;@RequestMapping(value = ""/test/avl"",method=RequestMethod.POST)&#xA;  public String test(HttpServletRequest request) {&#xA;    System.out.println(request.getAttribute(""test"")+"""");&#xA;    return ""Spring in Action"";&#xA;  }&#xA;</code></pre>&#xA;"
40081965,Where lookup tables should be placed in a microservices architecture?,2016-10-17 08:45:02,<microservices><lookup-tables>,1,268,3,1.0,2,"<p>In a microservices architecture, each microservice has its own database and tables should not be duplicated in different databases.&#xA;But there are tables, like lookup tables (called also reference tables), that are needed by multiple microservices.&#xA;Should we put lookup tables in each microservice database, or is it better to create a new microservice with a database holding all the lookup tables ?</p>&#xA;"
39891218,Setting up development environment in micro-services architecture,2016-10-06 08:30:12,<microservices><gateway>,1,365,4,0.0,2,<p>We are moving towards developing a web app in a micro-services architecture.<br>&#xA;We thought about running the services behind a API gateway that will handle authentication and will proxy the requests to the appropriate services.<br>&#xA;We have encountered a problem while setting up the development environment. How can we develop a service in a local machine (laptop) and test and run it in a way that is similar to the production (behind the gateway)?</p>&#xA;&#xA;<p>Consider the following requirements:</p>&#xA;&#xA;<ul>&#xA;<li>Inter process communication (B2B)</li>&#xA;<li>Manage and sync different versions</li>&#xA;<li>Access the service with authentication token (produced by the gateway)</li>&#xA;</ul>&#xA;
49531349,Request Caching with Circuit-Breaker(Opossum) in nodejs,2018-03-28 09:50:53,<javascript><node.js><microservices><hystrix><circuit-breaker>,1,149,3,0.0,2,"<p>Based on the Netflix Hystrix circuit-breaker design pattern i was trying to do the following:</p>&#xA;&#xA;<pre><code>const circuitBreaker = require('opossum');&#xA;import * as request from 'request-promise';&#xA;&#xA;const circuit = circuitBreaker(request.get);&#xA;&#xA;circuit.fallback(() =&gt; Promise.resolve({result:[]}));&#xA;</code></pre>&#xA;&#xA;<p>I have 3 node js services deployed . They use a circuit-breaker(opossum) to make REST Calls in between them. I have a fallback method which handles the scenario when a service goes down. I was wondering if something like request-caching can be used alongside the circuit breaker to return cached response  whenever the fallback is invoked. If yes, how can i achieve this ?</p>&#xA;&#xA;<p>P.S : <strong>request is my client to make REST calls</strong></p>&#xA;"
38922420,Microservices configuration server,2016-08-12 16:15:18,<microservices>,1,605,0,1.0,2,"<p>It's well understood that in a microservices architecture, configuration must be externalized. </p>&#xA;&#xA;<p>Tools like zookeeper, etcd or consul are excellent options to store that configuration. However a new layer on top of those services is required in order to provide new functionalities that are fundamental in a configuration server. Ex. versioning; change history; ""draft"" / published configuration, etc...</p>&#xA;&#xA;<p>I've found <a href=""https://github.com/spring-cloud/spring-cloud-config"" rel=""nofollow"">spring config server</a>, which is an interesting project and addresses all these concerns using git for handling the above mentioned requirements. However, I'd like avoid using git due to additional required setup. ex. replication, etc...</p>&#xA;&#xA;<p>Do you know any other options other then spring config server?</p>&#xA;"
51149979,Microservicess with Serverless (Lambda or Function),2018-07-03 08:30:31,<azure><lambda><microservices><azure-functions>,2,61,0,2.0,2,"<p>I have some concern on getting an idea of migrating current microservices system into serverless.</p>&#xA;&#xA;<p>Right now, between services are communicating with HTTP or API based.&#xA;Serverless like lambda or function can talk to each other with function call or lambda call. This way can be done by changing all HTTP code into lambda call within all services.</p>&#xA;&#xA;<p>Another way is still using HTTP request to call another service that on lambda through API Gateway. This method of calling is not good because the service request gone to Internet and go back again into API Gateway then neighbor service get the request. Too long and does not make sense for me.</p>&#xA;&#xA;<p>I will be glad if lambda app call another lambda app with local network HTTP request, this is still on my research on how to do it.</p>&#xA;&#xA;<p>I would like to know from all of you about your experience on migrating microservices based on HTTP communication between services into serverless like Lambda or Functions ?</p>&#xA;&#xA;<p>Do you change all your code into specific lambda function call ?&#xA;Do you use HTTP over internet and API Gateway again to call neighbor service ?&#xA;Have you guys figured it out on Local / Private network lambda call ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;"
51189616,How can I proceed a delete operation in Lagom Framework?,2018-07-05 10:59:14,<java><scala><akka><microservices><lagom>,2,79,4,0.0,2,"<p>I am a little newbie on the Lagom framework and I need to know what the right way to do a delete operation in this framework. I develop with Java and I tested two approaches:</p>&#xA;&#xA;<ol>&#xA;<li>when I handle the delete event I set the state to Optional.empty () but it returns nullPointerException crashes and the line in my readSide (Cassandra DataBase) is not deleted</li>&#xA;<li>I add a Status field to my entity and when I handle the delete event I pass it to -1. When I refer to my entity I test on State.present and status! = -1 to make sure the entity and deleted. For the readSide, the line is deleted properly</li>&#xA;</ol>&#xA;&#xA;<p>In terms of logic, I think the second approach is the most logical but I want to know if there is a good practice that the Lagom framework offers developers to do delete operations</p>&#xA;&#xA;<p><strong>EDIT 1</strong>&#xA;This is my ReadSideHandler code, how can I proceed to handle properly the empty option</p>&#xA;&#xA;<pre><code>@Override&#xA;public ReadSideHandler&lt;AuthenticationEvent&gt; buildHandler() {&#xA;    return readSide.&lt;AuthenticationEvent&gt;builder(""authenticationEventOffset"")&#xA;            .setGlobalPrepare(this::createTables)&#xA;            .setPrepare(tag -&gt; prepareStatements())&#xA;            .setEventHandler(AuthenticationLoginEvent.class,&#xA;                    e -&gt; insertAuthentication(e.getAuthentication()))&#xA;            .setEventHandler(AuthenticationLogoutEvent.class, e -&gt; deleteAuthentication(e.getAccessToken()))&#xA;            .build();&#xA;}&#xA;</code></pre>&#xA;"
51227737,How to implement OpenID Connect authentication with 3rd party IDPs in a microservices architecture,2018-07-07 23:37:39,<oauth-2.0><jwt><microservices><openid-connect>,3,192,4,0.0,2,"<p>For the past 10+ days I've read an watched ALL the content I could find on understanding OAuth2 and OpenID Connect, only to find that many people disagree on the implementation, which really confuses me.</p>&#xA;&#xA;<p>To my understanding, all the articles and examples I found assume you want access to eg. google calendar, profile info or emails if you eg. login with google, but I do NOT need to access other than my own API's - I only want to use Google, Facebook etc for logging in, and getting an id which I can link to my user in my own database - nothing more than that.</p>&#xA;&#xA;<p>I'll try illustrate my use case and use that as an example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/H4VwP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H4VwP.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>A note on the diagram: the Authentication service could probably be built into the API Gateway - not that i matters for this example, since this is not about ""where to do it"", but ""how to do it the best way"" possible, for an architecture such as mine, where it's used for my own API's / Microservices, and not accessing Google, Facebook etc. external API's</em></p>&#xA;&#xA;<p>If you can understand what I'm trying to illustrate with this diagram above, please tell me if I've misunderstood this.</p>&#xA;&#xA;<p>The most basic requirements for this architecture you see here are:</p>&#xA;&#xA;<ul>&#xA;<li>Users can login with Google, Facebook, etc.</li>&#xA;<li>The same login will be used for all micro-services</li>&#xA;<li>OpenId user will have a linked account in the database</li>&#xA;<li>User access is defined in my own db, based on groups, roles and permissions</li>&#xA;</ul>&#xA;&#xA;<p>I do not intend to use external API's after the user is authenticated and logged in. No need for ever accessing a users calendar, email etc. so I really just need the authentication part and nothing else (proof of successful login). All user access is defined in my own database.</p>&#xA;&#xA;<p>So a few fundamental questions comes to mind.</p>&#xA;&#xA;<ul>&#xA;<li>First of all, is OpenID Connect even the right tool for the job for authentication only (I'll have no use for authorization, since I will not need read/write access to google / facebook API's other than getting the ID from authenticating)?</li>&#xA;<li>People generally do not agree on whether to use the ID or Access token for accessing your own API's. As far as I understand the ID token is for the client (user-agent) only, and the access token is for eg. accessing google calendar, emails etc.... External API's of the OpenID Provider... but since I'll only be accessing my own API's, do I event need the access token or the ID token - what is the correct way to protect your own API's?</li>&#xA;</ul>&#xA;&#xA;<p>If the ID token is really just for the client, so it can show eg. currently logged in user, without going to the DB, I have 0 use for it, since I'll probably query the user from from the db and store it in redux for my react frontend app.</p>&#xA;&#xA;<p><strong>Dilemma: To store user details, groups, roles and permission inside JWT or not for API authorization?</strong></p>&#xA;&#xA;<ul>&#xA;<li>By only storing the user identifier in the token, it means that I always allow authenticated users that has a valid token, to call endpoints BEFORE authorization and first then determine access based on the db query result and the permissions in my own database.</li>&#xA;<li>By storing more data about the user inside the JWT, it means that in some cases, I'd be able to do the authorization / access (group, role, permission) check before hitting the API - only possible with user info, groups, roles and permission stored inside a JWT issued upon login. In some cases it would not be possible due to eg. the CMS content access permissions being on a per-node level. But still it would mean a little better performance. </li>&#xA;</ul>&#xA;&#xA;<p>As you can see on the diagram I'm sending all API requests through the gateway, which will (in itself or with an authentication service) translate the opaque access token into some JWT with an identifier, so I can identify the user in the graph database - and then verify if the user has the required groups, roles and permissions - not from an external API, but from my own database like you see on the diagram.</p>&#xA;&#xA;<p>This seems like a lot of work on every request, even if the services can share the JWT in case multiple services should need to cross call each other.</p>&#xA;&#xA;<p>The advantage of always looking up the user, and his permissions in the db, is naturally that the moment the user access levels change, he is denied/granted access immediately and it will always be in sync. If I store the user details, groups, roles and permission inside a JWT and persist that in the client localstorage, I guess it could pose a security issue right, and it would be pretty hard to update the user info, groups, roles and permissions inside that JWT?</p>&#xA;&#xA;<p>One big advantage of storing user access levels and info inside the JWT is of course that in many cases I'd be able to block the user from calling certain API's, instead of having to determine access after a db lookup.</p>&#xA;&#xA;<p>So the whole token translation thing means increased security at the cost of performance, but is is generally recommended and worth it? Or is it safe enough to store user info and groups, roles, permissions inside the JWT? </p>&#xA;&#xA;<p>If yes, do I store all that information from my own DB in the ID Token, Access token or a 3rd token - what token is sent to the API and determines if the user should be granted access to a given resource based on his permissions in the db? Do I really need an access token if I don't need to interact with the ID providers API? Or do I store and append all my groups, roles, permissions inside the ID token (that doesn't seem clean to me) issued by OpenID connect, and call the API and authorize my own API endpoints using that, even if some say you should never use the ID token to access an API? Or do I create a new JWT to store all the info fetched from my database, which is to be used for deciding if the user can access a given resource / API endpoint?</p>&#xA;&#xA;<p>Please do not just link to general specs or general info, since I've already read it all - I just failed to understand how to apply all that info to my actual use case (the diagram above). Try to please be as concrete as possible.</p>&#xA;&#xA;<p>Made another attempt to try and simply the flow:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/1d1Tn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1d1Tn.png"" alt=""enter image description here""></a></p>&#xA;"
46807757,Service discovery on aws ECS with Application Load Balancer,2017-10-18 10:11:46,<amazon-web-services><microservices>,2,1616,0,1.0,2,"<p>I would like to ask you if you have an microservice architecture (based on Spring Boot) involving Amazon Elastic Container Service (ECS) with Application Load Balancer(ALB), service discovery is performed automatically by the platform, or do you need a special mechanism (such as Eureka or Consul)?</p>&#xA;&#xA;<p>From the documentation (ECS and ALB) is not clear you have this feature provided.</p>&#xA;"
46824730,How should be project structure using microservices with gradle or maven?,2017-10-19 07:31:19,<maven><gradle><microservices><multi-module><multi-project>,2,697,0,2.0,2,"<p>I want to be sure what is the best practice for project structure while using microservice architecture.</p>&#xA;&#xA;<p>All microservices can be created as a new maven/gradle project or as a subproject/module.</p>&#xA;&#xA;<p>I think dependency inheritance, project repository should be taken into account.</p>&#xA;&#xA;<p>Due to the nature of the microservices, any service can has a different technology but still most of the services can have same dependencies(e.g. spring-boot)).</p>&#xA;&#xA;<p>Another issue is that should  team  fetch all services or just a service which will be worked on? so repository structure also will be affected by the structure.</p>&#xA;"
46803321,Is it wrong to use sessions in Microservices?,2017-10-18 05:23:31,<java><spring-boot><spring-security><microservices><spring-session>,1,1139,1,1.0,2,"<p>I have read that, session is against the concept of RESTfulness.</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/q/6068113/1358676"">Do sessions really violate RESTfulness?</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/32741333/session-management-in-microservices/32743085#32743085"">Session Management in microservices</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/319530/restful-authentication"">RESTful Authentication</a></p>&#xA;&#xA;<p>Since Microservices inevitably use <code>REST</code>, does the same apply here as well? If so, then why do we have Spring session? It even lists 'Spring Session allows providing session ids in headers to work with <code>RESTful</code> APIs' as one of its features.</p>&#xA;"
38511443,AWS Pub/Sub Message Pattern,2016-07-21 18:09:32,<amazon-web-services><aws-lambda><amazon-sqs><microservices>,2,1848,0,0.0,2,"<p>Can someone explain to me the advantage or disadvantage of using SNS -> Lambda  vs. SNS -> SQS -> Lambda.</p>&#xA;&#xA;<p>I'm looking to setup an architecture for pub/sub micro-service messaging, but having a queue in front of every Lambda seems excessive.</p>&#xA;"
38508387,"What is SOA, Microservices, REST and Web Services ""in plain English""?",2016-07-21 15:30:49,<web-services><rest><soa><microservices>,2,1920,0,1.0,2,"<p>Could somebody explain SOA, Microservices, REST and Web Services in simple terms. It is really fascinating and confusing me. Any help would be appreciated.</p>&#xA;"
38629740,How to implement security for my Microservices with Spring?,2016-07-28 07:28:20,<spring-security><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,221,0,2.0,2,"<p>We have one monolithic application having more than 10 services like user management, fleet booking, feedback and etc developed on spring rest.</p>&#xA;&#xA;<p>We want to migrate to Microservices(Spring Boot + Cloud + Netflix OSS).</p>&#xA;&#xA;<p>Below are my questions :&#xA;How can we implement security for all our rest services (with own user database)?&#xA;How to implement api gateway from security stand point ?</p>&#xA;"
38629237,How to create a Transaction 'Wrapper' for multiple Services?,2016-07-28 07:03:34,<c#><web-services><wcf><transactions><microservices>,2,434,3,0.0,2,"<p>Currently, I'm working on a project that using MicroServices as the main concept.</p>&#xA;&#xA;<p>For a clearer picture, I'll give you the example:</p>&#xA;&#xA;<p>I got <em>Service A</em> that has its own model and controller. </p>&#xA;&#xA;<p>Basically, Service A only contains basic CRUD operations for <em>Database A</em>. </p>&#xA;&#xA;<p>Second, I got <em>Service B</em>, same like Service A but different database (<em>Database B</em>). </p>&#xA;&#xA;<p>Now, I created 1 Services to consume both Service A and Service B. Currently I'm using TransactionScope for 'wrap' the transaction, but it didn't work.</p>&#xA;&#xA;<p>Here's the code :</p>&#xA;&#xA;<pre><code>//This is the service to call Service A and Service B&#xA;using (TransactionScope ts = new TransactionScope())&#xA;{&#xA;     callServiceAMethod(); // works good&#xA;     callServiceBMethod(); // something happened, and failed&#xA;&#xA;     //from here I don't know what should I do&#xA;     //What I'm expecting is : if one of the service i just called didn't work as expected, &#xA;     //the transaction will be rolled back else will committed     &#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Any help will be appreciated :)</p>&#xA;"
38480000,Service Fabric Nested Applications,2016-07-20 11:26:37,<deployment><configuration><microservices><azure-service-fabric>,1,195,6,0.0,2,"<p>I am trying to re-architect our current monolithic web application into a more modular (micro-service) style design.</p>&#xA;&#xA;<p>I have a good idea of the boundaries and a plan on how to build it...</p>&#xA;&#xA;<p>Each part of the app will have it's own domain package, a backing rest api, and a web front-end for managing the data. Plus other stuff like unit tests and possibly a connection helper library, etc.</p>&#xA;&#xA;<p>For argument's sake, say my monolithic app has 3 main components (modules):</p>&#xA;&#xA;<ol>&#xA;<li>An accounts module for creating and managing users</li>&#xA;<li>A Products module for administering and managing the product&#xA;catalog</li>&#xA;<li>An Orders module for creating, viewing and amending orders.</li>&#xA;</ol>&#xA;&#xA;<p>In the monolithic app these are all part of the same application (and VS solution and project) and usually have distinct controllers configured using MVC / WebApi Etc:</p>&#xA;&#xA;<pre><code>// MyApp.Web Project (base url ~/)&#xA;myapp.com/...&#xA;myapp.com/accounts/...&#xA;myapp.com/products/...&#xA;myapp.com/orders/...&#xA;&#xA;// MyApp.Api Project (base url ~/api)&#xA;myapp.com/api/...&#xA;myapp.com/api/accounts/...&#xA;myapp.com/api/products/...&#xA;myapp.com/api/orders/...&#xA;</code></pre>&#xA;&#xA;<p>Currently we host this in IIS using nested applications and virtual folders but I want to replicate this sort of idea or structure using a service fabric cluster. But each isolated area (accounts, products, orders) will be developed and deployed independently of one another.</p>&#xA;&#xA;<p><strong>How do I configure service fabric cluster to enable this type of situation?</strong></p>&#xA;&#xA;<p>For instance if I have a cluster of 50 nodes and on those 50 nodes I have instances spread out of each service and the service's api. How do I say:</p>&#xA;&#xA;<pre><code>v2.myapp.com/accounts --&gt; any available accounts web UI instance?&#xA;v2.myapp.com/products --&gt; any available products web UI instance?&#xA;v2.myapp.com/api/products --&gt; any available products api instance?&#xA;</code></pre>&#xA;&#xA;<p>Should I have VM Scale Sets for web and api or one for each component too, like VM Scale Sets for just products api and another for orders web UI, etc?</p>&#xA;&#xA;<p>Also please note that our system is BIG so there are lots of components, hence the reason for splitting out the monolithic style, so I need a consistent structure to enable all this.</p>&#xA;&#xA;<p>We have major scaleability issues and very slow (manual) virtual server provisioning. Plus a single monolithic SQl Server database. The features of SF I want is modular design, easy provisioning and deployment and a drastic increase in response times and throughput of our system. And of course good failover.</p>&#xA;&#xA;<p>At the end of the day I want customers to see a consistent url structure but under the covers I want to be able to have it all separate and working together over many nodes.</p>&#xA;&#xA;<p>Thanks in advance.<br>&#xA;Any help on how to configure this is very much appreciated.</p>&#xA;&#xA;<p>G.</p>&#xA;"
44939302,"*** process.env.ENV is not defined, assuming 'prod' env",2017-07-06 03:28:00,<angularjs><environment-variables><jhipster><microservices><gateway>,1,632,0,0.0,2,"<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in <code>application-dev.yml</code>) and&#xA;Getting following exception in console</p>&#xA;&#xA;<pre><code>*** process.env.ENV is not defined, assuming 'prod' env&#xA;</code></pre>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is given by yarn) and giving exception like below in console.</p>&#xA;&#xA;<pre><code>process.env.ENV is not defined, assuming 'prod' env&#xA;chrome-extension://kbfnbcaeplbcioakkpcpgfkobkghlhen/src/js/bundle.js:4776 *** &#xA;</code></pre>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other microservices applications.</p>&#xA;&#xA;<p>Why am I getting the above exception?</p>&#xA;"
45111662,Microservices with common users table,2017-07-14 21:11:33,<architecture><soa><microservices>,3,244,0,1.0,2,<p>Is it possible to design a microservice based  architecture on which each microservice have separate independent database and a common users table?</p>&#xA;
45007694,Microservices - Database compatibility in between old and new versions,2017-07-10 08:56:19,<database><rest><architecture><microservices>,1,175,3,1.0,2,"<p>I am trying to dive into Microservice architecture to start coding some of small pieces of logic for my company.</p>&#xA;&#xA;<p>I know one of microservices concerns is about the database handling (each microservice must have its separated db schmema). So I am looking for pieces of advice or experiences about to move out from an old to new microservice version.</p>&#xA;&#xA;<p>So lets say I have a REST API endpoint <code>ms/v1/whatEver</code> which is running today on prod. After a week we decide to go live with the next version of it. So that we create a <code>ms/v2/whatEver</code> which has some new columns and data types in the entities envolved in this service. Thus in order to not force all clients to migrate immediately we want to keep both versions up and running till users move in progressively to <code>v2</code>.</p>&#xA;&#xA;<p>A couple of scenarios come up in to my mind if we have both version up and running (which actually is my main doubt and the reason of this post):</p>&#xA;&#xA;<ol>&#xA;<li><p>Should they read/write in the same DB instance, hence <code>v1</code> implementation must be adapted to match with the new schema structure of <code>v2</code>?</p></li>&#xA;<li><p>Should they read/write in a separate DB instance. So in any manner both DBs have to be synchronised till the day we decide to turn off <code>v1</code> to guarantee we do not miss any data (eventual consistency)? So my question here is how to accomplish that (throughout framework, queue messaging, or something..)</p></li>&#xA;<li><p>Or, code forwarding every <code>v1</code> request (inside of it) to <code>v2</code> which is going to be the owner of the already migrated new schema (unique DB instance)?</p></li>&#xA;</ol>&#xA;&#xA;<p>I have been reading a couple of books like <a href=""https://developers.redhat.com/promotions/migrating-to-microservice-databases/"" rel=""nofollow noreferrer"">Migrating to Microservices Databases - Red Hat</a> but they are written in concept terms but nothing specific with technologies or best things to do whit this. So that my post. </p>&#xA;&#xA;<p>I really appreciate your opinions.&#xA;Thanks</p>&#xA;"
48961000,Why shared libraries between microservices are bad?,2018-02-24 08:43:10,<interface><architecture><shared-libraries><microservices><distributed-computing>,1,967,0,0.0,2,"<p>Sam Newman states in his book <em>Building Microservices</em></p>&#xA;&#xA;<blockquote>&#xA;  <p>The evils of too much coupling between services are far worse than the problems caused by code duplication</p>&#xA;</blockquote>&#xA;&#xA;<p>I just don't understand how the shared code between the services is evil. Does the author mean the <em>service boundaries themselves</em> are poorly designed if a need for a shared library emerges, or does he really mean I should duplicate the code in the case of common business logic dependency? I don't see what that solves.</p>&#xA;&#xA;<p>Let's say I have a shared library of entities common to two services. The common domain objects for two services may smell, but another service is the GUI to tweak the state of those entities, another is an interface for other services to poll the state for their purpose. Same domain, different function.</p>&#xA;&#xA;<p>Now, if the shared knowledge changes, I would have to rebuild and deploy both services regardless of the common code being an external dependency or duplicated across the services. Generally, same concerns all the cases for two services depending of the same article of the business logic. In this case, I see only harm of duplication of the code, reducing the cohesion of the system.</p>&#xA;&#xA;<p>Of course, <em>diverging</em> from the shared knowledge may cause headaches in the case of shared library, but even this could be solved with inheritance, composition and clever use of abstractions.</p>&#xA;&#xA;<p>So, what does Sam mean by saying code duplication is better than too much coupling via shared libraries? </p>&#xA;"
48861926,How to keep state consistent across distributed systems,2018-02-19 08:17:01,<rest><web-services><architecture><microservices><distributed-computing>,1,53,5,0.0,2,"<p>When building distributed systems, it must be ensured the client and the server eventually ends up with consistent view of the data they are operating on, i.e they never get out of sync. Extra care is needed, because network can not be considered reliable. In other words, in the case of network failure, client never knows if the operation was successful, and may decide to retry the call.</p>&#xA;&#xA;<p>Consider a microservice, which exposes simple CRUD API, and unbounded set of clients, maintained in-house by the same team, by different teams and by different companies also.</p>&#xA;&#xA;<p>In the example, client request a creation of new entity, which the microservice successfully creates and persists, but the network fails and client connection times out. The client will most probably retry, unknowingly persisting the same entity second time. Here is one possible solution to this I came up with:</p>&#xA;&#xA;<ul>&#xA;<li>Use client-generated identifier to prevent duplicate post</li>&#xA;</ul>&#xA;&#xA;<p>This could mean the primary key as it is, the half of the client and server -generated composite key, or the token issued by the service. A service would either persist the entity, or reply with OK message in the case the entity with that identifier is already present.</p>&#xA;&#xA;<p>But there is more to this: What if the client gives up after network failure (but entity got persisted), mutates it's internal view of the entity, and later decides to persist it in the service with the same id. At this point and generally, would it be reasonable for the service just silently:</p>&#xA;&#xA;<ul>&#xA;<li><em>Update</em> the existing entity with the state that client posted</li>&#xA;</ul>&#xA;&#xA;<p>Or should the service answer with some more specific status code about what happened? The point is, developer of the service couldn't really influence the client design solutions.</p>&#xA;&#xA;<p>So, what are some sensible practices to keep the state consistent across distributed systems and avoid most common pitfalls in the case of network and system failure?</p>&#xA;"
44540545,Microservices. What is difference between Service registry and service discovery,2017-06-14 09:18:44,<microservices><service-discovery>,1,2488,0,0.0,2,"<p>I am new to Microservice. I cam e across term  Service registry and service discovery. &#xA;What I understood is when a new service(or service instance comes up) then it will register itself with ""service registry"". It is also mentioned that client can contact service registry and get the list of IP-port where that service is available.  </p>&#xA;&#xA;<p>In that case what is the role of ""service discovery"". </p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>Accepted answer. Also more theoretical details were found <a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/</a></p>&#xA;"
44619634,What is the best way to run multiple services that use Socket.io,2017-06-18 21:19:51,<node.js><sockets><websocket><socket.io><microservices>,2,604,1,1.0,2,"<p>I am developing a website where I will use microservices.</p>&#xA;&#xA;<p>I will have a couple or more Node.js application that will use Socket.io.</p>&#xA;&#xA;<p>I was trying to figure out how I will architecture this.</p>&#xA;&#xA;<p>Can I use multiple Node.js with Socket.io connecting to a user or will I run into conflicts? I can use NGiNX as a proxy a an UUID to identify which microservice to send the request to. Does that make sens? Is there a better way?</p>&#xA;&#xA;<p>Or I was also thinking of using a Node.js has a proxy that receives all the Socket.io connection and then it creates a connection with the user. But this seems to be adding to the network load because I am adding a another microservice.</p>&#xA;&#xA;<p>Anyways, I would love your views on this.</p>&#xA;"
37684053,"Docker, connection refused for every other running services",2016-06-07 15:55:56,<ruby-on-rails><port><docker-compose><microservices>,1,615,0,0.0,2,"<p>My local installation of docker cannot access to other ports.</p>&#xA;&#xA;<p>This is my <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<pre><code>db:&#xA;  image: library/mysql:5.6&#xA;  environment:&#xA;    MYSQL_ALLOW_EMPTY_PASSWORD: ""yes""&#xA;  expose:&#xA;    - ""3306""&#xA;  ports:&#xA;    - ""3306:3306""&#xA;&#xA;mailcatcher:&#xA;  image: yappabe/mailcatcher&#xA;  ports:&#xA;    - ""1025:1025""&#xA;    - ""1080:1080""&#xA;&#xA;rails-app:&#xA;  build: .&#xA;  dockerfile: ""Dockerfile""&#xA;  environment:&#xA;    RAILS_ENV: development&#xA;  links:&#xA;    - mailcatcher&#xA;    - db&#xA;  command: bundle exec rails server -p 3005 -b '0.0.0.0'&#xA;  volumes:&#xA;    - "".:/home/app""&#xA;  volumes_from:&#xA;    - bundle&#xA;  expose:&#xA;    - ""3005""&#xA;  ports:&#xA;    - ""3005:3005""&#xA;</code></pre>&#xA;&#xA;<p>This is the config for mailcatcher <code>config/environments/development.rb</code>:</p>&#xA;&#xA;<pre><code>config.action_mailer.delivery_method = :smtp&#xA;config.action_mailer.smtp_settings = { address: ""localhost"", port: 1025 }&#xA;</code></pre>&#xA;&#xA;<p>This is how I run the rails app:</p>&#xA;&#xA;<pre><code>docker-compose run --service-ports rails-app&#xA;</code></pre>&#xA;&#xA;<p>This is what I see when running <code>docker ps</code>:</p>&#xA;&#xA;<pre><code>&gt; docker ps&#xA;CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                                            NAMES&#xA;1fa8ac2ad8fd        pmt_rails-app          ""bundle exec rails se""   5 seconds ago       Up 3 seconds        0.0.0.0:3005-&gt;3005/tcp                           pmt_rails-app_run_1&#xA;4f65bb2fc9ac        yappabe/mailcatcher    ""/run.sh""                About an hour ago   Up About an hour    0.0.0.0:1025-&gt;1025/tcp, 0.0.0.0:1080-&gt;1080/tcp   pmt_mailcatcher_1&#xA;cfb364ee569f        library/mysql:5.6      ""docker-entrypoint.sh""   About an hour ago   Up About an hour    0.0.0.0:3306-&gt;3306/tcp                           pmt_db_1&#xA;</code></pre>&#xA;&#xA;<p>This is what I get when rails app tries to send an email:</p>&#xA;&#xA;<pre><code>Errno::ECONNREFUSED: Connection refused - connect(2) for ""localhost"" port 1025&#xA;from /usr/local/lib/ruby/2.3.0/net/smtp.rb:542:in `initialize'&#xA;</code></pre>&#xA;&#xA;<p>I get the same error when I try to connect with another <code>rails server</code> that is running in another port.</p>&#xA;&#xA;<p>I am working with Docker-beta in a Mac OSX.</p>&#xA;"
37615250,Repository within domain objects,2016-06-03 13:07:27,<domain-driven-design><microservices>,2,285,3,0.0,2,"<p>I have seen lot of discussions regarding this topic but i couldn't get a convincing answer. The general advice is not to have repository inside a domain object.  What about an aggregate root? Isnt it right to give the root the responsibility to manipulate the composed objects? &#xA;For example, i have a microservice which takes care of invoices. Invoice is an aggregate root which has the different products. There is no requirement for this service to give details about individual products. I have 2 tables, one to store invoice details and other to store products of those invoices. I have two repositories corresponding to the tables. I have injected product repository inside the invoice domain object. Is it wrong to do so? </p>&#xA;"
37634349,How can I handle large files processing via messaging queries in Microservices environment?,2016-06-04 19:45:51,<java><jms><ipc><microservices>,1,733,3,0.0,2,"<p>Many people suggest that the good way for organizing IPC (ImicroservicesC) is asynchronous communication via queries like Kafka and JMS. </p>&#xA;&#xA;<p>But what if I need to pass large data files between services?</p>&#xA;&#xA;<p>Suppose I have a Video Microservice and a Publisher Microservice. The first one receives videos from the user, verifies and sends them to Publisher for converting and publishing. It's oblivious video can be a very large file and it can overload messaging system (Kafka is not suitable for big messages at all). Of course, I can share one database for them and send video_id via Kafka, but it couples these services and its not a real microservices architecture anymore.</p>&#xA;&#xA;<p>Do you have similar situations in practice? How do you handle it?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
44886715,Should the Auth Server be combined with the User Service in a microservices architecture?,2017-07-03 13:23:23,<spring><authentication><oauth-2.0><microservices>,2,592,0,0.0,2,"<p>I am currently building a microservices based application in spring boot with the following services</p>&#xA;&#xA;<ul>&#xA;<li>Auth server (Distributes access tokens)</li>&#xA;<li>User service (User info like username, password, email, etc.)</li>&#xA;<li>Various other unrelated services</li>&#xA;</ul>&#xA;&#xA;<p>When a user sends their credentials to the auth server, the auth server should verify that they are correct and then return an access token. </p>&#xA;&#xA;<p>My question is, should I combine the auth server with the user service so looking up credentials is a simple database call, or should I keep them as separate applications and have them both point to the same shared database? Is there a better alternative?</p>&#xA;"
44802594,Refused connection to RabbitMQ when using docker link,2017-06-28 12:34:43,<asp.net-core><rabbitmq><docker-compose><microservices>,1,800,6,0.0,2,"<p>I have a microservices application which has two services and a rabbit mq used as a message queue for communication between them. Now, I want to deploy them on docker. I have the following code in the <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<p>version: ""3""&#xA;services:</p>&#xA;&#xA;<pre><code>  rabbitmq:&#xA;    build: ./Rabbit&#xA;    hostname: ""rabbitmq""&#xA;    container_name: ""rabbitmq""&#xA;    environment:&#xA;      RABBITMQ_ERLANG_COOKIE: ""cookie""&#xA;      RABBITMQ_DEFAULT_USER: ""user""&#xA;      RABBITMQ_DEFAULT_PASS: ""pass""&#xA;      RABBITMQ_DEFAULT_VHOST: ""/""&#xA;    ports:&#xA;      - ""15672:15672""&#xA;      - ""5672:5672""&#xA;    # labels:&#xA;    #   NAME: ""rabbit1""&#xA;    volumes:&#xA;    - ""/opt/rabbitmq:/var/lib/rabbitmq""&#xA;&#xA;  service1:&#xA;    build: ./service1&#xA;    deploy:&#xA;      replicas: 5&#xA;      restart_policy:&#xA;        condition: on-failure&#xA;      resources:&#xA;        limits:&#xA;          cpus: ""0.1""&#xA;          memory: 50M&#xA;    ports:&#xA;      - ""8181:80""&#xA;    depends_on:&#xA;      - rabbitmq&#xA;    links:&#xA;     - rabbitmq&#xA;    networks:&#xA;      - webnet&#xA;</code></pre>&#xA;&#xA;<p>So, here I build the RabbitMQ image in a container and then link this container to the container of <code>service1</code>. Since <code>service1</code> one is an ASP.NET Core Web API, I use the following setup to connect to the message queue:</p>&#xA;&#xA;<pre><code>//Establish the connection&#xA;            var factory = new ConnectionFactory&#xA;            {&#xA;                HostName = ""rabbitmq"",&#xA;                Port = 5672,&#xA;                UserName = ""user"",&#xA;                Password = ""pass"",&#xA;                VirtualHost = ""/"",&#xA;                AutomaticRecoveryEnabled = true,&#xA;                NetworkRecoveryInterval = TimeSpan.FromSeconds(15)&#xA;            };&#xA;</code></pre>&#xA;&#xA;<p>But when I try to run <code>docker-compose up</code>, I receive the following error message:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Unhandled Exception:&#xA;  RabbitMQ.Client.Exceptions.BrokerUnreachableException: None of the&#xA;  specified endpoints were reachable --->&#xA;  RabbitMQ.Client.Exceptions.ConnectFailureException: Connection failed&#xA;  ---> System.Net.Internals.SocketExceptionFactory+ExtendedSocketException:&#xA;  No such device or address</p>&#xA;</blockquote>&#xA;&#xA;<p>Maybe I have a mistake in the <code>HostName</code> but I am not sure how to correct it.</p>&#xA;"
48209566,What to do when the queue is down?,2018-01-11 14:37:13,<architecture><queue><message-queue><microservices><amazon-sqs>,5,142,2,0.0,2,"<p>I have 2 microservices, <code>A</code> and <code>B</code>. When <code>A</code> receives a request from a user, it gets processed (store some things in the database) and a message is sent to a queue that is read by <code>B</code>.</p>&#xA;&#xA;<p>If the queue is down, my initial thought is to make the entire request fall over, rollback, and show an error to the user asking to try again later. Is it a bad practice?</p>&#xA;&#xA;<p>Would it be a better practice to store the messages in <code>A</code>'s database marked as <code>NOT_SENT</code> and have a job to send it later when the queue is up again? Or is it over-engineering?</p>&#xA;&#xA;<p>EDIT: the request to <code>A</code> needs to be synchronous, so the user knows its outcome, but they <strong>don't</strong> need to know yet the results of <code>B</code> processing the message, so it can be asynchronous.</p>&#xA;"
48370641,Microservice internal communication,2018-01-21 19:09:30,<microservices>,4,347,3,1.0,2,"<p>I've been reading up on Microservice Architecture But I still can't understand the inter-microservices communication mechanism.<br>&#xA;In many articles they said that microservices are usually exposed over a RESTful API. But when you search the internet you always see implementations based on messaging and events for the backend communications.<br><br>&#xA;So I'm confused, Is REST API a standard for all the microservices or we can see microservices without a REST endpoints.</p>&#xA;"
48294450,"Microservices, CQRS: Eventual consistency vs Strong consistency(Read after Write consistency)",2018-01-17 05:57:17,<microservices><cqrs><eventual-consistency>,3,910,4,1.0,2,<p>Using CQRS and Event store the choreography between microservices delivers an Eventual consistency where in the changes in one microservice take a bit to propagate to the other downstream systems(essentially other microservices) which are related.&#xA;What are the options if the data is so critical that both the microservices should have a strong consistency for the data? One option that i can think of is a write through Cache like a data grid but that would be very fragile specially in a distributed system.</p>&#xA;
44115310,SessionId lost when I make a request between backend of microservices,2017-05-22 14:20:30,<java><spring><rest><security><microservices>,3,271,2,1.0,2,"<p>I am trying to make request between microservices in order to retrieve a list of users with the same roles. For this, first I make a request between FrontEnd and Backend inside the microservice 1. Following, I call an endpoint in the microservice 2 from Microservice 1 backend, but the session Id is lost in it, and I can retrieve the context. &#xA;I am using spring security and Redis for the session Control. &#xA;Manually, I retrieve the session Id from the microservice 1 and I add it as an attribute of the header of the second call, to the microservice 2. But it does not work.</p>&#xA;&#xA;<pre><code>String sessionID= RequestContextHolder.currentRequestAttributes().getSessionId();&#xA;RestTemplate rest = new RestTemplate();&#xA;HttpHeaders headers= new HttpHeaders();            &#xA;headers.set(""Session"",sessionID);&#xA;HttpEntity&lt;ResponseData&gt; entity = new HttpEntity&lt;ResponseData&gt;(headers);&#xA;ResponseEntity&lt;ResponseData&gt; responseEntity =rest.exchange(targetApi,  HttpMethod.GET, entity,ResponseData.class);&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qFEXf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qFEXf.jpg"" alt=""enter image description here""></a></p>&#xA;"
44181863,Difference between Microservices and load balancer?,2017-05-25 13:30:39,<load-balancing><microservices>,2,636,2,0.0,2,"<p>I'm fairly new to the realm of microservices but know basics about load balancing. I recently read an article about the microservices: <a href=""https://aadrake.com/posts/2017-05-20-enough-with-the-microservices.html"" rel=""nofollow noreferrer"">Enough with the microservices</a>.    </p>&#xA;&#xA;<p>There it's mentioned that both the microservices and load balancers have clusters/different VM's for deploying many copies of application but in the case of microservices, we have a <strong>separate database</strong> in contrast to load balancers which backs a single database. Is it the only difference between them?</p>&#xA;&#xA;<p>Here's the quoted text:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""multiple copies of the same microservice can be deployed in order to&#xA;  achieve a form of scalability. However, most companies that adopt&#xA;  microservices too early will use the same storage subsystem (most&#xA;  often a database) to back all of their microservices. What that means&#xA;  is that you don’t really have horizontal scalability for your&#xA;  application, only for your service. If this is the scalability method&#xA;  you plan to use, why not just deploy more copies of your monolith&#xA;  behind a load balancer? You’ll accomplish the same goal with less&#xA;  complexity.""</p>&#xA;</blockquote>&#xA;"
35751630,Spring-cloud Zuul retry when instance is down,2016-03-02 15:36:12,<spring><spring-cloud><microservices><netflix-eureka><netflix-zuul>,2,1841,10,2.0,2,"<p>Using Spring-cloud Angel.SR6:</p>&#xA;&#xA;<p>Here is the configuration of my Spring-boot app with @EnableZuulProxy:</p>&#xA;&#xA;<pre><code>server.port=8765&#xA;&#xA;ribbon.ConnectTimeout=500&#xA;ribbon.ReadTimeout=5000&#xA;ribbon.MaxAutoRetries=1&#xA;ribbon.MaxAutoRetriesNextServer=1&#xA;ribbon.OkToRetryOnAllOperations=true&#xA;&#xA;zuul.routes.service-id.retryable=true&#xA;</code></pre>&#xA;&#xA;<p>I have 2 instances of <code>service-id</code> running on random ports.  These instances, as well as the Zuul instance, successfully register with Eureka, and I can access RESTful endpoints on the 2 <code>service-id</code> instances by accessing <a href=""http://localhost:8765/service-id/"" rel=""nofollow"">http://localhost:8765/service-id/</a>.... and find that they are balanced in a round-robin manner.</p>&#xA;&#xA;<p>I would like to kill one of the <code>service-id</code> instances and, when that defunct instance is next in line for forwarding, have Zuul attempt to contact it, fail, and retry with the other instance.  </p>&#xA;&#xA;<p>Is this possible, or am I misreading the documentation?  When I try the above config, the request 'destined' for the defunct instance fails with a 500 Forwarding error.  From the Zuul stacktrace: </p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:140)&#xA;&#xA;....&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-idRibbonCommand timed-out and no fallback available&#xA;</code></pre>&#xA;&#xA;<p>The subsequent request succeeds as expected.  This behavior continues until the defunct instance is removed from Zuul's registry.</p>&#xA;&#xA;<p><strong>EDIT:</strong> Updated to Brixton.M5.  No change in behavior.  Here's the Hystrix exception in more detail:</p>&#xA;&#xA;<pre><code>Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-id timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$DeprecatedOnFallbackHookApplication$1.onError(AbstractCommand.java:1521) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$FallbackHookApplication$1.onError(AbstractCommand.java:1411) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:314) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:306) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:7710) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:100) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$1.run(AbstractCommand.java:958) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$2.tick(AbstractCommand.java:978) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.util.HystrixTimer$1.run(HystrixTimer.java:100) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    ... 1 common frames omitted&#xA;&#xA;Caused by: java.util.concurrent.TimeoutException: null&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:601) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:581) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    ... 15 common frames omitted&#xA;</code></pre>&#xA;"
40960054,"Service Fabric, What Microservices is best intended for continuous polling from Service Bus",2016-12-04 15:12:29,<c#><azure><microservices><azureservicebus><azure-service-fabric>,3,1421,2,1.0,2,"<p>I am new to Service Fabric.</p>&#xA;&#xA;<p>We have a queue on Azure Service Bus. I want to continuously pull from the queue in my Service Fabric, process the message (execute some business logic) and save some data in the DB, then remove the message from the queue.</p>&#xA;&#xA;<p>The Microservice should check the queue every couple of seconds to monitor for a new message.</p>&#xA;&#xA;<p>My question is, <strong>What is the intended Microservice(s) that would pull data, process some business logic, then save to the DB. Is it A Stateless Service or a Reliable Actor</strong></p>&#xA;"
40880443,Can micro services be applied to the front-end with JS?,2016-11-30 04:40:09,<javascript><angularjs><reactjs><frontend><microservices>,1,524,3,0.0,2,"<p>I have a project which requires various developers to build components / modules for an app at any given time.</p>&#xA;&#xA;<p>However, each component can be written in a different framework or library e.g. <code>URI/app1</code> is a search component written in React, and <code>URI/app2</code> is a results component written in AngularJS. </p>&#xA;&#xA;<p>I'm trying to find a way so that given a <code>URI</code> if <code>URI/subdomain</code> is served I can serve a module which is fully encapsulated (technology wise) from other sub paths &amp; the URI.</p>&#xA;&#xA;<p>Does something along these lines exist? Is there a methodology or approach which will allow an app to holistically serve sub-modules (not fragments of a single page, but rather full pages under a unique path) and remain isolated to other front-end code, but still allow data to be passed across the technologies used, so that a developer could essentially come in and create a component / page / module under a subpath using the technology of their choice and have it be accepted cohesively across the existing app written in potentially varying technologies?</p>&#xA;"
40807355,Scheduled messages with RabbitMQ,2016-11-25 14:39:26,<rabbitmq><message-queue><microservices>,2,2663,3,1.0,2,"<p>I'm looking for a solution to have scheduled messages with RabbitMQ, so not only delaying the messages as described in several sources but schedule it to have a message e.g. every day.</p>&#xA;&#xA;<p>If not RabbitMQ, any other solutions out there you can think of and you'd suggest for a microservices environment using a message-bus?&#xA;So it's really about combining the concept of a task-scheduler and a message bus ...</p>&#xA;&#xA;<p>Or is it better to use a job scheduler just to push messages to the message queue, e.g. using rundeck in combination with RabbitMQ?</p>&#xA;"
50392109,Understanding Cassandra - can it replace RDBMS?,2018-05-17 12:59:06,<cassandra><bigdata><microservices><cql>,2,81,3,1.0,2,"<p>I've spent the last week cramming on Cassandra, trying to understand the basics, as well as if it fits our needs, or not. I think I understand it on a basic level at this point, but if it works like I believe I'm being told...I just can't tell if it's a good fit.</p>&#xA;&#xA;<p>We have a microservices platform which is essentially a large data bus between our customers. They use a set of APIs to push and pull shared data. The filtering, thus far, is pretty simple...but there's no way to know what the future may bring.</p>&#xA;&#xA;<p>On top of this platform is an analytics layer with several visualizations (bar charts, graphs, etc.) based on the data being passed around.</p>&#xA;&#xA;<p>The microservices platform was built atop MySQL with the idea that we could use clustering, which we honestly did not have a lot of luck with. On top of that, changes are painful, as is par for the course in the RDBMS world. Also, we expect extraordinary amounts of data with thousands-upon-thousands of concurrent users - it seems that we'll have an inevitable scaling problem.</p>&#xA;&#xA;<p>So, we began looking at Cassandra as a distributed nosql potential replacement.</p>&#xA;&#xA;<p>I watched the DataStax videos, took a course on another site, and started digging in. What I'm finding is:</p>&#xA;&#xA;<ul>&#xA;<li>Data is stored redundantly across several tables, each of which uses different primary and clustering keys, to enable different types of queries, since rows are scattered across different nodes in the cluster</li>&#xA;<li>Rather than joining, which isn't supported, you'd denormalize and create ""wide"" tables with tons of columns</li>&#xA;<li>Data is eventually consistent, so new writes may not be readily readable in a predictable, reasonable amount of time.</li>&#xA;<li>CQL, while SQL-like, is mostly a lie. How you store and key data determines which types of queries you can use. It seems very limited and inflexible.</li>&#xA;</ul>&#xA;&#xA;<p>While these concepts make sense to me, I'm struggling to see how this would fit most long-term database needs. If data is redundant across several different tables...how is it managed and kept consistent across those many tables? Are materialized views the answer in this case?</p>&#xA;&#xA;<p>I <em>want</em> to like this idea and love the distributed features, but frankly am mostly scared off, at this point. I feel like I've learned a lot and nothing at all, in the last week, and am entirely unsure how to proceed.</p>&#xA;&#xA;<p>I looked into JanusGraph, Elassandra, etc. to see if that would provide a simpler interface on top of Cassandra, relegating it to basically a storage engine, but am not confident many of these things are mature enough or even proper, for what we need.</p>&#xA;&#xA;<p>I suppose I'm looking for direction and insight from those of you who have built things w/ Cassandra, to see if it's a fit for what we're doing. I'm out of R&amp;D time, unfortunately. Thanks!</p>&#xA;"
50455134,Can Software Architects predict of how microservice architectures will mature over time?,2018-05-21 19:05:24,<architecture><microservices><soa><software-design>,1,81,4,1.0,2,"<p>In March 2014 ( just over four years ago at the time of this question ), James Lewis and Martin Fowler wrote: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Many people believe that [decay of modularity over time] is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can't truly assess how microservice architectures mature.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now that many MSAs have been built by a variety of businesses, do we have a general understanding of the maturation of these architectures? What do we know about what works as time goes forward? What do we know about what does not work?</p>&#xA;"
43927492,Microservices - Stubbing/Mocking,2017-05-12 00:15:48,<java><cloudfoundry><microservices>,5,926,2,0.0,2,"<p>I am developing a product using microservices and am running into a bit of an issue. In order to do any work, I need to have all 9 services running on my local development environment. I am using Cloud Foundry to run the applications, but when running locally I am just running the Spring Boot Jars themselves. Is there anyway to setup a more lightweight environment so that I don't need everything running? Ideally, I would only like to have the service I am currently working on to have to be real.</p>&#xA;"
43792085,How to check service-to-service authentication in Google Cloud Endpoints?,2017-05-04 20:17:14,<google-app-engine><oauth-2.0><google-cloud-endpoints><microservices><google-oauth2>,1,171,3,2.0,2,"<p>I'm trying to split a monolith Google App Engine application (using Python &amp; standard environment) into several services within one application. Default service is calling API implemented using the Endpoints framework in another service.</p>&#xA;&#xA;<p>Everything works nicely except that I don't understand how to correctly check authentication of the default service (and make it work both in local development server and in production).</p>&#xA;&#xA;<p>To call the service I'm using <code>google-api-python-client</code> and default application credentials.</p>&#xA;&#xA;<pre><code>from googleapiclient.discovery import build&#xA;from oauth2client.client import GoogleCredentials&#xA;service = build(&#xA;    name, version,&#xA;    credentials=GoogleCredentials.get_application_default(),&#xA;    discoveryServiceUrl=discovery_url)&#xA;service.client_token().execute()&#xA;</code></pre>&#xA;&#xA;<p>My service API code looks like the following</p>&#xA;&#xA;<pre><code>@endpoints.api(&#xA;    name='test',&#xA;    version='v1',&#xA;)&#xA;class TestApi(remote.Service):&#xA;&#xA;    @endpoints.method(&#xA;        message_types.VoidMessage,&#xA;        TestResponse,&#xA;        path='test',&#xA;        http_method='GET',&#xA;        name='test')&#xA;    def get_test(self, request):&#xA;        # user = endpoints.get_current_user()&#xA;        # if not user:&#xA;        #     raise endpoints.UnauthorizedException&#xA;        return TestResponse(test='test')&#xA;</code></pre>&#xA;&#xA;<p>In production <code>endpoints.get_current_user()</code> seems to return a correct application user, but I don't know how to correctly validate that it's the same application. In local development environment <code>endpoints.get_current_user()</code> returns <code>None</code>.</p>&#xA;"
43850359,Microservice Coupling,2017-05-08 14:32:40,<spring><architecture><cloud><microservices><coupling>,5,280,9,1.0,2,"<p>I'm building a new application with microservice concepts, but I don't know how to communicate with another microservice without coupling. Here is my scenario.</p>&#xA;&#xA;<p>I want to show a graphic bar about my sales but I have two microservices, the first one is the <strong>sales-service</strong> and the another one <strong>product-service</strong>. In this case I have to select the period I want to filter and then select the sales and after select the products from these sales, but I'm calling the product-service directly with REST and if my product-service going down fails every thing. What is the correct way to work in this scenario?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/faHqp.jpg"" rel=""nofollow noreferrer"">Diagram of Architecture</a></p>&#xA;&#xA;<p>This is the architecture with some services. The problem is that sale-service has to communicate with others services to get some informations.</p>&#xA;&#xA;<p>We have a sales software in hundreds of client and this application recieves this data and we have a front-end that shows this informations. In this scenario, microservice is the best approatch?</p>&#xA;&#xA;<p>I'm using Spring Cloud.</p>&#xA;"
49944789,Handle Status Update In Even Sourcing Pattern,2018-04-20 15:13:09,<java><microservices><event-sourcing>,1,61,9,0.0,2,"<p>I was looking at an auditing pattern to save history of my entity and I came across Event Sourcing Pattern. It is an interesting pattern and most of it makes sense to me but I had one question on how to implement a certain use case scenario?</p>&#xA;&#xA;<p>Use Case:</p>&#xA;&#xA;<ol>&#xA;<li>There is an invoice generated with amount of $100 and status as in review.</li>&#xA;<li>Then the invoice status is updated to billed</li>&#xA;<li>Then a payment of $50 is adjustment of $20 is made and status is updated to paid</li>&#xA;<li>We later realized that the amounts were incorrect. So we want to rollback previous transaction and revert bill status to billed again</li>&#xA;<li>We then post a payment of $70 and adjustment of $20 and update invoice status to complete.</li>&#xA;</ol>&#xA;&#xA;<p>From my understanding of event store. It should only contain the actions that were applied on the entity.So the event always has the updated transaction amounts(payment and adjustment) and status.</p>&#xA;&#xA;<p><strong>Database:</strong></p>&#xA;&#xA;<p>Invoice:</p>&#xA;&#xA;<pre><code>| id    | balance | payment | adjustment | status   |&#xA;|-------|---------|---------|------------|----------|&#xA;| 12345 | 10      | 70      | 20         | Paid     |&#xA;</code></pre>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | Event            | Payload |&#xA;|----------|------------|------------------|---------|&#xA;| 1        | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status</p>&#xA;&#xA;<p>So here are my questions</p>&#xA;&#xA;<ol>&#xA;<li>I get how balances can be reversed but I do not see how we can accomplish the same effect for status</li>&#xA;<li>Also how will I handle if api calls(commands) come out of  order for the above events. i.e &#xA;&#xA;<ul>&#xA;<li>Step 3 calls service</li>&#xA;<li>then step 5 </li>&#xA;<li>then step 4.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>from what I understand the balances will be fine but the invoice status will be incorrect.</p>&#xA;&#xA;<p>Please advise me on how to best handle this on event sourcing pattern.</p>&#xA;"
34439201,Java Spring will not talk to Consul when run as a Docker container,2015-12-23 15:46:51,<java><docker><spring-cloud><microservices><consul>,2,1970,1,1.0,2,"<p>I am trying to solve what I believe is a common use case for running micro services.  In this case I am testing consul with a spring cloud application. I am trying to test consul in two different ways.  The first of which is running in a docker container and the other is running on the docker host machine.  I am then attempting to start a spring cloud container that will talk with either consul example.</p>&#xA;&#xA;<p>I have been unable to make the spring cloud application talk to consul when the spring cloud application is run as a docker container.  When the spring cloud application is run with the host networking mode it works as it can resolve the localhost ports, but this is not an acceptable solution if I wish to run multiple instances of the image.  </p>&#xA;&#xA;<p>An example of my docker compose file when running both services as containers is shown below. Here I am attempting to set the consul uri in spring cloud through the environment variables, but have been unable to get it to work using a variety of configurations.  If anyone could point to an example of these functions working together that would be immensely helpful.</p>&#xA;&#xA;<pre><code> consul1:&#xA;  image: progrium/consul&#xA;  ports:&#xA;    - ""8400:8400""&#xA;    - ""8500:8500""&#xA;    - ""8600:53/udp""&#xA;    - ""8600:53/tcp""&#xA;  environment:&#xA;      GOMAXPROCS: 100&#xA;      entrypoint: ""/bin/consul""&#xA;      hostname: consul&#xA;      command: agent -log-level=debug -server -config-dir=/config -bootstrap -ui-dir /ui&#xA;&#xA;simpletest:&#xA;    build: simpletest&#xA;    hostname: simpletest&#xA;    environment:  &#xA;      JAVA_OPTS: ""-Xdebug -Xrunjdwp:server=y,transport=dt_socket,suspend=n -Dspring.cloud.consul.host=consul1""&#xA;    ports:&#xA;     - 39041:7051&#xA;     - 39052:7055&#xA;#     d2fdockerroot_consul1_1 consul&#xA;#    links:&#xA;#     - consul1&#xA;</code></pre>&#xA;"
34406896,How to share code between micro services?,2015-12-22 00:57:07,<architecture><microservices>,2,1258,3,1.0,2,"<p>For example, I have a project which has 4 micro services: client-web, admin-web, client-api, admin-api.</p>&#xA;&#xA;<p>These four micro services should share one DB code,  should I make the DB code as a submodule of git and use it in each micro service?</p>&#xA;&#xA;<p>does it against micro service principle? </p>&#xA;"
47380189,Microservices governance vs SOA,2017-11-19 18:04:35,<architecture><domain-driven-design><microservices><soa>,2,475,5,2.0,2,"<p>I was working in SOA goverened projects for the last 10 years and now we switch to a Microservices architecture ones.</p>&#xA;&#xA;<p>The good thing in SOA was that we had a Canonical Data Model where which was built with some effort indeed but at the end all systems ended up speaking the same 'language' and communication was centralized via a Service Bus.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QNcwq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QNcwq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In a Microservice architecture teams are independent and as there is no service bus wonder how all this intergration points will work.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/37mGm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/37mGm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>1) Is there a way to enfore some contracts like there is WSDL in SOA (for SOAP) ?</p>&#xA;&#xA;<p>2) If team developing service B is autonoumous and deploys a new service it has to keep the old version as well no ? In SOA this problem was solved that on the service bus we kept v1 and a we did a transformation to v2.It was trasparent for consumers that service B has a new version.</p>&#xA;&#xA;<p>3) What type of govenrnance you would put in place in case the number of microservices is quite high like in the below picture knowing the teams have to be as much as possible autonoumous ('agile')?</p>&#xA;&#xA;<p>I am not looking fot the best answer , I am interested in different opinions as there is no magic solution here.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/k2mB3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k2mB3.png"" alt=""enter image description here""></a></p>&#xA;"
52051459,"Jhipster - unable to Use a Gateway app when deploying everything on docker host except the Gateway itself, Mixed Docker and locally deployment",2018-08-28 06:30:31,<docker><microservices><jhipster><keycloak><gateway>,1,31,0,2.0,2,"<p>I have some JHipster Spring Microservice and gateway projects. I deployed all of them on a host using docker except the gateway. I started the gateway on another host.</p>&#xA;&#xA;<p>I use Keycloak for OAuth authentication.</p>&#xA;&#xA;<p>Everything works fine when i deploy all of the microservices and databases and Gateways as docker containers on a docker network using docker-compose.</p>&#xA;&#xA;<p>But it doesn't work when i just deploy everything on docker except the gateway.i mean if the gateway resides outside of docker-created network. the motivation for this action is that I just want my UI programmer to up and run the gateway on his own PC, and use microservices which are deployed on server host. Just for ease of UI development in need to up and run this sole gateway using <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>I used a technique to assign a separate IP to each container on my docker network. This technique is called Docker MacVLan networking. so that every container in the host have a separate IP address in physical network and each of these containers are visible on other hosts in the network.</p>&#xA;&#xA;<p>the problem is that in normal docker deployment (when gateway is deployed in a docker network in same host) everything works fine. but in my scenario after successful login, every microservice return <code>error 401</code>.</p>&#xA;&#xA;<p>in microservice it says this error:</p>&#xA;&#xA;<pre><code>o.s.s.oauth2.client.OAuth2RestTemplate   : Setting request Accept header to [application/json, application/x-jackson-smile, application/cbor, application/*+json]&#xA;o.s.s.oauth2.client.OAuth2RestTemplate   : GET request for ""http://keycloak:9080/auth/realms/jhipster/protocol/openid-connect/userinfo"" resulted in 401 (Unauthorized); invoking error handler&#xA;n.m.b.s.o.CachedUserInfoTokenServices    : Could not fetch user details: class org.springframework.security.oauth2.client.resource.OAuth2AccessDeniedException, Unable to obtain a new access token for resource 'null'. The provider manager is not configured to support it.&#xA;p.a.OAuth2AuthenticationProcessingFilter : Authentication request failed: error=""invalid_token"", error_description=""token string here""&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/C7MwY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/C7MwY.png"" alt=""SSO 401 is Happening""></a></p>&#xA;&#xA;<p>it says that your token is invalid. the same mechanism just works when everything is deployed in same host in docker. is it for the Keycloak that prevents the token to validate for external hosts? i personally doubt that , because it didn't prevent me from logging into gateway successfully. and i just checked keycloak. its up by the command <code>-b 0.0.0.0</code></p>&#xA;&#xA;<p>Please help me up and run a gateway just by <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>In summary I could rephrase my question to: <strong><em>i just want the UI Developer be able to test his angular/spring-gateway project in it's own PC while other services are deployed in powerful server using docker</em></strong> (authentication using <strong><em>Keycloak</em></strong>). and it is not possible to deploy those other services on UI developers own PC. how to do it in JHipster?</p>&#xA;"
51976057,Microservices architecture and MySQL database pagination,2018-08-22 22:32:57,<javascript><mysql><node.js><amazon-web-services><microservices>,2,103,2,2.0,2,"<p>So imagine, I want to retrieve all orders for an array of customers.&#xA;The <code>arrayList</code> in the example below will have an array of customer IDs.</p>&#xA;&#xA;<p>This array will be passed into the <code>get</code> method below and processed asynchronously retrieving orders for each customer ID in the array.</p>&#xA;&#xA;<p>Here's where I get lost. How can you paginate the database result set and pull only a small set of records at a time from the database without bring having to pull all the records across the network.</p>&#xA;&#xA;<p>What's confusing me is the asynchronous nature as well as we won't know how many orders per customer there are? So how can you efficiently return a set page size at a time?</p>&#xA;&#xA;<p><strong>service.js</strong></p>&#xA;&#xA;<pre><code>function callToAnotherService(id) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        //calls service passing id&#xA;    }&#xA;}&#xA;&#xA;exports.get = arrayList =&gt; Promise.all(arrayList.map(callToAnotherService))&#xA;    .then((result) =&gt; result);&#xA;</code></pre>&#xA;"
43100199,zuul API Gateway Filter,2017-03-29 17:24:47,<spring><microservices><spring-cloud><netflix-zuul>,2,545,3,0.0,2,"<p>I am facing problem when i trying to access another REST API(registered in ZUUL route) from zuul pre-filter, the call is becoming recursive i.e its running my pre-filter code again and again. My Usecase is as follows-</p>&#xA;&#xA;<ol>&#xA;<li><p>In Zuul <code>PreFilter</code> <code>run()</code> method, I am validating the token passed in the header.</p></li>&#xA;<li><p>After validating the token, I am calling one rest service(User Location Service) to fetch the user details. My User Location Service is itself registered in ZUUL as below:</p>&#xA;&#xA;<pre><code>user-location-service:&#xA;  path: /userLocationService/**&#xA;  url: http://localhost:9002&#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>The problem is that the JWT token validation code is running again and again, Can you please suggest some solution where I can apply the call Userlocation service so that the <code>PreFilter</code> code would not run again and again?</p>&#xA;"
43212533,Eventual Consistency in microservice-based architecture temporarily limits functionality,2017-04-04 16:15:01,<microservices><application-design><eventual-consistency><event-based-programming>,1,629,3,0.0,2,"<p>I'll illustrate my question with Twitter. For example, Twitter has microservice-based architecture which means that different processes are in different servers and have different databases.</p>&#xA;&#xA;<p>A new tweet appears, server A stored in its own database some data, generated new events and fired them. Server B and C didn't get these events at this point and didn't store anything in their databases nor processed anything.</p>&#xA;&#xA;<p>The user that created the tweet wants to edit that tweet. To achieve that, all three services A, B, C should have processed all events and stored to db all required data, but service B and C aren't consistent yet. <strong>That means that we are not able to provide edit functionality</strong> at the moment.</p>&#xA;&#xA;<p>As I can see, a possible workaround could be in switching to immediate consistency, but that will take away all microservice-based architecture benefits and probably could cause problems with tight coupling.    </p>&#xA;&#xA;<p>Another workaround is to restrict user's actions for some time till data aren't consistent across all necessary services. Probably a solution, depends on customer and his business requirements.    </p>&#xA;&#xA;<p>And another workaround is to add additional logic or probably service D that will store edits as user's actions and apply them to data only when they will be consistent. Drawback is very increased complexity of the system.</p>&#xA;&#xA;<p>And there are two-phase commits, but that's 1) not really reliable 2) slow.<br>&#xA;I think slowness is a huge drawback in case of such loads as Twitter has. But probably it could be solved, whereas lack of reliability cannot, again, without increased complexity of a solution.</p>&#xA;&#xA;<p>So, the questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Are there any nice solutions to the illustrated situation or only things that I mentioned as workarounds? Maybe some programming platforms or databases?</li>&#xA;<li>Do I misunderstood something and some of workarounds aren't correct?</li>&#xA;<li>Is there any other approach except Eventual Consistency that will guarantee that all data will be stored and all necessary actions will be executed by other services?</li>&#xA;</ol>&#xA;&#xA;<p><em>Why Eventual Consistency has been picked for this use case</em>? As I can see, right now it is the only way to guarantee that some data will be stored or some action will be performed if we are talking about event-driven approach when some of services will start their work when some event is fired, and following my example, that event would be “tweet is created”. So, in case if services B and C go down, I need to be able to perform action successfully when they will be up again.</p>&#xA;&#xA;<p>Things I would like to achieve are: reliability, ability to bear high loads, adequate complexity of solution. Any links on any related subjects will be very much appreciated.</p>&#xA;&#xA;<p>If there are natural limitations of this approach and what I want cannot be achieved using this paradigm, it is okay too. I just need to know that this problem really isn't solved yet.</p>&#xA;"
37143689,JHipster Registry rejects gateways and microservices,2016-05-10 16:03:40,<jwt><jhipster><microservices><spring-cloud-config>,2,2306,0,1.0,2,"<p>I'm trying to use JHipster for a project using microservices, but the latest JHipster Registry won't let my gateway or microservices access the config server and rejects them.</p>&#xA;&#xA;<p>I installed the JHipster Vagrant DevBox, then used <code>docker run -p 8761:8761 jhipster/jhipster-registry</code> to run the JHipster registry.&#xA;Then, I generated a gateway and 2 microservices following <a href=""http://www.ipponusa.com/blog/jhipster-3-0-introducing-microservices/"" rel=""nofollow"">this</a>, and it worked.</p>&#xA;&#xA;<p>But then I wanted to use the JHipster Registry from GitHub, so I cloned it and runned it (apparently it had been updated to 2.0.0 in the meantime). Sadly, the gateway and the microservices weren't able to access this registry. They were still able to access the Docker image registry though (I suppose Docker didn't update it). But since it was fancier, and probably more up-to-date, I wanted to use the latest version of the registry, the same as the one from GitHub. So I tried to update the Docker image Jhipster Registry with <code>docker pull</code>. And now it won't work with either registry - Docker image or GitHub clone. </p>&#xA;&#xA;<p>When a registry is running and I run a gateway or microservice, I get 6 times this:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.511 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@86ba8f5 pairs: {GET /config/gateway/dev/master HTTP/1.1: null}{Accept: application/json, application/*+json}{User-Agent: Java/1.8.0_91}{Host: localhost:8761}{Connection: keep-alive}&#xA;2016-05-10 15:39:07.522 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@43c7802510 pairs: {null: HTTP/1.1 401 Unauthorized}{Server: Apache-Coyote/1.1}{X-Content-Type-Options: nosniff}{X-XSS-Protection: 1; mode=block}{Cache-Control: no-cache, no-store, max-age=0, must-revalidate}{Pragma: no-cache}{Expires: 0}{Content-Type: application/json;charset=UTF-8}{Transfer-Encoding: chunked}{Date: Tue, 10 May 2016 15:39:07 GMT}&#xA;</code></pre>&#xA;&#xA;<p>Then I get an error:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:13.781 ERROR 20706 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Then I get Java exceptions:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 common frames omitted&#xA;&#xA;[WARNING] &#xA;java.lang.reflect.InvocationTargetException&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;... 6 more&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 more&#xA;</code></pre>&#xA;&#xA;<p>And finally a <code>BUILD FAILURE</code> and a Maven error:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project gateway: An exception occurred while running. null: InvocationTargetException: Could not locate PropertySource and the fail fast property is set, failing: 401 Unauthorized -&gt; [Help 1]&#xA;[ERROR] &#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR] &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>In the registry's shell I get this line 6 times too:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.519 DEBUG 17958 --- [io-8761-exec-10] i.g.j.r.s.Http401UnauthorizedEntryPoint  : Pre-authenticated entry point called. Rejecting access&#xA;</code></pre>&#xA;&#xA;<p>I tried updating everything, and I am currently trying to downgrade things (since the doc says ""we recommend you use the same version tag as the one you use for your JHipster generator"", but I don't think it'll work since JHipster Registry's latest version is 2.0.0 and the JHipster generator introduced microservices with the 3.0 version), and I also tried copying directly the secret from the central-server-config to the config of the applications, but apparently to no avail.</p>&#xA;&#xA;<p>Could you help me with this ?</p>&#xA;&#xA;<p>Thank you very much in advance.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>I tried updating JHipster to 3.2.1 using <code>npm install -g generator-jhipster</code>, which apparently worked, but when I run <code>yo jhipster</code>, Yeoman still uses JHipster 3.1.0. Actually, even if I uninstall JHipster with <code>npm uninstall -g generator-jhipster</code>, Yeoman can still use JHipster 3.1.0...</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>It works fine if I reinstall everything locally (in the directory where I use <code>yo jhipster</code>).&#xA;However, I still can't update JHipster globally in Yeoman. When I try using <code>npm install -g generator-jhipster</code>, it updates JHipster globally to 3.2.1 but Yeoman still uses 3.1.0. If I try to update JHipster using <code>yo</code>/""Update your generators""/generator-jhipster, I get an error:</p>&#xA;&#xA;<pre><code>npm WARN deprecated npmconf@2.1.2: this package has been reintegrated into npm and is now out of date with respect to npm&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules/generator-jhipster&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules&#xA;/usr/local/lib&#xA;└── generator-jhipster@3.2.1 &#xA;&#xA;npm ERR! Linux 3.13.0-85-generic&#xA;npm ERR! argv ""/usr/local/bin/node"" ""/usr/local/bin/npm"" ""install"" ""-g"" ""generator-jhipster""&#xA;npm ERR! node v4.4.4&#xA;npm ERR! npm  v3.8.9&#xA;npm ERR! path /usr/local/lib/node_modules/generator-jhipster&#xA;npm ERR! code EACCES&#xA;npm ERR! errno -13&#xA;npm ERR! syscall access&#xA;&#xA;npm ERR! Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster'&#xA;npm ERR!     at Error (native)&#xA;npm ERR!  { [Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster']&#xA;npm ERR!   errno: -13,&#xA;npm ERR!   code: 'EACCES',&#xA;npm ERR!   syscall: 'access',&#xA;npm ERR!   path: '/usr/local/lib/node_modules/generator-jhipster' }&#xA;npm ERR! &#xA;npm ERR! Please try running this command again as root/Administrator.&#xA;&#xA;npm ERR! Please include the following file with any support request:&#xA;npm ERR!     /home/vagrant/npm-debug.log&#xA;&#xA;I've just updated your generators. Remember, you can update&#xA;a specific generator with npm by running:&#xA;&#xA;    npm install -g generator-_______&#xA;</code></pre>&#xA;&#xA;<p>Using <code>sudo</code> will do the same and <code>sudo su</code> give me this when I try to run <code>yo</code>:</p>&#xA;&#xA;<pre><code>/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:53&#xA;                throw err;&#xA;                ^&#xA;&#xA;Error: EACCES: permission denied, open '/root/.config/configstore/insight-yo.json'&#xA;You don't have access to this file.&#xA;&#xA;    at Error (native)&#xA;    at Object.fs.openSync (fs.js:549:18)&#xA;    at Object.fs.readFileSync (fs.js:397:15)&#xA;    at Object.create.all.get (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:34:26)&#xA;    at Object.Configstore (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:27:44)&#xA;    at new Insight (/usr/local/lib/node_modules/yo/node_modules/insight/lib/index.js:37:34)&#xA;    at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/yo/lib/cli.js:163:11)&#xA;    at Module._compile (module.js:409:26)&#xA;    at Object.Module._extensions..js (module.js:416:10)&#xA;    at Module.load (module.js:343:32)&#xA;</code></pre>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Ok it does <strong>not</strong> work even with a local installation...&#xA;Well the gateway does access to the registry, but it displays a debug page when I try to access to localhost:8080.&#xA;Actually, during the generation, I get a <code>permission denied</code> again, and missing dependencies (<code>gulp-rev</code>).</p>&#xA;&#xA;<p>I just saw this: ""It is wise to use a tag to have a stable version: the JHipster DevBox tags are the same as the JHipster Generator tags, so using the DevBox v3.2.0 also means using the generator v3.2.0"" on the DevBox GitHub page, so maybe I'll just delete and download the DevBox again...</p>&#xA;"
37254914,"I renamed my microservice, what do I do with the semantic version?",2016-05-16 13:18:13,<rename><microservices><semantic-versioning>,1,74,3,0.0,2,"<p>I have a number of microservices in a distributed system - one of which I have recently renamed to better reflect its bounded context and disambiguate with another similarly named service.</p>&#xA;&#xA;<p>The service was on version 3.1.0 at the point of renaming. My question is, what do I do with the version now? Is it 4.0.0? Or is this conceptually now a new service, replacing the old one and starting again from 1.0.0?</p>&#xA;&#xA;<p>I would lean towards the latter option, but I'm also versioning the db schema to match the service, and I don't want to end up in the position where the service is 1.0.0 but the db schema is 3.1.0...</p>&#xA;"
43498534,"In a NodeJs microservices Architecture, should I use a package.json per service?",2017-04-19 14:24:23,<node.js><microservices>,1,297,2,2.0,2,"<p>I'm currently developing a microservices architecture in NodeJs. My first approach, was a <code>package.json</code> per service. Although, it can be very tricky when accessing to a common area (with logging or database utils), for all microservices. For instance:</p>&#xA;&#xA;<pre><code>common-area &gt;&#xA;    logger.js&#xA;    package.json - install module typeorm&#xA;&#xA;service1 &gt;&#xA;    app.js - use logger.js&#xA;    package.json - also install module typeorm&#xA;</code></pre>&#xA;&#xA;<p>When running <code>node app.js</code> (Service 1) we end up with 2 typeorm modules loaded, once we made two different installations, one in common area (used by logger) and another in service1.</p>&#xA;&#xA;<p>Should I use only one <code>package.json</code>, for all micro-services, resulting in only one <code>node_modules</code> folder?</p>&#xA;"
43418403,Microservices and coupling,2017-04-14 19:57:55,<spring-mvc><microservices><coupling>,2,324,3,0.0,2,"<p>I am trying to use some kind of microservice architecture. I am trying to use HTTP and JSON as a communication medium (I know better than to call it ReST). </p>&#xA;&#xA;<p>So, I'm using spring-mvc and I wanted to use a class as a <code>ResponseBody</code> on the called and as a <code>RequestBody</code> on the callee. So it so happens that I can duplicate and mirror the class on both the projects, or create a jar and include it in both.</p>&#xA;&#xA;<p>I see coupling in both cases, the first one is duplicate coupling and the other is (I'm sure it has a name) coupling. </p>&#xA;&#xA;<p>And the <code>Request</code> and <code>Response</code> models are not what the projects have in common. I am using event-driven architecture for both and the events are somewhat similar (kinda exactly the same). </p>&#xA;&#xA;<p>What should I do?</p>&#xA;"
43369008,Unable to connect with Azure Container Services - Kubernetes,2017-04-12 12:03:27,<azure><kubernetes><credentials><microservices><azure-container-service>,1,588,7,1.0,2,"<p>I am working on setting up environment for deploying microservices.</p>&#xA;&#xA;<p>I have gotten as far as building my code and deploying to a registry but having problem running it in Azure Container Services.</p>&#xA;&#xA;<p>I am following this guide to connect to ACS: <a href=""https://docs.microsoft.com/en-us/azure/container-service/container-service-connect"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/container-service/container-service-connect</a> </p>&#xA;&#xA;<p>But i fail on the step: Download Cluster Credentials&#xA;Using the given command</p>&#xA;&#xA;<pre><code>az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt;&#xA;</code></pre>&#xA;&#xA;<p>Ofc changing the reseource group and clustername to the correct names from my portal. I get an error:</p>&#xA;&#xA;<pre><code>[WinError 10049] The requested address is not valid in its context&#xA;</code></pre>&#xA;&#xA;<p>(if i change resource group or clustername to something else I get other errors so seems it can find those at least)</p>&#xA;&#xA;<p>When i try to search for the error it seems to be some IP adress problem but can't figure out what to do. Tried running same command from other network (from home) to make sure work firewall is not blocking something.. but I get the same error</p>&#xA;&#xA;<p>Any help appriciated!</p>&#xA;"
42204181,Spring Cloud Stream Kafka - How to implement idempotency to support distributed transaction management (eventual consistency),2017-02-13 12:34:23,<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,2,1234,6,0.0,2,"<p>I have the following typical scenario: </p>&#xA;&#xA;<ul>&#xA;<li>An order service used to purchase products. Acts as the commander of the distributed transaction.</li>&#xA;<li>A product service with the list of products and its stock.</li>&#xA;<li><p>A payment service.</p>&#xA;&#xA;<pre><code>    Orders DB               Products DB&#xA;       |                       |&#xA;---------------         ----------------          ----------------&#xA;| OrderService  |       | ProductService |        | PaymentService |&#xA; ---------------         ----------------          ----------------&#xA;       |                       |                         |&#xA;       |                --------------------             |&#xA;       --------------- | Kafka orders topic |-------------&#xA;                       ---------------------&#xA;</code></pre></li>&#xA;</ul>&#xA;&#xA;<p>The normal flow would be:</p>&#xA;&#xA;<ol>&#xA;<li>The user orders a product.</li>&#xA;<li>Order service creates an order in DB and publishes a message in Kafka topic ""orders"" to reserve a product (PRODUCT_RESERVE_REQUEST).</li>&#xA;<li>Product service decreases the product stock one unit in its DB and publishes a message in ""orders"" saying PRODUCT_RESERVED</li>&#xA;<li>Order service gets the PRODUCT_RESERVED message and orders the payment publishing a message PAYMENT_REQUESTED</li>&#xA;<li>Payment service orders the payment and answers with a message PAYED</li>&#xA;<li>Order service reads the PAYED message and marks the order as COMPLETED, finishing the transaction.</li>&#xA;</ol>&#xA;&#xA;<p>I am having trouble to deal with error cases, e.g: let's assume this:</p>&#xA;&#xA;<ol start=""5"">&#xA;<li>Payment service fails to charge for the product, so it publishes a message PAYMENT_FAILED</li>&#xA;<li>Order service reacts publishing a message UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service increases the stock in the DB to cancel the reservation and publishes PRODUCT_UNRESERVATION_COMPLETED</li>&#xA;<li>Order service finishes the transaction saving the final state of the order as CANCELLED_PAYMENT_FAILED.</li>&#xA;</ol>&#xA;&#xA;<p>In this scenario imagine that for whatever reason, order service publishes a UNDO_PRODUCT_RESERVATION message but doesn't receive the PRODUCT_UNRESERVATION_COMPLETED message, so it retries publishing another UNDO_PRODUCT_RESERVATION message.</p>&#xA;&#xA;<p>Now, imagine that those two UNDO_PRODUCT_RESERVATION messages for the same order end up arriving to ProductService. If I process both of them I could end up setting an invalid stock for the product. </p>&#xA;&#xA;<p>In this scenario how can I implement idempotency? </p>&#xA;&#xA;<p><strong>UPDATE:</strong></p>&#xA;&#xA;<p>Following Artem's instructions I can now detect duplicated messages (by checking the message header) and ignore them but there may still be situations like the following where I shouldn't ignore the duplicated messages:</p>&#xA;&#xA;<ol>&#xA;<li>Order Service sends UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service gets the message and starts processing it but crashes before updating the stock.</li>&#xA;<li>Order Service doesn't get a response so it retries sending UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service knows this is a duplicated message BUT, in this case it should repeat the processing again. </li>&#xA;</ol>&#xA;&#xA;<p>Can you help me come up with a way to support this scenario as well? How could I distinguish when I should discard the message or reprocess it?</p>&#xA;"
48505946,Single Database backed Micro-server architecture?,2018-01-29 16:35:32,<architecture><microservices>,2,121,3,0.0,2,"<p>In an application I am planning to build, I am trying to decide an architecture for our server. One idea I had was to spawn multiple servers at different addresses like <code>orders.example.com</code>, <code>settings.example.com</code> etc, i.e. , one server process per component of the system, which will be backed by a single database cluster.</p>&#xA;&#xA;<p>I am wondering if this is a good idea, and what are the caveats of it, if anyone has ever used it ?</p>&#xA;"
48531937,AWS ALB per ECS Service vs. multiple services per ALB for a microservices architecture,2018-01-30 23:05:32,<amazon-web-services><microservices><amazon-elb><amazon-route53><amazon-alb>,1,272,4,0.0,2,"<p>Initially I thought that multiple services per ALB listener with different path patterns to distribute API calls appropriately was the obvious choice. In terms of health checks though (if one of those services goes down), I don't know of a smart way to divert traffic for just that service to a different region. </p>&#xA;&#xA;<p>If I have an active active setup with weighted route 53 records that will failover on a health check, I don't see any other solution than to either cut off that entire ALBs traffic and divert to another region, or ignore the 1 down service and continue to send traffic to the partially failing ALB.</p>&#xA;&#xA;<p>Having a one to one mapping of ALBs to services fixes this solution, but it adds additional overhead in terms of cost and complexity.</p>&#xA;&#xA;<p>What is the recommended pattern to follow for an active active microservices architecture?</p>&#xA;"
48687955,Communication among microservices: Apache Kafka vs Hazelcast's Topic,2018-02-08 14:35:09,<apache-kafka><microservices><messaging><hazelcast>,1,400,0,2.0,2,"<p>Disclaimer.&#xA;I have experience with <a href=""https://hazelcast.com/"" rel=""nofollow noreferrer"">Hazelcast</a> and <a href=""http://vertx.io/"" rel=""nofollow noreferrer"">Vert.x</a>. I'm new to <a href=""https://kafka.apache.org/"" rel=""nofollow noreferrer"">Apache Kafka</a>. Sorry if my question look preconceived, it's not.</p>&#xA;&#xA;<p>There are two widespread ways to arrange communication among microservices: REST and messaging. In my region, when someone says they're using messaging for communication among microservices - it de facto means Apache Kafka. </p>&#xA;&#xA;<p><em>Could you please help me to find a clue why Apache Kafka is better fit for communication needs among microservices than Hazelcast's Topic? Is it better? Because of which guarantees, features or architecture decisions?</em></p>&#xA;&#xA;<p>The Hazelcast's example for cluster wide messaging looks as following:</p>&#xA;&#xA;<pre><code>// node #1&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"")&#xA;         .publish(new Date());&#xA;&#xA;// node #2&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"");&#xA;         .addMessageListener(message -&gt; /*Do something here*/);&#xA;</code></pre>&#xA;&#xA;<p>Also there is Vert.x (very roughtly speaking actors framework) written on top of Hazelcast's topics and member discovery.</p>&#xA;&#xA;<p><em>Is Kafka messaging better for communication among microservices?</em></p>&#xA;"
48753245,How to expose APIs endpoints from private AWS ALB,2018-02-12 18:35:49,<amazon-web-services><microservices><amazon-vpc><aws-ecs>,3,240,0,0.0,2,"<p>We are having several microservices on AWS ECS. We have single ALB which has different target group for different microservices. We want to expose some endpoints externally while some endpoints just for internal communication. </p>&#xA;&#xA;<p>The problem is that if we put our load balancer in public VPC than it means that we are exposing all register endpoints externally. If we move load balancer to private VPC, we have to use some sort of proxy in public VPC, which required additional infra/cost and custom implementation of all security concerns like D-DOS etc.</p>&#xA;&#xA;<p>What possible approaches we can have or does AWS provide some sort of out of the box solution for this ?</p>&#xA;"
48805353,Can we call Zuul enabled server through RestTemplate,2018-02-15 10:47:22,<java><microservices><netflix-eureka><netflix-zuul>,3,431,2,0.0,2,"<p>I am trying to call a <code>zuul</code> enabled server through <code>RestTemplate</code> by directly giving the URL.&#xA;For example: restTemplate.getForObject(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>"", Employee[].class);</p>&#xA;&#xA;<p>But it is giving an error to me:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: No instances available for localhost&#xA;      at org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.execute(RibbonLoadBalancerClient.java:90) ~[spring-cloud-netflix-core-1.2.3.RELEASE.jar:1.2.3.RELEASE]</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Question in detail</strong> :&#xA;I am having four projects (Github link (branch-master): <a href=""https://github.com/vickygupta0017/microservice-poc"" rel=""nofollow noreferrer"">https://github.com/vickygupta0017/microservice-poc</a>)</p>&#xA;&#xA;<ol>&#xA;<li>microservice-server (eureka-server) port:8080</li>&#xA;<li>microservice-producer (Rest-api)   port:8086</li>&#xA;<li>zuul-gatewayproxy (zuul-server)   port:8090</li>&#xA;<li><p>microservice-consumer (spring-mvc) port:8087</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Gg1hF.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gg1hF.jpg"" alt=""Flow Image""></a></p></li>&#xA;</ol>&#xA;&#xA;<p>If I am calling <code>zuul server</code> directly from browser(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>), then it is redirecting the request to producer successfully.&#xA;But if I am calling this URL from the consumer through <code>RestTemplate</code> then it is giving me this error.</p>&#xA;&#xA;<p><strong>For Information :</strong> If I am not using zuul sever then I am able to call 'microservice-producer' from 'microservice-consumer' using <code>RestTemplate</code> successfully.</p>&#xA;"
48731168,How to apply a microservices architecture to a voting application?,2018-02-11 11:50:05,<node.js><microservices>,2,66,4,2.0,2,"<p>I am developing the FreeCodeCamp full stack voting application and would like to apply a microservices architecture. The user stories of the voting application are as follows:</p>&#xA;&#xA;<ul>&#xA;<li>As an authenticated user, I can keep my polls and come back later to access them.</li>&#xA;<li>As an authenticated user, I can share my polls with my friends.</li>&#xA;<li>As an authenticated user, I can see the aggregate results of my polls.</li>&#xA;<li>As an authenticated user, I can delete polls that I decide I don't want anymore.</li>&#xA;<li>As an authenticated user, I can create a poll with any number of possible items.</li>&#xA;<li>As an unauthenticated or authenticated user, I can see and vote on everyone's polls.</li>&#xA;</ul>&#xA;&#xA;<p>I am conceptualizing an architecture and come up with this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hn6Pe.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hn6Pe.jpg"" alt=""Concept Architecture Voting App""></a></p>&#xA;&#xA;<p>The application is composed of 6 microservices:&#xA;1. UI&#xA;2. Aggregator&#xA;3. Authorization (login, logout)&#xA;4. Social Media (sharing)&#xA;5. Polls (with db)&#xA;6. Users (with db)</p>&#xA;&#xA;<p>Curious how a developer having built microservices would break down these user stories into microservices. Thank you!</p>&#xA;"
48809275,SpringBoot microservice How to set properties in application context using java configuration,2018-02-15 14:11:20,<java><spring><spring-boot><microservices><applicationcontext>,2,455,4,0.0,2,"<p>I have a spring-boot microservice with Java based config. Now there is an auth token container, which I need to call to get the access token. That auth token library has a class like this. Notice that the class <code>AuthServletContextListener</code> comes from a third party  <code>jar</code> file which I can not modify.</p>&#xA;&#xA;<pre><code>public class AuthServletContextListener implements ServletContextListener {&#xA;    public void contextInitialized(ServletContextEvent arg0) {&#xA;        try {&#xA;            ServletContext e = arg0.getServletContext();&#xA;            Properties config = new Properties();&#xA;            this.addProp(config, e, ""auth.token.url"", ""Token Service URL"");&#xA;            this.addProp(config, e, ""auth.system.username"", ""System Username"");&#xA;            this.addProp(config, e, ""cauth.system.password"", ""System Password"");&#xA;            TokenContainer.init(config);&#xA;        } catch (IOException arg3) {&#xA;            arg3.printStackTrace();&#xA;        }&#xA;&#xA;    }&#xA;&#xA;&#xA;    private void addProp(Properties config, ServletContext context, String propName, String descrip) {&#xA;        String propVal = (String) context.getAttribute(propName);&#xA;        if (StringUtils.isEmpty(propVal)) {&#xA;            propVal = context.getInitParameter(propName);&#xA;        }&#xA;&#xA;        if (StringUtils.isNotEmpty(propVal)) {&#xA;            config.put(propName, propVal);&#xA;        } else {&#xA;            throw new RuntimeException(""error: "");&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The AuthContextListener has an annotation that automatically looks for an application startup event. This automatically starts the container correct settings if the above context params are included. I can then grab the token through that container like this:</p>&#xA;&#xA;<pre><code>TokenContainer.getSystemToken() &#xA;</code></pre>&#xA;&#xA;<p>This will initialize successfully if the above context params are included in the web.xml like so:</p>&#xA;&#xA;<pre><code>&lt;context-param&gt;&#xA;   &lt;param-name&gt;auth.system.username&lt;/param-name&gt;&#xA;   &lt;param-value&gt;UserName&lt;/param-value&gt;&#xA;&lt;/context-param&gt; &#xA;</code></pre>&#xA;&#xA;<p>The same Application context configuration as above can be performed by creating a Spring bean with the following information:</p>&#xA;&#xA;<pre><code>&lt;bean&gt;&#xA;    &lt;property name=""attributes""&gt;&#xA;        &lt;map&gt;&#xA;            &lt;entry key=""auth.token.url"" value=""${auth.token.url}""/&gt;&#xA;            &lt;entry key=""auth.system.username"" value=""${auth.system.username}""/&gt;&#xA;            &lt;entry key=""auth.system.password"" value=""${auth.system.password}""/&gt;&#xA;        &lt;/map&gt;&#xA;    &lt;/property&gt;&#xA;&lt;/bean&gt;&#xA;</code></pre>&#xA;&#xA;<p>My question is how can I achieve the same using Java based configuration in a latest spring boot application. All I have is <code>application.yml</code> file with the auth endpoint, username and password values. I tried using <code>@Configuration</code> bean but no luck. How can I set those three props in application context and make that listener start automatically for me.</p>&#xA;"
48762736,What is the best way to send password from app server to authentication micro service?,2018-02-13 08:49:49,<node.js><microservices>,1,53,7,0.0,2,"<p>I am currently in a process to develop micro service architecture in one of my projects. I have one public layer of App Servers which actually routes the user requests to relevant micro services and replies back to client. My mirco services are in private layer.</p>&#xA;&#xA;<p>Currently i am using REST API to send data back and forth. However, I was wondering, what is the best way to send username and password from app server to micro service? Should I use plain text format as micro service is in private layer? Please suggest best way.</p>&#xA;"
41039545,How to manage common frontend components on microservices,2016-12-08 12:27:36,<architecture><frontend><single-page-application><microservices><orchestration>,1,438,3,2.0,2,"<p>How to manage frontend on microservices, especially when you have common components? I found a few solutions on the internet but all of them have some drawbacks and none of them is a good fit for us.</p>&#xA;&#xA;<p>Let me clearify my problem. We have over 5 groups of people working on different microservices in a large single project. And almost all of them has some common,shared components on frontend. And these components are huge as they are already a different project but totally shared. Now how to manage these shared components or should we duplicate them?</p>&#xA;&#xA;<p>First solution I found is to make those components shared and maintain from a single point like node packages and npm install when needed from different groups. But at this point the microservice approach is broken since everybody will be dependent to these components and no one will be able to maintain as soon as they need, not good. And very hard to maintain since in the future different groups may different needs from the component.</p>&#xA;&#xA;<p>Second is to duplicate the components according to each project and develop within the microservice group but this time it becomes very frankenstein and the common concepts that we should obey are hard to catch. It's a really enterprise project that all components should match in terms of behaivor and look to the other components reoccured in the project. </p>&#xA;&#xA;<p>So we need a frontend solution for microservices that should be suitable for an enterprise project which is needed to obey same rules(like font size,color,actions etc..) at different points as it is monolithly written, but maintainable by different groups at the same time.</p>&#xA;&#xA;<p>How can we balance that or can we?</p>&#xA;&#xA;<p>Thanks to @kayess: Shortly how to apply shared kernel on microservices as the teams will not be dependent to each other?</p>&#xA;"
41019199,Enabling CORS in Azure Service Fabric Web Api,2016-12-07 13:50:41,<angularjs><azure><asp.net-web-api><microservices><azure-service-fabric>,2,883,5,1.0,2,"<p>I have an angular app that sends an http request to my Service Fabric Web API (deployed on a Secure Service Fabric cluster) like so:</p>&#xA;&#xA;<pre><code>    $scope.request_headers = {&#xA;            ""Content-Type"": ""application/xml; charset=utf-8"",&#xA;            ""Access-Control-Allow-Origin"":""*""&#xA;        }&#xA;    $http({&#xA;                url: ""Service_Fabric_web_api_url"",&#xA;                method: ""GET"",&#xA;                headers:$scope.request_headers&#xA;            }).&#xA;            then(function (result) {&#xA;                console.log(result);&#xA;            });&#xA;</code></pre>&#xA;&#xA;<p>I've also enabled CORS globally in my web api startup class like so:</p>&#xA;&#xA;<pre><code>HttpConfiguration config = new HttpConfiguration();&#xA;var cors = new EnableCorsAttribute(""*"", ""*"", ""*"");&#xA;config.EnableCors(cors);&#xA;</code></pre>&#xA;&#xA;<p>When I run my angular app locally and try sending the http request, I still get this error:</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load Service_Fabric_web_api_url. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:xxxxx' is therefore not allowed access. The response had HTTP status code 500.&#xA;</code></pre>&#xA;&#xA;<p>I'm able to access my service directly from my browser with the same url.</p>&#xA;&#xA;<p>Also, the same http request works when I tried deploying my Web Api on an unsecure Service Fabric Cluster with the same lines added to the startup class to enable CORS. </p>&#xA;&#xA;<p>Why is this happening even though I've enabled CORS globally in my Web API and particularly when its on a secure cluster?</p>&#xA;"
45886359,Golang Nats subscribe issue,2017-08-25 17:05:11,<go><message-queue><microservices><nats.io>,1,262,5,0.0,2,"<p>I work currently on a micro service architecture.&#xA;Before I insert NATS into my project I wanted to test some simple scenarios with it.</p>&#xA;&#xA;<p>In one scenario I have a simple publisher, which publishes 100.000 messages in a for loop over a basic Nats server running on localhost:4222.</p>&#xA;&#xA;<p>The big problem with it, is the subscriber. When he receive between 30.000 - 40.000 messages my whole main.go program and all other go routines just stops and do nothing. I can just quit with ctrl + c. But the Publisher is still keep sending the messages. When I open a new terminal and start a new instance of the subscriber all again works well, till the Subscriber receive about 30000 messages. And the worst thing is that there appears not even one error and also no logs on the server so I have no idea whats going on.</p>&#xA;&#xA;<p>After that I was trying replace the Subscribe-method with the QueueSubscribe-method and all works fine.</p>&#xA;&#xA;<p>What is the main difference between Subscribe and QueueSubscribe?</p>&#xA;&#xA;<p>Is NATS-Streaming a better opportunity? Or in which cases I should prefer Streaming and in which the standard NATS-Server </p>&#xA;&#xA;<p>Here is my code:</p>&#xA;&#xA;<p>Publisher:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;func main() {&#xA;    go createPublisher()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createPublisher() {&#xA;&#xA;    log.Println(""pub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    msg := make([]byte, 16)&#xA;&#xA;    for i := 0; i &lt; 100000; i++ {&#xA;        nc.Publish(""alenSub"", msg)&#xA;        if (i % 100) == 0 {&#xA;            fmt.Println(""i"", i)&#xA;        }&#xA;        time.Sleep(time.Millisecond)&#xA;    }&#xA;&#xA;    log.Println(""pub finish"")&#xA;&#xA;    nc.Flush()&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Subscriber:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;var received int64&#xA;&#xA;func main() {&#xA;    received = 0&#xA;&#xA;    go createSubscriber()&#xA;    go check()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createSubscriber() {&#xA;&#xA;    log.Println(""sub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    nc.Subscribe(""alenSub"", func(msg *nats.Msg) {&#xA;        received++&#xA;    })&#xA;    nc.Flush()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func check() {&#xA;    for {&#xA;        fmt.Println(""-----------------------"")&#xA;        fmt.Println(""still running"")&#xA;        fmt.Println(""received"", received)&#xA;        fmt.Println(""-----------------------"")&#xA;        time.Sleep(time.Second * 2)&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
40377076,Access to Microservices via Eureka Server,2016-11-02 10:01:34,<spring><spring-boot><microservices><netflix-eureka>,2,1976,1,1.0,2,"<p>can I access to microservice with someting like this:&#xA;Eureka Server: <a href=""http://localhost:8761/"" rel=""nofollow noreferrer"">http://localhost:8761/</a>&#xA;Microservice url: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a>&#xA;Call to Microservice to be something like: <a href=""http://localhost:8761/name-service/"" rel=""nofollow noreferrer"">http://localhost:8761/name-service/</a>&#xA;Is it posible?&#xA;When i open the eureka server the service is registered.</p>&#xA;&#xA;<p>eureka/application.properties:</p>&#xA;&#xA;<pre><code>server.port=8761&#xA;eureka.client.register-with-eureka=false&#xA;eureka.client.fetch-registry=false&#xA;logging.level.com.netflix.eureka=OFF&#xA;logging.level.com.netflix.discovery=OFF&#xA;</code></pre>&#xA;&#xA;<p>name-service/application.properties</p>&#xA;&#xA;<pre><code>spring.application.name=name-service&#xA;server.port=8080&#xA;</code></pre>&#xA;&#xA;<p>How can i achieve this?</p>&#xA;"
40485481,Front End Developer workflow for Service Fabric Web Apps,2016-11-08 11:15:26,<azure><microservices><azure-service-fabric>,1,396,7,2.0,2,"<p>I'm a front end developer about to join a project team working with Service Fabric to build a Web Front End to their microservice driven application.</p>&#xA;&#xA;<p>One of the problems I've been having in my own research is that when working with local Service Fabric Clusters, I have to redeploy my Application to test if something does or doesn't work in my Web App. This slows down developer velocity massively, as the process will only take longer and longer as other Back End services are added. I largely work with the Web App communicating to an API Gateway Service (GraphQL.NET). </p>&#xA;&#xA;<p>What I'd like to know is if there's a way to run a local Web Application out outside of a Service Fabric cluster, but still have it communicate to one. This would allow my front end developer tool chain to remain intact, and develop at a much faster pace with incremental building and live-reload tools.</p>&#xA;&#xA;<p>Of course, if anyone's come up with any better solution to the problem, I'd love to hear about it! ;)</p>&#xA;"
29825744,How to decide between using messaging (e.g. RabbitMQ) versus a web service for backend component interactions/communication?,2015-04-23 13:58:41,<web-services><rest><messaging><spring-rabbit><microservices>,2,1338,0,1.0,2,"<p>In developing backend components, I need to decide how these components will interact and communicate with each other. In particular, I need to decide whether it is better to use (RESTful, micro) web services versus a message broker (e.g. RabbitMQ).  Are there certain criteria to help decide between using web services for each component versus messaging?</p>&#xA;"
29775643,Microservice Event driven Design with multiple Instances,2015-04-21 14:49:06,<spring><jms><spring-jms><microservices><event-driven-design>,1,740,0,1.0,2,<p>At the Moment we design and plan to transform our system to a microservice architecture pattern. </p>&#xA;&#xA;<p>To loose coupling we think about an event driven design with an JMS Topic. This looks great. But i don't now how we can solve the problem with multiple instances of a microservice. &#xA;For failover and load balancing we have <em>n</em> instances of each service. If an event is published to the topic each instance will receive and process that event. </p>&#xA;&#xA;<p>It's possible to handle this with locks and processed states in the data storage. But this solution looks very expensive and every instance has the same work. This is not a load balaning for me. </p>&#xA;&#xA;<p>Is there some good Solution or best practice for this pattern?</p>&#xA;
41762928,How to do client side load balancing for discovered microservices in nodejs,2017-01-20 11:45:09,<node.js><microservices><netflix-ribbon>,2,1286,1,0.0,2,"<p>We are trying to build a microservice with nodejs in an environment with other microservices written in java/spring boot.</p>&#xA;&#xA;<p>The other microservices are using consul.io for service discovery and ribbon for client side load balancing. (that would be: spring-boot, spring-cloud-starter-consul-discovery, spring-cloud-starter-feign and spring-cloud-starter-ribbon projects)</p>&#xA;&#xA;<p>Now in this mix, we have a <a href=""https://www.npmjs.com/package/consul"" rel=""nofollow noreferrer"">consul node module</a> to register or discover services, but what of rest of the things? How do I do a discovery-aware rest call with a load balancing handled on the client, similar to that of ribbon.</p>&#xA;&#xA;<p>How can I achieve this in node's stack?</p>&#xA;"
41850142,Microservices centralized database model,2017-01-25 11:13:51,<mysql><database><go><microservices>,2,1030,3,1.0,2,"<p>Currently we have some <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">microservice</a>, they have their own database model and migration what provided by GORM Golang package. We have a big old MySQL database which is against the microservices laws, but we can't replace it. Im afraid when the microservices numbers start to growing, we will be lost in the many database model. When I add a new column in a microservice I just type <code>service migrate</code> to the terminal (because there is a cli for run and migrate commands), and it is refresh the database.</p>&#xA;&#xA;<p>What is the best practice to manage it. For example I have 1000 microservice, noone will type the <code>service migrate</code> when someone refresh the models. I thinking about a centralized database service, where we just add a new column and it is store the all model with all migration. The only problem, how will the services get know about database model changes. This is how we store for example a user in a service:</p>&#xA;&#xA;<pre><code>type User struct {&#xA;    ID        uint           `gorm:""column:id;not null"" sql:""AUTO_INCREMENT""`&#xA;    Name      string         `gorm:""column:name;not null"" sql:""type:varchar(100)""`&#xA;    Username  sql.NullString `gorm:""column:username;not null"" sql:""type:varchar(255)""`&#xA;}&#xA;&#xA;func (u *User) TableName() string {&#xA;    return ""users""&#xA;}&#xA;</code></pre>&#xA;"
51099034,Map JPA Embedded entity class id to Embeddable entity class id,2018-06-29 09:53:58,<java><hibernate><spring-data-jpa><microservices><hibernate-mapping>,2,119,5,0.0,2,"<p>I have a class:</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class A {&#xA;    @Embedded&#xA;    @AttributeOverride(name = ""id"", column = @Column(name = ""b_id""))&#xA;    private B b;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There is column b_id BIGINT NOT NULL in table A</p>&#xA;&#xA;<pre><code>@Embeddable&#xA;@Entity&#xA;public class B {&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>we are getting error: Caused by: org.hibernate.MappingException: component property not found: id</p>&#xA;&#xA;<p>Basically, we need to map B in A using id</p>&#xA;&#xA;<p>Kindly help</p>&#xA;"
42490380,Handling JWT and Refresh token flow,2017-02-27 16:06:38,<security><jwt><microservices>,1,1223,0,1.0,2,<p>I am building a front end built in react that accesses multiple microservice apis that I am also building. For auth I have built a jwt login system but was wondering what is the process of handling refresh tokens. </p>&#xA;&#xA;<ol>&#xA;<li><p>Is the refresh token inside the jwt with the user info or is it in its own token with a different encryption for extra protection?</p></li>&#xA;<li><p>If it is in its own token what should the other micro services respond with to the react app if the jwt is invalid and needs to be refreshed. Is there a common http status code used?</p></li>&#xA;<li><p>I have read that a refresh token should be more secure then your jwt cause it can be used to issue jwts and will have a longer active time. Is there any extra security past encryption that can be done server side or client side that isnt already done for jwts?</p></li>&#xA;<li><p>When should you refresh the refresh token with a new token and timestamp that it becomes invalid?</p></li>&#xA;</ol>&#xA;
42435307,Spring Cloud Netflix vs Kubernetes,2017-02-24 09:42:37,<kubernetes><microservices><docker-swarm><netflix-zuul><spring-cloud-netflix>,1,2244,1,1.0,2,"<p>I am trying to finally choose between Spring Cloud Netflix, Kubernetes and Swarm for building our microservices environment. They are all very cool and do some choice is very hard. &#xA;I'll describe a little which kind of problems I want to solve.&#xA;I couldn't find any best way to design Api Gateway (not a simple load balancer) with Kubernetes or Swarm , that's why I want to use Zuul. But from other side Api Gateway must use service discovery which in case of Kubernetes or Swarm will be embedded inside the orchestra. With Kubernetes I can use it's spring cloud integration, but this way I will have server side discovery and client side discovery inside Kubernetes. Which is overkill I think. &#xA;I am wondering does anyone have some experience with them and any suggestions about that.&#xA;Thanks.</p>&#xA;"
39457873,How to include CorrelationId in microservice architecture?,2016-09-12 19:57:35,<microservices><asp.net-core-webapi>,1,777,4,1.0,2,"<p>I am creating a microservices architecture using ASP.NET Core web api. All the services are decoupled from each other, and may be deployed in different environments. Every service has its own logging. When requests flows through these services it could fail in any of the service, We need a way of tracing a series of events back to the source, even if it means traversing multiple services.<br>&#xA;So to handle this issue, the service that originates the request creates a CorrelationId and pass it to the next service. The 2nd service pass it to 3rd service and so on. If exception occurs the corresponding service will log the exception message along with CorrelationId.</p>&#xA;&#xA;<p>I wanted to know what would be a best place for the caller of the service to pass the correlationid? </p>&#xA;&#xA;<p>Should the caller pass correlationid in HttpHeader or should it pass it as a part method parameter something like below</p>&#xA;&#xA;<p><em>This is the service that is getting called</em></p>&#xA;&#xA;<pre><code> public class RequestDTO&#xA; {&#xA;    public string CorrelationId {get;set;}&#xA;    public string SomeOtherData {get;set;}&#xA; }&#xA;&#xA; public Service2Controller:Controller&#xA; {&#xA;    public Task&lt;in&gt; DoSomething(RequestDTO request)&#xA;    {&#xA;         // add the correlationid in current request Items collection&#xA;         // So global exception handling can access it and log it &#xA;         // along with the exception&#xA;&#xA;         HttpContext.Items.Add(""CorrelationId"", request.CorrelationId);&#xA;    }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>in the approach above if there is an exception before this method is invoked, the CorrelationId will not be available for global exception handler for logging.</p>&#xA;&#xA;<p>Any suggestions? or alternate approach</p>&#xA;"
39561186,Best practice for loading multiple dynamic services and them dependencies services,2016-09-18 18:28:43,<c#><multithreading><reflection><microservices>,2,58,5,0.0,2,"<p>I want to devlop a custom system for my self.</p>&#xA;&#xA;<p>I want to loading custom services by configuratin with dependency services - for example:</p>&#xA;&#xA;<pre><code>&lt;Services&gt;&#xA;    &lt;Service name=""ServiceA"" args="""" type=""CommonLib.IServiceA"" dependencies=""""/&gt;&#xA;    &lt;Service name=""ServiceB"" args="""" type=""CommonLib.IServiceB"" dependencies=""ServiceA""/&gt;&#xA;    &lt;Service name=""ServiceC"" args="""" type=""CommonLib.IServiceC"" dependencies=""ServiceA,ServiceB""/&gt;&#xA;    &lt;Service name=""ServiceD"" args="""" type=""CommonLib.IServiceD"" dependencies=""ServiceA,ServiceB,ServiceC""/&gt;&#xA;    &lt;Service name=""ServiceE"" args="""" type=""CommonLib.IServiceE"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD""/&gt;&#xA;    &lt;Service name=""ServiceF"" args="""" type=""CommonLib.IServiceF"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD,ServiceE""/&gt;&#xA;&lt;/Services&gt;&#xA;</code></pre>&#xA;&#xA;<p>All those services are implement custom interface:</p>&#xA;&#xA;<pre><code>public interface IService&#xA;{&#xA;    bool Start();&#xA;    bool Stop();&#xA;    bool IsReady {get;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What the best practice for loading dynamic services toghether but depends on those dependencies?</p>&#xA;&#xA;<p>Loop every service and postpone till those dependencies are loaded and ready?</p>&#xA;&#xA;<p>Have any tutorial for that?</p>&#xA;"
47145930,Microservices versioning best practices,2017-11-06 21:16:16,<architecture><versioning><microservices>,2,885,0,1.0,2,"<p>I read the Susan Fowler's book ""production ready microservices"" and in two places (until now) I found </p>&#xA;&#xA;<ul>&#xA;<li>(page 26) ""Avoid Versioning Microservices and Endpoints"", </li>&#xA;<li>""versioning microservices can easily become an organizational nightmare"" (page 27),</li>&#xA;<li>In microservice ecosystems, the versioning of microservices is discouraged(page 58)</li>&#xA;</ul>&#xA;&#xA;<p>Anyway, I used all types of versioning for all kind of different projects: git tag, deb package versioning, python packages versioning, http api versions and I never had very big problems to manage the project's versions. Beside of this I knew exactly to what version to roll out in case of some failures or bugs from customers.</p>&#xA;&#xA;<p>Anybody have any clue why in this book the microservice versioning is so blamed and what advises would you have regarding the topic?</p>&#xA;"
47295217,How to start a spring boot tomcat server on a specified port through command prompt,2017-11-14 21:07:54,<java><spring><spring-mvc><spring-boot><microservices>,1,415,1,2.0,2,"<p>I have a very simple ""Hello World"" kind of REST api created using Spring Boot that is accessible through <a href=""http://localhost:8080/greeting/world"" rel=""nofollow noreferrer"">http://localhost:8080/greeting/world</a> without any problem.</p>&#xA;&#xA;<p>I would like to start two more instances of this API on ports 8081 and 8082 but not able to do so. It says <code>java.net.BindException: Address already in use: bind</code></p>&#xA;&#xA;<p><strong>Command Used:</strong></p>&#xA;&#xA;<pre><code>mvn spring-boot:run -Dserver.port=8081&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: world-greeting-service&#xA;</code></pre>&#xA;&#xA;<p><strong>WorldGreetingServiceApplication.java</strong></p>&#xA;&#xA;<pre><code>@RestController&#xA;@SpringBootApplication&#xA;public class WorldGreetingServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(WorldGreetingServiceApplication.class, args);&#xA;    }&#xA;&#xA;    @RequestMapping(""/greeting/world"")&#xA;    public String greetWorld() {&#xA;        return ""Hello World!"";&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Am I missing anything?</p>&#xA;"
47329630,How to host MassTransit and RabbitMq,2017-11-16 12:25:13,<rabbitmq><cloud><microservices><masstransit><queuing>,2,325,3,0.0,2,"<p>We are working towards an architecture like one below but we will have micro services on cloud and some on premises which will talk to each other using queue(s) and bus(es), </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qfFOh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qfFOh.png"" alt=""RabbitMQ implementation of an event bus""></a></p>&#xA;&#xA;<p>Now I am confused with where we should host MassTransit and RabbitMq, also should it be a ASP.NET Core project on its own ? if yes what I will be doing in it ? starting a bus ? creating queues ? I am not able to move forward with this</p>&#xA;"
37793364,"AWS ECS: How do I get around ""too many containers"" with my microservice architecture API?",2016-06-13 15:13:57,<amazon-web-services><elastic-beanstalk><microservices><amazon-ecs>,2,916,6,0.0,2,"<p>I'm working on an API with microservice architecture. I deploy to ECS via Elastic Beanstalk. Each microservice is a long-running task (which, on ECS equates to a single container). I just passed up 10 tasks, and I can no longer deploy.</p>&#xA;&#xA;<blockquote>&#xA;  <p>ERROR: Service:AmazonECS, Code:ClientException, Message:Too many containers., Class:com.amazonaws.services.ecs.model.ClientException</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""http://docs.aws.amazon.com/AmazonECS/latest/developerguide/service_limits.html"" rel=""nofollow"">According to the documentation</a>, 10 task definition containers is a hard limit on ECS.</p>&#xA;&#xA;<p>Is there any way to get around this? How can I continue adding services to my API on ECS? This limitation suggests to me I am not using the service as intended. What is the best way to deploy a collection of microservices each as a separate Docker container on AWS?</p>&#xA;&#xA;<p><strong>EDIT:</strong> My understanding of the relationship between containers and tasks was completely wrong. Looks like the entire API is a single task and each container in my Dockerrun.aws.json is a container inside the API task. So, the limitation is a limit on containers inside a single task.</p>&#xA;"
37854185,Server to Server communication in microservices,2016-06-16 08:46:04,<java><spring><microservices><spring-cloud-netflix>,2,967,11,1.0,2,"<p>I am working on microservice architecture, but I am facing some challenges in that.</p>&#xA;&#xA;<p>First let me give you a brief about the architecture.</p>&#xA;&#xA;<ol>&#xA;<li><p>User logs in and get a signed token which will be used to call all REST APIS.</p></li>&#xA;<li><p>There will be lot of API server where APIs are secured using Spring security and Authorized as per the user roles.</p></li>&#xA;<li><p>Services have to interact with each other to get/update information.</p></li>&#xA;<li><p>Every service will have the power to validate a token issue by auth server.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem:-</p>&#xA;&#xA;<ol>&#xA;<li><p>Everything works fine if User logs in and the same token is used and passsed to every service which is validated across.So, services dont need to trust each other as the token is passed.</p></li>&#xA;<li><p>Now, the problem is there are some services which needs to be called from server itself without logging in. Lets say a server to server call. How will a service authenticate and authorize the call from other services.</p></li>&#xA;</ol>&#xA;&#xA;<p>I read about spring Microservices but Zuul is also not the saviour here as every API server has spring security embedded and not just the API gateway.</p>&#xA;&#xA;<p>One solution can be that every service has its own default user with certaing roles which is used to Login->Fetch a token->call other server api with token.</p>&#xA;&#xA;<p>Can you please give me some pointers in server to server calls where each server is authenticated and authorized using spring security.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;"
43532494,Use ehcache for application deployed via docker against the stateless rule,2017-04-21 01:37:26,<docker><spring-boot><ehcache><microservices><stateless>,3,333,1,0.0,2,"<p>I have an spring-boot application which I would like to deploy it into multiple docker instances and there is a load balance before the instances.&#xA;However, the application uses ehcache to cache some data from a database. It makes the application stateful.&#xA;So without session sticky, a same customer might hit different docker instances and see different results.&#xA;My question is if I can't apply session sticky in load balance, what is the best practice to deploy an app with cache feature via docker style and still comply the rule of should-be-stateless?</p>&#xA;"
43538070,How to manage state in microservices?,2017-04-21 08:49:10,<kubernetes><microservices>,1,464,4,0.0,2,"<p>First of all, this is a question regarding my thesis for school. I have done some research about this, it seems like a problem that hasn't been tackled yet (might not be that common).</p>&#xA;&#xA;<p>Before jumping right into the problem, I'll give a brief example of my use case.</p>&#xA;&#xA;<p>I have multiple namespaces containing microservices depending on a state X. To manage this the microservices are put in a namespace named after the state. (so namespaces state_A, state_B, ...)</p>&#xA;&#xA;<p>Important to know is that each microservice needs this state at startup of the service. It will download necessary files, ... according to the state. When launching it with state A version 1, it is very likely that the state gets updated every month. When this happens, it is important to let all the microservices that depend on state A upgrade whatever necessary (databases, in-memory state, ...).</p>&#xA;&#xA;<p>My current approach for this problem is simply using events, the microservices that need updates when the state changes can subscribe on the event and migrate/upgrade accordingly. The only problem I'm facing is that while the service is upgrading, it should still work. So somehow I should duplicate the service first, let the duplicate upgrade and when the upgrade is successful, shut down the original. Because of this the used orchestration service would have to be able to create duplicates (including duplicating the state).</p>&#xA;&#xA;<p>My question is, are there already solutions for my problem (and if yes, which ones)? I have looked into Netflix Conductor (which seemed promising with its workflows and events), Amazon SWF, Marathon and Kubernetes, but none of them covers my problem.</p>&#xA;&#xA;<p>Best of all the existing solution should not be bound to a specific platform (Azure, GCE, ...).</p>&#xA;"
43664192,Do we create difference projects when implementing micro services architecture in spring,2017-04-27 17:19:09,<java><spring><spring-mvc><spring-boot><microservices>,1,99,5,0.0,2,"<p>I am confused with microservice architecture. I am not able to understand how to implement the microservice architecture in spring. In spring we use <code>@RestController</code> for Rest API. Let's say we have two rest controller like below</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/user"")&#xA;public class UserService {&#xA;// this class will hanlder operations related to user&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/role"")&#xA;public class RoleService {&#xA;// this class will hanlder operations related to role&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Both rest controllers belong to one single project. Can we say our above structure is microservices? Or we have to create two projects one is <code>UserServiceProject</code> and another one is <code>RoleServiceProject</code>. In <code>UserServiceProject</code> we create Rest Controller for rest API of User operations. In <code>RoleServiceProject</code> we create Rest Controller for rest API of Role Operations. </p>&#xA;&#xA;<p>As microservices architecture says each service should be independently deployable. From this definition can we say that if we have 2 services we need to create two projects so that both projects can be independently deployable. </p>&#xA;&#xA;<p>Please also note both services share the same database and also there is a relationship between User and Role.</p>&#xA;"
43633659,What to use for microservices inter-communications .NET,2017-04-26 12:03:03,<.net><design-patterns><microservices>,1,875,11,0.0,2,"<p>Doing some research on splitting our monolith into micro-services and trying to understand/determine the best way for communications between services, or if I should even be communicating between services?</p>&#xA;&#xA;<p>Should each micro-service be a web service that only serves Http or should I be using a service bus to pass work requests around?</p>&#xA;"
47566338,Not able to read configuration from Consul in spring-boot application,2017-11-30 05:13:58,<spring-boot><microservices><spring-cloud><consul><spring-cloud-consul>,1,806,3,2.0,2,"<p>I am creating a <code>Spring Boot</code> application, which will read configuration like DB properties from <code>Consul</code>. But I am not able to read the key value from Consul using my application. Following is, what I am trying to do.</p>&#xA;&#xA;<pre><code>**pom.xml**&#xA;&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0""&#xA;         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.tuturself&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-consul&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;spring.retry.version&gt;1.2.1.RELEASE&lt;/spring.retry.version&gt;&#xA;        &lt;consul.version&gt;1.1.2.RELEASE&lt;/consul.version&gt;&#xA;        &lt;consul.discovery.version&gt;1.1.2.RELEASE&lt;/consul.discovery.version&gt;&#xA;        &lt;jackson.version&gt;2.8.1&lt;/jackson.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-consul-all&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-consul-discovery&lt;/artifactId&gt;&#xA;            &lt;version&gt;${consul.discovery.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring.retry.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;3.5.1&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;1.8&lt;/source&gt;&#xA;                    &lt;target&gt;1.8&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;repackage&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-consul-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.2.1.RELEASE&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>And Following is my Main class:</strong></p>&#xA;&#xA;<pre><code>@EnableRetry&#xA;@RefreshScope&#xA;@EnableDiscoveryClient&#xA;@SpringBootApplication&#xA;@ComponentScan(""com.test.*"")&#xA;public class SpringBootConsulApplication {&#xA;&#xA;    private static ConsulConfiguration consulConfiguration;&#xA;&#xA;    public static void main(String[] args) {&#xA;        try {&#xA;            String consulHost = System.getProperty(""spring.cloud.consul.host"");&#xA;            System.out.println(""consulHost ::"" + consulHost);&#xA;            String consulPort = System.getProperty(""spring.cloud.consul.port"");&#xA;            System.out.println(""consulPort ::"" + consulPort);&#xA;            String consulPrefix = System.getProperty(""spring.cloud.consul.config.prefix"");&#xA;            System.out.println(""consulPrefix ::"" + consulPrefix);&#xA;            new SpringApplicationBuilder(SpringBootConsulApplication.class).web(true).run(args);&#xA;        } catch (Exception ex) {&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I am reading the consul properties using the <code>@Value</code> annotation:</p>&#xA;&#xA;<pre><code>@Configuration&#xA;@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)&#xA;public class ConsulConfiguration {&#xA;&#xA;    @Value(""${cassandra.host}"")&#xA;    private String cassandraHost;&#xA;&#xA;    @Value(""${cassandra.user}"")&#xA;    private String userName;&#xA;&#xA;    @Value(""${cassandra.password}"")&#xA;    private String password;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>bootstrap.yml</code> in resources folder:</p>&#xA;&#xA;<pre><code>spring:&#xA;  cloud:&#xA;    consul:&#xA;      host: localhost&#xA;      port: 8500&#xA;      enabled: true&#xA;      config:&#xA;        enabled: true&#xA;        prefix: config/application&#xA;        defaultContext: apps&#xA;        profileSeparator: '::'&#xA;  application:&#xA;    name: spring-boot-consul&#xA;</code></pre>&#xA;&#xA;<p>Consul is up and running in my local system on <code>localhost:8500</code> where I have the file <code>config/application/spring-boot-consul.yml</code> file;</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: spring-boot-consul&#xA;cassandra:&#xA;  host: 127.0.0.1:9042,127.0.0.2:9042&#xA;  user: my_user&#xA;  password: my_pass&#xA;  pooling:&#xA;    maxThread: 10&#xA;    timeout: 50&#xA;  keyspace:&#xA;    name: test_keyspace&#xA;    readConsistency: ONE&#xA;    writeConsistency: ONE&#xA;</code></pre>&#xA;&#xA;<p>When I am strating the application, it is showing not able to bind <code>cassandra.host</code> in my <code>ConsulConfiguration</code>  class. Thus stopping the application. Any hints , What I am doing wrong here?</p>&#xA;"
45412334,API gateway and microservice authentication,2017-07-31 09:40:46,<microservices><api-gateway>,1,470,0,3.0,2,"<p>How API Gateway and Micro services works.</p>&#xA;&#xA;<p>Could anyone explain the basic flow of Micro service architecture with Gateway. I couldn't find the proper answer.</p>&#xA;&#xA;<p>Say we have auth server and customer micro service running on separate instances and in front of all the services we have an API gateway.</p>&#xA;&#xA;<p>My question is.</p>&#xA;&#xA;<p>when user try to log in using username and password, the API gateway call <strong>auth server</strong> and return the <strong>access token</strong> to user.</p>&#xA;&#xA;<p>Then user trying to access the specific url (/customers - customer micro service) that is running on separate instance.&#xA;what API Gateway do ?</p>&#xA;&#xA;<ol>&#xA;<li>validate the token with auth server and get the user id and pass the request to <strong>customer service with the user id</strong> ?</li>&#xA;</ol>&#xA;&#xA;<p>OR </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>validate the token and pass the request to customer microservice <strong>with the access token</strong> ? and customer microservice responsible is to the check the user id (Make an HTTP call to auth server) ? </li>&#xA;</ol>&#xA;"
45400096,Migrating multi-module project to microservices?,2017-07-30 13:00:55,<java><microservices>,5,473,1,0.0,2,"<p>I have multi module application. To be more explicit these are maven modules where high level modules depends on low level modules. &#xA;Below are the some of the modules :-</p>&#xA;&#xA;<pre><code>    user-management&#xA;    common-services&#xA;    utils&#xA;    emails&#xA;</code></pre>&#xA;&#xA;<p>For example :- If <code>user management</code> module wants to use any services from <code>utils</code> module, it can call its services as dependency of utils is already injected under user-management.&#xA;To convert/call my project truly following microserives architecture, I believe i need to convert each module as  independently deployable services where each module is a war module&#xA;and provides its services over http(mainly as resful web services) . Is that correct or anything else need to be taken care of as well ? </p>&#xA;&#xA;<p>Probably each modules now has to be secured and authentication layer as well ?</p>&#xA;&#xA;<p>If that's the crux of microservices I really do not understand when someone ask whether you have worked on microservices as to me Its not tool/platform/framework but a simple &#xA;concept to divide you monolithic application in to smaller set of deployable modules whose services is available through HTTP. Is n't it ? May be its another buzz word.</p>&#xA;&#xA;<p><strong>Update:-</strong>&#xA;Obviously there are adavantages going micro services way like independent unit testablemodule, scalable as it can be deployed on separate machine, loose coupling etc but I see I need to handle two complex concerns also </p>&#xA;&#xA;<ol>&#xA;<li>Authentication:- For each module I need to ensure it authenticates the request which is not the case right now</li>&#xA;<li>Transaction:- I can not maintain the transaction atomicity across different services which I could do very easily at present</li>&#xA;</ol>&#xA;"
45547556,Blue Green deployment with multiple Micro Services with internal calls,2017-08-07 13:00:57,<java><amazon-web-services><spring-boot><microservices><blue-green-deployment>,4,693,4,0.0,2,"<p>I have a 8 spring boot micro services which internally call each other. The calling dns's of other micro services, define in the application.properties file of each service.</p>&#xA;&#xA;<p>Suppose,  micro service A represent by A -> a.mydns.com and B-> b.mydns.com etc</p>&#xA;&#xA;<p>So basically each micro service consist of a ELB and two HA Proxies (distribute &#xA; in two zones) and 4 App servers (distribute in two zones).</p>&#xA;&#xA;<p>Currently I am creating the new Green servers (app servers only) and switch the live traffic from HA Proxy level. In this case, while the new version of the micro services are testing, it expose to the live customers also.</p>&#xA;&#xA;<p>Ideally, the approach should be, <strong>creating the entire server structure including ELB's and HA Proxies for each micro service right?</strong></p>&#xA;&#xA;<p>But then how come I face the challenge of testing it with a test dns. I can map the ELB to a test dns. <strong>But then how about the external micro service dns's which hard coded in side the application.properties file?</strong></p>&#xA;&#xA;<p>What would be the approach I should take in such scenario?</p>&#xA;"
45544777,"NodeJS Microservices, combining data",2017-08-07 10:29:38,<javascript><node.js><redis><microservices>,1,147,13,1.0,2,"<p>I'm building a NodeJS platform that consist of several core 'parts' (users, messages and trading signals).</p>&#xA;&#xA;<p>So my idea is to create microservices for each of them, and it works pretty well.. But I can't get my head around how to 'join' data between the microservices (I'm a frontender originally.....)</p>&#xA;&#xA;<p>For example, I have 3 microservices.. Each with its own MongoDB, on its own machine complete isolated.. Imagine the common situation where the messages is retrieved from a single microservice, the message has a 'user_id' and I need to get the username and profilePicture to be combined in the retrieved message object..?</p>&#xA;&#xA;<p>I read a lot about using Redis, but it seems like a 'messaging' service to me, not much of a 'combine' service.. Can anyone help me through the darkness??</p>&#xA;&#xA;<p>Thanks!!</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jQphv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jQphv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I know its a very general question... But I just can't get a grip of what the 'best practice' is when combining data of multiple micro services..</p>&#xA;"
45146319,Spring - Make microservice only accessible internally,2017-07-17 14:00:20,<spring><spring-security><microservices>,2,221,3,0.0,2,"<p>How can I setup a microservice which can only be called by other internal services. The microservice should not be accessible in public, because it has access to databases with secret information. I already tried to secure the microservice with spring security but in this case I got problems with the FeignClient concerning authorization.</p>&#xA;"
40691082,Splitting and naming Microservices,2016-11-19 09:07:16,<soa><microservices>,1,1036,0,1.0,2,"<p>I recently started a side-project. It was supposed to be a virtual recipe-book with the capabilities to store and retrieve recipes (CRUD), rate them and search through them. This is nothing new, but i wanted to build it as a desktop application to learn more about databases, unit testing, UIs and so on. Now that the core domain is pretty much done (i use a DDD approach) and i implemented most of the CRUD Repositories, i want to make this a bit more extensible by hosting the core functionality online, so i am able to write multiple backends (desktop application, web application, web api, etc).</p>&#xA;&#xA;<p>Service Oriented Architecture (or Microservices) sound like a good approach to me to do that. The problem i am facing is how to decide, which parts of my project belong into a separate service and how to name them.</p>&#xA;&#xA;<p>Take the following parts of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Core domain (Aggregates, Entities, Value Objects, Logic) -> <em>Java</em></li>&#xA;<li>Persistence (DAOs, Repositories, multiple Database backend implementations) -> <em>Java</em></li>&#xA;<li>Search (Search Services which use SQL queries on the persistence DB for searching) -> <em>Java</em></li>&#xA;<li>Desktop Application -> <em>JS (Electron) or JavaFX</em></li>&#xA;<li>Web Application -> <em>Flask or Rails</em></li>&#xA;<li>Web API (Manage, Rate, Search for recipes using REST) -> <em>?</em></li>&#xA;</ul>&#xA;&#xA;<p>My initial approach would be to put the core domain, the persistence, the search and the web api into a single sub-project and host that whole stack on Heroku or something similar. That way my clients could consume the web interface. The Desktop and Web apps would be different projects on their own. The Dektop app could share the core domain if they are both written in Java.</p>&#xA;&#xA;<p>Is this a valid approach, or should i split the first service into smaller parts? How do you name these services?</p>&#xA;"
40734086,Implementing API Gateway for ASP.NET API Microservices,2016-11-22 05:01:43,<.net><asp.net-web-api><asp.net-core><microservices><api-gateway>,2,3920,0,0.0,2,"<p>I have developed my micro services using ASP.NET Core WEB API. I am still planning and investigating at this step to add an API Gateway that can acts just as proxy and routes client requests to the designated service (just to isolate and prevent clients from calling the services directly). The gateway will also perform logging and security checks.</p>&#xA;&#xA;<p>I don't need any Discovery Mechanisms for the time being (but if there is a platform I could leverage that would be great).</p>&#xA;&#xA;<p>For constraint purposes let's say that my micro services are hosted on static IPs.</p>&#xA;&#xA;<p>As far as creating my own AP-Gateway, what things do I need to do?&#xA;How would such gateway be implemented?&#xA;How should I host it?  How many?&#xA;I need some patterns that I can translate into an generic implementation.</p>&#xA;&#xA;<p>I was thinking about a simply structured DB that maps every api requested to a micro service API at the other end, then using HttpWebRequest to construct the request and return back the response. Then I can create a message handler that can log all the requests.</p>&#xA;"
40586946,gofabric8> Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip,2016-11-14 10:49:35,<maven><openshift><kubernetes><microservices><fabric8>,4,180,0,0.0,2,<p>I'm trying to set up environment for microservices. I'm using fabric8 to do that.</p>&#xA;&#xA;<p>I'm using <code>mvn fabric8:cluster-start -Dfabric8.cluster.kind=openshift</code> command. while executing i'm getting following error...</p>&#xA;&#xA;<pre><code>  [INFO] gofabric8&gt; Downloading https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-mac.zip...&#xA;    [INFO] gofabric8&gt; **Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip fileUnable to download client zip: not a valid zip file**&#xA;    [INFO] gofabric8&gt; using the executable /Users/apple/.fabric8/bin/minishift&#xA;    [INFO] gofabric8&gt; running: /Users/apple/.fabric8/bin/minishift start --vm-driver=xhyve --memory=4096 --cpus=1&#xA;    [INFO] gofabric8&gt; Starting local OpenShift cluster...&#xA;    [INFO] gofabric8&gt; Downloading ISO&#xA;    [INFO] gofabric8&gt; &#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] BUILD FAILURE&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] Total time: 18:50 min&#xA;    [INFO] Finished at: 2016-11-14T16:05:32+05:30&#xA;    [INFO] Final Memory: 21M/224M&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [ERROR] Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = ''' -&gt; [Help 1]&#xA;    org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = '''&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;</code></pre>&#xA;&#xA;<p>Any Idea?</p>&#xA;
40645778,Microservices waiting on responses from other services,2016-11-17 02:33:58,<soa><restful-architecture><microservices>,3,76,1,0.0,2,"<p>I recently encountered a question where a person asked me what would you do in the following scenario:</p>&#xA;&#xA;<p>You have service A, service B, and service C interacting with one another. Service A can only perform its full functionality if it receives response from B and C. However, C has a lot of requests queued and will take a long time to respond. How would service A handle this scenario? Will service A wait and wait until C will respond even after getting the response from B? How will you make this architecture faster?</p>&#xA;"
40574379,SNS + CloudFormation,2016-11-13 13:31:34,<microservices><amazon-sns><amazon-cloudformation>,3,327,3,1.0,2,"<p>I'm using <em>AWS CloudFormation</em> to build a stack for a microservice. My <em>AWS CloudFormation</em> template creates resources like: a Lambda function, an SNS topic and API Gateway.</p>&#xA;&#xA;<p>This microservice does some work and publishes messages to the SNS topic. Other microservices subscribe to this topic.</p>&#xA;&#xA;<p>The problem I'm facing is that when I upgrade my microservice's <em>CloudFormation</em> template (sometimes I need to redeploy it, and recreate all resources), the SNS topic changes its <code>ARN</code>. Hence, all microservices that use this topic need to change as well.</p>&#xA;&#xA;<p>I think I could create a separate <em>CloudFormation</em> template for the SNS topic (I have more than one per microservice).</p>&#xA;&#xA;<ul>&#xA;<li>Will this be a good approach? </li>&#xA;<li>If not, what's the recommended way?</li>&#xA;</ul>&#xA;"
46581254,Microservices and service granularity,2017-10-05 08:37:47,<domain-driven-design><microservices>,3,110,4,1.0,2,"<p>I have never worked with microservices architecture before and there is something important that it is still not clear in what I am reading.</p>&#xA;&#xA;<p>In a microservice architecture a service is a single endpoint or a single module with several endpoints?</p>&#xA;&#xA;<p>Are the endpoints that are fine grained or the granularity is at a higher level? I thought at the beginning that the endpoints were fine grained and this is why there was the risk of making the API too chatty. </p>&#xA;&#xA;<p>I am now finding articles that say that in microservices architecture a service is associated to ""bounded context"". It seems to me that a bounded context needs more than a single endpoint in an API.</p>&#xA;"
46585082,Async communication between spring boot micro services,2017-10-05 12:00:04,<asynchronous><spring-boot><microservices><spring-rabbitmq>,1,662,4,1.0,2,"<p>I am new to spring boot and created 2 micro services.&#xA;They need to communicate with one other in synchronous and asynchronous way.&#xA;For synchronous communication, I can use the RestTemplate.&#xA;But how to do for asynchronous calling ?&#xA;my requirement for Asynchonous is:&#xA;lets say I am querying for something from one micro service. To fetch the queried data it will take sometime because of queried for large sum of data. &#xA;In this case, I need to save the request into some transaction table and return the response with transactionId and callBackAPI. After sometime if I call the callBackAPI with transactionId. Then I should be able to get the previously queried data.</p>&#xA;&#xA;<p>Please help me with this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
50835738,Monolith to Microservices (What tasks are involved?),2018-06-13 11:09:31,<architecture><microservices>,3,100,1,1.0,2,"<p>I am curious of what tasks are involved in the transistion of a monolith site into microservices. What do you have to do to make it work, i.e. redirecting. To put this into practise what tasks are involved in the transistion of the following website? </p>&#xA;&#xA;<p><a href=""http://www.wehkamp.nl/"" rel=""nofollow noreferrer"">http://www.wehkamp.nl/</a></p>&#xA;&#xA;<p>In short, I understand what the transistion does but not what has to be done to make the transistion.</p>&#xA;"
24787801,Spring Boot Environment-specific configurations,2014-07-16 18:10:58,<spring-mvc><jpa><spring-boot><environment><microservices>,2,8119,0,2.0,3,"<p>I have a spring boot application that uses the <strong>actuator, auto-configuration and JPA</strong>. I want to be able to use an in-memory DB in my <strong>test</strong> profile, a MySQL DB configuration during <strong>development</strong> and a separate <strong>production</strong> DB configuration when the app is deployed in production. Presumably from the java command line I should be able to specify the environment and the right configuration file or config block in <strong>application.properties</strong> (or .yml) will be picked up.</p>&#xA;&#xA;<p>I have not found a good post with example describing how to do this switching so I thought I'd ask if anyone has a good example. My main aim is to pre-define the <code>spring.datasource</code> and <code>spring.jpa</code> properties at build time and then at run-time switch the app config per environment ""dynamically"" using the java command line argument. Secondary goal would be to do the same with the <code>management</code> configurations, etc.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
34158847,Inter-microservices Communication using REST & PUB/SUB,2015-12-08 14:49:01,<rest><server><publish-subscribe><microservices>,3,925,0,1.0,3,"<p>This is still a theory in my mind.</p>&#xA;&#xA;<p>I'm rebuilding my backend by splitting things into microservices. The microservices I'm imagining for starting off are:<br/>&#xA;- Order (stores order details and status of each order)<br/>&#xA;- Customer (stores customer details, addresses, orders booked)<br/>&#xA;- Service Provider (stores service provider details, status &amp; location of each service provider, order(s) currently being processed by the service provider, etc.)<br/>&#xA;- Payment (stores payment info for each order)<br/>&#xA;- Channel (communicates with customers via email / SMS / mobile push)<br/></p>&#xA;&#xA;<p>I hope to be able to use PUB/SUB to create a message with corresponding data, which can be used by any other microservice subscribing to that message.</p>&#xA;&#xA;<p>First off, I understand the concept that each microservice should have complete code &amp; data isolation (thus, on different instances / VMs); and that all microservices should communicate strictly using HTTP REST API contracts.</p>&#xA;&#xA;<p>My doubts are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>To show a list of orders, I'll be using the Order DB to get all orders. In each Order document (I'll be using MongoDB for storage), I'll be having a customer_id Foreign Key. Now the issue of resolving customer_name by using customer_id.<br/>&#xA;If I need to show 100 orders on the page and go with the assumption that each order has a unique customer_id associated with it, then will I need to do a REST API call 100 times so as to get the names of all the 100 customer_ids?&#xA;Or, is data replication a good solution for this problem?</p></li>&#xA;<li><p>I am envisioning something like this w.r.t. PUB/SUB: The business center personnel mark an order as assigned &amp; select the service provider to allot to that order. This creates a message on the cross-server PUB/SUB channel.<br/>&#xA;Then, the Channel microservice (which is on a totally different instance / VM) captures this message &amp; sends a Push message &amp; SMS to the service provider's device using the data within the message's contents.<br/>&#xA;Is this possible at all?<br/>&#xA;<strong>UPDATE TO QUESTION 2:</strong> I want the Order microservice to be completely independent of any other microservices that will be built upon / side-by-side it. Channel microservice is an example of a microservice that depends upon events taking place within Order microservice.</p></li>&#xA;</ol>&#xA;&#xA;<p>Also, please guide me as to what all technologies / libraries to use.</p>&#xA;&#xA;<p>What I'll be developing on:<br/>&#xA;Java<br/>&#xA;MongoDB<br/>&#xA;Amazon AWS instances for each microservice.<br/></p>&#xA;&#xA;<p>Would appreciate anyone's help on this.<br/>&#xA;Thanks!</p>&#xA;"
33556707,Dynamic Scalable and adaptive architecture,2015-11-05 23:21:28,<docker><zeromq><microservices><consul>,2,434,0,1.0,3,"<p>I am a PhD student in Cloud Computing, I plan to use the microservices based architecture with consul and zeromq for my research project. I had few questions that I am finding hard to understand. Can someone help me out in sharing their experience.</p>&#xA;&#xA;<ol>&#xA;<li>We have microservices based on dockers, We have zeromq and we have consul. Can you mention how we could combine all the three together to have a dynamic adaptive environment? </li>&#xA;</ol>&#xA;&#xA;<p>Though I understand as to what zeromq, docker and consul is individually, I am still unable to get a clear picture of how all of them function as a whole.We have docker containers having microservices running inside them on a host. We use zeromq for transport (Pub-sub/pipeline) of messages between docker containers. The containers may be running on the same host/datacenter or on different hosts/datacenters. We then use consul for service discovery.Is my understanding correct here? </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>How does the architecture dynamically scale up/down according to workload? </li>&#xA;</ol>&#xA;&#xA;<p>Say, I have a situation where I need more worker nodes for a particular computation for sometime. Who spins up more number of worker nodes. Which component determines/takes this decision? </p>&#xA;&#xA;<p>Is there a scheduling component? If so, can someone briefly explain how it happens or which component performs that function?</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>So, what is the major role of consul? Is it used just for service discovery?Can it be used for configurations as well. If so, whats its limitation? </li>&#xA;</ol>&#xA;&#xA;<p>I see that even zeromq has service discovery mechanisms, so why do we require consul? </p>&#xA;&#xA;<ol start=""4"">&#xA;<li>How does a failure of a node information gets propagated in the architecture? Which component is responsible? Is it just consul ? Or zeroMq also?</li>&#xA;</ol>&#xA;&#xA;<p>Please advice.</p>&#xA;"
33478131,Centralised configuration of docker-compose services,2015-11-02 12:57:09,<database><docker><config><docker-compose><microservices>,1,87,6,2.0,3,"<p>Imagine a non-trivial <a href=""https://www.docker.com/docker-compose"" rel=""nofollow"">docker compose</a> app, with nginx in front of a webapp, and a few linked data stores:</p>&#xA;&#xA;<pre class=""lang-css prettyprint-override""><code>web:&#xA;  build: my-django-app&#xA;  volumes:&#xA;    - .:/code&#xA;  ports:&#xA;    - ""8000:8000""&#xA;  links:&#xA;    - redis&#xA;    - mysql&#xA;    - mongodb&#xA;nginx:&#xA;  image: nginx&#xA;  links:&#xA;    - web&#xA;redis:&#xA;  image: redis&#xA;  expose:&#xA;    - ""6379""&#xA;mysql:&#xA;  image: mysql&#xA;  volumes:&#xA;    - /var/lib/mysql&#xA;  environment:&#xA;    - MYSQL_ALLOW_EMPTY_PASSWORD=yes&#xA;    - MYSQL_DATABASE=myproject&#xA;mongodb:&#xA;  image: mongo&#xA;</code></pre>&#xA;&#xA;<p>The databases are pretty easy to configure (for now), the containers expose pretty nice environmental variables to control them (see the <code>mysql</code> container), but what of <code>nginx</code>? We'll need to template a vhost file for that, right?</p>&#xA;&#xA;<p>I don't want to roll my own image, that'll need rebuilding for each changed config, from different <strong>devs</strong>' setups, to <strong>test</strong>, through <strong>staging</strong> and <strong>production</strong>. And what if we want to, in a lightweight manner, do <strong>A/B testing</strong> by flipping a config option? </p>&#xA;&#xA;<p>Some <strong>centralised config management</strong> is needed here, maybe something controlled by docker-compose that can write out config files to a shared volume?</p>&#xA;&#xA;<p>This will only get more important as new services are added (imagine a microservice cloud, rather than, as in this example, a monolithic web app)</p>&#xA;&#xA;<p><strong>What is the correct way to manage configuration in a docker-compose project?</strong></p>&#xA;"
34020234,Communication between Node.js microservices,2015-12-01 12:15:03,<json><node.js><express><architecture><microservices>,1,1519,2,0.0,3,"<p>I'm creating an application with Node.js using microservices architecture. I'm trying to find the best way of communication between nodes. I have a Java background so the best option I can imagine is something like SOAP, where you create a proxy object and by calling it's method a request to a remote node would be made via http.</p>&#xA;&#xA;<p>Currently I only see an option of direct calls like </p>&#xA;&#xA;<pre><code>http.get(""remote-node/api/method1"", function(res) {&#xA;}).on('error', function(e) {&#xA;  console.log(""Got error: "" + e.message);&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However I don't think it's convenient. Are there better approaches?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
32604241,Best Protocol for a App to Use a Service on the Same Server?,2015-09-16 09:10:24,<php><api><http><service><microservices>,1,53,0,0.0,3,"<p>I have a PHP app that needs to talk to a service which has a API that produces XML responses to HTTP requests. If this service was on a separate server I would normally use a HTTP client like Guzzle to create and consume, requests and responses.</p>&#xA;&#xA;<p>But my service will be (for the time being) on the same server. In this scenario is making HTTP requests in this fashion still my best option? Will all my requests to the API leave the server which will add latency which could be avoided?</p>&#xA;"
32534401,SOA - Microservices : Use API REST or SOAP,2015-09-12 01:59:21,<architecture><soa><microservices>,3,4423,0,3.0,3,"<p>I'm face to a big dilemm : in my company, we are working on microservices architecture and switching to a full SOA eco system.</p>&#xA;&#xA;<p>Some consultants and developpers say it would be better to SOAP for web services, because it would allow to specify and give a validated format to all developer teams. I'm scared using SOAP we would be restricted at the end.</p>&#xA;&#xA;<p>Based on your experience, for a SOA / Microservices architecture, would it be better to use SOAP or REST API ?</p>&#xA;&#xA;<p>Thanks in advance for your helpful feedback.</p>&#xA;"
32574103,Microservices - how to solve security and user authentication?,2015-09-14 21:18:13,<authentication><java-ee><microservices>,2,1504,1,2.0,3,"<p>There is a lot of discussion about microservice architecture. What I am missing - or maybe what I did not yet understand is, how to solve the issue of security and user authentication?</p>&#xA;&#xA;<p>For example: I develop a microservice which provides a Rest Service interface to a workflow engine. The engine is based on JEE and runs on application servers like GlassFish or Wildfly. &#xA;One of the core concepts of the workflow engine is, that each call is user centric. This means depending of the role and access level of the current user, the workflow engine produces individual results (e.g. a user-centric tasklist or processing an open task which depends on the users role in the process).</p>&#xA;&#xA;<p>In my eyes, thus a service is not accessible from everywhere. For example if someone plans to implement a modern Ajax based JavaScript application which should use the workflow microservice there are two problems:</p>&#xA;&#xA;<p>1) to avoid the cross-scripting problem from JavaScript/Ajax the JavaScript Web application needs to be deployed under the same domain as the microservice runs</p>&#xA;&#xA;<p>2) if the microservice forces a user authentication (which is the case in my scenario) the application need to provide a transparent authentication mechanism. </p>&#xA;&#xA;<p>The situation becomes more complex if the client need to access more than one user-centric microservices forcing user authentication.&#xA;I always end up with an architecture where all services and the client application running on the same application server under the same domain.</p>&#xA;&#xA;<p>How can these problems be solved? What is the best practice for such an architecture?</p>&#xA;"
36844842,Patterns for knowing if a pub-sub message was successful,2016-04-25 15:26:16,<design-patterns><publish-subscribe><amazon-sqs><amazon-sns><microservices>,1,354,4,0.0,3,"<p>I'm developing microservices for a project and we're experimenting with pub-sub communication using AWS SNS+SQS. We're unsure how to signal to services whether or not other services have successfully completed tasks or not.<br>&#xA;For example, if service A emits an SNS Event and service D, E, and F all are listening to the subscribed SQS Queue, how does service A know if the activities kicked off by service A inside of service D, E, and F were successful?  </p>&#xA;&#xA;<p>I'll give a more concrete example:&#xA;A new user registers for a website.  This network call first reaches the <code>user service</code> in the backend.  If the user was successful, it sends off an event saying a new user was created.  That triggers the <code>email service</code> to send an email to for the user to confirm his registration. What happens if it fails to send an email? &#xA;Has the <code>user service</code>:</p>&#xA;&#xA;<p>1) Already responded to the frontend saying it was successful</p>&#xA;&#xA;<p>2) Or is it waiting for a confirmation?  What is a good pub-sub pattern for confirmations?  </p>&#xA;&#xA;<p>I know we could have just done a synchronous call, but this example is simplified for brevity's sake.  </p>&#xA;"
39126827,"Laravel passport, Oauth and microservices",2016-08-24 14:58:30,<laravel><oauth><oauth-2.0><microservices>,2,1351,0,0.0,3,"<p>I am having a difficulty in terms of architecture and wondering if someone has some insights.</p>&#xA;&#xA;<p><strong>The plan</strong></p>&#xA;&#xA;<ul>&#xA;<li>I will have multiple microservices (different laravel projects, catalog.microservice.com, billing.microservice.com) each providing an API. </li>&#xA;<li>On top of these will be an angular fronted consuming those APIs. </li>&#xA;<li>I will have another micro service (passport.microservice.com) for auth now thanks to laravel 5.3 passport this is even easier.  </li>&#xA;</ul>&#xA;&#xA;<p><strong>The flow:</strong></p>&#xA;&#xA;<ul>&#xA;<li>User goes to catalog.microservice.com </li>&#xA;<li>user need to authenticate and provides a user and password</li>&#xA;<li>request is made by angular (aka client) to passport.microservice.com through password grand type to get an authorization token</li>&#xA;<li>now that I have a token I am authorized to call a resource from catalog.microservice.com</li>&#xA;<li>catalog.microservice.com needs to know if the token is valid and makes a request (some kind of middleware?) to passport.microservice.com</li>&#xA;<li>passport.microservice.com returns the user, scope etc.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is this a good approach?</li>&#xA;<li>The token validation in catalog.microservice.com can be a middleware? </li>&#xA;</ul>&#xA;"
39044130,Java EE Microprofile,2016-08-19 16:47:42,<java><microservices>,2,1358,0,0.0,3,<p>I know it could be a pretty vague topic but please can someone explain it in plain English. I've read some articles regarding the trending topic java EE's 'microprofile' but was not able to clearly understand its purpose.</p>&#xA;&#xA;<p>My understanding in this emerging concept is that java community finds way to reshape the Java EE model to become a microservices friendly framework or platform. </p>&#xA;&#xA;<p>If we can already create a distributed microservice application in few minutes using spring boot or other API / library then why do we need microprofile?</p>&#xA;
39088230,How to ensure thrift objects are backward compatible?,2016-08-22 20:31:30,<java><thrift><microservices>,1,643,0,0.0,3,"<p>We're currently using <strong>thrift</strong> for developing our micro-services.&#xA;When I recently came across this below issue.</p>&#xA;&#xA;<p>Assume below is the thrift contract for Summary Object and there is an API which gets and updates summary using the summary object passed.</p>&#xA;&#xA;<p><strong>Version - 1.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<p>Now let's say there are 5 services which are using this <strong>1.0</strong> contract of Summary.<br/>&#xA;In the next release we add another Object called a <strong>list of summaryvalues</strong>.</p>&#xA;&#xA;<p>So the new contract would look like</p>&#xA;&#xA;<p><strong>Version - 2.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost,&#xA;    3: optional list&lt;i32&gt; summaryValues&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>So when this below list is populated, we save the list of values <code>summaryValues</code> aganist that <code>summaryId</code>.</li>&#xA;<li>And when the client sends this list as <code>null</code> we remove the existing values saved for that 'summaryId`.</li>&#xA;</ol>&#xA;&#xA;<p>Now the <strong>problem</strong> occurs when other services which are using <strong>OLDER</strong> version of the thrift contract (<strong>Version 1.0</strong>) try to call getSummary and updateSummary.<br/>&#xA;The intention of the Older Client by calling updateSummary was to set another value for <code>summaryCost</code>. However since this client doesn't contain the object <code>summaryValues</code> it sends the Summary object with <code>summaryValues</code> as null to Server.<br/></p>&#xA;&#xA;<p><strong>This is resulting in the Server removing all existing values of <code>summaryValues</code> for that <code>summaryId</code>.</strong></p>&#xA;&#xA;<p>Is there a way to handle this in thrift? The isSet() Methods don't work here, as they try to perform a simple null check.<br/>&#xA;Every time we release a newer client with modification to existing objects, we're having to forcefully upgrade client versions of other servers even though the change is not related to them.</p>&#xA;"
38975554,Multiple FabricTransportServiceRemotingListeners in a Single Service,2016-08-16 12:54:40,<microservices><azure-service-fabric>,1,434,0,0.0,3,"<p>I'd like to be able to expose multiple FabricTransportServiceRemotingListeners from a single Stateless service inside my cluster. I've attempted to register the listeners as follows:</p>&#xA;&#xA;<pre><code>    protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;    {&#xA;        return new[]&#xA;        {&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryCommandService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryCommandEndpoint""&#xA;                    }), ""SqlCategoryCommandService""),&#xA;&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryQueryService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryQueryEndpoint""&#xA;                    }), ""SqlCategoryQueryService"")&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>However when I make a proxy to the <code>ICategoryQueryService</code> which is implemented by the second listener this exception regarding an unimplemented Interface method is thrown leading me to believe that the first listener is incorrectly responding to all Proxy calls.</p>&#xA;&#xA;<pre><code>""Interface id '740213831' is not implemented by object 'TaxonomyService.SqlCategoryCommandService'""&#xA;</code></pre>&#xA;&#xA;<p>I'm creating the Proxy using the following code:</p>&#xA;&#xA;<pre><code>var proxy = ServiceProxy.&#xA;     Create&lt;ICategoryQueryService&gt;(new Uri(""fabric:/Taxonomy/TaxonomyService""));&#xA;</code></pre>&#xA;&#xA;<p>Is the scenario I've described possible?</p>&#xA;"
39020065,Marathon: How to specify environment variables in args,2016-08-18 13:54:03,<microservices><mesos><marathon><consul>,1,2340,1,0.0,3,"<p>I am trying to run a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<p>With Marathon I have the following JSON script:</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"": ""consul-agent"",&#xA;    ""instances"": 10,&#xA;    ""constraints"": [[""hostname"", ""UNIQUE""]],&#xA;    ""container"": {&#xA;        ""type"": ""DOCKER"",&#xA;        ""docker"": {&#xA;            ""image"": ""consul"",&#xA;            ""privileged"": true,&#xA;            ""network"": ""HOST""&#xA;        }&#xA;    },&#xA;    ""args"": [""agent"",""-bind"",""$MESOS_SLAVE_IP"",""-retry-join"",""$MESOS_MASTER_IP""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, it seems that marathon treats the <code>args</code> as plain text.</p>&#xA;&#xA;<p>That's why I always got errors:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Error starting agent: Failed to start Consul client: Failed to start lan serf: Failed to create memberlist: Failed to parse advertise address!&#xA;</code></pre>&#xA;&#xA;<p>So I just wonder if there are any workaround so that I can start a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>Thanks @janisz for the link.</p>&#xA;&#xA;<p>After taking a look at the following discussions:</p>&#xA;&#xA;<ul>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/3416"" rel=""nofollow"">#3416</a>: <em>args in marathon file does not resolve env variables</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/2679"" rel=""nofollow"">#2679</a>: <em>Ability to specify the value of the hostname an app task is running on</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1328"" rel=""nofollow"">#1328</a>: <em>Specify environment variables in the config to be used on each host through REST API</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1828"" rel=""nofollow"">#1828</a>: <em>Support for more variables and variable expansion in app definition</em></p></li>&#xA;</ul>&#xA;&#xA;<p>as well as the Marathon documentation on <a href=""https://mesosphere.github.io/marathon/docs/task-environment-vars.html"" rel=""nofollow"">Task Environment Variables</a>.</p>&#xA;&#xA;<p>My understanding is that:</p>&#xA;&#xA;<ul>&#xA;<li>Currently it is not possible to pass environment variables in args</li>&#xA;<li>Some post indicates that one could pass environment variables in <code>""cmd""</code>. But those environment variables are Task Environment Variables provided by Marathon, not the environment variables on your host machine.</li>&#xA;</ul>&#xA;&#xA;<p>Please correct if I was wrong.</p>&#xA;"
35913253,Microservice based or Monolithic,2016-03-10 10:03:10,<cordova><spring-boot><microservices>,3,584,0,0.0,3,"<p>I read a lot about Microservices and their structure and it seems, that there are a lot of advantages when it comes to maintainability. </p>&#xA;&#xA;<p>I want to build a mobile app with Spring Boot and Phonegap, which pulls news from RESTful Web Services. </p>&#xA;&#xA;<p>So I'm thinking f building it as a microservice so I can add other services without rebuilding the whole application. Because in future I might want to add other services.</p>&#xA;&#xA;<p>But is it really worth to build a Microservice based application for such a small mobile app? </p>&#xA;"
27857790,Best practice for redirecting between docker containers,2015-01-09 09:47:35,<redirect><docker><reverse-proxy><boot2docker><microservices>,1,964,4,0.0,3,"<p>Given I have multiple web applications running in docker containers, I want to be able to let the user be redirected from on service to another service in his browser. I wonder how to achieve this - especially if I want my applications to be portable from one docker host to a different host. </p>&#xA;&#xA;<p>Let's say we have a ServiceA which redirects the user to ServiceB. So we have a relationship </p>&#xA;&#xA;<p><code>ServiceA --&gt; ServiceB</code></p>&#xA;&#xA;<p>One approach would be to statically assign ports and hostnames and set them as environment vars to my web services - which I would not prefer because I don't want to care about which service runs on which port.</p>&#xA;&#xA;<p>A second approach would be to have a proxy like nginx and link the services and use the proxy host and port. But this would require to change the proxy configuration when moving a service to a different host.</p>&#xA;&#xA;<p>The third approach that comes to mind, is to use etcd and ambassadors to register and resolve services. So ServiceA would use a ServiceB-Ambassador which looks up ServiceB in etcd. This results in many docker containers just to connect between services.</p>&#xA;&#xA;<p>Which way would you prefer? Or are there different approaches?</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>The real problem is to inject the uri of ServiceB into ServiceA, so I can launch my ServiceA with an argument like <code>-DserviceB.uri=&lt;serviceUri&gt;</code>, so that serviceA can build the correct redirect header.</p>&#xA;"
32217639,Online Store and Microservices,2015-08-26 03:44:02,<restful-architecture><microservices>,1,443,0,3.0,3,"<p>I am working for a big online store. At the moment our architecture is something weird where we have microservices which actually all share the same DB (doesn't work well at all...).&#xA;I am considering improving that but have some challenges on how to make them independant.</p>&#xA;&#xA;<p>Here is a use case. I have customers, customers purchase products. Let say I have 3 microservices : customer authentication, order management, product management.&#xA;An order is linked to a customer and a product.&#xA;Could you describe a solution for the following problems :</p>&#xA;&#xA;<ol>&#xA;<li>How do you make the link between an order and a customer?</li>&#xA;<li>Let say both services share a customer ID, how do you handle data consistency? If you remove a customer on the customer service side, you end up with inconsistency. If your service has to notify the other services then you end up with tighlty coupled services which to me sounds like what you wanted to avoid in the first place. You could kind of avoid that by having an event mechanism which notify everyone but what about network errors when you don't even know who is supposed to receive the event?</li>&#xA;<li>I want to do a simple query : retrieve the customers from US that bought product A. Given that 3million people bought product A and we have 1 million customers in the US; How could you make that reasonably performant? (Our current DB would execute that in few milliseconds)</li>&#xA;</ol>&#xA;&#xA;<p>I can't think of any part of our code where we don't have this kind of relation. One of the solution I can think of is duplicating data. E.g. When a customer purchase something, the order management service will store the customer details and the product details. You end up with massive data replication, not sure if that's a good thing and I would still be worried about consistency.</p>&#xA;&#xA;<p>I couldn't find a paper addressing those issues. What are the different options?</p>&#xA;"
31510697,Automating microservices load balancing / scaling,2015-07-20 07:16:00,<docker><load-balancing><coreos><microservices><akka-cluster>,1,381,0,1.0,3,"<p>Reading up on micro services for a few days now I was wondering how do people go about automating the load balancing and scaling these things?</p>&#xA;&#xA;<p>I have a specific scenario in mind what I would like to achieve but not sure if it's possible or maybe I'm thinking about it wrong. So here it goes...</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Let's say I have a cluster of 3 CoreOS machines named A,B and C.</p>&#xA;&#xA;<p>First thing I want is transparent deployment for which I can probably use fleet. </p>&#xA;&#xA;<p>Then I would like to detect, when one of the services is under huge load and deploy another instance of it and have that one and the first one deployed, automatically load balanced in a way that would not disrupt other services that are using it (traffic goes through load balancer from now on).</p>&#xA;&#xA;<p>Another way could be that I manually deploy another version of the services which then gets load balanced automatically and traffic router to the load balancer.</p>&#xA;&#xA;<p>Then the last question, how is this all different to something like Akka cluster and how does development of those differ from micro services?</p>&#xA;"
39839881,Is it OK to pass on OAuth Access Token between services?,2016-10-03 20:28:57,<oauth><oauth-2.0><authorization><access-token><microservices>,3,1446,0,0.0,3,"<p>Considering the following scenario in a context of the SSO/OAuth/microservices:</p>&#xA;&#xA;<ol>&#xA;<li>User successfully logs-in to the web application using OAuth's Implicit Flow.</li>&#xA;<li>Web app requests some data from <strong>Service A</strong> and <strong>Service B</strong> passing on user's Access Token to authorize both requests.</li>&#xA;<li><strong>Service A</strong> also calls <strong>Service B</strong> (passing on the same Access Token!) in order to build response to the initial Web App request.</li>&#xA;</ol>&#xA;&#xA;<p>Now, is this OK to pass on the user's Access Token from <strong>Service A</strong> to <strong>Service B</strong>? </p>&#xA;&#xA;<p>Or should <strong>Service A</strong> use ""Client Credentials"" grant to obtain its own Access Token to authorize call to the <strong>Service B</strong>?</p>&#xA;&#xA;<p><strong>UPDATE</strong>:<br>&#xA;Please assume both services are owned by the same organization and both trust the same Authorization Server. Also both services are behind the same API Gateway which validates Access Tokens.</p>&#xA;"
39672919,How to design a sails.js project with microservices architecture?,2016-09-24 05:35:16,<node.js><architecture><sails.js><microservices>,2,1195,0,3.0,3,"<p>I learned about microservices from <a href=""http://microservices.io/"" rel=""nofollow"">here</a></p>&#xA;&#xA;<p>Now, I want to use microservices architecture in my next sails.js project.</p>&#xA;&#xA;<p><strong>One way I could think of is:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Breaking my one sails.js application into multiple small sails.js sub-projects/repositories. </p></li>&#xA;<li><p>Having one controller-model in one sub-project. For example, If we consider simple eCommerce app with entities say User, Products, Orders, etc. then there will be separate sails.js repositories for each of them with respective sails.js model-controller.  Then this single sub-repository will from my one microservice.</p></li>&#xA;<li><p>Each sub-repository then will obviously have its own configs.</p></li>&#xA;<li><p>These microservices will them communicate with each other using some HTTP node module.</p></li>&#xA;<li><p>Then writing my own <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow"">API gateway</a> for routing in node.js, which will be responsible for invoking methods/web-services from these sub-repositories depending on the request from clients.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is this the best way OR is there alternative way to design your project using microservices architecture?</p>&#xA;&#xA;<p>What will be the best way to implement inter-service communication, API gateway with sail.js? If one microservice designed with above mentioned approach get bigger, and if I have to split it up in 2, how sails.js model should be changed?</p>&#xA;"
34722107,Is DAO microservice good approach in microservices architecture?,2016-01-11 12:55:19,<web-services><rest><database-design><architecture><microservices>,5,1813,0,1.0,3,"<p>I'm creating a web-application and decided to use micro-services approach. Would you please tell me what is the best approach or at least common to organize access to the database from all web-services (login, comments and etc. web-services). Is it well to create DAO web-service and use only it to to read/write values in the database of the application. Or each web-service should have its own dao layer.</p>&#xA;"
34526251,What is the difference between Kubernetes and Amazon ECS,2015-12-30 09:05:46,<docker><kubernetes><containers><microservices><amazon-ecs>,2,2207,2,0.0,3,<p>What is the difference between Amazon ECS and Kubernetes implementation architecture?</p>&#xA;&#xA;<p>I need to decide to pick a technology for container management in cloud.&#xA;What is the deciding factor while picking any of these technology?</p>&#xA;&#xA;<p>I am using Docker for container creation and execution.</p>&#xA;
34575783,Azure Service Fabric actor microservice,2016-01-03 11:03:07,<c#><microservices><azure-service-fabric>,2,1744,3,0.0,3,<p>Microsoft is offering a microservice solution for it's cloud platform Azure. There are two frameworks - reliable services and reliable actors. </p>&#xA;&#xA;<p>I was wondering if a reliable actor is an independently microservice? Or form multiple actors together a microservice?</p>&#xA;
39268365,Nested GraphQL servers / microservices,2016-09-01 09:56:38,<microservices><graphql><apollo-server>,1,291,1,1.0,3,<p>I would like to replace all my REST APIs with GraphQL (apollo-server preferred). It's clear to me how to use GraphQL in monolithic apps but it's not clear how to do it for microservices.</p>&#xA;&#xA;<p>The main API server consists of multiple microservices where each microservice exposes its own REST API through which the central API server communicates with it. I would like to replace all these REST APIs with GraphQL thus I would get microservices as nested GraphQL servers communicating with each other through GraphQL instead of REST.</p>&#xA;&#xA;<p>The problem that I'm facing is how to easily build a GraphQL query string for microservices based on the received attributes in the resolver of the main GraphQL server. There is no way to tell GraphQL to return all the fields for microservice. The best way would be to simple forward just a part of a the main query further to a microservice. </p>&#xA;&#xA;<p>Any ideas? Do you think that REST is still more appropriate for microservices then GraphQL?</p>&#xA;
39305118,Event publisher for ASP.NET Web Api,2016-09-03 08:57:40,<c#><asp.net><asp.net-web-api><domain-driven-design><microservices>,2,1891,3,2.0,3,"<p>I have started to work with micro-services and I need to create an event publishing mechanism.</p>&#xA;&#xA;<p>I plan to use Amazon SQS. </p>&#xA;&#xA;<p>The idea is quite simple. I store events in the database in the same transaction as aggregates.&#xA;If user would change his email, event <code>UserChangedEmail</code> will be stored in the database.</p>&#xA;&#xA;<p>I also have event handler, such as <code>UserChangedEmailHandler</code>, which will (in this case) be responsible to publish this event to SQS queue, so other services can know that user changed email.</p>&#xA;&#xA;<p>My question is, what is the practice to achieve this? Should I have some kind of background timed process which will scan events table and publish events to SQS?&#xA;Can this be process within WebApi application (preferable), or should this be a separate a process?</p>&#xA;&#xA;<p>One of the ideas was to use Hangfire, but it does not support cron jobs under a minute.</p>&#xA;&#xA;<p>Any suggestions?</p>&#xA;&#xA;<p><strong>EDIT:</strong> </p>&#xA;&#xA;<p>As suggested in the one of the answers, I've looked in to NServicebus. One of the examples on the <a href=""http://docs.particular.net/samples/step-by-step/"" rel=""nofollow"">NServiceBus page</a> shows core of my concern.</p>&#xA;&#xA;<p>In their example, they create a log that order has been placed. What if log or database entry is successfully commited, but publish breaks and event never gets published?</p>&#xA;&#xA;<p>Here's the code for the event handler:</p>&#xA;&#xA;<pre><code>public class PlaceOrderHandler :&#xA;    IHandleMessages&lt;PlaceOrder&gt;&#xA;{&#xA;    static ILog log = LogManager.GetLogger&lt;PlaceOrderHandler&gt;();&#xA;    IBus bus;&#xA;&#xA;    public PlaceOrderHandler(IBus bus)&#xA;    {&#xA;        this.bus = bus;&#xA;    }&#xA;&#xA;    public void Handle(PlaceOrder message)&#xA;    {&#xA;        log.Info($""Order for Product:{message.Product} placed with id: {message.Id}"");&#xA;        log.Info($""Publishing: OrderPlaced for Order Id: {message.Id}"");&#xA;&#xA;        var orderPlaced = new OrderPlaced&#xA;        {&#xA;            OrderId = message.Id&#xA;        };&#xA;        bus.Publish(orderPlaced); &lt;!-- my concern&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
47837207,Entity-level access restriction in the microservice architecture based on user or group membership,2017-12-15 17:31:03,<security><design><architecture><permissions><microservices>,3,982,1,1.0,3,"<p>In the systems, there may be data that is restricted in nature. &#xA;Sometimes access to specific entities should be easily restricted or granted based on user or group membership. </p>&#xA;&#xA;<p>What is the best way to implement this in the microservice architecture?</p>&#xA;&#xA;<h2>#1</h2>&#xA;&#xA;<p>Should access control, managing permissions etc. be the responsibility of the microserive itself? Developers will have to implement access control, store, and update permissions for every service. Seems like not very robust and error-prone approach.</p>&#xA;&#xA;<h2>#2</h2>&#xA;&#xA;<p>Create dedicated microservice handling permission management? This service will be called by other microserives to check access permissions for each entity and filtering entities before returning results. Centralized permissions storage and management is an advantage but microservice will have to make a call to ""Permission Service"" for each entity to check access rights what may have a negative influence on performance. And developers still have to integrate access checks into their services what leaves space for an error.</p>&#xA;&#xA;<h2>#3</h2>&#xA;&#xA;<p>Make access control responsibility of the API Gateway or Service Mesh. It is possible to think of an implementation that will automatically filter responses of all services. But in the case when the microservice returns list of entities permissions should be checked for each entity. Still a potential performance problem.</p>&#xA;&#xA;<h2>Example</h2>&#xA;&#xA;<p>Consider the following synthetic example. &#xA;Healthcare system dealing with test results, X-Ray images etc. Health information is very sensitive and should not be disclosed.</p>&#xA;&#xA;<p>Test results should be available only to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>laboratory</li>&#xA;</ul>&#xA;&#xA;<p>Attending doctor may send the patient to another specialist. A new doctor should have access to test results too. So access can be granted dynamically.</p>&#xA;&#xA;<p>So each entity (e.g. test results, X-Ray image) has a set of rules what users and groups are allowed to access it.</p>&#xA;&#xA;<p>Imagine there is a microservice called ""Test Results Service"" dealing with test results. Should it be responsible for access control, manage permissions etc.? Or permissions management should be extracted to separate microservice?</p>&#xA;&#xA;<p>Healthcare system may also handle visits to a doctor. Information about patient's visit to the doctor should be available to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>clinic receptionist</li>&#xA;</ul>&#xA;&#xA;<p>This is the example of a different entity type that requires entity level access restriction based on user or group membership.</p>&#xA;&#xA;<p>It is easy to imagine even more examples when entity level access control is required.</p>&#xA;"
49875284,Logback to Elasticsearch through yaml or properties,2018-04-17 10:07:11,<spring><elasticsearch><logging><microservices><logback>,1,187,3,0.0,3,"<p>I have many spring based microservice project where I used Logback to Elasticsearch for saving all logs to Elastic search index. I have configured using xml based on some tutorials I got. The configuration is based on xml like as shown below. Instead of xml how can we configure Logback to Elasticsearch using yaml or key value property files.</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;configuration&gt;&#xA;    &lt;springProperty scope=""context"" name=""microserviceName""&#xA;        source=""spring.application.name"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""profile""&#xA;        source=""spring.profiles.active"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESHost""&#xA;        source=""logging.esHost"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESPort""&#xA;        source=""logging.esPort"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESLoggingLevel""&#xA;        source=""logging.esLoggingLevel"" /&gt;  &#xA;    &lt;springProperty scope=""context"" name=""consoleLoggingLevel""&#xA;        source=""logging.consoleLoggingLevel"" /&gt; &#xA;&#xA;    &lt;appender name=""ELASTIC"" class=""com.internetitem.logback.elasticsearch.ElasticsearchAppender""&gt;&#xA;        &lt;url&gt;http://${myESHost}:${myESPort}/_bulk&lt;/url&gt;&#xA;        &lt;index&gt;logs-%date{yyyy-MM-dd}&lt;/index&gt;&#xA;        &lt;type&gt;tester&lt;/type&gt;&#xA;        &lt;loggerName&gt;es-logger&lt;/loggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;errorLoggerName&gt;es-error-logger&lt;/errorLoggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;connectTimeout&gt;30000&lt;/connectTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;errorsToStderr&gt;false&lt;/errorsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeCallerData&gt;false&lt;/includeCallerData&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;logsToStderr&gt;false&lt;/logsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxQueueSize&gt;104857600&lt;/maxQueueSize&gt; &lt;!-- optional (default 104857600) --&gt;&#xA;        &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;!-- optional (default 3) --&gt;&#xA;        &lt;readTimeout&gt;30000&lt;/readTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;sleepTime&gt;250&lt;/sleepTime&gt; &lt;!-- optional (in ms, default 250) --&gt;&#xA;        &lt;rawJsonMessage&gt;false&lt;/rawJsonMessage&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeMdc&gt;false&lt;/includeMdc&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxMessageSize&gt;100&lt;/maxMessageSize&gt; &lt;!-- optional (default -1 --&gt;&#xA;        &lt;authentication class=""com.internetitem.logback.elasticsearch.config.BasicAuthentication"" /&gt; &lt;!-- optional --&gt;&#xA;        &lt;properties&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;host&lt;/name&gt;&#xA;                &lt;value&gt;${HOSTNAME}&lt;/value&gt;&#xA;                &lt;allowEmpty&gt;false&lt;/allowEmpty&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;severity&lt;/name&gt;&#xA;                &lt;value&gt;%level&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;thread&lt;/name&gt;&#xA;                &lt;value&gt;%thread&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;stacktrace&lt;/name&gt;&#xA;                &lt;value&gt;%ex&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;logger&lt;/name&gt;&#xA;                &lt;value&gt;%logger&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;        &lt;/properties&gt;&#xA;        &lt;headers&gt;&#xA;            &lt;header&gt;&#xA;                &lt;name&gt;Content-Type&lt;/name&gt;&#xA;                &lt;value&gt;text/plain&lt;/value&gt;&#xA;            &lt;/header&gt;&#xA;        &lt;/headers&gt;&#xA;    &lt;/appender&gt;&#xA;&#xA;    &lt;root level=""info""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;        &lt;appender-ref ref=""ELASTIC"" /&gt;&#xA;    &lt;/root&gt;&#xA;&#xA;    &lt;logger name=""es-error-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;    &lt;logger name=""es-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender name=""ES_FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;&#xA;            &lt;!-- ... --&gt;&#xA;            &lt;encoder&gt;&#xA;                &lt;pattern&gt;%msg&lt;/pattern&gt; &lt;!-- This pattern is important, otherwise it won't be the raw Elasticsearch format anyomre --&gt;&#xA;            &lt;/encoder&gt;&#xA;        &lt;/appender&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;"
49836268,How to deal with authentication in a micro-services architecture,2018-04-14 21:14:47,<microservices><grpc>,2,172,4,3.0,3,"<p>I am currently reading a lot about microservices but still, I don't understand some parts. I made the following draw:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GkgRC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GkgRC.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each microservice has 2 accesses:</p>&#xA;&#xA;<ul>&#xA;<li>REST: For http uses</li>&#xA;<li>gRPC: For intra/background communication/exchanges</li>&#xA;</ul>&#xA;&#xA;<p>If I want to login I can just send an Http Request to my Authentication service. But what about if I want to access the Stuff service that needs you to be already connected?</p>&#xA;&#xA;<p>Let say that the user wants to display the stuff available in the database STUFF, the service Stuff will first check if the ""token"" of the connected user is right, by exchanging with the Authentication service, and then return the stuff or a ""login requires request"".</p>&#xA;&#xA;<p>So the thing I don't understand is, if each services that needs a client already connected needs to exchange with Authentication, then it will create a huge internet traffic in order to check each user request.. So I though about make one Authentication service per service, but since I should have only one Database, then it's the database that will slow the traffic?</p>&#xA;&#xA;<p>Also, if I understand, each micro service should be on separate servers, not the same one?</p>&#xA;&#xA;<p>I hope I am clear, don't hesitate to ask for more details !</p>&#xA;&#xA;<p>Thanks in advance :)</p>&#xA;&#xA;<p>Max</p>&#xA;&#xA;<h1>Edit 1</h1>&#xA;&#xA;<p><strong>Based on @notionquest's answer:</strong></p>&#xA;&#xA;<p>So it should more looks like that right?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pdOdR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pdOdR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Also, based on Peter's comment, each service can implement its own middleware (JWT as mentioned) so the API Gateway is only a ""pass-through"". However, I don't feel like it could be a nice for me since each service make a token check for each internal exchange, doesn't it?</p>&#xA;&#xA;<p>For the stuff, it's easy since it checks only 1 time the token. Now, let's say that, after the user got the stuff, he choose one and wanna buy it. Then the ""Buying service"" will call the stuff service in order the verify the price of the item, but... It will have to check the user token since the stuff is a ""on authenticated access"", so it means that ""Buying"" service and ""Stuff"" service both check the token, which add an extra check.</p>&#xA;&#xA;<p>I though about an internal guaranteed access between services but is it worth it?</p>&#xA;&#xA;<p>Also, maybe you said to implement the middleware for each service since they have a REST access, but the API Gateway would just destroy the idea of having REST access</p>&#xA;"
44253950,Using soap services(.asmx) with Azure Service fabric,2017-05-30 05:16:14,<web-services><rest><soap><microservices><azure-service-fabric>,1,256,0,1.0,3,<p>I am migrating my existing services to Azure service fabric. My existing application support the soap service(asmx) for the legacy users. I want to use the same web service as part of my microservice. That web service test.asmx(say) can be called from Rest Apis as well(If soln is there). But I'm not finding any way to use the soap service as part of Azure service fabric microservice approach. Help me out of possible solutions for tackling the web service scenario. Thanks!</p>&#xA;
44420585,Microservices: how to effectively deal with data dependencies between microservices,2017-06-07 18:47:49,<node.js><mean-stack><microservices>,2,125,0,1.0,3,"<p>I am developing an application utilizing the microservices development approach with the mean stack.  I am running into a situation where data needs to be shared between multiple microservices.  For example, let's say I have user, video, message(sending/receiving,inbox, etc.) services.  Now the video and message records belong to an account record.  As users create video and send /receive message there is a foreign key(userId) that has to be associated with the video and message records they create. I have scenarios where I need to display the first, middle and last name associated with each video for example.  Let's now say on the front end a user is scrolling through a list of videos uploaded to the system, 50 at a time.  In the worst case scenario, I could see a situation where a pull of 50 occurs where each video is tied to a unique user.</p>&#xA;&#xA;<p>There seems to be two approaches to this issue:</p>&#xA;&#xA;<p>One, I make an api call to the user service and get each user tied to each video in the list.  This seems inefficient as it could get really chatty if I am making one call per video.  In the second of the api call scenario, I would get the list of video and send a distinct list of user foreign keys to query to get each user tied to each video.  This seems more efficient but still seems like I am losing performance putting everything back together to send out for display or however it needs to be manipulated.</p>&#xA;&#xA;<p>Two, whenever a new user is created, the account service sends a message with the user information each other service needs to a fanout queue and then it is the responsibility of the individual services to add the new user to a table in it's own database thus maintaining loose coupling.  The extreme downside here would be the data duplication and having to have the fanout queue to handle when updates needs to be made to ensure eventual consistency.  Though, in the long run, this approach seems like it would be the most efficient from a performance perspective.  </p>&#xA;&#xA;<p>I am torn between these two approaches, as they both have their share of tradeoffs.  Which approach makes the most sense to implement and why?</p>&#xA;"
44331178,Testing same API for multiple response sets,2017-06-02 14:20:01,<javascript><node.js><rest><microservices><pact>,1,148,0,1.0,3,"<p>We've been trying to test an API exposed from a microservice (say GET /contacts) which is being consumed by another microservice.</p>&#xA;&#xA;<p>In order to avoid integration tests, we created consumer-driven contract tests where the consumer microservice created pacts and published them to a broker from where the producer would verify the pact separately.</p>&#xA;&#xA;<p>We've used <a href=""https://docs.pact.io/"" rel=""nofollow noreferrer"" title=""Pact IO"">Pact IO</a> to achieve this and it has been quite good so far.</p>&#xA;&#xA;<p>Now we are facing issues when trying to do exhaustive tests where we would want to see how an empty list is returned from GET /contacts.</p>&#xA;&#xA;<p>The problem is: while adding interactions, we could use Provider States but we couldn't find a way to differentiate between writing tests for getting a list of contacts from GET /contacts once and getting an empty list in another test.</p>&#xA;&#xA;<p>This is how we create pact tests in our consumer microservice:</p>&#xA;&#xA;<pre><code>mockServer.start()&#xA;        .then(() =&gt; {&#xA;          provider = pact({&#xA;            // config&#xA;          })&#xA;          return provider.addInteraction({&#xA;            state: 'Get all contacts',&#xA;            uponReceiving: 'Get all contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: //list of all contacts&#xA;            }&#xA;          })&#xA;        .then(() =&gt; {&#xA;          return provider.addInteraction({&#xA;            state: 'Get empty list of contacts',&#xA;            uponReceiving: 'Get empty list of contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: [] // empty list&#xA;            }&#xA;          })&#xA;        })&#xA;</code></pre>&#xA;&#xA;<p>We cannot find a way to differentiate between these interations in our tests! :(</p>&#xA;&#xA;<p>Any help would be appreciated!</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
36586934,Carrying request context through the stack and across thrift service boundaries with Node.js,2016-04-13 01:26:35,<node.js><typescript><microservices><restify>,1,305,0,0.0,3,"<p>I'm trying to figure out an appropriate method to carry a request-id (x-request-id from a restify request header) through my stack; across thrift inter-service calls, and with rabbitmq queue messages. The goal is that anywhere, in any service, I can correlate an error or event back to an initiating http request. Is there a known practice for doing this with Node? I'd like to avoid passing a context around through virtually every function call.</p>&#xA;&#xA;<p>I've looked into the way New Relic handles instrumentation, and there's this blog: <a href=""https://opbeat.com/blog/posts/how-we-instrument-nodejs/"" rel=""nofollow"">https://opbeat.com/blog/posts/how-we-instrument-nodejs/</a>; but these types of instrumentation require hooking into tons of node core library calls, and don't really help with carrying the context across thrift calls.</p>&#xA;&#xA;<p>How can I take a restify header id such as ""x-request-id"" from a request, and have access to it deeper in my stack (even in async callbacks) without modifying every function to pass the values through? </p>&#xA;&#xA;<p>I'm also looking for a clean way to pass it through all thrift calls (getting it across service boundaries).</p>&#xA;&#xA;<p>This is with TypeScript and Node.js 5.x</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
33680497,What is a Java MicroService,2015-11-12 20:16:11,<java><microservices>,2,1730,3,3.0,3,"<p>I been searching on the web but im a little confused on what exactly is a java microservice. I mean i know what a web service is, and im told that a microservice is the following per wiki:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In computing, microservices is a software architecture style in which complex applications are composed of small, independent processes communicating with each other using language-agnostic APIs.</p>&#xA;</blockquote>&#xA;&#xA;<p>and the properties of a microservice are:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Properties of microservices architecture:</p>&#xA;  &#xA;  <p>It's a kind of architecture The services are easy to replace Services&#xA;  are organized around capabilities, e.g. user interface front-end,&#xA;  recommendation, logistics, billing, etc Services can be implemented&#xA;  using different programming languages, databases, hardware and&#xA;  software environment, depending on what fits best Architectures are&#xA;  symmetrical rather than hierarchical (producer - consumer)</p>&#xA;</blockquote>&#xA;&#xA;<p>but i need a concrete java example to understand how i can make a microservice.  Does anyone have a example you could provide ?</p>&#xA;"
51627473,Spring Boot YAML Auto Data Source Configuration Issue - Data Source URL not picked up,2018-08-01 07:18:19,<java><spring><spring-boot><yaml><microservices>,1,59,7,0.0,3,"<p>Currently, We are creating a spring boot project for our newer modules. </p>&#xA;&#xA;<p>Technology We have used as follows :</p>&#xA;&#xA;<ol>&#xA;<li>Java 1.8</li>&#xA;<li>Maven 3.5.2</li>&#xA;<li>Spring Boot: 1.5.6.RELEASE (spring-boot-starter-parent)</li>&#xA;</ol>&#xA;&#xA;<p>public class Application {</p>&#xA;&#xA;<pre><code>public static void main(String[] args) {&#xA;    SpringApplication.run(Application.class, args);&#xA;}&#xA;&#xA;@Autowired&#xA;private DataSource datasource;&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>application.properties</p>&#xA;&#xA;<ul>&#xA;<li>spring.datasource.url=<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>spring.datasource.username=XXX</li>&#xA;<li>spring.datasource.password=XXX</li>&#xA;<li>spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver</li>&#xA;</ul>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<ul>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles:</li>&#xA;<li>active: ""dev""</li>&#xA;<li>main:&#xA;&#xA;<h2>     - banner-mode: ""off""</h2></li>&#xA;</ul></li>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles: dev</li>&#xA;<li>datasource:&#xA;&#xA;<ul>&#xA;<li>url:<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>username:XXX</li>&#xA;<li>password:XXX</li>&#xA;<li>driver-class-name:oracle.jdbc.driver.OracleDriver</li>&#xA;</ul></li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>When we are adding data source information as properties file the application working as expected. But information as YAML means showing below error.</p>&#xA;&#xA;<p><strong>ERROR</strong></p>&#xA;&#xA;<p>Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'testapplication': <strong>Unsatisfied dependency expressed through field 'datasource'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource</strong> [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Tomcat.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.tomcat.jdbc.pool.DataSource]: Factory method 'dataSource' threw exception; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: <strong>Cannot determine embedded database driver class for database type NONE. If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (the profiles ""dev"" are currently active)</strong>.</p>&#xA;"
35314963,What is best practice to communicate between React components and services?,2016-02-10 12:13:11,<rest><reactjs><redux><flux><microservices>,2,6713,0,3.0,3,"<p>Instead of using flux/redux architecture, how react components should communicate with services?</p>&#xA;&#xA;<p><strong>For example:</strong>&#xA;There is a container having few representational (react) components:</p>&#xA;&#xA;<ol>&#xA;<li>ChatBox - enables to read/write messages</li>&#xA;<li>AvatarBox with password changer - which enables to change user's password</li>&#xA;<li>News stream - lists news and apply filter to them</li>&#xA;</ol>&#xA;&#xA;<p>Thinking of them as resources representation, I want each of them to access Microservice API by itself (getting or updating data). Is this correct?&#xA;It will provide clean responsibility managing models, but it gives performance doubts using http requests to load each component's content</p>&#xA;&#xA;<p>This question also reffers to: <a href=""https://stackoverflow.com/questions/35286730/how-to-execute-efficient-communication-for-multiple-microservices"">How to execute efficient communication for multiple (micro)services?</a></p>&#xA;"
35348080,How to handle shared datasources using microservices architecture,2016-02-11 19:14:25,<java><architecture><redis><microservices><bigdata>,1,622,0,1.0,3,"<p>I have couple of services in my microservice architecture.</p>&#xA;&#xA;<p>Two of the service(Service A, Service B) got different api's and provide different domain logic. However they do share some logic that should be returned - user-state from Redis.</p>&#xA;&#xA;<ul>&#xA;<li>When user state is changed Iam publishing from a 3rd service to all the my micro-services</li>&#xA;</ul>&#xA;&#xA;<p>solutions:</p>&#xA;&#xA;<ol>&#xA;<li><p>I could create another service which would be responsible for ""user-state"" and will hold all user data on Redis.&#xA;Disadvantages: &#xA;My clients going to have additional call on every api requests(to get the user-state).</p></li>&#xA;<li><p>Duplicate the user-state datasource for each microservices(holding more than one redis instance) and return it independently for each request.&#xA;Disadvantages: &#xA;I am going to duplicate my data and duplicate Redis instances(each microservice will access it's own)</p></li>&#xA;<li><p>have one redis datasource while all services going to use it. &#xA;Disadvantages: &#xA;Duplicating redis-logic(in order to retrieve the data) among the services and break microservices principle by using one shared datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What would you suggest doing?</p>&#xA;"
35223505,Spring Boot project setup design decisions,2016-02-05 11:50:38,<java><spring><spring-boot><microservices>,1,252,1,1.0,3,"<p>We will be using Spring Boot to create services. Our initial idea would be that each service (not necessarily microservice) would be self-contained, and deployed as a .jar file. Maven for build.</p>&#xA;&#xA;<p>I'm wondering what would be a good Spring Boot project structure, as each service would be self-contained, but I'm guessing services will still have some code/entities that can or should be reused between services</p>&#xA;&#xA;<p>Options:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each service is a standalone Spring Boot project. Implements only the entities, controllers, and utils that the actual service requires.</p>&#xA;&#xA;<p>Good: each service is fully self-contained</p>&#xA;&#xA;<p>Bad: what about custom utility classes that need to be re-used between services? What about domain objects that services may need to share?</p></li>&#xA;<li><p>All services are created in the same codebase. All services can re-use utilities, controllers, etc. from all other services&#xA;Good: easy re-use&#xA;Bad: A JVM is now able to serve all service calls? service boundaries are now handled by load balancers?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!  </p>&#xA;"
41609091,Sharing files between microservices,2017-01-12 09:12:44,<node.js><microservices><seneca>,2,1858,1,1.0,3,"<p>I'm trying to move a project from its current monolithic state to microservices architecture. The project is in Node.js, so I've started looking into <a href=""http://senecajs.org/"" rel=""nofollow noreferrer"" title=""Seneca.js"">Seneca.js</a>, especially with its <a href=""https://github.com/senecajs/seneca-mesh"" rel=""nofollow noreferrer"" title=""seneca-mesh"">seneca-mesh</a> module. Moving image manipulation (crop, resize, etc.) into a microservice seemed the most sensible first step, since it drastically slows down my application now.</p>&#xA;&#xA;<p>When the application is monolithic, there is no problem in passing certain files into file-manipulation logic — just read it from local storage disk. With microsevices, however, if we keep in mind <em>scalability</em>, it becomes more difficult. Of course, I could build an image manipulation microservice, scale it up <em>within the same host machine</em>, and share directories I need between it, so they, too, can read from a local disk.</p>&#xA;&#xA;<p>What if I want a truly scalable microservice, that can be run and scaled on <em>different</em> machines with different IP-adresses that <em>don't share the same filesystem</em>? I thought that maybe I could take advantage of Node's streaming API and send these files back and forth via HTTP or TCP or sockets or you name it.</p>&#xA;&#xA;<p>As far as I've learned, Seneca.js cannot do it <em>the right way</em>. Of course, I could send a file from the main app to image manipulation service via Seneca.js like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('/files/hello.jpg')&#xA;  .on('data', function(data) {&#xA;    seneca.act({ role: 'file', cmd: 'chunk', data: data }, cb);&#xA;  })&#xA;  .on('end', function(err) {&#xA;    seneca.act({ role: 'file', cmd: 'end' });&#xA;  })&#xA;  .on('error', function(err) {&#xA;    seneca.act({ role: 'test', cmd: 'error' });&#xA;  });&#xA;</code></pre>&#xA;&#xA;<p>And receive it in chunks:</p>&#xA;&#xA;<pre><code>seneca.add({ role: 'file', cmd: 'chunk' }, writeToFileCb);&#xA;seneca.add({ role: 'file', cmd: 'end' }, endFileWriteCb);&#xA;</code></pre>&#xA;&#xA;<p>But this approach seems ugly and wheel-reinventive.</p>&#xA;&#xA;<p>Another way would be to come up with some HTTP server and send files as <code>multipart/form-data</code> or <code>application/octet-stream</code>, like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('file.json')&#xA;  .pipe(request.post('http://image-manipulator'))&#xA;</code></pre>&#xA;&#xA;<p>But this means reinventing the framework for microservice communication. All in all, I ask for advice on file sharing between distributed microservices and possible frameworks for this.</p>&#xA;"
41661858,Microservice Interaction,2017-01-15 13:52:12,<c#><.net><microservices><restful-architecture>,2,439,2,0.0,3,"<p>I would like to know what is the best practice on making one Microservice to interact with another Microservice?</p>&#xA;&#xA;<p> I am developing in C#. What I currently have done is, created a service bus which passes new events created from one Microservice. I then use task runner (WebJob) which consumes the messages off the bus and then I am using Http to Post to another Microservice endpoint. Each microservice is a web api. </p>&#xA;&#xA;<p>I would like to ask if I am doing it correctly, if not I am happy to hear the suggestions. </p>&#xA;"
42949138,Rails: Microservice architecture with dedicated authorization service and app services using Knock (JWT),2017-03-22 10:37:22,<ruby-on-rails><ruby><jwt><microservices>,1,461,0,0.0,3,"<p>I'm now trying to separate monolithic application into microservices (dedicated rails app's) and wanted to know - is there a solution to move authorization service from each service?</p>&#xA;&#xA;<p>For example, I have 6 different Rails API services with 'knock' gem that have user model for authentication purpose.&#xA;All those services sharing one user database.</p>&#xA;&#xA;<p>I want to implement dedicated service with user model, but how other services will verify users with given tokens?</p>&#xA;&#xA;<p>Also I want to able to control what services user can and can't use. So there should be AccessRole service?</p>&#xA;&#xA;<p>Draft case:</p>&#xA;&#xA;<ol>&#xA;<li>User go to 'articles' (frontend UI client)</li>&#xA;<li>auth_service is validating token from client</li>&#xA;<li>access_service got message from auth_service somehow and validating user's role to access 'articles' resource.</li>&#xA;<li>articles_service send response to client with json data.</li>&#xA;</ol>&#xA;&#xA;<p>Here some more questions:</p>&#xA;&#xA;<ol>&#xA;<li>How access_service will communicate with auth_service? Should they use one user database to verify user's credentials and role?</li>&#xA;<li>articles_service and so on - should they become private services without access to public and act as black boxes to user?</li>&#xA;</ol>&#xA;"
50700178,Should API gateway be responsible for authorisation?,2018-06-05 12:32:36,<authentication><architecture><authorization><microservices><api-gateway>,1,100,0,1.0,3,"<p>Currently I have a monolith application with Java/Spring Boot the following endpoints:</p>&#xA;&#xA;<ul>&#xA;<li><code>/login</code></li>&#xA;<li><code>/logout</code></li>&#xA;<li><code>/some-resource</code></li>&#xA;</ul>&#xA;&#xA;<p>To access <code>some-resource</code>, the flow is following:</p>&#xA;&#xA;<ol>&#xA;<li>The user makes a <code>POST</code> request to <code>/login</code> endpoint. If the credentials are correct, a JWT token is returned in header, otherwise a 401.</li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<p>Now I want to split the monolith into 2 services: ""AuthServer"" and ""SomeResourceServer"". There will be an API gateway on the top. I am thinking about 2 possible ways to handle authorisation</p>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 1</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway calls the ""AuthServer"" to validate the JWT token. If the token is valid, the API gateway calls ""SomeResourceServer"" and returns the results. Otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 2</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway simply forwards the request to ""SomeResourceServer"". Then ""SomeResourceServer"" calls ""AuthServer"" to validate the JWT token. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p>In Option 1 the API gateway is responsible to handle authorisation (communicate with ""AuthServer""), in option 2 the communication is done between the servers. So which option is more correct? Are there any good/bad practices? Or maybe another way/option?</p>&#xA;"
47007159,Looking for JWT Auth microservice example,2017-10-30 01:54:51,<node.js><authorization><jwt><microservices>,1,982,0,1.0,3,"<p>I am wanting to build a authentication/authorization service using NodeJS, Mongo, and JWT.  This service would be a micro-service that handles requests not only from my API Gateway before allowing requests, but from other services that might want to check auth and roles. I am assuming that all other services will use this Auth Service to validate the JWT as well as roles, etc.</p>&#xA;&#xA;<p>Hopefully this diagram better explains what I am looking for.&#xA;<a href=""https://i.stack.imgur.com/NDuCY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NDuCY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Can anyone point me to a resource that might help me learn how to do this with NodeJS?</p>&#xA;"
46920685,How to do canary releases and dynamic routing with Netflix Zuul?,2017-10-24 21:55:19,<spring-boot><microservices><netflix-zuul><canary-deployment><dynamic-routing>,1,222,0,1.0,3,"<p>We faced with the problem that we need to do such thing as dynamic routing and canary releases. So, for example, we deploy microservice <code>microservice-1</code>. Then, when someone finished a big feature we want to deploy it as a microservice <code>microservice-1.1</code>.</p>&#xA;&#xA;<h3>Question</h3>&#xA;&#xA;<p>Is it possible to dynamically reroute requests using information, for example, from Headers, and route to the microservice version <code>microservice-1.1</code> instead on <code>microservice-1</code>?</p>&#xA;&#xA;<p>For example, someone needs this feature and he will modify/add specific Header and for all requests, he will use new <code>microservice-1.1</code>. And if that Header is missing then the current microservice-1 version should be used.</p>&#xA;&#xA;<p>For service discovery, I am using Eureka. Right now I am looking at <a href=""https://linkerd.io/"" rel=""nofollow noreferrer"">linkerd</a> but there is no support for Eureka and I am working on it right now. Of course, if it is possible to do it using Zuul that would be great. Please advise where to look at. </p>&#xA;"
42053559,Eventual consistency with both database and message queue records,2017-02-05 15:04:53,<database><domain-driven-design><message-queue><microservices><eventual-consistency>,3,466,2,0.0,3,"<p>I have an application where I need to store some data in a database (mysql for instance) and then publish some data in a message queue. My problem is: If the application crashes after the storage in the database, my data will never be written in the message queue and then be lost (thus eventual consistency of my system will not be guaranted).&#xA;How can I solve this problem ?</p>&#xA;"
31764926,Microservices API calls and dependency design,2015-08-01 18:35:43,<design><dependencies><microservices>,2,359,0,2.0,3,"<p>Are there any best practice on designing microservices service regarding API dependency (APIs that the service is calling to)?</p>&#xA;&#xA;<p>For example if I have a ""Order Management"" (OM) service, obviously it will need to call ""User Management"" (UM) service since it will need to query user info (shipping address, email, etc) many times. If I let my OM calls UM all the time when it needs user info this will create lots of dependency on UM service. </p>&#xA;&#xA;<p>As far as I understand services are supposed to be autonomous and as decoupled as possible - but now I got a OM service that will go down everytime UM service go down.</p>&#xA;&#xA;<p>Upon searching on Google I found 3 alternatives:</p>&#xA;&#xA;<ol>&#xA;<li>Use the event-based programming to replciate user data as soon as user data is created in UM module so it is always replicated into a table inside OM</li>&#xA;<li>Use database's replciation mechanism to replicate data from UM onto OM database</li>&#xA;<li>Copy user data into order object as nested json to eliminate dependency for order query and update (but I suppose initial order creation will still need to call UM)</li>&#xA;</ol>&#xA;&#xA;<p>Are there any best practices on the challenge here or are there any rules of thumb of deciding which design approach to take?</p>&#xA;"
38106036,Documenting a message bus API?,2016-06-29 17:07:47,<c#><json><documentation><microservices><netmq>,1,337,0,1.0,3,"<p>I've been searching for the past couple of days for some way to document the API for a microservices architecture I'm working on.  First, I'll give a very quick description of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Written in C#, .NET 4.6.1</li>&#xA;<li>Using NetMQ with x-pub/x-sub proxy as a ""message broker""</li>&#xA;<li>All communication is plain C# objects serialized to JSON</li>&#xA;<li>Some clients are JavaScript in the browser, others are .NET applications</li>&#xA;</ul>&#xA;&#xA;<p>The short of it is that I'd like to know how other people document the models that are published to their message bus.  I've seen quite a few projects (like Swagger) that help document REST calls, but we're not using REST.  Our application is almost entirely event-based with pub-sub messaging using JSON.</p>&#xA;&#xA;<p>My first thought was to document the JSON with JSON-Schema and use a tool to convert that to nicely-formatted API docs.  That would probably work okay, but what bothers me is that there don't seem to be any tools to automate the schema generation as part of a build process.  If our models diverge from the API documentation, I want it to be a build error.  Even better, if there was some way to auto-generate the basic documentation as part of the build process, the docs could be kept in sync.</p>&#xA;&#xA;<p>How do you guys do it?  The lack of documentation tools specific to a message bus architecture in favor of REST is making me question our decision to use a messaging architecture based on message queues.  :)</p>&#xA;"
38070572,How to architecture Microservice & OpenID connect?,2016-06-28 08:10:32,<microservices><openid-connect><oauth2>,1,1235,0,1.0,3,"<p>We have three microservices: microA, microB &amp; microC.</p>&#xA;&#xA;<ul>&#xA;<li>microA &amp; microB are powering product 1.</li>&#xA;<li>microA &amp; microC are powering product 2.</li>&#xA;</ul>&#xA;&#xA;<p>Obviously, we would need a security layer, in our case implementing an ""OpenID Connect"" provider fits well with the business needs. We add to the stack the OpenID provider.</p>&#xA;&#xA;<p>The user/rights management is quite easy &amp; natural: we associate the OpenId identifier of the user on each microservices to a subset of rights:</p>&#xA;&#xA;<p>For example on the service microA, we store that the user OpenID XXX can do this and that. it's isolated on the microservice level. Respect the boundaries of our context. Fine.</p>&#xA;&#xA;<p>When the user login with OpenID on product1, we grant an access token to the user + an Id token.</p>&#xA;&#xA;<p>The situation becomes more complex when product1 expose an API that third-party use.</p>&#xA;&#xA;<p>Now, let say that my user comes to the third-party webapp and is prompted to login &amp; allow the third-party to get some rights on product1 API.</p>&#xA;&#xA;<p>If I understand correctly OpenID connect, it's all about authentication over OAuth2, but how do we handle classic OAuth2 scope management then?</p>&#xA;&#xA;<p>The best scenario I have found is:</p>&#xA;&#xA;<ol>&#xA;<li><p>make the whole OpenID connect to have the authentication info </p></li>&#xA;<li><p>and then make another full OAuth2 process to another Authorization server to ask the user to grant some scopes to the third party?</p></li>&#xA;</ol>&#xA;&#xA;<p>which means that on the third-party:</p>&#xA;&#xA;<ul>&#xA;<li>the user will be prompted to login on the OpenID Provider </li>&#xA;<li>then redirected and prompted to accept the scope requested</li>&#xA;</ul>&#xA;&#xA;<p>Is that correct? If yes, OAuth2 server flow is like 4 HTTP requests to the end user, so performing it twice is like executing eight requests to get the Authentication + Authorization flow done. Seems too massive.</p>&#xA;"
38168658,Multiple microservices and database associations,2016-07-03 09:40:56,<database><rest><spring-boot><microservices>,2,480,0,0.0,3,"<p>I have a question concerning microservices and databases. I am developing an application: a user sees a list of countries and can click through it so he can see a list of attractions of that country. I created a country-service, auth-service (contains users for oAuth2) and an attraction-service. Each service has its own database. I mapped the association between an attraction and its country by the <strong>iso code</strong> (for example: BE = belgium): /api/attraction/<strong>be</strong>.</p>&#xA;&#xA;<p>The approach above seems to work but I am a bit stuck with the following: a user must be able to add an attraction to his/her list of favorites, but I do not see how that's possible since I have so many different databases. </p>&#xA;&#xA;<p>Do I create a favorite-service, do I pass id's (I don't think I should do this), what kind of business key can I create, how do I associate the data in a correct way...?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
38023093,Refer to another service/task running in same ECS cluster,2016-06-24 22:43:57,<docker><microservices><amazon-ecs>,1,237,0,1.0,3,"<p>I know how to refer to ""services"" from within the same task. But how can I refer to an essential task from within another task definition?&#xA;For example:</p>&#xA;&#xA;<ul>&#xA;<li>Service ""mesage-broker"" is running task rabbitmq.&#xA;&#xA;<ul>&#xA;<li>Service ""user-api"" is running task user-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;<li>Service ""order-api"" is running task order-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;</ul></li>&#xA;</ul>&#xA;"
38224152,How to maintain repositories into a single repository,2016-07-06 12:34:37,<git><docker><docker-compose><microservices>,1,65,1,1.0,3,"<p>I have a repository for each micro-services ('A', 'B', ..). The structure of a repository looks like :</p>&#xA;&#xA;<pre><code>A&#xA;|-dockerfile&#xA;|-src&#xA;  |-Java&#xA;  |-Groovy&#xA;</code></pre>&#xA;&#xA;<p>Since all of these repositories belongs to a project called 'WholeProject', I want to maintain a repository 'WholeProject' which looks like :</p>&#xA;&#xA;<pre><code>WholeProject&#xA;|-docker-compose.yml&#xA;|-µS&#xA;  |-A&#xA;  |-B&#xA;  |-..&#xA;</code></pre>&#xA;&#xA;<p>So I could easily maintain a docker-compose file and a repository that contains all the revelant things about my project.</p>&#xA;&#xA;<p>Is this a good idea ? How can I perform that ?</p>&#xA;"
38125926,Run Google App Engine application with microservice,2016-06-30 14:20:04,<python><google-app-engine><publish-subscribe><microservices>,1,515,2,3.0,3,"<p>I have a one big monolith application, and now its time to separate some modules to micro services!&#xA;I read a lot about pub/sub and microservices in Google docs, but can't find answers to my questions:</p>&#xA;&#xA;<ol>&#xA;<li>How app.yaml file looks like for my module(microservice)?</li>&#xA;<li>How app.yaml looks like for my app?(I mean, with microservice)</li>&#xA;<li>Where I need to declare this module - in application app.yaml or in both app.yaml?</li>&#xA;<li>How can I use single datastore with my app and my module?</li>&#xA;</ol>&#xA;&#xA;<p>My app.yaml now looks like:</p>&#xA;&#xA;<pre><code>application: my-application&#xA;version: 1&#xA;runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;</code></pre>&#xA;&#xA;<p>with some credentials and libs.</p>&#xA;&#xA;<p>Waiting for your answers!</p>&#xA;"
42836979,Can same dyno run multiple different processes?,2017-03-16 14:31:27,<amazon-web-services><heroku><microservices>,3,373,0,0.0,3,"<p>I got a question regarding heroku architecture. I am creating small app running as microservices (not a lot of - about 4-6 microservices). The point is, that I would like to get this app available 24/7, so free dyno hours are not enough for me.</p>&#xA;&#xA;<p>I saw that if I will expand to <code>hobby</code> plan I would get something what heroku calls <code>10 Process Types</code>. Here my question comes: </p>&#xA;&#xA;<p>Can I run another microservice on each of that process (web), or heroku gives me ability only to install one web process per dyno, and given <code>10 process types</code> are for scaling my app? In other words, If i need 6 microservices running 24/7 should I buy 6 hobby dynos?</p>&#xA;"
38254720,Migrate from monolith to Micro service architecture,2016-07-07 20:30:29,<microservices>,2,115,1,0.0,3,<p>We are on the initial stages of designing a micro service for my client from their standard monolith app that is sitting on 4 JBOSS servers in their own data center. Is micro service architecture target at only cloud based deployment? Can i deploy a micro service on premise production ready tomcat /JBOSS? Is that a good fit?</p>&#xA;
39967784,Microservice vs SOA differs,2016-10-10 22:35:46,<soa><microservices>,5,712,0,1.0,3,"<p>I was looking for differences b/w SOA and Microservices architecture style&#xA;and found a good link <a href=""https://www.infoq.com/articles/boot-microservices"" rel=""nofollow noreferrer"">https://www.infoq.com/articles/boot-microservices</a></p>&#xA;&#xA;<p>It Says:<br>&#xA;As a successor to ""Service Oriented Architecture"" (SOA), microservices can be categorized in the same family of ""distributed systems"", and carry forward many of the same concepts and practices of SOA. Where they differ, however, is in terms of the scope of responsibility given to an individual service. In SOA, a service may be responsible for handling a wide range of functionality and data domains, while a general guideline for a microservice is that it is responsible for managing a <strong>single data domain</strong> and the corresponding functions around that domain.</p>&#xA;&#xA;<p>Please help me to understand :<br>&#xA;The meaning of single data domain (recommended for microservice).&#xA;is it saying that a separate Microservice has to be build to manage a single domain/entity (and associated/composite domain/entities with this single domain/entity). Becasue if this case, then there will be many(~20 to ~50) microservices even to implement a basic functionality (enterprise) application</p>&#xA;&#xA;<p>Edit:&#xA;I have gone through the link <a href=""https://stackoverflow.com/questions/25501098/difference-between-microservices-architecture-and-soa"">Difference between Microservices Architecture and SOA</a>, but it explains, that it is same on the first two tenets, and different on 3rd point (in SOA, Services share schema and contract, not class), but that is SOAP contracts, but then what is the difference b/w SOA (with REST) vs Microservices (which is mostly with REST)</p>&#xA;"
40068013,ci/cd independent microservices in monorepo with git bash,2016-10-16 07:35:35,<git><bash><continuous-integration><microservices><monorepo>,1,249,0,1.0,3,"<p>Using Bash and git, how do I get a collection of directories containing files that differ from that last time the branch was merged into <code>master</code>?</p>&#xA;&#xA;<p>Even better would be a collection of changed that match a pattern such as containing a particular file name , i.e. building a collection of changed directories containing <code>package.json</code> and a different collection of changed containing <code>requirements.txt</code>.</p>&#xA;"
40058568,Synchronous communication in a mostly asynchronous microservices architecture,2016-10-15 11:40:51,<architecture><publish-subscribe><microservices>,1,253,2,1.0,3,"<p>I'm trying to extract some services from my monolithic application pet project, mostly as a learning exercise. I'm using AMQP (RabbitMQ) for communication between services, which is working just fine. However, I'm having trouble separating the web frontend from the rest of the application. The web service takes care of views and UI logic, but needs to query the backend ""core"" service for the main data. AMQP doesn't seem like a good fit for this, as the frontend service needs to wait for the response, and response times are critical. My first thought was to implement a REST interface for just this line of communication, but the same service also uses AMQP to subscribe to communication of other services. </p>&#xA;&#xA;<p>This seems like it should be a pretty common occurrence, but I haven't been able to find any answers.</p>&#xA;&#xA;<p>I guess my main question is what to do when one service needs to offer both synchronous and asynchronous communication. I'm also using Ruby, which doesn't lend itself to having the multiple threads it would require to listen on two interfaces. A few things I've considered:</p>&#xA;&#xA;<ul>&#xA;<li>Just using AMQP, sending a message with a <code>reply_to</code> field, and blocking until response is received.</li>&#xA;<li>Extract the data access part of the core backend service and giving it a REST API. Then both the web service and the part that ""subscribes"" would query this other service. Seems unnecessary to have a service just for access database.</li>&#xA;<li>Having multiple threads and using some kind of event loop to listen on two interfaces. Seems overly complex.</li>&#xA;</ul>&#xA;"
49612709,Should each microservice manage its own user-permissions and user-roles?,2018-04-02 13:58:40,<jwt><microservices>,2,215,3,0.0,3,"<p>I have a design issue I am not sure of how to solve.</p>&#xA;&#xA;<p>Let's say my main application consists of 6 modules:</p>&#xA;&#xA;<ul>&#xA;<li>client</li>&#xA;<li>gateway</li>&#xA;<li>auth-service</li>&#xA;<li>forum</li>&#xA;<li>gallery</li>&#xA;<li>messages</li>&#xA;</ul>&#xA;&#xA;<p>The client is supposed to communicate with the gateway-service only.</p>&#xA;&#xA;<p>Should I have my gateway do the user-authentication (which ideally results in a JWT) and the other 3 productive-services (forum, gallery, messages) just verify that token and retrieve permissions and roles <strong>they manage themselves</strong> for that given user?</p>&#xA;&#xA;<p>To perhaps illustrate my few troubles, I create a sequence diagram:&#xA;<a href=""https://i.stack.imgur.com/j82Fv.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j82Fv.jpg"" alt=""this image shows the sequence diagram, which I am having trouble with""></a></p>&#xA;&#xA;<p><a href=""https://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharinghttps://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharing"" rel=""nofollow noreferrer"" title=""link to Google Drive file"">Click here</a> for the original draw.io graphics if you prefer that.</p>&#xA;&#xA;<p>I do not want to use any 3rd-party auth-services; I just want my auth-service (which is pretty much done) to register users and let them login. Or should I be managing permissions and roles in that service as well?</p>&#xA;&#xA;<p>I tried to wrap my brain around this issue for months, but I simply cannot find a suitable structure so I can let the user register, login/logout and communicate with various productive services. I am currently using Java for the backend stuff, but the good thing about microservices is, that I do not have to use one programming language for them all.</p>&#xA;&#xA;<p>Any help here is welcome!</p>&#xA;&#xA;<p>P.s.: I read <a href=""https://stackoverflow.com/questions/29644916/microservice-authentication-strategy"">Microservice Authentication strategy</a> and <a href=""https://stackoverflow.com/questions/33921375/zuul-api-gateway-authentication"">Zuul - Api Gateway Authentication</a>, but both did not seem to apply in my case.</p>&#xA;"
38714097,Deploy Service Fabric Application through VSTS release pipeline using Hosted Agent,2016-08-02 07:19:59,<azure><vsts><microservices><azure-service-fabric><vsts-release>,1,888,8,0.0,3,"<p>I have set up continuous integration using Hosted Agent for service fabric by following this document <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/"" rel=""nofollow noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/</a></p>&#xA;&#xA;<p>In Release pipeline after importing certificate I am getting the following error and deployment failing. I am not able to identify where the issue is&#xA;<a href=""https://i.stack.imgur.com/Afc7G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Afc7G.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;  &#xA;  <p>Finishing task: ServiceFabricDeploy </p>&#xA;  &#xA;  <h2>[error]System.Exception: Task ServiceFabricDeploy failed.</h2>&#xA;  &#xA;  <p>This caused the job to fail. Look at the logs for the task for more details. </p>&#xA;  &#xA;  <p>[error]   at Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.Run(IJobContext jobContext, IJobRequest job, IJobExtension jobExtension, CancellationTokenSource tokenSource)</p>&#xA;</blockquote>&#xA;&#xA;<p>Under Deploy service fabric task it is showing the below error&#xA;<a href=""https://i.stack.imgur.com/bSCBZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bSCBZ.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>Imported cluster client certificate with thumbprint 'A6B32E70CFE715F608A247C1ED94AB3D0164A58E'.</p>&#xA;  &#xA;  <p>Thumbprint Subject                                            </p>&#xA;  &#xA;  <p>A6B32E70CFE715F608A247C1ED94AB3D0164A58E  >CN=clusternamedns.eastus.cloudapp.azure.com                                     </p>&#xA;  &#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;</blockquote>&#xA;&#xA;<h2><strong>Update</strong></h2>&#xA;&#xA;<p>After setting system.debug to true in variables, I got the following log</p>&#xA;&#xA;<pre><code>    2016-08-03T05:44:31.6556865Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.6566887Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.6577063Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.6587072Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.6597111Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.6606871Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.6647953Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.6656886Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.6666879Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.6676869Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.6770225Z ##[debug]Leaving C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1.&#xA;&#xA;2016-08-03T05:44:31.6850322Z ##[debug]Caught exception from task script.&#xA;&#xA;2016-08-03T05:44:31.6890370Z ##[debug]Error record:&#xA;&#xA;2016-08-03T05:44:31.7380329Z ##[debug]Connect-ServiceFabricCluster : An error occurred during this operation.  Please check the trace logs for more details.&#xA;&#xA;2016-08-03T05:44:31.7390333Z ##[debug]At C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1:73 char:12&#xA;&#xA;2016-08-03T05:44:31.7410325Z ##[debug]+     [void](Connect-ServiceFabricCluster @clusterConnectionParameters)&#xA;&#xA;2016-08-03T05:44:31.7420325Z ##[debug]+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;2016-08-03T05:44:31.7430323Z ##[debug]    + CategoryInfo          : InvalidOperation: (:) [Connect-ServiceFabricCluster], FabricException&#xA;&#xA;2016-08-03T05:44:31.7440363Z ##[debug]    + FullyQualifiedErrorId : CreateClusterConnectionErrorId,Microsoft.ServiceFabric.Powershell.ConnectCluster&#xA;&#xA;2016-08-03T05:44:31.7450426Z ##[debug] &#xA;&#xA;2016-08-03T05:44:31.7470318Z ##[debug]Script stack trace:&#xA;&#xA;2016-08-03T05:44:31.7500512Z ##[debug]at &lt;ScriptBlock&gt;, C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1: line 73&#xA;&#xA;2016-08-03T05:44:31.7910331Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7920318Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 22&#xA;&#xA;2016-08-03T05:44:31.7930364Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 18&#xA;&#xA;2016-08-03T05:44:31.7940315Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7960349Z ##[debug]Exception:&#xA;&#xA;2016-08-03T05:44:31.8000522Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.8010571Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.8020684Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.8030335Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.8040334Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.8060326Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.8070343Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.8080330Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.8090325Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.8100358Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.8340330Z ##[error]An error occurred during this operation.  Please check the trace logs for more details.&#xA;</code></pre>&#xA;"
49443206,Difference between OSGI and microservices,2018-03-23 05:54:50,<osgi><microservices><osgi-bundle>,2,1173,1,0.0,3,<p>When would you like to choose for OSGI modules than micro services and is there anything i can do with micro services that i can not do with OSGI modules?</p>&#xA;
38507565,"Connect ""MicroService Gateway"" with ""UAA Server"" Jhipster 3.5.0",2016-07-21 14:53:24,<jhipster><microservices>,4,1731,4,0.0,3,"<p>I created a UAA Server:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? [BETA] JHipster UAA server (for microservice OAuth2 authentication)&#xA;</code></pre>&#xA;&#xA;<p>And I created a Microservicio Gateway:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? Microservice gateway&#xA;...&#xA;? (6/16) What is the folder path of your UAA application?. ../elseruaa&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li>I created the docker containers, in ""docker-compose"", and creates well.</li>&#xA;<li>I have to add some extra configuration on the gateway to work with the server UAA?</li>&#xA;<li><p>I get the following error trace in the container gateway:</p>&#xA;&#xA;<p><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration.setFilterChainProxySecurityConfigurer(org.springframework.security.config.annotation.ObjectPostProcessor,java.util.List) throws java.lang.Exception; nested exception is org.springframework.beans.factory.BeanExpressionException: Expression parsing failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.springframework.security.oauth2.provider.token.TokenStore org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration.tokenStore; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tokenStore' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.TokenStore]: Factory method 'tokenStore' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jwtAccessTokenConverter' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter]: Factory method 'jwtAccessTokenConverter' threw exception; nested exception is java.lang.IllegalStateException: No instances available for elseruaa...</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you very much for your help.</p>&#xA;"
44946517,Unable to get jhipster gateway home page,2017-07-06 10:34:22,<angular><jhipster><microservices>,2,390,1,0.0,3,<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in application-dev.yml)&#xA;There is no errors in console.</p>&#xA;&#xA;<p><code>index.html</code> completely loading may be routing is not working fine.</p>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is provided by yarn) </p>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other micro services applications.</p>&#xA;
44988481,Spring Cloud - how to allow access to endpoint for specific microservice only?,2017-07-08 16:42:24,<spring><oauth-2.0><microservices><spring-cloud>,2,286,4,1.0,3,"<p>I have simple microservice architecture:</p>&#xA;&#xA;<ul>&#xA;<li>edge service</li>&#xA;<li>service registry</li>&#xA;<li>auth service (I am using JWT and OAuth2)</li>&#xA;<li>user service</li>&#xA;<li>frontend and some core services</li>&#xA;</ul>&#xA;&#xA;<p>When the user tries to log in, the credentials are passing from edge service to auth service. Auth service fetches user's data from user service (using <strong>@FeignClient</strong>) and if username/password matches, it generates token. Nothing fancy about it.</p>&#xA;&#xA;<p>There a 'little' problem with this approach: the endpoint <code>/api/user/{username}</code> in user service, which is used by auth service to fetch user's data, might be used by any user to get any other user's data (password, roles etc.). The one solution would be somehow create JWT token for auth-service with role <code>AUTH_SERVICE</code> and at the user service side check JWT and if the role is different than <code>AUTH_SERVICE</code> reject the request.</p>&#xA;&#xA;<p>Are there any other solutions?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>I thought that my design is quite common but apparently I should have been more specific in the first place:</p>&#xA;&#xA;<ul>&#xA;<li>Auth-servie is my Authorization Server and the other services are Resource servers</li>&#xA;<li>I use API gateway pattern and my auth-service is also behin proxy</li>&#xA;<li>After the client application obtains JWT it adds it to every request and based on that the authentication and authorization is performed; every Resource server has a public key which is used to verify signature; if it's valid, the service knows that JWT has been generated by trusted auth-service and the service based on JWT creates OAuth2Authenication object which contains all the user information</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT2:</strong></p>&#xA;&#xA;<p>I ended up merging auth-service to user-service, which was the suggestion given from a couple of SO users. After thinking about it it seemed unnecessary to have a seperate auth-service for just JWT generation. I've accepted @Abhijit Sarkar answer because it has some valid points even though he wasn't right about additional call to auth-service to verify validity of the token.</p>&#xA;"
48824086,Keycloak: AnonymousAuthenticationToken cannot be cast to KeycloakAuthenticationToken,2018-02-16 09:53:19,<java><spring><spring-security><microservices><keycloak>,6,1064,0,0.0,3,"<p>I am developing a microservice infrastructure based on Spring Cloud. I want to secure the application with Keycloak, which is basically working fine if the user is authenticated. </p>&#xA;&#xA;<p>If the user is not authenticated Keycloak throws the folling error:</p>&#xA;&#xA;<pre><code>java.lang.ClassCastException: org.springframework.security.authentication.AnonymousAuthenticationToken cannot be cast to org.keycloak.adapters.springsecurity.token.KeycloakAuthenticationToken&#xA;at org.keycloak.adapters.springsecurity.facade.SimpleHttpFacade.getSecurityContext(SimpleHttpFacade.java:63) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.corsRequest(AuthenticatedActionsHandler.java:102) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.handledRequest(AuthenticatedActionsHandler.java:54) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:78) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakSecurityContextRequestFilter.doFilter(KeycloakSecurityContextRequestFilter.java:79) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:82) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakPreAuthActionsFilter.doFilter(KeycloakPreAuthActionsFilter.java:84) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractAuthenticatedActionsValve.invoke(AbstractAuthenticatedActionsValve.java:67) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:595) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractKeycloakAuthenticatorValve.invoke(AbstractKeycloakAuthenticatorValve.java:181) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;</code></pre>&#xA;&#xA;<p>The security config looks as follows:</p>&#xA;&#xA;<pre><code>@KeycloakConfiguration&#xA;public class SecurityConfig extends KeycloakWebSecurityConfigurerAdapter&#xA;{&#xA;    private final KeycloakClientRequestFactory keycloakClientRequestFactory;&#xA;&#xA;    public SecurityConfig(KeycloakClientRequestFactory keycloakClientRequestFactory)&#xA;    {&#xA;        this.keycloakClientRequestFactory = keycloakClientRequestFactory;&#xA;    }&#xA;&#xA;    /**&#xA;   * define the actual constraints of the app.&#xA;   * @param http&#xA;   * @throws Exception&#xA;   */&#xA;  @Override&#xA;  protected void configure(HttpSecurity http) throws Exception&#xA;  {&#xA;      super.configure(http);&#xA;      http&#xA;      .cors()&#xA;      .and()&#xA;      .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)&#xA;      .sessionAuthenticationStrategy(sessionAuthenticationStrategy())&#xA;      .and()&#xA;      .authorizeRequests()&#xA;          .antMatchers(""/*"").hasRole(""user"")&#xA;          .anyRequest().permitAll();&#xA;  }&#xA;&#xA;    /**&#xA;     * define the session auth strategy so that no session is created&#xA;     * &#xA;     * @return concrete implementation of session authentication strategy&#xA;     */&#xA;    @Bean&#xA;    @Override&#xA;    protected SessionAuthenticationStrategy sessionAuthenticationStrategy()&#xA;    {&#xA;        return new NullAuthenticatedSessionStrategy();&#xA;    }&#xA;&#xA;    /**&#xA;     * registers the Keycloakauthenticationprovider in spring context and sets its&#xA;     * mapping strategy for roles/authorities (mapping to spring seccurities'&#xA;     * default ROLE_... for authorities ).&#xA;     * &#xA;     * @param auth&#xA;     *          SecurityBuilder to build authentications and add details like&#xA;     *          authproviders etc.&#xA;     * @throws Exception&#xA;     */&#xA;    @Autowired&#xA;    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception&#xA;    {&#xA;        KeycloakAuthenticationProvider keyCloakAuthProvider = keycloakAuthenticationProvider();&#xA;        keyCloakAuthProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper());&#xA;&#xA;        auth.authenticationProvider(keyCloakAuthProvider);&#xA;    }&#xA;&#xA;    /**&#xA;     * Sets keycloaks config resolver to use springs application.properties&#xA;     * instead of keycloak.json (which is standard)&#xA;     * &#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public KeycloakConfigResolver KeyCloakConfigResolver()&#xA;    {&#xA;        return new KeycloakSpringBootConfigResolver();&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakAuthenticationProcessingFilterRegistrationBean(&#xA;            KeycloakAuthenticationProcessingFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakPreAuthActionsFilterRegistrationBean(KeycloakPreAuthActionsFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions would be much apprechiated.</p>&#xA;&#xA;<p>Kind regards&#xA;Blacky</p>&#xA;"
48873507,Caching in a Microservices architecture,2018-02-19 20:14:02,<microservices>,1,589,0,0.0,3,"<p>In the <strong>API Gateway</strong> a caching feature can be implemented to reduce access time and bandwidth usage.<br>&#xA;What kind of data are cached in the gateway? <br>&#xA;In a <em>micro-services architecture</em>, does a gateway cache the discovered services descriptions ? if so, how he maintains the consistency of his cache?</p>&#xA;"
48963386,"Microservices, REST, event sourcing and data consistency",2018-02-24 13:29:08,<rest><apache-kafka><domain-driven-design><microservices><event-sourcing>,1,246,1,0.0,3,"<p>I'm planning a model for microservices using event sourcing. To achieve a high scalability and high throughput handling capacity, I'll use Kafka as a message broker for the microservices.</p>&#xA;&#xA;<p>At this point, I have questions about the implementation of the model to be able to have the benefits of Kafka topic and partition. There are some requirements that my model needs to fit:</p>&#xA;&#xA;<ol>&#xA;<li>Microservices must ingest data from the message broker (POST/PATCH/PUT/DELETE)</li>&#xA;<li>Data consistency is mandatory, if entity A needs previous existence of entity B, then must exists only records of entity A that points to valid records of entity B</li>&#xA;<li>The microservices can't couple their domains (refering to DDD)</li>&#xA;<li>The system must handle high thrgoughput of read and writes operations</li>&#xA;</ol>&#xA;&#xA;<p>Well, with this requirements in mind, I've endend up with a model that:</p>&#xA;&#xA;<ol>&#xA;<li>Use an Elasticsearch database that have the current valid state</li>&#xA;<li>All write requests are received by a ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Validate the request and the new state that is requested</li>&#xA;<li>Produce a write operation in the message broker</li>&#xA;<li>Receives state change events from the message broker</li>&#xA;<li>Responds to requester with the new state changed</li>&#xA;</ol></li>&#xA;<li>All write operations are consumed by a ""Microservice Processor"" that:&#xA;&#xA;<ol>&#xA;<li>Handles all the business logic and data denormalization</li>&#xA;<li>Updates the state in the Elasticsearch database</li>&#xA;<li>Produce a state change event in the message broker</li>&#xA;</ol></li>&#xA;<li>All read requests are handled by the ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Searchs at the Elasticsearch database for the requested resource's records</li>&#xA;<li>Responds to the requester with the results</li>&#xA;</ol></li>&#xA;</ol>&#xA;&#xA;<p>My questions:</p>&#xA;&#xA;<ol>&#xA;<li>This model does some coupling of the domains? The Gateway is validating subresources ID's to ensure data consistency in one Elasticsearch database (the case of A pointing to B).</li>&#xA;<li>I don't know if this model fits reports requests, there are some complex reports that process a lot of data with input parameters from the user and from his point of view, the operation must be ""synchronous"" (request/response REST)</li>&#xA;<li>Is the validation of requests/new state a part of the business logic (related to DDD)? If so, my model is incorret to separate them into two microservices?</li>&#xA;</ol>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>My new proposal for my client:</p>&#xA;&#xA;<ol>&#xA;<li>Instead of having a gateway acting as a part of the microservice, let gateway only for: routing (microservice registry), balancing and auth stuffs (calling a dedicated microservice for authentication/authorization)</li>&#xA;<li>The microservices hold their own data/database, consistency is ensured by event sourcing architeture</li>&#xA;<li>Reports: if it's about one domain, can be a resource at the microservice that holds the data, if more than one domain is required, another microservice will provide the report</li>&#xA;</ol>&#xA;"
48921774,Microservices unsuitable for business domain?,2018-02-22 07:28:39,<database><domain-driven-design><microservices><distributed-computing><soa>,2,80,2,1.0,3,"<p>The business domain has five high-level bounded contexts</p>&#xA;&#xA;<ul>&#xA;<li>Customers</li>&#xA;<li>Applications</li>&#xA;<li>Documents</li>&#xA;<li>Decisions</li>&#xA;<li>Preforms</li>&#xA;</ul>&#xA;&#xA;<p>Further, these bounded contexts has sub-contexts like ordering and delivery of the documents. Despite the project of consisting ten of thousands of classes and dozens of EJB's, most of the business logic resides in relational database views and triggers for a reason: A lot of joins, unions and constraints involved in all business transactions. In other words, there is complex web of dependencies and constraints between the bounded contexts, which restricts the state transfers. In layman terms: the business rules are very complicated.</p>&#xA;&#xA;<p>Now, if I were to split this monolith to database per service microservices architecture, bounded contexts being the suggested service boundaries, I will have to implement all the business logic with explicit API calls. I would end up with hundreds of API's implementing all these stupid little business rules. As the performance is main factor (we use a lot of effort to optimize the SQL as it is now), this is out of the question. Secondly, segregated API's would probably be nightmare to maintain in this web of ever evolving business rules, where as database triggers actually support the high cohesion and DRY mentality, enforcing the business rules transparently.</p>&#xA;&#xA;<p>I came up with a conclusion microservice architecture being unsuitable for this type of document management system. Am I correct, or approaching the idea from wrong angle?</p>&#xA;"
36832219,How to use redis for number of micro-services?,2016-04-25 04:51:34,<caching><redis><microservices>,3,4406,0,1.0,3,"<p>I am very much new to redis. I have been investigating on redis for past few days.I read the documentation on cache management(lru cache), commands ,etc. I want to know how to implement caching for multiple microservice(s) data .&#xA;I have few questions:</p>&#xA;&#xA;<ol>&#xA;<li>Can all microservices data(cached) be kept under a single instance of redis&#xA;    server?</li>&#xA;<li><p>Should every microservice have its own cache database in redis?</p></li>&#xA;<li><p>How to refresh cache data without setting EXPIRE? Since it would consume more memory.</p></li>&#xA;</ol>&#xA;&#xA;<p>Some more information on best practices on redis with microservices will be helpful.</p>&#xA;"
36642718,Two microservices for read and write to one database table,2016-04-15 09:01:05,<architecture><microservices>,2,1649,0,1.0,3,"<p>I'm a little bit confused about the microservice best practice approach. </p>&#xA;&#xA;<p>Following scenario:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Massive incoming messages from mqtt devices. A rest api where customers could read the messages (mostly only a part of them).</p>&#xA;</blockquote>&#xA;&#xA;<p>My idea was, to create one microservice for storing the messages in a database table. And a second microservice with a rest api to read this messages.&#xA;I want to do this, because of scaling issues. (The incoming storing part needs much more power, than the reading rest api)</p>&#xA;&#xA;<p>I read that the ""perfect"" microservice should be the only one, who accesses his data in a database. So other microservices should ask for this data, via its API and not on database level.&#xA;So my approach would be not the perfect one. I see a few options to handle this:</p>&#xA;&#xA;<ul>&#xA;<li>only one mircroservice, for storing and reading</li>&#xA;<li>making an api in the storing microservice, where the rest microservice could fetch the data.</li>&#xA;</ul>&#xA;&#xA;<p>But all of them, doesn't look good for me. </p>&#xA;&#xA;<p>Whats your opinion?</p>&#xA;&#xA;<p>Regards,&#xA;Markus</p>&#xA;"
36615117,microservice messaging db-assigned identifiers,2016-04-14 06:15:30,<microservices><spring-cloud-stream>,2,154,0,2.0,3,"<p>The company I work for is investigating moving from our current monolithic API to microservices. Our current API is heavily dependent on spring and we use SQL server for most persistence. Our microservice investigation is leaning toward spring-cloud, spring-cloud-stream, kafka, and polyglot persistence (isolated database per microservice). </p>&#xA;&#xA;<p>I have a question about how messaging via kafka is typically done in a microservice architecture. We're planning to have a coordination layer between the set of microservices and our client applications, which will coordinate activities across different microservices and isolate clients from changes to microservice APIs. Most of the stuff we've read about using spring-cloud-stream and kafka indicate that we should use streams at the coordination layer (source) for resource change operations (inserts, updates, deletes), with the microservice being one consumer of the messages. </p>&#xA;&#xA;<p>Where I've been having trouble with this is inserts. We make heavy use of database-assigned identifiers (identity columns/auto-increment columns/sequences/surrogate keys), and they're usually assigned as part of a post request and returned to the caller. The coordination layer may be saving multiple things using different microservices and often needs the assigned identifier from one insert before it can move on to the next operation. Using messaging between the coordination layer and microservices for inserts makes it so the coordination layer can't get a response from the insert operation, so it can't get the assigned identifier that it needs. Additionally, other consumers on the stream (i.e. consumers that publish the data to a data warehouse) really need the message to contain the assigned identifier.</p>&#xA;&#xA;<p>How are people dealing with this problem? Are database-assigned identifiers an anti-pattern in microservices? Should we expose separate microservice endpoints that return database-assigned identifiers so that the coordination layer can make a synchronous call to get an identifier before calling the asynchronous insert? We could use UUIDs but our DBAs hate those as primary keys, and they couldn't be used as an order number or other user-facing generated ids.</p>&#xA;"
36705199,Lock a Service-Bus Queue and prevent others from accessing it,2016-04-18 22:12:03,<c#><azureservicebus><microservices>,4,541,5,1.0,3,"<p>I have multiple queues that multiple clients insert messages into them.</p>&#xA;&#xA;<p>On the server side, I have multiple micro-services that access the queues and handle those messages. I want to lock a queue whenever a service is working on it, so that other services won't be able to work on that queue.</p>&#xA;&#xA;<p>Meaning that if service A is processing a message from queue X, no other service can process a message from that queue, until service A has finished processing the message. Other services can process messages from any queue other than X.</p>&#xA;&#xA;<p>Does anyone has an idea on how to lock a queue and prevent others from accessing it? preferably the other services will receive an exception or something so that they'll try again on a different queue.</p>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>Another way can be to assign the queues to the services, and whenever a service is working on a queue no other service should be assigned to the queue, until the work item was processed. This is also something that isn't easy to achieve.</p>&#xA;"
44495957,docker microservice apps restart over and over again in kubernetes,2017-06-12 09:29:14,<docker><kubernetes><microservices>,1,422,9,0.0,3,"<p>I am trying to run microservice applications with kubernetes. I have rabbitmq, elasticsearch and eureka discovery service running on kubernetes. Other than that, I have three microservice applications. When I run two of them, it is fine; however when I run the third one they all began restarting over and over again without any reason.</p>&#xA;&#xA;<p>One of my config files:</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: hrm&#xA;  labels:&#xA;    app: suite&#xA;spec:&#xA;  type: NodePort&#xA;  ports:&#xA;    - port: 8086&#xA;      nodePort: 30001&#xA;  selector:&#xA;    app: suite&#xA;    tier: hrm-core&#xA;---&#xA;apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: hrm&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: suite&#xA;        tier: hrm-core&#xA;    spec:&#xA;      containers:&#xA;      - image: privaterepo/hrm-core&#xA;        name: hrm&#xA;        ports:&#xA;        - containerPort: 8086&#xA;      imagePullSecrets:&#xA;      - name: regsecret&#xA;</code></pre>&#xA;&#xA;<p>Result from kubectl describe pod hrm:</p>&#xA;&#xA;<pre><code> State:     Running&#xA;      Started:      Mon, 12 Jun 2017 12:08:28 +0300&#xA;    Last State:     Terminated&#xA;      Reason:       Error&#xA;      Exit Code:    137&#xA;      Started:      Mon, 01 Jan 0001 00:00:00 +0000&#xA;      Finished:     Mon, 12 Jun 2017 12:07:05 +0300&#xA;    Ready:      True&#xA;    Restart Count:  5&#xA;  18m       18m     1   kubelet, minikube               Warning     FailedSync  Error syncing pod, skipping: failed to ""StartContainer"" for ""hrm"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=hrm pod=hrm-3288407936-cwvgz_default(915fb55c-4f4a-11e7-9240-080027ccf1c3)""&#xA;</code></pre>&#xA;&#xA;<p>kubectl get pods:</p>&#xA;&#xA;<pre><code>NAME                        READY     STATUS    RESTARTS   AGE&#xA;discserv-189146465-s599x    1/1       Running   0          2d&#xA;esearch-3913228203-9sm72    1/1       Running   0          2d&#xA;hrm-3288407936-cwvgz        1/1       Running   6          46m&#xA;parabot-1262887100-6098j    1/1       Running   9          2d&#xA;rabbitmq-279796448-9qls3    1/1       Running   0          2d&#xA;suite-ui-1725964700-clvbd   1/1       Running   3          2d&#xA;</code></pre>&#xA;&#xA;<p>kubectl version:</p>&#xA;&#xA;<pre><code>Client Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.4"", GitCommit:""d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae"", GitTreeState:""clean"", BuildDate:""2017-05-19T18:44:27Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.0"", GitCommit:""fff5156092b56e6bd60fff75aad4dc9de6b6ef37"", GitTreeState:""dirty"", BuildDate:""2017-04-07T20:43:50Z"", GoVersion:""go1.7.1"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;</code></pre>&#xA;&#xA;<p>minikube version:</p>&#xA;&#xA;<pre><code>minikube version: v0.18.0&#xA;</code></pre>&#xA;&#xA;<p>When I look at pod logs, there is no error. It seems like it starts without any problem. what could be the problem here?</p>&#xA;&#xA;<p>edit: output of kubectl get events:</p>&#xA;&#xA;<pre><code>19m        19m         1         discserv-189146465-lk3sm    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Created                   kubelet, minikube       Created container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Started                   kubelet, minikube       Started container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Pulled                    kubelet, minikube       Container image ""elasticsearch:2.4"" already present on machine&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Created                   kubelet, minikube       Created container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Started                   kubelet, minikube       Started container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned hrm-3288407936-d2vhh to minikube&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Created                   kubelet, minikube       Created container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Started                   kubelet, minikube       Started container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936              ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: hrm-3288407936-d2vhh&#xA;18m        18m         1         hrm                         Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set hrm-3288407936 to 1&#xA;19m        19m         1         minikube                    Node                                     Normal    RegisteredNode            controllermanager       Node minikube event: Registered Node minikube in NodeController&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kubelet, minikube       Starting kubelet.&#xA;19m        19m         1         minikube                    Node                                     Warning   ImageGCFailed             kubelet, minikube       unable to find data for container /&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeAllocatableEnforced   kubelet, minikube       Updated Node Allocatable limit across pods&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientDisk     kubelet, minikube       Node minikube status is now: NodeHasSufficientDisk&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientMemory   kubelet, minikube       Node minikube status is now: NodeHasSufficientMemory&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasNoDiskPressure     kubelet, minikube       Node minikube status is now: NodeHasNoDiskPressure&#xA;19m        19m         1         minikube                    Node                                     Warning   Rebooted                  kubelet, minikube       Node minikube has been rebooted, boot id: f66e28f9-62b3-4066-9e18-33b152fa1300&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeNotReady              kubelet, minikube       Node minikube status is now: NodeNotReady&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kube-proxy, minikube    Starting kube-proxy.&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeReady                 kubelet, minikube       Node minikube status is now: NodeReady&#xA;8m         8m          1         minikube                    Node                                     Warning   SystemOOM                 kubelet, minikube       System OOM encountered&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned parabot-1262887100-r84kf to minikube&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;18m        18m         1         parabot-1262887100          ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: parabot-1262887100-r84kf&#xA;18m        18m         1         parabot                     Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set parabot-1262887100 to 1&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulling                   kubelet, minikube       pulling image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Created                   kubelet, minikube       Created container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Started                   kubelet, minikube       Started container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Created                   kubelet, minikube       Created container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Started                   kubelet, minikube       Started container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;</code></pre>&#xA;"
48279479,How to query in a Event Driven Microservice architecture?,2018-01-16 10:50:06,<microservices><cqrs><event-driven>,3,308,0,1.0,3,"<p>Let suppose the following simple UC based on a CQRS architecture:</p>&#xA;&#xA;<p>We have a backend managing a Business Object, let says a Movie.</p>&#xA;&#xA;<ul>&#xA;<li>This backend is composed of 2 Microservices: a CommandManager (Create/Update/Delete Movie) and a QueryManager (Query Movie)</li>&#xA;<li>We have a frontend that offer a web page for creating a new Movie and this action lead automatically to another web page describing the Movie. </li>&#xA;</ul>&#xA;&#xA;<p>A simple way to do that is:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend make a POST request to the CommandManager</li>&#xA;<li>The CommandManager write the new movies to the datastore and return the movie key</li>&#xA;<li>The frontend make a GET using this key to the QueryManager</li>&#xA;<li>The QueryManager looks for the Movie in the Datastore using the key and return it.</li>&#xA;<li>The frontend deliver the page with the Movie Information.</li>&#xA;</ul>&#xA;&#xA;<p>Ok, now I want to transform this UC in a more Event Driven way. Here is the new flow:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend write a Message in the BUS with the new movie information</li>&#xA;<li>The CommandManager listen the BUS and create the new movies in the datastore. Eventually, it publish a new message in the BUS specifying that a new Movie has been created.</li>&#xA;</ul>&#xA;&#xA;<p>At this point, the frontend is no more waiting for a response due to the fact that this kind of flow is asynchronous. How could we complete this flow in order to forward the user to the Movie Information Web page? We should wait that the creation process is done before querying the QueryManager. </p>&#xA;&#xA;<p>In a more general term, in a asynchronous architecture based on bus/event, how to execute Query used to provide information in a web page?</p>&#xA;"
48271960,Event Sourcing and dealing with data dependencies,2018-01-15 23:09:44,<apache-kafka><microservices><event-sourcing><distributed-system><distributed-transactions>,1,181,0,0.0,3,"<p>Given a REST API with the following operations resulting in events posted to Kafka:</p>&#xA;&#xA;<ul>&#xA;<li>AddCategory</li>&#xA;<li>UpdateCategory</li>&#xA;<li>RemoveCategory</li>&#xA;<li>AddItem (refers to a category by some identifier)</li>&#xA;<li>UpdateItem</li>&#xA;<li>RemoveItem</li>&#xA;</ul>&#xA;&#xA;<p>And an environment where multiple users may use the REST API at the same time, and the consumers must all get the same events. The consumers may be offline for an extended period of time (more than a day). New consumers may be added, and others removed.</p>&#xA;&#xA;<p>The problems:</p>&#xA;&#xA;<ul>&#xA;<li>Event ordering (only workaround single topic/partition?)&#xA;&#xA;<ol>&#xA;<li>AddItem before AddCategory, invalid category reference.</li>&#xA;<li>UpdateItem before AddCategory, used to be a valid reference, now invalid.</li>&#xA;<li>RemoveCategory before AddItem, category reference invalid.</li>&#xA;<li>....infinite list of other concurrency issues.</li>&#xA;</ol></li>&#xA;<li>Event Store snapshots for fast resync of restarted consumers&#xA;&#xA;<ol>&#xA;<li>Should there be a compacted log topic for both categories and items, each entity keyed by its identifier?</li>&#xA;<li>Can the whole compacted log topic be somehow identified as an offset?</li>&#xA;<li>Should there only be one one entry in the compacted log topic, and the data of it contain a serialized blob of all categories and items given an offset (would require single topic/partition).</li>&#xA;<li>How to deal with the handover from replaying the rendered entities event store to the ""live stream"" of commands/events? Encode offset in each item in the compacted log view, and pass that to replay from the live event log?</li>&#xA;</ol></li>&#xA;</ul>&#xA;&#xA;<p>Are there other systems that fit this problem better?</p>&#xA;"
48201224,Kafka AND REST for communication between microservices?,2018-01-11 06:45:16,<rest><architecture><apache-kafka><message-queue><microservices>,1,429,2,1.0,3,"<p>I am currently working on an architecture see below. First I'm not sure if this kind of architecture is called an <em>event-driven</em> or a <em>data-driven</em> architecture or maybe both.</p>&#xA;&#xA;<p>There some input messages are sent from the <strong>Frontend</strong> to <strong>T1</strong>. These messages are first validated, then collected and in the end evaluated.</p>&#xA;&#xA;<p>My current approach is to persist the raw messages with all meta information in <strong>MS A</strong>, the sorted collections in <strong>MS B</strong> and the evaluations in <strong>MS C</strong>. This separates the data to the appropriately concerned microservices.  </p>&#xA;&#xA;<p>In <strong>T2</strong> I only produce the messages which <strong>MS B</strong> requires.<br>&#xA;In <strong>T3</strong> I only produce the messages which <strong>MS C</strong> requires.<br>&#xA;But when evaluation the collections all meta information from <strong>MS A</strong> is required. So how to proceed with this kind?</p>&#xA;&#xA;<ol>&#xA;<li>Should I send only the minimum of data to the queue and provide an API?</li>&#xA;<li>Should I send all data to the queues (forward data for following services)?</li>&#xA;<li>Should I send all information for the next service to the queue and provide an API?</li>&#xA;<li>Something else?</li>&#xA;</ol>&#xA;&#xA;<p>Or did I misunderstand the approach ""Communicating microservices through Kafka""?</p>&#xA;&#xA;<p>Please feel free to offer criticism!<br>&#xA;Thanks for advice!</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/BgT2M.png"" height=""500""/></p>&#xA;"
44124914,How to deploy multiple version of an application in production for microservice based application,2017-05-23 02:40:41,<api><amazon-web-services><elastic-beanstalk><microservices><production-environment>,4,920,0,3.0,3,"<p><br/>&#xA;Is it possible to have multiple versions of service(s) deployed in production at the same time. From my assumption, this should be pretty common pattern for microservice/api based projects or mobile projects. I want to know how do you do it and what are common pattern in industry for this kind of problems. It would be helpful if your answers around AWS environment or Kubernetes environment.&#xA;<br/>Thanks in Advance.</p>&#xA;"
44183595,Java - Kubernetes find services by label,2017-05-25 14:54:26,<java><spring-boot><kubernetes><spring-cloud><microservices>,2,436,0,3.0,3,"<p>I'm trying to develop a sample application using spring cloud and minikube which consist of 3 spring boot applications.</p>&#xA;&#xA;<p>The first two are two different application (servers) which have the same endpoint but different functionality, and the third one is a client used to integrates the two other applications into one single exposed api.</p>&#xA;&#xA;<p>I managed to deploy all three applications in minikube and managed to develop the full stack and make them communicate between each other, but now I want to go a step further and make the discovery of the two servers automatically, without hard coding the service names.</p>&#xA;&#xA;<p>I deployed the two servers in minikube using the same label and would like to find something so that the client is able to find the services related to the two server apps automatically. This will allow expanding the application easily, so that when I add a new server to the stack the client will find it and expose it without need of any change.</p>&#xA;&#xA;<p>Using Netflix Eureka this can be easily achieved by using something like </p>&#xA;&#xA;<pre><code>discoveryClient.getInstances(""service-name"").forEach((ServiceInstance s)&#xA;</code></pre>&#xA;&#xA;<p>But I do no want to add an extra eureka server to the list of microservices since we are going to use kubernetes.</p>&#xA;&#xA;<p>Is there any library which gives this functionality for kubernetes?</p>&#xA;"
35743527,Microservice with own UI with Spring and Thymleaf,2016-03-02 09:45:51,<spring><thymeleaf><microservices><ssi>,2,590,7,0.0,3,"<p>I have three web application microservices and one gateway that include the UI. So, what i want to do is to change the app's that every microservice has his own UI and the gateway should make server side includes. Im using Thymeleaf as template engine and do the includes like this: </p>&#xA;&#xA;<p><code>&lt;div th:replace=""http://localhost:8080/#/organizations""&gt;&lt;/div&gt;</code></p>&#xA;&#xA;<p>My Problem is that the CSS and JS files are not Included from the original localhost:8080 server rather from the server with includes the content localhost:9090.</p>&#xA;&#xA;<p>This is how i include the JS and CSS files at *:8080:</p>&#xA;&#xA;<p><code>&lt;script th:src=""@{webjars/jquery/$jquery.version$/jquery.min.js}""&lt;/script&gt;</code></p>&#xA;&#xA;<p>Hope you understand my problem and someone can help...</p>&#xA;"
46386326,Backing Services as attached resources,2017-09-24 03:32:03,<spring-boot><cloud><microservices><cloudfoundry><12factor>,1,126,0,0.0,3,"<p>I was looking at 12 factor app principle and saw this statement. I believe this statement states that the application must respond to any backing service such database or message broker and connect to them irrespective of what they are. How does it differ from traditional way of connecting? For eg: in my microservice , I was defined database and kafka broker as user provided service in cloud foundry. It just provides the connection parameters as vcap service variables. I still have code to connect to a database and kafka broker which are entirely different. What does this statement signify and how does it differ from what we do in non-cloud environment?</p>&#xA;"
46404449,Micro service architecture for Angular2,2017-09-25 11:44:49,<angular><design-patterns><architecture><microservices>,1,657,4,2.0,3,"<p>If we take an enterprise  angular 2 web app it has several modules(screens) such as Customer management, Reservations, Booking management, Reporting and etc....</p>&#xA;&#xA;<p>What we normally do is we create common components in a component library and use them on main angular application. The main angular app contains all the modules(screens) with REST API integrations(assuming backed is REST). When app is getting bigger &amp; bigger compile time and rendering consuming more time &amp; resources. Also if one particular area is having a issue we cannot have a release since all are bundle to one app.</p>&#xA;&#xA;<p>As you all know <strong>Micro service architecture</strong> is a method of developing software systems that has grown in popularity. So, my question is can we apply same architecture for these type of enterprise angular 2 apps?. </p>&#xA;&#xA;<p>It is like this. We have a customer management as a separate angular app. Again Booking management is another angular app. Reporting is another app. These apps are going to be separate war files when deploying to the web server. </p>&#xA;&#xA;<p>Once we have developed such loosely coupled apps this will reduce the over head of project size, compile time &amp; resources. Also this will make unit testing more easier. Particular set of developers are only considering the only one unit of the module.</p>&#xA;&#xA;<p>Kindly share your expert thoughts about this</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46471625,Multiple microservice symfony application share vendor folder,2017-09-28 14:27:00,<php><symfony><composer-php><share><microservices>,2,314,5,1.0,3,"<p>We are working on a new web project, with a microservice architecture.</p>&#xA;&#xA;<p>We will need around 5 Front Web project, and about 5 API microservice orchestrate with an API manager.</p>&#xA;&#xA;<p>We plan to use Symfony2 Framework, but I think it will be too Heavy. I mean because by the instance of the composer that will download all around the same library from symfony component, core... and same library used for each project (phpmailer for example).</p>&#xA;&#xA;<p>Actually, I was asking myself about a great sharing strategy for the vendor folder assuming that each SF2 project would use a share vendor folder and compute all library in a unique folder.&#xA;We need all the same version for each library in each project.</p>&#xA;&#xA;<p>Does somebody have some experiment on this kind of sharing? Best practices? Is it preferable to have one vendor folder per project? </p>&#xA;&#xA;<p>Open discution !</p>&#xA;&#xA;<p>Cheers.</p>&#xA;"
41008507,Is there an established pattern for paging in Service Fabric ReliableCollections,2016-12-07 02:36:18,<azure><microservices><azure-service-fabric><service-fabric-stateful>,2,403,0,2.0,3,"<p>In reliable collections (specifically IReliableDictionary), an approach for implementing 'common' queries is to update a secondary dictionary which structures the keys to be ordered a specific way in an enumeration.  For large data sets, <strong>I would like to avoid shuttling a large amount of data around</strong>.  </p>&#xA;&#xA;<p>To achieve this I would like to <strong>implement some sort of continuation token</strong> which the caller can supply to me when requesting the data.  I am currently implementing this by first generating an ordered enumeration and returning the first n items where n = the MAX_PAGE size.   <strong>The continuation is essentially the last key in that list of n items</strong>. The next time the caller passes in the continuation token, <strong>I generate the ordered enumerable with the filter function specifying that the key should be greater than the continuation</strong>.  </p>&#xA;&#xA;<p>This has 2 problems (that I can see):</p>&#xA;&#xA;<ol>&#xA;<li>The <strong>collection could change between when the caller first requests a page and a subsequent request</strong>.  This, I'm not certain I can avoid since updates to the collection need to be able to occur at any time regardless of who is attempting to page through the data.</li>&#xA;<li>I'm not certain how the filter function is used. I would assume that since a developer could filter on anything, the <strong>GetEnumerableAsync() method must supply all keys in the dictionary before returning the enumerable</strong>.  For a sufficiently large data set, this seems slow.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Are there any prescribed approaches for paging data like this?</strong>  I am beginning to feel like I might be barking up the wrong tree with Reliable Collections for some of my use cases.  </p>&#xA;"
40932850,Mongodb IsoDate and the issue with if-modified-since on microservices,2016-12-02 13:00:42,<java><mongodb><microservices>,1,170,2,1.0,3,"<p>When I insert a document on my MongoDB using spring data, I do the following:</p>&#xA;&#xA;<pre><code>Update update = new Update();&#xA;update.currentDate(""lastModified"");&#xA;mongoTemplate.upsert(query, update, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>I'm using the currentDate of MongoDB, because I want to save the date that MyDocument was last modified with the date where my MongoDB database is located. </p>&#xA;&#xA;<p>Based on the <a href=""https://www.ietf.org/rfc/rfc2616.txt"" rel=""nofollow noreferrer"">spec</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>The If-Modified-Since request-header field is used with a method to&#xA;     make it conditional: if the requested variant has not been modified&#xA;     since the time specified in this field, an entity will not be&#xA;     returned from the server; instead, a 304 (not modified) response will&#xA;     be returned without any message-body.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, the purpose of saving this date is to verify if MyDocument was modified or not based on the received date.</p>&#xA;&#xA;<p>So, when I execute the update, the following IsoDate is created on the database:</p>&#xA;&#xA;<pre><code>ISODate(""2016-12-02T12:11:33.083Z"")&#xA;</code></pre>&#xA;&#xA;<p>So, when a client wants to know if the document has changed, they send me back this date, and I query on the database:</p>&#xA;&#xA;<pre><code>    Query query = new Query(where(""id"").is(filter.getId()));&#xA;    Criteria criteria = Criteria.where(""lastModified"").gt(filter.getLastModified());&#xA;    query.addCriteria(criteria);&#xA;    return mongoTemplate.findOne(query, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>This works perfectly, except for one problem: The spec says that the header if-modified-since has the following format:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT</p>&#xA;</blockquote>&#xA;&#xA;<p>Which means that the milliseconds is not passed on the if-modified-since header. However, MongoDB IsoDate saves the current date with milliseconds. So, when two dates are exactly the same, the query will not return 304 Not Modified, but it will return the entire resource, because the query will be the following:</p>&#xA;&#xA;<pre><code>{ ""id"" : 123, ""lastModified"" : { ""$gt"" : { $java : 2016-12-02T12:11:39.000Z } } }&#xA;</code></pre>&#xA;&#xA;<p>Since the client does not send the milliseconds, the java put the milliseconds as zeros ( 2016-12-02T12:11:39.<strong>000</strong>Z), which means that &#xA;the date on my database is greater than the date sended by my client:</p>&#xA;&#xA;<p>2016-12-02T12:11:33.083Z > 2016-12-02T12:11:39.000Z </p>&#xA;&#xA;<p>Because of the 83 milliseconds. </p>&#xA;&#xA;<p><strong>The final question is</strong>: What it is the correct way to solve this problem, and work correctly as the specs for if-modified-since suggests?</p>&#xA;"
40890804,Register MicroServices in Azure Active Directory (AAD) for Security,2016-11-30 14:24:14,<azure><asp.net-web-api><owin><azure-active-directory><microservices>,1,654,4,0.0,3,"<p>I have a service fabric application (Stateless and Statefull) deployed in Service fabric cluster. I am trying to implement security in the applications. The application uses the Active Directory Authentication Library (ADAL) to get a token from Azure AD using the OAuth 2.0 client credential flow, where the client credential is a password. I am able to implement the same scenario in ordinary web api applications by registering them in Azure portal. Can anyone tell me how to register a service fabric microservice application with WebApi exposed using Owin. i have difficulties registering the reply url and sign on url as the urls are dynamic(for statefull partitionid and replica id). I receive unauthorized access while calling the corresponding service. I am not sure of what url has to be registered for a statefull or stateless application when adding the application in in azure active directory. Could you please suggest me where I'm wrong and what to do to implement.</p>&#xA;"
50312750,How can I keep databases of two web applications in sync?,2018-05-13 04:23:50,<java><sql-server><microservices><database-trigger>,2,65,0,0.0,3,"<p>I have two webapps, each with its own backend microservice and each microservice has its own database. For any changes in tables of database of microservice1, I want to change(create/update) entries in tables of database of microservice 2. How can I do that? </p>&#xA;&#xA;<h1>Context:</h1>&#xA;&#xA;<p><strong>Webapp 1:</strong> UI for human resource coordinators to schedule an interview. </p>&#xA;&#xA;<p><strong>Microservice 1:</strong> Backend service that schedules an interview.</p>&#xA;&#xA;<p><strong>DB for microservice 1:</strong> Stores information related to interview of a candidate. </p>&#xA;&#xA;<pre><code>  interviews: [ {&#xA;      ""interviewId"": ""1"",&#xA;      ""candidateId"": ""abc"",&#xA;      ""interviewers"": [&#xA;      {&#xA;         ""interviewer_name"": ""Thor"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      },&#xA;      {&#xA;         ""interviewer_name"": ""Loki"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      }&#xA;   ]&#xA;} ]&#xA;</code></pre>&#xA;&#xA;<p><strong>Webapp 2:</strong> UI for interviewers to coordinate on questions to ask in an interview. </p>&#xA;&#xA;<p><strong>Microservice 2:</strong> Backend service for interviewers to coordinate on question selection. i.e. each interviewer selects what question he/she is going to ask from a candidate in an interview (this is to ensure no two interviewers end up asking same question from a candidate).</p>&#xA;&#xA;<p><strong>DB for microservice 2:</strong> Schemas</p>&#xA;&#xA;<p>// QuestionBank : Table containing questions, that interviewers can select.</p>&#xA;&#xA;<p>// Interviewers : Table containing all interviewers in the firm.</p>&#xA;&#xA;<p>// InterviewToInterviewer : (many to many mapping of interviews with interviewers). One interview can have many interviewers, and each interviewer can participate in many interviews.</p>&#xA;&#xA;<p>// InterviewToInterviewerToQuestion :  (many to many mapping of interviewToInterviewers with questions). For each interview an Interviewer can select many questions and each of the question in a questionbank can be a part of many interviewToInterviewer entry.</p>&#xA;&#xA;<h1>Current Workflow:</h1>&#xA;&#xA;<p>As soon as interview is scheduled from webapp1:</p>&#xA;&#xA;<ol>&#xA;<li>An email is sent to all the interviewers. Email contains a link to a webapp 2, clicking on this link opens webapp2 that provides an interface for interviewers to select questions they plan to ask in an interview.</li>&#xA;</ol>&#xA;&#xA;<h1>Requirement:</h1>&#xA;&#xA;<ol>&#xA;<li><p>If the questions are not selected by interviewer, then I want to send reminders to them. For this I want webapp2 to know that an interview is scheduled. </p></li>&#xA;<li><p>I want webapp2 to know about any lineup changes (in a given interview, interviewer is changed or an interview is cancelled etc) that happens. </p></li>&#xA;</ol>&#xA;&#xA;<h1>Solutions I thought off:</h1>&#xA;&#xA;<ol>&#xA;<li><p>As soon as interview is scheduled/changed from webapp1, webapp1 will calls webapp2 (webapp2 exposes an API for that) to let webapp2 know that a new interview is created or an existing interview is updated. </p></li>&#xA;<li><p>For any new entry/update in interview table in DB1, a DB trigger is launched to DB2. I am not sure whether this is possible also. </p></li>&#xA;</ol>&#xA;&#xA;<p>Out of the two approaches above can someone help me with the pros and cons of one choosing over other. Or there is some other alternative approach to achieve this.</p>&#xA;&#xA;<p>Leads here are appreciated. </p>&#xA;"
50435696,Django admin + authentication system in microservice architecture,2018-05-20 14:13:20,<django><django-rest-framework><django-admin><microservices><django-apps>,1,165,0,1.0,3,"<p>I have a <strong>large</strong> Django project which is basically a monolith containing apps.&#xA;I need to break it to microservices.</p>&#xA;&#xA;<p>I have 2 questions that I couldn't find a clear answers to:</p>&#xA;&#xA;<ol>&#xA;<li><p>Currently we're using Django admin extensively and I wonder if it's&#xA;possible to continue using it once the monolith is broken. It means&#xA;reading and manipulating data from all the microservices in a ""used&#xA;to work on"" UI. It would also be helpful for this process to be done more smoothly.</p></li>&#xA;<li><p>Authentication and authorization - Would we still be able to use&#xA;this built in ""app"" in a microservice architecture? Is it possible&#xA;to take this pare only to another service and communicate with it&#xA;over HTTP?</p></li>&#xA;</ol>&#xA;"
50328886,How to setup nginx as reverse proxy for rest microservice in kubernetes?,2018-05-14 11:11:19,<docker><nginx><kubernetes><microservices>,3,125,2,2.0,3,<p>I have a rest microservice and would like to setup nginx as a reverse proxy for it. I am little confused about which approach to follow:</p>&#xA;&#xA;<ol>&#xA;<li>Run nginx in each pod where application code is running.</li>&#xA;<li>Run nginx in separate pods and redirect http requests to application code running in separate pods.</li>&#xA;</ol>&#xA;&#xA;<p>Can someone explain which one is better </p>&#xA;
43814764,Testing microservices?,2017-05-05 22:46:35,<testing><go><integration-testing><microservices>,3,437,1,0.0,3,<p>I know this question is a little subjective but I am lost on what to do here. At the moment I am using Go + Go-kit to write some microservices. I'd like to test the endpoints of these microservices in an integration test type fashion but I am unsure how to go about it. The only thing I can think of is to have shell scripts that hit the endpoints and check for responses. But this seems like kludge and not a real smart practice. I feel like there should be a better way to do this. Does anyone have any suggestions?</p>&#xA;
34301614,"Zuul url mapping with spring boot,Eureka",2015-12-15 23:47:42,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-zuul>,1,3960,3,1.0,3,<p>I am building Rest api using microservice architecture. I have multiple apis for user that we have made into multiple projects. I have everything else ready except I am not able to map the user facing url to the application url in zuul.</p>&#xA;&#xA;<p>The user facing url is : user/v1/accountholders/{id}/cards and the actual url for my application is /user-cards/v1/accountholders/{id}/cards. </p>&#xA;&#xA;<p>Here id is the path variable. Below are other similar api url so if there is a way to configure them generically in zuul. Also the context root of the application url is also the project name in Eureka.</p>&#xA;&#xA;<pre><code>Other similar urls are:&#xA;&#xA;client side:- /user/v1/accountholders/{id}/cards/{cardid}&#xA;application:- /user-cards/v1/accountholders/{id}/cards/{cardid}&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders/{id}&#xA;application:- /user-cardholder/v1/accountholders/{id}&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts/{accid}&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts/{accid}&#xA;</code></pre>&#xA;&#xA;<p>Need some help to set this up in the properties or yml file for zuul. I havent been able to make any progress with the mapping stuff yet. Any inputs will be helpful.</p>&#xA;&#xA;<p><strong>SOLVED:-</strong>&#xA;After getting the input from @Daniel (which is the accepted answer)This is what i used in zuul config:-</p>&#xA;&#xA;<pre><code>zuul:&#xA; routes:&#xA;   User-Cards: &#xA;        path: /user/v1/accountholders/*/cards/**&#xA;        url: http://desktop-uvkv1ed:9999/user-cards/v1/accountholders&#xA;   User-Transactions1: &#xA;        path: /user/v1/accountholders/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Transactions2:  &#xA;        path: /user/v1/accountholders/*/accounts/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Accounts: &#xA;        path: /user/v1/accountholders/*/accounts/**&#xA;        url: http://desktop-uvkv1ed:7777/user-accounts/v1/accountholders&#xA;   User-Cardholders: &#xA;        path: /user/v1/accountholders/**&#xA;        url: http://desktop-uvkv1ed:8888/user-cardholders/v1/accountholders&#xA;</code></pre>&#xA;
37243939,How to initialize a postgres database tables in microservice architecture with node running in docker,2016-05-15 21:39:56,<node.js><postgresql><docker><containers><microservices>,1,460,1,1.0,3,"<p>What is the best practice for initializing a node microservice's tables in a postgres database ? Should it be on service start ?</p>&#xA;&#xA;<p>I'm thinking of copying all the .sql files to the container (during docker build) + install psql into that container, and only run the .sql files during docker run before npm start. Does this make sense ?</p>&#xA;&#xA;<p>I need to consider the fact that soon I will need to manage upgrading the database's tables for the microservice as well.</p>&#xA;"
43529266,How to use Haskell Stack with Docker Compose?,2017-04-20 20:25:35,<haskell><docker><docker-compose><microservices><haskell-stack>,1,398,2,0.0,3,"<p>I am trying to use docker compose to tie together some haskell services for local development. Most of the time I'm messing around in <code>stack ghci</code>, running unit tests, etc, but I also need to be able to run code that hits a dependency. Docker compose is great for this: I can run the dependencies (databases, other services, etc), and link everything together. </p>&#xA;&#xA;<p>Stack has docker support. It can build in a docker container with <code>docker: enable: true</code>, and also can create an executable image with <code>stack image container</code>.</p>&#xA;&#xA;<p>How do I leverage stack's docker functionality from within <code>docker-compose.yml</code>? </p>&#xA;&#xA;<pre><code>version: ""3""&#xA;&#xA;services:&#xA;&#xA;  my-service:&#xA;&#xA;    # how can I use `stack image container` here? Is it possible?&#xA;    build: '.'&#xA;&#xA;    links:&#xA;    - other-service&#xA;&#xA;    env_file:&#xA;    - test.env&#xA;&#xA;  other-service:&#xA;    image: other-service-image&#xA;</code></pre>&#xA;&#xA;<p>Do I have to make my own Dockerfile, or is there some way to use the <code>stack image container</code> functionality?</p>&#xA;&#xA;<p>Follow-up questions: Is there some way to run <code>stack ghci</code> with all the settings (env, links, etc) from the docker compose file? </p>&#xA;"
43384538,Database location in Microservices Architecture,2017-04-13 05:57:03,<azure><docker><microservices>,3,361,4,0.0,3,"<p>We have a monolithic application which we are now converting to microservice architecture using containers. </p>&#xA;&#xA;<p>Our microservices are <em>stateful</em> (i.e they need to insert/retrieve data from db). As per microservice architecture, each microservice should have its own data (i.e database in our case).</p>&#xA;&#xA;<p>My question is that <strong>where</strong> the database of each microservice should be deployed, whether it should be in the same host in which the microservice is deployed, in the same container in which the microservice is deployed or it should be in the separate server like azure db or something?</p>&#xA;&#xA;<p>What would be the pros &amp; cons of each approach and what is the best approach according to microservice best practices?&#xA;*</p>&#xA;"
43396744,Microservices UI Frontend with Java and ReactJS Server Side Rendering,2017-04-13 15:52:36,<java><reactjs><microservices><serverside-rendering>,2,3077,9,3.0,3,"<p>My current design is to have clients connect to my (Java) Web API Gateway using a browser, the Web API Gateway will call each (Java) microservice to get their JSON data and return it to the UI component that made the request on the client. </p>&#xA;&#xA;<p>The only client side rendering will be from each ReactJS UI component for recurring requests to the gateway. </p>&#xA;&#xA;<p>On the server side the full HTML view will be rendered prior to being sent back to the client. </p>&#xA;&#xA;<pre><code>Client browser&#xA;&#xA;     ▼ (Request Dashboard View)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Request microservice JSON data)&#xA;&#xA;Microservice A JSON Data&#xA;Microservice B JSON Data&#xA;Microservice C JSON Data&#xA;Microservice D JSON Data&#xA;&#xA;     ▼ (Return JSON Data to gateway)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Render HTML and return to Client)&#xA;&#xA;Client browser&#xA;&#xA;     ▼ (ReactJS UI Components request data from API Gateway)&#xA;</code></pre>&#xA;&#xA;<p>This is where it gets unclear, would it be best to have each UI component communicate with the Web API Gateway or the parent Microservice it came from to get data? </p>&#xA;&#xA;<p>Considerations</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components talk to the Web API Gateway seems reasonable but will couple the microservices to the gateway, meaning to expose a new API on the microservice the gateway will also need to be updated. </li>&#xA;<li>Having the UI components talk directly to its Microservice for data removes the need to also update the Web API Gateway, keeping them less coupled. But this then exposes the Microservice to external calls from the client browser. </li>&#xA;</ul>&#xA;&#xA;<p>Design Decisions</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components within the API gateways creates a UI monolith as opposed to having each microservice responsible for its own UI component. Using the monolithic approach simplifies the solution and also avoids the complexities of having to aggregate each microservices UI component when the client requests a particular view. </li>&#xA;</ul>&#xA;&#xA;<p>Tools:</p>&#xA;&#xA;<ul>&#xA;<li>Java</li>&#xA;<li>Nashorn</li>&#xA;<li>Dropwizard </li>&#xA;<li>ReactJS</li>&#xA;<li>Gradle</li>&#xA;<li>Webpack</li>&#xA;<li>NodeJS</li>&#xA;<li>NPM </li>&#xA;</ul>&#xA;&#xA;<p><strong>How do I aggregate multiple microservice ui components on the Web API Gateway using Java and ReactJS then serve this pre-rendered HTML data along with the JavaScript application to the client?</strong></p>&#xA;&#xA;<p><strong>Helpful References:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Server side rendering with Java 8 and Nashhorn <a href=""http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/"" rel=""nofollow noreferrer"">http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/</a></li>&#xA;</ul>&#xA;"
48134800,Deploying Go apps with micro-service architecture in containers or not in containers?,2018-01-07 06:15:06,<go><kubernetes><microservices><devops><docker-container>,2,331,3,1.0,3,"<p>I'm new to DevOps specifically using golang and microservice architecture.</p>&#xA;&#xA;<p>I'm wondering if go applications should or should not be deployed in containers (Docker). In this case, I have a system built with micro-service architecture. For example here, I have 2 web services, A and B. Also I have another web server acts as a gateway in front of those two.</p>&#xA;&#xA;<p>Both A and B need access for a database, MySQL for example. A handles table A, and B handles table B.</p>&#xA;&#xA;<p>I know that in Go, source codes are compiled into a single executable binary file. And because I have 3 services here, I have 3 binaries. All three run as web server exposing JSON REST API.</p>&#xA;&#xA;<p>My questions are these:</p>&#xA;&#xA;<ul>&#xA;<li><p><strong>Can I deploy these servers together in one host running on different ports?</strong>&#xA;If my host get an IP x.x.x.x for example, my gateway can run in x.x.x.x:80, A in port 81, and B in port 82 for example. A and B will talk to a MySQL server somewhere outside or maybe inside the same host. Is this a good practice? Can Continuous Deployment works with this practice?</p></li>&#xA;<li><p><strong>Why should I deploy and run those binaries inside containers like Docker?</strong>&#xA;I know that since its release few years ago, Docker had found its way to be integrated inside a development workflow easily. But of course using Docker is not as simple as just compiling the code into a binary and then moving it to a deployment server. Using Docker we have to put the executable inside the container and then move the container as well to the deployment server.</p></li>&#xA;<li><p><strong>What about scalibility and high availability without using Docker?</strong>&#xA;Can I just replicate my services and run them all at once in different hosts using a load balancer? This way I should deploy A, B, and gateway in one host, and another A, B, and gateway in another host, then setup load balancer in front of them. A, B, and the gateway runs in port 80, 81, and 82 respectively. This way I could have  thousands of nodes in a form of VMs or LXD containers maybe, spread accross hundreds of bare metals, deployed with a simple bash script and ssh, or Ansible if things get complex. Yes or no?</p></li>&#xA;<li><p><strong>And what about the scalability and availability of using Docker?</strong>&#xA;Should I just put all my services inside containers and manage them with something like Kubernetes to achieve high availability? Doing this does add overhead, right? Because the team will have to learn new technology like Kubernetes if they haven't known it yet.</p></li>&#xA;<li><p>Can you give me an example of some best practices of deploying golang services?</p></li>&#xA;</ul>&#xA;"
42199241,What is an efficient way to communicate in microservices architecture,2017-02-13 08:03:56,<node.js><web-services><amazon-ec2><microservices>,3,319,0,0.0,3,<p>I am using Node.js and a REST based light weight web service to communicate between servers. i want to know if there is another more efficient way to communicate between servers?&#xA;I am using ec2 instances in a vpn.</p>&#xA;
42332737,Exchange reference token for JWT - downstream microservices authorization,2017-02-19 20:52:59,<jwt><microservices><identityserver4>,2,743,0,2.0,3,"<p>I am currently creating a new application based on a Microservices architecture, with authentication provided by Identity Server 4. </p>&#xA;&#xA;<p>Following lots of research and also setting up proof of concepts, I have Identity Server setup to secure the API's and a native application successfully accessing these services using tokens.</p>&#xA;&#xA;<p>Initially the client was issued an access token which was used to access the API's, I have however now switched this out to use reference tokens.  Now, onto the issue!</p>&#xA;&#xA;<p>The approach I would like to take here is to adopt a Microservices gateway, which receives a reference token and then turns this into a JWT for inclusion in any requests to the downstream microservices.  Within the Gateway, how can I ""exchange"" the inbound reference token for a JWT? Is there something within Identity Server that can assist here? Or do I need to use the introspection endpoint, sending in the reference token and retrieving the claims to construct a JWT within the gateway service for passing in the Authorization header to all downstream services?</p>&#xA;&#xA;<p>If there is any further information that I can provide to help with understanding the goal of the architecture, please just let me know.</p>&#xA;"
48458627,How to filter and sort data from multiple microservices?,2018-01-26 09:27:49,<architecture><microservices>,1,362,0,3.0,3,"<p>We have microservices which work with different, but related data. For example, ads and their stats. We want to be able to filter, sort and aggregate this related data for UI(and not only for it). For example, we want to show to a user ads which have 'car' in their text and which have more than 100 clicks.</p>&#xA;&#xA;<p><strong>Challenges:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There could be a lot of data. Some users have millions of rows after filtration</li>&#xA;<li>Services doesn't have all the data. For example, for statistics service ad without stats == non existent ad. It doesn't know anything about such ads. But sorting and filtration should work anyway(ad without stats should be considered as ad without zero clicks)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Requirements:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Eventual consistency within couple of seconds is OK</li>&#xA;<li>Data loss is not acceptable</li>&#xA;<li>5 to 10 seconds filtration and sorting for big clients with millions of rows is OK</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solutions we could think of:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Load all data required by query from all services and filter and sort it in memory.</li>&#xA;<li>Push updates from services to Elasticsearch(or something like this). Elastic handles query and returns ids of desired entities which then loaded from services.</li>&#xA;<li>One big database for all services which has everything</li>&#xA;</ul>&#xA;&#xA;<p>What should we pay attention to? Are there other ways to solve our problem?</p>&#xA;"
46115104,Hazelcast cluster: serialization and replication issue,2017-09-08 11:08:51,<java><microservices><hazelcast><distributed-cache><hazelcast-imap>,1,198,0,2.0,3,"<p>Our application consists of several micro services. Each microservice has a configuration for its own hazelcast instance. All hazelcast instances form a cluster with distributed data. Hazelcast replicated map is used as a way to replicate data objects (DTOs include several fields) between those micro services. Microservices are hosted on AWS.</p>&#xA;&#xA;<p>There was a problem with data object serialization that's why we created a separated project with custom serialization config. All data objects (java classes) we want to replicate are listed in this config code. Artifact built from this very configuration project is included in each micro service as a maven dependency. This helps to solve serialization problem.</p>&#xA;&#xA;<p>This solution led us to the new problem what appear if it's needed to add new data object. Firstly we should add this very data object to config project, then rebuild this project. After that, we should rebuild all micro services with updated dependency and redeploy. And if at least one of micro services wasn't rebuilt there will be a serialization error because of this very micro service hazelcast instance doesn't know how to serialize new data object. The process of rebuilding and redeploying all application isn't so convenient for us.</p>&#xA;&#xA;<p>Please, share your experience! Is there any way to make it easier? </p>&#xA;"
46069921,Is there a difference between API gateway pattern and BFF?,2017-09-06 08:07:33,<microservices><netflix-zuul><api-gateway>,1,1333,1,1.0,3,<p>My understanding is that API gateway pattern is like a proxy to all microservices. So client calls the API gateway which takes care of further routing. BFF is a specific case of API gateway pattern where we have a routing mechanism for each type of client. Am I right?</p>&#xA;
48791411,Horizontal scaling of consumers when the publisher provides sequenced messages,2018-02-14 16:02:53,<asynchronous><rabbitmq><microservices>,4,167,0,1.0,3,"<p>In a distributed service oriented architecture, lets say I have a producer that send messages to a consumer using RMQ. </p>&#xA;&#xA;<p>We decided then to horizontally scale the consuming part of our architecture by adding more consumers and we faced some limitations.</p>&#xA;&#xA;<p>The publisher provide a sequence number in every message it sent. And it’s very important that the consumers process the messages based on the sequence number it has.</p>&#xA;&#xA;<p>Every time that deal with a given resource, lets say A, the publisher will send RMQ messages that says ""Hey lets do sequence 1 for A"" and then ""Hey lets do sequence 2 for A"" and so on.</p>&#xA;&#xA;<p>If for example the publisher provides 3 messages for A with sequences 1, 2 and 3 and the 3 messages are distributed to 3 different instances of our consumer. The message of sequence 2 is requeued until sequence 1 is well processed, same for sequence 3.</p>&#xA;&#xA;<p>At the end the messages are all well processed, but after many retries! This causes some latency in our system as we retries many times if we’ve 100 sequences to consume.</p>&#xA;&#xA;<p>A possible solution would be to make sure each set of sequences for a given resource has to be processed by the same consumer. But how can we achieve that?</p>&#xA;&#xA;<p>How can I avoid the requeuing in order to make sure every instance of our consumer always get the messages for a given resource well ordered?</p>&#xA;"
48624757,Asynchronous Message-Passing and Microservices,2018-02-05 14:27:51,<java><spring-boot><apache-kafka><microservices>,3,434,2,2.0,3,"<p>I am planning the develop of a microservice based architecture application and I decided to use kafka for the internal communicaton while I was reading the book <em>Microservice Architecture by Ronnie Mitra; Matt McLarty; Mike Amundsen; Irakli Nadareishvili</em> where they said: </p>&#xA;&#xA;<blockquote>&#xA;  <p>letting microservices directly interact with message brokers (such as&#xA;  RabbitMQ, etc.) is rarely a good idea. If two microservices are&#xA;  directly communicating via a message-queue channel, they are sharing a&#xA;  data space (the channel) and we have already talked, at length, about&#xA;  the evils of two microservices sharing a data space. Instead, what we&#xA;  can do is encapsulate message-passing behind an independent&#xA;  microservice that can provide message-passing capability, in a loosely&#xA;  coupled way, to all interested microservices.</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/XK10H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XK10H.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I am using Netflix Eureka for Service registration and discovery, Zuul as edge server and Hystrix. &#xA;Said so, in practice, how can I implement that kind of microservice? How can I make my microservices indipendent from the communcation channel ( in this case Kafka)? &#xA;Actually I'm directly interacting with the channel, so I don't have an extra layer between my publishers/subscribers and kafka.</p>&#xA;&#xA;<p><strong>UPDATE 06/02/2018</strong></p>&#xA;&#xA;<p>to be more precise, we have a couple of microservices: one is publishing news on a topic (activemq, kafka...) and the other microservice is subscribed on that topic and doing some operations on the messages that are coming through. So we have these services that are coupled to the message broker (to the channel)... we have the the message broker's apis ""embedeed"" on our code and for example, if we want to change the message broker we have to change all the microservices that made use of the message broker's api. So, they are suggesting to use a microservice(in the picture I assume is the Events Hub) that is the ""dispatcher"" of the various messages. In this way it is the only component that interacts with the channel.</p>&#xA;"
41164987,User's locale in microservice - JHipster,2016-12-15 13:09:07,<java><spring-security><jwt><jhipster><microservices>,1,264,0,0.0,3,"<p>In one of the microservices, in a JHipster microservice architecture, I want to generate a document, in the users' language.</p>&#xA;&#xA;<p>In the gateway, the users' language is retrieved by a cookie (AngularCookieLocaleResolver). But when a request, routed through the gateway, arrives at the microservice, no cookies are found on the request.</p>&#xA;&#xA;<p>I see a few options here:</p>&#xA;&#xA;<ol>&#xA;<li>Add a locale claim to the JWT-token</li>&#xA;<li>Contact the gateway with the username, to retrieve the locale</li>&#xA;<li>Do not generate locale specific content at a microservice</li>&#xA;</ol>&#xA;&#xA;<p>I would prefer the first option, but maybe there are some better options...</p>&#xA;&#xA;<p>Can anyone help me choose or list up alternatives?</p>&#xA;"
41036330,Store private key in microservices,2016-12-08 09:49:19,<microservices><private-key><public-key>,1,140,0,1.0,3,"<p>There are some microservice which communicating with each other with rsa encrypted messages. The private keys are in files currently, what is the best practice to store the private and public keys in the containers? The current solution is in the /etc/ssl, but this is a little bit hard to manage and not to safety.</p>&#xA;"
45853546,"Two processes reside in different AP servers and refer to a same boolean flag. (Spring, Java)",2017-08-24 05:25:54,<java><spring><microservices><consistency>,4,41,0,0.0,3,"<p>I am using Spring Framework to develop a web application. I have two services which are going to store some processed results into one table T in Database. The logic now is:</p>&#xA;&#xA;<p><strong>Service A</strong></p>&#xA;&#xA;<pre><code>for all items:&#xA;    result = func(item)&#xA;    store result to Table T (with status = new)&#xA;is_running = False&#xA;</code></pre>&#xA;&#xA;<p><strong>Service B</strong></p>&#xA;&#xA;<pre><code>for some items:&#xA;    if is_running == False:&#xA;        result = func(item)&#xA;        store result to Table T (with status = new)&#xA;    else:&#xA;        store result to Table T (with status = inprogress)&#xA;</code></pre>&#xA;&#xA;<p>The boolean flag <code>is_running</code> will be a field in Service A.</p>&#xA;&#xA;<p>Since we have MicroService Architechture for the domain server, Service A and Service B may reside in different AP servers. How can I ensure Servie A and Service B refer to the same <code>is_running</code>?</p>&#xA;&#xA;<p>Is it possible to use <a href=""https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html#beans-factory-scopes"" rel=""nofollow noreferrer"">Spring's bean scope</a> to achieve this?</p>&#xA;"
46002727,What is the difference between an API-Gateway and an Edge Service?,2017-09-01 14:42:21,<microservices>,1,935,0,0.0,3,"<p>I understand the concept behind an API gateway as described by Richardson:</p>&#xA;&#xA;<p><a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a></p>&#xA;&#xA;<p>But what is the difference to an Edge service. Is this a concrete implementation of the API gateway pattern?</p>&#xA;"
40422613,Sharing data between isolated microservices,2016-11-04 12:24:29,<web-services><heroku><database-design><web-applications><microservices>,1,804,1,3.0,3,"<p>I'd like to use the microservices architectural pattern for a new system, but I'm having trouble figuring out how to share and merge data between the services when the services are isolated from each other. In particular, I'm thinking of returning consolidated data to populate a web app UI over HTTP.</p>&#xA;&#xA;<p>For context, I'm intending to deploy each service to its own isolated environment (Heroku) where I won't be able to communicate internally between services (e.g. via <code>//localhost:PORT</code>. I plan to use RabbitMQ for inter-service communication, and Postgres for the database.</p>&#xA;&#xA;<p>The decoupling of services makes sense for CREATE operations:</p>&#xA;&#xA;<ul>&#xA;<li>Authenticated user with <code>UserId</code> submits 'Join group' webform on the frontend</li>&#xA;<li>A new <code>GroupJoinRequest</code> including the <code>UserId</code> is added to the RabbitMQ queue</li>&#xA;<li>The <code>Groups</code> service picks up the event and processes it, referencing the user's <code>UserId</code></li>&#xA;</ul>&#xA;&#xA;<p>However, READ operations are much harder if I want to merge data across tables/schemas. Let's say I want to get details for all the users in a certain group. In a monolithic design, I'd just do a SQL <code>JOIN</code> across the Users and the Groups tables, but that loses the isolation benefits of microservices.</p>&#xA;&#xA;<p>My options seem to be as follows:</p>&#xA;&#xA;<h3>Database per service, public API per service</h3>&#xA;&#xA;<p>To view all the <code>Users</code> in a <code>Group</code>, a site visitor gets a list of <code>UserID</code>s associated with a group from the Groups service, then queries the <code>Users</code> service separately to get their names.</p>&#xA;&#xA;<p><strong>Pros:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>very clear separation of concerns</li>&#xA;<li>each service is entirely responsible for its own data</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>requires multiple HTTP requests</li>&#xA;<li>a lot of postprocessing has to be done client-side</li>&#xA;<li>multiple SQL queries can't be optimized</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data over HTTP, single public API</h3>&#xA;&#xA;<p>A public API server handles request endpoints. Application logic in the API server makes requests to each service over a HTTP channel that is only accessible to other services in the system.</p>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>good separation of concerns</li>&#xA;<li>each service is responsible for an API contract but can do whatever it wants with schema and data store, so long as API responses don't change</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>non-performant</li>&#xA;<li>HTTP seems a weird transport mechanism to be using for internal comms</li>&#xA;<li>ends up exposing multiple services to the public internet (even if they're notionally locked down), so security threats grow from greater attack surface</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data through message broker</h3>&#xA;&#xA;<p>Given I've already got RabbitMQ running, I could just use it to queue requests for data and then to send the data itself. So for example:</p>&#xA;&#xA;<ul>&#xA;<li>client requests all Users in a Group</li>&#xA;<li>the public API service sends a <code>GetUsersInGroup</code> event with a <code>RequestID</code></li>&#xA;<li>the <code>Groups</code> service picks this up, and adds the <code>UserID</code>s to the queue</li>&#xA;<li>The `Users service picks this up, and adds the User data onto the queue</li>&#xA;<li>the API service listens for events with the <code>RequestID</code>, waits for the responses, merges the data into the correct format, and sends back to the client</li>&#xA;</ul>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Using existing infrastructure</li>&#xA;<li>good decoupling</li>&#xA;<li>inter-service requests remain internal (no public APIs)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Multiple SQL queries</li>&#xA;<li>Lots of data processing at the application layer</li>&#xA;<li>harder to reason about</li>&#xA;<li>Seems strange to pass large quantities around data via event system</li>&#xA;<li>Latency?</li>&#xA;</ul>&#xA;&#xA;<h3>Services share a database, separated by schema, other services read from <code>VIEW</code>s</h3>&#xA;&#xA;<p>Services are isolated into database schemas. Schemas can only be written to by their respective services. Services expose a SQL <code>VIEW</code> layer on their schemas that can be queried by other services. </p>&#xA;&#xA;<p>The <code>VIEW</code> functions as an API contract; even if the underlying schema or service application logic changes, the <code>VIEW</code> exposes the same data, so that </p>&#xA;&#xA;<p><strong>Pros</strong>: </p>&#xA;&#xA;<ul>&#xA;<li>Presumably much more performant (single SQL query can get all relevant data)</li>&#xA;<li>Foreign key management much easier</li>&#xA;<li>Less infrastructure to maintain</li>&#xA;<li>Easier to run reports that span multiple services</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>tighter coupling between services</li>&#xA;<li>breaks the idea of fundamentally atomic services that don't know about each other</li>&#xA;<li>adds a monolithic component (database) that may be hard to scale (in contrast to atomic services which can scale databases independently as required)</li>&#xA;<li>Locks all services into using the same system of record (Postgres might not be the best database for all services)</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>I'm leaning towards the last option, but would appreciate any thoughts on other approaches.</p>&#xA;"
40539447,Run two processes in a single docker container or two containers connecting to the same DB?,2016-11-11 00:37:10,<python><docker><containers><apache-kafka><microservices>,1,224,1,1.0,3,"<p>I need to develop an application that listens to a kafka topic and saves the data to a DB (cassandra). It will be a high density stream of data so saving the data will be resource expensive. Once the data is saved it will be queried and exposed through a REST API.</p>&#xA;&#xA;<p>I see two options, but both of them have downsides:</p>&#xA;&#xA;<p><strong>Option 1</strong><br>&#xA;Create two services, each one in a separate docker container. One would run only the kafka listener process in python and the other one a flask web server.<br>&#xA;<em>Advantages</em>: Every container runs only one process<br>&#xA;<em>Downsides</em>: Both services connect to the same DB, which is not ideal according to the microservices pattern architecture, for the services are not completely decoupled.</p>&#xA;&#xA;<p><strong>Option 2</strong><br>&#xA;Run both, kafka listener and web service in one container.<br>&#xA;<em>Advantages</em>: Just one service to connect to the DB.<br>&#xA;<em>Downsides</em>: More than one process running in a single docker container, and one of them (saving and updating) would be a lot more resource expensive than the other, so it would not scale uniformly.   </p>&#xA;&#xA;<p>Is there another way to go that doesn't involve moving to a monolithic architecture? Or which one of them is the best practice?</p>&#xA;"
29689630,Moving over to microservices for .NET apps - some questions,2015-04-17 03:18:48,<.net><rest><architecture><restsharp><microservices>,2,1406,0,2.0,3,"<p>I'd like to start getting into splitting my apps into microservices. My first task is to remove functionality that is repeated in each of our apps. Things like email sending, exporting, searching indexes etc - stuff where the same or similar code is repeated in every app.</p>&#xA;&#xA;<p>I just feel a little overwhelmed and struggling to get a start. I understand that the purpose of microservices is that you can pick the right language for the job, but for our current purposes i'm going with the assumption that .NET would be the primary framework i'll be building everything in.</p>&#xA;&#xA;<p>Basically, to start with, I want to create a microservice that simply sends emails that all our apps can talk to and tell to send the emails they need. The way I was thinking was the email sender has the logic to send the email, but each app needs to tell it the recipients, body etc.</p>&#xA;&#xA;<p>I'm struggling with things like:</p>&#xA;&#xA;<ul>&#xA;<li><p>What protocol should the apps use to talk to this service? REST over HTTP? If this is the case, would the email sending microservice effectively just be a Web API 2 app (this is what I'd personally go with if i were to build a REST api).</p></li>&#xA;<li><p>If I'm going REST, whats the best way to make restful calls from the backend? Most emails in our system are sent via the backend code right now. I've seen the RestSharp name thrown around, is this generally considered the best way?</p></li>&#xA;<li><p>Future planning, I think having some sort of gateway which knows about all the services would be beneficial so that each app only needs to know about this gateway and then the gateway talks to whatever services it needs. Would this just be yet another REST API in between the apps and the micro services?</p></li>&#xA;</ul>&#xA;&#xA;<p>Sorry for all the questions, just getting a start in all this sort of stuff (and architecture in general) in order to step up in my workplace and it's a bit to get my head around currently.</p>&#xA;"
41853686,Using RabbitMQ in for communication between different Docker container,2017-01-25 14:06:41,<docker><rabbitmq><message-queue><microservices>,2,332,0,0.0,3,"<p>I want to communicate between 2 apps stored in different docker containers, both part of the same docker network. I'll be using a message queue for this ( RabbitMQ )</p>&#xA;&#xA;<p>Should I make a 3rd Docker container that will run as my RabbitMQ server, and then just make a channel on it for those 2 specific containers ? So that later on I can make more channels if I need for example a 3rd app that needs to communicate with the other 2?</p>&#xA;&#xA;<p>Regards!</p>&#xA;"
41757509,How to setup Docker for a polyglot microservice-based application?,2017-01-20 06:38:13,<docker><docker-compose><dockerfile><microservices><docker-machine>,1,183,0,0.0,3,"<p>Working on a larger-than-usual project of mine, I am building an web application that will talk to several APIs of mine, each written in its own language. I use two databases, one being MariaDB and the second being Dgraph (graph database.)</p>&#xA;&#xA;<p>Here is my local director architecture:</p>&#xA;&#xA;<ul>&#xA;<li><strong>services</strong> - all my services&#xA;&#xA;<ul>&#xA;<li><strong>api</strong> - contains all my APIs&#xA;&#xA;<ul>&#xA;<li><strong>auth</strong> - contains my user auth/signup API&#xA;&#xA;<ul>&#xA;<li><strong>v1</strong> - contains my current (only) API version</li>&#xA;</ul></li>&#xA;<li><strong>trial</strong> - contains my an API of mine called <em>trial</em></li>&#xA;<li>etc...</li>&#xA;</ul></li>&#xA;<li><strong>application</strong> - contains the app users will interact with</li>&#xA;<li><strong>daemon</strong> - contains my programs that will run as daemons</li>&#xA;<li><strong>tools</strong> - contains tools (import data, scrapers, etc)</li>&#xA;</ul></li>&#xA;<li><strong>databases</strong> - to contain my two configs (MariaDB and Dgraph)</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/PewMe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PewMe.png"" alt=""Local File Structure""></a></p>&#xA;&#xA;<p>Because some components are written in PHP7-NGINX while others are in PYTHON-FLASK-NGINX, how can I do a proper Docker setup with that in mind? Each service, api, daemon and tool is independant and they all talk through their own REST-endpoints.</p>&#xA;&#xA;<p>Each has its own private github repository, and I want to be able to take each one and deploy it to its own server when needed.</p>&#xA;&#xA;<p>I am new to Docker and all the reading I do confuses me: should I create a docker-compose.yml for each service or one for the entire project? But each service is deployed separately so how does docker-compose.yml know that?</p>&#xA;&#xA;<p>Any pointers to a clean solution? Should I create a container for each service and in that container put NGINX, PHP or PYTHON, etc?</p>&#xA;"
41893494,Docker Swarm Mode routing mesh vs linkerd,2017-01-27 11:59:09,<docker><microservices><docker-swarm-mode><linkerd>,1,713,0,1.0,3,"<p>Is Docker Swarm Mode routing mesh a built-in substitute for linkerd routing mesh? In other words, is there still any reason to look into linkerd if there is an out-of-the-box solution?</p>&#xA;"
41914911,microservice based event store,2017-01-28 21:15:33,<microservices><cqrs><event-store><eventsource>,1,244,0,0.0,3,"<p>Unfamiliar with all the details of domain driven design, would it make sense  in a microservice architecture to think of each service as it's own domain and in turn build an event store per service?</p>&#xA;&#xA;<p>Not totally sure what the trade-offs might be from a single monolithic event store for the entire system. For example, more difficulty replaying conditions in the system or debugging cross service dependencies.</p>&#xA;"
41881610,Spring-Cloud Zuul breaks UTF-8 symbols in forwarded multipart request filename,2017-01-26 19:40:58,<spring-boot><utf-8><microservices><netflix-zuul><netflix-eureka>,1,770,1,1.0,3,"<p>this is first time for me on SO, so please be patient for my first question.</p>&#xA;&#xA;<p>I think i have some kind of configuration problem, but after a day of experiments i'm stuck. Our application is based on Spring-Cloud [Brixton release]. We have configuration like this: Portal (web application serving angular-based web-ui), which has zuul proxy with single route configured to our gateway service, like so:</p>&#xA;&#xA;<pre><code>zuul:&#xA;   ignoredServices: '*'&#xA;   prefix: /api&#xA;   routes:&#xA;       api-proxy:&#xA;          path: /**&#xA;          serviceId: api-gateway&#xA;</code></pre>&#xA;&#xA;<p>which has another Zuul configured and relays requests to inner bussiness logic services:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredServices: '*'&#xA;  routes:&#xA;     service1:&#xA;       path: /service1/**&#xA;       serviceId: service1&#xA;     service2:&#xA;       path: /service2/**&#xA;       serviceId: service2&#xA;</code></pre>&#xA;&#xA;<p>All this configuration is working with no problem.&#xA;The problem now that i am facing is with file upload multipart requests. To be more precise - those multipart requests, when file to be uploaded has non latin symbols (e.g. ąčęėįš) from <code>UTF-8</code>. When request reaches service which has to deal with <code>@RequestPart MultipartFile file</code>, then <code>file.getOriginalFilename()</code> returns questionmarks in the places of aforementioned symbols. Now, i have tried to directly upload such file to such controller, and filename comes without questionmarks, that is, not broken, which suggests, that some bad interpretation/parsing of multipart request occurs somewhere in Zuul filters, when proxy relays incomming request.</p>&#xA;&#xA;<p>Maybe someone had similar experience with Zuul and can direct me some way to resolve this problem?</p>&#xA;"
50989454,Python asyncio Protocol behaviour with multiple clients and infinite loop,2018-06-22 13:48:22,<python-3.x><server><client-server><microservices><python-asyncio>,1,105,0,1.0,3,"<p>I'm having difficulty understanding the behaviour of my altered echo server, which attempts to take advantage of python 3's <code>asyncio</code> module.</p>&#xA;&#xA;<p>Essentially I have an infinite loop (lets say I want to stream some data from the server to the client indefinitely whilst the connection has been made) e.g. <code>MyServer.py</code>:</p>&#xA;&#xA;<pre class=""lang-py prettyprint-override""><code>#! /usr/bin/python3&#xA;import asyncio&#xA;import os&#xA;import time&#xA;&#xA;class MyProtocol(asyncio.Protocol):&#xA;&#xA;    def connection_made(self, transport):&#xA;        peername = transport.get_extra_info('peername')&#xA;        print('Connection from {}'.format(peername))&#xA;        self.transport = transport&#xA;&#xA;    def connection_lost(self, exc):&#xA;        asyncio.get_event_loop().stop()&#xA;&#xA;    def data_received(self, data):&#xA;        i = 0&#xA;        while True:&#xA;            self.transport.write(b'&gt;&gt; %i' %i)&#xA;            time.sleep(2)&#xA;            i+=1&#xA;&#xA;loop = asyncio.get_event_loop()&#xA;coro = loop.create_server(MyProtocol, &#xA;    os.environ.get('MY_SERVICE_ADDRESS', 'localhost'), &#xA;    os.environ.get('MY_SERVICE_PORT', 8100))&#xA;server = loop.run_until_complete(coro)&#xA;&#xA;try:&#xA;    loop.run_forever()&#xA;except:&#xA;    loop.run_until_complete(server.wait_closed())&#xA;finally:&#xA;    loop.close()&#xA;</code></pre>&#xA;&#xA;<p>Next when I connect with <code>nc ::1 8100</code> and send some text (e.g. ""testing"") I get the following:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;*** Connection from('::1', 58503, 0, 0) ***&#xA;testing&#xA;&gt;&gt; 1&#xA;&gt;&gt; 2&#xA;&gt;&gt; 3&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Now when I attempt to connect using <code>nc</code> again, I do not get any welcome message and after I attempt to send some new text to the server I get an endless stream of the following error:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;Is there anybody out there?&#xA;socket.send() raised exception&#xA;socket.send() raised exception&#xA;...&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Just to add salt to the wound the <code>socket.send() raised exception</code> message continues to spam my terminal until I kill the python server process...</p>&#xA;&#xA;<p>As I'm new to web technologies (been a desktop dinosaur for far too long!), I'm not sure why I am getting the above behaviour and I haven't got a clue on how to produce the intended behaviour, which loosely looks like this:</p>&#xA;&#xA;<ol>&#xA;<li>server starts</li>&#xA;<li>client 1 connects to server</li>&#xA;<li>server sends welcome message to client&#xA;4  client 1 sends an arbitrary message</li>&#xA;<li>server sends messages back to client 1 for as long as the client is connected</li>&#xA;<li>client 1 disconnects (lets say the cable is pulled out)</li>&#xA;<li>client 2 connects to server</li>&#xA;<li>Repeat steps 3-6 for client 2</li>&#xA;</ol>&#xA;&#xA;<p>Any enlightenment would be extremely welcome!</p>&#xA;"
42582463,Monitoring a microservice architecture,2017-03-03 15:14:05,<amazon-web-services><aws-lambda><microservices><prometheus>,2,253,0,1.0,3,"<p>I'm designing an architecture that similar to what's described <a href=""https://aws.amazon.com/blogs/compute/better-together-amazon-ecs-and-aws-lambda/"" rel=""nofollow noreferrer"">here</a>.  The diagram is: &#xA;<a href=""https://i.stack.imgur.com/y72pp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/y72pp.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>My question is how do you monitor such an architecture where independent pieces compose into a logical unit?  It's almost as if we need a monitoring system that checks S3 for .zip files and then polls S3 for the corresponding png files.  If <em>after</em> X hours no png files are found then alert.  </p>&#xA;&#xA;<p>Is there a tool that does timeseries analysis?  Does Prometheus do this?</p>&#xA;"
42527724,Accessing microservices deployed on apache mesos agents,2017-03-01 09:18:27,<dns><load-balancing><microservices><mesos><marathon>,2,100,1,0.0,3,"<p>How client can access a deployed microservice <strong>without</strong> specifing the host agent ip-address and the related mapping port.</p>&#xA;&#xA;<p>If we add Mesos-DNS as the client resolver, we can only obtain agent ip-addresses but it doesn't return the list of  microservices instances and their related ports.</p>&#xA;&#xA;<p>Supposed we have three instannces of webapp1 as follow:</p>&#xA;&#xA;<pre><code>+---------+---------+&#xA;| agent1  | agent2  |&#xA;+---------+---------+&#xA;|         |         |&#xA;| ins1:11 | ins3:13 |&#xA;|         |         |&#xA;| ins2:12 |         |&#xA;|         |         |&#xA;+---------+---------+&#xA;</code></pre>&#xA;&#xA;<p>client should be enabled to access one of instances directly (without referring agent1 and agent2 ip-addresses or those 11, 12 and 13 port numbers). For example:</p>&#xA;&#xA;<pre><code>$ lynx webapp1.marathon.mesos&#xA;</code></pre>&#xA;"
42562820,DDD. Shared kernel? Or pure event-driven microservices?,2017-03-02 18:10:44,<domain-driven-design><microservices><bounded-contexts>,3,1670,1,1.0,3,"<p>I'm breaking my system into (at least) two bounded-contexts: study-design and survey-planning.</p>&#xA;&#xA;<p>There's a concept named ""subject"" (potential subject for interviewing) in the study-design context. We also maintain associations between subjects and populations in that domain.</p>&#xA;&#xA;<p>Now, in the survey-planning, we also need (some) information about the subject (for example: for planning a visit, or even for anticipated selection of questionnaire, in case the population the subject belongs to is known beforehand).</p>&#xA;&#xA;<p>So, I need that ""subject"" in both contexts. </p>&#xA;&#xA;<p>What approach should I pick? Having a shared kernel, as explained in Eric Evans DDD book? I don't mind (at least for now) having the two contexts sharing the same database.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FKtJ9.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FKtJ9.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Or... should I go pure microservice? Meaning: those two can't / shouldn't share database..., and in that case I might have to go the mirroring / duplicating route through event passing: <a href=""https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts"" rel=""nofollow noreferrer"">https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts</a></p>&#xA;&#xA;<p>Any thoughts on which one is better, for the above situation?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
42404800,How to build front end for Microservices,2017-02-23 00:20:21,<user-interface><architecture><microservices>,1,477,1,0.0,3,"<p>Let's say I have a dozen microservices. I am wondering where should the front end go. Let's say front end is HTML, Javascript, CSS. One way is to make it a separate service handled by a UI team. So it can form the API gateway where the request from browser comes in first. But this seems against the idea of independent self contained services.<br>&#xA;browser ------> API Gateway ------> Microservices&#xA;<br>&#xA;In <a href=""https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/"" rel=""nofollow noreferrer"">this</a> link, they say that Javascript and CSS should be served by microservices. API gateway should serve only the HTML page. THere is a nice diagram showing this >>&#xA;<a href=""https://i.stack.imgur.com/1suda.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1suda.png"" alt=""microservices with UI""></a>&#xA;I have two questions<br>&#xA;1. How will this be implemented? How will API gateway serve the JS and CSS files in microservices, and maybe HTML fragments too. How will initial page load happen and from where.<br>&#xA;2. Now we are mingling HTML into microservices. But what if I want to serve Android and iOS apps too? THanks.</p>&#xA;"
39591223,Can SOA and Microservices co-exist?,2016-09-20 10:04:15,<design><architecture><soa><microservices>,3,379,0,0.0,3,<p>It is often documented to build a microservice based architecture from a monolith. Is it also possible to have microservices in SOA based architecture?</p>&#xA;
39540366,Go-kit real world example with inter microservice data transfers,2016-09-16 21:31:37,<go><microservices>,1,947,0,4.0,3,"<p>I try to work with go-kit (gokit.io) and to build real-work application with it.&#xA;I look through examples. These examples are great. But I do not understand how to do services to service communications / data transfers in go-kit framework. </p>&#xA;&#xA;<p>I can see ""real-world"" shipping app, but I do not understand how it could be ""real world"" micro-services. I can see in sources that, for example, they build the booking service just passing foreign repositories into service</p>&#xA;&#xA;<pre><code>type service struct {&#xA;    cargoRepository         cargo.Repository&#xA;    locationRepository      location.Repository&#xA;    routingService          routing.Service&#xA;    handlingEventRepository cargo.HandlingEventRepository&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and later they get data from repositories (this repository belongs to foreign micro-service) just calling the method:</p>&#xA;&#xA;<p><code>locationRepository.Find(...)</code></p>&#xA;&#xA;<p>Could someone please explain me:</p>&#xA;&#xA;<ul>&#xA;<li>how to build micro-service to micro-service communications in go-kit framework? Just show me the way / pattern, please. I do not understand it at all.</li>&#xA;</ul>&#xA;&#xA;<p>I see it as they just share direct access to data. But in real world micro-services, I expected that micro-services will communicate to each other to get needed data. And I do not understand how to do it in go-kit framework.</p>&#xA;"
39601492,how monolith spring 3 application will communicate with microservice?,2016-09-20 18:41:04,<spring><spring-boot><microservices><netflix-ribbon>,1,238,2,0.0,3,<p>I have one monolith spring web application developed using spring 3.1 and spring-security 3.1 with Java 7 and it is deployed on tomcat 7. </p>&#xA;&#xA;<p>Now I have a new requirement where I have to create a micro-service for a new module using spring boot with java 8. This micro-service will be deployed separately on different EC2 instance. </p>&#xA;&#xA;<p>I am looking for suggestion/idea to access new microservice from my existing spring web application. </p>&#xA;&#xA;<p>How to perform <em>inter process communication</em> within these two spring application?</p>&#xA;&#xA;<p>Can someone provide me any help/pointer?</p>&#xA;
50134195,Authorization between micro services and users,2018-05-02 12:01:47,<architecture><microservices>,1,127,0,1.0,3,"<p>What would be best way to handle access and authorization between microservices and users?</p>&#xA;&#xA;<p>I'm building an application on microservice architecture. Services speak to each other through REST. there are endpoints that should be accessed only by other microservices and not directly by users, some endpoints are public and some would require users to register or have admin privileges. On top of that Users will have roles like admins and regular users.</p>&#xA;&#xA;<p>I'm trying to figure out if Oauth2 and scopes is the best approach for what I'm trying to achieve. e.g. each microservice will have ""user"" that have permission on certain scopes like ""service1-place-order"". </p>&#xA;"
47566892,Microservices : Embedded tomcat vs standalone tomcat : Difference,2017-11-30 06:07:52,<java><tomcat><kubernetes><microservices><embedded-tomcat-8>,1,1205,0,0.0,3,"<p>Can embedded tomcat or any such embedded server be used for microservices in production environment? How, embedded server is different wrt the normal standalone full fledged server (performance . reliability wise)? Is the embedded server light weight compared to standalone? What are the features that embeded servers do not have compared to their standalone ones? Can we change the default security settings, tls ciphers etc advanced things in embedded tomcat?</p>&#xA;"
47757342,Programmatically add a service to docker compose project,2017-12-11 16:34:58,<docker><docker-compose><microservices>,1,231,0,0.0,3,"<p>I have a project with components base on Docker and orchestrated with <code>docker-compose</code>. Some of them are optional, and can be added at runtime.</p>&#xA;&#xA;<p>I can think about two ways to achieve that:</p>&#xA;&#xA;<ul>&#xA;<li>Create a new <code>serviceA.yml</code> compose file and run it as a separate project</li>&#xA;<li>Add <code>serviceA</code> to my base <code>compose.yml</code> and run it again</li>&#xA;</ul>&#xA;&#xA;<p>What is the preferred option to do that?</p>&#xA;&#xA;<p>I've also seen that you can combine <code>docker-compose</code> files with the <code>extend</code> keyword, but I don't think this can fit, since I have a variable number of services that I can add at runtime.</p>&#xA;"
45241581,Microservices vs functions as service (faas),2017-07-21 15:36:08,<aws-lambda><microservices>,1,909,0,1.0,3,"<p>Microservice architecture is/was next big thing. Easy to deploy, easy to develeop, not as complicated to scale and develop as monolith systems.</p>&#xA;&#xA;<p>Oriented mostly towards containers, it all looked new and promising, but i recently discovered there is a new hype about function as service or faas (aws lambda for example). </p>&#xA;&#xA;<p>Wikipedia says the following about Faas ""Building an application following this model is one way of achieving a ""serverless"" architecture, and is typically used when building microservices applications.""</p>&#xA;&#xA;<p>My conclusion was that in faas one should not worry about maintaining hardware and network resources. But is that the only advantage? Could microservice architecture pattern be fully achieved using functions as service?</p>&#xA;"
45167593,Authorization of actions across microservices,2017-07-18 13:01:29,<web-services><rest><authorization><microservices><event-sourcing>,2,108,1,1.0,3,"<p>A modern multi-user web application imposes a lot of restrictions on the actions that users can perform. In other words, the actions require authority. For example, a user can only change its own personal data, and only members of a group can post content to that group. In a classic monolith application, such restrictions are easily enforced by joining several database tables and acting according to the results of queries. However, with microservices, it becomes much less clear where and how such limitations should be handled.</p>&#xA;&#xA;<p>For the sake of argument, consider a Facebook clone. The whole application consists of several parts:</p>&#xA;&#xA;<ul>&#xA;<li>A front-end, written in JS and other web technologies</li>&#xA;<li>A backend consisting of a number of microservices</li>&#xA;<li>An API for retrieving and submitting data to the backend, i.e. a gateway</li>&#xA;</ul>&#xA;&#xA;<p>As for the business logic, there are (among others) two well-known entities:</p>&#xA;&#xA;<ul>&#xA;<li>Events (as in concerts, birthday parties etc.)</li>&#xA;<li>Posts (text entries existing on walls, pages, events etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Suppose that these two entities are managed by separate services, EventService and PostService. Then consider the following constraint:</p>&#xA;&#xA;<blockquote>&#xA;  <p>A post to an event can be deleted by two kinds of users: the author of the post, and the host(s) of the event.</p>&#xA;</blockquote>&#xA;&#xA;<p>In a monolith, this constraint would've been conceptually very easy to deal with. Upon receiving a request to delete a post, supplying the post id and user id,</p>&#xA;&#xA;<ol>&#xA;<li>Fetch the event which the post belongs to.</li>&#xA;<li>Check if the user is the author of the post.</li>&#xA;<li>If yes, delete the post. If not, fetch the hosts of the event.</li>&#xA;<li>Check if the user is among the hosts.</li>&#xA;<li>If yes, delete the post.</li>&#xA;</ol>&#xA;&#xA;<p>However, with a microservice strategy, I have a hard time figuring out how to divide the responsibilities of an operation like this across the services.</p>&#xA;&#xA;<h2>Alternative 1</h2>&#xA;&#xA;<p>An easy way around it would be to put logic like this in the gateway. That way, the same procedure as described above could essentially be performed, but with calls to the services instead of directly to the database. Rough sketch:</p>&#xA;&#xA;<pre class=""lang-js prettyprint-override""><code>// Given postId and userId&#xA;// Synchronous solution for presentational purposes&#xA;&#xA;const post = postClient('GET', `/posts/${postId}`);&#xA;const hosts = eventClient('GET', `/events/${post.parentId}/hosts`);&#xA;const isHost = hosts.find(host =&gt; host.id == userId);&#xA;&#xA;if (isHost) {&#xA;    postClient('DELETE', `/posts/${postId}`);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I'm not happy with this solution. Once I start putting logic like this in the gateway, it'll become very tempting to <em>always</em> do it, as it's a quick and simple way to get things done. All business logic would eventually amass in the gateway, and the services would become ""stupid"" CRUD endpoints. This would defeat the purpose of having separate services with well-defined areas of responsibility.  Furthermore, it could be slow as it could give rise to a high number of calls to the services when operations are getting more complex.</p>&#xA;&#xA;<p>I would essentially be reinventing the monolith, replacing database queries with slow and limited network calls.</p>&#xA;&#xA;<h2>Alternative 2</h2>&#xA;&#xA;<p>Another option would be to allow unlimited communication <em>between</em> services, allowing PostService to simply ask EventService whether the user is a host of the event in question before performing the delete. However, I'm afraid that having a potentially large number of microservices communicating with each other could introduce a lot of coupling in the longer run. Experts seem to generally advise against direct inter-service communication.</p>&#xA;&#xA;<h2>Alternative 3</h2>&#xA;&#xA;<p>With a solid system for publishing and subscribing to events, the services could stay updated about what happens in other services. For example, every time a user is promoted to host in EventService, an event would be posted (e.g. <code>events.participant-status-changed, {userId: 14323, eventId: 12321, status: 'host'}</code>). PostService could subscribe to the event and remembering this fact when a request to delete a post is received.</p>&#xA;&#xA;<p>However, I'm not quite happy with this one either. It'd create a very intricate and error-prone system, where an unhandled (but potentially rare) event could make services go out of sync. Also, there's a risk that logic would end up in the wrong place. For example, the constraint in this question would be handled by PostService even though conceptually it's a property of the event entity.</p>&#xA;&#xA;<p>I should stress though that I'm very optimistic about the usefulness of events when implementing applications using microservices. I'm just not sure they are the answer to this category of problems.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How would you tackle this hypothetical, but quite realistic difficulty?</p>&#xA;"
45351222,Is it possible to proxy a POJO in microservices application?,2017-07-27 12:45:39,<java><spring-boot><microservices>,1,140,2,0.0,3,"<p>I would like to avoid duplicating my POJOs in a microservices application, so I am wondering if there is a way to do that (like proxying)?</p>&#xA;&#xA;<p>I mean, is there a way for a <code>Service A</code> to access POJOs (or other classes/interfaces) defined inside a <code>Service B</code> without physically creating these POJOs classe files in <code>Service A</code>? </p>&#xA;&#xA;<p>The big big challenge in a microservice architecture is that point and I didn't find a way to solve it.</p>&#xA;"
51783877,How Ribbon get the list of Available instances of a service,2018-08-10 09:56:30,<spring><microservices><ribbon><eureka>,1,27,0,0.0,3,<p>I am using ribbon as load balancer on API gateway and eureka server. When client request comes to my API gateway does it query service registry every time to get the avaliable instance of a service or ribbon stores the available instances into it's cache.</p>&#xA;
51939287,Design of cloud Microservice on Heroku advice,2018-08-20 22:28:01,<heroku><design><architecture><microservices><paas>,1,43,0,0.0,3,"<p>I am new to the world of microservice and I have tried to learn about it and how it could be apply to my needs. I need to design a cloud plaform easily maintenable and scalable with the following (as far as I see them) :</p>&#xA;&#xA;<ul>&#xA;<li>Rails API + PostgreSQL (microservice 1)</li>&#xA;<li>Frontend framework (microservice 2)</li>&#xA;<li>Some Python script (microservice 3)</li>&#xA;<li>Some other Python script (microservice 4)</li>&#xA;</ul>&#xA;&#xA;<p>Inspired by <a href=""https://stackoverflow.com/questions/41795612/how-to-deploy-microservices-on-heroku"">this question &amp; answer</a>, <strong>each microservice is a separate Heroku app</strong>. What about the security between them when they talk to each other and the response time?</p>&#xA;&#xA;<p>Also, since the service is meant to grow, it would be expensive sooner or later, how to optimize cost in this situation ? I just discovered <a href=""https://captainduckduck.com/"" rel=""nofollow noreferrer"">CaptainDuckDuck</a> but I'm afraid of the ""lack"" of experience from its user base since it's quite new and not as much popular as other PaaS. Is the only solution is to go to something like DigitalOcean or AWS EC2 and manage by ourselves the job that Heroku does ?</p>&#xA;&#xA;<p>Because doing microservice like this, is not really a microservice design since all the services are not hosted on the same machine, am I right ?&#xA;A more <em>microservice-friendly</em> approach would be to use <a href=""https://www.heroku.com/private-spaces"" rel=""nofollow noreferrer"">Heroku Private Spaces</a> (even if that doesn't answer the cost issue) ?</p>&#xA;&#xA;<p>For information, I have this design already up and running. So it's not a matter of <em>""will it work?""</em>, but more <em>""is it the right way?""</em>.</p>&#xA;&#xA;<p>Thanks for your feedbacks</p>&#xA;"
51821786,@EnableZuulProxy doesnot work due to `HttpServletRequest` class not found,2018-08-13 11:55:10,<java><spring-boot><microservices><netflix-zuul>,1,130,6,0.0,3,"<p>I am writing a <code>Zuul</code> enabled API gateway for my microservices,&#xA;However while starting the the microservice containing <code>zuul</code>, I am getting the below mentioned error</p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: <strong>Caused by: java.lang.ClassNotFoundException:</strong>&#xA;  <strong>javax.servlet.http.HttpServletRequest</strong></p>&#xA;</blockquote>&#xA;&#xA;<p>After numerous search, I have found below two solutions which does not help me. Hence I am here</p>&#xA;&#xA;<ol>&#xA;<li>Enable the <code>Apache tomcat facet</code>. This for some reason disabled in <code>Dynamic web module 3.0</code>.</li>&#xA;<li>Creating custom <code>dispatcher servlet</code>. But this solution should be feasible when we use servlet 2.5.</li>&#xA;</ol>&#xA;&#xA;<p>Since I am using a spring-boot app imported from <code>https://spring.io</code>, so it cements that I am using <code>servlet 3.0</code>.</p>&#xA;&#xA;<p>My API gateway <code>pom.xml</code>:</p>&#xA;&#xA;<pre><code>&lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>I have annotated my API gateway class with <code>@EnableZuulProxy</code>.</p>&#xA;&#xA;<p>Having said these could you please help me with my error highlighted above.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Edit:  When I change the &#xA;  1. <code>spring-starter-parent</code> to <strong>1.5.3RELEASE</strong> instead of the latest.&#xA;  2. <code>spring-cloud.version</code> to <strong>Edgware.SR2</strong> from <strong>Finchley.SR1</strong>. I face no issue at all.</p>&#xA;</blockquote>&#xA;&#xA;<p>I guess it is latest spring thing ? Any thoughts!</p>&#xA;"
51889526,Why would we go for micro-services if there is requirement for lower latency code?,2018-08-17 06:25:20,<java><microservices>,1,63,8,1.0,3,"<p>In a monolith, we just need to either make a function call or method invocation as opposed to inter process communication. Can someone familiar with micro-services architecture help to understand reasons how you can use micro services for developing low latency applications?</p>&#xA;&#xA;<p>I think Chronicle framework claims that you can develop micro-services based products and use chronicle queues to communicate without incurring network hop latency. </p>&#xA;"
51542197,Async Flows Design in Lagom or Microservices,2018-07-26 15:12:22,<domain-driven-design><microservices><lagom>,1,67,7,5.0,3,"<p>How to design asyn flows in Lagom ? </p>&#xA;&#xA;<p>Problem faced: In our product we have a Lead Aggregate which has a User Id (represents the owner of the lead), Now User has a limitation which says one user can have max of 10 Lead associated with this. We designed this by creating a separate Service ResourceManagement and when a User asks for Picking a Lead, we send a Command to LeadAggregate which generates a Event LeadPickRequested. On ProcessManager Listen to the event and asks for the Resource From ResourceManagement, on Success send Command to LeadAggregate - MarkAsPicked and on this send Push notification to the User that Lead is Picked but from building the UI perspective its very difficult and same cannot be done for exposing our API to third party. </p>&#xA;&#xA;<p>One Sol. we have done is when request is received on Service save a RequestID Vs Request Future . in Command Add the request Id and when the LeadAggregate finally change into Picked State or Picked Failure a PM listen to the event , checks if a RequestFuture is there for the request Id , then complete the future with correct response. This way it works as Sync API for the end User. </p>&#xA;&#xA;<p>Any Better Sol. for this</p>&#xA;"
40702179,micro service web app with AWS,2016-11-20 08:43:36,<amazon-web-services><amazon-s3><amazon-ec2><microservices>,1,601,0,2.0,3,"<p>I am developing a web application for image upload and retrieval with AWS cloud services using a micro service architecture.&#xA;I am new to AWS and micro service architecture, please help me map the components of the architecture to AWS components.</p>&#xA;&#xA;<p>Do i consider each micro service to run on one EC2 instance with auto scaling and load balancing?&#xA;Or do I run each micro service on one EC2 cluster?</p>&#xA;&#xA;<p>If i put my static html files in an S3, how can i call database methods to load the html pages with content? &#xA;Is it by calling am API gateway from the client?</p>&#xA;&#xA;<p>I have searched the web, but was unable to find a tutorial which implements multiple services as micro services using AWS EC2 / ECS.</p>&#xA;&#xA;<p>Please help me figure out how to map my requirements and if there are any tutorials on implementing a similar app, will be very helpful.</p>&#xA;&#xA;<p>Thank you in advance! :)</p>&#xA;"
40760397,java.lang.ClassNotFoundException on Maven dependencies,2016-11-23 09:23:29,<java><spring><maven><spring-boot><microservices>,1,542,4,3.0,3,"<p>We have a set of Spring Boot applications organized as microservices running successfully for a few months. We used Sprig Boot 1.3.3.</p>&#xA;&#xA;<p>Now we have a problem with maven build process switching to Spring Boot 1.4.2. We are developing microservice based software architecture. We have <strong>core.common</strong> service which is referenced by other services using dependecies like this:</p>&#xA;&#xA;<pre><code>&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;com.group&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;core.common&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;        &lt;scope&gt;compile&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt; &#xA;</code></pre>&#xA;&#xA;<p>This service is responsible for providing common classes and methods needed to each of other services. </p>&#xA;&#xA;<p>We also use separate service (<strong>root.service</strong>) to build <strong>all other services</strong> and to package them into <code>jar</code> files. This is the part of <code>pom.xml</code> from that <strong>root.service</strong>:</p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;modules&gt;&#xA;        &lt;module&gt;../core.adminservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.locationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.reportservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.userservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.notificationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.trackingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.mappingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.common&lt;/module&gt;&#xA;    &lt;/modules&gt;&#xA;</code></pre>&#xA;&#xA;<p>Until switched to Spring Boot 1.4.2 version we were able to do <code>mvn clean install</code> over <strong>root.service</strong> to test and build the rest of the services from <strong>modules</strong> specification. </p>&#xA;&#xA;<p>After switching to Spring Boot 1.4.2 version, when I try to execute <code>mvn clean install</code> in <strong>root.service</strong> I am getting <code>java.lang.ClassNotFoundException</code>. Exception message says that none of the services form <strong>modules</strong> specification cannot find any of classes from <strong>core.common</strong> service used in particular service from <strong>modules</strong>.&#xA;When I try to run <code>mvn compile</code> or <code>mvn test</code> everything runs just fine and I get successful builds and tests. When I try to run services from <strong>eclipse</strong> also everything is just fine.</p>&#xA;&#xA;<p>Do you have any ideas? Please help.</p>&#xA;&#xA;<p><strong>EDIT</strong>&#xA;Full stack trace for one use case:</p>&#xA;&#xA;<pre><code>Running com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.002 sec &lt;&lt;&lt; FAILURE! - in com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;initializationError(com.blockpeek.core.adminservice.tests.services.AdminServiceTest)  Time elapsed: 0.002 sec  &lt;&lt;&lt; ERROR!&#xA;java.lang.NoClassDefFoundError: com/blockpeek/core/common/services/AbstractCRUDService&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;Caused by: java.lang.ClassNotFoundException: com.blockpeek.core.common.services.AbstractCRUDService&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;</code></pre>&#xA;&#xA;<p>Maven Version:</p>&#xA;&#xA;<pre><code>$ mvn -version&#xA;Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T17:41:47+01:00)&#xA;Maven home: C:\Program Files\apache-maven-3.3.9&#xA;Java version: 1.8.0_101, vendor: Oracle Corporation&#xA;Java home: C:\Program Files\Java\jdk1.8.0_101\jre&#xA;Default locale: en_US, platform encoding: Cp1252&#xA;OS name: ""windows 10"", version: ""10.0"", arch: ""amd64"", family: ""dos""&#xA;</code></pre>&#xA;&#xA;<p><strong>EDIT 2:</strong> This is what I get if i run <code>mvn -e clean install</code>:</p>&#xA;&#xA;<pre><code>[ERROR] -&gt; [Help 1]                                                                                                                             &#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:compile (def&#xA;ult-compile) on project core.adminservice: Compilation failure                                                                                  &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)                                                      &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)                             &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)                              &#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)                &#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)                                              &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)                                                                       &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)                                                                       &#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)                                                                         &#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)                                                                             &#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)                                                                              &#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)                                                                                &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                          &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                        &#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                &#xA;        at java.lang.reflect.Method.invoke(Method.java:498)                                                                                     &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)                                                  &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)                                                          &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)                                                &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)                                                            &#xA;Caused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure                                                    &#xA;        at org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:1029)                                        &#xA;        at org.apache.maven.plugin.compiler.CompilerMojo.execute(CompilerMojo.java:137)                                                         &#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)                                    &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)                                                      &#xA;        ... 20 more                                                                                                                             &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.                                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:                                       &#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] After correcting the problems, you can resume the build with the command                                                                &#xA;[ERROR]   mvn &lt;goals&gt; -rf :core.adminservice  &#xA;</code></pre>&#xA;"
45648115,Dockering a nodejs application with external dependencies,2017-08-12 08:20:12,<node.js><docker><containers><microservices>,2,178,0,1.0,3,"<p>We are building Node.js microservices. For some reusable components we have created a utils folder. This folder is outside the actual microservices package. When we run the microservices, we can refer to that code using <code>require(../../utils/logger)</code> and it works like a charm.&#xA;However when trying to create the docker image for my microservices </p>&#xA;&#xA;<pre><code>project the container gives me an error saying:&#xA;Error: Cannot find module '../../Utils/logger&#xA;</code></pre>&#xA;&#xA;<p>which makes a lot of sense as we are building the docker image inside the microservice project.&#xA;There are few architectural decisions which needs to be taken here:</p>&#xA;&#xA;<ol>&#xA;<li><p>We move the utils code into each microservice as required.</p>&#xA;&#xA;<ul>&#xA;<li>Pro: Microservice remains self sustained completely and no code level dependency on any other package.</li>&#xA;<li>Cons: Maintenance of cross cutting concerns and the changes would be cumbersome.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>2.Create a private npm module and inject dependency into the microservice package.json file. Not sure if that would work.</p>&#xA;&#xA;<p>Any suggestions on this are highly appreciated.</p>&#xA;&#xA;<p>Best,&#xA;- Vaibhav</p>&#xA;"
45688730,Decompose microservices: Business capability vs Domain,2017-08-15 08:01:46,<domain-driven-design><microservices><software-design>,1,1010,2,3.0,3,"<p>As I read, there are two patterns to define one microservice, by <a href=""http://microservices.io/patterns/decomposition/decompose-by-business-capability.html"" rel=""nofollow noreferrer"">business capability</a> and by <a href=""http://microservices.io/patterns/decomposition/decompose-by-subdomain.html"" rel=""nofollow noreferrer"">subdomain</a>. But I still find it very ambiguous. I get confused how these two patterns differentiate from each other. Both of them revolve around activities involving an area of business logic. All of components in each service are small enough to get packaged with each other without affecting other services. Could anyone please give me a further explanation about these two?</p>&#xA;"
28339882,"service discovery, load balancing and connection pooling approach",2015-02-05 09:03:45,<load-balancing><connection-pooling><soa><microservices>,1,642,0,1.0,4,<p>There are two approaches that can be used for service interaction when having SOA for large systems deployed on cloud like AWS.</p>&#xA;&#xA;<ol>&#xA;<li><p>Have each service cluster behind internal elb. client makes a connection pool with corresponding elb and elb does round-robin balancing.</p></li>&#xA;<li><p>going with service discovery approach like netflix eureka.</p></li>&#xA;</ol>&#xA;&#xA;<p>Currently we are using 1st approach where each service cluster is behind internal elb and clients communicate via elbs so each client instance has to maintain only 1 pool i.e. with the elb endpoint.</p>&#xA;&#xA;<p>I have following doubts regarding 2nd apporach.</p>&#xA;&#xA;<ol>&#xA;<li>Is there a benefit in moving to service discovery and smart client architecture where service client knows all service instances (via eureka service or equivalent) and does internal load balancing?</li>&#xA;<li>In above case how does connection pooling work? Currently each client instance has to maintain exactly 1 connection pool i.e. with the corresponding service's elb. But with rich client each client will have all the service instance endpoints to directly communicate to. Making connection on each request will not be efficient and having so many connection pools (1 for each service instance) for each client is a overkill I guess.</li>&#xA;</ol>&#xA;&#xA;<p>Need inputs/suggestions on above two questions.</p>&#xA;
29071226,What is a good practice to promote a microservice to a public API?,2015-03-16 07:03:15,<design><architecture><microservices>,3,996,0,3.0,4,"<p>Microservices seem to be a very good fit for my software after watching and reading number of articles from Martin Fowler, Sam Newman, Adrian Cockcroft and Sudhir Tones. However, when thinking deeper into the implementation, there are number of concerns:</p>&#xA;&#xA;<ol>&#xA;<li>My software has an UI, let's call it a web-based component. This component will need to coordinate/orchestrate calls to 10-20 different microservices internally (let's call it ""private microservices"") and return data to the AJAX call. Is it a good design to couple the orchestration logic in this component? Or should I create another microservice that does the job and the web-based component should be very thin to delegate the call to this microservice?</li>&#xA;<li>I will need to expose some public APIs. Should I have a separate layer to delegate the call like in the case above? </li>&#xA;</ol>&#xA;&#xA;<p>I think it might be more or less about the design pattern for public/private microservices. </p>&#xA;&#xA;<p>What would be a good pattern to address the above concerns?</p>&#xA;&#xA;<p><strong>Updated on 9 Apr 2015</strong>:</p>&#xA;&#xA;<p>API Gateway Pattern actually addresses my concerns. I also agree with other answers regarding EAI patterns or security consideration.</p>&#xA;&#xA;<p>To extend more regarding my findings, I think Netflix architecture is having, so-called ""edge service"", which is the front tier that is serving requests coming from either web-based or devices and the middle-tier services are actually your microservices. So i think to promote a middle-tier service to be an edge-service, this has to be a delegate. It will keep the middle-tier clean and consistent. </p>&#xA;&#xA;<p>Have a look at <a href=""https://github.com/cfregly/fluxcapacitor#project-overview"" rel=""nofollow"">https://github.com/cfregly/fluxcapacitor#project-overview</a> to have more ideas.</p>&#xA;"
26529567,What are the strategies available for doing pagination or filtering data using microservices architecture?,2014-10-23 13:46:09,<filter><pagination><filtering><paging><microservices>,1,743,0,1.0,4,<p>Usually when you have a monolithic application or data model then you can create a SQL joining different tables and apply filters to them. Then once you get resultset back you can page that data as well. But if you are using microservice architecture the data model might be disparate. I heard netflix actually takes it to an extreme where they have every table  exposed as a microservice. How can you handle paging and filtering in this case?</p>&#xA;&#xA;<p>I know they use API Gateway pattern which  could act as aggregation layer (probably this is where RxJava like projects come in). It would be great to have ideas from people using microservices or tackle this problem.</p>&#xA;
33118913,Authentication and Authorization in Microservices,2015-10-14 07:13:53,<authentication><oauth-2.0><authorization><microservices>,1,608,0,1.0,4,"<p>I've been reading a fair bit on Microservices recently, and especially around AuthN and AuthZ. For the most part, this all makes a lot of sense, and I can see how it all should work.</p>&#xA;&#xA;<p>For what I'm playing with, I going with delegated authorization - so I'm to be passing tokens around from client to service, and then passing the same token on from service to service. I also have an endpoint on the OAuth2 Service that will accept a token and return the details of the token - the User ID, the Start and End of the validity period, the scopes that the token is valid for, etc.</p>&#xA;&#xA;<p>The problem that I'm running into here is - in order to correctly issue a token, there needs to be some communication with the User Service to ensure that the User that the token is for is actually valid. And in order to verify a Token, there needs to be some communication with the User Service to ensure that the User is still valid. And yet, in order to safely communicate with the User Service to get details about a User, a Token is needed that gives permission for this access.</p>&#xA;&#xA;<p>I assume there is some standard practice on how to solve this circular dependency between the OAuth2 and User Service, but I've not seen any mention of it at all. Is this a common problem? Or have I just missed something obvious?</p>&#xA;&#xA;<p>(Note - for now I'm only implementing Client Credentials Grant and Resource Owner Password Credentials Grant, since I'm only playing around to see how it all works and they're easier to call with cURL. I don't know that this makes any difference though)</p>&#xA;"
30995669,Microservices service registry registration and discovery,2015-06-23 06:46:40,<web-services><rest><service><amqp><microservices>,1,1494,0,3.0,4,"<p><strong>Little domain presentation</strong></p>&#xA;&#xA;<p>I m actually having two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User - managing CRUD on users</li>&#xA;<li>Billings - managing CRUD on billings, with a ""reference"" on a user concerned by the billing</li>&#xA;</ul>&#xA;&#xA;<p><strong>Explanation</strong></p>&#xA;&#xA;<p>I need, when a billing is called in a HTTP request, to send the fully billing object with the user loaded. In that case, and in this specifical case, I really need this.</p>&#xA;&#xA;<p>In a first time, I looked around, and it seems that it was a good idea to use message queuing, for asynchronicity, and so the billing service can send on a queue :</p>&#xA;&#xA;<blockquote>&#xA;  <p>""who's the user with the id 123456 ? I need to load it""</p>&#xA;</blockquote>&#xA;&#xA;<p>So my two services could exchange, without really knowing each other, or without knowing the ""location"" of each other.</p>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>My first question is, what is the aim of using a service registry in that case ? The message queuing is able to give us the information without knowing anything at all concerning the user service location no ?</p></li>&#xA;<li><p>When do we need to use a service registration :&#xA;In the case of Aggregator Pattern, with RESTFul API, we can navigate through hateoas links. In the case of Proxy pattern maybe ? When the microservices are interfaced by another service ?</p></li>&#xA;<li><p>Admitting now, that we use proxy pattern, with a ""frontal service"". In this case, it's okay for me to use a service registration. But it means that the front send service know the name of the userService and the billing service in the service registration ? Example :</p></li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>Service User registers as ""UserServiceOfHell:<a href=""http://80.80.80.80/v1/"" rel=""nofollow"">http://80.80.80.80/v1/</a>""&#xA;  on ZooKeeper</p>&#xA;  &#xA;  <p>Service Billing registers as ""BillingService:<a href=""http://90.90.90.90/v4.3/"" rel=""nofollow"">http://90.90.90.90/v4.3/</a>""</p>&#xA;</blockquote>&#xA;&#xA;<p>The front end service  needs to send some requests to the user and billing service, it implies that it needs to know that the user service is ""UserServiceOfHell"". Is this defined at the beginning of the project ?</p>&#xA;&#xA;<ul>&#xA;<li>Last question, can we use multiple microservices patterns in one microservices architecture or is this a bad practice ?</li>&#xA;</ul>&#xA;&#xA;<p><em>NB : Everything I ask is based on <a href=""http://blog.arungupta.me/microservice-design-patterns/"" rel=""nofollow"">http://blog.arungupta.me/microservice-design-patterns/</a></em></p>&#xA;"
33926707,Passing objects between microservices,2015-11-25 21:28:36,<php><oop><soa><microservices>,1,527,0,1.0,4,"<p>I am experimenting with moving some parts of a monolith to external services. I like the idea so far and it seems a lot cleaner to encapsulate all related functionality inside one application. The different applications use RabbitMQ to communicate. </p>&#xA;&#xA;<p>I have a user object in one service. If I want to use this exact same class in the service I can easily serialize it and send the serialized object in the message body. But since both the sender and receiver need to contain the user class I would have to share a library containing some representation of the user object (although to me it seems strange to put the real user object in the library since it's core to the main application). I guess I could also just pass an array with a <code>user</code> key and defined key-values.</p>&#xA;&#xA;<p>I'm also thinking that if I someday create a service in something other than PHP then it won't be able to unserialize the user object and thus will have no access to the data in the message.</p>&#xA;&#xA;<p>So basically I like the idea of passing entities between services and being able to user them as objects in the receiving end, but I'm not sure if this is the right approach.</p>&#xA;&#xA;<p>My question is what would the best way to pass objects between these services be?</p>&#xA;"
40234243,OAuth 2.0 service to service authentication and best practices,2016-10-25 07:48:33,<authentication><oauth><microservices>,1,519,0,0.0,4,"<p>I have to deal with such type of auth flows:</p>&#xA;&#xA;<ol>&#xA;<li>Create auth flows for Web users;</li>&#xA;<li>In the same way deal with service to service authentication</li>&#xA;</ol>&#xA;&#xA;<p>Briefly following diagram can depict main components that we'll have:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NzDM7.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/NzDM7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>For users Authentication we'd like to use OAuth2 (the Implicit Flow) and in general it looks more or less clear.</p>&#xA;&#xA;<p>The question about service to service authorization can it be OAuth2 Authorization Code Flow used?</p>&#xA;&#xA;<p>The main problem there that inside of datacenter1 it will be plenty of backend services that's why it will be good as services will work on the similar permission model as a users (at least some some functionality might be retracted ).</p>&#xA;&#xA;<p>And additional question: what is the general recommendation for this use case if Authorization Server is inside of Datacenter1 or outside?</p>&#xA;"
39015444,Should instances of a horizontally scaled microservice share DB?,2016-08-18 10:08:28,<docker><soa><microservices>,1,134,0,3.0,4,"<p>Given a microservice that owns a relational database and needs to scale horizontally, I see two approaches to provisioning of the database server:</p>&#xA;&#xA;<ul>&#xA;<li>provide each instance of the service with it's own DB server instance with a coupled process lifecycle </li>&#xA;</ul>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<ul>&#xA;<li>have the instances connect to a shared (by identical instances of the same service) independent db server or cluster</li>&#xA;</ul>&#xA;&#xA;<p>With an event driven architecture and the former approach, each instance of the microservice would need to process each event and take the appropriate action to mutate its own isolated state. This seems inefficient.  </p>&#xA;&#xA;<p>Taking the latter approach, only one instance has to process the event to achieve the same effect but as a mutation of the shared state. One must ensure each event is processed by only one instance of the given microservice (is this trivial?) to avoid conflict.</p>&#xA;&#xA;<p>Is there consensus on preferred approach here? What lessons has your experience taught you on this?</p>&#xA;"
41445442,How to sync the database with the microservices (and the new one)?,2017-01-03 14:12:27,<mysql><database><message-queue><microservices><nsq>,1,888,12,0.0,4,"<p>I'm developing a website with the microservice architecture, and each of the service owns a database. The database stores the data which the microservice needs.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><code>Post</code>, <code>Video</code> services need the user information, so both of the services subscribed to the <code>NEW_USER_EVENT</code>. </p>&#xA;&#xA;<p>The <code>NEW_USER_EVENT</code> will be triggered when there's a new user registered.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0SY8a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0SY8a.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Once the services received the <code>NEW_USER_EVENT</code>, they put the incoming user information to each of their own database. So they can do things without asking the <code>User</code> service.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NR8Xk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NR8Xk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>So far so good. But here comes the question:</p>&#xA;&#xA;<ul>&#xA;<li>What if I'm going to create a new service? How do I get the registered user informations and put them in the new service?</li>&#xA;</ul>&#xA;&#xA;<p>Maybe I can get the informations from the existing services. But the events are pushed by the messaging queue (<code>NSQ</code>). </p>&#xA;&#xA;<p>If I'm going to copy the data from one of the microservices, how do I make sure which service has the latest user informations? (<em>Because some services haven't received the latest event</em>) </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/vJoGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vJoGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><em>Read More:</em></p>&#xA;&#xA;<p><a href=""http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/"" rel=""nofollow noreferrer"">The Hardest Part About Microservices: Your Data</a></p>&#xA;&#xA;<p><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""nofollow noreferrer"">Intro to Microservices, Part 4: Dependencies and Data Sharing</a></p>&#xA;"
36080524,Rails: How to listen to / pull from service or queue?,2016-03-18 09:21:32,<ruby-on-rails><rabbitmq><apache-kafka><microservices>,4,2107,3,0.0,4,"<p>Most Rails applications work in a way that they are waiting for requests comming from a client and then do their magic.&#xA;But if I want to use a Rails application as part of a microservice architecture (for example) with some asychonious communication (Serivce A sends an event into a Kafka or RabbitMQ queue and Service B - my Rails app - is supposed to listen to this queue), how can I tune/start the Rails app to immediately listen to a queue and being triggered by event from there? (Meaning the initial trigger is not comming from a client, but from the App itself.)</p>&#xA;&#xA;<p>Thanks for your advice!</p>&#xA;"
31717615,Databases in a microservices pattern/architecture,2015-07-30 07:27:01,<web-services><rest><design-patterns><microservices>,2,453,0,3.0,4,"<p>I'm trying to understand the layout of the microservices pattern. Given that each microservice would run on its on VM (for sake of example) how does the database fit into this architecture? </p>&#xA;&#xA;<p>Would each service, in turn, connect to the consolidated database to read/write data? </p>&#xA;&#xA;<p>Thanks for any insight</p>&#xA;"
35613841,Most efficient way to communicate between multiple .NET apps,2016-02-24 21:48:15,<.net><rest><azure><architecture><microservices>,4,1116,0,2.0,4,"<p>Currently i have a setup where my clients (web apps, iOS app etc) talks to my backend API .NET web app (Nancy) via REST calls. Nothing special.</p>&#xA;&#xA;<p>I now have a requirement to split this API up into microservices, where each service can be individually upgraded/deployed. </p>&#xA;&#xA;<p>My main API (public) will just perform authentication, then call into one of my microservices, which will be in my private network.</p>&#xA;&#xA;<p><strong>What's the different ways i could communicate between my main API and other microservice API's? Pros/cons of each approach?</strong></p>&#xA;&#xA;<p>The communication needs to be realtime - e.g request comes in from a browser/device, main API performs auth, then calls into microservice API then returns response. So i can't use things like queues or pub/sub. It doesn't necessarily need to use HTTP, but it needs to be realtime communication (request/response). I also have other services (WebJobs, cloud services, etc) that need to talk to these microservices (they are also in the private network).</p>&#xA;&#xA;<p>The only approach that comes to mind is simple REST-based calls. Totally fine, but latency is the main issue here.</p>&#xA;&#xA;<p>Can anyone recommend any other solutions to this problem? Is there anything in Azure suited to this?</p>&#xA;&#xA;<p>Many thanks</p>&#xA;"
35465175,"microservice architecture questions about code resue, security and database sharing",2016-02-17 18:49:53,<microservices>,1,117,0,1.0,4,<p>I have the following questions about micro service architecture</p>&#xA;&#xA;<ol>&#xA;<li><p>How common code/utility-libs are being reused between different micro services? Where this common code is also being developed</p></li>&#xA;<li><p>In my micro-service some services are for clients and some can be internal ( for other micro services to use). What is the best option to make internal services secure?</p></li>&#xA;<li><p>What if two micro-services has to use the same database? Say they do totally different operations but using the same database table?</p></li>&#xA;<li><p>Micro services are mostly about the back end but the GUI is going to be the same. In that case each micro service deployment requires website update as well. Is that consider as a disadvantage?</p></li>&#xA;</ol>&#xA;
39763013,many log files on azure service fabric,2016-09-29 06:33:42,<azure><microservices><azure-service-fabric>,2,628,0,0.0,4,"<p>I have a azure service fabric development cluster running locally with two applications.</p>&#xA;&#xA;<p>After a two week holiday I come back and see that my hard drive is completely full, consequently nothing really works anymore.</p>&#xA;&#xA;<p>the sfdevcluster\log\traces folder has many *.etl files all larger than 100MB.&#xA;And all kinds of other log files > 250 MB are present</p>&#xA;&#xA;<p>So my questions: how to disable tracing/logging on azure service fabric and are there tools to administer log files?</p>&#xA;"
39852947,"Spring microservices, stateless session, angular and static file serving",2016-10-04 12:56:13,<angularjs><spring-security><spring-boot><spring-cloud><microservices>,1,577,1,0.0,4,"<p>I am designing the backend of large application which is divided into microservices. I am using <strong>Spring Cloud</strong> with its tools: <strong>Eureka</strong>, <strong>Zuul</strong> and etc. I have implemented <strong>OAuth2</strong> authorization server which supports four grant types. It is working without problems.</p>&#xA;&#xA;<p>Then I was asked to serve <strong>html files</strong> and <strong>in such manner that if not authorized, backend must redirect to login page and strongly recommended that I don't use sessions</strong>. I thought that without session spring cant really know what's going with, in the end <strong>it must have token to decide to build security context</strong>.</p>&#xA;&#xA;<p>I started researching about this issue. I found that examples from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/"" rel=""nofollow"">Spring Security and Angular JS tutorial</a> show that routings and redirections are accomplished inside <strong>angular</strong> with the help of <strong>ui-route</strong>. I skimmed several projects in github and they also were using angular for redirections.</p>&#xA;&#xA;<p>Is it possible to redirect using backend in totally stateless session?(This sounds so dumb, but it couldn't be expressed otherwise. I want to give this answer to my coworkers that are stating that is possible). If possible, are there any examples?</p>&#xA;"
39215533,spring cloud config : how to use multiple configs,2016-08-29 21:30:41,<java><microservices><spring-cloud-config>,1,4253,0,1.0,4,"<h3>What I want to try:</h3>&#xA;&#xA;<p>I want to try the <code>spring cloud config</code> for microservice project where I have a <code>common config</code> for all services and <code>multiple configs</code> for each service.<br>&#xA;I got idea on how to use multiple <code>profiles</code> using <code>spring.profiles.active</code> and <code>include</code>. I am trying to understand how can I load multiple configs on config client?</p>&#xA;&#xA;<h3>What I have:</h3>&#xA;&#xA;<p>In my git repo I have <code>spring-config-repo</code> where I have ...</p>&#xA;&#xA;<pre><code>application.yml&#xA;orderclient.yml&#xA;subscriberclient.yml&#xA;jmsclient.yml&#xA;productclient.yml&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>config Server</code> pointed to my config repo. </p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;  name: config-service&#xA;  cloud:&#xA;   config:&#xA;    server:&#xA;      git:&#xA;        uri: https://github.com/&lt;user&gt;/spring-config-repo&#xA;&#xA;server:&#xA; port: 8888&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>spring client</code> where I want to use multiple configs. Here in my case for <code>orderService</code> I want to load <code>application.yml,orderclient.yml,jmsconfig.yml</code> and For Product microService I need 'orderconfig.yml,jmsclient.yml,productclient.yml'</p>&#xA;&#xA;<pre><code>spring:&#xA;application:&#xA;  name: orderclient&#xA;profiles:&#xA;  active: test&#xA;cloud:&#xA;  config:&#xA;    uri: http://localhost:8888&#xA;&#xA;###Any kind of config properties to load jmsclient, productclient?&#xA;</code></pre>&#xA;&#xA;<p>Above I can access properties from orderclient.yml.</p>&#xA;&#xA;<h2>My Question:</h2>&#xA;&#xA;<h3>Question1:</h3>&#xA;&#xA;<p>How to access properties of <code>jmsclient.yml,productclient.yml</code> in <code>orderclient</code> application. </p>&#xA;&#xA;<h3>Question2:</h3>&#xA;&#xA;<p>Is there anyway to get list of all <code>propertySources.name</code> exposed by config server? where in above case it should dispaly</p>&#xA;&#xA;<pre><code>""propertySources"": {&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/aplication.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test,&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/orderclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/jmsclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA; ....}&#xA;</code></pre>&#xA;&#xA;<p>Please let me know if my question is not clear or need more information. Thanks.</p>&#xA;"
39228311,Best practices for storing content in secure area,2016-08-30 13:04:59,<node.js><microservices>,1,44,1,0.0,4,<p>In our project we have separate login page and several SPAs which user can access only after proper authentication.&#xA;All static content is placed in public CDN. But html files of SPAs are stored in DB and delivered to user by index service.&#xA;We don't want to store html files in DB because it is inconvenient for us.</p>&#xA;&#xA;<p>What is the best way to store html files in secure area?</p>&#xA;
47938835,How to create replay mechanism within event-drive microservice,2017-12-22 09:17:08,<java><architecture><transactions><microservices><event-driven-design>,2,170,3,1.0,4,"<p>We have 7 microservices communicated via eventbus.&#xA;We have a real-time transaction sequence:</p>&#xA;&#xA;<p>Service 1->service2->service3 (and so on.) Until transactions considered as completed</p>&#xA;&#xA;<p>We must make sure all transactions happened.</p>&#xA;&#xA;<p>Ofcourse we can have failures at any point. So we are thinking about mechanisem to replay ""half-baked"" transactions into completion.</p>&#xA;&#xA;<p>It's getting tricky. Two ways we thought about:</p>&#xA;&#xA;<ol>&#xA;<li><p>Having another service (supervisor service) that will log each part in our real time sequence and will be smart enough when transactions are not completed (timedout) to understand how we can continune from left point</p>&#xA;&#xA;<p>Disadvantages:&#xA;lots of ""smart"" logic on one central service</p></li>&#xA;<li><p>having retry mechanisem on every service while each one taking care of it's own and replay it's own until success or exhusated</p>&#xA;&#xA;<p>Disadvantages:&#xA; lots of retry duplicated code on each service</p></li>&#xA;</ol>&#xA;&#xA;<p>What do you experts think?</p>&#xA;&#xA;<p>Thank</p>&#xA;"
31206417,SOA by microservices - how to normalize/transform messages,2015-07-03 12:03:08,<architecture><soa><transformation><microservices>,3,555,0,1.0,4,"<p>We are developing solution which adapts Messages Pattern and Microservices to define and run business flows.</p>&#xA;&#xA;<p>It should have such components:</p>&#xA;&#xA;<ul>&#xA;<li>Gateways to initiate transaction, with given flow id,</li>&#xA;<li>BPM to store rules (which services should be called for given flow)</li>&#xA;<li>Service selector - kind of processor, it takes request from gateway, get flow definition and then call appropriate services one by one,</li>&#xA;<li>Functional Services.</li>&#xA;</ul>&#xA;&#xA;<p>We should be able to define multiple flows where each step is to call different service.</p>&#xA;&#xA;<p>Output of one service may be input for another one. Problem is that they can have different schema so it should be transformed/normalized somehow.</p>&#xA;&#xA;<p>But which part should be responsible to do such transformation? It should be configurable, because we want to add new flows without redeployment.</p>&#xA;&#xA;<p>First idea is to store responses from each services, and then each step will use XSLT transformation to produce input xml out of previous responses. But it may be configuration hell, cause creating and testing such XSLT won't be easy</p>&#xA;&#xA;<p>Do you have any suggestions how to solve this properly?</p>&#xA;"
31190685,Microservices explained,2015-07-02 17:07:56,<php><microservices>,4,1266,0,1.0,4,<p>I'm trying to understand micro services. Can someone please explain to me how it works? I've looked at several tutorials and still confused.</p>&#xA;&#xA;<p>Let's say you have a shopping application. What are the different microservices entailed for such an application?</p>&#xA;&#xA;<p>I will need to do the following</p>&#xA;&#xA;<ul>&#xA;<li>Account creation</li>&#xA;<li>Charge the customer</li>&#xA;<li>Get a list of items for sale&#xA;etc</li>&#xA;</ul>&#xA;
30288968,Micro Services and noSQL - Best practice to enrich data in micro service architecture,2015-05-17 16:03:12,<microservices>,4,2100,0,5.0,4,"<p>I want to plan a solution that manages enriched data in my architecture.<br>&#xA;To be more clear, I have dozens of micro services.<br>&#xA;let's say - Country, Building, Floor, Worker.<br>&#xA;All running over a separate NoSql data store.  </p>&#xA;&#xA;<p>When I get the data from the worker service I want to present also the floor name (the worker is working on), the building name and country name.</p>&#xA;&#xA;<p><strong>Solution1.</strong><br>&#xA;Client will query all microservices.<br>&#xA;Problem - multiple requests and making the client be aware of the structure.<br>&#xA;I know multiple requests shouldn't bother me but I believe that returning a json describing the entity in one single call is better.</p>&#xA;&#xA;<p><strong>Solution 2.</strong><br>&#xA;Create an orchestration that retrieves the data from multiple services.<br>&#xA;Problem - if the data (entity names, for example) is not stored in the same document in the DB it is very hard to sort and filter by these fields.</p>&#xA;&#xA;<p><strong>Solution 3.</strong><br>&#xA;Before saving the entity, e.g. worker, call all the other services and fill the relative data (Building Name, Country name).<br>&#xA;Problem - when the building name is changed, it doesn't reflect in the worker service. </p>&#xA;&#xA;<p><strong>solution 4.</strong><br>&#xA;(This is the best one I can come up with).<br>&#xA;Create a process that subscribes to a broker and receives all entities change.<br>&#xA;For each entity it updates all the relavent entities.<br>&#xA;When an entity changes, let's say building name changes, it updates all the documents that hold the building name.<br>&#xA;Problem:&#xA;Each service has to know what can be updated.&#xA;When a trailing update happens it shouldnt update the broker again (recursive update),  so this can complicate to the microservices.</p>&#xA;&#xA;<p><strong>solution 5.</strong><br>&#xA;Keeping everything normalized. Fileter and sort in ElasticSearch.&#xA;Problem: keeping normalized data in ES is too expensive performance-wise</p>&#xA;"
30267737,Microservice Database shared with other services,2015-05-15 19:56:41,<mysql><web-services><deployment><microservices>,1,1114,3,1.0,4,"<p>Something I have searched for but cannot find a straight answer to is this:</p>&#xA;&#xA;<p>For a given service, if there are two instances of that service deployed to two machines, do they share the same persistent store or do they have separate stores with some syncing mechanism (master/slave, clustering)?</p>&#xA;&#xA;<p>E.g. I have a OrderService backed by MySQL. We're getting many orders in so I need to scale this service up, so we deploy a second OrderService. Where does its data come from?</p>&#xA;&#xA;<p>It may sound silly but, to me, every discussion makes it seem like the service and database are a packaged unit that are deployed together. But few discussions mention what happens when you deploy a second service.</p>&#xA;"
36519652,Share data between microservices,2016-04-09 16:32:32,<database-design><architecture><microservices>,2,2792,0,2.0,4,"<p>I work on a microservices architecture and I want to solve a small data sharing problem (I don't know if is the right word).</p>&#xA;&#xA;<p>Example :</p>&#xA;&#xA;<p>I have one user service and is DB that stores email, username, password...</p>&#xA;&#xA;<p>I have another service and his database that work with the user data for generate documents with the user informations.</p>&#xA;&#xA;<p>Which is the best way for the second service for accessing to the user data ? Replicate user data (Just if is required for his job) for her in is database ?</p>&#xA;"
36571963,Python Development in multiple repositories,2016-04-12 11:28:36,<python><git><pip><setuptools><microservices>,2,594,4,0.0,4,"<p>We are trying to find the best way to approach that problem.&#xA;Say I work in a Python environment, with pip &amp; setuptools.&#xA;I work in a normal git flow, or so I hope.&#xA;So:</p>&#xA;&#xA;<ol>&#xA;<li>Move to feature branch in some app, make changes.</li>&#xA;<li>Move to feature branch in a dependent lib - Develop thing. </li>&#xA;<li>Point the app, using ""-e git+ssh"" to the feature branch of the dependent lib.</li>&#xA;<li>Create a Pull Request.</li>&#xA;</ol>&#xA;&#xA;<p>When this is all done, I want to merge stuff to master, but I can't without making yet another final change to have the app (step 3 above) requirements.txt now point to the main branch of the feature.</p>&#xA;&#xA;<p>Is there any good workflow for ""micro services"" or multiple dependent source codes in python that we are missing?</p>&#xA;"
34909182,Microservice solution structure in .NET applications,2016-01-20 19:48:28,<visual-studio><microservices>,1,1384,2,1.0,4,"<p>I'm developing an application using the microservices approach, and I'm having a hard time defining how those microservices will look like on a visual studio project.</p>&#xA;&#xA;<p>My initial approach is to create one visual studio solution for every microservice. Every solution will have the following projects:</p>&#xA;&#xA;<ul>&#xA;<li>Host</li>&#xA;<li>Business API</li>&#xA;<li>Data Access Layer</li>&#xA;<li>Model</li>&#xA;<li>Interfaces (for DI) </li>&#xA;<li>Data Access Mock</li>&#xA;<li>Tests for Business API</li>&#xA;</ul>&#xA;&#xA;<p>So there are 7 projects per microservice. Somehow it feels a lot of projects being reimplemented for every solution.</p>&#xA;&#xA;<p>Is this approach correct? Has anybody built microservices with .net? How does your projects configuration look like?</p>&#xA;"
35361819,how to scale microservice (service fabric) instance when queue length increass,2016-02-12 11:45:43,<azure><scale><microservices><azure-service-fabric>,2,1690,0,0.0,4,"<p><a href=""https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/"" rel=""nofollow"">https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/</a></p>&#xA;&#xA;<p>But how can I scale up my microservice when queue length increases. have any inbuild way in azure service fabric ?</p>&#xA;"
41636566,Inter-communication microservices - How?,2017-01-13 14:14:59,<node.js><web-services><rest><rabbitmq><microservices>,2,2165,1,1.0,4,"<p>I'm working on a personnal project which is to transform a monolithic web application into microservices (each service has its own database).</p>&#xA;&#xA;<p>At this moment the monolithic backend is made with  NodeJS and is able to reply REST request. &#xA;When I began to split the application into multiple services I faced the next problem : How to make the communication between them nicely ?</p>&#xA;&#xA;<p>First I tried to use <strong>REST call</strong> with the next example : &#xA;""Register Service"" inserts interesting things into its database, then forward (HTTP POST) the user information to the ""User Service"" in order to persist it into the ""user"" database.&#xA;From this example we have 2 services thus 2 databases.</p>&#xA;&#xA;<p>I realized at this moment <strong>it wasn't a good choice</strong>. Because my ""Register Service"" depends on ""User service"". They are kind of coupled and this is an anti-pattern of the microservices conception ( from what I read about ).</p>&#xA;&#xA;<p>The second idea was to use a <strong>message broker</strong> like RabbitMQ. ""Register Service"" still insert interesting things into its own database and publish a message in a queue with the user information as data. ""User Service"" consumes this message and persists data into its ""user"" database. By using this conception, both of the services are fully isolated and could be a great idea.</p>&#xA;&#xA;<p>BUT, <strong>how about the response to send to the client</strong> ( who made the request  to ""Register Service""). With the first idea we could send ""200, everything's ok !"" or 400. It is not a problem. With the second idea, we don't know if the consumer (""User Service"")  persisted the user data, so what do I need to reply to the client ?</p>&#xA;&#xA;<p>I have the same problem with the shop side of the web application. The client post the product he wants to buy to ""Order Service"". This one needs to check the virtual money he has into ""User Service"" then forward the product detail to ""Deliver Service"" if the user has enough money. How to do that with fully isolated services ? </p>&#xA;&#xA;<p>I don't want to use the http request time from the client to make async request/reply on the message broker. </p>&#xA;&#xA;<p>I hope some of you will enlighten me.</p>&#xA;"
43041563,User authentication in microservice application hosted on Amazon WS,2017-03-27 08:36:46,<amazon-web-services><authentication><architecture><microservices><aws-cognito>,1,259,0,3.0,4,"<p>I am building web application based on microservice architecture. At this moment I am considering few ways of user authentication flow. I predict following, example user roles:</p>&#xA;&#xA;<ul>&#xA;<li>admin - is able to create content, upload files etc (admin account can be created only by another admin)</li>&#xA;<li>unauthorized user - can view content</li>&#xA;<li>authorized user - can comment content</li>&#xA;</ul>&#xA;&#xA;<p>Here is, how I was thinking about authentication flow so far:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - have access to DB with users credentials and permissions</li>&#xA;<li>api gateway - retrieve requests from user, check if user is logged in (ie verifies OAuth2 access token with auth service) and transfer flow to other services based on user request (attaching JWT token with some basic user info)</li>&#xA;<li>another service - accept only requests from api gateway, and trusts user data from JWT token (does not need to connect with auth service to get information about user).</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>After deploying some stuff on AWS infrastructure my way of thinking have changed a little bit. As far as I understand AWS products (Lambda - serverless applications and API gateway), I should implement authentication flow as follows:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - gets request from user, retrieve data from dynamoDB and provide user cookie with JWT signed by private key</li>&#xA;<li>any other service - retrieves request with JWT token, verifies signature using public key, and perform some action.</li>&#xA;</ul>&#xA;&#xA;<h1>And now the question comes:</h1>&#xA;&#xA;<p>How deos AWS Cognito fits here? Is it something useful for me? As far as I understand, Cognito simplifies flow of authenticating users via 3rd parties (facebook, twitter etc. etc.). Does AWS Cognito serves login page, separated from my application, or it is only background/webservices impelementation?</p>&#xA;&#xA;<p>So far I am thinking about Cognito as a replacement for my <code>authentication service</code> - any of my services, should impelemnt Cognito authentication flow provided by SDK from amazon, and my static website would implement JavaScript SDK for user login/register. Am I right?</p>&#xA;"
42981194,How do you handle validation in composite microservice request?,2017-03-23 16:01:34,<architecture><microservices><software-design><distributed-transactions>,3,1030,0,0.0,4,"<p>Consider an application with two entities:</p>&#xA;&#xA;<ul>&#xA;<li><code>User</code> (contains basic user data, such as name)</li>&#xA;<li><code>Passport</code> (contains authentication credentials, i.e. password)</li>&#xA;</ul>&#xA;&#xA;<p>And two internal microservices:</p>&#xA;&#xA;<ul>&#xA;<li><code>UserService</code> (responsible for creating and managing users and their basic data)</li>&#xA;<li><code>AuthService</code> (responsible for user authentication and password handling)</li>&#xA;</ul>&#xA;&#xA;<p>The <code>User</code> entity belongs to the <code>UserService</code> and <code>Passport</code> entity belongs to the <code>AuthService</code>.</p>&#xA;&#xA;<p>Those two services should be separated, because they solve very different tasks: <em>profile data</em> and <em>authentication</em>.</p>&#xA;&#xA;<p>Also, consider we have a registration form with three fields:</p>&#xA;&#xA;<ul>&#xA;<li>E-Mail</li>&#xA;<li>Name</li>&#xA;<li>Password</li>&#xA;</ul>&#xA;&#xA;<p>This form will trigger HTTP-request to the <code>GatewayService</code>, which intercepts all requests to the application and routes them to internal microservices (or composes/aggregates them).</p>&#xA;&#xA;<p>Now, when gateway service receives the request with all the form data it needs to do the following:</p>&#xA;&#xA;<ol>&#xA;<li>Call <code>UserService</code> to create new user (it will respond with generated <code>userId</code>).</li>&#xA;<li>Call <code>AuthService</code> to create a passport for newly created user. It will need the <code>userId</code> received in step #1 and a <code>password</code> field from the original request.</li>&#xA;</ol>&#xA;&#xA;<p>This looks pretty straightforward, but what will happen if <code>AuthService</code> is unavailable on step #2? We will need to somehow separate those requests!</p>&#xA;&#xA;<p>The classic approach is to use the eventual consistency and to create <code>Passport</code> entity via asynchronous call (we can place this request to the queue and process it in separate service). In order to do this we will send an asynchronous request to the <code>AuthService</code> passing <code>userId</code> and <code>password</code> to it, instead of step #2, so the step #1 will immediately return response to the client.</p>&#xA;&#xA;<p>However, what if <code>password</code> field is not properly formatted (breaks validation rules)? The validation logic is only present in the <code>AuthService</code>, so we can't know if password is correct until the call is made to it. And now, the request is processed asynchronously, so we can't get back to user and tell him to correct the password.</p>&#xA;&#xA;<p><strong>SO, how do you properly handle validation in distributed composite requests to microservice application?</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>The naive solution is to move validation logic to the <code>GatewayService</code> itself, but it's a terrible idea, because it will make it fat and will leak business logic from <code>AuthService</code>.</p></li>&#xA;<li><p>The other idea is to provide an additional method for password validation and to call it prior to steps #1 and #2. It looks like a viable solution, but it will force us to have two methods for each business method in our microservices, one for prior validation and one for actual operation. Also, there is a time space between validation and operation, so the earlier correct value could become incorrect when operation is actually performed.</p></li>&#xA;<li><p>We could split the form in two to avoid composite requests and ask user for password after asking for personal data and creating an account for him. However, this could lead to security problems, where user account could be intercepted by some other party who could guess the next <code>userId</code>. We could, use some additional security token, but it will introduce odd functionality to services and will make the whole setup more complex.</p>&#xA;&#xA;<p>Also, this approach looks like an attempt to escape the problem, you can't always avoid composite requests.</p></li>&#xA;<li><p>We could use full-scale distributed transactions, e.g. <a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""nofollow noreferrer"">2PC</a>, but it will make the system dramatically complex and will mitigate the use of MSA in the first place.</p></li>&#xA;<li><p>And the final idea is to merge those two services together, but it will make no sense in microservice architecture to do so.</p></li>&#xA;</ol>&#xA;"
43034203,node.js api gateway implementation and passport authentication,2017-03-26 20:33:25,<node.js><passport.js><microservices>,1,837,1,0.0,4,"<p>I am working on implementing a microservices-based application using node.js.  While searching for examples on how to implement the api gateway, I came across the following article that seems to provide an example on implementing the api gateway: <a href=""https://memz.co/api-gateway-microservices-docker-node-js/"" rel=""nofollow noreferrer"">https://memz.co/api-gateway-microservices-docker-node-js/</a>.  Though, finding example for implementing the api gateway pattern in node.js seems to be a little hard to come by so far, this article seemed to be a really good example.  </p>&#xA;&#xA;<p>There are a few items that are still unclear and I am still have issues finding doc. on.  </p>&#xA;&#xA;<p>1) Security is a major item for the app. I am developing, I am having trouble seeing where the authentication should take place (i.e. using passport, should I add the authentication items in the api gateway and pass the jwt token along with the request to the corresponding microservice as the user's logged in information is needed for certain activities?  The only issue here seems to be that all of the microservices would need passport in order to decrypt the jwt token to get the user's profile information.  Would the microservice be technically, inaccessible to the outside world except through the api gateway as this seems to be the aim?</p>&#xA;&#xA;<p>2) How does this scenario change if I need to scale to multiple servers with docker images on each one?  How would this affect load balancing, as it seems like something would have to sit at a higher level to deal with load balancing?</p>&#xA;"
42651456,Spring cloud Zuul retry when instance is down and forward to other available instance,2017-03-07 14:56:39,<spring-cloud><microservices><netflix-zuul><spring-cloud-netflix><spring-cloud-feign>,2,2435,0,1.0,4,"<p>using 'Camden.SR5' for spring-cloud-dependencies, with spring boot '1.5.2.RELEASE'.</p>&#xA;&#xA;<p>In my current setup, I have </p>&#xA;&#xA;<ul>&#xA;<li>eureka server </li>&#xA;<li>config server  (running on random ports)</li>&#xA;<li>zuul gateway server  </li>&#xA;<li>and 2 instances of a service (running on random ports)</li>&#xA;</ul>&#xA;&#xA;<p>All these instances are successfully register with Eureka.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BYNWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BYNWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>When all the services are running, The load balancing is done properly through zuul without any issues.</p>&#xA;&#xA;<p>when an instance is killed, Zuul is still trying to fulfil the request using the same service which is down. However if waited till the eureka registry is fetched after shutting down the instance, requests are fulfilled with the other instances which are 'UP'.</p>&#xA;&#xA;<pre><code>    2017-03-07 19:57:41.409 DEBUG 26658 --- [nio-5555-exec-3] c.n.l.reactive.LoadBalancerCommand       : Got error org.apache.http.conn.HttpHostConnectException: Connect to 10.99.4.151:64381 [/10.99.4.151] failed: Connection refused when executed on server 10.99.4.151:64381&#xA;2017-03-07 19:57:41.420 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : Error executing HystrixCommand.run(). Proceeding to fallback logic ...&#xA;&#xA;com.netflix.client.ClientException: null&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:123) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:81) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:96) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>    at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    ... 162 common frames omitted&#xA;&#xA;2017-03-07 19:57:41.425 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : No fallback for HystrixCommand. &#xA;&#xA;java.lang.UnsupportedOperationException: No fallback available.&#xA;    at com.netflix.hystrix.HystrixCommand.getFallback(HystrixCommand.java:292) [hystrix-core-1.5.6.jar:1.5.6]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:117) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.11.jar:8.5.11]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_66]&#xA;&#xA;2017-03-07 19:57:41.428  WARN 26658 --- [nio-5555-exec-3] o.s.c.n.z.filters.post.SendErrorFilter   : Error during filtering&#xA;&#xA;com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:170) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:145) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:88) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Following are the zuul configuration used with @EnableZuulProxy and @EnableEurekaClient</p>&#xA;&#xA;<pre><code>    server:&#xA;  port: 5555&#xA;&#xA;spring:&#xA;  application:&#xA;    name: gateway-server&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        service-id: CONFIGSERVER&#xA;      fail-fast: true&#xA;      retry:&#xA;        multiplier:  1.1&#xA;        initial-interval: 1000&#xA;        max-attempts: 6&#xA;        max-interval: 2000&#xA;&#xA;hystrix:&#xA;  command:&#xA;    default:&#xA;      execution:&#xA;        isolation:&#xA;          thread:&#xA;            timeoutInMilliseconds: 100000&#xA;        timeout:&#xA;          enabled: false&#xA;&#xA;ribbon:&#xA;  ReadTimeout: 5000&#xA;  ConnectTimeout: 3000&#xA;  maxAutoRetries: 1&#xA;  MaxAutoRetriesNextServer: 2&#xA;  OkToRetryOnAllOperations: true&#xA;&#xA;&#xA;logging:&#xA;  level:&#xA;    ROOT: DEBUG&#xA;&#xA;zuul:&#xA;  routes:&#xA;    security-service:&#xA;      retryable: true&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The 2 instances of service with are running with unique instance-ids </p>&#xA;&#xA;<pre><code>@EnableEurekaClient&#xA;@EnableHystrix&#xA;@SpringBootApplication&#xA;public class SecurityServer implements HealthIndicator{&#xA;&#xA;    public static void main(String args[])&#xA;    {&#xA;        SpringApplication.run(SecurityServer.class,args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public Health health() {&#xA;        return Health.up().withDetail(""STATUS"", ""SUCCESS"").build();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>instanceId: ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${random.uuid}}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Can you help me with the zuul &amp; instances configuration, so that request is automatically forwarded to the other available instances when an instance goes down. </p>&#xA;"
42788267,"Can I use Oauth2 Authorization Code flow for a SPA (React app), if I have a server-side proxy?",2017-03-14 14:09:44,<oauth-2.0><single-sign-on><microservices><openid-connect><identityserver4>,1,1407,1,1.0,4,"<p>After watching an obscene amount of tutorials on OAuth2, there is one best practice that everyone repeatedly states - if you have a React app (or Angular, or Ember) - you <strong>must</strong> use <em>Implicit flow</em> with it.</p>&#xA;&#xA;<p>I understand that storing client credentials in publicly visible javascript would not work. However, my scenario is a bit different:</p>&#xA;&#xA;<ol>&#xA;<li>I'm only using Oauth2 for single sign on and token generation for microservices. I chose it instead of simply generating tokens, since well-supported third party libraries are built around the Oauth2 idea.</li>&#xA;<li>My idea is to have a React app, and a ASP.NET MVC app which serves the javascript and acts as a proxy for API requests. The user authenticates for the server-side app (by using Oauth2 authorization code flow).</li>&#xA;<li>Then if I need to retrieve data from an API, I call my ASP.NET MVC app from React (by sending a simple cookie). The MVC app holds the token without ever exposing it to the user's browser.</li>&#xA;<li>Obviously, when called, my MVC app then redirects the request to the necessary API, providing the bearer token.</li>&#xA;</ol>&#xA;&#xA;<p>To better understand why this is what I came up with, here are some requirements I've received that might be unusual:</p>&#xA;&#xA;<ol>&#xA;<li>I really don't want the access token to be shared - even if it's relatively short lived.</li>&#xA;<li>I also want to be able to limit each user account to 3 concurrent user sessions. Easy to do using cookies and server-side sessions.</li>&#xA;</ol>&#xA;&#xA;<p>I can't wrap my head around why this idea would be that bad. Is there any technical problem that might prevent this from working? Or maybe a security risk?</p>&#xA;"
49612911,Understanding microservices using Express.js and docker,2018-04-02 14:13:05,<node.js><express><microservices>,2,332,0,1.0,4,"<p>I am new to node.js and docker as well as the microservices architecture.&#xA;I am trying to understand what microservices architecture actually is and theoretically I do understand what microservices arch is.Please see the following implementation&#xA;This is the <strong>index.js</strong> file:</p>&#xA;&#xA;<pre><code>var express = require(""express""); &#xA;var app = express();&#xA;var service1 = require(""./service1"");&#xA;var service2 = require(""./service2"");&#xA;app.use(""/serviceonerequest"",service1);&#xA;app.use(""/servicetwo"",service2);&#xA;app.listen(3000,function(){&#xA;    console.log(""listening on port 3000"");&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service1</strong>:</p>&#xA;&#xA;<pre><code>    var express = require(""express"");&#xA;    var router = express.Router();&#xA;    router.use(express.json());&#xA;    router.get(""/"",(req,res)=&gt;{&#xA;        //perform some service here&#xA;        res.send(""in the get method of service 1"");&#xA;        res.end();&#xA;        });&#xA;&#xA;        router.post(""/letsPost"",(req,res)=&gt;{&#xA;            res.send(req.body);&#xA;            res.end(""in post method here"");&#xA;        })&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service2:</strong></p>&#xA;&#xA;<pre><code>var express = require(""express"");&#xA;var router = express.Router();&#xA;&#xA;router.use(express.json());&#xA;router.get(""/"",(req,res)=&gt;{&#xA;    //perform some service here&#xA;    res.end(""in the GET method for service 2"");&#xA;});&#xA;&#xA;router.post(""/postservice2"",(req,res)=&gt;{&#xA;    res.send(req.body);&#xA;});&#xA;&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>Does the above qualifies as 'micro service architecture'?Since there are two services and they can be accessed through the 'api-gateway' index.js?</li>&#xA;<li>I have read the basic tutorial of Docker.Is it possible to have the above three ""modules"" in separate containers?</li>&#xA;<li>If the above does not qualify as a microservice what should be done to convert the above sample into microservices?</li>&#xA;</ol>&#xA;"
38820356,Does Kong support API Aggregation,2016-08-08 02:04:58,<microservices><kong>,1,1695,1,2.0,4,"<p>We are just researching a couple of API gateways, in particular <a href=""https://getkong.org"" rel=""noreferrer"">Kong</a>.&#xA;Looking through their documentation it seems they support request/response transformation. </p>&#xA;&#xA;<p>However, if I understand this correctly, this seems limited to headers.</p>&#xA;&#xA;<p>Does Kong support API Aggregation like <a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""noreferrer"">Netflix</a> does it?</p>&#xA;"
38734740,How to config SpringBoot logback setting in application.yml?,2016-08-03 05:01:34,<spring-boot><yaml><logback><microservices>,2,2551,1,0.0,4,"<p>I want to specify my logback.xml file in my project, and in my SpringBoot application I was using the application.yml, I just add</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: logback.xml&#xA;</code></pre>&#xA;&#xA;<p>but it doesn't work for me, the error is :</p>&#xA;&#xA;<pre><code> Logging system failed to initialize using configuration from 'logback.xml'&#xA;java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Exception in thread ""main"" java.lang.IllegalStateException: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:289)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Caused by: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    ... 19 more&#xA;</code></pre>&#xA;&#xA;<p>And if I use</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: ./logback.xml&#xA;</code></pre>&#xA;&#xA;<p>to specify the config location, it appears the same error.&#xA;What should I do ?</p>&#xA;"
38687434,Best Practices for Microservices discovery without Hard Coding?,2016-07-31 19:01:30,<architecture><microservices>,2,397,0,0.0,4,"<p>This is a question that's been annoying me for a while, how does one write a series of microservices that run on on various machines at different locations without the need to hard code each services individual location?</p>&#xA;&#xA;<p>Like say for instance I had service A which does some form of validation of a json message. Service A runs on box 1,3,5 and more instances can be brought up as demand grows.</p>&#xA;&#xA;<p>Now say I have service B which looks to call upon service A, how would I communicate to service B where my service A resides? </p>&#xA;&#xA;<p>Possible Solutions I've considered:</p>&#xA;&#xA;<ul>&#xA;<li><p>Hard coding service B with the location of a 'master' node for Service A which then delegates tasks out to all instances of service A.</p></li>&#xA;<li><p>Utilization of message queues? - Service B writes to a series of message queues, Service A instances read from set message queues and sends back results to service B. </p></li>&#xA;<li><p>SSDP - utilizing some form of simple service discovery protocol to broadcast which services are running where on a set network and keeping track of these services. </p></li>&#xA;</ul>&#xA;&#xA;<p>I'm quite new to this architectural style so I'm hoping I've not missed something very simple?</p>&#xA;"
38554037,How to deal with shared models in micro service architectures,2016-07-24 16:06:26,<node.js><microservices>,3,1289,1,0.0,4,"<p>My goal is to create an architecture in which services should be able to deploy independent of each other and are completely autonomous, but what do you do when you have 2 services that reads from DB the same object type?</p>&#xA;&#xA;<p>In my case I have a socket server (micro service 1) and a http server (micro service 2). Using the http server my users creates an asset called: A, this asset gets stored on a DB and a mongoID is returned. Then, using another protocol and the ID, there are calls to the socket server that needs to check that validity of that ID, thus, needs to read from DB. This two services will have to share the model of A in order to map it to an object, but this means the 2 services will have to share code, and that's not ok.</p>&#xA;&#xA;<p>Do I need another service? or should I make only service1 able to read from DB and then make the second one talks to service 1?</p>&#xA;"
45002471,Are docker containers safe enough to run third-party untrusted containers side-by-side with production system?,2017-07-10 01:02:04,<docker><microservices>,2,147,0,1.0,4,"<p>We plan to allow execution of third-party micro-services code on our infrastructure interacting with our api. &#xA;Is dockerizing safe enough? Are there solutions for tracking resources(network, ram,cpu)container consumes? </p>&#xA;"
44582199,"Angular microservices, loadChildren from url",2017-06-16 06:25:06,<angular><architecture><microservices>,1,383,0,2.0,4,"<p>I recently started thinking of how to effectively implement Angular in a microservices architecture.</p>&#xA;&#xA;<p>Let's say we have a service for login, a service for user management and a service for browsing, adding and editing certain media. Each service has its own backend and frontend served in its own private container. So each part is then isolated with a clearly defined API to interact with for the backend, and its own isolated user interface consuming this API.</p>&#xA;&#xA;<p>Now, let's say I would like to tie up each of these microservices into a single application. I have two ways (as far as I can see) to do this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can configure a server to place each service under a sub-url, and have the application be an array of SPA's, a sort of MPA (Multi Page App). </p></li>&#xA;<li><p>I can create a master app where I set up the routes for each of my micro-apps and load them on demand (custom PreloadingStrategy, I'm looking at you).</p></li>&#xA;<li><p><sup>I also found <a href=""https://stackoverflow.com/questions/39904153/front-end-micro-services-with-angular-2#answer-39937403"" title=""this"">this</a>, a process which I personally don't think highly of, because you'll lose many of the benefits of microservices in a continuous delivery scheme of things. This aims to create a SPA monolith out of microservices.</sup></p></li>&#xA;</ol>&#xA;&#xA;<p>Now, the first alternative seems like a chore, and no fun at all. The second is intriguing to me. I came accross this article: <a href=""https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular"" rel=""nofollow noreferrer"">https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular</a> and immediately started thinking; how can I exploit this to load pre-built angular modules from a url instead of packaging them from the file system?</p>&#xA;&#xA;<p>So my question is; has anybody done this before? Is it possible? Are there security issues in doing this?&#xA;Or are there other alternatives of tying up my microservices into a larger application?</p>&#xA;"
37739538,API Gateway example for node.js,2016-06-10 03:45:31,<node.js><microservices>,1,2858,0,1.0,4,"<p>Looking for a good example of how to implement a node API gateway for a microservice application, I understand the purpose of having a gateway, I am just not sure of how to implement this without just adding another level of RESTful route calls. To me a gateway is supposed to just direct the route to the microservice. </p>&#xA;&#xA;<p><strong>API Gateway port 3000</strong></p>&#xA;&#xA;<pre><code>router.use('/microservicename/*', function (req, res, next) {&#xA;     **code that will direct to microservice**&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 server.js port 3001</strong></p>&#xA;&#xA;<pre><code>var express = require('express');&#xA;var app = express();&#xA;&#xA;var routes = require('./routes/routes');&#xA;&#xA;app.use('/microservicename', routes);&#xA;&#xA;var server = app.listen(3001, function () {&#xA;    console.log('Server running at http://127.0.0.1:3001/');&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 router.js (3001)</strong></p>&#xA;&#xA;<pre><code>router.get('/route1', function (req, res, next) {&#xA;  //get route code&#xA;});&#xA;&#xA;router.post('/route2', function (req, res, next) {&#xA;  //post route code&#xA;});&#xA;&#xA;router.put('/route3', function (req, res, next) {&#xA;  //put route code&#xA;});&#xA;&#xA;router.delete('/route4', function (req, res, next) {&#xA;  //delete route code&#xA;});&#xA;</code></pre>&#xA;"
46315996,Transformation from Legacy to Microservices architecture,2017-09-20 07:38:36,<rest><design><microservices><soa>,2,156,0,2.0,4,"<p>I want to discuss a transformation from fat DB to microservices architecture.</p>&#xA;&#xA;<p><strong>A bit of history:</strong>&#xA;So we have a legacy loan application system, which captures customer detail into a FAT database with some 1000+ tables. The application is doing a lot more than just just capturing loan with 100+ screens/processes built that are beyond loan capturing. Like administration, reporting, config etc.</p>&#xA;&#xA;<p><strong>Current State:</strong>&#xA;The whole Presentation Layer, Logic Layer, DB Layer, ORM layer is part of the one project.</p>&#xA;&#xA;<p><strong>Current Task In Hand:</strong>&#xA;The app is built in Win Forms, and my job is transform it to Modern UI as we need modern feature. </p>&#xA;&#xA;<p><strong>Approach:</strong>&#xA;The approach I am taking is to built some Micro Services on current DB Structure. Using the same DB will allow the current application to run as it is, and we can write a new DB Layer, Logic Layer in some Micro Services. We can then write Modern User Interface (angular/react) that will consume those services. &#xA;The second step then will be then stop the use of capturing operation from legacy app.</p>&#xA;&#xA;<p>Third step is to move the specific DB tables out of the legacy databases to their own databases.</p>&#xA;&#xA;<p>This approach seems best by keeping the current operation running as it is. Also, this approach allows us to run both applications parallel on the production environment. </p>&#xA;&#xA;<p><strong>Confusion:</strong>&#xA;The question I have is on detailed design. I am struggling to understand the context split in Micro Services. The information in the scope of first iteration is:&#xA;- Some Qualification Questions&#xA;- Contact details&#xA;- App requirements&#xA;- Bank Details&#xA;- Income details&#xA;- Expense details&#xA;- Previous loan information</p>&#xA;&#xA;<p>The microservices I am thinking to have is&#xA; - Application Service&#xA;    - Qual questions&#xA;    - App requirements&#xA;    - Previous Loan information&#xA;    - Income/Expense details&#xA; - Demographics Information&#xA;    - Bank Details&#xA;    - Contact Details</p>&#xA;&#xA;<p><strong>Questions:</strong>&#xA;- Does the approach sounds correct from legacy to microservices?&#xA;- The microservice split. Can someone suggest if this is right?</p>&#xA;&#xA;<p>Thanks a lot in advance.&#xA;Regards&#xA;Gaurav Sharma</p>&#xA;"
40786831,How do I version control a kubernetes application?,2016-11-24 12:48:39,<kubernetes><microservices><kubernetes-helm>,2,771,0,1.0,4,"<p>I've checked out helm.sh of course, but at first glance the entire setup seems a little complicated (helm-client &amp; tiller-server). It seems to me like I can get away by just having a helm-client in most cases.</p>&#xA;&#xA;<p><strong>This is what I currently do</strong></p>&#xA;&#xA;<p>Let's say I have a project composed of 3 services viz. <code>postgres</code>, <code>express</code>, <code>nginx</code>.</p>&#xA;&#xA;<p>I create a directory called <code>product-release</code> that is as follows:</p>&#xA;&#xA;<pre><code>product-release/&#xA;    .git/&#xA;    k8s/&#xA;        postgres/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;            Secret.mustache.yaml   # Needs to be rendered by the dev before use&#xA;        express/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;        nginx/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;    updates/&#xA;        0.1__0.2/&#xA;            Job.yaml    # postgres schema migration&#xA;            update.sh   # k8s API server scritps to patch/replace existing k8s objects, and runs the state change job&#xA;</code></pre>&#xA;&#xA;<p>The usual git stuff can apply now. Everytime I make a change, I make changes to the spec files, test them, write the update scripts to help move from the last version to this current version and then commit it and tag it.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<ol>&#xA;<li>This works for me so far, but is this ""the right way""?</li>&#xA;<li>Why does <code>helm</code> have the tiller server? Isn't it simpler to do the templating on the client-side? Of course, if you want to separate the activity of the deployment from the knowledge of the application (like secrets) the templating would have to happen on the server, but otherwise why?</li>&#xA;</ol>&#xA;"
40936597,Spring Eureka App doesn't show dashboard,2016-12-02 16:16:44,<java><spring><microservices><netflix-eureka>,3,1019,1,0.0,4,"<p>There is a Eureka Server application:</p>&#xA;&#xA;<pre><code>@EnableEurekaServer&#xA;@SpringBootApplication&#xA;public class RegistrationModulesServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(RegistrationModulesServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>With applicaton.yml config (be default):</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    hostname: localhost&#xA;  client: &#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;server:&#xA;  port: 1111  &#xA;</code></pre>&#xA;&#xA;<p>On the first run - I saw dashboard with statuses.&#xA;Like in documentation:&#xA;<a href=""https://i.stack.imgur.com/Sa2cD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Sa2cD.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Then - after restart I can see only xml response:&#xA;<a href=""https://i.stack.imgur.com/1lC5l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1lC5l.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Why?</p>&#xA;&#xA;<p>No error in log.</p>&#xA;"
50454109,Communication between microservices - request data,2018-05-21 17:46:22,<rest><rabbitmq><microservices><rpc>,3,363,3,1.0,4,"<p>I am dealing with communication between microservices.</p>&#xA;&#xA;<p>For example (<em>fictive example, just for the illustration</em>):</p>&#xA;&#xA;<ul>&#xA;<li><strong>Microservice A - Store Users (getUser, etc.)</strong></li>&#xA;<li><strong>Microservice B - Store Orders (createOrder, etc.)</strong></li>&#xA;</ul>&#xA;&#xA;<p>Now if I want to add new Order from the Client app, I need to know user address. So the request would be like this:</p>&#xA;&#xA;<p><strong>Client -> Microservice B (createOrder for userId 5) -> Microservice A (getUser with id 5)</strong></p>&#xA;&#xA;<p>The microservice B will create order with details (address) from the User Microservice.</p>&#xA;&#xA;<p><strong>PROBLEM TO SOLVE:</strong> How effectively deal with communication between microservice A and microservice B, as we have to wait until the response come back?</p>&#xA;&#xA;<p><strong>OPTIONS:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Use RestAPI,</li>&#xA;<li>Use AMQP, like RabbitMQ and deal with this issue via RPC. (<a href=""https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html"" rel=""nofollow noreferrer"">https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html</a>)</li>&#xA;</ul>&#xA;&#xA;<p>I don't know <strong>what will be better for the performance</strong>. Is call faster via RabbitMQ, or RestAPI? <strong>What is the best solution for microservice architecture</strong>?</p>&#xA;"
43763418,How to update Update X509 certificates for On-Premise Service Fabric cluster,2017-05-03 14:49:28,<microservices><azure-service-fabric>,1,288,2,0.0,4,"<p>The documentation for updating x509 certificates in Service Fabric is unclear to me with regards to non-Azure (On-Prem) installations: <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server</a></p>&#xA;&#xA;<p>I have followed these steps, but they have not worked.</p>&#xA;&#xA;<ol>&#xA;<li>Updated the cluster setup json template so that the thumbprint of the original certificate is now ""ThumbprintSecondary"".</li>&#xA;<li><p>Added the new certificate thumbprint under ""Thumbprint"". e.g.</p>&#xA;&#xA;<p>""security"": {&#xA;     ""metadata"": ""The Credential type X509 indicates this is cluster is &#xA;      secured using X509 Certificates. The thumbprint format is - d5 ec 42 3b 79 cb e5 07 fd 83 59 3c 56 b9 d5 31 24 25 42 64."",&#xA;        ""ClusterCredentialType"": ""X509"",&#xA;        ""ServerCredentialType"": ""X509"",&#xA;        ""CertificateInformation"": {&#xA;            ""ClusterCertificate"": {&#xA;                ""Thumbprint"": ""New Thumbprint"",&#xA;                ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;                ""X509StoreName"": ""My""&#xA;        },&#xA;        ""ServerCertificate"": {&#xA;        ""Thumbprint"": ""New Thumbprint"",&#xA;        ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;        ""X509StoreName"": ""My""&#xA;    },</p></li>&#xA;<li><p>Install the new certificate pfx and update the ACL for ""NETWORK SERVICE""</p></li>&#xA;<li>Run Start-ServiceFabricClusterConfigurationUpgrade -ClusterConfigPath ""Path to json Configuration File""</li>&#xA;</ol>&#xA;"
43785728,Where is the best place to do data aggregation for UI in microservices architecture,2017-05-04 14:30:33,<rest><api><web><single-page-application><microservices>,1,716,3,0.0,4,"<p>I am building an application using microservice architecture. It has five Rest API and one UI(single page application) microservices. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DbuHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DbuHq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Could anyone advise me which is the best option to do the data aggregation? </p>&#xA;&#xA;<ol>&#xA;<li>Make UI application as a static web application and do all API requests from the front end (from the browser using javascript framework) and all data aggregation do in front end itself and render? </li>&#xA;<li>Make UI application as a dynamic web application and do all API request and data aggregation in web application backend?</li>&#xA;</ol>&#xA;"
34503547,Spring MVC - Calling a rest service from inside another rest service,2015-12-29 02:22:05,<java><spring><rest><spring-mvc><microservices>,2,19997,4,3.0,4,"<p>I'm currently having a really weird issue with calling one REST service from inside another one and I could really use a hand in working out what I'm doing wrong.</p>&#xA;&#xA;<p><strong>So first off, a bit of context:</strong></p>&#xA;&#xA;<p>I have a webapp which calls off to a REST service to create a user account (for the sake of this explanation, the endpoint is localhost:8080/register). Earlier in the user journey I've called a different service to create the user's login credentials <code>localhost:8090/signup</code> but I need to check a few things in the call to /register so inside the call I'm calling out to a different endpoint on 8090 to get this information (<code>localhost:8090/availability</code>). Long story short, the webapp calls localhost:8080/register which in turn calls <code>localhost:8090/availability</code>.</p>&#xA;&#xA;<p>When I call the availability endpoint directly, from either a REST client or the webapp itself, everything works as expected, but for some strange reason, when I call it from inside the call to the register endpoint I get a HTTP415. Anyone have any insight into what's going wrong?</p>&#xA;&#xA;<p>The register controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And the availability controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public Boolean isUsernameAvailable(@RequestBody String username) {&#xA;&#xA;    // a load of business logic that returns a boolean&#xA;    return Boolean.TRUE;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Full disclosure - in practice, what I've shown as the contents of createUser() are actually several calls up the call stack, using the same class as I use to call the services from the webapp (which works perfectly well in that context), and I'm not actually just returning true in isUsernameAvailable (because that would be silly) but this is the simplest version of the code that replicates the issue. </p>&#xA;&#xA;<p>My current assumption is that I'm doing something that I'm going to kick myself over when I see it but I've been staring at this code too long to be able to see it any more.</p>&#xA;&#xA;<p><strong>Edit</strong> Vikdor's comment below solved this problem for me. I changed the createUser method to:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    restTemplate.setMessageConverters(Arrays.asList(new MappingJackson2HttpMessageConverter()));&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;"
47451190,Kafka instead of Rest for communication between microservices,2017-11-23 08:53:42,<rest><apache-kafka><microservices>,1,912,0,1.0,4,"<p>I want to change the communication between (micro)-services from REST to Kafka.&#xA;I'm not sure about the topics and wanted to hear some opinions about that.</p>&#xA;&#xA;<p>Consider the following setup:&#xA;I have an API-Gateway that provides CRUD functions via REST for web applications. So I have 4 endpoints which users can call.&#xA;The API-Gateway will produce the request and consumes the responses from the second service.&#xA;The second service consumes the requests, access the database to execute the CRUD operations on the database and produces the result.</p>&#xA;&#xA;<p>How many topics should I create?&#xA;Do I have to create 8 (2 per endpoint (request/response)) or is there a better way to do it?</p>&#xA;&#xA;<p>Would like to hear some experience or links to talks / documentation on that.</p>&#xA;"
47364834,Microservices sharing code,2017-11-18 10:09:25,<javascript><node.js><microservices>,1,94,7,1.0,4,"<p>There are so many answers and blogposts saying ""never share code between microservices"" and I wonder right now how I am supposed to follow that advice. I've got the following microservices and each of them is communicating via RabbitMQ:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0Agof.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Agof.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The express server and the two different background services have completely different code, while the request workers are just multiple instances. Each request worker is supposed to process a request and return a direct reply to it once it is done with it (RPC).</p>&#xA;&#xA;<p><strong>My question:</strong></p>&#xA;&#xA;<p>I have written a class (<code>RequestScheduler</code>) which offers methods to schedule a request (e. g. <code>getProfile: Promise&lt;IProfile&gt;</code>). Since I am apparently not allowed to share code between microservices what about the code for the communication between the microservices?</p>&#xA;&#xA;<p>I don't see a way how I could avoid sharing that code along my microservices on the left side.</p>&#xA;"
52031350,How ACID works in a restful micro-service architecture,2018-08-27 00:47:44,<java><rest><microservices><acid>,1,59,2,1.0,4,"<p>I'm pretty new at implementing microservice architecture and this question is breaking my mind</p>&#xA;&#xA;<p>How a microservice architecture address transactional mechanism between different end-points calls.</p>&#xA;&#xA;<p>An example is banking services based on a microservice architecture&#xA;basically, the banking operation is for different calls to different services to complete a transaction, if one of them fails, then there is no way to eliminate the partial process, I do not know if there is any mechanism to solve this problem</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>create a payment</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /payments/customer/10/payment/100/ </p>&#xA;  &#xA;  <p><strong>debit money from the account</strong></p>&#xA;  &#xA;  <p><strong>PUT</strong> /customers/10/accounts/20</p>&#xA;  &#xA;  <p><strong>Send a customer notification</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /alerts/customers/10</p>&#xA;</blockquote>&#xA;"
43246560,Microservices Architecture: Chatty services or data duplication,2017-04-06 05:39:28,<architecture><domain-driven-design><microservices>,3,395,0,1.0,4,"<p>TL;DR Should a service opt for saving data in its local database that it needs occasionally, or request the data every time from the service that the data originated from?</p>&#xA;&#xA;<p>Let's have some generic example of a web store / ordering app. Service A is a user session management service. It handles business logic of what a user is doing, what he can do, etc. The user can create his own shirt for purchase. Service B is a data aggregator that contains a lot of the inventory and what's available.</p>&#xA;&#xA;<p>The user starts creating a shirt, so service A request from service B, what styles/colors are available. Service B sends down a list of possible choices which service A then displays for the user. The user then selects one, customizes it and moves on to a new shirt. Again service A has to request from service B, what styles/colors are available. </p>&#xA;&#xA;<p>Now let's assume within a life cycle of a user session, these styles/colors won't change and we know this is going to be the same data being retrieved over and over again. Not by just this user, but all users. So in this case, since the styles/colors are really part of Service B's domain, they should stay there and live there, or would it be advised to prevent all these needless calls and upon the first request (temporarily) save in Service A the data for the lifecycle of the session to prevent chatty services.</p>&#xA;&#xA;<p>This is an over-simplified example but the problem remains real-world. Which is more suggested way of architecting this design? &#xA;This usually applies for example when some fairly-static data is passing through some service, and this service will need this data again a few times within the lifecycle of these transactions. So I'm unsure whether the service should just save it temporarily for the life-cycle knowing the data won't change or not caring if it changes within the lifecycle or opt for more chatty services and keep requesting every time.</p>&#xA;"
37289634,How to Set Request Headers Using a Feign Client?,2016-05-18 03:14:49,<spring-mvc><spring-cloud><microservices><netflix-feign><spring-cloud-netflix>,1,6976,0,3.0,4,"<p>We are developing a suite of Microservices using Spring Cloud framework and one of the the things that we need to do is to set request headers. I know I can pass a parameter <code>@RequestHeader</code> to a Feign method but the value needs to come from another bean. I don't know if SPEL can be used for a Feign param value.&#xA;I was thinking that this is a common enough use case for most clients so there'd be some examples, but so far I've not found any. Of course I can dig through the Spring course code and try to override the default Feign configuration but it kinda defeats the purpose of a declarative client if I've to write a lot of code to achieve this.&#xA;Any thoughts?</p>&#xA;"
37074642,Settings in application.yml for spring.cloud.config aren't used when app is executing,2016-05-06 14:13:00,<java><spring><spring-boot><spring-cloud><microservices>,1,4981,0,0.0,4,"<p>I have a problem with spring cloud: my settings in application.yml for spring.cloud.config aren't used when app is executing. let me put more detail here.&#xA;I'd like to my services could get settings from a remote ConfigServer. I've created the ConfigServer as a spring boot app with annotation @EnableConfigServer. &#xA;After that i've created client app with next config file:</p>&#xA;&#xA;<pre><code>    application:&#xA;      name: mw&#xA;    cloud:&#xA;      config:&#xA;        enabled: true&#xA;        uri: http://172.17.42.1:8888&#xA;        fail-fast: true&#xA;</code></pre>&#xA;&#xA;<p>main class:</p>&#xA;&#xA;<pre><code>    @EnableEurekaClient&#xA;    @SpringBootApplication&#xA;    public class MwApplication&#xA;</code></pre>&#xA;&#xA;<p>and extra configuration into app:</p>&#xA;&#xA;<pre><code>    @Configuration&#xA;    @EnableJpaRepositories(basePackages = {""com.sample.repository""})&#xA;    @EnableTransactionManagement&#xA;    @EnableScheduling&#xA;    public class AppConfiguration&#xA;</code></pre>&#xA;&#xA;<p>also i have next dependencies:</p>&#xA;&#xA;<pre><code>    spring-cloud-starter-eureka&#xA;    spring-cloud-config-client&#xA;    spring-boot-configuration-processor&#xA;    spring-boot-starter-data-jpa&#xA;</code></pre>&#xA;&#xA;<p>When i execute my client app, i've got this message: ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""<a href=""http://localhost:8888/mw/default"" rel=""nofollow"">http://localhost:8888/mw/default</a>""</p>&#xA;&#xA;<p>The app try to get data from default uri(localhost) instead of to use uri from my setting. I've looked at app in debug mode and saw org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration was creating ConfigClientProperties with default property and my settings from application.yml weren't used. </p>&#xA;&#xA;<p>What am i doing wrong?&#xA;thanks.</p>&#xA;"
43350853,Authentication with Kong,2017-04-11 15:56:31,<django><authentication><microservices><restful-authentication><kong>,1,741,0,4.0,4,"<p>I'm looking at <a href=""https://getkong.org/"" rel=""nofollow noreferrer"">Kong</a> to replace my current hand-rolled NodeJS API gateway. Currently I have a user service that handles authentication (written in Django) by providing a JWT back upon login, which the client then passes in through a header. My current API gateway then intercepts any calls, does a validation call back to the user service, and replaces the JWT Header with <code>X-User-Id</code> and <code>X-User-Email</code>. </p>&#xA;&#xA;<p>As far as I can tell, Kong can do roughly the same thing. I'm trying to figure out the flow of how this should work <em>in a perfect world</em>. I still have the opportunity to replace much of the infrastructure, so rewriting some services is not completely out of the question. </p>&#xA;&#xA;<p>So, in my mind, what would happen is the following:</p>&#xA;&#xA;<ol>&#xA;<li>User registers on my site. I then create a new consumer with their username/id on Kong</li>&#xA;<li>User logs in. This is where I get stuck. Do I log in (or in this case, simply authenticate the user as being said user), ask Kong for the JWT for this consumer, and return that? What if I wanted some more data in the payload of the JWT? What happens on Kong's side when the JWT expires?</li>&#xA;<li>When the user requests a service, Kong will the sniff out the JWT from the headers, replace it with <code>X-Consumer-*</code> - is that correct? </li>&#xA;</ol>&#xA;&#xA;<p>Please do correct me if my thinking is wrong, or if there is a better way to achieve this. I'm fairly new to the whole microservices thing. </p>&#xA;"
48515460,Is it recommended to use Database as a container in Production environment?,2018-01-30 06:46:30,<database><docker><containers><microservices><production-environment>,3,1693,0,0.0,4,"<p>Assuming we are using a micro service architecture for a product and we decide to use 'Database per service' model, and deploy in cloud servers by provider like AWS. &#xA;It is convenient to have databases running as a container for development and test environments. </p>&#xA;&#xA;<p>But can same be implemented for Production environment! If so, how safe it would be?&#xA;Or is it proper to go with cloud solution as AWS RDS-DB instead!!</p>&#xA;"
46131196,com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server,2017-09-09 13:26:18,<java><spring-boot><microservices>,4,9807,0,2.0,4,"<p>I am very new to the microservices and trying to run the code from link: <a href=""https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa"" rel=""nofollow noreferrer"">https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa</a> . When I simply run the code I see the following error comes. </p>&#xA;&#xA;<p>What is the issue ?</p>&#xA;&#xA;<pre><code>com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server&#xA;    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1030) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:944) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1468) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1435) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;&#xA;2017-09-09 18:53:11.909 ERROR 16268 --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error&#xA;</code></pre>&#xA;&#xA;<p>I have not installed anything special on to the system. Please let me know what do I need to install? </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/8oWl2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8oWl2.png"" alt=""enter image description here""></a></p>&#xA;"
41067341,"what is the difference between distributed computing, microservice and parallel computing",2016-12-09 19:11:53,<terminology><distributed-computing><microservices>,1,2395,0,1.0,4,"<p>My basic understanding for:</p>&#xA;&#xA;<p>Distributed computing is a model of connected nodes -from hardware perspective they share only network connection- and communicate through messages. each node code be responsible for one part of the business logic as in ERP system there is a node for hr, node for accounting. communication could be HTML, SOA, RCP</p>&#xA;&#xA;<p>Microservice is a service that is responsible for one part of the business logic and communicate with each other usually by http. microservices could share the hardware resources and are accessed by thier api.</p>&#xA;&#xA;<p>Parallel systems are systems which optimize the use of resources. for example multithreaded app running on several thread where sharing memory resources.</p>&#xA;&#xA;<p>I am a little bit confused since microservices are distributed systems, but when running multiple microservices on single hardware resources they are also parallel systems. Am i getting it right here:</p>&#xA;"
41018981,Microservices and database,2016-12-07 13:38:59,<database><docker><cloud><microservices><docker-swarm>,1,656,0,1.0,4,"<p>What is the best practice to deploy database in microservices architecture, more precisely in distributed environment, such as docker swarm? Microservices principles states each service should be stateless to enable scaling. As database obviously has a state, should it live at fixed position outside of cluster, deployed and configured before the cluster is initialized?</p>&#xA;&#xA;<p>I'm confused, because all docker compose examples includes database container in the service definition. But things aren't that simple. Often the database needs a lot of configuration before it's ready to use. Also, docker sucks at coordinating the service starting order.</p>&#xA;&#xA;<p>If it's really a good practice to deploy the database alongside with services to docker swarm, how to ensure consistency and persistence of cricial data?</p>&#xA;"
45847796,What is a sidecar in the context of microservices?,2017-08-23 19:19:33,<kubernetes><microservices><istio>,2,1026,0,1.0,4,<p>I'm currently looking through an Istio and Kubernetes talk and mention the management of services along with the use of sidecars. I'm not sure what that is.</p>&#xA;
40457443,azure service fabric reliable dictionary linq query very slow,2016-11-07 03:36:20,<c#><performance><linq-to-entities><microservices><azure-service-fabric>,1,1465,7,1.0,4,"<p>I have a reliable dictionary in service fabric stateful service. I have a simple linq expression.<br>&#xA;I am using Ix-Async package for building an asyncenumerable.  </p>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>using (ITransaction tx = this.StateManager.CreateTransaction())  &#xA;        {  &#xA;&#xA;          var result = (await customers.CreateLinqAsyncEnumerable(tx))&#xA;                .Where(x =&gt; x.Value.NameFirst != null &amp;&amp; x.Value.NameFirst.EndsWith(n, StringComparison.InvariantCultureIgnoreCase))&#xA;                    .Select(y =&gt; y.Value);&#xA;&#xA;           return await result.ToList();&#xA;&#xA;&#xA;        }  &#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The data is organized into 2 partitions with around 75,000 records in each partition. I am using Int64 range as the partition key. In the above code, the ""Result.ToList()"" takes around 1 minute to execute for each partition. Another weired thing is, the actual result is empty!. The same sql run in sql server returns rows with customer first names ending with ""c"". But, this is besides the point. My biggest concern is performance of ""ReliableDictionary"" linq query.<br>&#xA;Regards</p>&#xA;"
29787063,"Is kafka a good fit for a small scale microservices environment, or should I look for lightweight alternatives",2015-04-22 03:16:02,<apache-kafka><microservices>,2,1786,0,4.0,4,"<p>I'm working on a series of applications that will be deployed as microservices. Each one will have a separate database and I'm looking to coordinate data through single unified event store/log like Apache Kafka. I've started experimenting with Kafka, and most users seem to be using kafka at fairly large scale with clustering and fairly complex fault tolerance setups. We don't anticipate having particularly large volume initially, so I'm wondering if Kafka is the right choice? Is this a good fit for kafka or should I be looking at lighterweight alternatives given our current scale.</p>&#xA;"
41837637,Microservices vs multi-layered architecture,2017-01-24 19:45:25,<asp.net-web-api><architecture><microservices><multi-layer>,1,2806,0,1.0,4,"<p>My project has one backend service (Web API) and one frontend SPA application. Backend service has presentation, application services, domain and infrastructure layers located in different .net assemblies. Domain layer has business domain objects, infrastructure – communication with external data and other stuff, application services – set of services used by presentation layer, presentation – Web API controllers. I think it’s very common layered architecture.</p>&#xA;&#xA;<p>Our new architect announced we are going to move backend to microservices architecture braking down our layers and dividing domain, application service and infrastructure layers to a few services and convert presentation layer to backend for frontend layer (as <a href=""http://samnewman.io/patterns/architectural/bff/"" rel=""nofollow noreferrer"">here</a> described). In feature, we are going to have mobile application. Sql Server database is going to leave as is for now.</p>&#xA;&#xA;<p>I don’t have experience with microservice architecture, so my questions are: &#xA;Is multi-layered architecture out of fashion already? What benefits and problems can bring such architecture design for my application?</p>&#xA;"
41824300,.NET Core API Gateway,2017-01-24 09:18:44,<c#><api><.net-core><microservices><gateway>,2,6347,9,3.0,4,"<p>I've got some work to do for school around Microservices. </p>&#xA;&#xA;<p>I've got the architectural concept, but need an implementation to show off. I'll be using angular2 as a client, would like to use a .NET core API gateway to dispatch my requests to different services. </p>&#xA;&#xA;<p>What's the best approach for this? I red something about using Rx.Net, but no definitive example or implementation that I can follow.</p>&#xA;&#xA;<p>So what should I do to implement an API gateway in .NET Core?</p>&#xA;"
42498492,Avoid bottlenecks in microservices,2017-02-28 00:51:28,<microservices>,1,295,0,2.0,4,"<p>I'm going to apply Microservices for my Datawarehouse application. There are 4 main Microservices in application:</p>&#xA;&#xA;<p>1) Data Service: Import/Export external data sources to DWH and Query data from DWH.</p>&#xA;&#xA;<p>2) Analytics Service: for chart visualization on UI</p>&#xA;&#xA;<p>3) Machine Learning: for recommendation system</p>&#xA;&#xA;<p>4) Reports: for report generating</p>&#xA;&#xA;<p>The diagram as below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hW6lc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hW6lc.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each service has its own DB and they communicate directly with each other via TCP and Thift serialization. The problem here is Data Service suffer a high load from other services and can become a SPOF of application. Data in DWH is big too (maybe up to hundred miliions of records). How to avoid the bottlenecks for Data Service in this case? Or How do I define a properly bounded context to avoid the bottlenecks?</p>&#xA;"
39615381,Advantages of Service Fabric Microservices vs Collection of Azure Cloud services/web apps,2016-09-21 11:31:17,<azure><microservices><azure-service-fabric><azure-cloud-services><azure-appfabric>,2,4502,0,2.0,4,"<p>I have a application that can be broken down into multiple communicating services. My current implementation is monolithic and I want to reorganize the same so that individual components can be deployed,iterated upon, scaled independently. I see two ways to do this with Azure:</p>&#xA;&#xA;<ol>&#xA;<li>Service Fabric service composed of set of communicating micro-services(stateless, web-api etc.)</li>&#xA;<li>A collection of individual Azure Web Apps/ Cloud Services that call each other at the http end points.</li>&#xA;</ol>&#xA;&#xA;<p>Are there any obvious advantages of 1 over 2? Any rule of thumb to chose one over the other would also be very helpful.</p>&#xA;"
39467200,How to self register a service with Consul,2016-09-13 09:58:28,<c#><asp.net-core><microservices><consul>,1,2286,0,6.0,4,"<p>I'm trying to <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow noreferrer"">self</a> register my ASP.NET Core application to Consul registry on startup and deregister it on shutdown.</p>&#xA;&#xA;<p>From <a href=""https://www.consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow noreferrer"">here</a> I can gather that calling the http api [<code>put /v1/agent/service/register</code>] might be the way to go (or maybe not!).</p>&#xA;&#xA;<p>From my app, I thought I'll target the <code>Startup</code> class, starting with adding the my <code>.json</code> file</p>&#xA;&#xA;<pre><code>public Startup(IHostingEnvironment env)&#xA;{&#xA;   var builder = new Configuration().AddJsonFile(""consulconfig.json"");&#xA;   Configuration = builder.Build();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But now, I'm stuck as <code>ConfigureServices</code> method tells me thats where I add services to the container, and <code>Configure</code> method is where I configure the Http request pipeline.</p>&#xA;&#xA;<p>Anybody to point me in the right directions, online readings, examples, etc.                                        </p>&#xA;"
47311911,Event sourcing / CQRS read model - projections,2017-11-15 15:57:11,<domain-driven-design><microservices><cqrs><event-sourcing>,2,407,0,0.0,4,"<p>I have a microservice-based application running on AWS Lambda. Two of the microservices, the most crucial ones, use event-sourcing/cqrs. </p>&#xA;&#xA;<p><strong>Background: (this is also for me to organize my thoughts)</strong></p>&#xA;&#xA;<p>I'm using <a href=""https://github.com/bakerface/easy-source"" rel=""nofollow noreferrer"">this library</a>  and storing events in DynamoDB and projections in AWS S3.</p>&#xA;&#xA;<p>The write part works like a charm: Each command invocation loads the current state of the aggregate from DynamoDB (by running events through a handler and/or loading an cached aggregate), it decides to accept or reject the command based on some business logic, then writes to DynamoDB with <code>KeyConditionExpression: 'aggregateId = :a AND version &gt;= :v'</code> where the version is a count of events processed for that aggregate. If there's a conflict, the write fails. Seems like a good system to me!</p>&#xA;&#xA;<p>Each event is then broadcast to SNS (topic name is the service name) so other services can react to the event, if they want.</p>&#xA;&#xA;<p>The part that I really struggle with is the read. Projections are stored in S3 and tagged with the last commitId processed for each event source. When a read query comes in, it loads the entire projected state from S3 <em>(for all aggregates)</em>, queries the event sources for all newer events, computes the latest state (again, for all aggregates - and writing an updated object to S3 if it's newer), and returns relevant parts of the state based on the query params.</p>&#xA;&#xA;<p><strong>My problem: (or one of them)</strong></p>&#xA;&#xA;<p>I think I'm doing projections wrong. </p>&#xA;&#xA;<p>Most of my projections only group ids by important attribute, so the files stay relatively small. But I also need a way to retrieve an individual aggregate. Using projections for that seems crazy, because I need to load the entire state each time (i.e. every projected aggregate) apply new events to that, then retrieve the record I want (it may not have even changed).</p>&#xA;&#xA;<p>This is what I'm doing now, it's performing fine (&lt;100k records) but I can't imagine it will continue much longer. </p>&#xA;&#xA;<p>The other problem is queries. I need to build a projection mapping value to matching aggregateIds for every attribute I need to query on!! There's got to be a better way!</p>&#xA;&#xA;<p>No matter what way I think about this problem, projections always need the entire current state + any new events before it can return even a single record that hasn't changed.</p>&#xA;"
50264214,How to edit the source code in module after installed it using zef?,2018-05-10 01:28:25,<web><microservices><perl6><cro>,2,109,0,0.0,4,"<p>For example, I've installed the <a href=""http://cro.services"" rel=""nofollow noreferrer"">Cro</a> module, when I run my simple code:</p>&#xA;&#xA;<pre><code> my %headers = {Authorization =&gt; OAuth realm="""", oauth_consumer_key=""xxxxxxxxxxxxxxxx"", oauth_nonce=""29515362"", oauth_signature=""KojMlteEAHlYjMcLc6LFiOwRnJ8%3D"", oauth_signature_method=""HMAC-SHA1"", oauth_timestamp=""1525913154"", oauth_token=""xxxx-xxxxxxxxxxxxxxxxxx"", oauth_version=""1.0"", User-Agent =&gt; Cro};&#xA;&#xA; my $resp = await Cro::HTTP::Client.get: 'http://api.fanfou.com/statuses/home_timeline.json',&#xA;     headers =&gt; [&#xA;            user-agent   =&gt; 'Cro',&#xA;            content-type =&gt; 'application/json;charset=UTF-8',&#xA;            |%headers&#xA;     ];&#xA;&#xA; say $resp.header('content-type'); # Output: application/json; charset=utf-8;&#xA; my Str $text = await $resp.body-text(); &#xA;</code></pre>&#xA;&#xA;<p>And it says 'Could not parse media type <code>application/json; charset=utf-8;</code></p>&#xA;&#xA;<pre><code>Died with the exception:&#xA;    Could not parse media type 'application/json; charset=utf-8;'&#xA;      in method parse at /Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69 (Cro::MediaType) line 74&#xA;      in method content-type at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 74&#xA;      in method body-text-encoding at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 83&#xA;      in block  at /Users/ohmycloud/.perl6/sources/F870148C579AB45DEB39F02722B617776C3D6D5F (Cro::MessageWithBody) line 49&#xA;</code></pre>&#xA;&#xA;<p>It seems that <code>application/json; charset=utf8;</code> is not a valid <code>content-type</code>, so I add a test:</p>&#xA;&#xA;<pre><code>use Cro::MediaType;&#xA;use Test;&#xA;&#xA;sub parses($media-type, $desc, &amp;checks) {&#xA;    my $parsed;&#xA;    lives-ok { $parsed = Cro::MediaType.parse($media-type) }, $desc;&#xA;    checks($parsed) if $parsed;&#xA;}&#xA;&#xA;parses 'application/json; charset=utf-8;', 'application/json media type with charset', {&#xA;    is .type, 'application', 'Correct type';&#xA;    is .subtype, 'json', 'Correct subtype';&#xA;    is .subtype-name, 'json', 'Correct subtype name';&#xA;    is .tree, '', 'No tree';&#xA;    is .suffix, '', 'No suffix';&#xA;    is .Str, 'application/json; charset=utf-8;', 'Stringifies correctly';&#xA;};&#xA;&#xA;done-testing;&#xA;</code></pre>&#xA;&#xA;<p>And the output is:</p>&#xA;&#xA;<pre><code>not ok 1 - application/json media type with charset&#xA;# Failed test 'application/json media type with charset'&#xA;# at cro_media.pl6 line 6&#xA;# Could not parse media type 'application/json; charset=utf-8;'&#xA;1..1&#xA;# Looks like you failed 1 test of 1&#xA;</code></pre>&#xA;&#xA;<p>the source code seems locate in the <code>/Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69</code> file, and I add <code>';'?</code> after the <code>TOP</code> token:</p>&#xA;&#xA;<pre><code>token TOP { &lt;media-type&gt; ';'? }&#xA;</code></pre>&#xA;&#xA;<p>save, and run my code again, but the error is the same. So how to make the change work? In Perl 5, I can just edit my <code>.pm</code> module, but in Perl 6, I dont't know what to do. </p>&#xA;"
43609390,User as a microservice,2017-04-25 11:26:44,<architecture><microservices>,1,506,1,1.0,4,"<p>I'm working on PAAS solution as a product. we have divided business processes in several microservices. One core part of the processes is closely connected to nearly all microservices.</p>&#xA;&#xA;<p>Is this a good practice to create a separate service to manage data such as user management? After the implementation, only this service will have access to users and other related DB tables. All other services will have to call this new user microservice for user related tasks.</p>&#xA;&#xA;<p>This approach will enforced us to refactor DB schema by adding denormalization. We would not get underlying tables that is served among multiple microservices. If serveral services needs data, it would be shared via a microservice.</p>&#xA;"
47554214,Design choice for a microservice event-driven architecture,2017-11-29 13:39:28,<domain-driven-design><microservices><cqrs>,3,248,0,1.0,4,"<p>Let's suppose we have the following:</p>&#xA;&#xA;<p>DDD aggregates A and B, A can reference B.</p>&#xA;&#xA;<p>A microservice managing A that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create A</li>&#xA;<li>delete A</li>&#xA;<li>link A to B</li>&#xA;<li>unlink A from B</li>&#xA;</ul>&#xA;&#xA;<p>A microservice managing B that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create B</li>&#xA;<li>delete B</li>&#xA;</ul>&#xA;&#xA;<p>A successful creation, deletion, link or unlink always results in the emission of a corresponding event by the microservice that performed the action.</p>&#xA;&#xA;<p>What is the best way to design an event-driven architecture for these two microservices so that:</p>&#xA;&#xA;<ol>&#xA;<li>A and B will always eventually be consistent with each other. By consistency, I mean A should not reference B if B doesn't exist.</li>&#xA;<li>The events from both microservices can easily be projected in a separate read model on which queries spanning both A and B can be made</li>&#xA;</ol>&#xA;&#xA;<p>Specifically, the following examples could lead to transient inconsistent states, but consistency must in all cases eventually be restored:</p>&#xA;&#xA;<p><strong>Example 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B doesn't, A is not linked to B</li>&#xA;<li>Command: link A to B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 2</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is linked to B</li>&#xA;<li>Command: delete B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 3</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is not linked to B</li>&#xA;<li>Two simultaneous commands: link A to B and delete B</li>&#xA;</ul>&#xA;&#xA;<p>I have two solutions in mind.</p>&#xA;&#xA;<p><strong>Solution 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has previously received a ""B created"" event and no ""B deleted"" event.</li>&#xA;<li>Microservice B only allows deleting B if it has not previously received a ""A linked to B"" event, or if that event was followed by a ""A unlinked from B"" event.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B (for the race condition in which B is deleted before it has received the A linked to B event).</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A always allows linking A to B.</li>&#xA;<li>Microservice B listens for ""A linked to B"" events and, upon receiving such an event, verifies that B exists. If it doesn't, it emits a ""link to B refused"" event.</li>&#xA;<li>Microservice A listens for ""B deleted"" and ""link to B refused"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT: Solution 3, proposed by Guillaume:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has not previously received a  ""B deleted"" event.</li>&#xA;<li>Microservice B always allows deleting B.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p>The advantage I see for solution 2 is that the microservices don't need to keep track of of past events emitted by the other service. In solution 1, basically each microservice has to maintain a read model of the other one.</p>&#xA;&#xA;<p>A potential disadvantage for solution 2 could maybe be the added complexity of projecting these events in the read model, especially if more microservices and aggregates following the same pattern are added to the system.</p>&#xA;&#xA;<p>Are there other (dis)advantages to one or the other solution, or even an anti-pattern I'm not aware of that should be avoided at all costs?&#xA;Is there a better solution than the two I propose?</p>&#xA;&#xA;<p>Any advice would be appreciated.</p>&#xA;"
47680711,Which HTTP errors should never trigger an automatic retry?,2017-12-06 18:02:51,<http><microservices><hystrix><spring-retry>,1,461,3,2.0,4,"<p>I'm trying to make a few microservices more resilient and retrying certain types of HTTP requests would help with that.</p>&#xA;&#xA;<p>Retrying timeouts will give clients a terribly slow experience, so I don't intend to retry in this case. Retrying 400s doesn't help because a bad request will remain a bad request a few milliseconds later. </p>&#xA;&#xA;<p>I imagine there are other reasons to not retry a few other types of errors, but which errors and why?</p>&#xA;"
45538292,"In a publish/subscribe model in microservices, how to receive/consume a message only once per service type",2017-08-07 01:38:32,<rabbitmq><apache-kafka><messaging><publish-subscribe><microservices>,4,360,0,1.0,4,"<p>We are designing for a microservices architecture model where service A publishes a message and services B, and C would like to receive/consume the message. However, for high availability multiple instances of services B and C are running at the same time. Now the question is how do we design such that only one service instance of B and one service instance of C receive the message and not all the other service instances. </p>&#xA;&#xA;<p>As far as I know about RabbitMQ, it is not easy to achieve this behavior. I wonder if Kafka or any other messaging framework has a built-in support for this scenario, which I believe should be very common in a microservices architecture.</p>&#xA;"
51416552,How to call one microservice from another microservice using docker images,2018-07-19 07:16:12,<java><rest><docker><spring-boot><microservices>,2,103,8,2.0,4,"<p>I have two <code>SpringBoot</code> microservices <code>M1</code>(port 2002) and <code>M2</code>(port 2004)</p>&#xA;&#xA;<p><code>M1</code> and <code>M2</code> are communicating successfully if I run them using <code>eclipse</code> (run as Java Project or SpringBoot Project). </p>&#xA;&#xA;<p>However, I want to communicate them using <code>Docker container</code>.</p>&#xA;&#xA;<p>So I build images for both <code>Microservices</code> (<code>M1</code> and <code>M2</code>) using the command:</p>&#xA;&#xA;<pre><code>docker build -f Dockerfile -t image_name .&#xA;</code></pre>&#xA;&#xA;<p>And run the images using:</p>&#xA;&#xA;<pre><code>docker run -p 2004:2004 image_name&#xA;</code></pre>&#xA;&#xA;<p><strong>Note: I am exposing same port from docker as defined above</strong></p>&#xA;&#xA;<p>But the M1 and M2 are not able to communicate.&#xA;I am using <code>RestTemplate</code> </p>&#xA;&#xA;<pre><code>RestTemplate restTemplate = new RestTemplate();&#xA;ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://localhost:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p>I am getting below exception : </p>&#xA;&#xA;<pre><code>I/O error on GET request for \""http://localhost:2002/apis/test\"": Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)&#xA;</code></pre>&#xA;&#xA;<p>However, If I call the other microservice using my <strong>machine's IP</strong>, It's communicating successfully </p>&#xA;&#xA;<pre><code>ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://XX.XX.XX.XXX:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p><strong>Can someone please tell if I am  doing it write(using IP address) or there is another good approach to call one microservice from another using Docker?</strong> </p>&#xA;"
40669943,why hystrix or any other circuit breaker for a microservice?,2016-11-18 05:28:16,<java><spring><spring-boot><microservices><hystrix>,2,799,0,1.0,4,"<p>I am developing microservice with spring boot and spring cloud. I came to know about hystrix and circuit breaker pattern. I know that circuit breakers are for responding with alternate response in case of errors from downstream microservices on which I depend on to get the data. My question is, if I don't have any meaningful alternative response to provide, why would I need a circuit breaker at all?</p>&#xA;"
46605663,Best practices sharing types across multiple Haskell packages/microservices,2017-10-06 12:22:41,<haskell><architecture><microservices>,1,131,3,1.0,4,"<p>I am working in a Haskell project that is composed of multiple microservices. There are certain types that are needed by multiple services at the same time and therefore are defined in separate libraries that are imported by whichever needs them (each type is versioned). But there are things about it that make me uncomfortable and I was wondering which are the best practises regarding that topic. In particular:</p>&#xA;&#xA;<ul>&#xA;<li>I don't know how to handle instances of shared types. In order to avoid orphans the instances must be defined in the type's module for each of the types. But then there are instances that are not needed by all the microservices that import the package and have to be included regardless, potentially adding redundant dependencies to the microservice. An example would be a datatype <strong>T</strong> that is shared by a frontend and a backend. It has an instance of <strong>Store</strong> in order to be stored in a database that is not needed by the frontend, but still makes the frontend depend of the store package.</li>&#xA;<li>In order to avoid the previous issue I could introduce a wrapper every time the type has to ""leave"" a microservice to represent that type going through the wire. In the previous example I would have a <strong>Storable T</strong> which would have an instance for <strong>Store</strong>. This adds quite a lot of overhead to the overall development process though.</li>&#xA;<li>Is it even a good idea to share the types or should each microservice define its own representation of each type, so nothing has to be shared? So for a type <strong>T</strong> a microservice <strong>MA</strong> would have a representation <strong>A.T</strong> and an instance to serialise it in order to send the data to a microservice <strong>B</strong> which would decode that data into a representation <strong>MB.T</strong>.</li>&#xA;</ul>&#xA;&#xA;<p>And finally, regarding the logistical side of the matter,</p>&#xA;&#xA;<ul>&#xA;<li>What's the most convenient way to structure the project? Would a monorepo be a better choice than having separate repos/submodules?</li>&#xA;<li>Maybe related to the previous one, is there any way to find out automatically which microservices should be redeployed when one of the shared libraries is modified because the changes in the library affect a piece of code that is being used by the microservice?</li>&#xA;</ul>&#xA;"
34094882,"Storing submodules for micro services, but still using forks",2015-12-04 18:18:43,<git><docker><git-submodules><docker-compose><microservices>,3,869,0,2.0,5,"<p>I am stumped here.  A lot of this is already in place, its just the wrapping that I cannot figure out.</p>&#xA;&#xA;<p>We have a micro-service architecture, with many separate repositories.  We are using Docker, and Docker Compose for building and running the development environment, which works beautifully.</p>&#xA;&#xA;<p>The question I have, is how to package up the main collection of repositories.  So if I have a folder structure like:</p>&#xA;&#xA;<pre><code>\&#xA;    service1&#xA;        .git&#xA;        Dockerfile&#xA;    service2 &#xA;        .git&#xA;        Dockerfile&#xA;    service3&#xA;        .git&#xA;        Dockerfile&#xA;    docker-compose.yml&#xA;    README.md&#xA;</code></pre>&#xA;&#xA;<p>...Where service1, service2, service3 are each their own git repository.</p>&#xA;&#xA;<p>My first thought was to use git submodules, which <em>would</em> work, however we enforce policies to require developers to fork repositories instead of working off the main repository due to continuous integration constraints and code reviews.  I was not overly excited about using git submodules at all, even before I thought of this caveat, so an alternative solution would be much preferred.</p>&#xA;&#xA;<p>At the moment i can only think to write scripts to store a list of repositories; run a query for each to see if the logged-in developer has a fork of each, creating one if not, then pulling into the master folder; and then booting docker-compose.  This seems like a horrible solution though, enough so that I may just have to write docs to just tell devs how to manually do this process...</p>&#xA;&#xA;<p>Thoughts??</p>&#xA;&#xA;<p>Thanks for your time :)</p>&#xA;"
32093067,Microservices styles and tradeoffs - Akka cluster vs Kubernetes vs,2015-08-19 10:35:06,<akka><microservices><fault-tolerance><akka-cluster><tradeoff>,1,1425,0,1.0,5,"<p>So, here's the thing. I really like the idea of microservices and want to set it up and test it before deciding if I want to use it in production. And then if I do want to use it I want to slowly chip away pieces of my old rails app and move logic to microservices. This I think I can do using HAProxy and set up different routing based on URLs. So this should be covered.</p>&#xA;&#xA;<p>Then my next biggest concern is that I don't want too much overhead to ensure everything is running smoothly on the infrastructure side. I want preferrably low configuration and the ease of development, testing and deployment.</p>&#xA;&#xA;<p>Now, I want to know what are the benefits and downsides of each styles. Akka (cluster) vs something like Kubernetes (maybe even fabric8 on top of it).</p>&#xA;&#xA;<p>What I also worry about is fault tolerance. I don't know how do you do that with Kubernetes. Do you then have to include some message queue to ensure your messages don't get lost? And then also have multiple queue if one of the queues goes down? Or just retry until queue comes up again? Akka actors already have that right? Retrying and mail boxes? What are the strategies for fault tolerance for microservices? Do they differ for each approach?</p>&#xA;&#xA;<p>Someone please enlighten me! ;)</p>&#xA;"
29303048,HATEOAS and Microservices,2015-03-27 14:26:23,<rest><hateoas><microservices><hypermedia>,2,2172,6,0.0,5,"<p>I'm having some serious trouble seeing how HATEOAS and Microservices can co-exist.</p>&#xA;&#xA;<p>Let's take an example:</p>&#xA;&#xA;<p>Let's say we have a shopping cart resource.&#xA;And we need to put snapshots of products into it, e.g. product Id, product price; snapshot of current price when item was added to cart, and possibly some other values.&#xA;The actual use-case is not relevant, but just to get some idea on the problem at hand.</p>&#xA;&#xA;<p>When I have been doing HATEOAS earlier, I would have put a link in the shopping cart resource that links to products or a template url that links to a specific product.</p>&#xA;&#xA;<p>This way, the client can still be ignorant of resource URL's.</p>&#xA;&#xA;<p>But in the microservice world, a service should have no knowledge of other services. AFAIK.</p>&#xA;&#xA;<p>So how could they both work together?</p>&#xA;&#xA;<p>My interpretation of microservices is that they can never link to anything else than themselves, which would pretty much be a <code>Self</code> link.</p>&#xA;&#xA;<p>I've found the same question asked on ther places, e.g.&#xA;<a href=""https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc"" rel=""noreferrer"">https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc</a></p>&#xA;&#xA;<p>Where solutions like ""macro services"" that weave all this together is used.&#xA;Which doesn't seem like a clean way to solve things.</p>&#xA;&#xA;<p>[Edit]</p>&#xA;&#xA;<p>I've found some more nice info on the topic:&#xA;<a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">https://github.com/Netflix/eureka</a>&#xA;<a href=""https://github.com/RestExpress/HyperExpress"" rel=""noreferrer"">https://github.com/RestExpress/HyperExpress</a></p>&#xA;&#xA;<p>This seems nice to have some tool augument the resources with links, but this makes me think, where does the logic to decide what links a resource should have belongs?&#xA;In the service that exposes the resource?&#xA;In the central service registry?</p>&#xA;"
33881958,Spring Oauth2 client credentials flow example,2015-11-23 22:29:42,<java><spring-security><oauth-2.0><spring-security-oauth2><microservices>,1,1125,1,0.0,5,"<p>I am trying to implement service to service security into spring boot services using spring oauth2. I want a service to access a secured resource of another service without any user action involved.</p>&#xA;&#xA;<p>There are a lot of examples for authorization code grant type, but not very much about the client credentials grant type, which seems to be the right one for this use case.</p>&#xA;&#xA;<p>I can set up the auth server and use a curl request to get a token.&#xA;The tests I found used Http Objects to check status codes.</p>&#xA;&#xA;<p>How can I use the client credentials grant type in a java client with RestTemplate and spring oauth2?</p>&#xA;&#xA;<p>I would think it must be as simple as adding a dependency, an annotation and a config file, yet I can't make it run.</p>&#xA;"
32529742,how to roll back a transaction happening between microservices?,2015-09-11 18:15:08,<java><spring><spring-mvc><spring-data><microservices>,4,2904,0,1.0,5,"<p>we have <code>microservice</code> architecture where for most part each <code>microservice</code> is independent. But for some legacy reasons, there is a situation where we have to call another <code>microservice</code> from within another.</p>&#xA;&#xA;<p>eg: the following method is part of <code>Legal Service</code></p>&#xA;&#xA;<pre><code>@Autowired&#xA;public ServiceManager UserServiceManager;&#xA;&#xA;public void updateUserLegalData(){&#xA;&#xA;    //do db update of Legal info for the user&#xA;&#xA;   userServiveManager.setAcceptedLegal(true);&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There are two <code>db transactions</code> going on above. one is updating legalService db and other is updating UserService db. please NOTE userService is a <code>microservice</code>running on a separate VM.</p>&#xA;&#xA;<p>we are seeing situations where legal Service db is updated but call to userService is failing (<code>Internal server error</code>). so this leaves the application in an inconsistent state. How can we fix this in a recommended way?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
39154613,Netflix Ribbon and Hystrix Timeout,2016-08-25 20:57:31,<spring-boot><spring-cloud><microservices><hystrix><netflix-ribbon>,1,3615,2,1.0,5,"<p>We are using Spring cloud in our project. We have several micro services and each has its own .yml file.</p>&#xA;&#xA;<p>Below properies are only in zuul server</p>&#xA;&#xA;<pre><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000&#xA;&#xA;    ribbon: &#xA;     ConnectTimeout: 3000&#xA;     ReadTimeout: 60000&#xA;</code></pre>&#xA;&#xA;<p><strong>Test 1:</strong></p>&#xA;&#xA;<p><strong>Accounts Service:</strong></p>&#xA;&#xA;<p>This service is what I'm calling to test the timeout and I'm calling the request through zuul i.e., using the port 8006.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>The above service internally calls the below one using Spring RestTemplate.&#xA;I started testing by adding a sleep time of 5000ms like below in <strong>Association Service</strong> and made a request to <strong>Accounts Service</strong> (getAccounts call).</p>&#xA;&#xA;<p><strong>Association Service:</strong></p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/internal/userassociationstatus"", produces = ""application/json; charset=utf-8"", consumes = ""application/json"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public UserAssociationStatusVO getUserAssociationStatus(@RequestParam final Map&lt;String, String&gt; allRequestParams) {&#xA;        try {&#xA;            Thread.sleep(5000);&#xA;        } catch (InterruptedException e) {&#xA;            // TODO Auto-generated catch block&#xA;            e.printStackTrace();&#xA;        }&#xA;        return iUserAssociationsService.getUserAssociationStatus(allRequestParams);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Association Service</strong></p>&#xA;&#xA;<pre><code>org.apache.catalina.connector.ClientAbortException: java.io.IOException: An established connection was aborted by the software in your host machine&#xA;at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:393) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.tomcat.util.buf.ByteChunk.flushBuffer(ByteChunk.java:426) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:342) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Accounts Service</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://USERASSOCIATIONS-V1/user/v1/internal/userassociationstatus?cardholderid=123&amp;usercontextid=222&amp;role=ACCOUNT"": com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out; nested exception is java.io.IOException: com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;</code></pre>&#xA;&#xA;<p>If I keep the sleep time as 4500 it gives me response, but if is >=4800 it throws the above exception. I'm thinking this is not related to Ribbon Timeouts but something else. Any specific reason for the above exception after certain point. </p>&#xA;&#xA;<p><strong>Test 2</strong></p>&#xA;&#xA;<p>Then I tried keeping a sleep time of 75000 ms in <strong>Accounts Service</strong> directly and removed sleep time <strong>Association Service</strong>.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        try {&#xA;            Thread.sleep(75000);&#xA;        } catch (InterruptedException ex) {&#xA;            // TODO Auto-generated catch block&#xA;            ex.printStackTrace();&#xA;        }&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>In this case I got   ""exception"": ""com.netflix.zuul.exception.ZuulException"",</p>&#xA;&#xA;<p>And in my APIGateway(Zuul application) log I see the below error.</p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:134) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:76) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:112) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;    at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:197) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: useraccounts-v1RibbonCommand timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;</code></pre>&#xA;&#xA;<p>I think this has nothing to do with Ribbon ConnectTimeout or ReadTimeout. This error is because of the property <strong>""execution.isolation.thread.timeoutInMilliseconds: 60000""</strong>. I have also reduced this property to 10000 ms to test the behavior and got the same exception if the sleep time is more(ex: 12000).</p>&#xA;&#xA;<p><strong>I want to understand Ribbon ConnectTimeout and Read-timeout vs Hystrix timeout and how to test ribbon timeouts in my application. Also if I want different timeouts for different microservices, Do I keep these properties in respective .yml files?.</strong> Any thoughts?</p>&#xA;&#xA;<p>I'm trying to create a document to be used by my team so that it is easy for a developer to know how these timeout options work in Spring cloud.</p>&#xA;&#xA;<p>(It's a lengthy description but to make it clearer I had to write in detail)</p>&#xA;"
41433856,emailing in microservice architecture,2017-01-02 22:08:52,<rest><email><microservices><restful-architecture><email-integration>,1,1709,0,3.0,5,"<p>Sorry about my english - if some thing is not clear please ask me in comments - i will clarify this.</p>&#xA;&#xA;<p>I build system in microservice architecture. I have one service with user information, one service for ""offers"", and one service for ""ideas"". Services ""offers"" and ""ideas"" comunicate (by Restful API) with ""User"" service on login and other operations. And i wonder - how to deal with emails? Each service have it separate frontend and send emails after some actions (eg. when some third person open link with some offer the user who create this offer will get email, or when some user create idea the manager will get email). Moreover, on each service frontend, manager can create ""periodic"" mailing with season statistical data or just some other information. Each service email looks differently and have different content.</p>&#xA;&#xA;<p>I have many choices and don't know which will be better. This are some propositions:</p>&#xA;&#xA;<ol>&#xA;<li>Each service has his own separate emailing system and send all kinds&#xA;of email (after action, and periodic) independent. </li>&#xA;<li>The ""user service"" have ""engine"" to send action and periodic emails and other services give the task. Inside task there is link to service who give task and that link will generate email content (for example witch statistical data in periodic email). This solution is complicated...</li>&#xA;<li>The ""user service"" has only engine to periodic emails (tasks have link to generate email body...) but email after actions are send from each microservice indepenndent</li>&#xA;<li>Create new microservice only for sending email (periodic and ""after action"") with proper API. Ofcourse each service like ""offers"" should send also link (to themself) in mailing task - this link will be call when the periodic email will be send and the response of this link will be generated body of email....</li>&#xA;</ol>&#xA;&#xA;<p>Which one will be better? Or may be there is some better alternative? </p>&#xA;"
27865814,Does my concept follow a Microservice architecture?,2015-01-09 17:18:25,<php><magento><soa><single-page-application><microservices>,2,5151,0,3.0,5,"<p>I read <a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">the article on Microservices</a> on Martin Fowler's page and find it quite interesting. Now I plan structuring an E-Commerce Web Application as proof-of-concept and am wondering if my concept is considered being a Microservice architecture.</p>&#xA;&#xA;<p>The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li>a javascript based single page application, which sends AJAX requests to</li>&#xA;<li>a server with a REST API which feeds JSON data received by calling other services (I think you call this behaviour API Gateway)</li>&#xA;<li>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento (PHP) Shopsystem. In future I plan to then swap the providers with other systems.</p>&#xA;&#xA;<p>So my questions are:</p>&#xA;&#xA;<ul>&#xA;<li><p>MS are considered to be 'independently deployable'. I understand that in the world of JAVA we are talking about one JAR- or WAR-file, but how is a PHP service 'independently deployable'?</p></li>&#xA;<li><p>Does my concept NOT follow the principles of a MS architecture, because the providers are all part of one big (Magento) system?</p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading. I'm happy for any suggestions.</p>&#xA;"
31046924,Building authentication with Microservices Architecture,2015-06-25 09:52:50,<microservices>,3,3023,0,4.0,5,<p>I'm developing an app with microservices and I don't know how to distribute microservices to allow auth.</p>&#xA;&#xA;<p>I've read that each microservice should have its own database to avoid coupling.</p>&#xA;&#xA;<p>The problem is that Authentication (via JWT) and Users Microservices must have access to the same database and table (Users). I suppose this problem has been solved before due to similar applications having to deal with the same issue.</p>&#xA;&#xA;<p>How can I solve this?</p>&#xA;
31097306,Spring Boot + Tomcat - Microservices solution,2015-06-28 07:44:28,<spring-boot><microservices>,2,4706,4,1.0,5,<p>I'm planning to expose few microservices (~20 at this stage) using Spring Boot. I will be creating executable fat jars using the embededed Tomcat. The executable jar will be wrapped in Docker container and deployed to AWS. </p>&#xA;&#xA;<p>In my case 20 jars will have 20 tomcat instances running at the same time. I'm concerned about the overhead of running so many tomcat instances in the production server. Is this a valid concern?</p>&#xA;&#xA;<p>I was wondering if someone has used something similar configuration in production and can share their experience.</p>&#xA;&#xA;<p>Any suggestions will be appreciated.</p>&#xA;&#xA;<p>Thanks&#xA;JP</p>&#xA;
44355294,How to offer multiple versions of an API with different database schemas?,2017-06-04 14:44:09,<database><versioning><microservices>,1,387,2,2.0,5,"<p>In Kevin Goldsmith's 2015 talk about <a href=""https://youtu.be/7LGPeBgNFuU?t=925"" rel=""noreferrer"">microservices at Spotify</a> (from 15:25 - 17:43), he mentions that when they create a new version of an API they just create a new server, and keep the old server running with the old version for as long as there are still clients calling it (in this case, a smart lamp with Spotify embedded on it).</p>&#xA;&#xA;<p>I am confused about how they would be able to maintain and offer older versions for potentially years, when surely there would be database schema changes during that timeframe?</p>&#xA;&#xA;<p>I can see a few possible solutions, but none of them seem very reasonable:</p>&#xA;&#xA;<ol>&#xA;<li>Using the same database across all versions, only ever add new tables, and new nullable fields. Never delete fields, nor rename fields, nor set fields to non-nullable, nor delete tables, nor rename tables.</li>&#xA;<li>Using a different database per version, keep each version's data separate.</li>&#xA;<li>Using a different database per version, keep each version's data separate, but write a way to migrate and pass the requests from one version to another, so that each version receives the request with the valid parameters for that version.</li>&#xA;</ol>&#xA;&#xA;<p>Solution 1 sounds like it would induce way too much code smell, with legacy code everywhere (which Kevin, in my opinion, seems to suggest they certainly do not do).</p>&#xA;&#xA;<p>Solution 2 sounds like a nightmare to pull data out of for other services, or for reporting. What if the information about an entity that you want is in another version's database than the one you request?</p>&#xA;&#xA;<p>Solution 3 sounds like more of a nightmare as you would have to write code to migrate a request for your version, to the versions above and below yours. This would mean that you can't just leave the existing (the one currently in production) version as-is when creating a new version, as you would need to add migrations to move the request both forward and backward so that all versions received the correct parameters for the request.</p>&#xA;&#xA;<p>Hopefully I am just missing something simple here, and there is a magic solution to make this problem easier, but I really cannot see how they could accomplish this?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
36197572,How to improve communication between microservices,2016-03-24 10:07:12,<java><rest><spring-boot><microservices>,3,2704,0,0.0,5,"<p>In our company we use spring boot, microservices, spring cloud and so on... We are happy with this infrastructure, but I still have some concerns:&#xA;we use rest as comunication protocoll and even if a I find it great, I still think that we could find something better. With rest:</p>&#xA;&#xA;<ul>&#xA;<li>you need to use a client and a server (restcontroller)</li>&#xA;<li>you need to know the server <code>URI</code>, the http method (<code>POST, GET, PUT,...</code>)</li>&#xA;<li>you need know where params go (body, querystring)</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>Don't you think It would be much easier if we had something like RMI? I know it's a quite old technology(and it's not language independent), but it made life easier (you just need an interface and its implementation).</p>&#xA;&#xA;<p>Searching around, I found some interesting projects like feign clients or spring cloud stream, but none of them seem to be the silver bullet. </p>&#xA;&#xA;<p>What do you think about this topic? Is that a problem that you feel? If so, how do you approach it? </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
36144330,Scaling microservices using Docker,2016-03-22 00:49:13,<node.js><meteor><amazon-ec2><docker><microservices>,2,389,2,1.0,5,"<p>I've created a Node.js (Meteor) application and I'm looking at strategies to handle scaling in the future. I've designed my application as a set of microservices, and I'm now considering implementing this in production.</p>&#xA;&#xA;<p>What I'd like to do however is have many microservices running on one server instance to maximise resource usage whilst they are using a small number of resources. I know containers are useful for this, but I'm curious if there's a way to create a dynamically scaling set of containers where I can:</p>&#xA;&#xA;<ul>&#xA;<li>Write commands such as ""provision another app container on this server if the containers running this app reach > 80% CPU/other limiting metrics"",</li>&#xA;<li>Provision and prepare other servers if needed for extra containers,</li>&#xA;<li>Load balance connections between these containers (and does this affect server load balancing, e.g., send less connections to servers with fewer containers?)</li>&#xA;</ul>&#xA;&#xA;<p>I've looked into AWS EC2, Docker Compose and nginx, but I'm uncertain if I'm going in the right direction.</p>&#xA;"
47050984,Enabling session in lumen framework,2017-11-01 08:39:14,<laravel><microservices><lumen>,3,2894,12,1.0,5,"<p>I have two (but let's image more) micro-services (API) which need to be aware of authenticated user. Ideally I would simple like to resume their sessions.</p>&#xA;&#xA;<p>All micro-services are using same storage for sessions: redis.</p>&#xA;&#xA;<p>All API calls will have Cookie header, so all services will be able to resume sessions based on that cookie. I have successfully implemented this via PHP $_SESSIONs.</p>&#xA;&#xA;<p>Now the question: how would you go about implementing this with Laravel/Lumen?</p>&#xA;"
38186942,Correlation Token for Service Fabric Actors and Services,2016-07-04 14:20:13,<logging><token><actor><microservices><azure-service-fabric>,1,292,0,1.0,5,"<p>We started playing with Service Fabric as a microservice platform and after having succesfully implemented our firsts ""hello world"" samples about actor pattern, stateless/stateful services, web api (and so on) we are moving to looking solutions for other core aspects like auth/autz and application logging.</p>&#xA;&#xA;<p>I have a doubt about the Logging; in all the SOA we have designed till now we always added a ""correlation token"" to all the services involved (often at architectural level, automatically added as header onto WCF, hidden to the developers) so, now we are trying to do the same with Service Fabric.</p>&#xA;&#xA;<p>Looking for the best solution to let flow a ""Correlation Token"" through all the actor/service calls, since we haven't found out anything ready out-of-the-box, we are wondering if we are looking for something theoretically wrong.</p>&#xA;&#xA;<p>Any suggestion out there?</p>&#xA;"
39913816,Zero Downtime Deployment for Micro Service architecture,2016-10-07 09:22:58,<java><database><docker><spring-boot><microservices>,1,911,4,0.0,5,"<p>At the moment I'm working on an application which will be based on the <strong>Micro Service architecture</strong>. As main technologies we planned to use <strong>Spring Boot and Docker</strong> for each Micro Service development. One of the goals is to provide Zero Downtime Deployment feature for the users. </p>&#xA;&#xA;<p>I spent some time trying to found some solution and know about <code>Blue Green Deployment (BGD)</code> but some aspects is still not clear for me. The main problem is DataBase state and version compatibility. </p>&#xA;&#xA;<blockquote>&#xA;  <p>For example if <code>BGD</code> is used how to migrate all the data changes from&#xA;  Green to Blue contour after successful deployment?</p>&#xA;</blockquote>&#xA;&#xA;<p>I found interesting approach in Spring's <a href=""https://spring.io/blog/2016/05/31/zero-downtime-deployment-with-a-database"" rel=""nofollow"">Zero Downtime Deployment with a Database</a> article, but I think that such approach has too complicated Application Versions and Releases Planing process and backward compatibility requirements.</p>&#xA;&#xA;<p>So my I want to ask following questions:</p>&#xA;&#xA;<ol>&#xA;<li>Any suggestions on the Zero Downtime Deployment process concept, backed by real  experience using  it?</li>&#xA;<li>Is there any Out Of The box solutions (Paid or Free)  that provide Zero Downtime Deployment feature for applications with Relational Data Base?</li>&#xA;</ol>&#xA;&#xA;<p><strong>PS</strong></p>&#xA;&#xA;<p><em>It is interesting how Zero Downtime Deployment works in StackOverflow.com if it is?</em></p>&#xA;"
46742274,About the Mediator in Event-Driven Topology,2017-10-14 08:00:14,<events><microservices><event-driven><orchestration><event-driven-design>,2,278,0,2.0,5,"<p>I was reading this article called <a href=""http://radar.oreilly.com/2015/02/variations-in-event-driven-architecture.html"" rel=""nofollow noreferrer"">Variations in event-driven architecture</a> in which they demonstrate both the mediator and broker topologies.</p>&#xA;&#xA;<p>According to the article the mediator topology looks somewhat like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QTwOw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QTwOw.jpg"" alt=""Mediator Topology""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>The event flow starts with the client sending an event to an <em>event queue</em>, which is used to transport the event to the mediator. The <em>event mediator</em> receives the initial event and orchestrates that event by sending additional asynchronous events to <em>event channels</em> to execute each step of the process. <em>Event processors</em>, which listen on the event channels, receive the event from the even mediator and execute specific business logic to process the event [...] It is important to note that the event mediator doesn't actually perform the business logic necessary to process the initial event, rather, it knows of the steps required to process the event [...] The event channels can be either message queues o message topics.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, I was studying this diagram, trying to understand how the mediator could determine when a given processor has finished processing a given event, such that it could orchestrate the next step of the process.</p>&#xA;&#xA;<p>The article is not clear enough when it says</p>&#xA;&#xA;<blockquote>&#xA;  <p>For each initial event step, the event mediator creates a processing event, sends that processing event and <em>waits</em> for the processing event to be processed by the corresponding event processor. This process continues until all of the steps in the initial event have been processed.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now, the article is clear in that the communication is asynchronous, and event messages will travel through message queues, but the diagram does not show <em>any events coming out of the event processor and back to the mediator</em>.</p>&#xA;&#xA;<p>The article says the mediator waits for the event processor to finish, but it is not clear how this is supposed to happen in architectural terms.</p>&#xA;&#xA;<p>Is it asynchronous, queue-based RPC (e.g. <a href=""https://www.rabbitmq.com/tutorials/tutorial-six-python.html"" rel=""nofollow noreferrer"">Rabbit RPC</a>), or is there another listener waiting for an asynchronous response somewhere?</p>&#xA;&#xA;<p>Any thoughts on how this can be implemented from an architectural standpoint?</p>&#xA;"
48900551,Why ESB is considered bad in microservices architecture,2018-02-21 07:45:26,<architecture><microservices><distributed-computing><soa><esb>,1,1068,5,2.0,5,"<p>In microservices architecture, autonomous business services should talk directly with each other. The communication may be synchronous (orchestration) or event-based (choreography). An API gateway may aggregate the API's for the client (backends for frontends). With microservices we are seeking two ultimate goals</p>&#xA;&#xA;<ul>&#xA;<li>Low coupling</li>&#xA;<li>High cohesion</li>&#xA;</ul>&#xA;&#xA;<p>Which grants continuous deployment, fine-grained scaling, rapid technology adaptation, reusability, auditability an much more, of course for the price of higher complexity.</p>&#xA;&#xA;<p>However, it is highly discouraged to use ESB (Enterprise Service Bus) or other middleware. Microservices and ESB is often seen as an rival solutions. Why is an ESB seen so bad? As long as it is just used as an meditation channel with some additional monitoring and authentication layers (no business logic), what's the problem of using it in the microservice architecture?</p>&#xA;"
36627628,setting up Elasticsearch server for processing data from microservices,2016-04-14 15:29:55,<ruby-on-rails><elasticsearch><architecture><microservices>,1,880,0,3.0,5,"<p>I am very new to elasticsearch and its scaling, and I've got a question I don't even know how to approach. </p>&#xA;&#xA;<p>Here's the situation:</p>&#xA;&#xA;<p>There're several servers with Rails microservice applications. Each of them is getting each its own pretty big piece of data (more specifically, aggregating posts from different social networks - so the indexable search fields are the same in all databases).</p>&#xA;&#xA;<p>I need to find a solution that would allow to keep the data where it currently is and setting up an elasticsearch server dedicated exclusively to searching through multiple databases without the respective Rails apps turning on this search server. It potentially means setting up ES on each of the other servers, defining the search patterns there but making the multiple-model search on a totally different server.</p>&#xA;&#xA;<p>The final goal of these manipulations should be sending the entire ActiveRecord objects / or all the related attributes to the main application.</p>&#xA;&#xA;<p>Is it even possible to achieve? Maybe anyone has had a similar problem? </p>&#xA;&#xA;<p>I am a little lost about how to get started with it.</p>&#xA;"
36680157,Communication between REST Microservices: Latency,2016-04-17 17:59:56,<http><connection-pooling><microservices><http2>,3,2688,2,2.0,5,"<p>The problem I'm trying to solve is latency between Microservice communication on the backend. Scenario. Client makes a request to service A, which then calls service B that calls service C before returning a response to B which goes to A and back to the client.</p>&#xA;&#xA;<pre><code>Request: Client -&gt; A -&gt; B -&gt; C&#xA;Response: C -&gt; B -&gt; A -&gt; Client&#xA;</code></pre>&#xA;&#xA;<p>The microservices expose a REST interface that is accessed using HTTP. Where each new HTTP connection between services to submit requests is an additional overhead. I'm looking for ways to reduce this overhead without bringing in another transport mechanism into the mix (i.e. stick to HTTP and REST as much as possible). Some answers suggest using <a href=""https://stackoverflow.com/questions/35673254/communication-between-microservices"">Apache Thrift</a> but I'd like to avoid that. Other possible solutions are using Messaging Queues which I'd also like to avoid. (To keep operational complexity down).</p>&#xA;&#xA;<p>Has anyone experience in microservices communication using HTTP Connection pooling or HTTP/2? The system is deployed on AWS where service groups are fronted by a ELB. </p>&#xA;"
36792713,Dynamic component loading from external content,2016-04-22 11:31:26,<angular><distributed><microservices><angular2-template>,3,1136,4,0.0,5,"<p>The system I am working on consists of a number of distributed microservices with potentially multiple versions of each component active at the same time.</p>&#xA;&#xA;<p>The Angular2 app I am attempting to build shall be able to interact with each of these components by means of websockets. Because it seems unfeasible to prepare this application for all future versions and features of each component, the respective protocol implementation and even new components, I would like to push this responsibility to the components itself. </p>&#xA;&#xA;<p>Each component is able to communicate its capabilities (in the form of a NG2 component) as well as the protocol implementation and the necessary GUI elements (HTML/CSS) via a package sent over the very same websocket connection.</p>&#xA;&#xA;<p>Is there a pattern that enables this kind of 'on-demand-loading' of components and their templates in ng2?</p>&#xA;"
37662379,Jhipster import-jdl not generating entities,2016-06-06 16:23:46,<jhipster><microservices>,4,2344,1,4.0,5,"<p>I am running into a problem with import-jdl and I am not sure why it is not working. I am trying to generate entities for microservices application. </p>&#xA;&#xA;<p>All I get is </p>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;&#xA;<p>but nothing else.</p>&#xA;&#xA;<p>I used the sample <a href=""https://jhipster.github.io/jdl-studio/"" rel=""nofollow"">https://jhipster.github.io/jdl-studio/</a> entity provided by JDL without any modification. </p>&#xA;&#xA;<p>I have tried this in my Mac, Linux (Ubuntu), and Docker container but I get the same error. </p>&#xA;&#xA;<p>Here are the versions of the software: </p>&#xA;&#xA;<pre><code>JHipster Generator: v3.3.0&#xA;npm : 3.9.2&#xA;yo : 1.8.3&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>Microservices Application </p>&#xA;  &#xA;  <p>------- Application files will be generated in folder: /Users/anand/Desktop/jhexample </p>&#xA;  &#xA;  <hr>&#xA;  &#xA;  <p>JHipster update available: 3.4.0 (current: 3.3.0)   Run npm install&#xA;  -g generator-jhipster to update.  ______________________________________________________________________________</p>&#xA;  &#xA;  <p>? (1/16) Which <em>type</em> of application would you like to create?&#xA;  Microservice application</p>&#xA;  &#xA;  <p>? (2/16) What is the base name of your application? jhexample</p>&#xA;  &#xA;  <p>? (3/16) As you are running in a microservice architecture, on which&#xA;  port would like your server to run? It should be unique to avoid port&#xA;  conflicts. 8081</p>&#xA;  &#xA;  <p>? (4/16) What is your default Java package name? com.anand</p>&#xA;  &#xA;  <p>? (5/16) Which <em>type</em> of authentication would you like to use? JWT&#xA;  authentication (stateless, with a token)</p>&#xA;  &#xA;  <p>? (6/16) Which <em>type</em> of database would you like to use? MongoDB</p>&#xA;  &#xA;  <p>? (7/16) Would you like to use Maven or Gradle for building the&#xA;  backend? Maven</p>&#xA;  &#xA;  <p>? (8/16) Would you like to enable internationalization support? No</p>&#xA;  &#xA;  <p>? (9/16) Which testing frameworks would you like to use? (Press&#xA;   to select)Gatling</p>&#xA;</blockquote>&#xA;&#xA;<p>...snip...</p>&#xA;&#xA;<blockquote>&#xA;  <p>Server app generated successfully.</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>anand$ yo jhipster:import-jdl ./jhipster-jdl.jh&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;"
44704629,identity aspnet core microservices,2017-06-22 16:15:48,<asp.net-core><microservices><identityserver4>,1,373,0,1.0,5,"<p>I want to develop an application using microservices architecture. I'm really new at microservices and until now I've only worked with monolithich approach.</p>&#xA;&#xA;<p>What I would like to do is to have a microservice which takes care of user authentication and have Proxy APIS to authorize the requests. </p>&#xA;&#xA;<p>Authorizing the request in the Proxy API is pretty well documented on the IdentityServer4 docs, but, when the proxy api passes the request to the end microservice how do I authorize this request?</p>&#xA;&#xA;<p>I know that if I setup the end microservice correctly, the same token used in the proxy api can be used to authorize the request at the end microservice. But how do I pass it? Do I grab the token from the request in the Proxy API and pass it down to the end microservice just like that? is it a good practice to do this?</p>&#xA;&#xA;<p>Or is it a better option to block the end microservice to receive only requests from my proxy apis and have no authorization logic there?</p>&#xA;&#xA;<p>PD: I would like to use asp.net-core</p>&#xA;"
37523631,HTTP vs Thrift in microservices architecture,2016-05-30 10:39:41,<java><microservices>,1,2185,0,1.0,5,"<p>I'm have just start learning about micro-services and I have a question that I cannot answer myself. (and I'm also a Java based developer)</p>&#xA;&#xA;<p>I have a situation like this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I have service A (an API service) that call Thrift services (Named T1) for get data.</p></li>&#xA;<li><p>Then I have a service B that can use data response from A, parse these data and then generate some new data, finally, return it to client.</p></li>&#xA;</ol>&#xA;&#xA;<p>The question is: Which I should use?&#xA;B call API from A and parse (for example JSON data) with HttpClient/ AsyncHttpClient with connection pool or B direct call T1 and repeat what A do?</p>&#xA;&#xA;<p>IMHO, I think Thrift (with connection pooling too) is faster than HTTP call? Am I right?</p>&#xA;&#xA;<p>I see a lot of services that use HTTP for internal like Elastic search, Neo4j, Eureka Netflix, etc ...</p>&#xA;&#xA;<p>So, which one should I use? And why HTTP is so popular for internal use instead of RPC like Thrift, ProtoBuf, ...?</p>&#xA;&#xA;<p>Sorry for my bad english.&#xA;Thank you in advance.</p>&#xA;"
44085454,Join table between Different Microservices,2017-05-20 11:41:21,<architecture><microservices>,3,2111,0,1.0,5,"<p>I am still trying to make sense of micro service architecture.</p>&#xA;&#xA;<p>The idea to separate different application (include the database) excites me. But I am still confused if there are two micro-services e.g. Product and User. both product and user own table product and user respectively in their database. According to best practice in micro service, we only can access the database from the service. </p>&#xA;&#xA;<p>The problem is, let us suppose we have product table that has user_id column. We want to do search product which also return the name of the user who create the product. This requires join between product table in product micro-service and user table in user micro-service. How do you handle this? </p>&#xA;"
44065186,How to implement distributed transaction with hystrix fallback based on Spring Cloud architect,2017-05-19 08:35:52,<spring-cloud><microservices><distributed-transactions><hystrix><spring-cloud-netflix>,1,1134,1,4.0,5,"<p>I am using spring cloud to implement my micro services system, a ticket sale platform. The scenario is, there is a zuul proxy, a eureka registry, and 3 service: user service, order service and ticket service. Services use feign declarative REST Client to communicate with each other.</p>&#xA;&#xA;<p>Now there is a function to buy tickets, the main process is as below:<br>&#xA;  1. order service accept request to create order<br>&#xA;  2. order service create Order entity with Pending status.<br>&#xA;  3. order service call user service to process user pay.<br>&#xA;  4. order service call ticket service to update user tickets.<br>&#xA;  5. order service update the order entity as FINISHED.</p>&#xA;&#xA;<p>And I want to use <code>Hystrix Fallback</code> to implement transaction. For example, if the payment process is finished, but some error happened during ticket movement. How to revet user payment, and order status. Because user payment is in other service.</p>&#xA;&#xA;<p>The following is my current solution, I am not sure whether it is proper. Or is there any other better way to do that.</p>&#xA;&#xA;<p>At first, the OrderResource:</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/api/order"")&#xA;public class OrderResource {&#xA;&#xA;  @HystrixCommand(fallbackMethod = ""createFallback"")&#xA;  @PostMapping(value = ""/"")&#xA;  public Order create(@RequestBody Order order) {&#xA;    return orderService.create(order);&#xA;  }&#xA;&#xA;  private Order createFallback(Order order) {&#xA;    return orderService.createFallback(order);&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then the OrderService:</p>&#xA;&#xA;<pre><code>@Service&#xA;public class OrderService {&#xA;&#xA;    @Transactional&#xA;    public Order create(Order order) {&#xA;        order.setStatus(""PENDING"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        userCompositeService.payForOrder(payDTO);&#xA;&#xA;        order.setStatus(""PAID"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        ticketCompositeService.moveTickets(ticketIds, currentUserId);&#xA;&#xA;        order.setStatus(""FINISHED"");&#xA;        order = orderRepository.save(order);&#xA;        return order;&#xA;    }&#xA;&#xA;    @Transactional&#xA;    public Order createFallback(Order order) {&#xA;        // order is the object processed in create(), there is Transaction in create(), so saving order will be rollback,&#xA;        // but the order instance still exist.&#xA;        if (order.getId() == null) { // order not saved even.&#xA;            return null;&#xA;        }&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        try {&#xA;            if (order.getStatus() == ""FINISHED"") { // order finished, must be paid and ticket moved&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PAID"") { // is paid, but not sure whether has error during ticket movement.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PENDING"") { // maybe have error during payment.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;            }&#xA;        } catch (Exception e) {&#xA;            LOG.error(e.getMessage(), e);&#xA;        }&#xA;&#xA;        order.setStatus(""FAILED"");&#xA;        orderRepository.save(order); // order saving is rollbacked during create(), I save it here to trace the failed orders.&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Some key points here are:</p>&#xA;&#xA;<ol>&#xA;<li>Using <code>@HystrixCommand</code> in <code>OrderResource.create(order)</code> method, with <code>fallback</code> function.   </li>&#xA;<li>If there is some error in creation, the <code>order</code> instance used in  <code>OrderResource.create(order)</code> will be used again in fallback function. Although the persistence of this <code>order</code> will be roll-backed. But the data in this instance still can be used to check the running.   </li>&#xA;<li>So I use a status: 'PENDING', 'PAID', 'FINISHED' to check whether some service call is made.   </li>&#xA;<li><code>ticketCompositeService</code> and <code>userCompositeService</code> is a feign client. For feign client method <code>payForOrder()</code>, there is another method <code>payForOrderFallback()</code> for fallback.   </li>&#xA;<li>I need to make sure the fallback methods can be called multiple times.   </li>&#xA;<li>I add <code>try/catch</code> for <code>ticketCompositeService</code> and <code>userCompositeService</code> call, to make sure the order will be save anyway with 'FAILED' status.</li>&#xA;</ol>&#xA;&#xA;<p>It seems that this solution can work at the most of the time. Except that, in fallback function, if there is some error in <code>userCompositeService.payForOrderFallback(payDTO);</code>, then the following composite service call will not be called.</p>&#xA;&#xA;<p>And, another problem is, I think it is too complicated.</p>&#xA;&#xA;<p>So, for this scenario, how should I implement dist transaction properly and effectively. Any suggestion or advice will help. Thanks.</p>&#xA;"
35673254,Communication Between Microservices,2016-02-27 17:50:46,<rpc><thrift><microservices>,1,2549,4,2.0,5,"<p>Say you have microservice A,B, and C which all currently communicate through HTTP. Say service A sends a request to service B which results in a response. The data returned in that response must then be sent to service C for some processing before finally being returned to service A. Service A can now display the results on the web page. </p>&#xA;&#xA;<p>I know that latency is an inherent issue with implementing a microservice architecture, and I was wondering what are some common ways of reducing this latency? </p>&#xA;&#xA;<p>Also, I have been doing some reading on how Apache Thrift and RPC's can help with this. Can anyone elaborate on that as well?  </p>&#xA;"
46453981,How an authorization service implements ownership checks in a role-based microservice architecture,2017-09-27 17:34:28,<design><architecture><authorization><microservices><soa>,2,162,0,2.0,5,"<p>Let's say I have three types of users on a blogging app</p>&#xA;&#xA;<ol>&#xA;<li><strong>Author</strong> (is able to modify their own posts but not others)</li>&#xA;<li><strong>Administrator</strong> (is able to modify all posts)</li>&#xA;<li><strong>Reader</strong> (can not modify any posts)</li>&#xA;</ol>&#xA;&#xA;<p>To manage this system I want to have three main services: </p>&#xA;&#xA;<ul>&#xA;<li>An <strong>API Gateway</strong> that exposes all the APIs clients will consume, composing services as needed. </li>&#xA;<li>A <strong>Post Management Service</strong> which provides the CRUD operations for blog posts (including the data of who owns what posts)</li>&#xA;<li>An <strong>Authorization Service</strong> which stores roles and permissions, exposing an API which takes in an array of roles (the roles a requesting user has) and an array of permissions (the permissions needed to access an API) and determines if those inputted roles cover all the permissions inputted. </li>&#xA;</ul>&#xA;&#xA;<p>Now what I am struggling with is ownership of a resource (and where ownership should be checked).</p>&#xA;&#xA;<p>Without communicating with other services how would an authorization service determine if a user should be able to access something they own without knowing how to determine if a user owns a given resource. </p>&#xA;&#xA;<p>I've come up with a few different solutions to this problem, although I'm not quite happy with any of them. </p>&#xA;&#xA;<ol>&#xA;<li>The API Gateway would query a different service that manages the posts to determine if a requesting user owns the post they are trying to access, this would mean there is authorization logic that happens outside of the authorization service.</li>&#xA;<li>The service managing blog posts would handle authorization based on ownership, this would also mean authorization logic is happening outside the authorization service as well as the fact that unauthorized requests are being marked as authorized initially (since they will still pass through the authorization service)</li>&#xA;<li>The Authorization service could be given the knowledge of how to check ownership, the API would have to be able to be told whether or not it should check for ownership along with the permissions. This would add complexity to the authorization service and increase the cross-service communication which I'd like to relegate as much as possible to the API gateway since it should be the primary service composer. </li>&#xA;</ol>&#xA;&#xA;<p>Looking for ideas on alternative methods or insight into what the best solution to this problem might be.</p>&#xA;"
46311488,Confused about ESBs as a solution to point-to-point integration,2017-09-20 00:20:34,<architecture><microservices><esb>,4,675,0,0.0,5,"<p>Still very new to studying application architecture and having trouble stomaching some ideas in a book about microservices. In my readings, I have come across the older idea of the ESBs(Enterprise Service Bus) and its role in coordinating messages between new services and legacy applications. ESBs are touted as a solution to problems poised by point-to-point integration. Microservices seem to be the approach taken by newer companies as the de facto standard to creating an agile, scalable, and resilient app. But aren't microservices using point-to-point integration? Each node in an application built from microservices is communicating directly with other nodes, right? I feel I am connecting some dots that shouldn't be connected. Any help much appreciated, thanks in advance.</p>&#xA;"
40947247,"Event sourcing, CQRS and database in Microservice",2016-12-03 11:30:16,<microservices><cqrs><event-sourcing>,1,1104,1,1.0,5,"<p>I am quite new in context of Micro-service architecture and reading this post : <a href=""http://microservices.io/patterns/data/event-sourcing.html"" rel=""noreferrer"">http://microservices.io/patterns/data/event-sourcing.html</a> to get familiar with Event sourcing and data storage in Microservice architecture. &#xA;I have read many documents about 3 important aspect of system :</p>&#xA;&#xA;<ol>&#xA;<li>Using event sourcing instead of a simply shared DB and ORM and&#xA;    row update</li>&#xA;<li>Events are JAVA objects. </li>&#xA;<li>In case of saving data permanently&#xA;    , we need to use DB (either relational or noSQL)</li>&#xA;</ol>&#xA;&#xA;<p>Here are my questions :</p>&#xA;&#xA;<ol>&#xA;<li><p>How database comes along with event sourcing? I have read CQRS&#xA;pattern, but I can not understand how CQRS pattern is related to&#xA;event store and event objects ?  </p></li>&#xA;<li><p>Can any body provide me a&#xA;    complete picture and set of operations happens with all players to&#xA;    gather: CQRS pattern , Event sourcing (including event storage&#xA;    module) and finally different microservices?</p></li>&#xA;<li>In a system&#xA;        composed of many microservices, should we have one event storage or&#xA;        each microservice has its own ? or both possible ?</li>&#xA;<li>same&#xA;    question about CQRS. This pattern is implemented in all&#xA;    microservices or only in one ?  </li>&#xA;<li>Finally, in case of using&#xA;        microservice architecture, it is mandatory to have only one DB or&#xA;        each Microserivce should have its own ?</li>&#xA;</ol>&#xA;&#xA;<p>As you can see, I have understood all small pieces of game , but I can not relate them together to compose a whole image. Specially relevance between CQRS and event sourcing and storing data in DB. &#xA;I read many articles for example :</p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://ookami86.github.io/event-sourcing-in-practice/"" rel=""noreferrer"">https://ookami86.github.io/event-sourcing-in-practice/</a></li>&#xA;<li><a href=""https://msdn.microsoft.com/en-us/library/jj591577.aspx"" rel=""noreferrer"">https://msdn.microsoft.com/en-us/library/jj591577.aspx</a></li>&#xA;</ul>&#xA;&#xA;<p>But in all of them small players are discussed. Even a hand drawing piece of image will be appreciated. </p>&#xA;"
40972026,Netflix-Zuul vs Mashape-Kong,2016-12-05 10:26:37,<microservices><netflix-zuul><kong><mashape>,1,4235,4,3.0,5,<p>Both Zuul and kong serve as a good API gateway layer in a microservices architecture. What are some important differences between these two?</p>&#xA;
49944806,"How we configure API gateway, service discovery for micro services in pcf?",2018-04-20 15:13:55,<spring-boot><microservices><spring-cloud-netflix><pcf>,2,254,0,2.0,5,"<p>I am learning building  microservices using spring boot, Spring Cloud(netflix OSS Components). I have used netflix Eureka for service discovery, zuul for api gateway, ribbon, feign while running in my local machine.</p>&#xA;&#xA;<p>Netflix eureka, zuul, ribbon, feign spring cloud config are not useful when we deploy to PCF?(if yes what are the alternatives available in pcf and how to configure them?)</p>&#xA;&#xA;<p>As who are building microservices follows CI/CD approach, how developer verify working of  their micro services before pushing code as we don't use eureka, zuul,ribbon,feign in production pcf. (how to simulate pcf environment in developer machine?). </p>&#xA;"
47527983,Designing java project for monoliths and microservices at same time,2017-11-28 09:25:20,<java><scope><package><domain-driven-design><microservices>,3,268,2,0.0,5,"<p>I would like to know how you divide project modules in java for monolith with possibility of transforming modules to micro-services later?<br>&#xA;My personal naming looks like this:</p>&#xA;&#xA;<pre><code>com.company.shopapp.product&#xA;...product.domain (ddd, services, repositories, entities, aggregates, command handlers - everything with package scope)&#xA;...product.api (everything with public scope)&#xA;...product.controller (CQRS endpoints for commands in web perspective - (package scope))&#xA;...product.query(CQRS - package scope)&#xA;&#xA;com.company.shopapp.sales&#xA;- domain&#xA;- api &#xA;- controller&#xA;- query &#xA;</code></pre>&#xA;&#xA;<p>What we have here is basically product management context and sales context as packages. </p>&#xA;&#xA;<p>Modules communicate each other using public interfaces (api package) only. In my project I use ""..api.ProductFacade"" to centralize communication points.</p>&#xA;&#xA;<p>When my ""sales"" module grow i will turn it into microservice by implementing ""..api.ProductFacade"" interface as a ""rest"" or ""soap"" client and on the other side I will create Endpoint/RestController based on ProductFacade interface.&#xA;Package ""com.company.shopapp.product.api"" will be transformed into extended library and added to both projects. </p>&#xA;&#xA;<p>Edit: &#xA;I can achive this out of the box using @Feign library.&#xA;<a href=""https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance"" rel=""nofollow noreferrer"">https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance</a></p>&#xA;&#xA;<p>The whole idea feels nice, but maybe you have better way to design project and ensure that breaking it into micro-services will not break whole application. </p>&#xA;"
47544877,Websockets in microservices architecture,2017-11-29 04:05:22,<web-applications><websocket><microservices><api-gateway>,1,1872,5,0.0,5,"<p>Let's say we have a notification service which read an event from message queue and notify all web clients in real time. I know how web socket work but i am puzzled when there is an API gateway in between then how web socket connection is maintained between client, API gateway and notification service.</p>&#xA;&#xA;<p>Please help! Thanks</p>&#xA;&#xA;<p><strong>Edit:</strong>&#xA;Architecture:&#xA;<a href=""https://i.stack.imgur.com/wEeu3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wEeu3.jpg"" alt=""enter image description here""></a></p>&#xA;"
47516458,CQRS: project out-of-order notifications in an ElasticSearch read model,2017-11-27 17:17:35,<elasticsearch><apache-kafka><domain-driven-design><microservices><cqrs>,1,162,8,4.0,5,"<p>We have a microservice architecture and apply the CQRS pattern. A command sent to a microservice triggers an application state change and the emission of the corresponding event on our Kafka bus. We project these events in a read model built with ElasticSearch.</p>&#xA;&#xA;<p>So far, so good.</p>&#xA;&#xA;<p>Our microservices are eventually consistent with each other. But at any given time, they aren't (necessarily). Consequently, the events they send are not always consistent with each other either.</p>&#xA;&#xA;<p>Moreover, to guarantee the coherence between an application state change and the emission of the corresponding event, we persist in DB the new state and the corresponding event in the same transaction (I am aware that we could use event sourcing and avoid persisting the state altogether). An asynchronous worker is then responsible to send these events on the Kafka bus. This pattern guarantees that at least one event will be sent for each state change (which is not an issue since our events are idempotent). However, since each microservice has its own event table and asynchronous worker, we cannot guarantee that events will be sent in the sequence in which the corresponding state changes occurred in their respective microservices.</p>&#xA;&#xA;<p>EDIT: to clarify, each microservice has its own database, its own event table and its own worker. A specific worker processes the events in the order in which they were persisted in its corresponding event table, but different workers on different event tables, i.e. for distinct microservices, do not give such guarantee.</p>&#xA;&#xA;<p>The problem arises when projecting these incoherent or out-of-sequence events from different microservices in the same ElasticSearch document.</p>&#xA;&#xA;<p>A concrete example: let's imagine three different aggregates A, B and C (aggregate in the Domain Driven Design sense) managed by different microservices:</p>&#xA;&#xA;<ul>&#xA;<li>There is a many-to-many relation between A and B. Aggregate A references the aggregate roots B he is bound to, but B is unaware of its relationships with A. When B is deleted, the microservice managing A listens for the corresponding event and undoes the binding of A with B.</li>&#xA;<li>Similarily, there is a many-to-many relation between B and C. B knows of all related C aggregates, but the inverse is not true. When C is deleted, the microservice managing B listens for the corresponding event and undoes the binding of B with C.</li>&#xA;<li>C has a property ""name"".</li>&#xA;</ul>&#xA;&#xA;<p>One of the use cases is to find, through ElasticSearch, all aggregates A that are bound to an aggregate B that is in turn bound to an aggregate C with a specific name.</p>&#xA;&#xA;<p>As explained above, the separate event tables and workers could introduce variable delays between the emission of events from different microservices. Creating A, B and C and binding them together could for example result in the following sequence of events:</p>&#xA;&#xA;<ol>&#xA;<li>B created</li>&#xA;<li>B bound to C</li>&#xA;<li>C created with name XYZ</li>&#xA;<li>A created</li>&#xA;<li>A bound to B</li>&#xA;</ol>&#xA;&#xA;<p>Another example of batch of events: let's suppose we initially have aggregates B and C and two commands are issued simultaneously:</p>&#xA;&#xA;<ul>&#xA;<li>delete C</li>&#xA;<li>bind B to C</li>&#xA;</ul>&#xA;&#xA;<p>this could result in the events:</p>&#xA;&#xA;<ol>&#xA;<li>C deleted</li>&#xA;<li>B bound to C</li>&#xA;<li>B unbound from C (in response to event 1)</li>&#xA;</ol>&#xA;&#xA;<p>Concretely, we have trouble projecting these events in ElasticSearch document(s) because the events sometimes reference aggregates that do not exist anymore or do not exist yet. Any help would be appreciated.</p>&#xA;"
37148836,"What is service discovery, and why do you need it?",2016-05-10 20:56:48,<web-services><configuration><architecture><microservices>,1,1765,2,4.0,5,"<p>As far as I can tell, ""service discovery"" means a way for a client to find out about a server (or cluster of servers) that it wants to connect to.</p>&#xA;&#xA;<p>I've built web applications that communicate with other back-end processes using protocols like HTTP and AMQP. In those, each client has a config file that contains a host name or whatever information it needs to connect to the server, which gets set at deployment time using a configuration tool like Ansible. That's simple and seems to work pretty well.</p>&#xA;&#xA;<p>Is service discovery an alternative to just putting server information in a client's config file? If so, why is it better? If not, what problem does it solve?</p>&#xA;"
46236744,Swagger for Event?,2017-09-15 09:53:26,<events><swagger><microservices><event-driven>,4,327,1,0.0,5,"<p>The <a href=""https://github.com/OAI/OpenAPI-Specification"" rel=""nofollow noreferrer"">Swagger / OpenAPI specification</a> is useful to document and run automated tests against HTTP APIs. However, I run an event-driven microservices architecture and it is important to document the event payload passed among different services, even when they are not accessed via HTTP paths. Since eerything I've seen is API-based via HTTP paths, I'm wondering if Swagger handle this or, if not, is there anything similar for events?</p>&#xA;"
46244677,Verifying Access Token (JWT) in Each Service of a Microservices Architecture,2017-09-15 17:16:46,<rest><authentication><architecture><cloud><microservices>,2,422,1,0.0,5,"<p>I have an application which is implemented using microservice architecture. There is an authentication service (A) which uses jwt standard, and there are other services in the application like S1, S2, S3 and so on.&#xA;Now for example S1 receives a request, it should validate the token to see if the user is authorized or not. The validation can be achieved by:</p>&#xA;&#xA;<ul>&#xA;<li>Sending the token from S1 to A, then A validates the token and sends the result to S1 (which is a kind of overhead)</li>&#xA;<li>Validating the token inside S1 (which is a duplicate action inside every service, also requires secret key or public/private keys inside each service,  for signing/verification)</li>&#xA;</ul>&#xA;&#xA;<p>I'm not asking about how these approaches work exactly. The questions is, which one of them is better? Or what is the best practice in this situation?</p>&#xA;"
41024771,Micro Service vs Nano Service?,2016-12-07 18:30:53,<web-services><agile><microservices>,2,3641,4,0.0,5,"<p>So, what do you call it? A Micro service or a Nano Service?</p>&#xA;&#xA;<p>What differences they have? I came across many blogs on internet and I could find any satisfactory answer. </p>&#xA;&#xA;<p>Found this quotation from Mark Little on <a href=""https://www.infoq.com/news/2014/05/nano-services"" rel=""noreferrer"">InfoQ</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>First things first what actually is a micro service? Well there really isn’t a hard and fast definition but from conversations with various people there seems to be a consensus that a micro service is a simple application that sits around the 10-100 LOC mark.</p>&#xA;</blockquote>&#xA;&#xA;<p>another one:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Nanoservice is an antipattern where a service is too fine-grained. A nanoservice is a service whose overhead (communications, maintenance, and so on) outweighs its utility. Like Steve and others, Arnon concludes that Microservices is just another name for SOA</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm looking for an accurate and explainable distinction between a Micro and a Nano Service. I highly appreciate your opinions!</p>&#xA;"
29830038,Logging in microservices,2015-04-23 17:04:04,<logging><tracing><microservices>,3,1836,0,5.0,5,"<p>assume we've got a number of Web API microservices, and they are written in different languages/framworks (some are ASP.NET Web API, some are NodeJS, some are Flask etc.).</p>&#xA;&#xA;<p>I would like to log every request made to any service, and I would prefer a centralized log.</p>&#xA;&#xA;<p>What method/tools should I use?</p>&#xA;&#xA;<p>Regards,&#xA;Daníel</p>&#xA;"
29636094,Microservices communication,2015-04-14 19:45:33,<java><node.js><apache-zookeeper><microservices>,2,2362,1,3.0,5,"<p>I'm actually studying microservices and I'm facing a problem.</p>&#xA;&#xA;<p><strong>Context</strong></p>&#xA;&#xA;<p>I m developing two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User management, Spring Based, with MySQL database</li>&#xA;<li>Planning management, ASP.NET based with SQL Server database. The only access point of this service is an API listing some RESTFUL endpoints like <code>/planning/{day}/{userId} or /planning/{startDate}/{endDate}/{idUser}</code></li>&#xA;<li>Billing management, Node.Js based with MongoDB.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>What can I do to only permit accessing the planning information through the user service without couple the two services ? Knowing that the planning service could be accessed later from somewhere else, but not now.</p></li>&#xA;<li><p>How can I do to access billing information from billing service corresponding to a user from the MySQL database? I know that microservices are not coupled, and this point is killing me, cause it has to be coupled in a way no? Like referencing <code>idUser</code> in a billing? Else, how can I know which billing from my API should I expose? More precisely, how do microservices communicate between them, without to be coupled?</p></li>&#xA;<li><p>How to create authentication without duplicating authentication requests to the authentication service, from other services?</p></li>&#xA;</ol>&#xA;"
41814001,Heroku load balancer vs Netflix zuul,2017-01-23 19:20:54,<heroku><docker><microservices><netflix-zuul><netflix-eureka>,1,514,0,1.0,5,"<p>According to this answer <a href=""https://stackoverflow.com/a/41811770/2849613"">https://stackoverflow.com/a/41811770/2849613</a> I would like to get a little bit more information about best practices with microservices on Heroku. </p>&#xA;&#xA;<p>The question is which approach is better?</p>&#xA;&#xA;<ol>&#xA;<li>Install every services as independent app, and use one of them as REST ""proxy"" (for example Netflix Eureka)?</li>&#xA;</ol>&#xA;&#xA;<p>Or</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Create docker based approach with, for example Netflix Zuul as a load balancer?</li>&#xA;</ol>&#xA;&#xA;<p>On my own I see already some pros and cons of both approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p><strong>Pros</strong>: better scalability (easy to create new machines for bigger load). <strong>Cons</strong>: communication between services goes ""outside of heroku"" in other words: because heroku app have public address everyone can connect directly to service (without going threw Eureka), because of that every services need to provide some authentication method and share it between each other - I think that this is risk prone. </p></li>&#xA;<li><p><strong>Pros</strong>: easy to reproduce production environment for tests and develop (docker image), communication between services is done ""internally"" (image to image instead app to app). <strong>Cons</strong>: hard to scale (I think that load balancing between Heroku apps and then docker images is a little bit overhead). </p></li>&#xA;</ol>&#xA;&#xA;<p>Which approach is better? Maybe I can mix them together? Or maybe there is some different, better solution?</p>&#xA;&#xA;<p>Do be honest the only thing which I am sure, is that I want to use rabbitMQ as a message queue...</p>&#xA;"
42486386,Does CQRS With OLTP and OLAP Databases Make Sense?,2017-02-27 12:57:36,<api><olap><microservices><cqrs><oltp>,1,219,2,1.0,5,"<p>I have several OLTP databases with API's talking to them. I also have ETL jobs pushing data to an OLAP database every few hours.</p>&#xA;&#xA;<p>I've been tasked with building a custom dashboard showing hight level data from the OLAP database. I want to build several API's pointing to the OLAP database. Should I:</p>&#xA;&#xA;<ol>&#xA;<li>Add to my existing API's and call the OLAP database and use a CQRS type pattern, so reads come from OLAP, while writes come from OLTP. My concern here is that there could be a mismatch in the data between reads and writes. How mismatched the data is depends on how often you run the ETL jobs (Hours in my case).</li>&#xA;<li>Add to my existing API's and call the OLAP databases then ask the client to choose whether they want OLAP or OLTP data where API's overlap. My concern here is that the client should not need to know about the implementation detail of where the data is coming from.</li>&#xA;<li>Write new API's that only point to the OLAP database. This is a lot of extra work.</li>&#xA;</ol>&#xA;"
39485459,Microservice Versioning,2016-09-14 08:07:28,<architecture><versioning><soa><microservices>,4,834,0,1.0,5,"<p>What is the best practice to adapt for versioning in a Microservice Based Architecture, in terms of supporting multiple versioned deployment of the same service during runtime and how the consumers would be able to use different versions?&#xA;1) If we use Routing based Versioning as one of the approaches mentioned <a href=""http://niels.nu/blog/2016/microservice-versioning.html"" rel=""nofollow noreferrer"">here</a>&#xA;then I guess we would have the following drawbacks </p>&#xA;&#xA;<ol>&#xA;<li>Internal Services have to go through Reverse Proxy for consumption.</li>&#xA;<li>Consumers always have to be aware of the required versioning.</li>&#xA;</ol>&#xA;&#xA;<p>Is it a best practice to expose the version information to consumers?  </p>&#xA;&#xA;<p>In any case, as I feel, the following always applies:</p>&#xA;&#xA;<ol>&#xA;<li>For MAJOR version change, the consumers have to be changed.</li>&#xA;<li>For MINOR version change (backwards compatible), only the consumer(s) that requires the added functionality needs to change.</li>&#xA;<li>For PATCH version change, it's optional and would probably be seamless for any consumers to make use of it.</li>&#xA;</ol>&#xA;&#xA;<p>What kind of Microservice versioning strategy can help us in enabling the above?</p>&#xA;&#xA;<p>NOTE - Please feel free to let me know if this needs to be split in multiple questions.</p>&#xA;"
39450504,Serverless Framework - Two services under one APIGW endpoint,2016-09-12 12:37:05,<microservices><amazon-cloudformation><aws-api-gateway><serverless-framework>,5,628,0,1.0,5,"<p>If I have two services, 'Users' and 'Products', each with several functions with endpoints defined for each one (as any traditional API would), is it possible for them to be organised separately in a code base (for clarity) but once deployed share the same API base URL? For example, consider I have the following structure:</p>&#xA;&#xA;<pre><code>/src&#xA;-- /users&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;-- /products&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/users/serverless.yml</code> has the following defined:</p>&#xA;&#xA;<pre><code>functions:&#xA;  create:&#xA;    handler: handler.create&#xA;    events:&#xA;      - http: POST user&#xA;&#xA;  read:&#xA;    handler: handler.read&#xA;    events:&#xA;      - http: GET user&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/products/serverless.yml</code> has basically the same thing, just swap 'user' for 'products'.</p>&#xA;&#xA;<p>Currently, both of those services will be deployed to distinctly different API endpoints, one with a URL <code>https://fghijklmnop.execute-api...</code> and another with a URL <code>https://abcdevwxyz.execute-api....</code> </p>&#xA;&#xA;<p>My question is, would it be possible to have these services be deployed but remain under a single API with a single URL (so both would be served under URL <code>https://abcdevwxyz.execute-api....</code>)?</p>&#xA;&#xA;<p>I'm assuming the answer to be, 'No, because Cloud Formation...', but I thought I would post the question here simply for the sake of discussion and to aid my own understanding of building serverless applications.</p>&#xA;&#xA;<p>I'm aware of using Custom Domains, as per <a href=""https://stackoverflow.com/questions/38408493/serverless-framework-v1-multiple-resources-in-one-service"">the answer here</a>, but for a quicker development cycle this is not really an ideal solution.</p>&#xA;&#xA;<p>My only solution so far would be to simply create a service called 'api' which would contain all the endpoints my API would need which would simply invoke my other services' Lambda functions directly rather than via previously-configured endpoints. It would be an abstraction layer, really, but add potentially unnecessary layers to my application. Again, curious to see what the community feels on this.</p>&#xA;"
47647560,How to share entity between REST service between two microservices?,2017-12-05 06:41:54,<java><rest><microservices>,3,643,2,2.0,5,<p>I have created two micro-services using java. I need to make a REST api call from service A to service B. The data sent will be in JSON format. Using jax-rs I need to create entity class in both the service.</p>&#xA;&#xA;<p>Since both the entity class be same in both the projects. Do i </p>&#xA;&#xA;<ul>&#xA;<li>Create an common jar and use is for all my entity/domain objects? Does this make my microservice more tightly coupled?</li>&#xA;<li>Do i create the same class in both the microservice projects? This will just mean repeating the work in both the projects?</li>&#xA;</ul>&#xA;&#xA;<p>Is there a better way to communicate between the sevices?</p>&#xA;
45622414,Should there be authentication/authorization between microservices?,2017-08-10 19:51:25,<soa><microservices>,3,1038,0,0.0,5,"<p>I know this may be not a good question.</p>&#xA;&#xA;<p>I was asked a question: do we really need authentication among microservices. And I have no idea the answer. I did read some tutorials on SOA, microservices, and how to add authentication among the services. But I did not have too many ideas <strong>why we need authentication/authorization between microservices? Any use cases where they are required? Any use cases where they are not required?</strong> Any potential risk without authentication/authorization? </p>&#xA;&#xA;<p>Any comments welcomed. It is better to give some practical examples. Thanks</p>&#xA;"
45655728,What is the real difference between an API and an microservice?,2017-08-12 23:17:02,<api><microservices>,5,11680,0,2.0,5,"<p>I am learning about microservices and I don't understand what the real difference between creating a REST API and creating microservices is. I’m working in Go, but my question applies over all languages.</p>&#xA;"
20693516,"In a micro-service architecture, how the micro-services will be served?",2013-12-19 23:12:37,<service><deployment><architecture><port><microservices>,1,3018,0,1.0,6,"<p>I have read some articles and watched some videos, but did not find a concrete suggestion when it comes to serving those micro-services. My understanding is that they should be served with their own application server. </p>&#xA;&#xA;<p>My question is should they be deployed on different servers or it does not matter.</p>&#xA;&#xA;<p>When they are served on the same server(computer) won't there be port conflicts?</p>&#xA;"
28319278,How to connect separate microservice applications?,2015-02-04 10:40:39,<api><security><rest><http><microservices>,5,3209,2,1.0,6,"<p>I am building huge application using microservices architecture. The application will consist of multiple backend microservices (deployed on multiple cloud instances), some of which I would like to connect using rest apis in order to pass data between them.</p>&#xA;&#xA;<p>The application will also expose public api for third parties, but the above mentioned endpoints should be restricted ONLY to other microservices within the same application creating some kind of a private network.</p>&#xA;&#xA;<p>So, my question is: </p>&#xA;&#xA;<p><strong>How to achieve that restricted api access to other microservices within the same application?</strong></p>&#xA;&#xA;<p>If there are better ways to connect microservices than using http transport layer, please mention them.</p>&#xA;&#xA;<p>Please keep the answers server/language agnostic if possible.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
26491425,Why should a 12 Factor app be self contained?,2014-10-21 16:16:05,<java><paas><12factor><microservices>,2,1169,0,0.0,6,"<p>In the 12 Factor article on Port Binding&#xA;<a href=""http://12factor.net/port-binding"" rel=""nofollow noreferrer"">http://12factor.net/port-binding</a> there is a requirement that every app&#xA;be self-contained and not have a runtime injected e.g. Tomcat. For&#xA;what reason is this advised... what are advantages of self-contained apps for microservices?</p>&#xA;"
29888108,How to call a microservice in .NET,2015-04-27 05:49:37,<c#><.net><rest><asp.net-web-api><microservices>,4,11466,1,3.0,6,"<p>I've created a very simple REST microservice that receives information about an email and sends it. The microservice send method looks something like this:</p>&#xA;&#xA;<pre><code>//EmailController&#xA;[HttpPost]&#xA;public IHttpActionResult Send(Email email)&#xA;{&#xA;    // send email via exchange&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now in my application, I call it using RestSharp like this:</p>&#xA;&#xA;<pre><code>var client = new RestClient(""http://localhost:51467/api/"");&#xA;var request = new RestRequest(""email/send"", Method.POST);&#xA;request.RequestFormat = DataFormat.Json;&#xA;dynamic obj = new ExpandoObject();&#xA;obj.FromAddress = from;&#xA;obj.ToAddress = to;&#xA;obj.Subject = subject;&#xA;obj.Body = body;&#xA;&#xA;request.AddBody(obj);&#xA;client.Execute(request);&#xA;</code></pre>&#xA;&#xA;<p>Questions I have:</p>&#xA;&#xA;<ol>&#xA;<li><p>Is this the best way to do the call? Obviously i'll later have to add error handling etc, but I'm talking more the way I'm using RestSharp to do the call.</p></li>&#xA;<li><p>I'm finding it a bit uncomfortable that my app needs to kind of know what object the microservice expects to receive - there's no sort of definition/interface/contract that it uses to know for sure. Is this generally accepted as being ok for REST or should I implement some sort of interface that my app has so it can call my microservice in a bit more of a defined way. Is that even something possible with REST?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!</p>&#xA;"
35172625,Spring Cloud Config Eureka-first approach not working,2016-02-03 09:08:19,<spring><spring-boot><spring-cloud><microservices><netflix-eureka>,1,11088,3,2.0,6,"<p>I'm developing a Spring Cloud Eureka microservices application. I want my services to connect to the config service via an Eureka-first approach. Microservices are packaged as docker containers and deployed via docker-compose. The application is composed by:</p>&#xA;&#xA;<ol>&#xA;<li><code>myapp-service-registry</code>: a service registry service implemented with Spring Cloud Eureka</li>&#xA;<li><code>myapp-config-service</code>: a Spring Cloud config service server</li>&#xA;<li><code>myapp-service-test</code>: An example microservice which should try to take its config data from the config service by connecting to this via an Eureka-first approach. </li>&#xA;</ol>&#xA;&#xA;<p>The connection to the config service fail as described below. First of all some configuration data:</p>&#xA;&#xA;<p>Here is <code>myapp-service-registry</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${PORT:8761}&#xA;&#xA;eureka:&#xA;  client:&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;  server:&#xA;    waitTimeInMsWhenSyncEmpty: 0&#xA;</code></pre>&#xA;&#xA;<p>Here the <code>myapp-config-service</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${MYAPP_CONFIG_SERVICE_PORT:8888}&#xA;&#xA;spring: &#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;  config:&#xA;    name: myapp-config-service&#xA;&#xA;# eureka service registry client&#xA;&#xA;eureka: &#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>Config server and client are initialized as in <code>configserver-eureka</code> and <code>eureka-first</code> samples in <a href=""https://github.com/spring-cloud-samples/tests"" rel=""nofollow"">https://github.com/spring-cloud-samples/tests</a> :</p>&#xA;&#xA;<p><code>myapp-config-service</code>'s <code>bootstrap.yml</code> is:</p>&#xA;&#xA;<pre><code>spring:&#xA;    application:&#xA;        name: myapp-config-service&#xA;    cloud:&#xA;        config:&#xA;            discovery:&#xA;                enabled: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>eureka:&#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>bootstrap.yml</code>:</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: myapp-service-test&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        serviceId: myapp-config-service&#xA;</code></pre>&#xA;&#xA;<p>Following is the <code>docker-compose.yml</code> (env variable are replaced with actual values at launch):</p>&#xA;&#xA;<pre><code>myapp-service-registry:&#xA;image: myapp/myapp-service-registry:0.0.1&#xA;ports:&#xA;    - ${EUREKA_PORT}:${EUREKA_PORT}&#xA;&#xA;# myapp-config-service&#xA;&#xA;myapp-config-service:&#xA;    image: myapp/myapp-config-service:0.0.1&#xA;    volumes:&#xA;    - ${MYAPP_DATA_FOLDER}/config:/var/opt/myapp/config&#xA;    environment:&#xA;      MYAPP_CONFIG_SERVICE_PORT: ${MYAPP_CONFIG_SERVICE_PORT}&#xA;      SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;      SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;      MYAPP_CONFIG_SERVICE_GIT_URI: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;    ports:&#xA;        - ${MYAPP_CONFIG_SERVICE_PORT}:${MYAPP_CONFIG_SERVICE_PORT}&#xA;&#xA; # myapp-service-test&#xA;&#xA;myapp-service-test:&#xA;  image: myapp/myapp-service-test:0.0.1&#xA;  environment:&#xA;    SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;    SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;  ports:&#xA;    - ${MYAPP_SERVICE_TEST_TWO_PORT}:8080&#xA;</code></pre>&#xA;&#xA;<p>I can check that Eureka is working by connecting the browser to <a href=""http://[...MACHINE-IP...]:8761/"" rel=""nofollow"">http://[...MACHINE-IP...]:8761/</a> and seeing the Eureka dashboard. Similarly, I test that the config service is working and responds to <a href=""http:///[...MACHINE-IP...]:8888/myapp-config-service"" rel=""nofollow"">http:///[...MACHINE-IP...]:8888/myapp-config-service</a>; With the above configuration, on the other hand, myapp-service-test crashes at startup with the following log:</p>&#xA;&#xA;<pre><code>-02-03 08:26:45.191  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Starting TestServiceApplication v0.0.1 on b1bc37422027 with PID 1 (/app.jar started by root in /)&#xA;2016-02-03 08:26:45.223  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : No active profile set, falling back to default profiles: default&#xA;2016-02-03 08:26:45.448  INFO 1 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@4d97e82d: startup date [Wed Feb 03 08:26:45 UTC 2016]; root of context hierarchy&#xA;2016-02-03 08:26:46.382  INFO 1 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2016-02-03 08:26:46.442  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'configurationPropertiesRebinderAutoConfiguration' of type [class org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6b65138e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-02-03 08:26:47.089  INFO 1 --- [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING&#xA;2016-02-03 08:26:48.231  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:48.237  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.496  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false&#xA;2016-02-03 08:26:49.498  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false&#xA;2016-02-03 08:26:49.502  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server&#xA;2016-02-03 08:26:49.720  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't get a response from http://localhost:8761/eureka/apps/&#xA;&lt;...&gt;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.jar!/:1.19]&#xA;    at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.jar!/:1.19]&#xA;    at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    &lt;...&gt;&#xA;Caused by: java.net.ConnectException: Connection refused&#xA;    at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_66-internal]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.747 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.770 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_MYAPP-SERVICE-TEST/b1bc37422027:myapp-service-test - was unable to refresh its cache! status = java.net.ConnectException: Connection refused&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.785  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.&#xA;2016-02-03 08:26:49.810  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 10&#xA;2016-02-03 08:26:49.818  INFO 1 --- [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4&#xA;2016-02-03 08:26:50.443  WARN 1 --- [           main] lientConfigServiceBootstrapConfiguration : Could not locate configserver via discovery&#xA;&#xA;java.lang.RuntimeException: No matches for the virtual host name :myapp-config-service&#xA;    at com.netflix.discovery.DiscoveryClient.getNextServerFromEureka(DiscoveryClient.java:782) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    at org.springframework.cloud.netflix.config.DiscoveryClientConfigServiceBootstrapConfiguration.refresh(DiscoveryClientConfigServiceBootstrapConfiguration.java:71) [spring-cloud-netflix-core-1.1.0.M3.jar!/:1.1.0.M3]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:50.470  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Started TestServiceApplication in 7.101 seconds (JVM running for 9.329)&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v1.3.1.RELEASE)&#xA;&#xA;2016-02-03 08:26:50.773  INFO 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://localhost:8888&#xA;2016-02-03 08:26:51.015  WARN 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""http://localhost:8888/myapp-service-test/default"":Connection refused; nested exception is java.net.ConnectException: Connection refused&#xA;&#xA;&lt;...&gt;&#xA;&#xA;2016-02-03 08:26:54.856 ERROR 1 --- [pool-5-thread-1] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:57.272  WARN 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testTwoServiceController': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: java.lang.String myapp.services.two.TestServiceController.message; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'message' in string value ""${message}""&#xA;2016-02-03 08:26:57.281  INFO 1 --- [           main] o.apache.catalina.core.StandardService   : Stopping service Tomcat&#xA;2016-02-03 08:26:57.299 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Note that if I don't implement an Eureka-first approach (and set spring.cloud.config.uri directly in the service's <code>bootstrap.yml</code>), the service registers to Eureka, finds the config server and works correctly (I can see the registered service in Eureka's dashboard and can check that config properties are correctly read).</p>&#xA;"
34023438,microservices: How to model related domain objects?,2015-12-01 15:02:03,<soa><microservices>,1,353,0,1.0,6,"<p>I have 2 domain objects: Project and Contract. A project can have many contracts so in the database it is modeled as a classic one-to-many relationship. Our question is this: How do you model the above in the context of microservices? Do you (a) have 2 microservices ProjectService and ContractService? or (b) Do you have one ProjectService which encompasses both Projects and Contracts?</p>&#xA;&#xA;<p>We are thinking that answer (a) (i.e. 2 microservices ProjectService and ContractService) implies that one would have to call 2 services to retrieve and save the complete Project object hierarchy. On the other hand, answer (a) completely decouples Projects from Contracts which may be a good thing in theory, but practically useless since a Contract cannot logically exist without a Project.</p>&#xA;&#xA;<p>What is the correct approach here? Is answer (a) an example of the nano service anti pattern?</p>&#xA;"
33952306,"Microservice, amqp and service registry / discovery",2015-11-27 07:31:10,<rest><architecture><amqp><microservices><service-discovery>,1,767,1,1.0,6,"<p>I m studying Microservices architecture and I m actually wondering something.</p>&#xA;&#xA;<p>I m quite okay with the fact of using (back) service discovery to make request able on REST based microservices. I need to know where's the service (or at least the front of the server cluster) to make requests. So it make sense to be able to discover an ip:port in that case.</p>&#xA;&#xA;<p>But I was wondering what could be the aim of using service registry / discovery when dealing with AMQP (based only, without HTTP possible calls) ?</p>&#xA;&#xA;<p>I mean, using AMQP is just like ""I need that, and I expect somebody to answer me"", I dont have to know who's the server that sent me back the response.</p>&#xA;&#xA;<p>So what is the aim of using service registry / discovery with AMQP based microservice ?</p>&#xA;&#xA;<p>Thanks for your help</p>&#xA;"
32470907,"Microservices - Maintaining Multiple Data stores, initial data load etc",2015-09-09 04:28:10,<microservices>,1,547,2,1.0,6,"<p>On aspects of granulatiry of mictoservices have read about the 2 pizza rule, services that can be developed in 2 weeks etc.  When the case studies of amazon, nelflix, gilt are read we hear about 100s of services. While the service granularity does make sense, what is still not clear to me is about the data stores of each of these microservices. Will there not be just too many data stores if each of the services store/maintain their own data ?? It might be the same logical entity like a product, customer etc that is sliced &amp; the relevant portion/attributes stored/maintained by a corresponding microservice. There could be a service that maintains basic customer information, another that maintains the additional customer information like say his subscription information or his interests etc. </p>&#xA;&#xA;<p>Couple of questions that come to mind around the data stores</p>&#xA;&#xA;<ol>&#xA;<li>Will this not be a huge maintenance issue in terms of backups,&#xA;restores etc? </li>&#xA;<li>How is the initial data populated into these stores ? Are there any best practices around this ? Organisations are bound to have huge volumes of customer or product data &amp; they will most likely be mastered in other systems. </li>&#xA;<li>How does this approach of multiple data stores impact the 'omni-channel' approach where it  implies getting a single view of all data? Organizations might have had data consolidation initiatives going on to achieve the same</li>&#xA;</ol>&#xA;&#xA;<p>Edit: Edited the subject a bit</p>&#xA;"
40222469,"GraphQL: Filtering, sorting and paging on nested entities from separate data sources?",2016-10-24 15:46:21,<microservices><graphql><graphql-js><apollo-server>,1,2634,3,1.0,6,"<p>I'm attempting to use graphql to tie together a number of rest endpoints, and I'm stuck on how to filter, sort and page the resulting data.  Specifically, I need to filter and/or sort by nested values.   </p>&#xA;&#xA;<p>I cannot do the filtering on the rest endpoints in all cases because they are separate microservices with separate databases.  (i.e. I could filter on <code>title</code> in the rest endpoint for articles, but not on author.name). Likewise with sorting.  And without filtering and sorting, pagination cannot be done on the rest endpoints either.</p>&#xA;&#xA;<p>To illustrate the problem, and as an attempt at a solution, I've come up with the following using <code>formatResponse</code> in <a href=""https://github.com/apollostack/graphql-server"" rel=""noreferrer"">apollo-server</a>, but am wondering if there is a better way.</p>&#xA;&#xA;<p>I've boiled down the solution to the most minimal set of files that i could think of:</p>&#xA;&#xA;<p>data.js represents what would be returned by 2 fictional rest endpoints:</p>&#xA;&#xA;<pre><code>export const Authors = [{ id: 1, name: 'Sam' }, { id: 2, name: 'Pat' }];&#xA;&#xA;export const Articles = [&#xA;  { id: 1, title: 'Aardvarks', author: 1 },&#xA;  { id: 2, title: 'Emus', author: 2 },&#xA;  { id: 3, title: 'Tapir', author: 1 },&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>the schema is defined as:</p>&#xA;&#xA;<pre><code>import _ from 'lodash';&#xA;import {&#xA;  GraphQLSchema,&#xA;  GraphQLObjectType,&#xA;  GraphQLList,&#xA;  GraphQLString,&#xA;  GraphQLInt,&#xA;} from 'graphql';&#xA;&#xA;import {&#xA;  Articles,&#xA;  Authors,&#xA;} from './data';&#xA;&#xA;const AuthorType = new GraphQLObjectType({&#xA;  name: 'Author',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    name: {&#xA;      type: GraphQLString,&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const ArticleType = new GraphQLObjectType({&#xA;  name: 'Article',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    title: {&#xA;      type: GraphQLString,&#xA;    },&#xA;    author: {&#xA;      type: AuthorType,&#xA;      resolve(article) {&#xA;        return _.find(Authors, { id: article.author })&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const RootType = new GraphQLObjectType({&#xA;  name: 'Root',&#xA;  fields: {&#xA;    articles: {&#xA;      type: new GraphQLList(ArticleType),&#xA;      resolve() {&#xA;        return Articles;&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;export default new GraphQLSchema({&#xA;  query: RootType,&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>And the main index.js is:</p>&#xA;&#xA;<pre><code>import express from 'express';&#xA;import { apolloExpress, graphiqlExpress } from 'apollo-server';&#xA;var bodyParser = require('body-parser');&#xA;import _ from 'lodash';&#xA;import rql from 'rql/query';&#xA;import rqlJS from 'rql/js-array';&#xA;&#xA;import schema from './schema';&#xA;const PORT = 8888;&#xA;&#xA;var app = express();&#xA;&#xA;function formatResponse(response, { variables }) {&#xA;  let data = response.data.articles;&#xA;&#xA;  // Filter&#xA;  if ({}.hasOwnProperty.call(variables, 'q')) {&#xA;    // As an example, use a resource query lib like https://github.com/persvr/rql to do easy filtering&#xA;    // in production this would have to be tightened up alot&#xA;    data = rqlJS.query(rql.Query(variables.q), {}, data);&#xA;  }&#xA;&#xA;  // Sort&#xA;  if ({}.hasOwnProperty.call(variables, 'sort')) {&#xA;    const sortKey = _.trimStart(variables.sort, '-');&#xA;    data = _.sortBy(data, (element) =&gt; _.at(element, sortKey));&#xA;    if (variables.sort.charAt(0) === '-') _.reverse(data);&#xA;  }&#xA;&#xA;  // Pagination&#xA;  if ({}.hasOwnProperty.call(variables, 'offset') &amp;&amp; variables.offset &gt; 0) {&#xA;    data = _.slice(data, variables.offset);&#xA;  }&#xA;  if ({}.hasOwnProperty.call(variables, 'limit') &amp;&amp; variables.limit &gt; 0) {&#xA;    data = _.slice(data, 0, variables.limit);&#xA;  }&#xA;&#xA;  return _.assign({}, response, { data: { articles: data }});&#xA;}&#xA;&#xA;app.use('/graphql', bodyParser.json(), apolloExpress((req) =&gt; {&#xA;  return {&#xA;    schema,&#xA;    formatResponse,&#xA;  };&#xA;}));&#xA;&#xA;app.use('/graphiql', graphiqlExpress({&#xA;  endpointURL: '/graphql',&#xA;}));&#xA;&#xA;app.listen(&#xA;  PORT,&#xA;  () =&gt; console.log(`GraphQL Server running at http://localhost:${PORT}`)&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>For ease of reference, these files are available at <a href=""https://gist.github.com/scags9876/d96da7c2dbc98c43f8d735447928480a"" rel=""noreferrer"">this gist</a>.</p>&#xA;&#xA;<p>With this setup, I can send this query:</p>&#xA;&#xA;<pre><code>{&#xA;  articles {&#xA;    id&#xA;    title&#xA;    author {&#xA;      id&#xA;      name&#xA;    }&#xA;  } &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Along with these variables (It seems like this is not the intended use for the variables, but it was the only way I could get the post processing parameters into the formatResponse function.):</p>&#xA;&#xA;<pre><code>{ ""q"": ""author/name=Sam"", ""sort"": ""-id"", ""offset"": 1, ""limit"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>and get this response, filtered to where Sam is the author, sorted by id descending, and getting getting the second page where the page size is 1.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Or these variables:</p>&#xA;&#xA;<pre><code>{ ""sort"": ""-author.name"", ""offset"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>For this response, sorted by author name descending and getting all articles except the first.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      },&#xA;      {&#xA;        ""id"": 2,&#xA;        ""title"": ""Emus"",&#xA;        ""author"": {&#xA;          ""id"": 2,&#xA;          ""name"": ""Pat""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, as you can see, I am using the formatResponse function for post processing to do the filtering/paging/sorting.   .</p>&#xA;&#xA;<p>So, my questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Is this a valid use case?</li>&#xA;<li>Is there a more canonical way to do filtering on deeply nested properties, along with sorting and paging?</li>&#xA;</ol>&#xA;"
41358754,Looking for API Gateway Technology that call multiple microservices,2016-12-28 09:10:08,<amazon-web-services><microservices><aws-api-gateway><gateway><service-discovery>,1,422,1,4.0,6,"<p>In my company, we plan to migrate our back-end solution, which is a huge monolith, to a sexier microservices architecture.</p>&#xA;&#xA;<p>So far, we have benchmarked many technologies, and we will probably use the AWS infrastructure with AWS EC2 Container Services (ECS). Our microservices will be wrapped in Docker containers.</p>&#xA;&#xA;<p>We have already deployed containers and configured the auto-scaling and the load balancing. Everything works great.</p>&#xA;&#xA;<p>However, we are looking for an API Gateway technology that could allow us to call multiple microservices with only one request for the client.</p>&#xA;&#xA;<p>The idea is to develop an architecture that looks like Netflix one: &#xA;<a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""nofollow noreferrer"">http://techblog.netflix.com/2013/01/optimizing-netflix-api.html</a></p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>If the client (a web site) wants to fetch the cart of a client. It will send a Get request to the API.</p>&#xA;&#xA;<p>First, I would like that our gateway call the ""user"" microservice that will return the user's information and the list of the id product that his cart contains:</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [1,2,3]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then, without directly responding to the client, the gateway will call the ""product"" microservice to hydrate the Json with the information about each product.</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [&#xA;         {""id"": 1, ""name"": ""Iphone"", ...},&#xA;         {""id"": 2, ""name"": ""Ipad"", ...},&#xA;         {""id"": 3, ""name"": ""Ipod"", ...}&#xA;    ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, my question is do you know a nice technology that could do the job ?</p>&#xA;"
31573823,Microservice Composition Approaches,2015-07-22 20:55:23,<web-services><architecture><microservices>,4,2048,0,3.0,6,"<p>I have a question for the microservices community. I'll give an example from the educational field but it applies to every microservices architecture.</p>&#xA;&#xA;<p>Let's say I have <strong>student-service</strong> and <strong>licensing-service</strong> with a business requirement that the number of students is limited by a license. So every time a student is created a licensing check has to be made. There are multiple types of licenses so the type of the license would have to be included in the operation.</p>&#xA;&#xA;<p>My question is which approach have you found is better in practice:</p>&#xA;&#xA;<ol>&#xA;<li>Build a composite service that calls the 2 services</li>&#xA;<li>Coupling student-service to licensing-service so that when createStudent is called the student-service makes a call to licensing-service and only when that completes will the student be created</li>&#xA;<li>Use an event-based architecture</li>&#xA;</ol>&#xA;&#xA;<p>People talk about microservice architectures being more like a graph than a hierarchy and <strong>option 1</strong> kinda turns this into a hierarchy where you get increasingly coarse composites. Other downsides is it creates confusion as to what service clients should actually use and there's some duplication going on because the composites API would have to include all of the parameters that are needed to call the downstream services.&#xA;It does have a big benefit because it gives you a natural place to do failure handling, choreography and handle consistency.</p>&#xA;&#xA;<p><strong>Option 2</strong> seems like it has disadvantages too:</p>&#xA;&#xA;<ul>&#xA;<li><p>the API of licensing would have to leak into the student API so that you can specify licensing restrictions. </p></li>&#xA;<li><p>it puts a lot of burden on the student-service because it has to handle consistency across all of the dependent services</p></li>&#xA;<li>as more services need to react when a student is created I could see the dependency graph quickly getting out of control and the service would have to handle that complexity in addition to the one from its own logic for managing students.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Option 3</strong> While being decoupling heaven, I don't really think would work because this is all triggered from an UI and people aren't really used to ""go do something else until this new student shows up"" approach.</p>&#xA;&#xA;<p>Thank you </p>&#xA;"
47918407,Microservice architecture - carry message through services when order doesn't matter,2017-12-21 05:21:21,<design-patterns><architecture><rabbitmq><message-queue><microservices>,2,521,0,3.0,6,"<p><strong>Tl;dr</strong>: ""How can I push a message through a bunch of asynchronous, unordered microservices and know when that message has made it through each of them?""</p>&#xA;&#xA;<p>I'm struggling to find the right messaging system/protocol for a specific microservices architecture. This isn't a ""which is best"" question, but a question about what my options are for a design pattern/protocol.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/MbHRf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/MbHRf.png"" alt=""Diagram""></a></p>&#xA;&#xA;<ul>&#xA;<li>I have a <em>message</em> on the beginning queue. Let's say a RabbitMQ message with serialized JSON</li>&#xA;<li>I need that message to go through an arbitrary number of microservices</li>&#xA;<li>Each of those microservices are long running, must be independent, and may be implemented in a variety of languages</li>&#xA;<li>The order of services the message goes through does not matter. In fact, it should not be synchronous.</li>&#xA;<li>Each service can <em>append</em> data to the original message, but that data is ignored by the other services. There should be <em>no</em> merge conflicts (each service writes a unique key). No service will change or destroy data.</li>&#xA;<li>Once <em>all the services have had their turn</em>, the message should be published to a second RabbitMQ queue with the original data and the new data.</li>&#xA;<li>The microservices will have no other side-effects. If this were all in one monolithic application (and in the same language), functional programming would be perfect.</li>&#xA;</ul>&#xA;&#xA;<p>So, the question is, what is an appropriate way to manage that message through the various services? I <strong>don't</strong> want to have to do one at a time, and the order isn't important. But, if that's the case, how can the system know when all the services have had their whack and the final message can be written onto the ending queue (to have the next batch of services have their go).</p>&#xA;&#xA;<p>The only, semi-elegant solution I could come up with was </p>&#xA;&#xA;<ol>&#xA;<li>to have the first service that encounters a message write that message to common storage (say mongodb)</li>&#xA;<li>Have each service do its thing, mark that it has completed for that message, and then check to see if all the services have had their turn</li>&#xA;<li>If so, that last service would publish the message</li>&#xA;</ol>&#xA;&#xA;<p>But that still requires each service to be aware of all the other services <em>and</em> requires each service to leave its mark. Neither of those is desired.</p>&#xA;&#xA;<p>I am open to a ""Shepherd"" service of some kind.</p>&#xA;&#xA;<p>I would appreciate any options that I have missed, and am willing to concede that their may be a better, fundamental design.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
31047564,How to get a visualization of cross-app Spring Integration flow?,2015-06-25 10:19:06,<java><spring-integration><esb><microservices>,2,892,2,2.0,6,"<p>We have a microservices architecture, i.e. each of the main components of our system is designed to be run as a separate Java app (jar or war).</p>&#xA;&#xA;<p>We use Spring Integration to facilitate communication between the components (over a MQ service).</p>&#xA;&#xA;<p><strong>How can we get a graphical diagram of the whole integration layer of the system, given that each component has its own Spring Integration XML config?</strong></p>&#xA;&#xA;<p>Note that we know how to do it within a single application. The question is how to do it cross-app.</p>&#xA;&#xA;<p>Example: &#xA;Component 1 generates stream of POJOs -> MQ -> Component 2 serializes POJO object graph to JSON -> MQ -> Component 3 saves JSON to DB</p>&#xA;&#xA;<p>Also, if a viable solution would be to create a single Spring Integration config, then how to make sure all components use it?</p>&#xA;"
30173267,Microservice Architecture- cross-domain chattiness,2015-05-11 16:48:08,<architecture><soa><microservices>,3,808,6,3.0,6,"<p>I have a relatively new project that employs a microservice architecture. I feel pretty good about the size and granularity of the individual services, with the exception or our security service.</p>&#xA;&#xA;<p>I have three main services, let's say <code>foo-service</code>, <code>bar-service</code>, and <code>baz-service</code>. These services never need to communicate, but all three services regularly talk via HTTP requests to the <code>security-service</code>. I want this to stop for a variety of reasons- the biggest is that each request to my individual services spawns a request to the security service, which can turn into several extra hops once you account for load balancing, etc. I've been reading ""Software Architecture Patterns"" by Mark Richards, and he recommends in these instances you should share databases and violate DRY: copy the required functionality into each service. Still, he uses this example with smaller ""utility"" classes, which may not really apply in this instance. </p>&#xA;&#xA;<p>The security service isn't that big, so I could definitely copy it into each of the other services. That said, it's just big enough that I don't feel great copying and pasting it - 314 'relevant' lines of code according to coveralls (java so there's a lot more actual code ;-). I could easily turn it into a module that each service brings in- but then my services have a shared dependency and that has bit me in the past. Of course the security code will grow over time as we add authentication methods, but we aren't reinventing the wheel when it comes to auth so It's mostly integrating with other libraries and authentication services. That is, I don't imagine this particular code base getting huge.</p>&#xA;&#xA;<p>So my question, should I copy and paste the code or build a module that every service brings in? Thanks!</p>&#xA;"
34794630,Micro service security,2016-01-14 16:25:39,<c#><microservices>,2,1298,7,2.0,6,"<p>Over the last few days I've been playing with the micro service pattern and all is going well but security seems to baffle me.</p>&#xA;&#xA;<p><strike>&#xA;So If I may ask a question:&#xA;How do I handle user authentication on an individual service? At the moment I pass a request to the <code>Gateway API</code> which in turns connects to the service.&#xA;</strike></p>&#xA;&#xA;<p><strong>Question Edited Please See Below</strong></p>&#xA;&#xA;<p>Bearing in mind that the individual services should not know about each other. The <code>Gateway</code> is the aggregator as such. </p>&#xA;&#xA;<p><strong>Current architecture.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/60tiY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60tiY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>A little code to simulate the request:</p>&#xA;&#xA;<p><strong>Frontend - Client App</strong></p>&#xA;&#xA;<pre><code>public class EntityRepository&lt;T&gt;&#xA;{&#xA;    private IGateway _gateway = null;&#xA;    public EntityRepository(IGateway gateway)&#xA;    {&#xA;        this._gateway = gateway;&#xA;    }&#xA;    public IEnumerable&lt;T&gt; FindAll()&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;IEnumerable&lt;T&gt;&gt;().Result;&#xA;    }&#xA;    public T FindById(int id)&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;T&gt;().Result;&#xA;    }&#xA;    public void Add(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Update(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Save(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;}&#xA;&#xA;&#xA;   //Logic lives elsewhere&#xA;   public HttpResponseMessage Get(Type type)&#xA;   {&#xA;      return Connect().GetAsync(Path(type)).Result;&#xA;   }&#xA;   public HttpResponseMessage Post(Type type, dynamic obj)&#xA;   {&#xA;      return Connect().PostAsync(Path(type), obj);&#xA;   }&#xA;    private string Path(Type type)&#xA;    {&#xA;        var className = type.Name;&#xA;        return ""api/service/"" + Application.Key + ""/"" + className;&#xA;    }&#xA;    private HttpClient Connect()&#xA;    {&#xA;        var client = new HttpClient();&#xA;        client.BaseAddress = new Uri(""X"");&#xA;&#xA;        // Add an Accept header for JSON format.&#xA;         client.DefaultRequestHeaders.Accept.Add(&#xA;         new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;&#xA;        return client;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>I use generics to determine where it needs to fire once it hit's the gateway.&#xA;So if the <code>Type</code> is <strong>Category</strong> it will fire the <strong>Category</strong> service thus calling:</p>&#xA;&#xA;<pre><code>public IEnumerable&lt;dynamic&gt; FindAll(string appKey, string cls)&#xA;{&#xA;    var response = ConnectTo.Service(appKey, cls);&#xA;    return (appKey == Application.Key) ? (response.IsSuccessStatusCode) ? response.Content.ReadAsAsync&lt;IEnumerable&lt;dynamic&gt;&gt;().Result : null : null;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The Gateway does not contain the physical files/Class's of the types.</p>&#xA;&#xA;<p>After a little code, I was hoping someone could give me a little demonstration or the best approach to handle security/user authentication with the current architecture.</p>&#xA;&#xA;<p><strong>Case Scenario 1</strong>&#xA;User hits the web app and logs in, at that point the users encrypted email and password is sent to the <code>Gateway API</code> which is then passed to the <code>User Service</code> and decides whether the user is authenticated - all well and good but now I want to fetch all Messages from the <code>Message Service</code> that the user has received. I cannot really say in the Gateway if the user is authenticated, fetch the messages because that does not solve the issue of calling the <code>Message Service</code> outside of the <code>Gateway API</code></p>&#xA;&#xA;<p>I also cannot add authentication to each individual service because that would require all respective services talking to the <code>User Service</code> and that defeats the purpose of the pattern.</p>&#xA;&#xA;<p><strong>Fixes:</strong>&#xA;Only allow the Gateway to call the Services. Requests to services outside of the Gateway should be blocked.</p>&#xA;&#xA;<p>I know security is a broad topic but within the current context, I'm hoping someone could direct me with the best course of action to resolve the issue.</p>&#xA;&#xA;<p>Currently I have Hardcoded a <code>Guid</code> in all off the applications, which in turn fetches data if the app is equal.</p>&#xA;"
35379246,Django models across multiple projects/microservices. How to?,2016-02-13 11:24:40,<django><microservices>,4,2688,0,1.0,6,"<p>I'm wondering how to solve sharing of the model structure between multiple (separated) django projects/microservices. Eg:</p>&#xA;&#xA;<ol>&#xA;<li>Project: API</li>&#xA;<li>Project: Users dashboard</li>&#xA;<li>Project: Admin dashboard</li>&#xA;<li>Project: Statistics</li>&#xA;</ol>&#xA;&#xA;<p>Each of that projects uses the same django models. Is there a one, proper way to solve that?</p>&#xA;"
41655915,Microservices: Atomic Events,2017-01-14 22:54:45,<database><events><microservices>,2,582,1,3.0,6,"<p>I'm learning about microservice data replication right now, and one thing I'm having trouble with is coming up with the right architecture for ensuring event atomicity.  The way I understand it, the basic flow is:</p>&#xA;&#xA;<ol>&#xA;<li>Commit changes to a database.</li>&#xA;<li>Publish an event detailing the changes on the global message bus.</li>&#xA;</ol>&#xA;&#xA;<p>But what if, for example, a power outage occurred in-between Steps 1 and 2?  In a naively-built system, that would mean the changes persist but the event detailing them will never be published.  I've pondered the following ideas to create better guarantees, but I'm not quite sure of all the pros and cons of each:</p>&#xA;&#xA;<p>A:  Use an embedded database (like SQLite) in my microservice instance to track the full transaction, from the commit to the main database to the event publishing.</p>&#xA;&#xA;<p>B:  Create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  The service would then push the Event to the bus, and then make another commit to the main database to mark the Event as Published.</p>&#xA;&#xA;<p>C:  As above, create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  Then, notify (either manually via REST/Messages from within the service or via database hooks) a dedicated EventPusher service that a new event has been appended.  The EventPusher service will query the Events table and push the events to the bus, marking each one as Published upon acknowledgement.  Should a certain amount of time pass without any notification, the EventPusher will do a manual query.</p>&#xA;&#xA;<p>What are the pros and cons of each of the choices above?  Is there another superior option I have yet to consider?</p>&#xA;"
42140285,How to implement a microservice Event Driven architecture with Spring Cloud Stream Kafka and Database per service,2017-02-09 15:12:27,<apache-kafka><spring-cloud><microservices><spring-cloud-stream><spring-kafka>,2,2318,0,5.0,6,"<p>I am trying to implement an event driven architecture to handle distributed transactions. Each service has its own database and uses Kafka to send messages to inform other microservices about the operations.</p>&#xA;&#xA;<p>An example:</p>&#xA;&#xA;<pre><code> Order service -------&gt; | Kafka |-------&gt;Payment Service&#xA;       |                                       |&#xA;Orders MariaDB DB                   Payment MariaDB Database&#xA;</code></pre>&#xA;&#xA;<p>Order receives an order request. It has to store the new Order in its DB and publish a message so that Payment Service realizes it has to charge for the item:</p>&#xA;&#xA;<p>private OrderBusiness orderBusiness;    </p>&#xA;&#xA;<pre><code>@PostMapping&#xA;public Order createOrder(@RequestBody Order order){&#xA;    logger.debug(""createOrder()"");&#xA;    //a.- Save the order in the DB&#xA;    orderBusiness.createOrder(order);&#xA;    //b. Publish in the topic so that Payment Service charges for the item.&#xA;    try{&#xA;        orderSource.output().send(MessageBuilder.withPayload(order).build());&#xA;    }catch(Exception e){&#xA;        logger.error(""{}"", e);&#xA;    }&#xA;    return order;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>These are my doubts:</p>&#xA;&#xA;<ol>&#xA;<li>Steps a.- (save in Order DB) and b.- (publish the message) should be performed in a transaction, atomically. How can I achieve that?</li>&#xA;<li>This is related to the previous one: I send the message with: orderSource.output().send(MessageBuilder.withPayload(order).build()); This operations is asynchronous and ALWAYS returns true, no matter if the Kafka broker is down. How can I know that the message has reached the Kafka broker?</li>&#xA;</ol>&#xA;"
39920488,What is the role of falcor in a microservice architecture?,2016-10-07 15:09:11,<microservices><falcor>,2,1336,0,4.0,6,"<p>Say we have following taxi-hailing application that is composed of loosely coupled microservices:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QgctP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QgctP.png"" alt=""https://www.nginx.com/blog/introduction-to-microservices/""></a></p>&#xA;&#xA;<p><em>The example is taken from <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/introduction-to-microservices/</a></em></p>&#xA;&#xA;<p>Each services has its own rest api and all services are combined in a single api gateway. The client does not talk to a single service but to the gateway. The gateway requests information from several services and combines them to a single response. For the client it looks like it is talking to a monolithic application.</p>&#xA;&#xA;<p><strong>I am trying to understand: where could we incorporate falcor into this application?</strong></p>&#xA;&#xA;<p><strong>One Model Everywhere</strong> from <a href=""http://netflix.github.io/falcor/"" rel=""nofollow noreferrer"">http://netflix.github.io/falcor/</a> </p>&#xA;&#xA;<blockquote>&#xA;  <p>Falcor lets you represent all your remote data sources as a single&#xA;  domain model via a virtual JSON graph. You code the same way no matter&#xA;  where the data is, whether in memory on the client or over the network&#xA;  on the server.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this taxi-hailing application each microservice represents a single domain model already. Can you think of any benefit we could thrive by wrapping each microservice with falcor? I cannot.</p>&#xA;&#xA;<p>However I think it is very convenient to incorporate falcor into the api gateway because we can abstract away the different domain models created by the microservices into one single or at least a few models.</p>&#xA;&#xA;<p>What is your opinion?</p>&#xA;"
38863827,How to handle REST API paths when related resources belong to different microservices?,2016-08-10 03:39:49,<rest><microservices>,2,309,0,1.0,6,"<p>I have two microservices:</p>&#xA;&#xA;<ul>&#xA;<li>UserService, which defines paths such as /users, /users/:id;</li>&#xA;<li>MessageService, which defines paths such as /messages, /messages/:id.</li>&#xA;</ul>&#xA;&#xA;<p>Also, each message in MessageService has an attribute user_id which references a user in UserService.</p>&#xA;&#xA;<p>Now, lets say I want to list all messages of a given user. Right now I can think of the following approaches:</p>&#xA;&#xA;<ol>&#xA;<li>A path such as <strong>/users/:id/messages</strong> seems like the best approach if I want to follow the best REST API practices. However, it seems to me that I couldn't define such path inside MessageService because I would be tight-coupling it to UserService. I believe paths starting with /users should belong to UserService only.</li>&#xA;<li><strong>/messages?user_id=:id</strong> so I could use the existing /messages path and add a filter by attribute (user_id). Not sure if a good practice.</li>&#xA;<li>Put an API gateway in front of the microservices and create a proxy from <strong>/users/:id/messages</strong> to <strong>/messages?user_id=:id</strong>. This allows clients to use the most REST-friendly path while keeping the microservices loosely coupled.</li>&#xA;</ol>&#xA;&#xA;<p>Which of these approaches would be the most appropriate?</p>&#xA;"
38565470,Can Service Fabric Cluster Maintains the old versions of a service?,2016-07-25 10:35:16,<azure><microservices><azure-service-fabric>,1,327,1,0.0,6,"<p>I have a Micro Service in service fabric cluster which is a V1 for example. Now I upgraded it to the new version lets say v2. After a successful upgrade, Service Fabric replaced the old version with the new version of micro service. But I want to have and communicate with both versions of services. Can I achieve this in Service Fabric? If yes can anyone help me out on this?</p>&#xA;&#xA;<p>-Kishore.</p>&#xA;"
44610425,Good practices to propagate errors through micro services,2017-06-17 23:41:37,<rest><api><http><microservices><restful-architecture>,2,445,3,0.0,6,"<p>We have a micro services architecture and we are having some discussions about how to expose internal errors to the client.</p>&#xA;&#xA;<p>Here's an example:</p>&#xA;&#xA;<p>Let's suppose we have 3 services, service A, B and C.&#xA;When the client sends a request to the service A, which is public, this service sends a request to service B that sends a request to service C (which are internal and needs authentication, but the credentials are stored internally like environment variables, they are not send by the client).</p>&#xA;&#xA;<p>And for some reason the communication between B and C receives a 401 (could be 422, 403 or any client related errors), which means that the request was not authorized.</p>&#xA;&#xA;<p>Something like that:<a href=""https://i.stack.imgur.com/NmQB7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NmQB7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The communication between B and C is internal, the user don't know about these services. Should I expose our internal structure sending a 401 to the client? Given it's not the client's fault? Should I send a 500?</p>&#xA;"
44043159,How do I include end-to-end tests across microservices into multiple continuous delivery pipelines?,2017-05-18 08:59:34,<automated-tests><microservices><end-to-end><continuous-delivery><ase>,1,259,1,1.0,6,"<p>My team develops three microservices. The three work together to provide a business scenario. They communicate with REST and RabbitMQ. Looks like in <a href=""https://martinfowler.com/articles/microservice-testing/#testing-end-to-end-diagram"" rel=""noreferrer"">Toby Clemson's presentation on Microservice Testing</a>.</p>&#xA;&#xA;<p>Each microservice has its own continuous delivery pipeline. They are <em>delivery</em>, not <em>deployment</em> pipelines, meaning there is a manual release decision at the end.</p>&#xA;&#xA;<p><strong>How do I include an end-to-end test for the <em>business scenario</em>, i.e. across all microservices, into the delivery pipelines?</strong></p>&#xA;&#xA;<p>My team suggested this:</p>&#xA;&#xA;<p>We add one <em>shared</em> end-to-end stage that deploys all three microservices and runs the end-to-end test on them. Each time one of the pipelines reaches this stage, it deploys and tests. A semaphore ensures the pipelines pass the stage one after the other. Failure stops all three pipelines.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ODu29.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ODu29.png"" alt=""Shared end-to-end stage""></a></p>&#xA;&#xA;<p>To me, this seems to sacrifice all the independence the microservice architecture wins in the first place:</p>&#xA;&#xA;<ul>&#xA;<li><p>The end-to-end stage is a bottleneck. A fast pipeline could thwart slow pipelines because it reserves the end-to-end stage more often, making the others wait before they may run their tests.</p></li>&#xA;<li><p>Failure in one pipeline would stop the other pipelines from delivering, also disabling them from shipping urgent bug fixes.</p></li>&#xA;<li><p>The solution doesn't adapt to new business scenarios that need different combinations of microservices. We would either end up with a super-stage that wires all microservices, or each business scenario would require its own, new end-to-end stage.</p></li>&#xA;<li><p>The end-to-end stage shows only a narrow result because it confirms only that one exact combination of microservice versions work together. If production contains different versions, it does not guarantee this will work as well.</p></li>&#xA;<li><p>The stage is also in conflict with the manual release decision at the end: What if a build passed end-to-end but we decide to not release it to production? Production would then contain a different version of that microservice than end-to-end, causing warped results.</p></li>&#xA;</ul>&#xA;&#xA;<p><strong>So what's a better way to do this?</strong></p>&#xA;"
44065208,Data integrity across the databases of different Microservices,2017-05-19 08:37:06,<database><foreign-keys><relational-database><rdbms><microservices>,1,801,4,0.0,6,"<p>Let's say I am using relational databases for my microservices. I have <code>CustomersMService</code> which has its own database with table <code>Customer</code>, then I have <code>OrdersMService</code> which also has its own database but with table <code>Order</code> and that table has column <code>CustomerId</code>. My question is how can I ensure data integrity between databases, that <code>Orders</code> table won't point to non-existent Customers?</p>&#xA;"
35882330,how to get my configuration values in yml - using dropwizard (microservice) Jersey D.I @Injection?,2016-03-09 03:26:41,<java><jersey><dropwizard><inject><microservices>,1,4347,0,2.0,6,"<p>here's my code snippets.</p>&#xA;&#xA;<p>here's my yml file:</p>&#xA;&#xA;<pre><code>productionServer:&#xA;  host: production-server.amazonaws.com&#xA;  publicIp: xx.xx.xx.xx&#xA;  privateIp: xx.xx.xx.xx&#xA;  userName: xx.xx.xx.xx&#xA;  password: xx.xx.xx.xx&#xA;  remoteFilePath: fake/path/&#xA;  fileName: test.txt&#xA;  privateKey: private-public-key.ppk&#xA;&#xA;server:&#xA;  applicationConnectors:&#xA;    - type: http&#xA;      port: 8080&#xA;    - type: https&#xA;      port: 8443&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;  adminConnectors:&#xA;    - type: http&#xA;      port: 8081&#xA;    - type: https&#xA;      port: 8444&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;</code></pre>&#xA;&#xA;<p>MyConfiguration class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Configuration;&#xA;&#xA;public class MyConfiguration extends Configuration{&#xA;&#xA;    @NotNull&#xA;    @JsonProperty&#xA;    private ProductionServer productionServer;&#xA;&#xA;    // getters&#xA;&#xA;public class ProdctionServer{&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private host;&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private publicIp;&#xA;&#xA;      // getters&#xA;</code></pre>&#xA;&#xA;<p>Application class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Application;&#xA;&#xA;public class MyApplication extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    public static void main(String[] args) throws Exception{&#xA;        new MysApplication().run(args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public String getName(){ return ""micro-service""; }&#xA;&#xA;    @Override&#xA;    public void initialize(Bootstrap&lt;MyConfiguration&gt; bootstrap){}&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration conf, Environment environment ){&#xA;        final MyResource myResource = new MyResource();&#xA;        // health check&#xA;&#xA;        // environment.healthChecks().register(""template"",healthCheck);&#xA;&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println( ""==&gt; "" + conf.getProductionServer() );&#xA;&#xA;        // register&#xA;        environment.jersey().register( MyResource );&#xA;</code></pre>&#xA;&#xA;<p>and when running this app:</p>&#xA;&#xA;<p>i received a logged as follows:</p>&#xA;&#xA;<pre><code>==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@623e088f, io.dropwizard.jetty.HttpsConnectorFactory@39fcbef6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34f22f9d, io.dropwizard.jetty.HttpsConnectorFactory@77d67cf3], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@663411de]}}&#xA;==&gt; com.mycompany.myproject.model.ProductionServer@5b04476e&#xA;</code></pre>&#xA;&#xA;<p>meaning it is successfully gets the value of my yaml.&#xA;but my problem is during the D.I or dependency injection of MyConfiguration class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service. </p>&#xA;&#xA;<p>here's my code snippet of dependency binding the MyService.class and the MyConfiguration.class </p>&#xA;&#xA;<p>DependencyBinder.class</p>&#xA;&#xA;<p>import org.glassfish.hk2.utilities.binding.AbstractBinder;</p>&#xA;&#xA;<p>public class DependencyBinder extends AbstractBinder {</p>&#xA;&#xA;<pre><code>@Override&#xA;protected void configure() {&#xA;    bind(MyConfiguration.class).to(MyConfiguration.class);&#xA;    bind(MyService.class).to(MyService.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>public class MyService {&#xA;&#xA;    @Inject&#xA;    MyConfiguration conf;&#xA;&#xA;    public void invoke(){&#xA;        System.out.println( ""=============================== "" );&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println(""==&gt; "" + conf.getProductionServer() );&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>and during the invoking of the method invoke()...&#xA;i got a logged as follows:</p>&#xA;&#xA;<pre><code>=============================== &#xA;==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34e82c4d], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@19b70fbd], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@543f81c9]}}&#xA;==&gt; null&#xA;</code></pre>&#xA;&#xA;<p>now my problem is during the D.I or dependency injection of MyConfiguration class in MyService.class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service.&#xA;please give me some resolution? thnx.</p>&#xA;"
40938088,Microservices in practice,2016-12-02 17:44:43,<spring><docker><cloud><microservices><docker-swarm>,1,387,1,1.0,6,"<p>I have studied concept of microservices for a good while now, and understand what they are are and why they are necessary.</p>&#xA;&#xA;<p><strong>Quick refresher</strong></p>&#xA;&#xA;<p>In a nutshell, monolith application is decomposed into independent deployable units, each of which typically exposes it's own web API and has it's own database. Each service fulfills a single responsibility and does it well. These services communicates over synchronous web services such as REST or SOAP, or using asynchronous messaging such as JMS to fulfill some request in synergy. Our monolith application has became a distributed system. Typically all these fine grained APIs are made available through an API gateway or proxy, which acts as an single-point-of-entry facade, performing security and monitoring related tasks.</p>&#xA;&#xA;<p>Main reasons to adapt microservices is high availability, zero downtime update and high performance achieved via horizontal scaling of a particular service, and looser coupling in the system, meaning easier maintenance. Also, IDE functionality, build and deployment process will be significantly faster, and it's easier to change framework or even the language.</p>&#xA;&#xA;<p>Microservices goes hand in hand with clustering and containerization technologies, such as Docker. Each microservice could be packed as a docker container to run it in any platform. Principal concepts of clustering are <em>service discovery</em>, <em>replication</em>, <em>load balancing</em> and <em>fault tolerance</em>. Docker Swarm is a clustering tool which orchestrates these containerized services, glues them together, and handles all those tasks under the hood in a declarative manner, maintaining the desired state of the cluster.</p>&#xA;&#xA;<p>Sounds easy and simple in theory, but I still don't understand how to implement this in practice, even I know Docker Swarm pretty well. Let's view an concrete example.</p>&#xA;&#xA;<p><strong>Here is the question</strong></p>&#xA;&#xA;<p>I'm building a simplistic java application with <em>Spring Boot</em>, backed by <em>MySQL</em> database. I want to build a system, where user gets a webpage from <em>Service A</em> and submits a form. <em>Service A</em> will do some manipulation to data and sends it to <em>Service B</em>, which will further manipulate data, write to database, return something and in the end some response is sent back to user.</p>&#xA;&#xA;<p>Now the problem is, <em>Service A</em> doesn't know where to find <em>Service B</em>, nor <em>Service B</em> know where to find <em>database</em> (because they could be deployed at any node in the cluster), so I don't know how I should configure the Spring boot application. First thing to come in my mind is to use DNS, but I can't find tutorials how to setup such a system in docker swarm. What is the correct way to configure connection parameters in Spring for distributed cloud deployment? I have researched about Spring Cloud project, but don't understand if it's the key for this dilemma.</p>&#xA;&#xA;<p>I'm also confused how databases should be deployed. Should they live in the cluster, deployed alongside with the service (possibly with aid of docker compose), or is it better to manage them in more traditional way with fixed IP's?</p>&#xA;&#xA;<p>Last question is about load balancing. I'm confused if there should be multiple load balancers for each service, or just a single master load balancer. Should the load balancer has a static IP mapped to a domain name, and all user requests target this load balancer? What if load balancer fails, doesn't it make all the effort to scale the services pointless? Is it even necessary to setup a load balancer with Docker Swarm, as it has it's own routing mesh? Which node end user should target then?</p>&#xA;"
40856925,Microservices: database and microservice instances,2016-11-29 02:42:17,<microservices><instances><horizontal-scaling>,3,873,3,1.0,6,"<p>Lets say we have a microservice A and a B. B has its own database. However B has to be horizontally scaled, thus we end up having 3 instances of B. What happens to the database? Does it scale accordingly, does it stays the same (centralized) database for the 3 B instances, does it become a distributed database, what happens?</p>&#xA;"
34442192,Api gateway or No Api Gateway,2015-12-23 19:09:44,<microservices>,1,1401,1,0.0,6,"<p>I am developing an application based on the <code>microservice architecture</code>. Here, each <code>service</code> is an independently deployable <code>play-scala application</code> exposing <code>rest apis</code>. I want to implement an <code>Api gateway</code> on top of these services for mapping incoming requests.I am following the architecture discussed here :<a href=""http://%20https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""nofollow noreferrer"">Building Microservices</a></p>&#xA;&#xA;<p>There are very few projects with substantial maturity that are based on the microservice architecture. One of them is <a href=""https://github.com/theiterators/reactive-microservices#master"" rel=""nofollow noreferrer"">Reactive Microservices</a>.But this project is not using the <code>api gateway pattern</code> and seems to be following the <a href=""http://www.infoq.com/articles/seven-uservices-antipatterns"" rel=""nofollow noreferrer"">Anti Pattern</a> There is an <a href=""https://github.com/theiterators/reactive-microservices/issues/10"" rel=""nofollow noreferrer"">issue</a> opened for this project regarding the missing Api Gateway here .The contributors here claim that they did not follow the <code>api gateway pattern</code> because it has the risk of <code>single-point of failure</code>. </p>&#xA;&#xA;<p>This varying opinion is very confusing to me. So,I am looking for the suggestions on whether I should be using Api Gateway or not. <code>What is the right practice here ?</code> </p>&#xA;"
43290480,Using celery to build microservices,2017-04-08 05:19:33,<python-2.7><celery><microservices><celerybeat>,1,1023,0,3.0,6,"<p>I am going break down a project into small microservices.</p>&#xA;&#xA;<p>All microservices are cron-based. I am thinking of celery as a task distribution as well a mechanism to run periodic tasks (celerybeat).</p>&#xA;&#xA;<p>I don't want to build multiple celery app per microserverice as that will increase overhead of having multiple brokers and multiple flower system to use for monitoring.</p>&#xA;&#xA;<p>I tried with single app on multiple servers but I failed. My needs with celery are :</p>&#xA;&#xA;<ol>&#xA;<li>I need to have independent servers for each microservice </li>&#xA;<li>Task belonging to certain microservice should execute only on their servers; no sharing of task among other servers</li>&#xA;<li>In case microservice is down i don't want celerybeat to clog the broker with thousands of pending tasks, resulting in halting service at other microservices. </li>&#xA;<li>In do not have any need of communication between microservices.</li>&#xA;</ol>&#xA;&#xA;<p>I tried separating queues per worker which doesn't seem to be possible&#xA;I tried one worker per server but i need more than one worker on per microservices</p>&#xA;"
43179951,Business data querying/reporting in service oriented architecture,2017-04-03 08:33:41,<database><reporting><soa><microservices><database-replication>,2,254,7,1.0,6,"<p>For the better part of the last year my company has been slicing up a monolith and building new products upon principles of (micro) service architecture. This is all fine and gives us great flexibility in keeping UI and backend logic separate and lowering the amount of dependencies.</p>&#xA;&#xA;<p>BUT!</p>&#xA;&#xA;<p>There is an important part of our business that has a growing headache as a result of this, namely reporting.</p>&#xA;&#xA;<p>Since we make sure that there is no data replication (and business logic sharing) between services, then each service knows its own data and if another service really needs to keep a reference for that data, they do it through ID's (entity linking, essentially). And while otherwise its great, it's not great for reporting.</p>&#xA;&#xA;<p>Our business often needs to create ad-hoc reports about specific instances happening with our customers. In the 'old days' you made a simple SQL query that joined a couple of database tables and queried whatever you needed, but it is not possible with decoupled services. And this is a problem as business sees it.</p>&#xA;&#xA;<p>I am personally not a fan of data replication for reporting purposes in the back end, as that may have another tendency to grow into a nightmare (which it already is even in our legacy monoliths). So this problem is really not about legacy monoliths versus modern microservices, but about data dependencies in general.</p>&#xA;&#xA;<p>Have you faced issues like this and if yes, then how did you solve it?</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>We have been discussing in-house the few potential solutions how to solve this, but none of them are actually good and I've not gotten the answer I am looking for yet that solves the issues in large scale.</p>&#xA;&#xA;<ol>&#xA;<li><p>Good old replicate-everything-and-let-BI-people-figure-it-out is what is still used to this day. From the old monolith times the BI/data-warehouse team made duplicates of all databases, but same practice is more inconvenient, but still done to this day for all microservices that use a database. This is not good for various reasons and comes with the shared sandbox cancer you can expect.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that are meant for fetching out specific reports. Each of them connect to set microservices that carries the relevant data and builds the report as expected. This introduces tighter coupling however and can be incredibly complicated and slow with large datasets.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that each have databases replicated from other databases in background. This is problematic as team databases are being coupled and data is directly replicated and there is a strong dependency on technology of databases that is being used.</p></li>&#xA;<li><p>Have each service send out an event to RabbitMQ that BI services would pick up on and then fetch additional data, if needed. It sounds by far the best for me, but by far the most complex to implement as all services need to start publishing relevant data. It is what I would personally choose at present time, from a very abstract level, that is.</p></li>&#xA;</ol>&#xA;"
41161769,Authorisation in microservices - how to approach domain object or entity level access control using ACL?,2016-12-15 10:22:31,<spring><security><authorization><acl><microservices>,1,948,2,1.0,6,"<p>I am currently building microservices based system on java Spring Cloud. Some microservices use PostgreSQL and some of them MongoDB. REST and JMS is used for communication. The plan is to use SSO and OAuth2 for authentication</p>&#xA;&#xA;<p>The challenge I am facing is that authorisation have to be done on domain object/entity level. It means some kind of ACL (Access Control List) is needed. The best practice for this kind of architecture is to avoid something like this and have coarse grained security probably on application/service layer level in every microservice but unfortunately it is not possible.</p>&#xA;&#xA;<p>My final idea is to use Spring Security ACL and have the ACL tables in shared database between all microservices. The database would be accessed only by Spring infrastructure or through Spring api. The DB schema looks stable and unlikely will change. In this case I would simply break the rule about sharing db between microservices.</p>&#xA;&#xA;<p>I was considering different kinds of distributed solutions but left them: </p>&#xA;&#xA;<ul>&#xA;<li>One microservice with ACL and accessing it using rest - The problem is too many http calls and performance degradation. I would have to extend Spring Security ACL to replace db access by rest calls</li>&#xA;<li>ACL in every microservice for its own entities - Sounds quite reasonable but imagine a case having some read models of entities synchronised to some other microservices or same entity that exists in different bounded contexts (different microservices). ACLs can become really unmanageable and can be source of errors.</li>&#xA;<li>One microservice with ACL tables that are synchronised to other microservices as a read model. The problem is that there is no support in Spring Security ACL for MongoDB. I have seen some custom solutions on github and yes it is doable. But...when creating a new entity I have to create record in the microservice  that owns ACL and then it is asynchronously synchronised as a read model to microservice owning the entity. It does not sound as a easy solution</li>&#xA;<li>Choose some URL based access control on API gateway. But I would have to modify Spring Security ACL somehow. The API gateway would have to know too much about other services. Granularity of access control is bound to REST api granularity. Maybe I can not imagine all the consequences and other problems that would this approach bring</li>&#xA;<li>Finally the solution with shared db that I mentioned is my favorite. Actually it was the first one I have disqualified because it is “shared” database. But after going through possibilities it seemed to me that this is the only one that would work. There is some more additional complexity in case I would like to use some kind of caching because distributed cache would be needed.</li>&#xA;</ul>&#xA;&#xA;<p>I would really use some advice and opinions how to approach the architecture because this is really tricky and a lot of things can go wrong here.</p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>Lukas</p>&#xA;"
42484087,Microservice: Service discovery and Service Registry with Akka,2017-02-27 11:01:10,<akka><microservices>,1,535,2,2.0,6,<p>I'm going to apply Microservices architecture for my application. The internal communication between microservices will be achieved by using Akka. But I don't know how to make all microservices aware and register each other. I have some options to design Service Registry and Discovery:</p>&#xA;&#xA;<p>1) Use Zookeeper as a centrailized service to hold all metadata of all microservices (nodes) and let them access these metadata to communicate. The metadata of each node contains Akka path (address) information to let the other nodes communicate to.</p>&#xA;&#xA;<p>2) Join all microservices (Akka Nodes) to an Akka Cluster and each node will keep reference of each other to communicate. Akka Cluster supports gossip protocol and it will let all nodes in cluster aware together.</p>&#xA;&#xA;<p>Can anybody give me some advices about this? How to design Service Discovery and Service Registry efficiently on top of Akka? Are there any options for this?</p>&#xA;
37830008,Handling multiple event dependency in event-driven architecture,2016-06-15 08:28:15,<publish-subscribe><microservices><event-driven>,2,348,0,2.0,6,<p>What would be best practice if you have an event-driven architecture and a service subscribing to events has to wait for multiple event (of the same kind) before proceeding with creating the next event in the chain?</p>&#xA;&#xA;<p>An example would be a book order handling service that has to wait for each book in the order to have been handled by the warehouse before creating the event that the order has been picked so that the shipping service (or something similar) picks up the order and starts preparing for shipping.</p>&#xA;
45453061,What is the difference between microservices and webservices?,2017-08-02 06:29:44,<web-services><microservices>,3,3866,1,1.0,6,"<p>The closest I got to finding the actual difference is this <a href=""http://www.tatvasoft.com/blog/the-difference-between-micro-services-and-web-services/"" rel=""nofollow noreferrer"">article</a>.</p>&#xA;&#xA;<p>But I didn't understand what would make me choose one over the other and if microservices can also use a REST API and communicate via http.</p>&#xA;&#xA;<p>I mainly didn't understand what a microservice is and if it can come instead of a webservice, other than the purpose of </p>&#xA;&#xA;<blockquote>&#xA;  <p>breaking large software applications into loosely coupled modules</p>&#xA;</blockquote>&#xA;"
45510905,Authentication to access Spring boot Zuul Service routes,2017-08-04 15:47:31,<spring-mvc><spring-boot><microservices><netflix-eureka><netflix-zuul>,1,938,3,2.0,6,"<p>I have configured my micro services using Spring boot zuul and eureka services. &#xA;Now I need to authenticate all routes/REST API calls.&#xA;I mean, for all APIs client send one accessToken. &#xA;On zuul service, before routing to the particular service, I have to call a micro service (auth-service) with accessToken and that auth-service will check the user exists or not for the accessToken sent.&#xA;If the accessToken is valid then only routing should happen.</p>&#xA;&#xA;<p>Please help me to implement this using spring boot service.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
40660618,AWS API Gateway + Elastic Beanstalk and Microservices,2016-11-17 16:49:51,<amazon-web-services><elastic-beanstalk><microservices><aws-api-gateway>,1,4604,1,3.0,6,"<p>I'm going to build microservices' architecture on AWS and I want to ask you to clarify my doubts.</p>&#xA;&#xA;<p><strong>My current general concept</strong></p>&#xA;&#xA;<p>I would like to use API Gateway, which exposes microsevices' APIs running in Elastic Beanstalk. I would like to place the Elastic Beanstalk in VPC without direct access from Internet to its instances.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6BQi4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6BQi4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Questions &amp; Doubts:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Elastic Beanstalk gets subdomain on application creation. This subdomain should be used by API Gateway with integration type: AWS service, in action configuration - Am I right?</li>&#xA;<li>What would represent a single microservice? An Elastic Beanstalk's application is a specific scalable microservice?</li>&#xA;<li>How the microservices should communicate with each other? There would be some task where Im going to use SQS (Simple Queue Service). But in other cases, is it better when two microservices communicates with each other through API Gateway rather than directly - am I right?</li>&#xA;<li>Test environment: What structure should I use in test environment (or staging env.)? I think about creating separate VPC with another Elastic Beanstalk and other Amazon services.</li>&#xA;<li>Test environment and API Gateway: How should I set up an API Gateway? It should allow clients to access the microservices in test environment if request has specific subdomain, like: test.mydomain.com/hello_world/say_hello. I'm not sure how to use API Gateway in CI/CD to make it fast and simple, without manual copying some configuration from test stage to the production stage. (I'm not expecting any complex solution, only some hints about what components, parts, concepts could I use for it. More details I'll find on my own).</li>&#xA;<li>Have you any experience in deploying apps to Elastic Beanstalk using Codep Deploy and/or Jenkins? I'm interesting in which way could be better: Jenkins, AWS Code Deploy or Jenkins+CodeDeploy.</li>&#xA;</ol>&#xA;"
30621628,BDD and microservices,2015-06-03 13:31:54,<c#><bdd><distributed><specflow><microservices>,3,686,2,2.0,7,"<p>Our solution relies on microservices. On the other hand, our CIO expects us to practice Behavior Driven Development on every new feature. </p>&#xA;&#xA;<p>Is it possible to manage BDD in a microservices architecture ? Based on your experience, is it a good practice to adopt BDD against such an architecture, or do you think we should directly look at integration testing ?</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>More precisely, in my opinion, BDD Tests are expected to verify the business logic, and only the business logic. In many frameworks, BDD Tests scenarios are created by the skateholders, with a DSL. BDD Tests tend to converge to exclusive ""Infrastructure Ignorant"" practices. On the other hand, Integration Tests are supposed to verify that the solution matches the target infrastructure (they are done by DevOps ?), and only the infrastructure. When business functions are ""distributed"" over microservices, you should mock almost everything (infra and business) in your BDD Tests environment (it should be the local environment) and mocking business weakens a lot your goals. Do you think these practices are compatible ?</p>&#xA;"
30908112,Micro Service cross service dependencies,2015-06-18 06:36:30,<architecture><microservices>,3,3388,1,2.0,7,"<p>Just to simplify my situation I currently have 3 micro services.</p>&#xA;&#xA;<ol>&#xA;<li>Authentication</li>&#xA;<li>Locations</li>&#xA;<li>Inventory</li>&#xA;</ol>&#xA;&#xA;<p>The authentication service authenticates the user and sends back a JWT access token and I use that across the other services. Its stateless and all works well.</p>&#xA;&#xA;<p>I setup locations among some other things in the location service and this works well and as expected.</p>&#xA;&#xA;<p>But now I am at the inventory service and I need to add some inventory but it is linked to a location. I can easily pass the locationId in the API call but I have no way of authorizing the current user to add something to that location unless I then call the location service to validate this.</p>&#xA;&#xA;<p>This then creates service dependencies between each other and it is something I am trying to avoid at all costs otherwise you just lose most of the benefits of micro services.</p>&#xA;&#xA;<p>What would be the recommended approach to validate that the current user has permissions for that location? The only thing I have thought of so far is either</p>&#xA;&#xA;<ol>&#xA;<li>Getting the location API to issue out another access token with additional claims of what locations they have access to.</li>&#xA;<li>Or issuing out another completely separate token of some kind and passing that via the header to the inventory micro service to do a validation similar to how the JWT is authenticated.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>As mentioned below on providing aggregate roots (or I am assuming that means the same as API gateways) it would provide the 3rd option of another service on top to communicate to both to provide the information.</p>&#xA;&#xA;<p>However it then leaves a 3rd service dependent upon 2 others, so I just increased my service dependencies.</p>&#xA;"
33165216,Micro Service with API Gateway,2015-10-16 07:51:50,<c#><api><gateway><microservices>,2,8252,1,5.0,7,"<p>For my new project, I have to use <strong>Micro Services with Api Gateway</strong>. So I gathered detailed informations about Micro Service but the Api Gateway part is not clear.</p>&#xA;&#xA;<p>My question is,</p>&#xA;&#xA;<ol>&#xA;<li>Is anyone know about how the request routing part is done in Api&#xA;Gateway?</li>&#xA;<li>Is that can be done by simple if condition[<strong><em>pseudo code:</em></strong>&#xA;if(keyword==""product"") then route(""product service"")]?</li>&#xA;<li>Or Is that any better way to do it?</li>&#xA;</ol>&#xA;&#xA;<p>I am using C#.Net to develop Api.<br>&#xA;I got some info about Api Gateway from <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">https://www.nginx.com/blog/building-microservices-using-an-api-gateway/</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jVOVq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/jVOVq.png"" alt=""Api Gateway""></a></p>&#xA;"
32715464,How to forward all requests to specific version (of same service) during deployment using netflix?,2015-09-22 11:17:13,<spring-cloud><microservices><netflix><netflix-eureka><netflix-zuul>,1,918,1,1.0,7,"<p>I have 4 instance of the same service running on different hosts. I am deploying new version for that service node by node. While deployment, incoming requests get forwarded according to the load balancer to any version (host). Is there any way in netflix where I can forward all incoming requests to a specific version?</p>&#xA;&#xA;<p>Is there any generic way where we can define version (for same serviceId). And if incoming requests has version defined in header, we can use that to forward the requests to specific version.</p>&#xA;&#xA;<p>Could be something like:</p>&#xA;&#xA;<p>In Zuul Proxy,</p>&#xA;&#xA;<pre><code>zuul:&#xA;  routes:&#xA;    sample:&#xA;      path: /sample/{version}/**&#xA;      serviceId: sample-service&#xA;</code></pre>&#xA;&#xA;<p>In sample-service,</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    appname: sample-service&#xA;    metadataMap:&#xA;      version: v1&#xA;</code></pre>&#xA;&#xA;<p>or any other mechanism to achieve versioning of same service?</p>&#xA;"
36957369,Fabric Message is too large,2016-04-30 16:28:29,<c#><azure><microservices><azure-service-fabric>,2,1577,0,0.0,7,"<p>I'm trying to pass 5MB~ data from a service to an actor, and I'm getting the error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Fabric Message is too large</p>&#xA;</blockquote>&#xA;&#xA;<p>How can I increase the maximum size that can be transferred between micro-services?</p>&#xA;&#xA;<p>I looked at the following <a href=""https://github.com/Azure/azure-content/blob/master/articles/service-fabric/service-fabric-reliable-actors-reliabledictionarystateprovider-configuration.md"" rel=""noreferrer"">page</a> to see my options.</p>&#xA;&#xA;<p>I tried setting:</p>&#xA;&#xA;<pre><code>&lt;Section Name=""ServiceReplicatorConfig""&gt;&#xA;    ...&#xA;    &lt;Parameter Name=""MaxReplicationMessageSize"" Value=""1073741824"" /&gt;&#xA;&lt;/Section&gt;&#xA;</code></pre>&#xA;&#xA;<p>Please help.</p>&#xA;"
40205675,Microservices Authentication best practices and security (OAuth 2.0 and OpenIdConnect),2016-10-23 17:19:04,<security><oauth><oauth-2.0><microservices><openid-connect>,2,1694,2,3.0,7,"<p>There are several ways to build authentication in micro-services. However very popular is using JWT tokens and OAuth protocol together with OpenID Connect identity layer.</p>&#xA;&#xA;<p>In <a href=""http://nordicapis.com/api-security-oauth-openid-connect-depth/"" rel=""nofollow"">this tutorial</a> explaining how it can be achieved there is one tip:  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Pass by reference when tokens have to leave your network, and then convert them to by-value tokens as they enters your space. Do this conversion in your API gateway.</p>&#xA;</blockquote>&#xA;&#xA;<p>However it's not clear to me what's reason behind it. I suspect it might be due to some security benefits (not to give client possibility to read any specific info). Because in the JWT token itself it might be info about roles/permission. But for this purpose token can also be encrypted.</p>&#xA;&#xA;<p>Another reason might be that JWT token is too big and in order to don't carry this token every time such approach might be used. (or if JWT token is stored in cookie it has size limits).</p>&#xA;&#xA;<p>I haven't seen any info that JWT token authentication is compromised and it's a bad practice to keep it on client (in browser).</p>&#xA;&#xA;<p>On the other hand I see that Ping Identity is also using <strong>pass by reference</strong> approach. Can you help me understand the reasoning behind it?</p>&#xA;"
27790905,How to establish relationships between Spring Data REST / Spring HATEOAS based (micro) services?,2015-01-06 01:50:17,<spring-data-rest><hateoas><spring-cloud><microservices>,2,2702,2,3.0,7,"<p>Trying to figure out a pattern for how to handle relationships when using a hypermedia based microservices based on Spring Data Rest or HATEOAS.</p>&#xA;&#xA;<p>If you have service A (Instructor) and Service B (Course) each exist as an a stand alone app.</p>&#xA;&#xA;<p>What is the preferred method for establishing a relationship between the two services.  In a manner that does not require columns for IDs of the foreign service.  It would be possible for each service to have many other services that need to communicate in the same manor.</p>&#xA;&#xA;<p>Possible solution (Not sure a correct path)</p>&#xA;&#xA;<p>Each service has a second table with a OneToMany with the primary entity within the service.  The table would have the following fields:</p>&#xA;&#xA;<p>ID, entityID, rel, relatedID</p>&#xA;&#xA;<p>Then in the opposite service using Spring Data Rest setup a find that queries the join table to find records that match.</p>&#xA;&#xA;<p>The primary goal I want to accomplish would be any service can have relationships with any number of other services without having to have knowledge of the other service.</p>&#xA;"
36541906,centralized settings with microservices,2016-04-11 07:01:48,<microservices>,1,2419,0,2.0,7,"<p>Microservices are all about decomposing your system into separate components.&#xA;However, some things in a system seem like centralized in nature.&#xA;My concern is about the system settings.&#xA;In a monolith you have one big file / db with all the parameters, settings and preferences.&#xA;This can be updated, backup, restore, export, import etc (think about Windows registry). More than this, your customers are used to go to this one ""place"" and set the system.&#xA;With microservices architecture this ""centralism"" seems like an anti pattern.</p>&#xA;&#xA;<p>What are the mechanisms/ frameworks to deal with such contradiction?</p>&#xA;"
51726683,How should microservices developed using AWS API Gateway + Lambda/ECS talk?,2018-08-07 12:20:51,<amazon-web-services><aws-lambda><microservices><aws-api-gateway><amazon-ecs>,5,197,0,5.0,7,"<p>I am developing a ""micro-services"" application using AWS API Gateway with either Lambda or ECS for compute. The issue now is communication between services are via API calls through the API gateway. This feels inefficient and less secure than it can be. Is there a way to make my microservices talk to each other in a more performant and secure manner? Like somehow talk directly within the private network? </p>&#xA;&#xA;<p>One way I thought of is multiple levels of API gateway. </p>&#xA;&#xA;<ul>&#xA;<li>1 public API gateway</li>&#xA;<li>1 private API gateway per microservice. And each microservice can call another microservice ""directly"" inside the private network</li>&#xA;</ul>&#xA;&#xA;<p>But in this way, I need to ""duplicate"" my routes in 2 levels of API ... this does not seem ideal. I was thinking maybe use <code>{proxy+}</code>. So anything <code>/payment/{proxy+}</code> goes to payment API gateway and so on - theres still 2 levels of API gateway ... but this seem to be the best I can go? </p>&#xA;&#xA;<p>Maybe there is a better way? </p>&#xA;"
36137802,An event store could become a single point of failure?,2016-03-21 17:25:54,<cqrs><microservices><event-sourcing><get-event-store>,4,2355,4,3.0,7,"<p>Since a couple of days I've been trying to figure it out how to inform to the rest of the microservices that a new entity was created in a microservice A that store that entity in a MongoDB.</p>&#xA;&#xA;<p>I want to:</p>&#xA;&#xA;<ul>&#xA;<li><p>Have low coupling between the microservices</p></li>&#xA;<li><p>Avoid distributed transactions between microservices like Two Phase Commit (2PC)</p></li>&#xA;</ul>&#xA;&#xA;<p>At first a message broker like RabbitMQ seems to be a good tool for the job but then I see the problem of <strong>commit</strong> the new document in MongoDB and <strong>publish</strong> the message in the broker not being atomic.</p>&#xA;&#xA;<p><a href=""http://eventuate.io/whyeventsourcing.html"" rel=""nofollow noreferrer"">Why event sourcing?</a> by eventuate.io:&#xA;<a href=""https://i.stack.imgur.com/xovbk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xovbk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>One way of solving this issue implies make the schema of the documents a bit dirtier by adding a mark that says if the document have been published in the broker and having a scheduled background process that search unpublished documents in MongoDB and publishes those to the broker using <a href=""https://www.rabbitmq.com/confirms.html"" rel=""nofollow noreferrer"">confirmations</a>, when the confirmation arrives the document will be marked as published (using at-least-once and idempotency semantics). This solutions is proposed in <a href=""https://stackoverflow.com/a/13490358/3517383"">this</a> and <a href=""https://stackoverflow.com/a/17812090/3517383"">this</a> answers.</p>&#xA;&#xA;<p>Reading an <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">Introduction to Microservices</a> by Chris Richardson I ended up in this great presentation of <a href=""http://www.slideshare.net/chris.e.richardson/developing-functional-domain-models-with-event-sourcing-sbtb-sbtb2015"" rel=""nofollow noreferrer"">Developing functional domain models with event sourcing</a> where one of the slides asked:</p>&#xA;&#xA;<blockquote>&#xA;  <p>How to <strong>atomically</strong> update the database <strong>and</strong> publish events and publish events without 2PC? (dual write problem).</p>&#xA;</blockquote>&#xA;&#xA;<p>The answer is simple (on the next slide)</p>&#xA;&#xA;<blockquote>&#xA;  <p><strike>Update the database <strong>and</strong></strike> publish events</p>&#xA;</blockquote>&#xA;&#xA;<p>This is a different approach to <a href=""https://stackoverflow.com/q/13488982/3517383"">this one</a> that is based on <a href=""https://github.com/MarkNijhof/Cre8iveThought/blob/master/blog/articles/2009-11-12-cqrs--la-greg-young.txt"" rel=""nofollow noreferrer"">CQRS a la Greg Young</a>.</p>&#xA;&#xA;<blockquote>&#xA;  <p>The domain repository is responsible for publishing the events, this&#xA;  would normally be inside a single transaction together with storing&#xA;  the events in the event store.</p>&#xA;</blockquote>&#xA;&#xA;<p>I think that delegate the responsabilities of storing and publishing the events to the event store is a good thing because avoids the need of 2PC or a background process.</p>&#xA;&#xA;<p>However, in a certain way it's true <a href=""https://stackoverflow.com/a/12678477/3517383"">that</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If you rely on the event store to publish the events you'd have a&#xA;  tight coupling to the storage mechanism.</p>&#xA;</blockquote>&#xA;&#xA;<p>But we could say the same if we adopt a message broker for intecommunicate the microservices.</p>&#xA;&#xA;<p>The thing that worries me more is that the Event Store seems to become a Single Point of Failure.</p>&#xA;&#xA;<p>If we look this <a href=""https://github.com/cer/event-sourcing-examples"" rel=""nofollow noreferrer"">example</a> from <a href=""http://eventuate.io"" rel=""nofollow noreferrer"">eventuate.io</a>&#xA;<a href=""https://i.stack.imgur.com/52rMK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/52rMK.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>we can see that if the event store is down, we can't create accounts or money transfers, losing one of the advantages of microservices. (although the system will continue responding querys).</p>&#xA;&#xA;<p>So, it's correct to affirmate that the Event Store as used in the eventuate example is a Single Point of Failure?</p>&#xA;"
47071729,AWS Load Balancer 502,2017-11-02 09:27:21,<amazon-web-services><amazon-ec2><microservices><elastic-load-balancer><internal-load-balancer>,1,873,4,3.0,7,"<p>I have microservices(in different programming languages) running on an EC2 instance.&#xA;On production I notice a few 502 Bad Gateway Errors when these services try to interact with each other.&#xA;Also in the logs of the requested service it doesn't show any api call is being hit</p>&#xA;&#xA;<p>example service A calls service B, but in service B logs there is nothing to indicate that a call came from service A.</p>&#xA;&#xA;<p>Can it be AWS load balancer issue? Any help would be appreciated. Thanks in advance.</p>&#xA;&#xA;<p>Solution tried:&#xA;We tried making http/https connection agents in each service but still we get this issue.</p>&#xA;&#xA;<p>Update:&#xA;In lb logs, the api is logged, but the target response code shows ""-"" whereas lb response code shows 502 or 504. Does it mean that lb is not able to handle the traffic or my application?</p>&#xA;&#xA;<p>Also what can be the possible solution?</p>&#xA;"
42062199,Reactive Programming Advantages/Disadvantages,2017-02-06 07:14:55,<java><reactive-programming><microservices><rx-java2><project-reactor>,4,6250,1,6.0,7,"<p>I keep studying and trying Reactive Style of coding using Reactor and RxJava. I do understand that reactive coding makes better utilization of CPU compared to single threaded execution. </p>&#xA;&#xA;<p>Is there any concrete comparison between reactive programming vs imperative programming in web based applications? </p>&#xA;&#xA;<p>How much is the performance gain, throughput I achieve by using reactive programming over non-reactive programming?</p>&#xA;&#xA;<p>Also what are the advantages and disadvantages of Reactive Programming? </p>&#xA;&#xA;<p>Is there any statistical benchmark? </p>&#xA;"
38328727,What is the best way to design background jobs in microservices architecture?,2016-07-12 12:19:34,<architecture><microservices>,1,1727,1,1.0,7,"<p>I am using microservices architecture. As per my requirements, there are some Restful services required and some background jobs to be developed. </p>&#xA;&#xA;<p>For an example of Groceries delivery system,</p>&#xA;&#xA;<ul>&#xA;<li>Customers service - some restful service</li>&#xA;<li>Provider service - some restful service</li>&#xA;<li>OrderProvision - some background service which checks whether all of customer items got provided by different providers. </li>&#xA;</ul>&#xA;&#xA;<p>Once done, send an initiation to customer with the status and initiate delivery system to start delivering</p>&#xA;&#xA;<p>For the case of OrderProvision what is the best way to implement microservices?&#xA;In case of .Net framework, I can create a windows service/ scheduler task to run in background and do the checks. If it needs to be deployed on other servers like Linux, it does not work. What would be the best way to code such background tasks in microservices architecture?</p>&#xA;"
40966759,Microservices: Centralized Authorization vs Authorization in each service,2016-12-05 03:42:29,<architecture><microservices>,1,1391,0,1.0,7,"<p>Let's say I have a Microservices system built with an API Gateway.  </p>&#xA;&#xA;<p>Every request after coming through the Gateway have to be pre-authenticated by an Authentication Service (The Firewall pattern)  </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DySBr.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DySBr.png"" alt=""Firewall Pattern""></a>  </p>&#xA;&#xA;<p>But how about Authorization? For instance, I have 3 models and 3 services according to them in a <em>Hotel Management</em> system:  </p>&#xA;&#xA;<p><strong>User</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>each user can have many hotels  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Hotel</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a hotel is owned by a single user (owner)  </li>&#xA;<li>each hotel can have many employees (also a user)  </li>&#xA;<li>a hotel can have many rooms</li>&#xA;<li>for the sake of simplicity let's pretend that an employee have the same rights as the owner over a hotel  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Room</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a room can only belong to a single hotel</li>&#xA;<li>owner and employees can only edit rooms in hotels that they owned/employed at</li>&#xA;</ul>&#xA;&#xA;<p>An example request to edit a room <strong>Y</strong>, after being authenticated it will have a verified claim that state something like <strong>'I am user X'</strong>.  </p>&#xA;&#xA;<p>To know whether <strong>X</strong> has the right to edit over <strong>Y</strong> I have to make requests to Hotel Service asking ""Does <strong>Y</strong>'s Hotel associated with (owned by/employing) <strong>X</strong>?"".  </p>&#xA;&#xA;<p>The question is: <strong>Where do I make these requests?</strong><br>&#xA;Have the Gateway ask the <em>Hotel Service</em> before forwarding client request to <em>Room Service</em>, or let the <em>Room Service</em> ask the <em>Hotel Service</em> by itself. When to choose one over another ? What's the benefit ?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Also, this modeling seems kinda wrong to me. All these relations laying around Microservices just make my system really complicated. As it grows it becomes harder for me to visualize the workflow between services. Is there a solution to this problem? A centralized relationship service that utilizes graph database like Neo4j perhaps?</p>&#xA;"
48635782,Zookeeper vs Eureka for microservices?,2018-02-06 05:00:32,<apache-zookeeper><microservices><netflix-eureka><orchestration>,2,4240,0,4.0,7,"<p>I am going to implement the orchestration of a set of microservices in my application. Two widely using tools I found vs Apache <a href=""https://zookeeper.apache.org/"" rel=""noreferrer"">Zookeeper</a> and Netflix <a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">Eureka</a>.</p>&#xA;&#xA;<p>Can anyone please give me a comparison based on fundamental differences, those two services have?</p>&#xA;&#xA;<p>Is there any other powerful tool?</p>&#xA;"
29636899,Do microservices break the bounded context?,2015-04-14 20:33:12,<domain-driven-design><microservices>,2,3461,3,3.0,7,"<p>I am a bit confused. I am working in a young banking company and we decided to implement a DDD architecture to break complexity.</p>&#xA;&#xA;<p>So, here is my question (it follows a design suggestion made by someone in the team). Let's say we have 3 different domains. D1, D2, D3, that expose domain (web)services. Each domain manipulates strongly typed business entities, that rely on the same tables. In front of these domains, we want a microservice to garantee that data persisted in tables is consistent, in a centralized manner. D1, D2 and D3 ask the microservice to persist data conforming to specific rules. We want the microservice to act as a CRUD proxy to the tables. The microservice provides specific DTOs to D1, D2 and D3 domains, obfuscating the tables to D1, D2, D3.</p>&#xA;&#xA;<p>Does this approach sound good ? Would you consider using microservices in a DDD architecture to manage CRUD and data consistency for 1+ domains ? Does ""CRUDing"" and validating data with a microservice break the bounded context ? What are the best practices with dealing with microservices in a DDD architecture, if any ?</p>&#xA;&#xA;<p>Many thanks for your contribution,</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>The following article helped me to refine my thoughts : <a href=""http://martinfowler.com/bliki/MicroservicePremium.html"" rel=""noreferrer"">http://martinfowler.com/bliki/MicroservicePremium.html</a></p>&#xA;&#xA;<p>Microservices are useful on complex situations where monolithic systems failed at being maintainable. They are not good candidates for upfront design implementations. On the other hand, DDD tries to tackle complexity at the very beginning of the projects. Successful DDD should not meet microservices implementations.</p>&#xA;"
29704842,Integration testing Spring Boot based Microservices,2015-04-17 16:35:27,<junit><spring-boot><microservices>,2,3024,4,1.0,7,"<p>I have read many of the guides about working with Spring Boot and RESTful services, and many of them contain information about running unit tests, most notably ""Building an Application with Spring Boot"".  However, I haven't seen anything that gives an example on how to unit test a Spring Boot application that consumes/depends on other Spring Boot applications, as is common in cloud micro-services architecture. So, for example, we have the following Spring Boot services:</p>&#xA;&#xA;<p>ServiceMediator,&#xA;Adapter1,&#xA;Adapter2</p>&#xA;&#xA;<p>ServiceMediator calls Adapter1 or Adapter2, depending on the input.</p>&#xA;&#xA;<p>Is there a way to start up the Spring Boot services Adapter1 and Adapter2  before starting and testing the ServiceMediator in a Spring JUnit test?</p>&#xA;"
41903352,How do I register a microservice (or its methods) to Task in Netflix Conductor?,2017-01-27 21:33:02,<microservices><netflix><amazon-swf><axon><netflix-conductor>,2,1341,1,0.0,7,"<p>I was looking for a more sophisticated workflow than Saga from AxonFramework  -- which we are currently using -- and I found one in Netflix Conductor. &#xA;Sadly, I have searched the Internet for a decent example but to no avail.</p>&#xA;&#xA;<p>My question is, in Netflix Conductor, how might one define and create Task or WorkflowTask and most importantly, link a microservice to it? Here is a Netflix Conductor code from github:</p>&#xA;&#xA;<pre><code>    WorkflowDef def = new WorkflowDef();&#xA;    def.setName(""test"");&#xA;    WorkflowTask t0 = new WorkflowTask();&#xA;    t0.setName(""t0"");&#xA;    t0.setType(Type.SIMPLE);&#xA;    t0.setTaskReferenceName(""t0"");&#xA;&#xA;    WorkflowTask t1 = new WorkflowTask();&#xA;    t1.setName(""t1"");&#xA;    t1.setType(Type.SIMPLE);&#xA;    t1.setTaskReferenceName(""t1"");&#xA;&#xA;    def.getTasks().add(t0);&#xA;    def.getTasks().add(t1);&#xA;</code></pre>&#xA;&#xA;<p>Pardon my confusion as I am new to Netflix Conductor.</p>&#xA;"
50176793,Automate RabbitMQ consumer testing,2018-05-04 14:02:25,<rabbitmq><integration-testing><microservices>,2,245,0,0.0,7,"<p>I have a .net micro-service receiving messages using RabbitMQ client, I need to test the following:</p>&#xA;&#xA;<p>1- consumer is successfully connected to rabbitMq host.</p>&#xA;&#xA;<p>2- consumer is listening to queue.</p>&#xA;&#xA;<p>3- consumer is receiving messages successfully.</p>&#xA;&#xA;<p>To achieve the above, I have created a sample application that sends messages and I am debugging consumer to be sure that it is receiving messages.</p>&#xA;&#xA;<p>How can I automate this test? hence include it in my micro-service CI.</p>&#xA;&#xA;<p>I am thinking to include my sample app in my CI so I can fire a message then run a consumer unit test that waits a specific time then passes if the message received, but this seems like a wrong practice to me because the test will not start until a few seconds the message is fired.</p>&#xA;&#xA;<p>Another way I am thinking of is firing the sample application from the unit test itself, but if the sample app fails to work that would make it the service fault.</p>&#xA;&#xA;<p>Is there any best practices for integration testing of micro-services connecting through RabbitMQ?</p>&#xA;"
26975640,Why are Micro-Services Architectures not based on Enterprise Service Buses?,2014-11-17 15:08:19,<esb><microservices>,4,2300,0,2.0,8,"<p>What reasons are there against (or for) using the features of an Enterprise Service Bus when building an overall service adhering to a micro-service architecture (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">http://martinfowler.com/articles/microservices.html</a>)? Why should we use dumb pipes and smart endpoints as opposed to using smarter pipes and be able to develop simpler services? </p>&#xA;"
22987482,Can you use Hapi.JS as a Micro-services framework?,2014-04-10 12:04:08,<node.js><api><plugins><microservices>,1,2226,0,2.0,8,"<p>I've seen various interesting presentations recently about the joys of Micro Services (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow noreferrer"">http://martinfowler.com/articles/microservices.html</a>) and also wonder how we might use those concepts with Hapi.JS. </p>&#xA;&#xA;<p>The CTO of Mail Online (largest online newspaper on the planet) name checks HAPI and its plugin system in relation to micro-services :</p>&#xA;&#xA;<p><a href=""http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline"" rel=""nofollow noreferrer"">http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline</a></p>&#xA;&#xA;<blockquote>&#xA;  <p>A micro-services architecture is used, which was inspired by Fred George, which is a&#xA;  slightly different take on the hapi plugin architecture, structuring applications to be &#xA;  maintainable as they get bigger is a key challenge going forward and micro-services is a &#xA;  solution to this. The MailOnline are also heavy users of Joyent (On Premise SDC and public &#xA;  cloud).</p>&#xA;</blockquote>&#xA;&#xA;<p>There are also new node frameworks set up specifically for micro-services (senecajs.org)</p>&#xA;&#xA;<p>Has anyone seen any case studies (and ideally tutorials) on leveraging Hapi in this way?</p>&#xA;"
28930710,How to avoid concurrency issues when scaling writes horizontally?,2015-03-08 19:10:29,<azure><scalability><sharding><microservices><horizontal-scaling>,5,639,2,3.0,8,"<p>Assume there is a worker service that receives messages from a queue, reads the product with the specified Id from a document database, applies some manipulation logic based on the message, and finally writes the updated product back to the database (a).</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/RZYlA.png"" alt=""horizontally scaling writes""></p>&#xA;&#xA;<p>This work can be safely done in parallel when dealing with different products, so we can scale horizontally (b). However, if more than one service instance works on the same product, we might end up with concurrency issues, or concurrency exceptions from the database, in which case we should apply some retry logic (and still the retry might fail again and so on). </p>&#xA;&#xA;<p><strong>Question</strong>: How do we avoid this? Is there a way I can ensure two instances are not working on the same product?</p>&#xA;&#xA;<p><strong>Example/Use case</strong>: An online store has a great sale on productA, productB and productC that ends in an hour and hundreds of customers are buying. For each purchase, a message is enqueued (productId, numberOfItems, price).  <strong>Goal</strong>: How can we run three instances of our worker service and make sure that all messages for productA will end up in instanceA, productB to instanceB and productC to instanceC (resulting in no concurrency issues)?</p>&#xA;&#xA;<p><strong>Notes</strong>: My service is written in C#, hosted on Azure as a Worker Role, I use Azure Queues for messaging, and I'm thinking to use Mongo for storage. Also, the Entity IDs are <code>GUID</code>.</p>&#xA;&#xA;<p>It's more about the technique/design, so if you use different tools to solve the problem I'm still interested.</p>&#xA;"
31317470,How should you deal with auth and sharing Users info across microservices?,2015-07-09 12:26:19,<node.js><mongodb><nginx><microservices>,1,1189,3,6.0,8,"<p><strong>TLTR:</strong> What is a good way to communicate across services for Auth and User Info regardless of location of server or technology used</p>&#xA;&#xA;<p>I'm trying to learn about microservices and I'm a little bit unclear as to how I should approach accessing user information and control access with multiple services. Please let me know if I am approaching this completely wrong.</p>&#xA;&#xA;<p>For example I have a basic service for Blog CRUD operations and a Service for uploading and storing images and videos. I haven't done anything with Authorization or Users yet (except I am accounting for UserIds eventually being present in my Models (e.g. in my blog model ObjectID's for author, commenters, etc).</p>&#xA;&#xA;<p>I want to keep this as separated as possible (for learning purposes more then anything) and while at the moment I am building it all in Node.js I hope to be able to swap in and out different technologies such as nginx, a java/go/python service or a different storage (currently mongo, but would like to be able to switch to sql as an option )</p>&#xA;&#xA;<p>How I currently have these structured is I have both services built as Express.js apps and currently I am using node-http-proxy to proxy to the express services (this is just to save with setting up nginx for now but I don't want to be dependent on nginx either).</p>&#xA;&#xA;<p><em>How should I approach:</em></p>&#xA;&#xA;<ul>&#xA;<li><p>Authenticated user or some of the routes (e.g. when creating a new post or updating/deleting) and Not when getting the post to Read (eventually I would like to incorporate roles too)</p></li>&#xA;<li><p>populating the User information e.g. from the user's ID stored in the blog author and replacing it with the user information (in a single app I could just use mongoose populate</p></li>&#xA;</ul>&#xA;&#xA;<p>The main aim is I would like to keep the Auth and Users in separate services that could be called in any other service and stored in another DB for example if they were located on different physical servers.</p>&#xA;&#xA;<p>someone had suggested to me I could do this using HTTP/S but is there a better way to do this and can anyone point me to any implementation examples, Node.js would be preferable but not essential</p>&#xA;&#xA;<p>This likely requires some service registry but I am a bit lost as to how this would be implemented</p>&#xA;"
30648096,centralized API documentation for microservices,2015-06-04 15:30:59,<api><documentation><microservices>,3,3386,5,2.0,8,"<p>My team and I are currently building multiple services in parallel. We have the benefit of building all the services from scratch. I would like the ability to automatically display all API endpoints, from all services, in one page/site.  This would be helpful because (among other things):</p>&#xA;&#xA;<ol>&#xA;<li><p>I don't have to go to multiple documentation sites to see what are the available endpoints in my entire ""system"". </p></li>&#xA;<li><p>It'll be a good first step to determine if any of the services should be split, combined or simply refactored.  </p></li>&#xA;</ol>&#xA;&#xA;<p>Some of our services are in Django and the <a href=""http://swagger.io/"" rel=""noreferrer"">rest-swagger</a> module is a great help. But I don't see how I can combine rest-swagger documentation from multiple services into a single documentation page/site.</p>&#xA;&#xA;<p>I'm currently looking through <a href=""http://microservices.io/index.html"" rel=""noreferrer"">this site</a> and anything related to the <a href=""http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/"" rel=""noreferrer"">Netflix experience</a> but could not find a solution to my problem. Maybe centralized documentation isn't a big deal with 600+ services at Netflix, but that's hard to believe.</p>&#xA;&#xA;<p>Can anyone suggest a tool or method to have a combined API documentation for all services in a microservice architecture? </p>&#xA;&#xA;<p>My ideal scenario of what happens when a service is changed: </p>&#xA;&#xA;<ol>&#xA;<li>I click on the link to see the list of endpoints in my system.</li>&#xA;<li>A teammate updates a service and also it's documentation.</li>&#xA;<li>I refresh the page I am currently and I see that change made from step #2.</li>&#xA;</ol>&#xA;"
26854986,Cross-service linking for HATEOAS micro-services,2014-11-10 23:33:32,<spring><spring-boot><hateoas><spring-hateoas><microservices>,1,1372,3,4.0,8,"<p>I have a number of micro-services built with Spring Boot, so for a bit of fun, I thought I'd have a go at adding HATEOAS to them to help set up cross-resource linking. It seems to work quite nicely within a particular project, but I was wondering whether there's a good way to link across APIs. As an example, imagine I have 3 services:</p>&#xA;&#xA;<p>A user details service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}&#xA;</code></pre>&#xA;&#xA;<p>A user calendar service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/appointments&#xA;/users/{userid}/appointments/{appointmentid}&#xA;</code></pre>&#xA;&#xA;<p>A user messaging service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/messages&#xA;/users/{userid}/messages/{messageid}&#xA;</code></pre>&#xA;&#xA;<p>To make this browsable via the API, it would be good to have links from a user resource to its appointments and messages. Similarly, it would be nice to have links back from those resources. This is all very achievable when I have a single API with everything on the classpath, where I can write code such as:</p>&#xA;&#xA;<p>Code:</p>&#xA;&#xA;<pre><code>user.add(linkTo(methodOn(CalendarController.class).appointments(user.getKey())).withRel(""appointments""))&#xA;</code></pre>&#xA;&#xA;<p>However I'm not able to do this if CalendarController is not on the classpath of the service I'm currently hitting.</p>&#xA;&#xA;<p>Is there a good/recommended method for creating links to controllers which are not in the current project?</p>&#xA;&#xA;<p>Referenced from <a href=""http://forum.spring.io/forum/spring-projects/web/749306-cross-service-linking-for-hateoas-micro-services"">spring forums</a></p>&#xA;"
41262716,Don't allow direct calls to Microservices. Only allow through API Gateway,2016-12-21 12:20:58,<java><spring><rest><microservices><gateway>,4,1584,6,1.0,8,"<p>Maybe this is a strange question (I'm new with Microservices). But I'm looking for some info on how proceed with this. Does not need to be Spring specific, but that's the framework I'm using at the moment.</p>&#xA;&#xA;<p>Example:&#xA;Lets say we have two Microservices</p>&#xA;&#xA;<p>a) <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>b) <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>and we have setup Spring Zuul (acting as the API Gateway) with the following rules that forward the incoming calls:</p>&#xA;&#xA;<p>/rest/one -> <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>/rest/two -> <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>The question...&#xA;Is there a way to stop users from directly accessing the services mentioned in A and B (only allow the ones that come through the API Gateway)?</p>&#xA;&#xA;<p>Can this be done with Springs Zuul (Acting as a API Gateway) by setting up some extra filters or do we set it up in Microservices endpoints?</p>&#xA;&#xA;<p>Would even like to know if there is a way to not even processing the direct calls on the Microservices endpoints that don't come via the API Gateway.</p>&#xA;&#xA;<p>Maybe this is solved with server specific rules and has nothing to do with Spring? </p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>/D</p>&#xA;"
36083504,Database connection pool strategy for micro services,2016-03-18 11:44:23,<database><postgresql><jdbc><connection-pooling><microservices>,1,1749,2,0.0,8,"<p>We are trying to convert our monolithic application to a micro services based architecture. We use Postgresql as one of our database in the monolithic application with BoneCP for connection pooling. </p>&#xA;&#xA;<p>When this monolith is split to a number of independent micro-services with each of them running in a different JVM, I can think about two options for connection pooling</p>&#xA;&#xA;<ol>&#xA;<li>BoneCP or any decent connection pool for each microservice - My initial research shows that this is the primary choice. It is possible to have a fine grained control of connection requirements for each service.But, down side is that as the number of services increase, number of connection pool also increases and eventually there will be too many idle connections assuming that minimum connections in each pool is greater than 0.</li>&#xA;<li>Rely on database specific extensions like PGBouncer - This approach has the advantage that connection pool is managed by a central source rather than a pool for each micro service and hence number of idle connections can be brought down. It is also language/technology agnostic. Down side is that these extensions are database specific and some of the functionalities in JDBC may not work. For eg: Prepared statments may not work with PGBouncer in Transaction_Pooling mode. </li>&#xA;</ol>&#xA;&#xA;<p>In our case most of the micro-services(at least 50) will be connecting to the same Postgres server even though the database can be different. So, if we go with option 1, there is a higher chance of creating too many idle connections.The traffic to most of our services are very moderate and the rationale behind moving to micro-service is for easier deployment, scaling etc.</p>&#xA;&#xA;<p>Has anyone faced a similar problem while adopting micro-services architecture? Is there a better way of solving this problem in micro-service world?</p>&#xA;"
32334161,What is the conceptual difference between Service Discovery tools and Load Balancers that check node health?,2015-09-01 14:24:24,<load-balancing><distributed-computing><microservices><service-discovery><consul>,3,414,3,6.0,8,"<p>Recently several service discovery tools have become popular/""mainstream"", and I’m wondering under what primary use cases one should employ them instead of traditional load balancers.</p>&#xA;&#xA;<p>With LBs, you cluster a bunch of nodes behind the balancer, and then clients make requests to the balancer, who then (typically) round robins those requests to all the nodes in the cluster.</p>&#xA;&#xA;<p>With service discovery (<a href=""https://www.consul.io"" rel=""noreferrer"">Consul</a>, <a href=""https://zookeeper.apache.org"" rel=""noreferrer"">ZK</a>, etc.), you let a centralized “consensus” service determine what nodes for particular service are healthy, and your app connects to the nodes that the service deems as being healthy. <strong>So while service discovery and load balancing are two separate concepts, service discovery gives you load balancing as a convenient side effect.</strong></p>&#xA;&#xA;<p>But, if the load balancer (say <a href=""http://www.haproxy.org"" rel=""noreferrer"">HAProxy</a> or <a href=""http://wiki.nginx.org/Main"" rel=""noreferrer"">nginx</a>) has monitoring and health checks built into it, then you pretty much get service discovery as a side effect of load balancing! Meaning, if my LB knows not to forward a request to an unhealthy node in its cluster, then that’s functionally equivalent to a consensus server telling my app not to connect to an unhealty node.</p>&#xA;&#xA;<p>So to me, service discovery tools feel like the “6-in-one,half-dozen-in-the-other” equivalent to load balancers. Am I missing something here? If someone had an application architecture entirely predicated on load balanced microservices, what is the benefit (or not) to switching over to a service discovery-based model?</p>&#xA;"
31546631,What are the option to API gateway with docker?,2015-07-21 18:13:46,<api><docker><microservices><gateway><tyk>,2,6049,0,6.0,8,"<p>I've created several RESTful microservices and dockerized them. Now I want to have a web-based UI for them and the ability to create users and grant permissions to them to use some of the APIs.</p>&#xA;&#xA;<p>I know that I need some kind of API gateway. My first thought was that I always could do that bruteforce way: create some django app that would serve UI and proxy all request to APIs by hand, but this seems very dull. Maybe there are some alternatives? I've ready about Tyk, but can't find any information about the ability to add users and grant permissions to them.</p>&#xA;&#xA;<p>I probably could create an application that would serve as API gateway and automate proxying of requests by writing some code that would model that. So for example I basically need a mapping between external urls to actual api urls and some authorization logic. Maybe there are already something like that?</p>&#xA;"
34593341,Trade offs and best practices building microservices with Azure Service Fabric,2016-01-04 14:26:47,<c#><azure><asp.net-web-api2><microservices><azure-service-fabric>,2,2284,2,3.0,8,"<p>I want to build a microservice application based on Azure Service Fabric. For some stateful services or actors I want to access the state from outside via web api.</p>&#xA;&#xA;<p>What are the general trade-offs and best practices for such a Service Fabric project regarding to:</p>&#xA;&#xA;<ol>&#xA;<li><p>using one vs. multiple services in a single application? Therefore if I use one service per application, I will have multiple applications for my project. When is it useful to use one service per application?</p></li>&#xA;<li><p>using one vs. multiple actors in a single service? When is it useful to have more than one actor per service?</p></li>&#xA;<li><p>using one stateless web api service for the whole project vs. multiple stateless web services for each stateful service or for each application?</p></li>&#xA;</ol>&#xA;&#xA;<p>I know these decisions are based on the specific project. But maybe there are general advantages and disadvantages for the three points above.</p>&#xA;"
35409492,Eureka service discovery without Spring-boot,2016-02-15 12:32:50,<java><spring><spring-boot><microservices><netflix-eureka>,3,8751,1,5.0,8,"<p>I have written a spring boot micro-service and a REST client. The client is a part of another module and make RESTful calls to the micro-service. The micro-service registers with the Eureka registry and I want my client (Which is not a spring boot project) to use the Eureka to query and get the service endpoints. </p>&#xA;&#xA;<p>My problem is since the client is not a Spring-Boot applications I can not use the annotations like <code>@SpringBootApplication</code>, <code>@EnableDiscoveryClient</code> and the <code>DiscoveryClient</code> is not get auto wired to the application. Is there anyway to manually auto-wire the <code>DiscoveryClient</code> bean to the client without using the annotations ?</p>&#xA;"
41618538,Securing REST microservices with Spring Security,2017-01-12 16:41:21,<spring><spring-security><microservices>,1,4585,2,7.0,8,"<p>I'm looking for a best-practice and efficient solution to secure multiple microservices communicating via REST to a Web Client application.</p>&#xA;&#xA;<p><strong>Current setup</strong>:</p>&#xA;&#xA;<p>These microservices are made in Java, with Spring Framework and run into Docker containers.</p>&#xA;&#xA;<p>The client is an Angular 2 application.</p>&#xA;&#xA;<p>I made a new µService that will act as a ""<em>gateway</em>"" and be the only communication point between my web client and my other services.</p>&#xA;&#xA;<p>I retrieve a JWT encrypted token from a remote authentication API (let's call it LOCK)</p>&#xA;&#xA;<p><strong>Solution I was thinking about</strong>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ajEpM.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ajEpM.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I could store the login JWT into a cookie, and send it to the gateway.</p>&#xA;&#xA;<p>The gateway embed in the final payload sent to the concerned µService the token and store the user if it's new into a database.</p>&#xA;&#xA;<p>The microservice then get the query, checks in the remote authentication service the user role, and if it's sufficient, it returns a 200 status with result.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>We will need to have a RabbitMQ Broker into our µServices hive, and thus, to use the WebSockets. In order to secure WebSockets in the same way as securing REST APIs, I'm not sure if we still should manage security in a gateway, and maybe manage it at the microservice level by itself. Because lots of messages will transit, and we should maybe get rid a middleware that will slow down the thing.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<p>Is it a good practice ? What could possibly be done better ? Do you have any example of things done that fills the same needs ? Thanks a lot for your shares &amp; thoughts.</p>&#xA;"
36157778,Accessing stateless service via ServiceProxy fails + ASP.NET 5 Web API project throws Health State error,2016-03-22 14:55:29,<c#><asp.net><.net><microservices><azure-service-fabric>,6,5965,4,3.0,8,"<p>I'm new to microsoft azure service fabric. For my master's degree I have to develop a microservice-approach prototype in service fabric. After hours of researching I am still not getting my issue(s) solved.</p>&#xA;&#xA;<p>I want to access my (in a local fabric cluster deployed) stateless service in a web front-end like in <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/"" rel=""noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/</a>. The simplest way for doing that is by adding an ASP .NET 5 Web Api project to the Service Fabric application and make a <code>ServiceProxy</code> method call in the <code>ValuesController</code>. So I added this code to my solution:</p>&#xA;&#xA;<p><strong>ValuesController.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>[Route(""api/[controller]"")]&#xA;public class ValuesController : Controller&#xA;{&#xA;  // GET api/values/IObject&#xA;  [HttpGet(""{interfaceName}"")]&#xA;  public async Task&lt;string&gt; Get(string interfaceName)&#xA;  {&#xA;    var serviceName = ""fabric:/DataServiceFabric/MasterDataMService"";&#xA;    var masterDataService = ServiceProxy.Create&lt;IMasterDataMService&gt;(new Uri(serviceName));&#xA;    var result = await masterDataService.GetMasterDataByName(interfaceName);&#xA;    return result.Content;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After a F5-deploy my browser doesn't automatically navigate to my web front-end. By looking into the Service Fabric Explorer my ASP .NET 5 application throws a Health State error:</p>&#xA;&#xA;<pre><code>Kind        Health State  Description&#xA;=============================================================================&#xA;Partitions  Error         Unhealthy partitions: 100% (1/1), MaxPercentUnhealthyPartitionsPerService=0%.&#xA;Partition   Error         Unhealthy partition: PartitionId='413...', AggregatedHealthState='Error'.&#xA;Event       Error         Error event: SourceId='System.FM', Property='State'. Partition is below target replica or instance count.&#xA;</code></pre>&#xA;&#xA;<p>After this <a href=""https://stackoverflow.com/questions/34892366/partition-is-below-target-replica-or-instance-count-error-after-deploying-serv"">this</a> question the <em>""Partition is below target replica or instance count""</em> indicates that a unhandled exception in my service is preventing it from starting. But I'm not able to find a stack strace in my Service Fabric Explorer to debug this failure. This is my <code>ServiceManifest.xml</code> of my ASP .NET web service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (Web1):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Name=""Web1"" Version=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;ServiceTypes&gt;&#xA;      &lt;StatelessServiceType ServiceTypeName=""Web1Type""&gt;&#xA;         &lt;Extensions&gt;&#xA;            &lt;Extension Name=""__GeneratedServiceType__""&gt;&#xA;               &lt;GeneratedNames xmlns=""http://schemas.microsoft.com/2015/03/fabact-no-schema""&gt;&#xA;                  &lt;DefaultService Name=""Web1Service"" /&gt;&#xA;                  &lt;ServiceEndpoint Name=""Web1TypeEndpoint"" /&gt;&#xA;               &lt;/GeneratedNames&gt;&#xA;            &lt;/Extension&gt;&#xA;         &lt;/Extensions&gt;&#xA;      &lt;/StatelessServiceType&gt;&#xA;   &lt;/ServiceTypes&gt;&#xA;   &lt;CodePackage Name=""C"" Version=""1.0.0""&gt;&#xA;      &lt;EntryPoint&gt;&#xA;         &lt;ExeHost&gt;&#xA;            &lt;Program&gt;approot\runtimes\dnx-clr-win-x64.1.0.0-rc1-update1\bin\dnx.exe&lt;/Program&gt;&#xA;            &lt;Arguments&gt;--appbase approot\src\Web1 Microsoft.Dnx.ApplicationHost Microsoft.ServiceFabric.AspNet.Hosting --server Microsoft.AspNet.Server.WebListener&lt;/Arguments&gt;&#xA;            &lt;WorkingFolder&gt;CodePackage&lt;/WorkingFolder&gt;&#xA;            &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048"" /&gt;&#xA;         &lt;/ExeHost&gt;&#xA;      &lt;/EntryPoint&gt;&#xA;   &lt;/CodePackage&gt;&#xA;   &lt;Resources&gt;&#xA;      &lt;Endpoints&gt;&#xA;         &lt;Endpoint Name=""Web1TypeEndpoint"" Protocol=""http"" Type=""Input"" Port=""80"" /&gt;&#xA;      &lt;/Endpoints&gt;&#xA;   &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>And here my <code>ApplicationManifest.xml</code> of my service fabric solution:</p>&#xA;&#xA;<p><strong>ApplicationManifest.xml:</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ApplicationManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" ApplicationTypeName=""DataServiceFabricType"" ApplicationTypeVersion=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;Parameters&gt;&#xA;      &lt;Parameter Name=""ActorTestServiceActorService_PartitionCount"" DefaultValue=""10"" /&gt;&#xA;      &lt;Parameter Name=""MasterDataMService_InstanceCount"" DefaultValue=""-1"" /&gt;&#xA;   &lt;/Parameters&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;     &lt;ServiceManifestRef ServiceManifestName=""Web2Pkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;     &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""Web1"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""ActorTestServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""MasterDataMServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;      &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;DefaultServices&gt;&#xA;      &lt;Service Name=""Web1Service""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""Web1Type""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""ActorTestServiceActorService"" GeneratedIdRef=""761ee3cf-5a3a-49d8-9c57-aa3480d1acf1""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""ActorTestServiceActorServiceType""&gt;&#xA;            &lt;UniformInt64Partition PartitionCount=""[ActorTestServiceActorService_PartitionCount]"" LowKey=""-9223372036854775808"" HighKey=""9223372036854775807"" /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""MasterDataMService""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""MasterDataMServiceType"" InstanceCount=""[MasterDataMService_InstanceCount]""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;   &lt;/DefaultServices&gt;&#xA;&lt;/ApplicationManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>So I created a new solution with an ASP.NET 5 web application and the same <code>ValuesController.cs</code>. I ensured my stateless service is running on my local cluster and than I started my new web application. After calling the GET-Method in my Controller I got the following exception:</p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 0,2593ms 500&#xA;Microsoft.AspNet.Server.Kestrel: Error: An unhandled exception was thrown by the application.&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1}&#xA;</code></pre>&#xA;&#xA;<p>My stateless service is a SingletonPartition, so do I need a partition key here? And if yes, how do I get the key? The Service Fabric Explorer doesn't provide me with this information for my stateless service. Here is the <code>ServiceManifest.xml</code> of my stateless service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (MasterDataMService):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest Name=""MasterDataMServicePkg""&#xA;                 Version=""1.0.0""&#xA;                 xmlns=""http://schemas.microsoft.com/2011/01/fabric""&#xA;                 xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&#xA;                 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;&#xA;  &lt;ServiceTypes&gt;&#xA;    &lt;!-- This is the name of your ServiceType. &#xA;         This name must match the string used in RegisterServiceType call in Program.cs. --&gt;&#xA;    &lt;StatelessServiceType ServiceTypeName=""MasterDataMServiceType"" /&gt;&#xA;  &lt;/ServiceTypes&gt;&#xA;&#xA;  &lt;!-- Code package is your service executable. --&gt;&#xA;  &lt;CodePackage Name=""Code"" Version=""1.0.0""&gt;&#xA;    &lt;EntryPoint&gt;&#xA;      &lt;ExeHost&gt;&#xA;        &lt;Program&gt;MasterDataMService.exe&lt;/Program&gt;&#xA;      &lt;/ExeHost&gt;&#xA;    &lt;/EntryPoint&gt;&#xA;  &lt;/CodePackage&gt;&#xA;&#xA;  &lt;!-- Config package is the contents of the Config directoy under PackageRoot that contains an &#xA;       independently-updateable and versioned set of custom configuration settings for your service. --&gt;&#xA;  &lt;ConfigPackage Name=""Config"" Version=""1.0.0"" /&gt;&#xA;&#xA;  &lt;Resources&gt;&#xA;    &lt;Endpoints&gt;&#xA;      &lt;!-- This endpoint is used by the communication listener to obtain the port on which to &#xA;           listen. Please note that if your service is partitioned, this port is shared with &#xA;           replicas of different partitions that are placed in your code. --&gt;&#xA;      &lt;Endpoint Name=""ServiceEndpoint"" Type=""Input"" Protocol=""http"" Port=""80""/&gt;&#xA;    &lt;/Endpoints&gt;&#xA;  &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that I decided to set up a service communication with OWIN:</p>&#xA;&#xA;<p><strong>MasterDataMService.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>internal sealed class MasterDataMService : StatelessService, IMasterDataMService&#xA;{&#xA;  [...]      &#xA;&#xA;  protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;  {&#xA;    return new[]&#xA;    {&#xA;      new ServiceInstanceListener(initParams =&gt; new OwinCommunicationListener(""MasterDataMService"", new StartUp(), initParams))&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I can acess my microservice by using a <code>HttpClient</code> in my <code>DefaultController</code>:</p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>var client = new HttpClient();&#xA;var request = ""http://localhost:80/MasterDataMService/api/values/query"";&#xA;var result = string.Empty;&#xA;HttpResponseMessage response = await client.GetAsync(request);&#xA;if (response.IsSuccessStatusCode)&#xA;{&#xA;  result = await response.Content.ReadAsStringAsync();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But thats not what I originally wanted. I don't want to specifiy the service endpoint in my request. Instead I would like to communicate with my stateless service over a <code>ServiceProxy</code>. How do I achieve that here? What did I wrong? And how can I solve this Health State error with my ASP .NET 5 application which is deployed into my service fabric cluster?</p>&#xA;&#xA;<p>Thanks for your time.</p>&#xA;&#xA;<p><strong>Edit:</strong></p>&#xA;&#xA;<p><em>Extended stacktrace of invalid partition key exception:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,35ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1} ---&gt; System.Runtime.InteropServices.COMException: exception of HRESULT: 0x80071BBF&#xA;   at System.Fabric.Interop.NativeClient.IFabricServiceManagementClient4.EndResolveServicePartition(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.FabricClient.ServiceManagementClient.ResolveServicePartitionEndWrapper(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.Interop.AsyncCallOutAdapter2`1.Finish(IFabricAsyncOperationContext context, Boolean expectedCompletedSynchronously)&#xA;   --- End of inner exception stack trace ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Client.ServicePartitionResolver.&lt;ResolveAsyncHelper&gt;d__2a.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;GetClientAsync&gt;d__a.MoveNext()&#xA;</code></pre>&#xA;&#xA;<p>Please give me feedback if you need more. (full stack trace is 82 lines long)</p>&#xA;&#xA;<p><em>Invalid scheme exception stack trace:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.ArgumentException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,45ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.ArgumentException: the provided uri scheme 'http' is invalid; expected 'net.tcp'.&#xA;Parametername: via&#xA;   at System.ServiceModel.Channels.TransportChannelFactory`1.ValidateScheme(Uri via)&#xA;   at System.ServiceModel.Channels.ConnectionOrientedTransportChannelFactory`1.OnCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ChannelFactoryBase`1.InternalCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.ServiceChannelFactoryOverDuplexSession.CreateInnerChannelBinder(EndpointAddress to, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateServiceChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateChannel(Type channelType, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, Binding binding, EndpointAddress endpointAddress)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Wcf.Client.WcfCommunicationClientFactory`1.&lt;CreateClientAsync&gt;d__2.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;CreateClientWithRetriesAsync&gt;d__1e.MoveNext()&#xA;</code></pre>&#xA;"
43426699,DB design for microservice architecture,2017-04-15 13:34:54,<database><design><microservices>,2,7671,0,4.0,8,"<p>I am planning to use the Microservices architecture for the implementation of our website. I wanted to know if it is right to share databases between services or if it is preferable to have a separate database for each service. In this regard, can I consider having one common database for all services or does it violate the very essence of Microservice architecture ?</p>&#xA;"
43313424,Consul and Spring Boot services in Docker - not deregistering,2017-04-10 00:36:46,<java><docker><spring-boot><microservices><consul>,2,585,1,2.0,8,"<p>So we have Java microservices written with Spring-Boot, using Consul for service discovery and config management and running in Docker containers.  All of it is working, but when a container dies or a service restarts the old service-id never goes away in Consul and the service forever after shows as ""Failing"" in the Consul UI, even though the new container has registered and shows all Green.</p>&#xA;&#xA;<p>We are not using heartbeat - but I cannot find much documentation on what the difference between heartbeat and healthcheck are for Consul.</p>&#xA;&#xA;<p>Here's my bootstrp.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: my-service&#xA;  cloud:&#xA;    config:&#xA;      enabled: false&#xA;    consul:&#xA;      host: ${discovery.host:localhost}&#xA;      port: ${discovery.port:8500}&#xA;      config:&#xA;        watch:&#xA;          wait-time: 30&#xA;          delay: 10000 &#xA;        profile-separator: ""-""&#xA;        format: FILES&#xA;      discovery:&#xA;        prefer-ip-address: true&#xA;        instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}&#xA;</code></pre>&#xA;&#xA;<p>There are other settings to enable heartbeat, but the docs say something about this putting more stress on the Consul cluster.</p>&#xA;&#xA;<p>Has anyone managed to get Consul and Spring Boot/Docker services to actually de-register automatically?  It actually doesn't cause any real problems, but it makes the Consul UI pretty useless to actually monitor for up/down services.</p>&#xA;"
43489589,.NET Core Microservice using RabbitMQ,2017-04-19 07:47:42,<c#><asp.net-web-api><.net-core><microservices><rawrabbit>,1,5075,2,1.0,8,"<p>I am planing to use Microservice architecture for a project. The selected technology stack is <code>.NET Core</code> with <code>Docker</code> and <code>RabbitMQ</code> as a simple service bus and this should be able to deploy on <code>Linux</code>.</p>&#xA;&#xA;<p>Lets say I have a <code>Payment</code> service and an <code>Order</code> Service, I want each of these services to expose <code>REST</code> endpoints. Because of that, I thought of making these two services as <code>.NET Core Web APIs</code>. </p>&#xA;&#xA;<p>But the problem is the inter-service communication using <code>RabbitMQ</code>. Whenever I get a new <code>order</code>, I want to publish an event using <code>RabbitMQ</code> and then listen to that event in <code>Payment</code> service to perform certain operations (database updates). But since these are <code>Web APIs</code>, I don't think it's possible to listen to events as I described. (I feel like I might have to use something like a console application to subscribe to events.)</p>&#xA;&#xA;<p>I would like to find the most viable method to achieve this using the best practices considering the scalability and extendability of the system.</p>&#xA;"
40458770,"Microservice to Microservice calls, authorization from a queue message",2016-11-07 06:05:22,<spring-security><jwt><microservices><netflix-zuul><keycloak>,2,1044,0,3.0,8,"<p><strong>Context:</strong> I'm creating a cloud platform to support multiple applications with SSO. I'm using <strong>Keycloak for authentication</strong> and <strong>Netflix Zuul for authorization</strong> (API Gateway) thru <strong>Keycloak Spring Security Adapter</strong>.</p>&#xA;&#xA;<p>Each microservice expect an Authorization header, which contains a valid JWT, from which it will take the username (sub) to process the request. Each microservice-to-microservice call should go thru Netflix Zuul first, passing the Authorization header to maintain a stateless validation. That strategy allow to every microservice to know who is the user (sub) who is invoking the microservice indirectly.</p>&#xA;&#xA;<p><strong>Problem/Question 1:</strong> What happens if a microservice is invoked from a queue message? One idea that I had is to storage in the queue the information related to the message + userInfo, and, create a dedicated microservice to process that kind of messages, with that approach this special microservice should read the userInfo from the queue and process the message.</p>&#xA;&#xA;<blockquote>&#xA;  <p>UPDATE 1: Per an email reply from another forum, storing the JWT in a queue isn't a good idea, since it could be mined easily.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Problem/Question 2:</strong> But, what happens if the previous special microservice wants to call another normal microservice which expect to receive a JWT in a header? Should this special microservice create by himself a JWT to impersonate the user and be able to call the regular microservices?</p>&#xA;&#xA;<p>Another solution that I thought was to storage the original JWT in the queue, but, what happens if the queue calls to the special microservice later? Just after the JWT is not valid anymore (it expired) and the microservice called will reject the request?</p>&#xA;&#xA;<p><strong>Possible solutions:</strong> (Updated per João Angelo discussion, see below)</p>&#xA;&#xA;<blockquote>&#xA;  <p>I should authenticate the requests from my users (<strong>Authorization code flow</strong>) and my services (<strong>Client credentials grant</strong>), both requests should contain user information in the payload. When the request it comes from the user, I need to validate that the payload user info match with the JWT claims. When the request comes from a service, I just need to trust in that service (as long as it is under my control).</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate very much your help. Thanks.</p>&#xA;"
40377377,Micro Services communication,2016-11-02 10:16:49,<java><spring><rest><spring-integration><microservices>,5,1062,0,4.0,8,"<p>I'm new to micro-services, and I'm trying to take my project and turn it into  A micro services based project. My problem is figuring out how each service communicates with each other.</p>&#xA;&#xA;<p>First, I explored the REST style service, but if each service is based HTTP REST how do they ""talk"" to each other after all?</p>&#xA;&#xA;<p>Then I tried to learn Spring Integration, but then it became even unclearer how should they communicate because now it came to my mind that maybe I need to use RabbitMQ to be the middleware between the front end and the micro services back end.</p>&#xA;&#xA;<p>I also run into cloud and Docker technologies, so I guess each service should be on the cloud but still it doesn't make it clear how services communicate.</p>&#xA;&#xA;<p>I'm using Java, Spring technologies.</p>&#xA;&#xA;<p>I'll be happy if someone would give me a better picture how things should be.</p>&#xA;"
45515650,Client per MicroService vs Generic Client | Who is responsible for microservice client?,2017-08-04 21:19:05,<distributed-computing><microservices>,1,156,1,2.0,8,"<p>I have a microService architecture with 10 microServices and each of those provides a client. Inside of that client which is managed/controlled by microService team we just receive the parameters and pass them to a generic http invoker which receives the endpoint and N params and then does the call.&#xA;All microService use http and web api (I guess technology doesn't matter).</p>&#xA;&#xA;<p>For me doesn't make sense to be the microService team to provide a client, should be the responsibility of the consumer, if they want to create some abstractions or invoke it directly is their problem, not a microService problem. And the way I see a web API is as a contract. So I think we should delete all clients (pass responsibility to consumers) on the microService side and create a service layer on the consumer's side that uses the generic invoker to reach the endpoints.</p>&#xA;&#xA;<p>The image below represents all components where the <strong>red line defines</strong> the boundaries, <strong>who is responsible for what</strong>:</p>&#xA;&#xA;<ul>&#xA;<li>The gateway has Adapter Layer </li>&#xA;<li>Adapter Layer references the microService client package </li>&#xA;<li>MicroService client package references Generic HTTP invoker package&#xA;<a href=""https://i.stack.imgur.com/EnjD5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/EnjD5.jpg"" alt=""enter image description here""></a></li>&#xA;</ul>&#xA;&#xA;<p>The other side of that is because we might have N number of consumers and they are all repeating the code of the client. And if the microService provides a client, we have a unique/central place to control that.</p>&#xA;&#xA;<p><strong>Which approach is correct? Is the client a responsability of the microService or the consumer?</strong></p>&#xA;&#xA;<p>This is an internal product.</p>&#xA;"
45551966,Can (or should) 2 docker containers interact with each other via localhost?,2017-08-07 16:50:30,<docker><docker-compose><microservices><consul><docker-networking>,3,938,1,2.0,8,"<p>We're dockerizing our micro services app, and I ran into some discovery issues.</p>&#xA;&#xA;<p>The app is configured as follows:</p>&#xA;&#xA;<p>When the a service is started in 'non-local' mode, it uses Consul as its Discovery registry.&#xA;When a service is started in 'local' mode, it automatically binds an address per service (For example, tcp://localhost:61001, tcp://localhost:61002 and so on. Hard coded addresses)</p>&#xA;&#xA;<p>After dockerizing the app (for local mode only, for now) each service is a container (Docker images orchestrated with docker-compose. And with docker-machine, if that matters)&#xA;But one service can not interact with another service since they are not on the same machine and tcp://localhost:61001 will obviously not work.</p>&#xA;&#xA;<p>Using docker-compose with <a href=""https://docs.docker.com/compose/compose-file/#links"" rel=""noreferrer"">links</a> and specifying localhost as an alias (service:localhost) didn't work. Is there a way for 2 containers to ""share"" the same localhost? </p>&#xA;&#xA;<p>If not, what is the best way to approach this?&#xA;I thought about using specific hostname per service, and then specify the hostname in the links section of the docker-compose. (But I doubt that this is the elegant solution)&#xA;Or maybe use a dockerized version of Consul and integrate with it?</p>&#xA;&#xA;<p>This post: <a href=""https://stackoverflow.com/questions/43547795/how-to-share-localhost-between-two-different-docker-containers"">How to share localhost between two different Docker containers?</a> provided some insights about why localhost shouldn't be messed with - but I'm still quite puzzled on what's the correct approach here.</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
28607400,Sessions in a Microservice architecture for an E-Commerce system,2015-02-19 13:15:53,<php><magento><soa><single-page-application><microservices>,4,1282,2,5.0,10,"<p>I plan on developing a microservice E-Commerce system as proof of concept. The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li><p>a javascript based single page application, which sends AJAX requests to</p></li>&#xA;<li><p>a server (API Gateway) with a REST API which feeds JSON data received by calling other services</p></li>&#xA;<li><p>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</p></li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento Shopsystem. </p>&#xA;&#xA;<p>When I try to log in a user into they Magento system by sending a request to the REST Api obviously the server doesn't remember the session when sending the next request.</p>&#xA;&#xA;<p>Also I handle the shopping cart on the server side with Magento and add/update/remove items by REST Api calls. Here, also the added items get lost when sending the next request as the session got lost.</p>&#xA;&#xA;<p>So my question is:</p>&#xA;&#xA;<p>What are possible approaches to solve issues regarding session handling in a microservice architecture?</p>&#xA;"
32741333,Session Management in microservices,2015-09-23 13:43:15,<java><session><cookies><weblogic><microservices>,1,9293,3,5.0,10,"<p>We have the following setup.</p>&#xA;&#xA;<ol>&#xA;<li>STM (Stingrey Traffic Manager) does load balancing + session stickiness</li>&#xA;<li>Weblogic 'cluster'</li>&#xA;<li>Auth handled by a third party tool</li>&#xA;</ol>&#xA;&#xA;<p>Therefore I do not have to worry about session with regards to horizontal scaling/ running multiple instances of the application. STM/ Weblogic cluster makes sure that the subsequent request come to same managed server.</p>&#xA;&#xA;<p>What we currently have is a monolithic application and we are trying to move to microservices. Also we do not wan't to move out of current infrastructure (i.e. STM/ Weblogic cluster/ Auth tool). What we have planned is:</p>&#xA;&#xA;<ol>&#xA;<li>A Gateway WAR which routes requests to other microservices</li>&#xA;<li>N x Microservices (WAR) for each functional sub-domain</li>&#xA;<li>Only the API Gateway receives user requests and other microservices are not accessible from outside</li>&#xA;</ol>&#xA;&#xA;<p>So my question is</p>&#xA;&#xA;<ol>&#xA;<li>Should API Gateway be state-full while other microsevices are stateless?</li>&#xA;<li>If so, how should the user session data be shared between API Gateway and microservices?</li>&#xA;</ol>&#xA;&#xA;<p>Please suggest any better alternatives and resources/links as well.  Thanks.</p>&#xA;"
30116581,Call frontend methods from external meteor application,2015-05-08 05:44:51,<meteor><meteor-accounts><microservices>,2,630,0,0.0,10,"<p>I am making a dockerized services-based application. Some of the services will be written in meteor, some won't.</p>&#xA;&#xA;<p>One of the services is a registration service, where users can register for the platform. </p>&#xA;&#xA;<p>When doing microservices, normally I do the following:</p>&#xA;&#xA;<pre><code>var MyService = DDP.connect(service_url);&#xA;var MyOtherService = DDP.connect(other_service_url);&#xA;var RegistrationService = DDP.connect(registration_service_url);&#xA;</code></pre>&#xA;&#xA;<p>What I want to do is use the <code>loginWithFacebook</code> method. The issue is that using <code>Meteor.loginWithFacebook</code> on the frontend will invoke its backend methods on the main frontend server. </p>&#xA;&#xA;<p>However, I want to invoke its backend methods on the RegistrationService server (which has the relevant packages). The reason is because I am using the <code>Accounts.onCreateUser</code> hook to do extra stuff, and also because I want to keep the registration service separate from the frontend.</p>&#xA;&#xA;<p>Just for clarity, even though it is not correct, imagine I have this:</p>&#xA;&#xA;<pre><code>'click #facebook-login': function() {&#xA;  Meteor.loginWithFacebook(data, callback)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I want the <code>loginWithFacebook</code> method to use the server-side methods from <code>RegistrationService</code> <strong>when calling the client-side method .loginWithFacebook</strong>, so I actually want to do something to the effect of the following:</p>&#xA;&#xA;<pre><code>'click #facebook-login': function() {&#xA;  RegistrationService.loginWithFacebook(data, callback)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any help on this will be greatly appreciated. Thank you!</p>&#xA;"
36461493,Customizing Zuul Exception,2016-04-06 20:17:50,<java><spring-boot><spring-cloud><microservices><netflix-zuul>,4,9134,5,6.0,10,"<p>I have a scenario in Zuul where the service that the URL is routed too might be down . So the reponse body gets thrown with 500 HTTP Status and ZuulException in the JSON body response.</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": 1459973637928,&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""com.netflix.zuul.exception.ZuulException"",&#xA;  ""message"": ""Forwarding error""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>All I want to do is to customise or remove the JSON response and maybe change the HTTP status Code.</p>&#xA;&#xA;<p>I tried to create a exception Handler with @ControllerAdvice but the exception is not grabbed by the handler.</p>&#xA;&#xA;<p><strong>UPDATES:</strong></p>&#xA;&#xA;<p>So I extended the Zuul Filter I can see it getting into the run method after the error has been executed how do i change the response then. Below is what i got so far. I read somewhere about SendErrorFilter but how do i implement that and what does it do?</p>&#xA;&#xA;<pre><code>public class CustomFilter extends ZuulFilter {&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        return ""post"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;&#xA;        return 1;&#xA;    }&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        return true;&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;        final RequestContext ctx = RequestContext.getCurrentContext();&#xA;        final HttpServletResponse response = ctx.getResponse();&#xA;        if (HttpStatus.INTERNAL_SERVER_ERROR.value() == ctx.getResponse().getStatus()) {&#xA;            try {&#xA;                response.sendError(404, ""Error Error""); //trying to change the response will need to throw a JSON body.&#xA;            } catch (final IOException e) {&#xA;                e.printStackTrace();&#xA;            } ;&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added this to the class that has @EnableZuulProxy</p>&#xA;&#xA;<pre><code>@Bean&#xA;public CustomFilter customFilter() {&#xA;    return new CustomFilter();&#xA;}&#xA;</code></pre>&#xA;"
35289988,Authorization and user microservices design,2016-02-09 10:46:09,<microservices>,2,856,2,4.0,10,"<p>I'm trying to design microservice from an existing application with a quite standard user management: has authentication and authorization, and stores user data.</p>&#xA;&#xA;<p>I'm developping an <em>Authorization server</em> to manage user <strong>authentication</strong> and <strong>authorization</strong> using <code>OAuth2</code> as authorization. On other side I have to store user's information/profile.</p>&#xA;&#xA;<p><strong>Question:</strong> Should <em>Authorization server</em> manage:</p>&#xA;&#xA;<ul>&#xA;<li><strong>both authorization and user API?</strong> Thus other microservices can contact <em>Authorization server</em> on <code>/me</code> to get current user but also <code>/users</code> to get full list of users.</li>&#xA;<li><strong>Or only authorization and I have to create <em>User microservices</em>?</strong> Thus <em>Authorization server</em> only exposes <code>/me</code> API related to user and <em>User microservices</em> will expose <code>/users</code>?</li>&#xA;</ul>&#xA;&#xA;<p>The first solution is a bit simpler but the <em>Authorization server</em> will become less generic (less reusable) because user application data model will be part of it (database data model of <code>User</code> table).</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>The other requirement is <strong><em>Authorization server</em> should check if a user exists before authorizing it</strong>. </p>&#xA;&#xA;<p>There is no user auto-creation, users must be invited by <em>administrator</em> to get access.&#xA;With this requirement, the first solution is simple because <em>Authorization server</em> has access to user database but the second solution <em>Authorization server</em> implies:</p>&#xA;&#xA;<ol>&#xA;<li>Share database with <em>User service</em> (hum don't like that)</li>&#xA;<li>Call <em>User service</em> before authorization using REST API (for example) </li>&#xA;<li><em>Authorization server</em> should maintain minimal <code>User</code> table (can be renamed <code>Account</code>) and administrator will not create user on <em>User service</em> but only user account on <em>Authorization server</em></li>&#xA;</ol>&#xA;&#xA;<p>I think <strong>1.</strong> solution is out but any advices about <strong>2.</strong> and <strong>3.</strong>?</p>&#xA;&#xA;<p><strong>3.</strong> in first place seems the best, but if I want to switch to another <em>Authorization server</em>, for example a public one (OAuth2) like Google, Github, Facebook, etc... Security can be compromise because we can't control user account creation.</p>&#xA;&#xA;<p>Any feedback?</p>&#xA;"
38786207,Netflix Feign - Propagate Status and Exception through Microservices,2016-08-05 09:46:14,<java><spring><spring-boot><microservices><netflix-feign>,4,13177,0,1.0,10,"<p>I'm using <a href=""https://github.com/OpenFeign/feign/blob/master/okhttp/src/main/java/feign/okhttp/OkHttpClient.java"" rel=""noreferrer"">Netflix Feign</a> to call to one operation of a Microservice A to other other operation of a Microservice B which validates a code using Spring Boot. </p>&#xA;&#xA;<p>The operation of Microservice B throws an exception in case of the validation has been bad. Then I handled in the Microservices and return a <code>HttpStatus.UNPROCESSABLE_ENTITY</code> (422) like next:</p>&#xA;&#xA;<pre><code>@ExceptionHandler({&#xA;       ValidateException.class&#xA;    })&#xA;    @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY)&#xA;    @ResponseBody&#xA;    public Object validationException(final HttpServletRequest request, final validateException exception) {&#xA;        log.error(exception.getMessage(), exception);&#xA;        error.setErrorMessage(exception.getMessage());&#xA;        error.setErrorCode(exception.getCode().toString());&#xA;        return error;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So, when Microservice A calls to B in a interface as next:</p>&#xA;&#xA;<pre><code>@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /other"")&#xA;void otherOperation(@Param(""other"")  String other );&#xA;&#xA;@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /code/validate"")&#xA;Boolean validate(@Param(""prefix"") String prefix);&#xA;&#xA;static PromotionClient connect() {&#xA;&#xA;    return Feign.builder()&#xA;        .encoder(new GsonEncoder())&#xA;        .decoder(new GsonDecoder())&#xA;        .target(PromotionClient.class, Urls.SERVICE_URL.toString());&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the validations fails It returns a internal error 500 with next message:</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": ""2016-08-05T09:17:49.939+0000"",&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""feign.FeignException"",&#xA;  ""message"": ""status 422 reading Client#validate(String); content:\n{\r\n  \""errorCode\"" : \""VALIDATION_EXISTS\"",\r\n  \""errorMessage\"" : \""Code already exists.\""\r\n}"",&#xA;  ""path"": ""/code/validate""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I need to return the same as the Microservice operation B.</p>&#xA;&#xA;<p>Wich would be the best ways or techniques to propagate Status and Exceptions through microservices using Netflix Feign?</p>&#xA;"
44884316,How to implement contract testing when kafka is involved in microservice architecture?,2017-07-03 11:23:29,<java><jvm><apache-kafka><microservices><pact>,1,1471,0,2.0,10,<p>I am currently working on a project where we have kafka implementation in micro service architecture. Were you successful in creating contract test cases for mS to kafka topic interaction please using pact-jvm ?</p>&#xA;&#xA;<p>My implementation is microservice1 publishes a message to a REST Client which in turn posts the message to Kafka Topic. microservice2 uses GET method to retrieve messages from the Kafka Topic.</p>&#xA;
41010290,Microservices: REST vs Messaging,2016-12-07 05:49:29,<rest><architecture><messaging><microservices>,2,5671,2,2.0,10,"<p>I heard Amazon uses HTTP for its microservice based architecture. An alternative is to use a messaging system like RabbitMQ or Solace systems. I personally have experience with Solace based microservice architecture, but never with REST. <br>&#xA;Any idea what do various big league implementations like Amazon, Netflix, UK Gov etc use?<br>&#xA;Other aspect is, in microservices, following things are required (besides others):<br>&#xA;* Pattern matching<br>&#xA;* Async messaging.. receiving system may be down<br>&#xA;* Publish subscribe<br>&#xA;* Cache load event.. i.e. on start up, a service may need to load all data from a couple of other services, and should be notified when data is completely loaded, so that it can 'know' that it is now ready to service requests&#xA;<br>&#xA;These aspects are naturally done with messaging rather than REST. Why should anyone use REST (except for public API). Thanks.</p>&#xA;"
43983286,GraphQL and Microservices,2017-05-15 15:26:09,<rest><architecture><microservices><graphql>,2,1942,0,7.0,10,"<p>At my company we've decided on a microservice architecture for a new project.&#xA;We've taken a look at GraphQL and realised its potential and advantages for using as our single API endpoint.</p>&#xA;&#xA;<p>What we disagree on is how the communication should be done between GraphQL and each micro service. Some argue for REST, others say we should also have a graphQL endpoint for each service. </p>&#xA;&#xA;<p>I was wondering what are some of the pros and cons of each.&#xA;For example, having everything in graphQL seems a bit redundant, as we'd be replicating parts of the schema in each service.&#xA;On the other hand, we're using GraphQL to avoid some REST pitfalls. We're afraid having REST endpoints will nullify the advantages gained from gQL.</p>&#xA;&#xA;<p>Has anyone come across a similar dilemma?&#xA;None of us are experienced with GraphQL, so is there some obvious pro and con here that we might be missing?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
40495213,Service fabric projects in separate git repos,2016-11-08 19:46:45,<c#><azure><microservices><azure-service-fabric>,4,514,1,3.0,10,<p>Following a normal microservices framework we would like to place each microservice in it's own git repo and then have one repository for the Service Fabric project.  When we update one of the microservice the though would be that the Service Fabric project would redeploy just that service.</p>&#xA;&#xA;<p>Is there any examples of splitting the Service Fabric project up like this?  I've noticed in all of their examples everything is in one solution/repository.</p>&#xA;
43612866,Microservices with shared database? using multiple ORM's?,2017-04-25 14:01:50,<database><orm><microservices>,2,7791,3,3.0,10,"<p>I'm learning about microservices and I'm gonna build a project with a microservices architecture.</p>&#xA;&#xA;<p>The thing is, one of my team mates want to use one database for all services, sharing all tables so ""data doesn't get repeated"", each service would be built with different frameworks and languages like django and rails which use very different ORM standards.</p>&#xA;&#xA;<p>What would be the correct approach? Since I think working with one database would involve a lot of ""hacking"" the ORMs in order to make them work correctly.</p>&#xA;"
25965275,what suitable Scala framework can I choose to use for microservice,2014-09-22 00:36:00,<scala><microservices>,1,1197,1,0.0,-2,"<p>Currently, I am using finagle Scala web framework as microservice for our project, They are very easy to use and also convenient to be deployable. At the same time, my colleague are trying to use Play framework for micro service, but I think it is too huge. It is not micro anymore. </p>&#xA;&#xA;<p>May I know what is your opinion about this and is there any other good microservice framework in scala should be taken into consideration ?</p>&#xA;&#xA;<p>Many thanks in advance</p>&#xA;"
36415988,Is there some crashreporting library for java applications?,2016-04-05 02:17:38,<java><monitoring><microservices><reliability>,1,56,3,0.0,-2,"<p>I wan't to be able to perform Asserts in production runtime, and send out crash reports (with CRITICAL or WARNING messages) through different channels. Emails being one of them.</p>&#xA;&#xA;<p>As you can see, I wan't this library to be performing collection of most commonly required stats - like Stacktrace, Host details, configurations etc. </p>&#xA;"
50629814,"Javascript library to collect objects properties, do batch processing and map results back to objects",2018-05-31 17:33:21,<javascript><node.js><microservices>,3,65,0,0.0,-2,"<p>For array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1},&#xA;    {id: 2, name: ""test"", tagId: 15},&#xA;    {id: 3, name: ""test"", tagId: 5},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Need to reduce list of specific properties (tagId) to unique array [1,15,5], call some batch processing method, for example, doing http request for API for list of entities:</p>&#xA;&#xA;<pre><code>async (ids) =&gt; await axios.get('http://apihost/tag', {id: ids})&#xA;</code></pre>&#xA;&#xA;<p>For result array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""tag1""},&#xA;    {id: 15, name: ""tag2""},&#xA;    {id: 5, name: ""tag3""},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Finally need to map this objects by ID attribute to original array of objects matching by result.id => original.tagId, in fact doing an SQL join of two arrays to get this (like <a href=""https://github.com/mtraynham/lodash-joins"" rel=""nofollow noreferrer"">https://github.com/mtraynham/lodash-joins</a>):</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1, tag: {id: 1, name: ""tag1""}},&#xA;    {id: 2, name: ""test"", tagId: 15, tag: {id: 15, name: ""tag2""}},&#xA;    {id: 3, name: ""test"", tagId: 5, tag: {id: 5, name: ""tag3""}},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>I'm already wrote a PHP library for this with API like:</p>&#xA;&#xA;<pre><code>new BulkMap(source).map(&#xA;  'tagId',&#xA;  'tag',&#xA;  async (ids) =&gt; axios.get('http://apihost/tag', {id: ids})&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>But now i need this in JS. Is there any Javascript/NodeJS library to do so? It looks like pretty common used pattern for microservices.</p>&#xA;"
40884616,REST based message queue for microservices,2016-11-30 09:29:26,<java><activemq><message-queue><microservices>,1,660,3,0.0,-2,"<p>I'm given a task to implement Message queue to publish and consume message over queue but my requirement is, i'm gonna need to interact with queue using REST API (eg: ActiveMQ having REST API but problem with ActiveMq is when implementing consumer  we don't have way to keep waiting for message queue to fetch,we cant listen to the queue using REST client ).&#xA;So  i'm leaving my problem to you guys to give me better alternative for this &#xA;NOTE - solution should use only open source product only </p>&#xA;"
49910421,Is this microserviced?,2018-04-18 23:21:42,<java><spring-boot><microservices>,3,59,5,3.0,-2,"<p>I have created a simple blogging application using Spring Boot and RESTful APIs.  I have connected the same to a MySQL database to run some SQL queries like those for adding a blog, deleting a blog, etc.</p>&#xA;&#xA;<p>My questions are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>Does it mean that I have used a <em>microservice</em> architecture?  When does an architecture become a <em>microservice</em>? (I ask because many similar websites call an application as microservice-based.  Other than the main application, e.g., currency exchange instead of blogging, I see no other difference; for e.g., <a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">this one</a> - it does have many more aspects, but they are not contributing to its <em>microservice</em>-ness, IMHO).  </p></li>&#xA;<li><p>Can I call an application as horizontally scalable if I am using <em>microservice-based</em> architecture?</p></li>&#xA;</ol>&#xA;&#xA;<p>Note:  The tutorial I followed is <a href=""https://medium.com/@salisuwy/building-a-spring-boot-rest-api-part-iii-integrating-mysql-database-and-jpa-81391404046a"" rel=""nofollow noreferrer"">here</a> and the GitHub repo is <a href=""https://github.com/salisuwy/building-spring-boot-resp-api-v3"" rel=""nofollow noreferrer"">here</a>.</p>&#xA;"
43593778,Microservices design,2017-04-24 16:53:13,<java><spring><microservices>,1,122,9,1.0,-2,"<p>I am new to microservices and I am getting a hardtime in understanding what they exactly are. I would take an example situation, if you can break it down to how microservices should be written for this scenario then it woud be really great. </p>&#xA;&#xA;<p>Scenario: I have to work with two content management systems: Documentum and IBM FileNet.</p>&#xA;&#xA;<p>For each content management system I want to write an implementation to - </p>&#xA;&#xA;<ol>&#xA;<li>Create a new file or a folder.</li>&#xA;<li>Update a fileor a folder. </li>&#xA;<li>Delete a fileor a folder.</li>&#xA;<li>Update fileor folder metadata.</li>&#xA;<li>Search a file.</li>&#xA;<li>Get content of a file.</li>&#xA;<li>Create and Update permission sets applied on file or folder.&#xA;etc. </li>&#xA;</ol>&#xA;&#xA;<p>How should I break this down to microservices? &#xA;Should I write implementation for each content management systems in a seperate microservice? </p>&#xA;&#xA;<p>Please help.</p>&#xA;&#xA;<p>Thanks </p>&#xA;"
26247474,Is Apache Camel irrelevant when Spring Cloud is used?,2014-10-08 00:38:08,<apache-camel><mule><spring-boot><microservices><spring-cloud>,1,1095,0,0.0,-1,"<p>I am involved in the design of a service that uses Spring Cloud and Apache Camel. I was taken aback today when a colleague asked (maybe advocating would be a better term) whether we really need Apache Camel. From his perspective, most of the downstream systems we talk to are REST-based and therefore, no integration framework should be needed. If my recollection is correct, he also implied that Microservices and Integration Frameworks are incompatible.</p>&#xA;&#xA;<p>I started passionately suggesting that Spring Cloud helps solve a deployment/ops issue while Integration frameworks solve integration issues and that they have orthogonal requirements.</p>&#xA;&#xA;<p>Here are some of the protocols the system will be using to communicate:</p>&#xA;&#xA;<pre><code>REST&#xA;SOAP&#xA;AMQP&#xA;Azure SDK&#xA;AWS SDK (S3, SimpleBD, etc.)&#xA;Dropbox SDK&#xA;Paypal SDK&#xA;Braintree SDK&#xA;Caching (Memcached, EhCache)&#xA;Async (VM, Direct-VM, SEDA, SEDA-VM)&#xA;Facebook&#xA;Twitter&#xA;FTP&#xA;SMTP&#xA;File IO&#xA;SOLR/Elesticsearch&#xA;Quartz&#xA;</code></pre>&#xA;&#xA;<p>Unknown protocols: as we integrate in customers environment we need to integrate with their systems. The communication protocols are yet unknown.</p>&#xA;&#xA;<p>The following statement by Martin Fowler and James Lewis seems to suggest that ESB and Microservices are incompatible: ""We can't resist mentioning Jim Webber's statement that ESB stands for ""Egregious Spaghetti Box"". Now, how far do you think this statement applies to an integration framework such as Apache Camel?</p>&#xA;&#xA;<p>And more generally, does my colleague have a point? Does this mean that integration patterns have no place in microservices?</p>&#xA;"
25974964,Are micro-services in low latency systems a good recommendation?,2014-09-22 13:08:57,<java><design><low-latency><microservices>,1,609,2,0.0,-1,"<p>I am building a low latency system that does some currency exchange transactions to some exchanges and a friend recently told me that my micro-services approach is going to make things slower... I don't fully agree with him, and I think that it should be no major impact in performance and micro-services is the right path to go in order to have a more maintainable system. &#xA;I would be happy in getting some feedback from you to see what do you think about this topic.</p>&#xA;&#xA;<p>More specifically, in use case, I have an app that queries some data from some provider, transforms it to a JSon and sends it to the next application. The second application unmarshall the JSonMessage do some calculations, marshalls again and sends it to the third application. The third and last application its very simple it just needs to perform an operation in some currency exchanges with that message.  </p>&#xA;&#xA;<p>So my friend says that I should embed all 3 apps into 1 due to lack of performance when marshalling and unmarshalling... I can clearly distinguish different reasons to exist independently to each of the 3 apps, and I don't think it will be problematic to work in this style. Also I want to mention that I don't use any database or any sort of state, the hold system its completely stateless.</p>&#xA;"
28635179,Microservices with Flask,2015-02-20 17:50:37,<python><flask><docker><soa><microservices>,1,3560,0,0.0,-1,"<p>We are building a pretty large system that will expose several different REST API's, contain a Mongodb database, a Redis cache layer, and a backend computational library. Currently we are using Flask-Restful for building our API's, but for various reasons we also need to run another instance of Flask that provides database resources, and another layer on top of a front facing site. Blueprints are not really a solution since we might want to decouple these various services on different machines in ec2.</p>&#xA;&#xA;<p>We were planning to use Apache+WSGI as a production server, however each flask server would require a unique port, and it is a nightmare to manage all these microservices. I've heard of the concept of a gateway API, but I couldn't really find an documentation on how to implement one or how that looks in practice. </p>&#xA;&#xA;<p>Microservices/SOA seems like a really huge deal these days and in some sense our architecture is designed around that. But I am having trouble finding any info on how to do that in practice, especially in our specific setup. Management of all these servers seems like a potential nightmare. It feels like using Docker could solve most of our headaches, but I'm really curious to know what people did before containers.</p>&#xA;&#xA;<p>TLDR: Have lots of flask servers that are making up our microservice architecture. Have no idea how to manage that.</p>&#xA;"
49036468,Inter-Process communication in a microservices architecture,2018-02-28 18:44:13,<web-services><ipc><microservices>,6,171,0,0.0,-1,"<p>we are moving from monolithic to microservice architecture application, we're still in planning phase and we want to know what is the best practices of building it.</p>&#xA;&#xA;<p>suppose we have two services :</p>&#xA;&#xA;<ol>&#xA;<li><strong>User</strong> </li>&#xA;<li><strong>Device</strong>&#xA;&#xA;<ul>&#xA;<li>getUserDevices(UserId)</li>&#xA;<li>addDevice(DeviceInfo, UserId)</li>&#xA;<li>...</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p><strong>Each user has multiple devices</strong></p>&#xA;&#xA;<p>what is the most common, cleaner and proper way of asking the server to get all user devices ?</p>&#xA;&#xA;<p>1- <strong>{api-url}/User/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>needs another HTTP request to communicate with Device service.</p>&#xA;  &#xA;  <p>for user X, get linked devices from <strong>User</strong> service.</p>&#xA;</blockquote>&#xA;&#xA;<p>// <strong>OR</strong></p>&#xA;&#xA;<p>2- <strong>{api-url}/Device/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>for user X, get linked devices from <strong>Device</strong> service.</p>&#xA;</blockquote>&#xA;"
36026454,SFTP ChannelSftp.put stop it's execution process but successfully being uploaded or copy the source file,2016-03-16 03:49:51,<java><sftp><dropwizard><jsch><microservices>,1,571,5,1.0,-1,"<p>details:</p>&#xA;&#xA;<p>in my API i have struggle on debugging why is that the ChannelSftp.put method hangs up or stop it's execution process but when checking it's output it is successfully being uploaded. </p>&#xA;&#xA;<p>here's my code snippet:</p>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>@Inject&#xA;MyConfiguration conf;&#xA;&#xA;public String copyAndMove( String fileName ){&#xA;    try{&#xA;        MyServer origin = conf.getOriginServer().setFileName( fileName );&#xA;        MyServer destination = conf.getDestinationServer().setFileName( fileName );&#xA;&#xA;        SFTPServer originSftpServer = new SFTPServer( origin ).build();&#xA;        SFTPServer destinationSftpServer = new SFTPServer( destination ).build();&#xA;&#xA;        // originSftpServer.copyTo(destinationSftpServer);&#xA;        originSftpServer.copyTo(originSftpServer);&#xA;&#xA;        return ""Successfully copied file."";&#xA;        }catch( Exception ex ){&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>SFTPServer.class</p>&#xA;&#xA;<pre><code>public class SFTPServer {&#xA;&#xA;    private MyServer server;&#xA;    private static SFTPServer instance;&#xA;&#xA;    private Session session = null;&#xA;    private Channel channel = null;&#xA;    private ChannelSftp channelSftp = null;&#xA;&#xA;    // getters and setters&#xA;&#xA;    public SFTPServer(){}&#xA;&#xA;    public SFTPServer(MyServer server) throws  Exception{&#xA;        if(CommonUtil.isNull( server )){&#xA;            throw new Exception(""MyServer cannot be null!"");&#xA;        }&#xA;&#xA;        this.server = server;&#xA;    }&#xA;&#xA;    public SFTPServer build(){&#xA;        try{&#xA;            this.session = SFTPUtil.constructSession(getServer());&#xA;            this.channel = SFTPUtil.constructChannel(getSession());&#xA;            this.channelSftp = (ChannelSftp) channel;&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;&#xA;    public SFTPServer copyTo( SFTPServer destination ) {&#xA;        InputStream is = null;&#xA;        try{&#xA;            ChannelSftp channel = destination.getChannelSftp();&#xA;            String originSourceFile = String.format(""%s/%s"", getServer().getSourceFilePath(), getServer().getFileName());&#xA;            String destinationProcessedFile = String.format(""%s/%s"", destination.getServer().getProcessedFilePath(), destination.getServer().getFileName());&#xA;&#xA;            is = getChannelSftp().get(originSourceFile);&#xA;            channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }finally{&#xA;            CommonUtil.closeQuitely(is); // close input stream&#xA;            destination.destroy(); // disconnect session, channel, channelSftp&#xA;        }&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is this. it's seems that it cannot proceed until the program done for it's execution. when i debug on it it stop and it's execution for this code: <strong>channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);</strong> but on the sftp server it is successfully being copied from source to destination file path. please help me with this problem because it cannot return the <strong>Successfully copied file.</strong> on the service part. thanx. </p>&#xA;"
47767993,Split Rails app to small microservices with Go,2017-12-12 08:16:08,<ruby-on-rails><go><microservices>,1,126,0,2.0,-1,"<p>I'm wondering to do some scaling on our Rails app and I'd like to use Go lang. So, today we have quite big application written in RoR and Postgresql, where a lot of processing&amp;computations goes through Ruby which turned to be slow. </p>&#xA;&#xA;<p>I'm wondering to take some parts of our application, and to re-write them in Golang for the sake of better performances. </p>&#xA;&#xA;<p>I'd like to hear some good advices&amp;practices, especially how to start splitting them. How Go&amp;Rails can communicate and how to move some <strong>hard</strong> computations to Go ? Is there some way they can share same database/data ? </p>&#xA;&#xA;<p>Best Regards</p>&#xA;"
42105805,Microservices Communication Design,2017-02-08 06:03:09,<python><api><microservices>,2,629,0,0.0,-1,<p>I would like to know how to create a communication for each services. I am using API Gateway for the outside of the system to communicate with the services within. Is it necessary for a service to call another service through API Gateway or just directly into the service itself ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;
38403001,How to listen two micro services on same port in Node.js,2016-07-15 18:33:54,<node.js><microservices>,1,760,9,1.0,-1,"<p>I am new to micro service. I want to create one application with two micro services. But i don't know how to listen both (or more) micro services on a same port to make it as one application. &#xA;Is there any good tutorial pages available in online ? Please suggest me any blogpost or tutorial pages or help me to create a application with two micro services.</p>&#xA;&#xA;<p>I am trying to create a Bus booking application which has two services, </p>&#xA;&#xA;<ol>&#xA;<li>Bus Service (which gives bus names &amp; availability)</li>&#xA;<li>User Service (which gives &amp; connect user details with bus).</li>&#xA;</ol>&#xA;&#xA;<p>I created two this as two nodejs application. Now i need to know how to combine this two as one application (with microservice).for that i can't listen this to one port.</p>&#xA;"
51206924,how many hours each container is started,2018-07-06 09:14:01,<docker><microservices><swarm>,3,52,1,1.0,-1,"<p>how many hours each container is started</p>&#xA;&#xA;<p>Hi, I need know if have any tool or idea for take metrics, I want know how many hours, each container is up .</p>&#xA;&#xA;<p>This is possible actuality?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
51277418,mvn clean install -PbuildDocker don't work,2018-07-11 04:44:46,<java><spring><microservices>,2,64,3,0.0,-1,"<p>It is my error info:</p>&#xA;&#xA;<pre><code>Step 9/10 : EXPOSE ${EXPOSED_PORT}&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] Reactor Summary:&#xA;│[INFO]&#xA;│[INFO] spring-petclinic-microservices ..................... SUCCESS [ 0.246 s]&#xA;│[INFO] spring-petclinic-admin-server ...................... FAILURE [ 10.753 s]&#xA;│[INFO] spring-petclinic-monitoring ........................ SKIPPED&#xA;│[INFO] spring-petclinic-customers-service ................. SKIPPED&#xA;│[INFO] spring-petclinic-vets-service ...................... SKIPPED&#xA;│[INFO] spring-petclinic-visits-service .................... SKIPPED&#xA;│[INFO] spring-petclinic-config-server ..................... SKIPPED&#xA;│[INFO] spring-petclinic-discovery-server .................. SKIPPED&#xA;│[INFO] spring-petclinic-api-gateway ....................... SKIPPED&#xA;│[INFO] spring-petclinic-tracing-server .................... SKIPPED&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] BUILD FAILURE&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] Total time: 11.951 s&#xA;│[INFO] Finished at: 2018-07-11T10:30:27+08:00&#xA;│[INFO] Final Memory: 75M/651M&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;│ng-petclinic-admin-server: Exception caught: EXPOSE requires at least one argument -&gt; [Help 1]&#xA;│[ERROR]&#xA;│[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;│[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;│[ERROR]&#xA;│[ERROR] For more information about the errors and possible solutions, please read the following artic&#xA;│les:&#xA;│[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;│[ERROR]&#xA;│[ERROR] After correcting the problems, you can resume the build with the command&#xA;│[ERROR] mvn -rf :spring-petclinic-admin-server&#xA;</code></pre>&#xA;&#xA;<p>It seems like the expose require an argument. What it should be?</p>&#xA;&#xA;<p>This is the dockerfile.</p>&#xA;&#xA;<p>I have tried to set <code>EXPOSE_PORT</code> to <code>22</code> and <code>8899</code> which doesn't work.&#xA;This error info:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;│ng-petclinic-admin-server: Exception caught: Request error: POST unix://localhost:80/build?buildargs=&#xA;│%7B%22ARTIFACT_NAME%22%3A%22spring-petclinic-admin-server-1.5.9%22%2C%22EXPOSED_PORT%22%3A%229090%22%&#xA;│7D&amp;t=mszarlinski/spring-petclinic-admin-server: 500: HTTP 500 Internal Server Error -&gt; [Help 1]&#xA;│[ERROR]&#xA;</code></pre>&#xA;&#xA;<h2>Thanks!</h2>&#xA;&#xA;<p>This is the plugin apart of pom.xml about admin-server:</p>&#xA;&#xA;<pre><code>&lt;profiles&gt;&#xA;    &lt;profile&gt;&#xA;        &lt;id&gt;buildDocker&lt;/id&gt;&#xA;        &lt;build&gt;&#xA;            &lt;plugins&gt;&#xA;                &lt;plugin&gt;&#xA;                    &lt;groupId&gt;com.spotify&lt;/groupId&gt;&#xA;                    &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;&#xA;                    &lt;version&gt;${docker.plugin.version}&lt;/version&gt;&#xA;                &lt;/plugin&gt;&#xA;            &lt;/plugins&gt;&#xA;        &lt;/build&gt;&#xA;    &lt;/profile&gt;&#xA;&lt;/profiles&gt;&#xA;</code></pre>&#xA;"
45115860,how to use golang microservices?,2017-07-15 07:49:07,<go><microservices>,3,381,1,3.0,-1,"<p>My company use Go to build some HTTP API services. We want these services share one HTTP port. </p>&#xA;&#xA;<p>So the solution right now is we create a project named router, and router import some modules, every request pass through router to their own modules.<br>&#xA;But the question is that if one of these modules process crashed, the router just crash.</p>&#xA;&#xA;<p>Is there any solutions?</p>&#xA;&#xA;<p>Require:</p>&#xA;&#xA;<ol>&#xA;<li>One http port.</li>&#xA;<li>Every service is independent.</li>&#xA;</ol>&#xA;&#xA;<p>I know go-kit and go micro, also I have tried, but still not too understand.</p>&#xA;"
44000273,Micro service Architecture based on RESTful API's in java,2017-05-16 11:30:28,<java><rest><design-patterns><microservices>,3,152,4,0.0,-1,"<p>Best Architecture for implementing a <strong>WebService</strong> that takes requests from one side, save and enhance that and then call another service with new parameters.&#xA;is there any special <code>Design Pattern</code> for this?</p>&#xA;"
35838016,Which microservice library is best or mostly used?,2016-03-07 07:08:50,<microservices>,1,472,3,0.0,-1,<p>I am split my business logic into micro services. Which micro services library is good or mostly used? what about apache karaf? </p>&#xA;
46390552,which is the best API gateway for micro services using spring?,2017-09-24 13:27:44,<spring-boot><microservices>,1,1655,0,0.0,-1,"<p>I am trying to build a simple application with microservices architecture.&#xA;Below are the details about 3 microservices I have created.</p>&#xA;&#xA;<pre><code>1] Customer.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8081&#xA;2] vendor.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8082&#xA;3] product.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8083&#xA;</code></pre>&#xA;&#xA;<p>All the 3 micros runs on an embeded tomcat server.&#xA;Now I want to create a common gateway for all these micros [API gateway].&#xA;which help me to route my request based on the request I get for example:-&#xA;for example if I get a request of <a href=""http://hostname:port_of_gateway/customer"" rel=""nofollow noreferrer"">http://hostname:port_of_gateway/customer</a>.&#xA;on reading this I need to route the request tom my customer micro and fetch its response and send it back to client.&#xA;Which of the spring tool I can use to achieve this?</p>&#xA;"
46321680,How correctly make project structure in IntelliJ IDEA for Spring Boot microservices?,2017-09-20 12:08:32,<java><spring-boot><intellij-idea><microservices>,1,662,2,0.0,-1,<p>I used to work with Monolithic architecture and I don't have experience with Microservices. I need to create project with some modules (microservices).</p>&#xA;&#xA;<ol>&#xA;<li>auth </li>&#xA;<li>messages</li>&#xA;</ol>&#xA;&#xA;<p>I use IntelliJ IDEA for my project.</p>&#xA;&#xA;<p>Can you explain me what is the best practice for microservices project structure in this IDE?</p>&#xA;&#xA;<p>Should I use Maven or it is better to add IntelliJ IDEA project modules?</p>&#xA;
50448620,Issue while using the kubernetes annotations,2018-05-21 12:10:46,<kubernetes><microservices>,3,151,0,0.0,-1,"<p>I've read documentation of kubernetes annotations. </p>&#xA;&#xA;<p>But I couldn't find basic example about using this annotations. For Example;</p>&#xA;&#xA;<p>I have a deployment yaml like below:</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  annotations:&#xA;    test_value: ""test""&#xA;  name: nginx-deployment&#xA;  labels:&#xA;    app: nginx&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: nginx&#xA;    spec:&#xA;      containers:&#xA;      - name: nginx&#xA;        image: nginx:1.13&#xA;        ports:&#xA;        - containerPort: 80&#xA;</code></pre>&#xA;&#xA;<p>How can I use this annotation named test_value and where.</p>&#xA;&#xA;<p>Best Regards...</p>&#xA;"
43492974,Multiple docker services to listen on same host and port,2017-04-19 10:23:58,<nginx><docker><docker-compose><microservices><jwilder-nginx-proxy>,1,578,0,0.0,-1,"<p>i am new to nginx and I am not sure is this normal behavior...</p>&#xA;&#xA;<p>Here is the lib I am using: <a href=""https://github.com/jwilder/nginx-proxy"" rel=""nofollow noreferrer"">https://github.com/jwilder/nginx-proxy</a></p>&#xA;&#xA;<p>I will explain here what I trying to accomplish... </p>&#xA;&#xA;<p>I have 2 additional services <code>service1</code> and <code>service2</code> those services are simple node.js images with API endpoints</p>&#xA;&#xA;<pre><code>service1 have routes:&#xA;- service1/api/first&#xA;- service1/api/second&#xA;`&#xA;&#xA;`&#xA;service2 have routes:&#xA;- service2/api/third&#xA;- service2/api/fourth&#xA;`&#xA;&#xA;So is possible to be able to access this services from same host, like this:&#xA;localhost/service1/api/first&#xA;localhost/service2/api/third&#xA;?&#xA;&#xA;I tried like this:&#xA;&#xA;My `docker-compose.yml` file:&#xA;&#xA;&#xA;version: '2'&#xA;services:&#xA;  nginx-proxy:&#xA;    image: jwilder/nginx-proxy&#xA;    container_name: nginx-proxy&#xA;    ports:&#xA;      - ""80:80""&#xA;    volumes:&#xA;      - /var/run/docker.sock:/tmp/docker.sock:ro&#xA;&#xA;  whoami:&#xA;    image: jwilder/whoami&#xA;    environment:&#xA;      - VIRTUAL_HOST=whoami.local&#xA;  service1:&#xA;    image: mynode:1.1&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service1.local&#xA;      - VIRTUAL_PORT=8080&#xA;  service2:&#xA;    image: mynodeother:1.2&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service2.local&#xA;      - VIRTUAL_PORT=8081&#xA;</code></pre>&#xA;&#xA;<p>Here is generated config file from command <code>docker exec nginx-proxy cat /etc/nginx/conf.d/default.conf</code>:&#xA;<a href=""http://pushsc.com/show/code/58f739790a58d602a0b99d22"" rel=""nofollow noreferrer"">http://pushsc.com/show/code/58f739790a58d602a0b99d22</a></p>&#xA;&#xA;<p>Also when I visit localhost in browser I get: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Welcome to nginx!</p>&#xA;  &#xA;  <p>If you see this page, the nginx web server is successfully installed&#xA;  and working. Further configuration is required.</p>&#xA;  &#xA;  <p>For online documentation and support please refer to nginx.org.&#xA;  Commercial support is available at nginx.com.</p>&#xA;  &#xA;  <p>Thank you for using nginx.</p>&#xA;</blockquote>&#xA;"
41749456,How to integrate Machine learning into a ruby on rails application,2017-01-19 18:47:59,<python><ruby-on-rails><r><ruby><microservices>,1,1288,0,1.0,-1,"<p>Given Python and R have huge machine learning libraries that make it easy to train a machine learning model, and given rails provides a very fast way of building a web app, is there a 'best practice' for integrating a machine learning model (written in python or R) into a rails application? </p>&#xA;&#xA;<p>If so what tools can we use? What are pros and cons of each?</p>&#xA;"
51842460,Miscroservice Intercommunication with RabbitMQ,2018-08-14 13:18:11,<java><rabbitmq><microservices><messaging>,1,43,4,0.0,-1,"<p>I'm new in the worls of Microservices and I'm buildung a pretty basic Architecture the combine the basic components I might need for a later project.&#xA;My enviroment is eclipse using spring.&#xA;So I thought about having 3 different Microservices.&#xA;Service A does a simple calculation after a rest call and writes the parameters, the operand and the result in a database.&#xA;Service B should read the the last result from the database.&#xA;Service C should take the last 10 results from the Database.</p>&#xA;&#xA;<p>So after reading about best practice handling this task I thought about realizing it asynchronous. So A should message B and C when the result is written into the database so that they can read their needed values in parallel from the database instead of on waiting for another.&#xA;I found a pretty good tutorial where I think I got the code I need <a href=""https://www.youtube.com/watch?v=c7cWKZlgnNc"" rel=""nofollow noreferrer"">here</a> &#xA;I thought about running an instance of RabbitMQ on my localhost:9999 for example.&#xA;Then I would set Service A my message producer and B and C as my consumers with registering the connection to this adress. To communicate I would do one queue for each service where I send the signal when A is finished.&#xA;Is this a proper solution for this task and is my plan of realizing it reliable? Or do you have any better solution?&#xA;I hope this is not a dump question.&#xA;Thank you guys</p>&#xA;"
51454764,View injection container for angular,2018-07-21 09:38:02,<angular><dependency-injection><microservices><view-injection><micro-frontend>,1,49,3,1.0,-1,"<p>I'm trying to have an angular module for each backend microservice. So to keep each module independent and clean while they use each other's components when available and a default ""service-is-not-available"" component, when the component is not found in the container.</p>&#xA;&#xA;<p><strong>Example Scenario:</strong> Let's say there are a sales and accounting module.&#xA;The sales module needs a component with selector: 'total-price'.&#xA;Sales module and Accounting module are both used by the main module, but the sales doesn't know about accounting.&#xA;When I call the 'total-price' tag in sales I want the main module to find it in the accounting and display it in the sales.</p>&#xA;&#xA;<p>Here the 'total-price' tag selector works like an abstraction (OO interface) which it's implementation is placed at accounting module, and the main module should have an IOC to search and find the implementation an inject it to the sales, and return a not found view if the view is unavailable (kind of like null object pattern). This may also help with handling authorization and returning a proper view whenever the user is not permitted to see some component.</p>&#xA;&#xA;<p><strong>Code Sample:</strong>&#xA;<a href=""https://stackblitz.com/edit/angular-vxstyk?file=src%2Fapp%2Fsales%2Fsales%2Fsales.component.html"" rel=""nofollow noreferrer"">This</a> is a sample code for the scenario but it doesn't compile, because as my question states I'm looking for a way of orchestrating, and composing the UI and injecting the <code>&lt;total-price&gt;</code> component to sales without referencing the accounting module directly.</p>&#xA;"
45598647,Microservice between my own application and a logging application to structure logging,2017-08-09 18:56:37,<c#><microservices>,2,307,4,0.0,-1,<p>I'm trying to find a good example which explains me how I can build a micro-service that I can put between my own application and a logging application like seq. In this way I'll try to put the logging data in the same destination an I can switch easily from those logging application so I don't have to edit my entire code. Is there a way to do this and maybe a example which explains this. I've already googled for it but I didn't found any clear explanations.</p>&#xA;
50801690,Working with microservices. Hibernate or Scripts,2018-06-11 15:52:24,<java><database><hibernate><microservices>,1,58,3,0.0,-1,"<p>What is the best approach for database creation and relationship management when working with microservices?Hibernate or scripts, as i feel it shouldn't be the responsibility of microservices to create a database </p>&#xA;"
