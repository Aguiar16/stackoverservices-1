Id,Title,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
27054162,"what are REST,RESTFul, SOA and microservices in simple terms?",<rest><soa><microservices>,2,19619,3,11.0,23,"<p>I thought I knew what REST/""RESTFul"", restfulservices, webservices, SOA and microservices were but I came across so many different definitions that I reached the conclusion that those terms are overused, misused , or simply badly defined.</p>&#xA;&#xA;<p>I hope to have a clear understanding of what the aforementioned terms represent, their concrete definition , their commonality and differences, advantages vs disadvantages, and most importantly the bottom line - the most important things to remember in order to use those terms appropriately. </p>&#xA;"
27007353,How does data denormalization work with the Microservice Pattern?,<database><denormalization><microservices>,4,6219,4,21.0,62,"<p>I just read an article on <a href=""http://java.dzone.com/articles/microservices-and-paas-part-2"">Microservices and PaaS Architecture</a>. In that article, about a third of the way down, the author states (under <strong>Denormalize like Crazy</strong>):</p>&#xA;&#xA;<blockquote>&#xA;  <p>Refactor database schemas, and de-normalize everything, to allow complete separation and partitioning of data. That is, do not use underlying tables that serve multiple microservices. There should be no sharing of underlying tables that span multiple microservices, and no sharing of data. Instead, if several services need access to the same data, it should be shared via a service API (such as a published REST or a message service interface).</p>&#xA;</blockquote>&#xA;&#xA;<p>While this <em>sounds</em> great in theory, in practicality it has some serious hurdles to overcome. The biggest of which is that, often, databases are tightly coupled and every table has <em>some</em> foreign key relationship with at least one other table. Because of this it could be impossible to partition a database into <em>n</em> sub-databases controlled by <em>n</em> microservices.</p>&#xA;&#xA;<p>So I ask: <strong>Given a database that consists entirely of related tables, how does one denormalize this into smaller fragments (groups of tables) so that the fragments can be controlled by separate microservices?</strong></p>&#xA;&#xA;<p>For instance, given the following (rather small, but exemplar) database:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;user_id&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;product_id&#xA;order_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p>Don't spend too much time critiquing my design, I did this on the fly. The point is that, to me, it makes logical sense to split this database into 3 microservices:</p>&#xA;&#xA;<ol>&#xA;<li><code>UserService</code> - for CRUDding users in the system; should ultimately manage the <code>[users]</code> table; and</li>&#xA;<li><code>ProductService</code> - for CRUDding products in the system; should ultimately manage the <code>[products]</code> table; and</li>&#xA;<li><code>OrderService</code> - for CRUDding orders in the system; should ultimately manage the <code>[orders]</code> and <code>[products_x_orders]</code> tables</li>&#xA;</ol>&#xA;&#xA;<p>However all of these tables have foreign key relationships with each other. If we denormalize them and treat them as monoliths, they lose all their semantic meaning:</p>&#xA;&#xA;<pre><code>[users] table&#xA;=============&#xA;user_id&#xA;user_first_name&#xA;user_last_name&#xA;user_email&#xA;&#xA;[products] table&#xA;================&#xA;product_id&#xA;product_name&#xA;product_description&#xA;product_unit_price&#xA;&#xA;[orders] table&#xA;==============&#xA;order_id&#xA;order_datetime&#xA;&#xA;[products_x_orders] table (for line items in the order)&#xA;=======================================================&#xA;products_x_orders_id&#xA;quantity_ordered&#xA;</code></pre>&#xA;&#xA;<p><strong>Now there's no way to know who ordered what, in which quantity, or when.</strong></p>&#xA;&#xA;<p>So is this article typical academic hullabaloo, or is there a real world practicality to this denormalization approach, and if so, what does it look like (bonus points for using my example in the answer)?</p>&#xA;"
26866479,Architecture of a microservice based web app,<web-applications><soa><microservices>,4,6863,0,6.0,25,"<p>I am confused about the point at which a web application diverges into microservices - is it at url level or models level?&#xA;As an example, Suppose I have a monolithic app that serves 3 pages. Say each page serves a separate usecase and i want to back eack of them with their own microservices. Now, which of these is the correct way of implementing a microservice based architecture:</p>&#xA;&#xA;<ul>&#xA;<li>I create three different apps(microservices), each containing the (route, controller, models, templates) for one of the pages. And then based on which ever page is requested, I route the request to that particular app. This means that the whole page from database to HTML is served by a separate app. Basically, different pages in the same website are being completely served by different apps on the backend.</li>&#xA;<li>The 3 microservices do not handle the UI stuff but only the data for their usecases(models, controller, no templates) and expose it over a REST api. I have one public facing app. This app queries the three different apps(microservices) only for the data and then builds the html pages to be returned to browser. All the pages in a web app in this case are being served by a single app which internally makes use of three different microservices.</li>&#xA;</ul>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/b62O1.png"" alt=""enter image description here""></p>&#xA;"
33399988,Microservices: datasource per instance or per microservice?,<database><design><architecture><microservices>,5,2501,1,4.0,12,"<p>Building microservice architecture I faced the problem of data sharing between instances of the same microservice.</p>&#xA;&#xA;<p>I have microservice, that massively uses it's datasource - every request to service cause database request (usually insert). This service will be used very heavily and I plan to hide multiple instances behind Load Balancer. And here rises a question: shall these instances use ONE database (will the database be a bottleneck?) or MULTIPLE (datasource per instance) have?</p>&#xA;"
25595492,Single Sign-On in Microservice Architecture,<security><cloud><single-sign-on><microservices><paas>,2,13805,3,22.0,37,<p>I'm trying to design a green-field project that will have several services (serving data) and web-applications (serving HTML). I've read about microservices and they look like good fit.</p>&#xA;&#xA;<p>The problem I still have is how to implement SSO. I want the user to authenticate once and have access to all the different services and applications.</p>&#xA;&#xA;<p>I can think of several approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p>Add Identity service and application. Any service that has protected resources will talk to the Identity service to make sure the credentials it has are valid. If they are not it will redirect the user for authentication.</p></li>&#xA;<li><p>Use a web-standard such as OpenID and have each service handle it own identities. This means the user will have to authorize individually each service/application but after that it will be SSO.</p></li>&#xA;</ol>&#xA;&#xA;<p>I'll be happy to hear other ideas. If a specific PaaS (such as Heroku) has a proprietary solution that would also be acceptable.</p>&#xA;
26616962,Microservices: What are smart endpoints and dumb pipes?,<architecture><soa><messaging><distributed><microservices>,6,13620,0,7.0,15,"<p>I have read an article ""<a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""noreferrer"">Microservices</a>"" by Martin Fowler and find it difficult to understand <strong>smart endpoint</strong>s and <strong>dumb pipes</strong>. Please explain these terms, examples are welcome.</p>&#xA;"
36896418,Why would I choose a Windows Service over a Web API service?,<c#><web-services><asp.net-web-api><microservices>,1,586,1,0.0,-4,"<p>For me, Windows Services are inconvenient and cumbersome enough to question their validity in all apps that aren't ""Watch this folder for a change, react to this change.""</p>&#xA;&#xA;<p>I understand that this oversimplification is ignorant, why would one choose a windows service over the Web API.</p>&#xA;"
30296587,Using Amazon SQS with multiple consumers,<amazon-web-services><amazon-sqs><microservices><event-based-programming>,1,10770,0,5.0,17,"<p>I have a service-based application that uses Amazon SQS with multiple queues and multiple consumers. I am doing this so that I can implement an event-based architecture and decouple all the services, where the different services react to changes in state of other systems. For example:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Registration Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'registration-new' when a new user registers.</li>&#xA;</ul></li>&#xA;<li><strong>User Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'user-updated' when user is updated.</li>&#xA;</ul></li>&#xA;<li><strong>Search Service</strong>: &#xA;<ul>&#xA;<li>Reads from queue 'registration-new' and indexes user in search.</li>&#xA;<li>Reads from queue 'user-updated' and updates user in search.</li>&#xA;</ul></li>&#xA;<li><strong>Metrics Service</strong>:&#xA;<ul>&#xA;<li>Reads from 'registration-new' queue and sends to Mixpanel.</li>&#xA;<li>Reads from queue 'user-updated' and sends to Mixpanel.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I'm having a number of issues:</p>&#xA;&#xA;<ul>&#xA;<li>A message can be received multiple times when doing polling. I can design a lot of the systems to be idempotent, but for some services (such as the metrics service) that would be much more difficult.</li>&#xA;<li>A message needs to be manually deleted from the queue in SQS. I have thought of implementing a ""message-handling-service"" that handles the deletion of messages when all the services have received them (each service would emit a 'message-acknowledged' event after handling a message).</li>&#xA;</ul>&#xA;&#xA;<p>I guess my question is this: what patterns should I use to ensure that I can have multiple consumers for a single queue in SQS, while ensuring that the messages also get delivered and deleted reliably. Thank you for your help.</p>&#xA;"
30286443,Microservices: How to store source code of many microservices?,<git><microservices>,3,6232,0,8.0,29,"<p>Currently, I have <strong>20 microservices</strong> for one project. And every microservice stored in separate GIT reposotiry. &#xA;Subsequently, the number of services will increase <strong>to 200 (or more)</strong>.</p>&#xA;&#xA;<p>Every service has unit tests and integration tests. Every service has build in TeamCity (Continuous integration server). </p>&#xA;&#xA;<p>Question: How to store source code of 200 microservices for one project? In one repository or in separate repositories? </p>&#xA;"
36407520,Spring Cloud/Boot vs Wildfly Swarm,<java><spring-boot><microservices><wildfly-9><wildfly-swarm>,1,5675,4,4.0,12,"<p>I have doing some analysis of modern Container less Java Stack on net, two Major promising things i came about was:</p>&#xA;&#xA;<ol>&#xA;<li>Spring Boot/Cloud (Packed in Tomcat or Jetty,...)</li>&#xA;<li>Wildfly Swarm (Moduler Wildfly 9 Server with minimum possible components)</li>&#xA;</ol>&#xA;&#xA;<p>Yes both have their own features but i have not been able to find out a good comparison of both as both thing are in my point of view better then each other but still i have to decide what good for implementing,</p>&#xA;&#xA;<ol>&#xA;<li>Good for Developer health</li>&#xA;<li>Complex Enterprise logic</li>&#xA;<li>Scalability</li>&#xA;<li>Hot deployments</li>&#xA;<li>Microservice Approach</li>&#xA;<li>Enterprise Integration Patterns</li>&#xA;<li>Continuous Delivery Pipeline.</li>&#xA;</ol>&#xA;&#xA;<p>Thanks for your thoughts</p>&#xA;&#xA;<p>Zaheer  </p>&#xA;"
48906817,2PC vs Sagas (distributed transactions),<transactions><cloud><microservices><distributed-computing><saga>,1,361,1,2.0,15,"<p>I'm developing my insight about distributed systems, and how to maintain data consistency across such systems, where business transactions covers multiple services, bounded contexts and network boundaries.</p>&#xA;&#xA;<p>Here are two approaches which I know are used to implement distributed transactions:</p>&#xA;&#xA;<ul>&#xA;<li>2-phase commit (2PC)</li>&#xA;<li>Sagas</li>&#xA;</ul>&#xA;&#xA;<p>2PC is a protocol for applications to <em>transparently</em> utilize global ACID transactions by the support of the platform. Being embedded in the platform, it is transparent to the business logic and the application code as far as I know.</p>&#xA;&#xA;<p>Sagas, on the other hand, are series of local transactions, where each local transaction mutates and persist the entities along with some flag indicating the phase of the global transaction and commits the change. In the other words, state of the transaction is part of the domain model. Rollback is the matter of committing a series of ""inverted"" transactions. Events emitted by the services triggers these local transactions in either case.</p>&#xA;&#xA;<p>Now, when and why would one use sagas over 2PC and vice versa? What are the use cases and pros/cons of both? Especially, the brittleness of sagas makes me nervous, as the inverted distributed transaction could fail as well.</p>&#xA;"
35381163,Best practice to organize authorization in microservice architecture?,<authentication><architecture><authorization><microservices>,1,3241,8,3.0,9,"<p>For example, I have 3 services:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Seller</li>&#xA;<li>Buyer</li>&#xA;</ul>&#xA;&#xA;<p>Each of them got their own databases, models, services... etc</p>&#xA;&#xA;<p>Authentication service knows about users, user-groups, roles, permissions and creates token.</p>&#xA;&#xA;<p>Where should I store sellers/buyers entities? On Authentication service, or on Seller/Buyer services?</p>&#xA;&#xA;<p>How should Seller/Buyer services interact to create new seller/buyer entity?</p>&#xA;&#xA;<p>How should Seller/Buyer services check permissions?</p>&#xA;&#xA;<p>Seller and Buyer entities have some common fields: name, password, email..., but also each of them have their own additional fields.</p>&#xA;&#xA;<p>Seller and Buyer interact with each other.</p>&#xA;"
28500066,How to deploy SpringBoot Maven application with Jenkins ?,<maven><tomcat><jenkins><spring-boot><microservices>,4,19550,5,5.0,16,"<p>I have a Spring Boot application which runs on embedded Tomcat servlet container <code>mvn spring-boot:run</code> . And I don’t want to deploy the project as separate war to standalone Tomcat. </p>&#xA;&#xA;<p>Whenever I push code to BitBucket/Github, a hook runs and triggers Jenkins job (runs on Amazon EC2) to deploy the application. </p>&#xA;&#xA;<p>The Jenkins job has a post build action: <code>mvn spring-boot:run</code>, the problem is that the job hangs when post build action finished. </p>&#xA;&#xA;<p>There should be another way to do this. Any help would be appreciated.</p>&#xA;"
27865238,Parent pom and microservices,<java><maven><microservices>,3,5502,2,4.0,14,"<ul>&#xA;<li>We have several projects that are microservices, every project is independent (running on separate spring boot server, exposing rest services, using separate DB schema...)</li>&#xA;<li>We use maven to manage the dependencies.</li>&#xA;</ul>&#xA;&#xA;<p>Is it a good idea to have a parent pom declaring each microservices as modules? And so helping to manage the common dependencies (like the lib servlet-api witch is used in every project, to remove it of all of them and declare it in only the parent pom)</p>&#xA;"
33726653,Service Fabric Reliable Services Pipeline design,<c#><azure><pipeline><microservices><azure-service-fabric>,1,2574,0,10.0,14,"<p>I need to implement pipeline if Service Fabric's Reliable Services, and I need some guidelines about what of these approaches is preferable from the viewpoint of reliability simplicity and simple good design:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pWFql.png""><img src=""https://i.stack.imgur.com/pWFql.png"" alt=""enter image description here""></a></p>&#xA;"
31044380,Microservices authentication,<rest><microservices>,4,3308,0,4.0,9,"<p><strong>Context</strong></p>&#xA;&#xA;<p>I have multiple services like :</p>&#xA;&#xA;<ul>&#xA;<li>User (LDAP or active directory etc...)</li>&#xA;<li>Billing</li>&#xA;<li>Planning</li>&#xA;<li>etc...</li>&#xA;<li>Authentication</li>&#xA;</ul>&#xA;&#xA;<p>I need to connect on my microservices Using OAuth2.0, for beginning, using the standard login / password (I use my own data, and not gettint a third leg server)</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>According to these pictures :</p>&#xA;&#xA;<p><em>Step 1</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/csUn0.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p><em>Step 2</em></p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/xmohK.jpg"" alt=""enter image description here""></p>&#xA;&#xA;<p>How can I handle access_token control or authorization control, in my other services than authmicroservice ?</p>&#xA;"
31104540,DB consistency with microservices,<database><soa><microservices>,4,4038,1,10.0,29,"<p>What is the best way to achieve DB consistency in microservice-based systems?</p>&#xA;&#xA;<p>At the <a href=""https://www.youtube.com/watch?v=wgdBVIX9ifA"" rel=""noreferrer"">GOTO in Berlin</a>, Martin Fowler was talking about microservices and one ""rule"" he mentioned was to keep ""per-service"" databases, which means that services cannot directly connect to a DB ""owned"" by another service.</p>&#xA;&#xA;<p>This is super-nice and elegant but in practice it becomes a bit tricky. Suppose that you have a few services:</p>&#xA;&#xA;<ul>&#xA;<li>a frontend</li>&#xA;<li>an order-management service</li>&#xA;<li>a loyalty-program service</li>&#xA;</ul>&#xA;&#xA;<p>Now, a customer make a purchase on your frontend, which will call the order management service, which will save everything in the DB -- no problem. At this point, there will also be a call to the loyalty-program service so that it credits / debits points from your account.</p>&#xA;&#xA;<p>Now, when everything is on the same DB / DB server it all becomes easy since you can run everything in one transaction: if the loyalty program service fails to write to the DB we can roll the whole thing back.</p>&#xA;&#xA;<p>When we do DB operations throughout multiple services this isn't possible, as we don't rely on one connection / take advantage of running a single transaction.&#xA;What are the best patterns to keep things consistent and live a happy life?</p>&#xA;&#xA;<p>I'm quite eager to hear your suggestions!..and thanks in advance!</p>&#xA;"
29761872,Microservices and database joins,<database><integration><microservices>,5,10558,2,18.0,55,"<p>For people that are splitting up monolithic applications into microservices how are you handling the connundrum of breaking apart the database.  Typical applications that I've worked on do a lot of database integration for performance and simplicity reasons.</p>&#xA;&#xA;<p>If you have two tables that are logically distinct (bounded contexts if you will) but you often do aggregate processing on a large volumes of that data then in the monolith you're more than likely to eschew object orientation and are instead using your database's standard JOIN feature to process the data on the database prior to return the aggregated view back to your app tier.</p>&#xA;&#xA;<p>How do you justify splitting up such data into microservices where presumably you will be required to 'join' the data through an API rather than at the database.</p>&#xA;&#xA;<p>I've read Sam Newman's Microservices book and in the chapter on splitting the Monolith he gives an example of ""Breaking Foreign Key Relationships"" where he acknowledges that doing a join across an API is going to be slower - but he goes on to say if your application is fast enough anyway, does it matter that it is slower than before?</p>&#xA;&#xA;<p>This seems a bit glib?  What are people's experiences?  What techniques did you use to make the API joins perform acceptably?</p>&#xA;"
29644916,Microservice Authentication strategy,<authentication><architecture><microservices>,4,35930,7,47.0,92,"<p>I'm having a hard time choosing a decent/secure authentication strategy for a microservice architecture. The only SO post I found on the topic is this one: <a href=""https://stackoverflow.com/questions/25595492/single-sign-on-in-micro-service-architecture"">Single Sign-On in Microservice Architecture</a></p>&#xA;&#xA;<p>My idea here is to have in each service (eg. authentication, messaging, notification, profile etc.) a unique reference to each user (quite logically then his <code>user_id</code>) and the possibility to get the current user's <code>id</code> if logged in.</p>&#xA;&#xA;<p>From my researches, I see there are two possible strategies:</p>&#xA;&#xA;<h3>1. Shared architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/po7Qr.png"" alt=""Shared architecture""></p>&#xA;&#xA;<p>In this strategy, the authentication app is one service among other. But each service must be able to make the conversion <code>session_id</code> => <code>user_id</code> so it must be dead simple. That's why I thought of Redis, that would store the key:value <code>session_id:user_id</code>.</p>&#xA;&#xA;<h3>2. Firewall architecture</h3>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/NHGjh.png"" alt=""Firewall architecture""></p>&#xA;&#xA;<p>In this strategy, session storage doesn't really matter, as it is only handled by the authenticating app. Then the <code>user_id</code> can be forwarded to other services. I thought of Rails + Devise (+ Redis or mem-cached, or cookie storage, etc.) but there are tons of possibilities. The only thing that matter is that Service X will never need to authenticate the user.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How do those two solutions compare in terms of:</p>&#xA;&#xA;<ul>&#xA;<li>security</li>&#xA;<li>robustness</li>&#xA;<li>scalability</li>&#xA;<li>ease of use</li>&#xA;</ul>&#xA;&#xA;<p>Or maybe you would suggest another solution I haven't mentioned in here?</p>&#xA;&#xA;<p>I like the solution #1 better but haven't found much default implementation that would secure me in the fact that I'm going in the right direction.</p>&#xA;&#xA;<p>I hope my question doesn't get closed. I don't really know where else to ask it.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
42096392,Is it possible to combine different language in one application?,<java><php><node.js><microservices>,1,46,5,0.0,-3,"<p>first of all, i dont want to make things a bit ambiguous.</p>&#xA;&#xA;<p>is it possible to to use different language such node.js, php for developing a Web service?</p>&#xA;&#xA;<p>for instance the node.js will be responsible for user authentication and PHP and responsible messaging .&#xA;mainly the idea of the app will be in Microservice architecture.&#xA;The Node.js will have the authentication service&#xA;and the PHP will have the messaging service.&#xA;is that a good idea&#xA;because i am learning microservices architecure and i got the user authentication and i was thinking of use PHP to complete the rest of my project.&#xA;Obviously they will have a different DB.&#xA;thanks in advance</p>&#xA;"
41640621,Data Sharing between micro services,<design-patterns><architecture><microservices><aws-api-gateway><data-sharing>,4,6060,9,11.0,24,"<p><strong>Current Architecture:</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qlrIu.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qlrIu.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Problem:</strong></p>&#xA;&#xA;<p>We have a two-step flow between frontend and backend layers.  </p>&#xA;&#xA;<ul>&#xA;<li>First step:&#xA;The frontend validates an input <strong>I1</strong> from the user on microservice 1 (MS1)</li>&#xA;<li>Second step:&#xA;The frontend submits <strong>I1</strong> and more information to the microservice 2</li>&#xA;</ul>&#xA;&#xA;<p>The micro service 2 (MS2) needs to validates the integrity of <strong>I1</strong> as it is coming from the frontend. How to do avoid a new query to MS1? What's the best approach?</p>&#xA;&#xA;<p><strong>Flows that I'm trying to optimize removing the steps 1.3 and 2.3</strong></p>&#xA;&#xA;<p>Flow 1:</p>&#xA;&#xA;<ul>&#xA;<li>1.1 The User X requests data (MS2_Data) from MS2</li>&#xA;<li>1.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>1.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>1.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p>Flow 2:</p>&#xA;&#xA;<ul>&#xA;<li>2.1 The User X already has data (MS2_Data) stored on local/session storage</li>&#xA;<li>2.2 The User X persists data (MS2_Data + MS1_Data) on MS1</li>&#xA;<li>2.3 The MS1 check the integrity of MS2_Data using a B2B HTTP request</li>&#xA;<li>2.4 The MS1 use MS2_Data and MS1_Data to persist and Database 1 and build the HTTP response.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Approach</strong></p>&#xA;&#xA;<p>One possible approach is to use a B2B HTTP request between MS2 and MS1 but we would be duplicating the validation in the first step.&#xA;Another approach will be duplicating data from MS1 to MS2. however this is prohibitive due to the amount of data and it's volatility nature. Duplication does not seem to be a viable option.</p>&#xA;&#xA;<p>A more suitable solution is my opinion will the frontend to have the responsibility to fetch all the information required by the micro service 1 on the micro service 2 and delivered it to the micro service 2. This will avoid all this B2B HTTP requests.</p>&#xA;&#xA;<p><strong>The problem is how the micro service 1 can trust the information sent by the frontend. Perhaps using <a href=""https://jwt.io/introduction/"" rel=""noreferrer"">JWT</a> to somehow sign the data from the micro service 1 and the micro service 2 will be able to verify the message.</strong></p>&#xA;&#xA;<p><strong>Note</strong>&#xA;Every time the micro service 2 needs information from the micro service 1 a B2B http request is performed. (The HTTP request use <a href=""https://en.wikipedia.org/wiki/HTTP_ETag"" rel=""noreferrer"">ETAG</a> and <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control"" rel=""noreferrer"">Cache Control: max-age</a>). How to avoid this? </p>&#xA;&#xA;<p><strong>Architecture Goal</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FR7E7.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FR7E7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The micro service 1 needs the data from the micro service 2 on demand to be able to persist MS1_Data and MS2_Data on MS1 database, so the ASYNC approach using a broker does not apply here.</strong></p>&#xA;&#xA;<p>My question is if exists a design pattern, best practice or a framework to enable this kind of thrust communication. </p>&#xA;&#xA;<p>The downside of the current architecture is the number of B2B HTTP requests that are performed between each micro services. Even if I use a cache-control mechanism the response time of each micro service will be affected. The response time of each micro services is critical. The goal here is to archive a better performance and some how use the frontend as a gateway to distribute data across several micro services but using a <strong>thrust communication</strong>. </p>&#xA;&#xA;<p>MS2_Data is just an Entity SID like product SID or vendor SID that the MS1 must use to maintain data integrity. </p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qSYQY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qSYQY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The idea is to use the gateway as an api gateway request processing that will cache some HTTP response from MS1 and MS2 and use them as a response to MS2 SDK and MS1 SDK. This way no communication (SYNC OR ASYNC) is made directly between MS1 and MS2 and data duplication is also avoided.</p>&#xA;&#xA;<p>Of course the above solution is just for shared UUID/GUID across micro services. For full data, an event bus is used to distribute events and data across micro services in an asynchronous way (Event sourcing pattern). </p>&#xA;&#xA;<p>Inspiration: <a href=""https://aws.amazon.com/api-gateway/"" rel=""noreferrer"">https://aws.amazon.com/api-gateway/</a> and <a href=""https://getkong.org/"" rel=""noreferrer"">https://getkong.org/</a></p>&#xA;&#xA;<p><strong>Related questions and documentation:</strong></p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://stackoverflow.com/questions/41445442/how-to-sync-the-database-with-the-microservices-and-the-new-one/41475346"">How to sync the database with the microservices (and the new one)?</a></li>&#xA;<li><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""noreferrer"">https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/30213456/transactions-across-rest-microservices"">Transactions across REST microservices?</a></li>&#xA;<li><a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></li>&#xA;<li><a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"" rel=""noreferrer"">http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf</a></li>&#xA;<li><a href=""https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/"" rel=""noreferrer"">https://www.tigerteam.dk/2014/micro-services-its-not-only-the-size-that-matters-its-also-how-you-use-them-part-1/</a></li>&#xA;</ul>&#xA;"
37749087,"How to restore state in an event based, message driven microservice architecture on failure scenario",<messaging><reactive-programming><microservices><event-based-programming>,3,1771,0,7.0,12,"<p>In the context of a microservice architecture, a message driven, asynchronous, event based design seems to be gaining popularity (see <a href=""http://blog.christianposta.com/microservices/why-microservices-should-be-event-driven-autonomy-vs-authority/"" rel=""noreferrer"">here</a> and <a href=""https://www.nginx.com/blog/event-driven-data-management-microservices/"" rel=""noreferrer"">here</a> for some examples, as well as the <a href=""http://www.reactivemanifesto.org/#message-driven"" rel=""noreferrer"">Reactive Manifesto - Message Driven trait</a>) as opposed to a synchronous (possibly REST based) mechanism.</p>&#xA;&#xA;<p>Taking that context and imagining an overly simplified ordering system, as depicted below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Xtttg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Xtttg.png"" alt=""ordering system""></a></p>&#xA;&#xA;<p>and the following message flow:</p>&#xA;&#xA;<ul>&#xA;<li>Order is placed from some source (web/mobile etc.)</li>&#xA;<li>Order service accepts order and publishes a <code>CreateOrderEvent</code></li>&#xA;<li>The InventoryService reacts on the <code>CreateOrderEvent</code>, does some inventory stuff and publishes a <code>InventoryUpdatedEvent</code> when it's done</li>&#xA;<li>The Invoice service then reacts to the <code>InventoryUpdatedEvent</code>, sends an invoice and publishes a <code>EmailInvoiceEvent</code></li>&#xA;</ul>&#xA;&#xA;<p>All services are up and we happily process orders... Everyone is happy.&#xA;Then, the Inventory service goes down for some reason </p>&#xA;&#xA;<p>Assuming that the events on the event bus are flowing in a ""non blocking"" manor. I.e. the messages are being published to a central topic and do not pile up on a queue if no service is reading from it (what I'm trying to convey is an event bus where, if the event is published on the bus, it would flow ""straight through"" and not queue up - ignore what messaging platform/technology is used at this point). That would mean that if the Inventory service were down for 5 minutes, the <code>CreateOrderEvent</code>'s passing through the event bus during that time are now ""gone"" or not seen by the Inventory service because in our overly simplified system, no other system is interested in those events.</p>&#xA;&#xA;<p>My question then is: How does the Inventory service (and the system as a whole) restore state in a way that no orders are missed/not processed?</p>&#xA;"
31842622,Microservices: How to integrate the UI?,<microservices>,1,3595,3,3.0,13,"<p>today I started reading about Microservice architectures - and it seems to be very interesting!&#xA;But I have one doubt I need some exlanation on:&#xA;Assume I want to create a blog and would build 4 microservices for that: User/login Service, Article Service, Comments Service and Reporting/analytics Service(not a realistic example, I know...).&#xA;The Reporting/Analytics service is purely backend - no issue here for my understanding.&#xA;But the three others involve some UI part - and as to my understanding this UI part should also be part of the microservice itself, right?&#xA;How would the UI integration work? Would I then have a 5th ""front door"" service that collects the user requests, forwards them to the other services which then answer with HTML/CSS and the front door service would then compose the individual responses into what is returned to the user?</p>&#xA;&#xA;<p>Any change you have an example/use case for such a scenario?</p>&#xA;&#xA;<p>Thanks and regards!</p>&#xA;"
29460485,Microservices Architecture: Cross Service data sharing,<web-services><architecture><microservices>,3,7356,2,17.0,22,"<p>Consider the following micro services for an online store project:<br>&#xA;Users Service keeps account data about the store's users (including first name, last name, email address, etc')</p>&#xA;&#xA;<p>Purchase Service keeps track of details about user's purchases.</p>&#xA;&#xA;<p>Each service provides a UI for viewing and managing it's relevant entities.&#xA;The Purchase Service index page lists purchases. Each purchase item should have the following fields:<br>&#xA;id, full name of purchasing user, purchased item title and price.<br>&#xA;Furthermore, as part of the index page, I'd like to have a search box to let the store manager search purchases by purchasing user name.</p>&#xA;&#xA;<p>It is not clear to me how to get back data which the Purchase Service does not hold - for example: a user's full name.&#xA;The problem gets worse when trying to do more complicated things like search purchases by purchasing user name.</p>&#xA;&#xA;<p>I figured that I can obviously solve this by syncing users between the two services by broadcasting some sort of event on user creation (and saving only the relevant user properties on the Purchase Service end). That's far from ideal in my perspective. How do you deal with this when you have millions of users? would you create millions of records in each service which consumes users data?</p>&#xA;&#xA;<p>Another obvious option is exposing an API at the Users Service end which brings back user details based on given ids. That means that every page load in the Purchase Service, I'll have to make a call to the Users Service in order to get the right user names. Not ideal, but I can live with it.</p>&#xA;&#xA;<p>What about implementing a purchase search based on user name? Well I can always expose another API endpoint at the Users Service end which receives the query term, perform a text search over user names in the Users Service, and then return all user details which match the criteria. At the Purchase Service, map the relevant ids back to the right names and show them in the page. This approach is not ideal either.</p>&#xA;&#xA;<p>Am I missing something? Is there another approach for implementing the above? Maybe the fact that I'm facing this issue is sort of a code smell? would love to hear other solutions.</p>&#xA;"
37180375,Using Zuul as an authentication gateway,<spring-boot><spring-cloud><microservices><gateway><netflix-zuul>,3,14024,3,14.0,18,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I want to implement the design presented in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""noreferrer"">article</a>.</p>&#xA;&#xA;<p>It can be summarised by the diagram below:&#xA;<a href=""https://i.stack.imgur.com/viaL4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viaL4.png"" alt=""Security Architecture""></a></p>&#xA;&#xA;<ol>&#xA;<li>The client first authenticate with the IDP (OpenID Connect/OAuth2)</li>&#xA;<li>The IDP returns an access token (opaque token with no user info)</li>&#xA;<li>The client makes a call through the API gateway use the access token in the Authorization header</li>&#xA;<li>The API gateway makes a request to the IDP with the Access Token</li>&#xA;<li>The IDP verifies that the Access Token is valid and returns user information in JSON format</li>&#xA;<li>The API Gateway store the user information in a JWT and sign it with a private key. The JWT is then passed to the downstream service which verifies the JWT using the public key</li>&#xA;<li>If a service must call another service to fulfil the request it passes the JWT along which serves as authentication and authorisation for the request</li>&#xA;</ol>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have most of that done using:</p>&#xA;&#xA;<ul>&#xA;<li>Spring cloud as a global framework</li>&#xA;<li>Spring boot to launch individual services</li>&#xA;<li>Netflix Zuul as the API gateway</li>&#xA;</ul>&#xA;&#xA;<p>I have also written a Zuul PRE filter that checks for an Access Token, contacts the IDP and create a JWT. The JWT is then added to the header for the request forwarded to the downstream service.</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>Now my question is quite specific to Zuul and its filters. If authentication fails in the API gateway for any reason, how can I can stop the routing and respond directly with a 401 without continuing the filter chain and forwarding the call?</p>&#xA;&#xA;<p>At the moment if authentication fails the filter won't add the JWT to the header and the 401 will come from the downstream service. I was hoping my gateway could prevent this unnecessary call.</p>&#xA;&#xA;<p>I tried to see how I could use <code>com.netflix.zuul.context.RequestContext</code>to do this but the documentation is quite poor and I couldn't find a way. </p>&#xA;"
38071714,GraphQL and Microservice Architecture,<architecture><microservices><graphql>,5,14892,0,48.0,86,"<p>I'm trying to understand where GraphQL is most suitable to use within a Microservice architecture. </p>&#xA;&#xA;<p>There is some debate about having only 1 GraphQL schema that works as API Gateway proxying the request to the targeted microservices and coercing their response. Microservices still would use REST / Thrift protocol for communication thought.</p>&#xA;&#xA;<p>Another approach is instead to have multiple GraphQL schemas one per microservice. Having a smaller API Gateway server that route the request to the targeted microservice with all the information of the request + the GraphQL query.</p>&#xA;&#xA;<p><strong>1st Approach</strong></p>&#xA;&#xA;<p>Having 1 GraphQL Schema as an API Gateway will have a downside where every time you change your microservice contract input/output, we have to change the GraphQL Schema accordingly on the API Gateway Side.</p>&#xA;&#xA;<p><strong>2nd Approach</strong></p>&#xA;&#xA;<p>If using Multiple GraphQL Schema per microservices, make sense in a way because GraphQL enforces a schema definition, and the consumer will need to respect input/output given from the microservice.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>Where do you find GraphQL the right fit for designing microservice architecture? </p></li>&#xA;<li><p>How would you design an API Gateway with a possible GraphQL implementation?</p></li>&#xA;</ul>&#xA;"
34903605,Microservices: what are pros and cons?,<architecture><microservices>,2,9224,0,7.0,20,<p>What are pros and cons of using microservices in comparison with alternative architectures?&#xA;Is there a rule of thumb when microservices should be used?</p>&#xA;
41036545,How to pass through properties in JSON messages with Jackson and MongoDB?,<java><json><spring><jackson><microservices>,7,731,7,0.0,9,"<p>We have a microservice which gets some JSON data from the queue, processes it a little bit and sends the result of processing further on - again via queue. In the microservice we don't work with <code>JSONObject</code> an likes directly, we map JSON onto Java classes using Jackson.</p>&#xA;&#xA;<p>When processing, the microservice is only interested in a some properties of the incoming message, not all of them. Imagine it just receives</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And sends:</p>&#xA;&#xA;<pre><code>{&#xA;    ""operand1"": 3,&#xA;    ""operand2"": 5,&#xA;    ""multiplicationResult"": 15,&#xA;    /* other properties may come here */&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>How can I tunnell or pass-through other properties of the message which I'm not interested in this service without explicitly mapping them in my classes?</strong></p>&#xA;&#xA;<p>For the purposes of this microservice it would be enough to have a structure like:</p>&#xA;&#xA;<pre><code>public class Task {&#xA;   public double operand1;&#xA;   public double operand2;&#xA;   public double multiplicationResult;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However if I don't map all of the <em>other properties</em>, they will be lost.</p>&#xA;&#xA;<p>If I do map them then I'll have to update the model of this microservice every time the structure of the message changes which takes effort and is error-prone.</p>&#xA;"
44579396,In microservices should i use pub/sub instead RPC to get more loosely couple architecture?,<architecture><rpc><publish-subscribe><microservices>,2,1806,0,2.0,9,"<p>I current using a RPC call to another microservice via TCP and getting the response, but I think I can do it in this way:</p>&#xA;&#xA;<p>whithout make a RPC call, can I use a pub/sub to send to one service, publishing some channel like <em>request_user</em> and subscribed to a channel like  <em>object_user_response</em>, and then the other service that is subscribed to this <em>request_user</em>, publish <em>object_user_response</em>.</p>&#xA;&#xA;<p>Like that:</p>&#xA;&#xA;<pre><code>Service A &lt;-- (sub)object_user_response &lt;------  Redis&#xA;Service A --&gt; (pub)request_user -------------&gt;   Redis&#xA;&#xA;Service B &lt;-- (sub)request_user &lt;--------------- Redis&#xA;Service B --&gt; (pub) object_user_response ------&gt; Redis&#xA;</code></pre>&#xA;&#xA;<p>On receive a object_user_response, the service A checks if the id of user is the same that the function have requested. </p>&#xA;&#xA;<p>Should I use RPC or Pub/sub for that?&#xA;What is the most correct way to send data to a microservice and get response from there in terms of loosely coupled architecture, is using a RPC call or using two pub/sub, on for the request and another for the response?  </p>&#xA;"
40900818,Querying / Pagination Across Microservices,<web-services><rest><integration><soa><microservices>,1,836,3,0.0,11,"<p>Our shop has recently started taking on an SOA approach to application development.  We are seeing some great benefits with the separation of concerns, reusability, and other benefits of SOA/microservices.</p>&#xA;&#xA;<p>However, one <strong>big</strong> item we're stuck on is aggregating, filtering, and paginating results across services.  Let me describe the issue with a scenario.</p>&#xA;&#xA;<p>Say we have 3 services:</p>&#xA;&#xA;<ol>&#xA;<li><strong>PersonService</strong> - Stores information on people (names, addresses, etc)</li>&#xA;<li><strong>ItemService</strong> - Stores information on items that are purchasable.</li>&#xA;<li><strong>PaymentService</strong> - Stores information regarding payments that people have made for different items.</li>&#xA;</ol>&#xA;&#xA;<p>Now, say we want to build a reporting/admin tool that can display / report on multiple services in aggregate.  For instance, we want to display a paginated list of Payments, along with the Person and Item that each payment was for.  This is pretty straightforward:  Grab the list of payments, then query PersonService and ItemService for the respective Person and Item records.</p>&#xA;&#xA;<p>However, the issue comes into play when we want to then filter down that data:  For instance, displaying a paginated list of payments made by people with the first name 'Bob', who have purchased the item 'Car'. This makes things much more complicated, because we need to filter results from 3 different services without knowing how many results each service is going to return.  </p>&#xA;&#xA;<p>From a performance perspective, querying all of the services over and over again to narrow down the results would be costly, so I've been researching better solutions.  However, I cannot find concrete solutions to this problem (or at least a ""best practice"").  In a monolithic application, we'd simply use SQL joins across the different tables.  I'm having a ton of trouble figuring out how/if something similar is possible across services.</p>&#xA;&#xA;<p>My question to the community is:  What would your approach be?  Things I've considered:</p>&#xA;&#xA;<ol>&#xA;<li>Using some sort of search index (<strong>Elasticsearch</strong>, <strong>Solr</strong>) that contains all data for all services (updated via events pushed out by services), and then querying the search index for results.</li>&#xA;<li>Attempting to understand how projects like <strong>GraphQL</strong> and <strong>Neo4j</strong> may assist us with these issues.</li>&#xA;</ol>&#xA;"
47793065,Angular and Micro-Frontends,<javascript><html><angular><microservices>,6,3468,5,14.0,36,"<p>I am doing some research on how to split a huge single-page-monolith into a micro-frontend architecture.</p>&#xA;&#xA;<h1>The idea:</h1>&#xA;&#xA;<ul>&#xA;<li>the page consists of several components which would be running autonomously</li>&#xA;<li>each component is managed by one dev-team</li>&#xA;<li>each team can change, update and deploy their components without breaking components of other teams</li>&#xA;<li>each team chooses its own toolstack</li>&#xA;</ul>&#xA;&#xA;<h1>The reason</h1>&#xA;&#xA;<p>To efficiently develop large applications you need to have many people working on it. However the number of developers per app/team does not scale well. Parallel development of multiple independent apps by independent teams however can be scaled arbitrarily</p>&#xA;&#xA;<p>With this in mind it is imperative that teams can choose their own toolstack and especially perform independent version-upgrades of third party-libraries (like angular, react, jquery). If this was not the case a framework-update would need to be compatible with every single component before you could deploy it to production.</p>&#xA;&#xA;<h1>Does this work with Angular?</h1>&#xA;&#xA;<p>While independent version-upgrades are necessary, it would be reasonable to restrict the teams to a few supported frameworks (Angular, React, Vue, Polymer...) and for now I try to build a demo purely consisting of Angular-Apps.</p>&#xA;&#xA;<p>However even though Angular 5 is supposedly a platform-framework which supports huge multi-module apps, it seems to be almost impossible to have several independent angular-apps running in the same browser window.</p>&#xA;&#xA;<p>I managed to bootstrap several Angular-Apps (different versions, each hosted on its own server) on a single webapp by utilizing HTML-Imports. However there are several <code>global</code> dependencies which need to be shared between apps</p>&#xA;&#xA;<ul>&#xA;<li>zone.js can only be started once</li>&#xA;<li>routing requires url-changes</li>&#xA;<li>Browser-stuff like cookies, sessionstorage, etc...</li>&#xA;</ul>&#xA;&#xA;<p>There are several articles in the net on how to bootstrap multiple angular-modules but they all refer to multiple modules in the same core-app, which in turn means they all are running on the same framework-version and an update means you have to rebuild and deploy the whole monolith.</p>&#xA;&#xA;<p><strong>Is there any solution other than ""<code>iframes</code>"" to get multiple Angular (5) Apps running on the same Page?</strong></p>&#xA;"
44870461,Microservices: how to handle foreign key relationships,<database><microservices>,2,6194,0,11.0,26,"<p>Microservices architecture suggest that each service should handle it's own data. Hence any service (Service A) dependent on data owned by other service (service B) should access such data not by making direct DB calls but through the api provided by the second service (service B).</p>&#xA;&#xA;<p><strong>So what does microservices best practices suggest on checking foreign key constrains.</strong> </p>&#xA;&#xA;<p>Example: I am developing a delivery feature (microservice 1) for products and certain products are deliverable to only certain locations as mentioned in the products table accessible to only products micro service (mircoservice 2).</p>&#xA;&#xA;<p>How do I make sure that microservice 1 (i.e delivery feature) does not take an order to a unserviced location. I have this question because delivery feature can not directly access products database, so there is no constraints applicable at DB level when a delivery order is place in to delivery data base (no check is possible to see if a foreign key match exists in products database or table).</p>&#xA;"
51541318,How do I resolve the authors names of books in microservice world?,<node.js><amazon-web-services><aws-lambda><microservices>,4,165,1,1.0,11,"<p>So I'm starting a journey down the road of microservices. I've spent some hours online trying immerse myself into this topic. </p>&#xA;&#xA;<p>One concept I'm not quite grasping yet is the idea of <strong>not using SQL joins</strong> and therefore having a small independent database for authors and the same for books.</p>&#xA;&#xA;<p>So I understand the following SQL:</p>&#xA;&#xA;<pre><code>BooksTable - id, name, authorid&#xA;AuthorsTable - id, name&#xA;&#xA;select book.name, author.name from book &#xA;join author on book.authorId = author.id&#xA;</code></pre>&#xA;&#xA;<p>In Node.js world</p>&#xA;&#xA;<p><strong>index.js</strong></p>&#xA;&#xA;<pre><code>app.get('/api/books' bookDomain.get());&#xA;</code></pre>&#xA;&#xA;<p><strong>bookDomain.js</strong></p>&#xA;&#xA;<pre><code>exports.get = () =&gt; {&#xA;  const books = bookService.get();&#xA;&#xA;  const authors = authorService.get();&#xA;&#xA;  /*&#xA;    This is where I'm lost: how do you achieve the simple SQL &#xA;    above? I'm assuming in the domain is where this information is &#xA;    ""joined""? am I correct?&#xA;  */&#xA;};&#xA;</code></pre>&#xA;&#xA;<p><strong>Services</strong></p>&#xA;&#xA;<pre><code>Database1&#xA;**bookService.js**&#xA;database context&#xA;&#xA;Database2&#xA;**authorService.js**&#xA;database context&#xA;</code></pre>&#xA;&#xA;<p><strong>expected data</strong> (something like it, basically i'm saying JSON should be the return type)</p>&#xA;&#xA;<pre><code>[{&#xA;  book {&#xA;    ""name"": ""Book 1"",&#xA;    ""author"": ""Author Name 1""&#xA;  }&#xA;},&#xA;{&#xA;  book {&#xA;    ""name"": ""Book 2"",&#xA;    ""author"": ""Author Name 2""&#xA;  }&#xA;}]&#xA;</code></pre>&#xA;"
51942114,Why we need to write business logic in separate service layer instead of writing in controller itself?,<spring><spring-mvc><spring-boot><microservices>,2,46,3,0.0,-5,<p>Whats the use of creating different layer i.e. Service layer for business logic implementation instead of implementing that business logic in Controller itself</p>&#xA;
46031939,How to manage read requests in an event sourced application,<domain-driven-design><microservices><cqrs><event-sourcing><event-store>,2,109,2,2.0,9,"<p>I was asked to do some exploration in event sourcing. my objective is to create a tiny API layer that satisfies all the traditional CRUD operation. I am now using a package called 'sourced' and trying to play around with it (Using Nodejs).</p>&#xA;&#xA;<p>However, I came to realize that the event sourcing is not quite useful when it is used alone. usually, it is coupled with CQRS.</p>&#xA;&#xA;<p>My understanding of the CQRS is, when the UI sends a write command to the server. the app does some validation towards the data. and saves it in the event store(I am using mongoDB), for example: here is what my event store should look like:</p>&#xA;&#xA;<pre><code>{method:""createAccount"",name:""user1"", account:1}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""deposit"",name:""user1"",account: 1 , amount:100}&#xA;{method:""withdraw"",name:""user1"",account1,amount:250}&#xA;</code></pre>&#xA;&#xA;<p>It contains all the audit information rather than the eventual status.&#xA;however, I am confused how can I handle the read operation. what if I want to read the balance of an account. what exactly will happen?&#xA;here are my questions:</p>&#xA;&#xA;<ol>&#xA;<li>If we can not query the event store(database) directly for reading operation, then where should we query? should it be a cache in memory?</li>&#xA;<li>If we query the memory. is the eventual status already there or I have to do a replay (or left-fold) operation to calculate the result. for example, the balance of the account 1 is 50.</li>&#xA;<li>I found some bloggers talked about 'subscribe' or 'broadcast'. what are they and broadcast to who?</li>&#xA;</ol>&#xA;&#xA;<p>I will be really appreciated for any suggestion and please corret me if my understanding is wrong.</p>&#xA;"
48639206,How to start single Spring Boot Microservice on Multiple Ports in STS/eclipse?,<spring><spring-boot><microservices>,1,344,3,1.0,-6,<p>How  to start single Spring Boot Microservice on Multiple Ports in STS/eclipse ?</p>&#xA;
37897058,"How to properly setup documentation for Restful services in a micro-service architecture (HAL, ALPS)",<java><spring><spring-data><spring-data-rest><microservices>,2,391,1,0.0,9,"<p>I have been reading a lot about how to setup Microservices properly and I have been getting hung up with some of the more recent concepts including: HAL, ALPS, and the HAL Browser.  I have historically documented things leveraging Swagger UI, however, I am coming to understand that URL centric isn't the proper way and I should be organizing documentation around resources and links which is what the newer technologies are for.  I have quite a few knowledge gaps around these newer concepts, so I wanted to get a proper understanding of how these technologies work together so as I learn about each I can fit them into the puzzle.</p>&#xA;&#xA;<p>My current understanding is:</p>&#xA;&#xA;<p><b>HAL</b> - Is an additional format on top of JSON that will let you navigate through your API via links.</p>&#xA;&#xA;<p><b>ALPS</b> - It is an additional format on top of JSON that can let me provide English based descriptions to help describe my resources</p>&#xA;&#xA;<p><b>HAL Browser</b> - Swagger UI replacement for Resource and Link centric documentation.  Works with both HAL and ALPS together?</p>&#xA;&#xA;<p>Would my current understanding of these technologies be accurate or lacking in some areas?  Also implementation wise I am not fully understanding how the ALPS and HAL are interacting together.  I was aware of a hal+json format and a alps+json format, but I haven't seen a hal+alps+json format.</p>&#xA;&#xA;<p>The last area I would like to clear up is how I should be exposing these resources.  Typically I always had a focus on very lean json messages is sending the hal+json format around the expected or should I be hosting those endpoints at another URL specifically for documentation similar to swagger / HAL browser?</p>&#xA;"
38633023,What are the disadvantages of Spring Boot for Java web applications?,<java><spring><spring-boot><microservices>,1,8337,2,1.0,19,"<p>[This needs to be voted to be reopened to answer.]</p>&#xA;&#xA;<p>Spring boot is tipped as being the default go to when making a new spring application as it makes set up easier and automatically wires in common dependencies. </p>&#xA;&#xA;<p>I am yet in industry to see spring-boot used in the manner advertised.</p>&#xA;&#xA;<p>Factually and concisely, what are the disadvantages that are faced by developers on adoption of Spring boot as the de facto Spring go to?</p>&#xA;&#xA;<p>The advantages of Spring Boot <a href=""https://stackoverflow.com/questions/28831479/advantage-of-spring-boot"">question</a> shows advantages of which I agree there are many, but believe there should be a rounder view. </p>&#xA;&#xA;<p>An example non opinion based point would be:</p>&#xA;&#xA;<ul>&#xA;<li><p>Spring boot may unnecessarily increase the deployment binary size with unused dependencies.</p></li>&#xA;<li><p>Not being able to customize logging easily as shown <a href=""https://stackoverflow.com/questions/29609996/spring-boot-loggingapplicationlistener-interfering-with-application-server-logg"">here</a>.</p></li>&#xA;</ul>&#xA;"
44195150,How can we keep an java application running forever,<java><web-services><microservices>,2,72,4,0.0,-4,"<p>I want to write an java application, which should be running forever. &#xA;Webservice is a way to do so, but i don't want to run it as webservice. &#xA;I just want to run some threads inside application running forever, I don't want to process any webRequest as such.</p>&#xA;&#xA;<p>Can you please tell what are other ways to do so ?</p>&#xA;"
29148547,Spring Security OAuth2 AuthorizationServer,<spring-security><spring-security-oauth2><microservices>,1,854,0,0.0,0,"<p>I'm playing around with spring-security-oauth2. I try to build some microservices with an authentication backend. </p>&#xA;&#xA;<p>I set up an simple spring boot project with the following dependencies</p>&#xA;&#xA;<pre><code>    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.2.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>and one Configuration Class</p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class SecurityConfiguration {&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""clientDetailsServiceBean"")&#xA;    private ClientDetailsService clientDetailsService;&#xA;&#xA;    @Autowired&#xA;    @Qualifier(""userDetailsServiceBean"")&#xA;    private UserDetailsService userDetailsService;&#xA;&#xA;    @Configuration&#xA;    @EnableWebSecurity&#xA;    @EnableGlobalMethodSecurity(jsr250Enabled = true, securedEnabled = true, prePostEnabled = true)&#xA;    public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {&#xA;&#xA;        @Override&#xA;        @Bean(name = ""authenticationManagerBean"")&#xA;        public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;            return super.authenticationManagerBean();&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;            auth.userDetailsService(userDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        protected void configure(HttpSecurity http) throws Exception {&#xA;            http.authorizeRequests().anyRequest().permitAll().and().userDetailsService(userDetailsService).formLogin().and().httpBasic();&#xA;        }&#xA;    }&#xA;&#xA;    @Configuration&#xA;    @EnableAuthorizationServer&#xA;    public class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;        @Autowired&#xA;        @Qualifier(""authenticationManagerBean"")&#xA;        private AuthenticationManager authenticationManager;&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;            endpoints.authenticationManager(authenticationManager).tokenStore(tokenStore());&#xA;        }&#xA;&#xA;        @Bean&#xA;        public ApprovalStore approvalStore() throws Exception {&#xA;            TokenApprovalStore store = new TokenApprovalStore();&#xA;            store.setTokenStore(tokenStore());&#xA;            return store;&#xA;        }&#xA;&#xA;        @Bean&#xA;        public TokenStore tokenStore() {&#xA;            return new InMemoryTokenStore();&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;            clients.withClientDetails(clientDetailsService);&#xA;        }&#xA;&#xA;        @Override&#xA;        public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {&#xA;            security.checkTokenAccess(""permitAll()"");&#xA;            security.allowFormAuthenticationForClients();&#xA;        }&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>My Implementation of Client- and UserDetailsService are very simple and always returns an object</p>&#xA;&#xA;<pre><code>@Service(""clientDetailsServiceBean"")&#xA;public class ClientDetailsServiceBean implements ClientDetailsService {&#xA;&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(ClientDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public ClientDetails loadClientByClientId(String clientId) throws ClientRegistrationException {&#xA;        LOGGER.info(""Load client {}"", clientId); &#xA;        BaseClientDetails details = new BaseClientDetails();&#xA;        details.setClientId(clientId);&#xA;        details.setAuthorizedGrantTypes(Arrays.asList(""password"", ""refresh_token"", ""client_credentials""));&#xA;        details.setScope(Arrays.asList(""trust""));&#xA;        details.setAutoApproveScopes(Arrays.asList(""trust""));&#xA;        details.setAuthorities(Arrays.asList(new SimpleGrantedAuthority(""client_role2"")));&#xA;        details.setResourceIds(Arrays.asList(""clients""));&#xA;        details.setClientSecret(""secret"");&#xA;&#xA;        return details;&#xA;    }&#xA;&#xA;}&#xA;@Service(""userDetailsServiceBean"")&#xA;public class UserDetailsServiceBean implements UserDetailsService {&#xA;    private static final Logger LOGGER = LoggerFactory.getLogger(UserDetailsServiceBean.class);&#xA;&#xA;    @Override&#xA;    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {&#xA;        LOGGER.info(""Load user {}"", username);&#xA;        return new User(username, ""password"", Arrays.asList(new SimpleGrantedAuthority(""ROLE_USER"")) );&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But, when i try to receive an accessToken via</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Full authentication is required to access this resource"" and when i try</p>&#xA;&#xA;<pre><code>curl http://localhost:8081/oauth/token -d grant_type=client_credentials -d client_id=web_client -d client_secret=secret --user web_client:secret&#xA;</code></pre>&#xA;&#xA;<p>i receive an error ""Bad credentials"". From my point of view both should work, but it seems like my configuration is missing. </p>&#xA;&#xA;<p>There are other things with OAuth that unclear to me:&#xA;I try to build an spring-mvc application with spring-security and a custom login form. It's possible to handle token request and refresh cycles by spring security without redirect to the authentication app?</p>&#xA;&#xA;<p>In case of event driven application, it's possible to ensure the token is valid? In case of failure, the user clicks on button and an event is written but the processing of this will be hours later. How can i process the event with the user credentials?</p>&#xA;"
33431076,Environment variables inheritance with microservices (Laravel & Lumen),<php><laravel><inheritance><environment-variables><microservices>,1,399,6,0.0,0,"<p>Recently I ran into a problem while deploying a <strong>Lumen</strong> microservice next to a <strong>Laravel</strong> app. On the same machine I have a Laravel app and a Lumen app both with different <code>.env</code> file and the default environment variables (<code>APP_ENV</code>, <code>DB_HOST</code>, <code>DB_DATABASE</code>, etc).</p>&#xA;&#xA;<p>My <strong>Laravel</strong> app needs to make a request the the <strong>Lumen</strong> app to get some data. That's when the problem occures. When the <strong>Lumen</strong> app receives the request it also inherits the <strong>Laravel</strong>'s environment variables, making it impossible to do it's job (to connect to the database or other services that have the environment variables set in the <code>.env</code> file because all the variables are inherited from the parent request).</p>&#xA;&#xA;<p>Has anyone encountered this problem before? Am I using the microservices architecture the right way?</p>&#xA;&#xA;<p><strong>Update</strong> with code.</p>&#xA;&#xA;<p><em>Laravel app - UsersController.php</em> </p>&#xA;&#xA;<pre><code>/**&#xA; * Makes a request to the Core API and fills properties with the response data&#xA; *&#xA; * @param $method&#xA; * @param $uri&#xA; * @param array|null $data&#xA; */&#xA;public function request($method, $uri, array $data = null)&#xA;{&#xA;    $this-&gt;api = new Client(['base_uri' =&gt; 'http://127.0.0.1/']);&#xA;&#xA;    if (property_exists($this, 'uriPrefix')) $uri = $this-&gt;uriPrefix . $uri;&#xA;    $requestOptions = [&#xA;        'http_errors'   =&gt; false,&#xA;        'headers' =&gt; ['Accept' =&gt; 'application/json']&#xA;    ];&#xA;    if (session('api_cookie')) $requestOptions['headers']['Cookie'] = implode(';', session('api_cookie'));&#xA;    if ($data) {&#xA;        if ($method == 'GET') $requestOptions['query'] = $data;&#xA;        else if (($method == 'POST') || ($method == 'PUT')) $requestOptions['form_params'] = $data;&#xA;    }&#xA;&#xA;    $response = $this-&gt;api-&gt;request($method, $uri, $requestOptions);&#xA;&#xA;    session(['api_cookie' =&gt; $response-&gt;getHeader('Set-Cookie')]);&#xA;&#xA;    $this-&gt;responseCode = $response-&gt;getStatusCode();&#xA;    $this-&gt;responseReasonPhrase = $response-&gt;getReasonPhrase();&#xA;    $this-&gt;responseData = $response-&gt;getBody();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I make this request the <strong>Lumen</strong> app can't connect to the database because it inherits the <code>DB_</code> environment variables from the parent <strong>Laravel</strong> app.</p>&#xA;"
30800908,Dropwizard Jersey Client Sample,<jersey><dropwizard><microservices>,2,1941,3,0.0,0,"<p>Dropwizard <strong><a href=""http://www.dropwizard.io/manual/client.html"" rel=""nofollow"">official documentation</a></strong> jersey Client isn't testable, someone have a dropwizard jersey client sample?</p>&#xA;"
50663047,Microservices and Rest services deployed as jar file?,<java><rest><war><microservices>,3,66,0,0.0,0,"<p>Let's take the simple example, where I have multiplication service as part of single monolithic MathService(deployed as war).</p>&#xA;&#xA;<p>Now I need to deploy multiplication service as separate service(rest service) which MathService can call. The concept of dividing the single monolithic&#xA;in to small maintainable service is microservice.</p>&#xA;&#xA;<p>But I am not sure is it mandatory to deploy Multiplication service as war file? Can it be still deployed as jar file on the web server?</p>&#xA;&#xA;<p>My understanding is that it should be war file as rest calls(HTTP call) needs to be handled by the servlet. Including servlet means it has to be war file.&#xA;Is that correct?</p>&#xA;"
50627087,"If my users are stored in another database, should I duplicate them in my service that uses SQL database?",<mysql><sql><postgresql><microservices>,2,39,5,0.0,0,"<p>If my users are stored in some other database, but I am building posts in my SQL database, should I create another table <code>users</code>?</p>&#xA;&#xA;<p>If I did, I would be duplicating all of my users and would have to make sure this stays in sync with the other database, but on the other hand, my posts tables could save space by referring to fk instead of full id string each time.</p>&#xA;&#xA;<p>What is the recommendation? Create another table <code>users</code> or just pass in the user ids to query? </p>&#xA;"
33033834,how do I migrate a Java interface to a microservice?,<java><rest><microservices>,3,764,0,0.0,0,"<p>I am looking at microservices, and the possibility of migrating some of our code to this architecture.  I understand the general concept but am struggling to see how it would work for our example.</p>&#xA;&#xA;<p>Supposing I have an interface called <code>RatingEngine</code> and an implementation called <code>RatingEngineImpl</code>, both running inside my monolithic application.  The principle is simple - The <code>RatingEngineImpl</code> could run in a different machine, and be accessed by the monolithic application via (say) a REST API, serializing the DTOs with json over http.  We even have an interface to help with this decoupling.</p>&#xA;&#xA;<p>But how do I actually go about this?  As far as I can see, I need to create a new implementation of the interface for the rump monolith (ie now the client), which takes calls to the interface methods, converts them into a REST call, and sends them over the network to the new 'rating engine service'.  Then I also need to implement a new http server, with an endpoint for each interface method, which then deserializes the DTOs (method parameters) and routes the call to our original <code>RatingEngineImpl</code>, which sits inside the server.  Then it serializes the response and sends it back to the client.  </p>&#xA;&#xA;<p>So that seems like an awful lot of plumbing code.  It also adds maintenance overhead, since if you tweak a method in the interface you need to make changes in two more places.</p>&#xA;&#xA;<p>Am I missing something?  Is there some clever way we can automate this boilerplate code construction?</p>&#xA;"
36920620,fastest mechanism to return large data from a micro-service,<json><rest><http><redis><microservices>,1,323,6,1.0,0,"<p>I am new to the micro-service world.</p>&#xA;&#xA;<p>My micro-service has to return a large data (ballpark of 10-20 Mb).&#xA;The returned data contains <strong>large 2D arrays</strong> (""images"") and <strong>small structured data</strong> that can easily be represented with Json.</p>&#xA;&#xA;<p>Important: Both client and server are <strong>on the same machine</strong>.</p>&#xA;&#xA;<p>I have few options to return the data: </p>&#xA;&#xA;<ol>&#xA;<li>Encode the data to bytes array and send in the <strong>post</strong> body.</li>&#xA;<li>Encode only the ""images"" to binary and <strong>""multi-part"" post</strong> json + binary image1 + ... + binary imageN.</li>&#xA;<li>Write the data to a <strong>server resources</strong> (memory?)&#xA;and send the urls to client. The client will fetch the data with&#xA;few <strong>GET</strong> commands.</li>&#xA;<li>Write the data to <strong>Redis DB</strong> and send the client the&#xA;Redis address and data keys. The client will fetch the data with few&#xA;Redis readings.</li>&#xA;</ol>&#xA;&#xA;<p>What is <strong>fastest</strong> and the industry <strong>best known method</strong> to send back the results?</p>&#xA;"
44394119,monolithic or microservice concept,<django><microservices>,2,610,0,0.0,0,"<p>I have a very large django project with many features that uses django as backend framework. My project lets users use both a website and a iOS app.</p>&#xA;&#xA;<p>I am researching using a monolithic app (currently using monolithic) vs micro services, I watched this <a href=""https://www.youtube.com/watch?v=OuhCYGLByJg"" rel=""nofollow noreferrer"">video</a> but one part really throws me off. At 1:05, he previews his 'monolithic' app before he changes to micro services, which to me looks like a single project with a bunch of different apps. </p>&#xA;&#xA;<p>1) Are these technically just folders and not apps? These (what i would assume he calls folders) all have a models.py and views.py and most have a admin.py.</p>&#xA;&#xA;<p>2) What makes this a monolithic app? Is it just because he doesn't simply use django-admin startapp in the terminal to create these 'folders'?</p>&#xA;&#xA;<p>3) Or are microservices multiple projects connected and not simply multiple apps in a single project?</p>&#xA;&#xA;<p>My biggest confusion is with the previewed project in the video because before then I thought I had a good grasp on these concepts. I was simply looking to change to microservices, after this part in the video I'm not sure I even know what a monolithic app really is.</p>&#xA;"
36573857,Consistency with partitioned Service Fabric stateful service,<architecture><microservices><consistency><azure-service-fabric>,4,319,0,0.0,0,"<p>Let's take a simple example. I have a stateful service that manages users. It has a reliable dictionary that maps UserID to some data, including User Name.</p>&#xA;&#xA;<p>In this service's RegisterUser method, we want to check that the user name has not already been used. This is quite straightforward when the service is a singleton, but when it's partitioned we end up with several problems:</p>&#xA;&#xA;<ol>&#xA;<li>We have to ask all partitions if the user already exists. We could possibly introduce another singleton service that maps user name to user id to overcome this problem.</li>&#xA;<li>There's a race condition. Two users could try to register the name user name at the same time. It's possible that both users could succeed.</li>&#xA;</ol>&#xA;&#xA;<p>I'm looking for general advice for possible ways to deal with situations such as this. I can imagine that this sort of problem would occur regularly with partitioned data.</p>&#xA;"
36422243,spring security oauth2 authorization server without any UI,<spring-security><spring-boot><spring-security-oauth2><microservices>,2,951,0,0.0,0,"<p>I have implemented a spring security oauth2 authorization server as a spring boot microservice.  I'm trying to allow our main (non-java) application to migrate to oauth2 using this new service.  </p>&#xA;&#xA;<p>One thing I can't get around my head is how to set this up so that the authorization server never shows any UI.  In particular, is there any way to have the /oauth/authorize UI hosted on our main application, but still accept proxied authorization approvals?  Or does that UI need to be served directly by the authorization server?</p>&#xA;"
36400599,Spring Boot Issue while starting Jetty Container,<spring-boot><microservices>,1,526,5,0.0,0,"<p>When I am starting the spring boot application, it is throwing the following exception.</p>&#xA;&#xA;<p>I am not sure if the FAT jar includes servlet container that has anything related to OS related. Here is the exception I am getting while running the application:</p>&#xA;&#xA;<pre><code>    2016-04-04 15:42:55.146  INFO 10432 --- [           main] application&#xA;                   : Destroying Spring FrameworkServlet 'dispatcherServlet'&#xA;2016-04-04 15:42:55.147  INFO 10432 --- [           main] o.e.jetty.server.handl&#xA;er.ContextHandler  : Stopped o.s.b.c.e.j.JettyEmbeddedWebAppContext@1f144a2b{/,f&#xA;ile:/C:/Users/roopa_ranganath/AppData/Local/Temp/jetty-docbase.89466793494324913&#xA;0.8080/,UNAVAILABLE}&#xA;2016-04-04 15:42:55.154 ERROR 10432 --- [           main] o.s.boot.SpringApplica&#xA;tion               : Application startup failed&#xA;&#xA;org.springframework.boot.context.embedded.EmbeddedServletContainerException: Una&#xA;ble to start embedded Jetty servlet container&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:124) ~[spring-boot-1.3.3.RELEA&#xA;SE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:293) ~[sprin&#xA;g-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.finishRefresh(EmbeddedWebApplicationContext.java:141) ~[spring-boot-1.3.3.REL&#xA;EASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refres&#xA;h(AbstractApplicationContext.java:541) ~[spring-context-4.2.5.RELEASE.jar!/:4.2.&#xA;5.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.3.3.RELEASE.j&#xA;ar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.&#xA;java:766) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.createAndRefreshContext(Sp&#xA;ringApplication.java:361) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:307) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1191) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1180) [spring-boot-1.3.3.RELEASE.jar!/:1.3.3.RELEASE]&#xA;        at com.infosys.finanztools.Application.main(Application.java:13) [Finanz&#xA;ToolsServices-11.2.6-SNAPSHOT.jar!/:11.2.6-SNAPSHOT]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.&#xA;0_66]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.&#xA;0_66]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:&#xA;1.8.0_66]&#xA;        at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_66]&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:54) [FinanzToolsServices-11.2.6-SNAPSHOT.jar!/:11.2.6-SNAPSHOT]&#xA;        at java.lang.Thread.run(Unknown Source) [na:1.8.0_66]&#xA;Caused by: java.net.BindException: Address already in use: bind&#xA;        at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.Net.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.Net.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source) ~[na:1.8.0_66&#xA;]&#xA;        at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source) ~[na:1.8.0_66]&#xA;        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:27&#xA;7) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNet&#xA;workConnector.java:80) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java&#xA;:216) ~[jetty-server-9.2.2.v20140723.jar!/:9.2.2.v20140723]&#xA;        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLife&#xA;Cycle.java:68) ~[jetty-util-9.2.15.v20160210.jar!/:9.2.15.v20160210]&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:118) ~[spring-boot-1.3.3.RELEA&#xA;SE.jar!/:1.3.3.RELEASE]&#xA;        ... 16 common frames omitted&#xA;&#xA;2016-04-04 15:42:55.160  INFO 10432 --- [           main] .b.l.ClasspathLoggingA&#xA;pplicationListener : Application failed to start with classpath: [jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/, jar:file:/D:/FinanzToolsServices-11.2.&#xA;6-SNAPSHOT.jar!/lib/commons-io-2.4.jar!/, jar:file:/D:/FinanzToolsServices-11.2.&#xA;6-SNAPSHOT.jar!/lib/spring-boot-starter-web-1.3.3.RELEASE.jar!/, jar:file:/D:/Fi&#xA;nanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-boot-starter-1.3.3.RELEASE.jar&#xA;!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-boot-1.3.3.&#xA;RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-&#xA;boot-autoconfigure-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-&#xA;SNAPSHOT.jar!/lib/spring-boot-starter-logging-1.3.3.RELEASE.jar!/, jar:file:/D:/&#xA;FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/logback-classic-1.1.5.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/logback-core-1.1.5.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jcl-over-slf4j-1.7.16.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jul-to-slf4j-1.7.&#xA;16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/log4j-over-s&#xA;lf4j-1.7.16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/sna&#xA;keyaml-1.16.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spr&#xA;ing-boot-starter-tomcat-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11&#xA;.2.6-SNAPSHOT.jar!/lib/tomcat-embed-core-8.0.32.jar!/, jar:file:/D:/FinanzToolsS&#xA;ervices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-el-8.0.32.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-logging-juli-8.0.32.jar!/,&#xA;jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/tomcat-embed-websocke&#xA;t-8.0.32.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring&#xA;-boot-starter-validation-1.3.3.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-1&#xA;1.2.6-SNAPSHOT.jar!/lib/hibernate-validator-5.2.4.Final.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/validation-api-1.1.0.Final.jar!/, jar:f&#xA;ile:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jboss-logging-3.3.0.Final.j&#xA;ar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/classmate-1.1.0.&#xA;jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/hibernate-core-&#xA;3.6.0.Final.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/ant&#xA;lr-2.7.7.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/common&#xA;s-collections-3.2.2.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/dom4j-1.6.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/li&#xA;b/hibernate-commons-annotations-3.2.0.Final.jar!/, jar:file:/D:/FinanzToolsServi&#xA;ces-11.2.6-SNAPSHOT.jar!/lib/hibernate-jpa-2.0-api-1.0.0.Final.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jta-1.1.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/finacle-11.2.6.jar!/, jar:file:/D:/Fina&#xA;nzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-logging-1.1.1.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-beanutils-1.9.2.jar!/, j&#xA;ar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/log4j-1.2.17.jar!/, jar&#xA;:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/common-11.2.6.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-11.2.6.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-jaxb-11.2.6.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/finacle-jaxb-11.2&#xA;.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/framework-ap&#xA;i-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/calcul&#xA;ations-api-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/l&#xA;ib/calculations-impl-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPS&#xA;HOT.jar!/lib/commons-lang-2.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNA&#xA;PSHOT.jar!/lib/febaData-11.2.6.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SN&#xA;APSHOT.jar!/lib/spring-core-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsService&#xA;s-11.2.6-SNAPSHOT.jar!/lib/spring-web-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzTo&#xA;olsServices-11.2.6-SNAPSHOT.jar!/lib/spring-beans-4.2.5.RELEASE.jar!/, jar:file:&#xA;/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-webmvc-4.2.5.RELEASE.jar&#xA;!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-tx-4.2.5.RE&#xA;LEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-te&#xA;st-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/li&#xA;b/spring-context-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SN&#xA;APSHOT.jar!/lib/spring-expression-4.2.5.RELEASE.jar!/, jar:file:/D:/FinanzToolsS&#xA;ervices-11.2.6-SNAPSHOT.jar!/lib/spring-aop-4.2.5.RELEASE.jar!/, jar:file:/D:/Fi&#xA;nanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/aopalliance-1.0.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-oxm-4.2.5.RELEASE.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-orm-4.2.5.RELEASE.j&#xA;ar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/spring-jdbc-4.2.&#xA;5.RELEASE.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jmock&#xA;-junit3-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/j&#xA;mock-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/hamc&#xA;rest-core-1.3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/h&#xA;amcrest-library-1.3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/jmock-junit4-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.&#xA;jar!/lib/junit-dep-4.4.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.j&#xA;ar!/lib/jmock-legacy-2.5.1.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSH&#xA;OT.jar!/lib/objenesis-1.0.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/cglib-nodep-2.1_3.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAP&#xA;SHOT.jar!/lib/junit-3.8.2.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/hsqldb-1.8.0.7.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHO&#xA;T.jar!/lib/hibernate-ehcache-3.6.0.Final.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/ehcache-2.10.1.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-api-2.2.5.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-xjc-2.2.5.jar!/, jar:file:/D:/FinanzToolsServices&#xA;-11.2.6-SNAPSHOT.jar!/lib/jaxb-impl-2.2.5.jar!/, jar:file:/D:/FinanzToolsService&#xA;s-11.2.6-SNAPSHOT.jar!/lib/ehcache-core-2.5.0.jar!/, jar:file:/D:/FinanzToolsSer&#xA;vices-11.2.6-SNAPSHOT.jar!/lib/hibernate-entitymanager-3.6.0.Final.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/cglib-2.2.jar!/, jar:file:/D&#xA;:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/asm-3.1.jar!/, jar:file:/D:/Finan&#xA;zToolsServices-11.2.6-SNAPSHOT.jar!/lib/javassist-3.12.0.GA.jar!/, jar:file:/D:/&#xA;FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/integration-1.0.0.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/slf4j-log4j12-1.7.7.jar!/, jar:f&#xA;ile:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/slf4j-api-1.7.7.jar!/, jar:&#xA;file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jstl-1.2.jar!/, jar:file:/&#xA;D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/mysql-connector-java-5.1.10.jar!&#xA;/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-dbcp-1.4.ja&#xA;r!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/commons-pool-1.6.&#xA;jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-server-9.&#xA;2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/j&#xA;avax.servlet-api-3.1.0.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.j&#xA;ar!/lib/jetty-http-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsServices-11.2&#xA;.6-SNAPSHOT.jar!/lib/jetty-io-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/jetty-webapp-9.2.2.v20140723.jar!/, jar:file:/D:&#xA;/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-xml-9.2.15.v20160210.jar!/,&#xA;jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-servlet-9.2.15.v&#xA;20160210.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-&#xA;ant-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/ant-1.6.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/&#xA;ant-launcher-1.6.5.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/&#xA;lib/jetty-annotations-9.2.15.v20160210.jar!/, jar:file:/D:/FinanzToolsServices-1&#xA;1.2.6-SNAPSHOT.jar!/lib/javax.annotation-api-1.2.jar!/, jar:file:/D:/FinanzTools&#xA;Services-11.2.6-SNAPSHOT.jar!/lib/asm-5.0.1.jar!/, jar:file:/D:/FinanzToolsServi&#xA;ces-11.2.6-SNAPSHOT.jar!/lib/asm-commons-5.0.1.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/asm-tree-5.0.1.jar!/, jar:file:/D:/FinanzToolsSe&#xA;rvices-11.2.6-SNAPSHOT.jar!/lib/jetty-plus-9.2.2.v20140723.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-jndi-9.2.2.v20140723.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-util-9.2.15.v20160&#xA;210.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jetty-secur&#xA;ity-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!&#xA;/lib/apache-jstl-9.2.2.v20140723.jar!/, jar:file:/D:/FinanzToolsServices-11.2.6-&#xA;SNAPSHOT.jar!/lib/taglibs-standard-spec-1.2.1.jar!/, jar:file:/D:/FinanzToolsSer&#xA;vices-11.2.6-SNAPSHOT.jar!/lib/taglibs-standard-impl-1.2.1.jar!/, jar:file:/D:/F&#xA;inanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-databind-2.4.0.jar!/, jar:fi&#xA;le:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-core-2.4.0.jar!/, ja&#xA;r:file:/D:/FinanzToolsServices-11.2.6-SNAPSHOT.jar!/lib/jackson-annotations-2.4.&#xA;0.jar!/]&#xA;Exception in thread ""main"" java.lang.RuntimeException: java.lang.reflect.Invocat&#xA;ionTargetException&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:62)&#xA;        at java.lang.Thread.run(Unknown Source)&#xA;Caused by: java.lang.reflect.InvocationTargetException&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;        at java.lang.reflect.Method.invoke(Unknown Source)&#xA;        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner&#xA;.java:54)&#xA;        ... 1 more&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerExc&#xA;eption: Unable to start embedded Jetty servlet container&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:124)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:293)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.finishRefresh(EmbeddedWebApplicationContext.java:141)&#xA;        at org.springframework.context.support.AbstractApplicationContext.refres&#xA;h(AbstractApplicationContext.java:541)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationConte&#xA;xt.refresh(EmbeddedWebApplicationContext.java:118)&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.&#xA;java:766)&#xA;        at org.springframework.boot.SpringApplication.createAndRefreshContext(Sp&#xA;ringApplication.java:361)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:307)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1191)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java&#xA;:1180)&#xA;        at com.infosys.finanztools.Application.main(Application.java:13)&#xA;        ... 6 more&#xA;Caused by: java.net.BindException: Address already in use: bind&#xA;        at sun.nio.ch.Net.bind0(Native Method)&#xA;        at sun.nio.ch.Net.bind(Unknown Source)&#xA;        at sun.nio.ch.Net.bind(Unknown Source)&#xA;        at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)&#xA;        at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)&#xA;        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:27&#xA;7)&#xA;       at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNet&#xA;workConnector.java:80)&#xA;        at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java&#xA;:216)&#xA;        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLife&#xA;Cycle.java:68)&#xA;        at org.springframework.boot.context.embedded.jetty.JettyEmbeddedServletC&#xA;ontainer.start(JettyEmbeddedServletContainer.java:118)&#xA;        ... 16 more&#xA;</code></pre>&#xA;"
49013500,OAuth 2.0 Flows for Microservice Architectures,<oauth-2.0><authorization><microservices><auth0>,3,248,0,0.0,0,"<p>I'm trying to understand how to best apply the OAuth 2.0 grant types to a microservice architecture I am working on. Here's the situatation...</p>&#xA;&#xA;<p>I have a Single-Page Application/Mobile App acting as a client running in a web browser (browser acting as the user agent) or mobile phone. I use the <strong>Implicit Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.2"" rel=""nofollow noreferrer"">RFC 6749, section 4.1</a> to authenticate a user and acquire an access token that the app uses to access some externally exposed API.</p>&#xA;&#xA;<p>The architecture I am dealing with is a collection of microservices that call on one another. For example, consider an externally exposed API <code>serviceA</code> and internal APIs <code>serviceB</code> and <code>serviceC</code>. Let's say <code>serviceA</code> depends on <code>serviceB</code> which subsequently depends on <code>serviceC</code> (<code>A</code> --> <code>B</code> --> <code>C</code>). </p>&#xA;&#xA;<p>My question is, what is the typical authorization flow for this situation? Is it standard to use Implicit Grant for the SPA to acquire an access token and then use the <strong>Client Credentials Grant</strong> defined in <a href=""https://tools.ietf.org/html/rfc6749#section-4.4"" rel=""nofollow noreferrer"">RFC 6749, section 4.4</a> to acquire an access token for the machine to machine interaction between <code>serviceB</code> and <code>serviceC</code>?</p>&#xA;"
48956086,Patterns to segregate Models and DbContext on ASP.NET Core microservices,<design-patterns><asp.net-core><.net-core><microservices><ef-core-2.0>,1,79,3,0.0,0,"<p>I'm trying to make my services to deploy individually without depending on each other.</p>&#xA;&#xA;<p>All services will be using the same SQL database using EF Core (same DbContext).</p>&#xA;&#xA;<p>I'm using a separate project (MyServices.Data) that has all my models and the DbContext, but I'm really dependent on this and if there is any change on this Data project, all services needs to be redeployed.</p>&#xA;&#xA;<p>Is there any pattern/approach to this situation so I can have my project not dependant on it?</p>&#xA;"
36719045,kafka + storm topology vs microservices,<java><apache-kafka><apache-storm><microservices>,2,724,1,1.0,0,"<p>what's the benefit of using storm topology when one can use microservices that connect to kafka directly. the microservice approach seems to offer much better solution for:</p>&#xA;&#xA;<ul>&#xA;<li>tools (every possible library, IoC container etc)</li>&#xA;<li>continuous deployment (existing tools and best practices)</li>&#xA;</ul>&#xA;&#xA;<p>while storm topology seems to use plain java with need of static functions. </p>&#xA;&#xA;<p>so what are the benefits of using storm topology instead of microservices?</p>&#xA;"
36775802,Sharing huge data between microservices,<microservices>,2,2005,1,0.0,0,"<p>I am designing an review analysis platform in microservices architecture. </p>&#xA;&#xA;<p>Application is works like below;</p>&#xA;&#xA;<ul>&#xA;<li>all product reviews retrieved from ecommerce-site-a ( site-a ) as an excel file </li>&#xA;<li>reviews are uploaded to system with excel </li>&#xA;<li>Analysis agent can list all reviews, edit some of them, delete or approve</li>&#xA;<li>Analysis agent can export all reviews for site-a</li>&#xA;<li>Automated regexp based checks are applied for each review on upload and editing. </li>&#xA;</ul>&#xA;&#xA;<p>I have 3 microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Reviews: Responsible for Review Crud operations plus operations similar to approve/reject..</li>&#xA;<li>Validations: Responsible for defining and applying validation rules on review.</li>&#xA;<li>Export/Import: Export service exports huge files given site name (like site-a)</li>&#xA;</ul>&#xA;&#xA;<p><strong>The problem is</strong> at some point, validation service requires to get all reviews for site-a, apply validation rules and generate errors if is there any. I know sharing database schema's and entities breaks micro-services architecture.</p>&#xA;&#xA;<p>One possible solution is</p>&#xA;&#xA;<ul>&#xA;<li>Whenever validation service requires reviews for a site, it requests gateway, gateway redirects request to Reviews service and response taken. </li>&#xA;</ul>&#xA;&#xA;<p>Two <strong>possible drawbacks</strong> of this approach is</p>&#xA;&#xA;<ul>&#xA;<li>validation service <strong>knows</strong> about gateway? Is it brings a dependency?</li>&#xA;<li>in case I have 1b reviews for a site, getting all reviews via rest request may be a problem. ( or not, I can make paginated requests from validation service to gateway..)  </li>&#xA;</ul>&#xA;&#xA;<p>So what is the best practice for sharing huge data between micro-services without </p>&#xA;&#xA;<ul>&#xA;<li>sharing entity</li>&#xA;<li>and dublicating data</li>&#xA;</ul>&#xA;&#xA;<p>I read lot about using messaging queues but I think in my case it is not good to use messaging queue to share gigabytes of data.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>edit 1: Instead of sharing entity, using data stores with rest API can be a solution? Assume I am using mongodb, instead of sharing my entity object between microservices, I can use rest interface of mongo (<a href=""http://restheart.org/"" rel=""nofollow"">http://restheart.org/</a>) and query data whenever possible.  </p>&#xA;"
36760694,Working example of spring watchservicedirectoryscanner,<java><spring><spring-mvc><spring-boot><microservices>,2,1137,2,0.0,0,"<p>I'm struggling to implement a <code>WatchServiceDirectoryScanner</code>. I want to use the scanner to monitor new file uploads to a directory + sub directories. This will exist as part of a Spring boot MVC microservice. I can do this using Java 7's <code>WatchService</code> but would prefer a spring file integration style, AOP style</p>&#xA;&#xA;<p>I have it registered as a <code>@Bea</code>n in my app config but I'm struggling to figure out how to have it poll and scan a directory and then call... something (a message endpoint?) when a file is detected. Is anyone able to point me in the right direction for even conceptually how this is done. I cannot find an example implementation of this anywhere.</p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner"" rel=""nofollow"">http://docs.spring.io/spring-integration/reference/html/files.html#_watchservicedirectoryscanner</a></p>&#xA;&#xA;<p><a href=""http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-"" rel=""nofollow"">http://docs.spring.io/spring-integration/api/org/springframework/integration/file/DefaultDirectoryScanner.html#listFiles-java.io.File-</a></p>&#xA;&#xA;<p>here is my Spring appConfig:</p>&#xA;&#xA;<pre><code>public class appConfig {&#xA;    @Bean&#xA;    public DirectoryScanner scanner() {&#xA;        return new WatchServiceDirectoryScanner(""/uploads/test"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
36694873,Token/stateless auth in Silex application with a Microservice architecture?,<php><session><authentication><silex><microservices>,1,710,2,0.0,0,"<p>I would like to use Silex as a base framework for couple of services. It would be used by different clients and apis (mobile, web etc.) so I'm generally trying to avoid cookies/session and 'do it' using headers.</p>&#xA;&#xA;<p>Setup/flow of what I'm trying to achieve:</p>&#xA;&#xA;<ol>&#xA;<li><p>user logins in his mobile app/on webpage producing request to authservice.domain.com, gets back new token as a response which is as well registered in token store</p></li>&#xA;<li><p>when user access from web or mobile app products.domain.com the token is read from the headers and checked in store</p></li>&#xA;</ol>&#xA;&#xA;<p>Everything looks beautiful, but somehow I cannot make Silex add headers to requests following the login step, I'm able to add it to response, but not to request (i tried using before/after middleware so 1st auth, then add token in $app->after/before)... btw. im not sure if I understand it right, but if a user press a refresh page button when setting headers this way won't the custom header get lost? if that's the case is it possible to keep token persisted in headers without cookies/sessions after all?</p>&#xA;&#xA;<p>Here's example code I'm running after getting token, it gets sets on response (and i can see it in chrome), but it won't get set on request - I tried as well using with before middleware</p>&#xA;&#xA;<pre><code>    $this-&gt;after(function(Request $request, Response $response) {&#xA;        $response-&gt;headers-&gt;set(""X-token"",""2"");&#xA;        $request-&gt;headers-&gt;set(""X-token"",""2"");&#xA;    });&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions on how I can achieve this? So... stateless auth using  headers over multiple services in plain (Silex : )) php without keeping token in cookies or (api gateway) sessions? </p>&#xA;"
36638486,Unable to run node js seneca microservice,<node.js><api><microservices>,1,258,5,0.0,0,"<p>I am new in node js. I try to run my first node microservice using seneca framework. But it shows following error</p>&#xA;&#xA;<pre><code>&gt; npm ERR! Linux 4.2.0-16-generic&#xA;&gt; &#xA;&gt; npm ERR! argv ""/usr/local/bin/node"" ""/usr/bin/npm"" ""start""&#xA;&gt; &#xA;&gt; npm ERR! node v5.10.1&#xA;&gt; &#xA;&gt; npm ERR! npm  v3.8.6&#xA;&gt; &#xA;&gt; npm ERR! code ELIFECYCLE&#xA;&gt; &#xA;&gt; npm ERR! myproject@0.0.1 start: `node server.js`&#xA;&gt; &#xA;&gt; npm ERR! Exit status 2&#xA;&gt; &#xA;&gt; npm ERR! &#xA;&gt; &#xA;&gt; npm ERR! Failed at the myproject@0.0.1 start script 'node server.js'.&#xA;&gt; &#xA;&gt; npm ERR! Make sure you have the latest version of node.js and npm &#xA;&gt; installed.&#xA;&gt; &#xA;&gt; npm ERR! If you do, this is most likely a problem with the myproject&#xA;&gt; package,&#xA;&gt; &#xA;&gt; npm ERR! not with npm itself.&#xA;&gt; &#xA;&gt; npm ERR! Tell the author that this fails on your system:&#xA;&gt; &#xA;&gt; npm ERR!     node server.js&#xA;&gt; &#xA;&gt; npm ERR! You can get information on how to open an issue for this&#xA;&gt; project with:&#xA;&gt; &#xA;&gt; npm ERR!     npm bugs myproject&#xA;&gt; &#xA;&gt; npm ERR! Or if that isn't available, you can get their info via:&#xA;&gt; &#xA;&gt; npm ERR!     npm owner ls myproject&#xA;&gt; &#xA;&gt; npm ERR! There is likely additional logging output above.&#xA;&gt; &#xA;&gt; &#xA;&gt; npm ERR! Please include the following file with any support request:&#xA;&gt; &#xA;&gt; npm ERR!     ~/Desktop/micro services/myproject/npm-debug.log&#xA;</code></pre>&#xA;&#xA;<p>i use Seneca.js Yeoman generator to create this project. Please anyone help me.</p>&#xA;&#xA;<p>my project directry looks like the following structure</p>&#xA;&#xA;<pre><code>        test-seneca&#xA;        |&#xA;        |-- client&#xA;        |   |-- css&#xA;        |   |-- js&#xA;        |   |-- partials&#xA;        |   |-- index.html&#xA;        |-- server&#xA;        |   |-- api.js&#xA;        |-- test&#xA;        |   |-- functional&#xA;        |-- bower.json&#xA;        |-- package.json&#xA;        |-- server.js &#xA;</code></pre>&#xA;&#xA;<p>my package.json is</p>&#xA;&#xA;<pre><code>{&#xA;&#xA;  ""name"": ""myproject"",&#xA;&#xA;  ""version"": ""0.0.1"",&#xA;&#xA;  ""scripts"": {&#xA;&#xA;    ""postinstall"": ""./node_modules/.bin/webdriver-manager update --standalone &amp;&amp; ./node_modules/.bin/bower install"",&#xA;&#xA;    ""test"": ""./node_modules/.bin/protractor test/functional/protractor.conf.js""&#xA;&#xA;  },&#xA;&#xA;  ""dependencies"": &#xA;{&#xA;&#xA; ""async"": ""^0.9.0"",&#xA;&#xA;    ""hapi"": ""~8.2.0"",&#xA;&#xA;    ""hapi-seneca"": ""^1.0.3"",&#xA;&#xA;    ""seneca"": ""git://github.com/rjrodger/seneca.git"",&#xA;&#xA;    ""seneca-account"": ""^0.1.8"",&#xA;&#xA;    ""seneca-auth"": ""git://github.com/rjrodger/seneca-auth.git"",&#xA;&#xA;    ""seneca-card"": ""^0.1.3"",&#xA;&#xA;    ""seneca-project"": ""^0.1.4"",&#xA;&#xA;    ""seneca-user"": ""~0.2.10""&#xA;&#xA;  },&#xA;&#xA;  ""devDependencies"": {&#xA;&#xA;    ""protractor"": ""~1.7.0"",&#xA;&#xA;    ""bower"": ""~1.3.12""&#xA;&#xA;  }&#xA;&#xA;}&#xA;</code></pre>&#xA;"
35286730,How to execute efficient communication for multiple (micro)services?,<php><rest><restful-architecture><microservices>,1,574,1,1.0,0,"<p><strong>Case:</strong> Software build with many microservices and internal services.</p>&#xA;&#xA;<p><strong>The doubt</strong> is how to manage performance issues (network latency, size of resource) getting multiple resources from many microservices at once.</p>&#xA;&#xA;<p>I Just can not imagine making 20 HTTP requests to access all necessary resources.</p>&#xA;"
28581644,Protect Kafka against flood,<security><apache-kafka><microservices>,3,174,0,0.0,0,"<p>I use Kafka in production. Many services send and read messages into it.</p>&#xA;&#xA;<p>All work fine but I had a bug in one service.&#xA;For a weird reason this one sends millions messages by second to Kafka.</p>&#xA;&#xA;<p>Due to this bug, my Kafka crashes.</p>&#xA;&#xA;<p>It's not a Kafka bug but how can I protect it against potential flood ?</p>&#xA;"
40525468,Java 8 LocalDate displaying in swagger,<java><documentation><swagger><microservices><swagger-2.0>,1,1693,0,0.0,0,"<p>I have a DTO which contains field of Java 8 LocalDate type. With Jackson annotations it's possible to set format to <code>ISO.DATE</code> and everything works good. But Swagger (I have version 2.+) see the <code>LocalDate.class</code> as object</p>&#xA;&#xA;<pre><code>LocalDate {&#xA;month (integer, optional),&#xA;year (integer, optional)&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(That's true but...) I want to dipsay this as string with format as it works with <code>util.Date</code>.&#xA;How can I solve it?</p>&#xA;"
40436389,using entity in other jhipster microservice,<jhipster><microservices>,2,673,0,0.0,0,"<p>I have problem to use entities between Microservices ,I have microservice1 has Team entity I need to use Team entity in microservice2 ,I mean I need to import TeamRepository.java in microservice2,How can do that with jhipster?</p>&#xA;"
40467382,how to use role authorization for micro services architecture?,<ruby-on-rails><microservices><rails-api>,3,205,0,0.0,0,<p>I wrote an API in rails which is of micro services architecture.&#xA;In my API i need to implement Role authorization to authorize each and every user using their roles.&#xA;Is there any gem that fits into micro services architecture or should I write my own logic to authorize users.&#xA;i was using gem authorization gem but it does provide much capability that fits into micro services architecture.(rolify)&#xA;Is there any other that suits micro services architecture?</p>&#xA;&#xA;<p>Thanks in Advance.</p>&#xA;
40469391,"Wait for condition in Enzyme and Jest (eventual consistency, assert with timeout)",<reactjs><microservices><jestjs><enzyme>,1,431,4,0.0,0,"<p>I have a simple test:</p>&#xA;&#xA;<pre><code>import React from 'react';&#xA;import GenericButton from 'components/buttons/GenericButton';&#xA;import { shallow } from 'enzyme';&#xA;import { shallowToJson } from 'enzyme-to-json';&#xA;&#xA;describe('Generic Button', () =&gt; {&#xA;    test('Button action called when clicked', () =&gt; {&#xA;        var clicked = false;&#xA;        const component = shallow(&#xA;            &lt;GenericButton action={() =&gt; {&#xA;                clicked = true;&#xA;            }}&#xA;            id=""testComponent""/&gt;&#xA;        );&#xA;&#xA;        component.find('testComponent').first().simulate('click');&#xA;        expect(clicked).toBeTruthy();&#xA;    });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However this will fail as the action is done eventually,</p>&#xA;&#xA;<p>If i set the assertion to happen eventually (using setTimeout for example) it will work</p>&#xA;&#xA;<p>however it would be better if i do something of the following before the assert (found this on examples using jasmine)</p>&#xA;&#xA;<pre><code>        waitsFor(() =&gt; {&#xA;            return clicked;&#xA;        }, ""the value to change"", 1000);&#xA;</code></pre>&#xA;&#xA;<p>What is the equivalent call for enzyme/jest?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Edit: Content of component</p>&#xA;&#xA;<pre><code>render() {&#xA;    return &lt;Button id={this.props.id}&#xA;                   key={this.props.id}&#xA;                   onClick={() =&gt; this.props.action()}&#xA;                   bsStyle={this.props.style}&gt;&#xA;               {this.props.text}&#xA;           &lt;/Button&gt;;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>(Button is a 3rd party library component)</p>&#xA;"
32750861,Using search in grails 3.x web-micro rest call does not work,<grails><microservices>,1,80,3,0.0,0,"<p>I'm using the web-micro profile from Grails 3.x to write microservices.  I need to be able to search on one of the fields.  I believe in previous versions of grails, you could add the fields to the query string. </p>&#xA;&#xA;<p><a href=""http://localhost:3141/zipcode?zip=55509"" rel=""nofollow"">http://localhost:3141/zipcode?zip=55509</a> would return just the zipcode object(s) that had that value for zip.</p>&#xA;&#xA;<p>This does not seem to work in Grails 3.x web-micro.</p>&#xA;&#xA;<pre><code>@Entity &#xA;@Resource(uri=""/zipcode"") &#xA;class ZipCode { &#xA;    static belongsTo = [kingdomGroup : KingdomGroup] &#xA;    String zip &#xA;&#xA;    static constraints = { &#xA;    }&#xA;&#xA;    String toString() { zip } &#xA;}&#xA;</code></pre>&#xA;"
35914674,Cascading microservices using Meteor,<meteor><package><cluster-computing><microservices>,1,169,11,1.0,0,"<p>I've been looking into scaling Meteor, and had an idea by using the <a href=""https://www.google.co.uk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi3z66g-7XLAhWDRhQKHS_qBwsQFggkMAA&amp;url=https%3A%2F%2Fgithub.com%2Fmeteorhacks%2Fcluster&amp;usg=AFQjCNEy9N5lo-9TmjFYvjgmCCO93mAwmg"" rel=""nofollow"">Meteor Cluster package</a>;</p>&#xA;&#xA;<ul>&#xA;<li>Create a super-service*, which the user connects to, containing general core packages to be used by every micro-service (api, app, salesSite, etc. would make use of its package),</li>&#xA;<li>The super-service then routes to the appropriate micro-service (e.g., the app), providing it with the functionality of its own packages.</li>&#xA;</ul>&#xA;&#xA;<p>(* - as in super- and sub-, not that it's awesome... I mean it is but...)</p>&#xA;&#xA;<p>The idea being that I can cascade each service as a superset of the super-service. This would also allow me to cleverly inherit functionality for other services in a cascading service style. E.g.,</p>&#xA;&#xA;<p>unauthedApp > guestApp > userApp > modApp > adminApp, </p>&#xA;&#xA;<p>for the application, where the functionality of the previous service are inherited to the preceding service (e.g., the further right along that chain, the more extra functionality is added and inherited).</p>&#xA;&#xA;<p>Is this possible?</p>&#xA;&#xA;<p>EDIT: If possible, is there a provided example of how to implement such a pattern using micro-services?</p>&#xA;&#xA;<p><strong>[[[[[ BIG EDIT #2: ]]]]]</strong></p>&#xA;&#xA;<p>Think I'm trying to make a solution fit the problem, so let me re-explain so this question can be answered based on the issue rather than the solution I'm trying to implement.</p>&#xA;&#xA;<p>Basically, I want to ""inherit"" (for lack of a better word) the packages depended on needed functionality, so that no code is unnecessarily sent through the wire. </p>&#xA;&#xA;<p>So starting with the core packages, which has libraries I want all of my services to have, I then want to further ""add"" the functionality as needed. Then I want to add page packages if serving a page-based service (instead of, say, the API service, which doesn't render pages), then the appropriate role-based page packages, etc., until the most specific packages are added.</p>&#xA;&#xA;<p>My thought was that I could make the services chain in such a way that I could traverse through from the most generic to most specific service, and that would finally end with a composition of packages from multiple services. So, for e.g., the guestApp, that might be the core packages + generic page packages + generic app packages + unauthApp packages + guestApp packages, so no unneccessary packages are added.</p>&#xA;&#xA;<p>Also with this imaginary pattern I'm describing, I don't need to add all my core packages to each microservice - I can deal with them all within the core package right at the top of the package traversal I've discussed above and not have to worry about forgetting to add the packages to the ""inherited"" packages.</p>&#xA;&#xA;<p>Hope my reasoning here makes sense, and I hope you guys know of a best practice for doing this. Thank you!</p>&#xA;"
33659658,Service Fabric Reliable Services: proccessing parallel request with CPU-bound methods,<c#><azure><microservices><azure-service-fabric>,2,1663,0,0.0,0,"<p>Azure <strong>Service Fabric</strong>'s Reliable Actors turn-based concurrency is described in official documentation.As If I get it right, <strong>Reliable Services</strong>, can serve multiple requests simultaneously.&#xA;Lets say I have a Reliable Service with single CPU-bounded method.&#xA;Method is async as expected, so Service can handle multiple requests.&#xA;My local cluster is hosted on 2-core machine, when I call Service from 2 different console-app clients, CPU 100% utilized as expected. So there is no reason to handle more than 2 request simultaneously. How can I limit this?&#xA;And if I move to real cluster, I don't know anything about machine Service hosted on, what should I do then?</p>&#xA;&#xA;<pre><code>public async Task&lt;bool&gt; CpuBoundAsync(int value)&#xA;&#xA;    {&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK IN PROGRESS"");&#xA;        int z;&#xA;        await Task.Run(() =&gt;&#xA;        {&#xA;            for (int i = 0; i &lt; int.MaxValue; i++)&#xA;            {&#xA;                z++;&#xA;                z--;&#xA;            }&#xA;        });&#xA;&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK COMPLETED"");&#xA;        return true;&#xA;    }&#xA;</code></pre>&#xA;"
29731394,dependency management on micro services architecture,<git><dependencies><microservices>,2,836,0,0.0,0,"<p>I build an app based on the micro services architecture, i have now two services with some common code to both.</p>&#xA;&#xA;<p>What is the conventional way to do that? (different projects, modules etc)&#xA;I would also like a refernece on how to handle them in a git repository (for all? for each?)</p>&#xA;"
29821391,Spring @RequestMapping redirect to same path with additional info,<java><spring><spring-mvc><spring-boot><microservices>,2,861,3,0.0,0,"<p>A somewhat unusual scenario perhaps, but we need to redirect in a Spring MVC controller from:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html&#xA;</code></pre>&#xA;&#xA;<p>to:</p>&#xA;&#xA;<pre><code>/js/hal-browser/browser.html#/some_path/&#xA;</code></pre>&#xA;&#xA;<p>All my attempted solutions to date have resulted in a redirect loop, as Spring performs the redirect but is then repeatedly matching /browser.html in the redirect URL, regardless of the additional info.  What I need to say is 'match /browser.html ONLY if it's the end of the path'.</p>&#xA;&#xA;<p>I have tried <code>setUseSuffixPatternMatch(Boolean.FALSE);</code> on the <code>PathMatchConfigurer</code> to no avail, also tried the following URI template regex pattern in the request mapping itself:</p>&#xA;&#xA;<pre><code>""/js/hal-browser/{file:browser\\.html$}""&#xA;</code></pre>&#xA;&#xA;<p>..but still get a redirect loop. Ideas appreciated - this is Spring 4.1.6 in a SpringBoot 1.2.3 microservice, by way of context.</p>&#xA;&#xA;<p><strong>Update:</strong>&#xA;On further investigation and a better understanding of the URL fragment in use by the HAL browser to determine which path it will make a request to within the microservice itself, I believe the solution may lie not in trying to redirect off <code>browser.html</code>, as Spring will map this to the same controller method on every request regardless of the fragment value, but instead either reverting to the default context path for the application (<code>/</code>), which the HAL browser has set as its default entry point, or finding a way to configure the embedded tomcat container to respond with something sensible (not just a 404) on the default context path even though the app is mapped to /some_path.</p>&#xA;&#xA;<p>As further context, we can redirect no problem at all from a convenience path of <code>/browser</code> (or whatever) into the HAL browser with the correct entry point fragment as the context path of the service - that works fine. The issue is the browser itself has a 'Go to entry point' button which, when pulling it in as a <a href=""https://github.com/Product-Foundry/hal-browser-webjar"" rel=""nofollow"">webjar</a>, is hardcoded to <code>/</code>. The other alternative is to ditch the webjar and just copy in the static files for the browser and update the entry point.</p>&#xA;"
29610354,Discovery pattern for REST API endpoint,<java><node.js><rest><microservices>,1,674,3,0.0,0,"<p>I m actually studying Microservice architecture pattern and it seems that the API Gateway pattern uses the Discovery pattern, but with REST API endpoints.</p>&#xA;&#xA;<p>Can anybody explain me how it works for example if my API Gateway is NodeJS based and my REST APIs are Java written ?</p>&#xA;&#xA;<p>I dont really know how can I implement this pattern and I dont find any code or schema to help me understand a bit more.</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
38764797,Get AccessToken from spring cloud zuul API Gateway,<wso2is><spring-cloud><microservices><oauth2><netflix-zuul>,1,301,4,0.0,0,<p>We are using zuul as API gateway in spring cloud. Now we want to extract access token from zuul for further implementation.Please provide suggestion how we want to implement. Thank you</p>&#xA;
49849813,Node js microservice,<node.js><spring><microservices>,1,53,3,0.0,0,<p>Can anyone please tell how to consume a node js based microservice from spring based web application?can restful API be the best choice to be used by the application to message the microservices based on nodejs ?</p>&#xA;
36176403,Spring boot microservice with OAuth 2 and JWT for Security,<oauth-2.0><spring-boot><jwt><microservices><api-management>,1,1343,0,0.0,0,"<p>I am developing a Spring boot application for payment using microservices, which will be consumed by mobile application and web application. </p>&#xA;&#xA;<p>1) Users need to be authenticated for accessing the mobile app</p>&#xA;&#xA;<p>2) Third party mobile apps using my services need to be authenticated (with my app)</p>&#xA;&#xA;<p>3) Web applications using my services need to be authenticated. </p>&#xA;&#xA;<p>My user details will be there in DB or LDAP. I have plans for integrating IBM API management and the deployment will be in on-premise servers. Based on this requirement how I need to design and implement my solution? </p>&#xA;&#xA;<p>After going through different blogs I am confused now. So a proper guidance will be very helpful for me.</p>&#xA;"
42060090,How mule api manager manage spring boot based service?,<spring-boot><mule><microservices>,1,555,0,1.0,0,"<p>I've created a spring boot based service and like to deploy it to existing mule API platform, then I realize there are some challenges I need to face by myself such as, service discovery and policy management. </p>&#xA;&#xA;<p>To be specific, I want to know if there is any way to manage policy for spring boot service from mule API manager? Since there is no agent that mule service has.</p>&#xA;"
42046797,"New to Microservices - refactoring a monolith ""Marketplace"" database",<oop><microservices>,1,180,3,0.0,0,"<p>I am new to microservices and have been struggling to wrap my brain around it. On the surface they sound like a good idea, but from a practical standpoint, I can't break away from my centralized database background. For an example, I have this real-world Marketplace example that I cannot figure out if microservices would help or hurt. This site was working well until the PO asked for ""Private Products."" Now it is fragile and slow so I need to do a major refactor. A good time to implement microservices. I feel like many systems have this type of coupling, so that deconstructing this example would be very instructive. </p>&#xA;&#xA;<p><strong>Current State</strong> </p>&#xA;&#xA;<p>This is a b2b marketplace where users belong to companies that are buying products from each other. Currently, there exists a monolithic database: User, Company, Catalog, Product, and Order. (This is a simplification, the actual scenario is much more complicated, users have roles, orders have header/detail, products have inventories, etc.)</p>&#xA;&#xA;<ul>&#xA;<li>Users belong to Companies</li>&#xA;<li>Companies have a Catalog of their Products</li>&#xA;<li>Companies have Orders for Products from other Companies </li>&#xA;</ul>&#xA;&#xA;<p>So far so good. I could see breaking the app into microservices on the major entity boundaries. </p>&#xA;&#xA;<p><strong>New Requirement</strong></p>&#xA;&#xA;<p>Unfortunately for my architectural aspirations, the product owner wants more features. In this case: Private Products.</p>&#xA;&#xA;<ul>&#xA;<li>Products are Public or Private</li>&#xA;<li>Companies send time-bound Invitations to Products or Catalogs to Users of other Companies</li>&#xA;</ul>&#xA;&#xA;<p>This seemingly simple request all the suddenly complicated everything.</p>&#xA;&#xA;<p><strong>Use Case - User displays a list of products</strong></p>&#xA;&#xA;<p>For example, listing or searching products was once just a simple case of asking the Products to list/search themselves. It is one of the top run queries on the system. Unfortunately, now what was a simple use case just got messy.</p>&#xA;&#xA;<ul>&#xA;<li>A User should be able to see all public Products (easy)</li>&#xA;<li>A User should be able to see all their own Company's private Products (not horrible)</li>&#xA;<li>A User can see any Product that their Company has Ordered in the past regardless of privacy (Uh oh, now the product needs to know about the User Company's Order history) </li>&#xA;<li>A User can see any private Product for which they have an active Invitation (Uh oh, now the product needs to know about the User's Product or Catalog Invitations which are time dependent)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Initial Monolithic Approach</strong></p>&#xA;&#xA;<p>This can be solved at the database level, but the SQL joins basically ALL of the tables together (and not just master data tables, all the transactions as well.) While it is a lot slower than before, since a DBMS is designed for big joins it seems like the appropriate tool. So I can start working on optimizing the query. However, as I said, for this and other reasons the system is feeling fragile.</p>&#xA;&#xA;<p><strong>Initial Design Thoughts... and ultimately my questions</strong></p>&#xA;&#xA;<p>So considering a Microservices architecture as a potential new direction, I began to think about how to start. Data redundancy seems necessary. Since, if I translate my major entities into services, asking to get a list of products without data redundancy would just have all of the services calling each other and a big slow mess. </p>&#xA;&#xA;<p>Starting with a the idea of carving out ""Product and Catalog"" as its own microservice. Since Catalogs are just collections of Products, they seem to belong together - I'll just call the whole thing the ""Product Service"". This service would have an API for managing both products and catalogs and, most importantly, to search and list them.</p>&#xA;&#xA;<p>As a separate service, to perform a Product search would require a lot of redundant data as it would have to subscribe to any event that affected product privacy, such as:</p>&#xA;&#xA;<ul>&#xA;<li>Listen for Orders and keep at least a summary of the relationship between purchased Products and Purchasing Companies</li>&#xA;<li>Listen to Invitations and maintain a list of <strong>active</strong> User/Product/Time relationships </li>&#xA;<li>Listen to User and Company events to maintain a User to Company relationship</li>&#xA;</ul>&#xA;&#xA;<p>I begin to worry about keeping it all synchronized. </p>&#xA;&#xA;<p>In the end, a Product Service would have a large part of the current schema replicated. So I begin to think, maybe Microservices won't work for this situation. Or am I being melodramatic and the schema will be simpler enough to be more managable and faster so it is worth it?</p>&#xA;&#xA;<p>Overall, am I thinking about this whole approach properly? Is this how microservice based designs are intended to be thought through? If not, can somebody give me a push in a different direction?</p>&#xA;"
42061684,Microservice redundancy issue in our architecture,<microservices>,1,246,4,0.0,0,"<p>We have 12 microservices deployed in our application server. Problem is, since we have a microservice for each specific function, a lot of libraries are being repeated in each microservice instead of if they are shared in larger monolithic services or app. This causes each .ear file to be large per microservice. with this, out of memory errors start to happen more often.</p>&#xA;&#xA;<p>Is there any way to get around this? or better ways to do this?</p>&#xA;"
31468806,Identity management with multiple spring boot micro services,<spring><spring-boot><single-sign-on><microservices><identity-management>,2,918,1,0.0,0,"<p>I have multiple spring boot applications for difference purposes. &#xA;For example, mobile clients send their GPS coordinates to one spring boot micro service and at the same time, these mobile client access another spring boot micro service to do their CRUD operations. </p>&#xA;&#xA;<p>I'm facing with a problem of authenticating clients. I don't want do the authentication at all the services. Rather I would like to do this by using another identity management server (ex: Kerberos)  which produce a SSO token for all these micro services.</p>&#xA;&#xA;<p>OR a proxy which authenticates all the incoming requests and delegates them to relevant micro service.</p>&#xA;&#xA;<p>I searched couple of hours and I couldn't find any solid information on securing micro services even in general.</p>&#xA;&#xA;<ol>&#xA;<li>The design or architecture I'm taking is correct? </li>&#xA;<li>What is the best approach for this kind of a situation?</li>&#xA;<li>How can I implement this identity server/proxy who does the authentication?</li>&#xA;<li>Any technology, known identity mgmt servers which can easily integrate with Spring, known design patterns are there?</li>&#xA;</ol>&#xA;&#xA;<p>One question more,&#xA;It is OK to implement same authentication layer at each of these services?&#xA;(Because I think it is bad and I may wrong with that)</p>&#xA;&#xA;<p>I would like to stick with Spring.</p>&#xA;&#xA;<p>Highly appreciate if someone can direct me to a correct path.</p>&#xA;"
48153334,Microservices Monitoring Using Status Code,<amazon-web-services><microservices>,1,34,3,0.0,0,"<p>We are using Amazon ECS for micro-services based architecture. We are right now using ALB service monitoring with target-group associated with each service in an ECS cluster. </p>&#xA;&#xA;<p>Right now, We are facing difficulty to monitor the microservices as they are hosted under route 53 private hosted zone. </p>&#xA;&#xA;<p>We have tried to monitor Route 53 health monitoring but route 53 doesn't allow to monitor the health of the endpoints with a simple routing policy. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Ref:&#xA;  <a href=""https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html</a></p>&#xA;</blockquote>&#xA;&#xA;<p>We need to monitor the status code of each microservice at any interval of time. </p>&#xA;&#xA;<p>We have also setup health-check for each microservice. Example: service-a.domain/ping. We need a status-page which represent the health of all available service we add using the status code we add. Also, any way if we can monitor them from application load balancer target group).</p>&#xA;&#xA;<p>What will be the best way to monitor every microservice. ?</p>&#xA;"
47975940,NodeJs micro services shared dependencies,<node.js><npm><microservices><dependency-management>,1,66,7,0.0,0,"<p>i have built a microservices application using NodeJs . i have building this app for 4 month now and it starts to be big. i have used private modules to share code between the services but now i face anther problem. </p>&#xA;&#xA;<p>i am getting duplicate code for requiring this modules(and public modules) as many of them are being used in all the services and are called in my index file.</p>&#xA;&#xA;<p>so what i have try to do is build anther private module that it`s purpose is to include all this modules dependencies and control all the updates .</p>&#xA;&#xA;<p>that works good, the problem is the IDE ""phpstorm"" screams on me because now those dependencies are not in the service package.json  and also i dont have autocomplete on them(same reason) .</p>&#xA;&#xA;<p>is there a way to let the package json to use this dependencies from that package , or maybe anther technique to achieve this </p>&#xA;"
39721025,microservices for very small enterprise,<api><web-applications><architecture><microservices>,2,699,2,0.0,0,"<p>Presently i'm working as web developper in a small company and i'm in charge to create a new web software to manage our business.&#xA;We cannot hire new developpers yet and we must deliver a first version as soon as posible.&#xA;In this context, i'm thinking about microservices architecture and i don't know if we should spend some time and resources to start our project with this kind of architecture.&#xA;Somebody has some experience about this subject?</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
35890054,Test automation for microservices architecture,<automated-tests><microservices>,3,609,2,0.0,0,"<p>I am in charge of implementing QA processes and test automation for a project using microservices architecture.</p>&#xA;&#xA;<p>Project has one public api that makes some data available. So I will automate API tests. Tests will live in one repository. This part is clear to me, I did this before in other monolith projects. I had one repo for API tests. And possibly another repo for selenium tests.</p>&#xA;&#xA;<p>But then here the whole poduct consists of many microservices that communicate via restful apis and/or rabbit queues. How would I go about automating tests for each of these individual servicess? Would tests for each individual service be in a separate repo? Note: services are written in Java or PHP. I will automate tests with Python. It seems to me that I will end up with a lot of repos for tests/stubs/mocks.</p>&#xA;&#xA;<p>What suggestions or good resources can community offer? :)</p>&#xA;"
35589008,Advice on how to monitor (micro)services?,<service><spring-boot><monitoring><microservices><spring-boot-actuator>,1,851,2,0.0,0,"<p>We are transitioning from building applications on monolith application servers, to more microservices oriented applications on Spring Boot. We will publish health information with SB Actuator through HTTP or JMX.</p>&#xA;&#xA;<p>What are the options/best practices to monitor services, that will be around 30-50 in total? Thanks for your input!</p>&#xA;"
46725906,Spring boot micro services rest API security,<rest><security><spring-boot><oauth><microservices>,1,691,0,0.0,0,<p>Am newbie to spring boot micro services. I have 3 micro service that are</p>&#xA;&#xA;<pre><code>1. Login authentication&#xA;2. User service&#xA;3. Account service.&#xA;4. UI Service&#xA;</code></pre>&#xA;&#xA;<p>UI Service contains UI part this micro service will calls other API's. First 3 services should validate every rest api calls. I need to implement security for rest api calls that need to be global and shared across all micro services. What would be the best approach without using oauth. Because OAuth need server. Hence without this is there any way to achieve this. I googled and not getting clear view. how to resolve this</p>&#xA;
46717204,Microservices sequential data processing,<multithreading><microservices><partitioning><seq>,1,31,3,0.0,0,"<p>Suppose I am receiving a stream of unordered sequential data in time.</p>&#xA;&#xA;<p>For example, input could be:</p>&#xA;&#xA;<pre><code>[&#xA;    {id:1, timestamp:1},&#xA;    {id:2, timestamp:1},&#xA;    {id:2, timestamp:2},&#xA;    {id:1, timestamp:2},&#xA;    {id:3, timestamp:1}&#xA;] &#xA;</code></pre>&#xA;&#xA;<p>Each entity is identified by 'id' field. There could be a large amount of entities and processing for each input could take some time. &#xA;The problem is that I need to process each of those events in order it was received for each entity. </p>&#xA;&#xA;<p>I was considering some solutions as to put messages to Kafka topic with partitions and receive parallelism?&#xA;Or create local storage of received messages and marking each processed message for each entity after successful processing (on other machine or on the same in Thread pool)?</p>&#xA;&#xA;<p>Questions:&#xA;Is it is a good solution? &#xA;How can I reach this functionality while scaling data consumers (having fixed number of services/ creating new instances)? &#xA;Maybe there is a better way to solve such kind of problem?</p>&#xA;"
46764158,"Design an application with multiple request sources: WS(SOAP\REST), MQ, batch",<java><java-ee><design-patterns><microservices><enterprise-architecture>,1,41,3,1.0,0,"<p>I have to design an application which gets requests from multiple sources like Web service (can be SOAP or REST), online system, Message Queue or some batch job. Application needs to interface with 2 more applications for getting results. I understand that this can be done using microservices. This application needs to be built in Java. I am looking for some framework which can help me with accepting input from multiple sources as mentioned above.</p>&#xA;"
46782161,User preferences with microservice architecture,<amazon-web-services><microservices><user-preferences>,1,178,4,0.0,0,"<p>Me and my team are implementing a product based on microservices architecture(<strong><em>every microservice has it's own data storage</em></strong>). We already have a couple of services deployed on AWS and we need to add an ability to save user preferences like:</p>&#xA;&#xA;<ol>&#xA;<li>Saved filters to query data</li>&#xA;<li>UI widget settings</li>&#xA;<li>Columns order</li>&#xA;<li>etc</li>&#xA;</ol>&#xA;&#xA;<p><strong>I think that we have the following options to implement saving user-preferences in my case:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Extend user profile(it is used to store companies and users, roles) service and add new items there</li>&#xA;<li>Create new microservice for keeping only user preferences</li>&#xA;<li>Use some of AWS services for that(I am still checking what is the best)</li>&#xA;</ol>&#xA;&#xA;<p><strong>What we use for security:</strong></p>&#xA;&#xA;<ul>&#xA;<li>AWS Cognito</li>&#xA;<li>SAML IDP</li>&#xA;<li>JWT tokens</li>&#xA;</ul>&#xA;&#xA;<p>We also have user-profile microservice(I mentioned earlier). It contains data received from other products like admin service.</p>&#xA;&#xA;<p>What do you think? What is the best option for my case?</p>&#xA;"
46786169,How to check the request body parameters type validation in akka http micro-services?,<scala><akka><microservices><akka-http>,1,326,6,1.0,0,"<p>my Object is</p>&#xA;&#xA;<pre><code>case class  Request(id:Int,name:String,phone:String)&#xA;</code></pre>&#xA;&#xA;<p>my request in postman is</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"":   ""1205"", **here i have changed the request body parameter type Int to String**&#xA;    ""name"":     ""sekhar"",&#xA;    ""phone"":""1234567890""&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>how can I check the request parameter is valid or invalid when my request body field is the wrong data type</p>&#xA;&#xA;<p>I have used</p>&#xA;&#xA;<pre><code>implicit def myRejectionHandler = RejectionHandler.newBuilder()&#xA;    .handle {&#xA;      case MissingQueryParamRejection(param) =&gt;&#xA;        println("" Test1  "")&#xA;        val errorResponse = ErrorResponse(BadRequest.intValue, ""Missing Parameter"", s""The required $param was not found."")&#xA;        var json:JsValue=Json.toJson(errorResponse)&#xA;        complete(HttpResponse(BadRequest, entity = HttpEntity(ContentTypes.`application/json`, json.toString())))&#xA;    }&#xA;    .handle { case MissingFormFieldRejection(msg) =&gt;&#xA;      println("" Test2  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handle { case MalformedQueryParamRejection(msg,error,cause) =&gt;&#xA;      println("" Test3  "")&#xA;      complete(BadRequest, msg)&#xA;    }&#xA;    .handleAll[MethodRejection] { methodRejections =&gt;&#xA;    val names = methodRejections.map(_.supported.name)&#xA;     println("" Test4  "")&#xA;    complete((MethodNotAllowed, s""Can't do that! Supported: ${names mkString "" or ""}!""))&#xA;    }&#xA;    .handleNotFound { complete((NotFound, ""Not here!"")) }&#xA;    .result()&#xA;&#xA;val routes: Route = handleRejections(myRejectionHandler) {&#xA;    //Routes &#xA;  }&#xA; Http().bindAndHandle(routes, ""localhost"", 8090)&#xA;</code></pre>&#xA;&#xA;<p>it's, again and again, takes only handleAll[MethodRejection] when being changed the query params(for the false parameter too) on that time too.</p>&#xA;"
51566509,In Microservices is it acceptable to have an API returning an Aggregate Root that was replicated?,<domain-driven-design><microservices><multiple-databases><aggregateroot>,3,72,7,0.0,0,"<p>Imagine we have a microservice M1 with an aggregate root called <code>Player</code> and a microservice M2 with an aggregate root called <code>Classification</code>, now in the M1 we need to do some logic based on some property from <code>Classification</code>, now some steps to do that are:</p>&#xA;&#xA;<ol>&#xA;<li>Replicate the list of possible Classifications to M1 via asynchronous messaging;</li>&#xA;<li>Do what is asked by the business in M1;</li>&#xA;</ol>&#xA;&#xA;<p>Ok, now imagine we have a view to add Players, and in that view is possible to choose the <code>Classification</code> of the new <code>Player</code> from a dropdown list. Now the question:</p>&#xA;&#xA;<p>Should the dropdown list be populated with the Classifications that were replicated into M1 or from M2?</p>&#xA;&#xA;<p>As you can see, by using the data from M1 we would have to expose the <code>Classification</code> from M1 via an API, thus the title of the question.</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>The replications happens through async messaging using events, so I'm not exposing the entire aggregate to M1 just some properties like an Id and the Description of the classification.</p>&#xA;"
37715757,Trade-offs of microservices and modularity architectural design?,<design><osgi><polymorphic-associations><microservices><modularity>,1,124,3,0.0,0,"<p><a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow"">Microservices</a> and <a href=""https://en.wikipedia.org/wiki/Modular_programming"" rel=""nofollow"">Modular Programming</a> has proved to be a proper choice when design a software system. Benefits of it includes reusability, distributability, readability, etc.</p>&#xA;&#xA;<p>We are a MOOC site using OSGI as modularity implementation:</p>&#xA;&#xA;<ul>&#xA;<li>Each feature have its own database, service, and standalone web application</li>&#xA;<li>Direct access to database of other feature is prohibited</li>&#xA;</ul>&#xA;&#xA;<p>Take 3 features as a example:</p>&#xA;&#xA;<pre><code>     course               project         Q&amp;A(question&amp;answer)&#xA;&#xA;+---------------+    +---------------+    +---------------+&#xA;|     web       |    |     web       |    |     web       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     service   |    |     service   |    |     service   |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     dao       |    |     dao       |    |     dao       |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;|     Database  |    |     Database  |    |     Database  |&#xA;|               |    |               |    |               |&#xA;+---------------+    +---------------+    +---------------+&#xA;</code></pre>&#xA;&#xA;<p>Requirements:</p>&#xA;&#xA;<ol>&#xA;<li>Every course/project has Q&amp;A module, user that participated-in can ask question about this course/project here.</li>&#xA;<li>A standalone global(or common) Q&amp;A entry, listing questions that aggregated from all courses/projects, and user can ask context-independent(aka, not related to any course/project) question here.</li>&#xA;</ol>&#xA;&#xA;<p>I do not know if this design or architecture(<strong>completely isolation from top to bottom of every feature</strong>) is good or not, but I'm facing some inconveniences indeed:</p>&#xA;&#xA;<ol>&#xA;<li><p>modular web application</p>&#xA;&#xA;<p>Q&amp;A feature is either a standalone feature and part of course/project.  Currently I'm think both embed Q&amp;A module as web component of standalone course-webapp/project-webapp, and standalone qa-webapp itself, but I have no idea what's the best way to reuse controllers to avoid duplicated code on web layer</p></li>&#xA;<li><p>rational database <a href=""https://en.wikipedia.org/wiki/Polymorphic_association"" rel=""nofollow"">Polymorphic Association</a> problem</p>&#xA;&#xA;<p>A question maybe belong to course/project, or context-independent, and id of course/project came from another database, polymorphic association is inevitable. Currently I'm using a extra column post_to_type on table question to tackle with this.</p></li>&#xA;<li><p>Let me say course/project can be private or public. questions listed under global Q&amp;A entry only include questions that belong to public course/project, not private. But again, since each feature have its own database and direct access to database of other feature is prohibited, I do not have any idea what's the elegant and efficient way to deal with this.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is something wrong with our modular design when using OSGI, or its just me thinking so uncomfortable with this? and what's the best practices to design a microservices / modular architecture, specifically in object-oriented language like Java?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
49113488,Distributed Database Design style for micro service-oriented architecture,<spring-boot><microservices><distributed-database>,3,246,0,1.0,0,"<p>I am trying to convert one monolithic application into micro service oriented architecture style. Back end I am using spring , spring boot frameworks for development. Front-end I am using angular 2. And also using postgreSQL as database. &#xA;        Here my confusion is that , when I am designing my databases as distributed, according to functionalities it may contain  5 databases. Means I am designing according to vertical partition. Then I am thinking to implement inter-microservice communication services to achieve the entire functionality. </p>&#xA;&#xA;<p>The other way I am thinking that to horizontally partition the current structure. So my domain is based on some educational university. So half of university go under one DB and remaining will go under another DB. And deploy services according to Two region(two for two set of university). </p>&#xA;&#xA;<p>Currently I am decided to continue with the last mentioned approach. I am new to these types of tasks, since it referring some architecture task. Also I am beginner to this microservice and distributed database world. So Can anyone help me to confirm that my approach will give solution to my issue? Can I continue with my second approach - Horizontal partitioning of databases according to domain object? </p>&#xA;"
49226015,How to isolate services in choreography service composition,<architecture><microservices><distributed-computing><service-composition>,1,55,1,2.0,0,"<p>I always encourage to design each service without knowing other services exists (isolated). </p>&#xA;&#xA;<p>Few days ago, i was reading about the cons and pros of choreography over orchestration in micro service architecture, i came across this topic that, &#xA;Lets say we have a system which consist of 3 services: ordering, payment, shipment. if i use a orchestrator, the orchestrator knows when and how to call each service. in fact its duty is to know how and when call what service, but in choreography, i have no idea when payment service does not know the ordering service exists how its gonna subscribe to its event (for sure at least ordering system needs to have payment models)?</p>&#xA;&#xA;<p>i become more confuse when i start to think that, if we have a method in ordering service which returns the ordering information followed by payment data and shipping data. how its going to return payment and shipping data?</p>&#xA;"
46434569,How can I make my .NET Core microservice do a recursive health check?,<asp.net-core><microservices><health-monitoring>,1,586,0,0.0,0,"<p><a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/monitor-app-health"" rel=""nofollow noreferrer"">As described</a> I can do:</p>&#xA;&#xA;<pre><code>checks.AddUrlCheck(Configuration[""OrderingUrl""])&#xA;</code></pre>&#xA;&#xA;<p>to make my health check dependant on the health of other Microservices. However,I do not just want to do an url check. I want to do a full health check on the other Microservice (so it will also check the database dependencies etc of the other Microservice). This could be something like,</p>&#xA;&#xA;<p><code>checks.AddFullMicroserviceIncludingDatabaseAndUrlCheck(Configuration[""OrderingUrl""])</code> (hypothically).</p>&#xA;&#xA;<p>How can I do such a recursive health check in my .NET Core microservice?</p>&#xA;"
44965110,How to call other REST APIs from your node micro-service and send the result as a response?,<node.js><backend><microservices><es6-promise><request-promise>,2,1166,0,0.0,0,"<p>I am currently trying to implement a BFF (backend for front end architecture).</p>&#xA;&#xA;<p>Using <code>request-promise</code> library I can successfully hit the other microservice but not able to return the result as a response from BFF microservice.</p>&#xA;&#xA;<p>Each time it is returning this result <code>Promise { pending }</code> pending state, could somebody please help me out on this?</p>&#xA;&#xA;<p>My main issue is to know how to receive data into BFF microservice from the other microservice that we are hitting and returning the result from microservice which is hitting other one.</p>&#xA;&#xA;<p>Or if somebody could help me to let know how to access the result from inside <code>.then</code> of any promise?</p>&#xA;&#xA;<p>The flow is like this:</p>&#xA;&#xA;<pre><code>client(ios/android)===(sends request)==&gt;BFF Microservice==&gt;BP microservice&#xA;</code></pre>&#xA;&#xA;<p>(BFF Microservice handles the request and returns the response on the basis of result received from other microservice)</p>&#xA;&#xA;<p>Microservice code which is calling another microservice:</p>&#xA;&#xA;<pre><code>import yagmodel from '../../lib/models/yag-model'&#xA;import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;import config from 'config'&#xA;&#xA;//template below to call the REST APIs of other microservices.&#xA;&#xA;export async function getAllBP (req,res) {&#xA;    let yagresponse// this varaible is defined to get data from inside(rs.then )&#xA;&#xA;    const username= req.swagger.params.username.value&#xA;    const authheader= req.swagger.params.Authorization.value&#xA;    console.log(""Authorization:""+authheader)&#xA;&#xA;    let rs= await yagmodel.bp(username,authheader)&#xA;    console.log(rs)&#xA;&#xA;    rs.then((response)=&gt;{&#xA;        // console.log(response.body)&#xA;        yagresponse=response.body&#xA;        //console.log(rsp)&#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;&#xA;    res.status(200).send(yagresponse) &#xA;}&#xA;</code></pre>&#xA;&#xA;<p><code>yag-model.js</code> code:</p>&#xA;&#xA;<pre><code>import {errorsList} from '../../lib/errors/errorsList'&#xA;import request from 'request-promise'&#xA;&#xA;module.exports.bp = async function getBP(username,authheader){&#xA;    const options={&#xA;        uri: `http://localhost:4000/Health/BP/`+username,&#xA;        json: true,&#xA;        resolveWithFullResponse: true,&#xA;        headers: {&#xA;            'Content-Type': 'application/json; charset=utf-8',&#xA;            'Accept': 'application/json; charset=utf-8',&#xA;            'Authorization':authheader&#xA;        },&#xA;        method: 'GET'&#xA;    }&#xA;&#xA;    return request(options).then ((response)=&gt;{&#xA;        return response.body        &#xA;    }).catch((err)=&gt;{&#xA;        console.log(err)&#xA;        console.log('errorstatuscode:'+err.statusCode)&#xA;    })&#xA;}&#xA;</code></pre>&#xA;"
45085790,"Spring cloud DiscoveryClient. getLocalServiceInstance() deprecated, how to use Registration?",<java><spring><microservices><spring-cloud><auto-registration>,1,734,1,0.0,0,"<p>I have a requirement to get the current instance-id of the running microservice, the problem is that I have the requirement that if the process is not registered a ""random generated"" instance id has to be provided.</p>&#xA;&#xA;<p>I'm trying to get the service instance id from the DiscoveryClient but as the code points out the <code>getLocalServiceInstance</code> is deprecated and I can't use it.</p>&#xA;&#xA;<p>I tried to use the <code>Registration</code> as stated in the javadoc but coudn't find a way to get it initialized.</p>&#xA;&#xA;<p>Is there a conventional/specific way to get a service own registration?</p>&#xA;&#xA;<p>Btw, I cannot use a direct implementation because it is a starter that does not know what DiscoveryService implementation will be available at runtime.</p>&#xA;&#xA;<pre><code>/**&#xA; * @deprecated use the {@link org.springframework.cloud.client.serviceregistry.Registration} bean instead&#xA; *&#xA; * @return ServiceInstance with information used to register the local service&#xA; */&#xA;@Deprecated&#xA;ServiceInstance getLocalServiceInstance();&#xA;</code></pre>&#xA;"
45031529,Create service instances with parameters in Service Fabric,<c#><azure><microservices><azure-service-fabric><azure-iot-hub>,1,171,3,0.0,0,"<p>I'm using Service Fabric on Azure for a project at work where, put simply, I have a service whose function is to read data from IoT Hub.</p>&#xA;&#xA;<p>As it stands, that service is reading data from 32 partitions at the same time (multiple threads), but I'm trying to refactor it into one service intance per partition. The problem is I can't find a way to create 32 instances of a service and inform each instance of the Hub partition it should read (paramethers perhaps?).</p>&#xA;&#xA;<p>I can provide code samples if needed, but I feel the problem is pretty self-explanatory.</p>&#xA;"
45023334,How to efficiently handle spring boot microservices?,<java><spring><spring-boot><dns><microservices>,2,192,4,0.0,0,"<p>I have bunch of spring boot microservices running in unique ports. How do we handle these microservices in production ?</p>&#xA;&#xA;<p>In production, we only need the DNS, how do we handle the DNS mapping.</p>&#xA;&#xA;<p>For ex:&#xA;<em>example-microservice-1 (port: 8001)<br>&#xA;example-microservice-2 (port: 8002)<br>&#xA;example-microservice-3(port: 8003)<br>&#xA;example-microservice-4 (port: 8004)<br>&#xA;example-microservice-5 (port: 8005)</em>  </p>&#xA;&#xA;<p>I would want something like below,<br>&#xA;<em>myprod.com/example-microservice-1<br>&#xA;myprod.com/example-microservice-2</em>   ...</p>&#xA;&#xA;<p>Instead of,<br>&#xA;<em>myprod:8001/example-microservice-1<br>&#xA;myprod:8002/example-microservice-2</em>  </p>&#xA;&#xA;<p>(removed ""https/http"" above due to less reputation) </p>&#xA;&#xA;<p>All the microservices exists in a different codebase and when build will create individual runnable jars.</p>&#xA;"
44936115,Authorization in microservice architecture,<scope><authorization><microservices>,1,695,8,1.0,0,"<p>currently I develop a backend based on the microservice architecture.&#xA;Unfortunately, I have a problem how to realize the authorization.</p>&#xA;&#xA;<p>So let me explaine my system - there are the following services:</p>&#xA;&#xA;<ul>&#xA;<li>OAuth 2.0 Service (issuing JWT)</li>&#xA;<li>Group Service</li>&#xA;<li>Some Ressource Services (e.g. ToDos Service)</li>&#xA;</ul>&#xA;&#xA;<p>Every user is in one or many groups.&#xA;Each resource (like a ToDo list) also belongs to a group.&#xA;That means if some user creates a todo list, that list gets stored in the name of the group.</p>&#xA;&#xA;<p>Szenario:</p>&#xA;&#xA;<ul>&#xA;<li>User A is in group A</li>&#xA;<li>User B is in group A and B</li>&#xA;<li>User C is in group C</li>&#xA;<li>User A creats a ToDo list in group A.</li>&#xA;<li>User B modifies this ToDo list (he is allowed to do this since he is also in group A)</li>&#xA;<li>User C also tries to modify this ToDo list, but he shouldn't allowed to do this since he is only in group C.</li>&#xA;</ul>&#xA;&#xA;<p>Has any body a great idea how I could realize this in a microservice architecture and keep the dependencies between the services on a minimum?</p>&#xA;&#xA;<p>Certainly, I could ask on every request the Group Service if the user is in the group to which the resource belongs to. But so I get a really hard dependency between the Resource Services and the existence of a Group Service - I like to avoid this dependency.&#xA;Another option would be to store all groups, to which the user belongs to, in the access token. But with this option the client has to ask every time the OAuth Service for a new token when the user gets a member of a new group.</p>&#xA;&#xA;<p>So is there any other option how I could realize this szenario?</p>&#xA;"
33869866,Microservice architecture implementation of CRM HRM and Domain design problems,<architecture><domain-driven-design><crm><erp><microservices>,2,988,8,0.0,0,"<p>We are building a enterprise platform that consists of CRM, HRM, SALE, PROPERTY etc.&#xA;We are working on the microservice architecture.</p>&#xA;&#xA;<p><strong>The real question is:</strong>&#xA;CRM and HRM will be deployed as separate independent microservices but often these two microservices need to talk to each other. A HRM user creates a company contact employee and the HRM microservice API saves the information related to HRM inside HRM module in 'hrm' database while the employee details like name, surname, address etc will be saved to CRM database calling the CRM microservice APIs i.e. the Contact API saves the above info as contact of type 'Internal' or 'Employee'.&#xA;So basically what I am trying to do here is separating the data related to each microservices. </p>&#xA;&#xA;<p><strong>Is this way of domain design correct?</strong> or should I have to process and store all the information (entered by a HRM permissioned user) inside HRM module and 'hrm' database? such that we don't care CRM. And if so, CRM only seems to manage EXTERNAL contacts only? Will this have any future problems?</p>&#xA;"
38121112,.NET Core Authorize attribute with external JWT authentication microservice?,<asp.net-web-api><authorization><asp.net-core><jwt><microservices>,2,1615,0,1.0,0,"<p>So I'm just having a bit of trouble getting my head round the .NET Core [Authorize] attribute.</p>&#xA;&#xA;<p>I have an authentication service running (let's say <code>authapi.com</code>) which when provided with valid authentication details will return a JWT.  When this JWT is given back to it, it will validate the JWT and return a message indicating such.</p>&#xA;&#xA;<p>So, I'm now building another WebAPI (let's say <code>genericapi.com</code>)which will require authorization for some of the actions/controllers.  The idea being, the JWT will be passed in the headers of the request to <code>genericapi</code> which then needs to pass those on to <code>authapi.com</code> to validate them.</p>&#xA;&#xA;<p>I tried adding a Policy but it got convoluted really quick, and I had to write <code>[Authorize(Policy=""TokenValid"")]</code> on everything, when I'd rather just the default <code>[Authorize]</code> did this, since ALL authorization will have to hit <code>authapi</code>.</p>&#xA;&#xA;<p>How would I go about getting that JWT from the header and passing it to the <code>authapi</code> as standard behaviour for <code>[Authorize]</code>?</p>&#xA;&#xA;<p>Bear in mind: I don't want to do anything with the JWTs on <code>genericapi</code>, all authentication is to be handled by <code>authapi</code>.</p>&#xA;"
38178208,Can CakePhp 2.x or 3.x be used to develop web app based on micro service architecture,<rest><cakephp><cakephp-3.0><microservices><cakephp-2.8>,1,447,5,0.0,0,<p>I was evaluating PHP based frameworks for development of highly available and scalable applications based on micro service architecture. </p>&#xA;&#xA;<p>I have not seen any documentation for using CakePhp 2.x or 3.0 for design and development of micro services. Where as Laravel ( which is another PHP MVC framework based on Symphony) seems to have these capabilities based on its Lumen modules or components.</p>&#xA;&#xA;<p>It appears that CakePhp frameworks are only suited for design and development of big gigantic monolithic app. </p>&#xA;&#xA;<p>Can anyone point me to a documentation or example about how to use CakePhp 2.x or 3.x for designing web apps based on Micro service architecture ? </p>&#xA;
33180090,Spring security Post Requests,<spring><spring-security><microservices>,1,1204,0,0.0,0,"<p>Im following this guide <code>https://spring.io/guides/gs/securing-web/guide</code> to set up spring security for my microservice</p>&#xA;&#xA;<p>Im just sending basic POST and GET requests. I can do GET requests but when I try for POST requests I get a 403 error.(""Expected CSRF token not found. Has your session expired?"")&#xA;Im trying to set up basic authentication for my microservice</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45325062,Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams?,<jvm><microservices><datacontract><pact>,3,117,1,1.0,0,<p>Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams ?</p>&#xA;
45174699,jwt - Django-rest-framework-jwt authentication in microsevices,<jwt><microservices>,1,163,3,0.0,0,"<p>I am newbie in JSON web token and micro services. I read in an articles that if i share the private, all services can verify user on their own. Then i tried to implement an application to practice.&#xA;Basically, I have two services A and B. A is used for authentication. Then, I tried implement a API that required authentication in service B. But when I used a token generated by authentication A in API, 401 status code and ""Invalid signature."" were returned. &#xA;So anyone can explain to me what I did wrong?</p>&#xA;"
39405067,org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization,<java><spring-boot><microservices>,1,14900,0,2.0,0,"<p>I'm developing <strong>spring boot microservices</strong> example from the link: <a href=""https://dzone.com/articles/spring-boot-creating"" rel=""nofollow"">https://dzone.com/articles/spring-boot-creating</a>. In this project I simply updated the parent dependency to its latest version and other code files are unchanged. I faced the following error when I click <strong><a href=""http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4"" rel=""nofollow"">http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4</a></strong></p>&#xA;&#xA;<pre><code>2016-09-09 11:46:20.888 ERROR 14152 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : StandardWrapper.Throwable&#xA;&#xA;org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization.&#xA;[[FATAL] A resource model has ambiguous (sub-)resource method for HTTP method GET and input mime-types as defined by""@Consumes"" and ""@Produces"" annotations at Java methods public java.util.List br.com.alexandreesl.handson.rest.ProductRest.getProducts() and public java.util.List br.com.alexandreesl.handson.rest.CustomerRest.getCustomers() at matching regular expression /. These two methods produces and consumes exactly the same mime-types and therefore their invocation as a resource methods will always fail.; source='org.glassfish.jersey.server.model.RuntimeResource@14c14bf']&#xA;    at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:555) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.access$500(ApplicationHandler.java:184) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:350) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:315) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:297) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.processWithException(Errors.java:255) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.&lt;init&gt;(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.WebComponent.&lt;init&gt;(WebComponent.java:392) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:177) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:369) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at javax.servlet.GenericServlet.init(GenericServlet.java:158) ~[tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1194) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.allocate(StandardWrapper.java:806) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:133) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:522) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:1110) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:785) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1425) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_102]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_102]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_102]&#xA;</code></pre>&#xA;&#xA;<p>the updated <strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;junit&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;junit&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Application.java</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;public class Application {&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(Application.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ApplicationConfig.java</strong></p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class ApplicationConfig {&#xA;    @Named&#xA;    static class JerseyConfig extends ResourceConfig {&#xA;        public JerseyConfig() {&#xA;            this.packages(""br.com.alexandreesl.handson.rest"");&#xA;        }&#xA;    }&#xA;&#xA;    @Bean&#xA;    public RestTemplate restTemplate() {&#xA;        RestTemplate restTemplate = new RestTemplate();&#xA;        return restTemplate;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Order.java</strong></p>&#xA;&#xA;<pre><code>public class Order {&#xA;    private long id;&#xA;    private long amount;&#xA;    private Date dateOrder;&#xA;    private Customer customer;&#xA;    private Product product;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>OrderRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class OrderRest {&#xA;    private long id = 1;&#xA;&#xA;    @Inject&#xA;    private RestTemplate restTemplate;&#xA;&#xA;    @GET&#xA;    @Path(""order"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Order submitOrder(@QueryParam(""idCustomer"") long idCustomer,&#xA;            @QueryParam(""idProduct"") long idProduct,&#xA;            @QueryParam(""amount"") long amount) {&#xA;&#xA;        Customer customer = restTemplate.getForObject(""http://localhost:8080/customer?id={id}"", Customer.class, idCustomer);&#xA;        Product product = restTemplate.getForObject(""http://localhost:8080/product?id={id}"", Product.class,idProduct);&#xA;&#xA;        Order order = new Order();&#xA;        order.setCustomer(customer);&#xA;        order.setProduct(product);&#xA;        order.setId(id);&#xA;        order.setAmount(amount);&#xA;        order.setDateOrder(new Date());&#xA;        id++;&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Customer.java</strong></p>&#xA;&#xA;<pre><code>public class Customer {&#xA;    private long id;&#xA;    private String name;&#xA;    private String email;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>CustomerRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class CustomerRest {&#xA;    private static List&lt;Customer&gt; customers = new ArrayList&lt;Customer&gt;();&#xA;&#xA;    static {&#xA;        Customer customer1 = new Customer();&#xA;        customer1.setId(1);&#xA;        customer1.setNome(""Customer 1"");&#xA;        customer1.setEmail(""customer1@gmail.com"");&#xA;&#xA;        Customer customer2 = new Customer();&#xA;        customer2.setId(2);&#xA;        customer2.setNome(""Customer 2"");&#xA;        customer2.setEmail(""Customer2@gmail.com"");&#xA;&#xA;        Customer customer3 = new Customer();&#xA;        customer3.setId(3);&#xA;        customer3.setNome(""Customer 3"");&#xA;        customer3.setEmail(""Customer3@gmail.com"");&#xA;&#xA;        Customer customer4 = new Customer();&#xA;        customer4.setId(4);&#xA;        customer4.setNome(""Customer 4"");&#xA;        customer4.setEmail(""Customer4@gmail.com"");&#xA;&#xA;        Customer customer5 = new Customer();&#xA;        customer5.setId(5);&#xA;        customer5.setNome(""Customer 5"");&#xA;        customer5.setEmail(""Customer5@gmail.com"");&#xA;&#xA;        customers.add(customer1);&#xA;        customers.add(customer2);&#xA;        customers.add(customer3);&#xA;        customers.add(customer4);&#xA;        customers.add(customer5);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Customer&gt; getCustomers() {&#xA;        return customers;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""customer"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Customer getCustomer(@QueryParam(""id"") long id) {&#xA;        Customer cli = null;&#xA;        for (Customer c : customers) {&#xA;            if (c.getId() == id)&#xA;                cli = c;&#xA;        }&#xA;        return cli;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Product.java</strong></p>&#xA;&#xA;<pre><code>public class Product {&#xA;    private long id;&#xA;    private String sku;&#xA;    private String description;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ProductRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class ProductRest {&#xA;    private static List&lt;Product&gt; products = new ArrayList&lt;Product&gt;();&#xA;&#xA;    static {&#xA;        Product product1 = new Product();&#xA;        product1.setId(1);&#xA;        product1.setSku(""abcd1"");&#xA;        product1.setDescription(""Product1"");&#xA;        Product product2 = new Product();&#xA;        product2.setId(2);&#xA;        product2.setSku(""abcd2"");&#xA;        product2.setDescription(""Product2"");&#xA;        Product product3 = new Product();&#xA;        product3.setId(3);&#xA;        product3.setSku(""abcd3"");&#xA;        product3.setDescription(""Product3"");&#xA;        Product product4 = new Product();&#xA;        product4.setId(4);&#xA;        product4.setSku(""abcd4"");&#xA;        product4.setDescription(""Product4"");&#xA;        products.add(product1);&#xA;        products.add(product2);&#xA;        products.add(product3);&#xA;        products.add(product4);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Product&gt; getProducts() {&#xA;        return products;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""product"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Product getProduct(@QueryParam(""id"") long id) {&#xA;        Product prod = null;&#xA;        for (Product p : products) {&#xA;            if (p.getId() == id)&#xA;                prod = p;&#xA;        }&#xA;        return prod;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please guide on this issue.</p>&#xA;"
39425569,Spring Boot Java8 Microservice Simple Message Subscription service,<spring-boot><java-8><jms><microservices>,2,659,0,0.0,0,<p>I am new to Microservice and JMS likes to know how can I</p>&#xA;&#xA;<ul>&#xA;<li>create a subscription      </li>&#xA;<li>read the subscription </li>&#xA;</ul>&#xA;&#xA;<p>Using Spring Boot and JMS </p>&#xA;
39416301,Microservices - API Gateway Layer,<spring-boot><cloudfoundry><microservices><pivotal-cloud-foundry>,1,1395,1,0.0,0,"<p>I have read few details of use of api gateway in microservices architecture. I have read that it basically helps with security , transformation , throttling etc. Is orchestration also one of it responsibilities? When I read about microservices , I saw that it should have dumb pipes and smart endpoints and services must be choreographed and not orchestrated. So my assumption is that orchestration is not a responsibility  of api gateway.</p>&#xA;"
42691892,Microservices Per DB table,<domain-driven-design><microservices>,3,200,2,0.0,0,"<p>I ran into the microservices architecture for e-commerce application where each table has it's own micro service basically with CRUD operations (something like rest client for each table). &#xA;Now I am thinking about combine and model them around business domains, before that I wanted to know does anyone encountered such situation and is it right architecture or not.&#xA;Any suggestions will be very helpful.&#xA;Thanks.</p>&#xA;"
42711116,Service Fabric - DeleteServiceAsync timing out,<azure><microservices><azure-service-fabric><service-fabric-stateful>,1,62,3,0.0,0,"<p>I am spawning several ASF microservices to run some process. Once the process is done, I am deleting those services using <code>DeleteServiceAsync</code> by using following code. Almost 98% of the time, everything works fine. However, 2% of the time, I run into timeout issue and the microservices stucks in deleting state with Idle Secondary replica. Thanks in advance for any suggestions to resolve this issue.</p>&#xA;&#xA;<pre><code>using (FabricClient fc = new FabricClient())&#xA;{&#xA;    fc.ServiceManager.DeleteServiceAsync(deleteServiceDescription, TimeSpan.FromMinutes(5), cancellationToken);&#xA;}&#xA;</code></pre>&#xA;"
42778151,Integrating with Auth0,<publish-subscribe><microservices><cqrs><eventual-consistency>,1,38,4,0.0,0,"<p>I'm in the process of implementing a user management Microservice (MS) and wanted to find out whether what I'm doing is ok. Users are created from the UI, which interacts with an API. The API makes an RPC call to the user management MS, and publishes a CreateUserCommand to an InMem-bus. The consumer then handles the command by then creating a user in the DB, but then I need this user also registered within Auth0 - would the way to go about this be to send a different command to a persistent queue, for a subscriber to pick it up and register that user with Auth0 (persistent queue in case can't reach Auth0). Once that completes successfully, I could then publish a UserCreatedEvent? </p>&#xA;&#xA;<p>Any help with this would be much appreciated.</p>&#xA;"
39866282,How to access User-Provided environment variables in cloud foundry?,<deployment><environment-variables><cloud><cloudfoundry><microservices>,1,807,0,0.0,0,"<p>I'm aware of setting environment variables in <code>manifest.yml</code> by doing following</p>&#xA;&#xA;<pre><code>--- &#xA;- applications:&#xA;  - name:&#xA;    .&#xA;    .&#xA;    env:&#xA;      MY_ENV_VAR: 'my-var-value'&#xA;</code></pre>&#xA;&#xA;<p>How do I access <code>MY_ENV_VAR</code> in my program (python for example) ?</p>&#xA;&#xA;<p>Additionally, I only want to access this variable in cloud foundry environment. While doing local development, I would like to use some hard-coded value, how do I separate these two scenarios (python example again) ?</p>&#xA;"
40044128,Fetch Configuration from Spring Cloud Config over SSL,<java><ssl><spring-boot><microservices><spring-cloud-config>,2,1658,0,0.0,0,"<p>I am building microservices using Spring Boot where configuration is distributed using Spring Cloud Config. Config application has SSL enabled.</p>&#xA;&#xA;<p>I want my spring boot application to communicate to Config server over https. Problem is that before loading SSL configuration from bootstrap.yml, application initiates a rest call to Config Server to fetch the configuration and fails miserably with error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""https://host:8888/abcd/development,production"": sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; nested exception is javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: &#xA;</code></pre>&#xA;&#xA;<p>I have configured a truststore with CA certificate in bootstrap.yml:</p>&#xA;&#xA;<pre><code># MicroServices Properties&#xA;spring:&#xA;  application:&#xA;     name: abcd&#xA;  profiles:&#xA;    active: development,production&#xA;  cloud:&#xA;    config:&#xA;      uri: https://&lt;host&gt;:8888 &#xA;      fail-fast: true&#xA;      password: abc@123&#xA;      username: user&#xA;server:&#xA;  ssl:&#xA;    trust-store: D:/Certs/caCert/server.p12&#xA;    trust-store-password: keystore&#xA;    key-store-provider: PKCS12&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions what should I do to create successful SSL communication with Config Server?</p>&#xA;"
40082248,Handle message dependency when using evening environment(MessageMQ),<spring-boot><rabbitmq><message><microservices>,1,28,3,0.0,0,"<p>I am developing a micro service platform using Spring technologies. I am facing some problem when consuming message from Rabbit MQ.</p>&#xA;&#xA;<p>Scenario:</p>&#xA;&#xA;<p>I have two message queue, <strong>student</strong> and <strong>enrollment</strong>. In my one microservice I put the student and enrollment creation request to message queue. </p>&#xA;&#xA;<p>But, since the message queue order not guaranteed, enrollment message comes <strong>before</strong> the students come. &#xA;On that time my relation database fail. </p>&#xA;&#xA;<p>What is the best way to handle this kind of scenario(message ordring) when using message mq in microservice platform? </p>&#xA;"
39932500,Microservices with Spring-Boot and Release Management,<spring-boot><microservices><spring-boot-maven-plugin>,1,485,5,1.0,0,"<p>Looking for advice in how to do release management of microservices built with Spring Boot. </p>&#xA;&#xA;<p>Most projects I've worked use the release plugin (maven) to create tags as well as to release maven projects (jar, war, rpm). Usually, this relies on the maven parent/child relationship for all sub-projects (jars, wars) during the release process (monolith source code, all living in a single git repository). I'm wondering how do people maintain different boot projects (microservices) and make releases.  </p>&#xA;&#xA;<p>The way I see it, the following are possible strategies:</p>&#xA;&#xA;<ol>&#xA;<li>One Spring Boot project (microservice maven project) per git repository so that releases are managed independently. </li>&#xA;<li>A Multi-Module maven project with each module being a microservice. All submodules (microservices) will have to be released together. The parent pom will have to use a Boot's parent pom. </li>&#xA;<li>Rely on the maven-release-plugin ability to release only certain sub-modules based on a release. This will make each maven sub-module have different versions (potentially).</li>&#xA;</ol>&#xA;&#xA;<p>What has your team found useful? I like Boot's programming model, but I'm hopeful I can use a release strategy that is consistent with Boot model of keeping things simple.</p>&#xA;"
40132631,SocketTimeoutException : null while opening New Spring Starter Project,<spring><web-services><spring-boot><microservices><eclipse-jee>,1,1497,0,0.0,0,"<p>SocketTimeoutException : null while opening New Spring Starter Project</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/uWW5K.png"" alt=""enter image description here""></p>&#xA;&#xA;<pre><code>JAVA_HOME=C:\Program Files (x86)\Java\jdk1.7.0_40&#xA;Path=%JAVA_HOME%\bin;C:\..&#xA;</code></pre>&#xA;"
40208887,"When utilizing a microservices architecture, will the underlying read/write database become a bottleneck?",<sql><amazon-web-services><scalability><microservices>,3,348,1,0.0,0,"<p>As I described in the question, if I were to implement a microservices architecture, would the centralized read/write database become a bottleneck?</p>&#xA;&#xA;<p>To expand with an example, let's say I have three microservices: <code>users</code>, <code>teams</code>, and <code>team_members</code>. Each has its own microservice, but they all rely on each other in the database, so exclusive, parallel databases wouldn't be appropriate. Since microservices is meant to distribute the work to several different servers, doesn't the central database ultimately defeat the purpose of these microservices, as they all end up calling to the same server?</p>&#xA;"
40108015,Microservice's High availability concern on cloud,<cloud><microservices>,1,230,3,0.0,0,"<p>I was reading about Microservices and everything makes sense to me but I have one little doubt.</p>&#xA;&#xA;<p>On cloud, every component has a availability SLA (lets assume 99.9%). So, if we have a single component to do a job, our application SLA would be the same (approx.). But if we create multiple components to do one job, our application's SLA would be reduced because all the components can go down at different time. In microservices, one service can communicate to other services to complete a task. Now, any of the participant service can be down at different time, So our application availability will be lesser compared to monolithic service?</p>&#xA;"
41880524,Microservices based architecture and individual cache for each node,<java><hibernate><caching><architecture><microservices>,1,764,0,0.0,0,"<p>Is it considered bad practice to use separated, local cache for each node in distributed microservice application? I've heard that in monolithic application it's OK to use local EHCache as 2nd level cache provider for Hibernate, but in distributed environment it's common practice to use distributed caches, such as Memcached, Redis or Hazelcast. What are the consequences of using separated cache for each node?</p>&#xA;"
42332938,What is the difference between Service Fabric Applications and Services,<azure><microservices><azure-service-fabric>,3,387,2,0.0,0,<p>What is the reasoning behind Applications concept in Service Fabric? What is the recommended relation between Applications and Services? In which scenarios do Applications prove useful?</p>&#xA;
37445823,Force an Asynchronous call to behave Synchronously,<javascript><asynchronous><reactjs><microservices>,2,250,3,0.0,0,"<p>In my React app, I'm trying to calculate a value based on three other values. I've contained all of the calculation logic to the back end, which is a microservice I make asynchronous calls to. The function in which I am asynchronously trying to get that calculated value is in the middle of many synchronous hooks. </p>&#xA;&#xA;<p>In the UI layer, I call the function which I want to return the end result (returned asynchronously). That called function calls another function, which calls another function, which returns a new Promise. See code below:</p>&#xA;&#xA;<pre><code>// DateUI.js (layer 1)&#xA;selectDate(dateField, flight, idx, saved, momentTime, e) {&#xA;    if (moment(momentTime).isValid()) {&#xA;        if (dateField == ""StartDate"") {&#xA;            // The initial problematic function call, need to set endDate before I continue on&#xA;            let endDate = PlanLineActions.calculateFlightEndDate(periodTypeId, numberOfPeriods, momentTimeUnix);&#xA;&#xA;            flight.set(""EndDate"", endDate);&#xA;        }&#xA;&#xA;        this.theNextSyncFunction(..., ..., ...);&#xA;    }&#xA;}&#xA;&#xA;&#xA;// DateActions.js (layer 2)&#xA;calculateFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let plan = new Plan();&#xA;&#xA;    plan.getFlightEndDate(periodTypeId, numberOfPeriods, startDate).then(function(response) {&#xA;        // response is JSON: {EndDate: ""12/05/2016""}&#xA;        response.EndDate;&#xA;    }, function(error) {&#xA;        log.debug(""There was an error calculating the End Date."");&#xA;    });&#xA;}&#xA;&#xA;&#xA;// DateClass.js (layer 3)&#xA;getFlightEndDate(periodTypeId, numberOfPeriods, startDate) {&#xA;    let path = '/path/to/microservice';&#xA;    return this.callServer(path, 'GET', {periodTypeId: periodTypeId, numberOfPeriods: numberOfPeriods, startDate: startDate});&#xA;}&#xA;&#xA;&#xA;// ServerLayer.js (layer 4)&#xA;callServer(path, method = ""GET"", query = {}, data, inject) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        super.callServer(uri.toString(),method,data,inject).then((data) =&gt; {&#xA;            resolve(data);&#xA;        }).catch((data) =&gt; {&#xA;            if (data.status === 401) {&#xA;                AppActions.doRefresh();&#xA;            }&#xA;            reject(data);&#xA;        });&#xA;    });&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I am under the impression that, because ServerLayer.js (layer 4) returns a <code>new Promise</code> (and thus DateClass.js (layer 3)), calling <code>plan.getFlightEndDate(...).then(function(response) {...</code> will not complete until the response comes back resolved or rejected. This is not currently happening, as the code in DateUI.js (layer 1) will continue on to call <code>this.theNextSyncFunction</code>, and then resolve ~50ms later with the proper data.</p>&#xA;&#xA;<p>How do I force PlanLineActions.calculateFlightEndDate(...) in DateUI.js (layer 1) to complete with a response before I continue on with selectDate()?</p>&#xA;"
37403682,A real world project using microservices architecture,<node.js><architecture><microservices>,1,483,5,0.0,0,"<p>Anyone knows an open source project that is on microservices architecture? I need a more real app that has addressed cross-cutting concerns,etc not just an educational sample.</p>&#xA;&#xA;<p>Please introduce if you know any. Especially if it's on Node.js or C#.net stack.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
41123857,How to publish an event in the microservice world?,<amazon-web-services><events><microservices><grpc>,1,149,3,0.0,0,"<p>There are many books and blogs detailing how event-based communication between microservices is easier to maintain than services calling eachother directly. </p>&#xA;&#xA;<p>However how would this be implemented in the AWS world? I was considering Topics, but it is far from ideal.</p>&#xA;&#xA;<p>How is this patter usually implemented to give guarantees on latency, durability, guaranteed delivery, idempotency etc.</p>&#xA;"
50128046,How should I design my Spring Microservice?,<spring><spring-boot><microservices>,3,78,0,0.0,0,"<p>I am trying to create a <code>Microservice architecture</code> for a hobby project and I am confused about some decisions. Can you please help me as I never worked using Microservice before?</p>&#xA;&#xA;<ol>&#xA;<li>One of my requirements is that my <code>AngularJS</code> GUI will need to show some drop-down or List of values (example: a list of countries). This can be fetched using a <code>Microservice</code> REST call, but where should the values come from? Can I fetch these from my <code>Config Server</code>? or should it come from <code>Database</code>? If the latter, then should each of the Microservice have their own Database for lookup value or can it be a common one?</li>&#xA;<li>How would server-side validation work in this case? I mean, there will certainly be a Microservice call the GUI will make for validation but should the validation service be a common Microservice for all Use Cases/Screens or should it be one per GUI page or should the <code>CRUD</code> Microservice be reused for validation as well?</li>&#xA;<li>How do I deal with a use-case where the back-end is not a Database but a Web-service call? Will I need some local <code>DB</code> still to maintain some state in between these calls (especially to take care of scenario where the Web-service call fails) and finally pass on the status to GUI?</li>&#xA;</ol>&#xA;"
50289914,Deal with enumeration in Microservices architecture,<architecture><microservices><enumeration>,2,41,3,1.0,0,"<p>I recently faced a problem when I designed the microservices architecture of our new system. &#xA;To give more context on that, let's suppose that we have two different services. </p>&#xA;&#xA;<ul>&#xA;<li><p>A service is responsible to make payments and the other one </p></li>&#xA;<li><p>B service is responsible to keep track of the orders. </p></li>&#xA;</ul>&#xA;&#xA;<p>We have a use case that we need to update an order state from the service A. </p>&#xA;&#xA;<p>We have these states in an enumeration list inside the service B. </p>&#xA;&#xA;<p>How can I avoid the sharing of this enumeration between two services? &#xA;I need to have decoupled services.</p>&#xA;&#xA;<p>Please feel free to ask for clarifications. </p>&#xA;"
51781316,Unable to login through gateway jhipster 4.9.0 microservice architechture,<java><microservices><jhipster><jhipster-registry>,1,33,4,0.0,0,"<p>I've generated microservice application through jHipster 4.9.0.&#xA;My UAA server is running on port 9999 and gateway on 8080 these microservices are connected through jHipster registry. When I try to log in through the gateway <strong>it's giving me 404 for /auth/login</strong> although gateway has this endpoint in AuthResource.java file.&#xA;I have just generated these microservices and trying to log in but unfortunately, I'm unable to log in. Please guide me if there is something wrong I do not want to use the latest version of jHipster. JHipster registry version is 3.3. war download from github. It would be great if you can help me in any way. Thanks in advance. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/LzYgn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LzYgn.png"" alt=""enter image description here""></a></p>&#xA;"
43567411,PACT: java-maven,<maven><microservices><pact><pact-java>,1,785,0,1.0,0,"<p>I need few answer for my doubt:</p>&#xA;&#xA;<ol>&#xA;<li>Pact-mock-service Vs pact-jvm-server, is both are same? Pls describe this.</li>&#xA;<li>Am implementing the PACT in java-maven</li>&#xA;</ol>&#xA;&#xA;<p>I can able to run this:</p>&#xA;&#xA;<p><a href=""https://github.com/anha1/microservices-pact-maven"" rel=""nofollow noreferrer"">https://github.com/anha1/microservices-pact-maven</a></p>&#xA;&#xA;<p><a href=""https://github.com/warmuuh/pactbroker-maven-plugin"" rel=""nofollow noreferrer"">https://github.com/warmuuh/pactbroker-maven-plugin</a></p>&#xA;&#xA;<p>Help me to understand this with pact-mock-service and pact-jvm-server</p>&#xA;"
43753039,Openshift Container Platform V3.X vs. Fabric8,<containers><openshift><kubernetes><microservices><fabric8>,1,660,0,0.0,0,"<p>I took a look at Fabric8 Microservices Platform and searched for some alternatives for comprehension. I found Red Hats Openshift Container Platform, which seems to be the same as Fabric8, but not Open-Source. &#xA;I tried to figure out what are the major benefits of Red Hats solution.&#xA;I am already on the Openstack. </p>&#xA;"
43607751,How to create SPARK/Flink Stream Data Processing as a Microservice (REST API),<apache-spark><playframework-2.0><microservices><apache-flink><lagom>,1,224,0,2.0,0,"<p>I am creating streaming analytics application using Spark, Flink &amp; Kafka. Each analytics/functionality will implement as a Microservice so that this analytics can able to use in the different project later.</p>&#xA;&#xA;<p>I run my Spark/Flink job perfectly in Simple Scala application and submit this job over Spark &amp; Flink cluster respectively. But I have to start/run this job when REST POST startJob() request invoke to my web service.</p>&#xA;&#xA;<p>How can I integrate my Spark &amp; Flink data processing functionality in a web service oriented application? </p>&#xA;&#xA;<p>Till now I tried <a href=""http://www.lagomframework.com/"" rel=""nofollow noreferrer"">Lagom Microservice</a> but i found so many issues you can check </p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/43255302/best-approach-to-ingest-streaming-data-in-lagom-microservice"">Best approach to ingest Streaming Data in Lagom Microservice&#xA;</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/43570899/java-io-notserializableexception-using-apache-flink-with-lagom"">java.io.NotSerializableException using Apache Flink with&#xA;Lagom</a></li>&#xA;</ol>&#xA;&#xA;<p>I think i am not taking the right direction for Stream Processing Microservice Application. Looking for right direction to implement this analytics over REST Service.</p>&#xA;"
43689879,How does one pass user context between an API and a microservice?,<rest><microservices><azure-service-fabric>,2,412,3,1.0,0,"<p>I am trying to setup audit logging and we were wanting the log event to happen as close to the action as possible, while also knowing which user performed the action. This means we need to pipe in the user info.  What are best practices for this?</p>&#xA;"
43674924,What is the best way to manage microservice issue or bug on git,<git><microservices><issue-tracking>,2,208,4,0.0,0,"<p>Micro-Service is about having many projects on git within different repositories.</p>&#xA;&#xA;<p>So, what is the best way to manage an issue, when there is a bug which needed to fix the code on multiple services?</p>&#xA;"
43682155,Sharing entity ID between microservices,<rest><microservices><hateoas>,1,342,5,2.0,0,"<p>Let's say I have a <code>Users</code> microservice. Its data is consumed via REST API following HATEOAS ""pattern"", so a common request/response would be something like this:</p>&#xA;&#xA;<pre><code>GET /users&#xA;&#xA;{&#xA;  results: 5,&#xA;  data :[&#xA;    {&#xA;      name: ""John Doe"",&#xA;      email: ""whatever"",&#xA;      ...,&#xA;      links : [&#xA;        {&#xA;          rel: ""self"",&#xA;          href: ""/users/1""&#xA;        }&#xA;      ]&#xA;    },&#xA;    ...&#xA;  ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As HATEOAS says, the users' ID is not returned, but a link to ""self"". </p>&#xA;&#xA;<p>So far, so good. Now, I want another microservice to manage users' pictures. In that new microservice there is a relationship between one user an her pics, so I will need a user identifier.</p>&#xA;&#xA;<p>Should I use ""/users/1"" (""self"" link) as user ID in the pics microservice? </p>&#xA;&#xA;<p>If not, how can I approach this?</p>&#xA;"
47335582,Feign Exception 403 after updating to Spring Boot 1.5.8 and Finchley/Edgware Spring Cloud,<java><spring><oauth-2.0><microservices><netflix-feign>,1,563,0,0.0,0,"<p>I'm relatively new to microservices and I've been trying to use this proof-of-concept application that uses Spring Boot and Spring Cloud: &#xA;<a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a></p>&#xA;&#xA;<p>The problem is that, while the app runs fine on Spring Boot 1.3.5 and Spring Cloud Brixton.RELEASE, it breaks when upgrading either one of them.</p>&#xA;&#xA;<p>The error ocurrs when registering a new account, and it gives the following error:</p>&#xA;&#xA;<p><code>status 403 reading AuthServiceClient#createUser(User); content:↵{""timestamp"":1510753211255,""status"":403,""error"":""Forbidden"",""message"":""Access Denied"",""path"":""/uaa/users""}</code></p>&#xA;&#xA;<p>And the stack trace:</p>&#xA;&#xA;<p><code>2017-11-15 15:40:11.284 ERROR 9072 --- [nio-6000-exec-1] o.a.c.c.C.[.[.[.[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [/accounts] threw exception [Request processing failed; nested exception is feign.FeignException: status 403 reading AuthServiceClient#createUser(User); content: {""timestamp"":1510753211255,""status"":403,""error"":""Forbidden"",""message"":""Access Denied"",""path"":""/uaa/users""}] with root cause</code></p>&#xA;&#xA;<p>As this seems to be a Feign error, and <code>AuthServiceClient.java</code> seems to be the culprit, I've included it here:</p>&#xA;&#xA;<pre><code>@FeignClient(name = ""auth-service"")&#xA;public interface AuthServiceClient {&#xA;&#xA;@RequestMapping(method = RequestMethod.POST, value = ""/uaa/users"", consumes = MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;void createUser(User user);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>As there have been no changes to the code whatsoever, I don't understand what the cause could be and what to do to fix this error.</p>&#xA;"
47379427,How to consume response of one rest api in another rest API java Microservices?,<java><rest><spring-mvc><microservices>,2,1458,0,0.0,0,"<p>I have 2 micro services running :-</p>&#xA;&#xA;<pre><code>1] user &#xA;   running on tomcat port :8081,&#xA;   database name:  user.&#xA;2] order&#xA;   running on tomcat port :8082,&#xA;   database name:  order.&#xA;</code></pre>&#xA;&#xA;<p>I have a REST API in order micro service as shown below:-</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/order/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;    public List registerCustomer() {&#xA;    List list=new ArrayList();&#xA;    list.add(""aaa"");&#xA;    list.add(""aab"");&#xA;    return list;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>now How can I consume this micro in user</p>&#xA;&#xA;<pre><code>  @RequestMapping(value = ""/user/getdetail"", method = RequestMethod.GET,headers=""Accept=application/json"")&#xA;&#xA;   // need to call REST API /order/getdetail and return list&#xA;    }   &#xA;</code></pre>&#xA;&#xA;<p>As I am new to micro services I am not aware of to communicate between micros?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47348422,Throw Exception through multiple services,<spring><rest><spring-boot><microservices>,1,65,4,0.0,0,<p>I have a little microservice architecture with 3 depending services. Each service represents a seperate Spring Boot project. If an exception occurs on the lowest level of the architecture I would like to throw it through all other services up to the highest/user endpoint service.</p>&#xA;&#xA;<p>Each service API returns a <strong>HttpEntity(Response Entity)</strong> including a specific object. I found a lot of possible solutions like <strong>ResponseEntityExceptionHandlers</strong> but all examples shown for a single service architecture without multiple depending services.</p>&#xA;&#xA;<p>Are there any best practices how to throw an Exception through multiple services with Spring Boot?</p>&#xA;
43018514,"AWS Lambda + Spring, how to load application.yml",<java><spring><amazon-web-services><aws-lambda><microservices>,1,695,0,1.0,0,"<p>I have problem with customizing API gateway domain, for my restful app deployed on AWS lambda. Customized domain, works this way, that depending on basePath it chooses different APIs which finally touches Lambda. For example:</p>&#xA;&#xA;<p><code>api.mycustomdomain.com/view/ping</code> -> goes to application <code>view</code> with path <code>/view/ping</code>&#xA;<code>api.mycustomdomain.com/admin/ping</code> -> goes to application <code>admin</code> with path <code>/admin/ping</code></p>&#xA;&#xA;<p>I am using this example as boilerplate: <a href=""https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store</a></p>&#xA;&#xA;<p>What I would like to achieve is handler which depending on <code>Host</code> header strips prefix from request path.</p>&#xA;&#xA;<p>I have prepared following application.yml file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: ""/view""&#xA;  productionHost: ""api.mycustomdomain.com""&#xA;</code></pre>&#xA;&#xA;<p>The problem/question is. How can I now load those into my Lambda function? Here is my naive try:</p>&#xA;&#xA;<pre><code>public class LambdaHandler implements RequestHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; {&#xA;    SpringLambdaContainerHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; handler;&#xA;    boolean isinitialized = false;&#xA;&#xA;    @Value(""${server.contextPath}"")&#xA;    private String prefix;&#xA;&#xA;    @Value(""${server.productionHost}"")&#xA;    private String productionHost;&#xA;&#xA;    public AwsProxyResponse handleRequest(AwsProxyRequest awsProxyRequest, Context context) {&#xA;        if(awsProxyRequest.getHeaders().get(""Host"").equals(productionHost))&#xA;            awsProxyRequest.setPath(awsProxyRequest.getPath().substring(prefix.length()));&#xA;&#xA;        if (!isinitialized) {&#xA;            isinitialized = true;&#xA;            try {&#xA;                handler = SpringLambdaContainerHandler.getAwsProxyHandler(PingPongApp.class);&#xA;            } catch (ContainerInitializationException e) {&#xA;                e.printStackTrace();&#xA;                return null;&#xA;            }&#xA;        }&#xA;        return handler.proxy(awsProxyRequest, context);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Obviously this doesn't work, LambdaHandler is working out of Spring context.</p>&#xA;&#xA;<p>Any ideas how can I deal with that?</p>&#xA;"
42928059,Request per second and performance limit of Spring rest backend,<spring><performance><rest><microservices>,2,3308,0,0.0,0,"<p>I would like to develop a Spring REST backend application with tomcat.&#xA;I expect 1000-5000 active users. The users will create requests from clients(Android, web, Ios) to backend. Most of requests will create a simple db select.</p>&#xA;&#xA;<ul>&#xA;<li>How to calculate the limit of requests per second?</li>&#xA;<li>How to estimate the performance limits?</li>&#xA;<li>Should I use Microservice architecure or monolithic?</li>&#xA;</ul>&#xA;&#xA;<p>Thanks</p>&#xA;"
43032883,How could authentication work across microservices?,<javascript><node.js><authentication><jwt><microservices>,3,111,3,0.0,0,"<p>I have two separate Node.js services.</p>&#xA;&#xA;<p>Service <code>A</code> is responsible for authenticating users.  If a user successfully logs in, the user is redirected to Service <code>B</code> (hosted on a <strong>subdomain</strong> of the domain Service <code>A</code> is hosted on).</p>&#xA;&#xA;<p>I am using <a href=""https://jwt.io/"" rel=""nofollow noreferrer"">JWT</a> for authentication.</p>&#xA;&#xA;<p><strong>Question:</strong> How can Service <code>B</code> be aware if a user is or is not authenticated?</p>&#xA;&#xA;<p>I imagine one way that Service <code>B</code> could be aware if they are or aren't authenticated is by asking Service <code>A</code> to check the JWT on each  Request to Service <code>B</code>. But how is Service <code>A</code> supposed to send the JWT to the client when the client is going to be redirected to a new origin?</p>&#xA;&#xA;<p>Is it safe to do something like:</p>&#xA;&#xA;<pre><code>window.location.href = 'https://b.example.com?jwt=tokenhere'&#xA;</code></pre>&#xA;&#xA;<p>I don't believe storing the JWT on <code>localStorage</code> since it does not allow cross origin access.</p>&#xA;"
50039099,Separate one module from JSF application,<rest><jsf><java-ee><architecture><microservices>,1,47,4,0.0,0,"<p>We have big JSF monolithic application. We want to change the architecture of this application. Currently, my goal - change one module in our application. I need to move the logic from one module to another application which will be implemented on another stack of technologies (it will be rest-service with some js-framework on frontend).</p>&#xA;&#xA;<p>The application should work in the same way. We should have the link to the page as it was earlier but this page should be rendered by another service. We should have the same session between these 2 applications. The user should be able to go throw the pages without an additional step of authentification.</p>&#xA;&#xA;<p>We are planning to move also other modules, not only this one. I need a help. Do you have any thoughts how it should be implemented? any examples?</p>&#xA;"
34376576,Best architecture to share large files among microservices,<nfs><microservices><data-sharing>,1,1629,0,0.0,0,"<p>I am about to start re-designing an old monolithic software with a microservices-oriented architecture (educational purposes). To give a bit of context, the old software runs on a powerful server that performs the following operations:</p>&#xA;&#xA;<ol>&#xA;<li>Receives batch data (binary file) from a producer.</li>&#xA;<li>Accumulates batch data from each producer.</li>&#xA;<li>Periodically, execute a batch operation over each producer's accumulated data, and store the result (another binary file).</li>&#xA;</ol>&#xA;&#xA;<p>Now, I want to create a separated microservice for this batch operation.  I would like to have this microservice executed in dozens of machines in paralell, so that I can process a big amount of producers.</p>&#xA;&#xA;<p>Each microservice instance will receive a binary file with each producer's data and output another binary file. The problem is that these files can be big (e.g. each producer may produce 20Mb of accumulated data). I came across several ways of dealing with this but I am not convinced by any of them:</p>&#xA;&#xA;<ol>&#xA;<li>Send the binary data among microservices using HTTP calls. I did not try it but it does not seem reasonable.</li>&#xA;<li>Store all the data in a central data repository from where each microservice can download it. Maybe I could use some sort of NFS, but I am not sure if that's a good option. Also, doesn't this go against the microservices philosophy?</li>&#xA;<li>Have a copy of all the data near each microservice. I am afraid I'll eventually run into consistency problems.</li>&#xA;</ol>&#xA;&#xA;<p>What do you believe is the best option (if any)? Thanks!</p>&#xA;"
34424706,How to access meteor collection through the database,<meteor><microservices>,3,154,1,0.0,0,"<p>I want to have my application's admin code hosted on a completely different app that shares the same database. However, that means that my collections are defined, at least in the code, in the global namespace of my main application and not my admin application. How can I access my collections, that are in the database, without having the global variables defined in a file shared between the meteor server/client? For reference, I am using this article as the idea to set up my admin tools this way. <a href=""http://joshowens.me/building-an-admin-app-as-a-microservice-with-meteor-js/"" rel=""nofollow"">admin article</a></p>&#xA;"
46193708,How To Make Relations Between Two Entities From Different Microservices In Spring Boot?,<spring-boot><spring-data><spring-data-jpa><microservices>,1,588,1,0.0,0,"<p>I am trying to make a simple <strong>Spring Boot</strong> web app using <strong>Microservice Architecture</strong>.</p>&#xA;&#xA;<p>I have two microservices with entities as defined below:</p>&#xA;&#xA;<pre><code>Microservice 1 :&#xA;&#xA;@Entity&#xA;public class Article {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and</p>&#xA;&#xA;<pre><code>Microservice 2 :&#xA;&#xA;@Entity&#xA;public class Tag {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I want to have a <strong>Many To Many</strong> relation between these two entities in my <strong>Gateway</strong>.</p>&#xA;&#xA;<p>I had tried to use feign client as below:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@FeignClient(value = ""article-service"")&#xA;public interface ArticleClient {&#xA;&#xA;    @RequestMapping(value = ""/articles/"", method = RequestMethod.GET)&#xA;    Set&lt;Article&gt; getArticleById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;&#xA;@FeignClient(value = ""tag-service"")&#xA;public interface TagClient {&#xA;&#xA;    @RequestMapping(value = ""/tags/"", method = RequestMethod.GET)&#xA;    Tag getTagById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And defined <strong>Article</strong> and <strong>Tag</strong> entities in my <strong>Gateway</strong> like this:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Entry {&#xA;&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;    @ManyToMany(cascade = CascadeType.ALL)&#xA;    @JoinTable(name = ""article_tag"",&#xA;        joinColumns = @JoinColumn(name = ""article_id"", referencedColumnName = ""id""),&#xA;        inverseJoinColumns = @JoinColumn(name = ""tag_id"",&#xA;                referencedColumnName = ""id""))&#xA;    private Set&lt;Tag&gt; tags;&#xA;}&#xA;&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Tag {&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    @ManyToMany(mappedBy = ""tags"")&#xA;    private Set&lt;Article&gt; articles;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have a table named <strong>article_tag</strong> in my database (<strong>Postgres</strong>).</p>&#xA;&#xA;<p>Now how can I define my repositories in the <strong>Gateway</strong>?&#xA;How to write getArticlesByTagId() or getTagsByArticleId() functions?&#xA;I did whatever I could to make this relation work but I think they are not going to get along with each other :)</p>&#xA;"
46092604,event-driven microservices id generation,<java><microservices>,2,203,3,0.0,0,"<p>I'm a newbie with microservices. I'm trying to create a microservices architecture where there is an API gateway that should just receive the request and create an event accordingly. Then the event will be intercepted by a microservice that stores the needed data into a database. </p>&#xA;&#xA;<p>Maybe I'm making a mistake with the design but I expect that after a client calls the API gateway the request proceeds asynchronously and the data consistency won't be guaranteed. </p>&#xA;&#xA;<p>So how the client knows if the resource has been created and its id?</p>&#xA;&#xA;<p>Should the client listen to the events as well?</p>&#xA;&#xA;<p>Is this the right architecture or am I going through the wrong path?</p>&#xA;&#xA;<p>Thank you in advance for your comments!</p>&#xA;&#xA;<p>Note: I'm not using any structured framework. I like them but this is mostly an experiment and I'd like keep everything simple. Anyway I'm opened if your suggestion involve spring or whatever java framework. </p>&#xA;&#xA;<p>(Edit)</p>&#xA;&#xA;<p>Another interesting point. Let's give that the API response is asynchronous, if the client has to insert an aggregated data made by two resources (identified by their own id), how this can be achieved through an event-driven architecture?</p>&#xA;"
46190467,CQRS + Microservices Handling event rollback,<domain-driven-design><microservices><cqrs><event-store>,3,223,3,1.0,0,"<p>We are using microservices, cqrs, event store using nodejs cqrs-domain, everything works like a charm and the typical flow goes like:</p>&#xA;&#xA;<ol>&#xA;<li>REST->2. Service->3. Command validation->4. Command->5. aggregate->6. event->7. eventstore(transactional Data)->8. returns aggregate with aggregate ID-> 9. store in microservice local DB(essentially the read DB)-> 10. Publish Event to the Queue</li>&#xA;</ol>&#xA;&#xA;<p>The problem with the flow above is that since the transactional data save i.e. persistence to the event store and storage to the microservice's read data happen in a different transaction context if there is any failure at step 9 how should i handle the event which has already been propagated to the event store and the aggregate which has already been updated?</p>&#xA;&#xA;<p>Any suggestions would be highly appreciated.</p>&#xA;"
46171136,"All my microservices have their own db's, should I create common microservice to handle connections?",<database><architecture><microservices>,1,95,4,1.0,0,"<p>I have a number of microservices that maintain their own databases (mongodb, elastic, mysql) and each of the microservices I have to set-up a new connection constantly. </p>&#xA;&#xA;<p>I was considering would it be wise if I created another microservice, that could handle these connections for the microservices, before they start up.</p>&#xA;&#xA;<p>Example:&#xA;My API Gateway microservice gets a request for search, it then calls search microservice, which before the search starts, calls the database setup miscroservice and returns an established connection back to it, based on what microservice called it (in this case - the search microservice).</p>&#xA;&#xA;<p>Would it be better, if I just found out what connection is needed inside the API Gateway? Or should I just leave the logic separately in each microservice.</p>&#xA;"
49349235,"Micro-services architecture, need advise",<microservices>,5,104,0,1.0,0,"<p>We are working on a system that is supposed to 'run' jobs on distributed systems.</p>&#xA;&#xA;<p>When jobs are accepted they need to go through a pipeline before they can be executed on the end system.</p>&#xA;&#xA;<p>We've decided to go with a micro-services architecture but there one thing that bothers me and i'm not sure what would be the best practice.</p>&#xA;&#xA;<p>When a job is accepted it will first be persisted into a database, then - each micro-service in the pipeline will do some additional work to prepare the job for execution.</p>&#xA;&#xA;<p>I want the persisted data to be updated on each such station in the pipeline to reflect the actual state of the job, or the its status in the pipeline.</p>&#xA;&#xA;<p>In addition, while a job is being executed on the end system - its status should also get updated.</p>&#xA;&#xA;<p>What would be the best practice in sense of updating the database (job's status) in each station:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each such station (micro-service) in the pipeline accesses the database directly and updates the job's status</p></li>&#xA;<li><p>There is another micro-service that exposes the data (REST) and serves as DAL, each micro-service in the pipeline updates the job's status through this service</p></li>&#xA;<li><p>Other?....</p></li>&#xA;</ol>&#xA;&#xA;<p>Help/advise would be highly appreciated.</p>&#xA;&#xA;<p>Thanx a lot!!</p>&#xA;"
49353369,Microservices and messaging,<microservices><messaging>,1,43,3,0.0,0,<p>I'm in the process of restructuring my first application to use microservices and messaging using an event driven architecture. I will have a content microservice to retrieve content from various sources and add to a message queue for processing. My query is that should the content microservice store the content in its own database as well or is that redundant as I am using messaging?  </p>&#xA;
44535853,Security considerations for API Gateway clustering?,<api><security><microservices><api-gateway>,1,63,0,2.0,0,"<p><a href=""https://i.stack.imgur.com/lWDTz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lWDTz.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>Clients that communicate against a single point of entry via an API Gateway over HTTPS against a RESTful API</li>&#xA;<li>API Gateway: API Keys for tracking and analytics, oAuth for API platform authentication</li>&#xA;<li>User Micro service provides user authentication and authorization, generates JWT that is signed and encrypted (JWS,JWE)</li>&#xA;<li>Other micro services determine permissions based on claims inside JWT</li>&#xA;<li>Micro services communicate internally via PUB/SUB using JWT in the message and other info. Each micro service could be scaled out with multiple instances (cluster with a load balancer).</li>&#xA;</ol>&#xA;&#xA;<p><strong>Question</strong>: <em>Can I cluster the the API Gateway and have the load balancer in front of it.  What do I need to consider with respect to managing authentication?  ie: sharing of API Keys across the API Gateway cluster?</em>  </p>&#xA;&#xA;<p>Extra notes, I'm planning on terminating SSL at the gateway and the use of bcrypt for passwords in the db.</p>&#xA;&#xA;<p>Any feedback would be great, thank you.</p>&#xA;"
44502869,How to load a zip file in java servlet and expose as URL,<java><url><servlets><microservices><embedded-jetty>,2,98,5,0.0,0,"<p>My requirement is loading a zip file from file system in java servlet and expose as URL (without extracting the zip file).</p>&#xA;&#xA;<p>For example, a zip file is located in C:\temp\example.zip. Content of this zip file is </p>&#xA;&#xA;<ol>&#xA;<li>example.html and its dependent files</li>&#xA;<li>one.js</li>&#xA;<li>two.js.</li>&#xA;</ol>&#xA;&#xA;<p>How to construct URL like ""<a href=""http://localhost:8080/app/example.zip/example.html"" rel=""nofollow noreferrer"">http://localhost:8080/app/example.zip/example.html</a>""? &#xA;Server could be jetty. Any help is highly appreciated. Thanks.</p>&#xA;&#xA;<p>I can even change the server or can use some other approach also to achieve the above solution. As said earlier, the only constraint is ""should not be extracted"".</p>&#xA;"
44585239,Splitting monolith to microservices database issues,<database><oracle><join><microservices>,1,227,6,0.0,0,"<p>I am splitting monolith application to microservices and I was able to split it to three microservices, for easier explanation suppose these are:</p>&#xA;&#xA;<ul>&#xA;<li>Users (CRUD)</li>&#xA;<li>Messages (CRUD)</li>&#xA;<li>Other things (CRUD)</li>&#xA;</ul>&#xA;&#xA;<p>All of these are distinct bounded contexts and I'm using database table for microservice. So in DB i have:</p>&#xA;&#xA;<pre><code>USERS table&#xA;id&#xA;surname&#xA;lastname&#xA;...&#xA;&#xA;OTHER_THINGS table&#xA;id&#xA;col1&#xA;col2&#xA;...&#xA;&#xA;MESSAGES table&#xA;id&#xA;title&#xA;created_time&#xA;USER_ID&#xA;OTHER_THING_ID&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>Now my web page needs searching/filtering of messages by all of the specified columns of all of these tables. For example:</p>&#xA;&#xA;<p>Web page user can enter:</p>&#xA;&#xA;<ul>&#xA;<li>surname of USER, </li>&#xA;<li>col2 of OTHER_THINGS </li>&#xA;<li>title of messages </li>&#xA;</ul>&#xA;&#xA;<p>And I should return only filtered rows.</p>&#xA;&#xA;<p>With monolith I have used simple database JOINS, but in this situation I can't find the best option. Can you suggest me possible options and which ones are better?</p>&#xA;"
46571540,Java Spring-boot micro-services Exception handling,<java><spring-mvc><spring-boot><microservices><netflix>,1,1080,1,0.0,0,"<p>Java exception handling is sub divided in to Errors, checked exceptions and unchecked exceptions. This question is about exceptions.</p>&#xA;&#xA;<p>Normal Java exception handling is to extend the Exception class for checked exceptions and handle those as you need by considering exception hierarchy.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionA extends Exception {}&#xA;&#xA;public class RunClass {&#xA;&#xA;    public static void main() {&#xA;        try {&#xA;            RunClass runClass = new RunClass();&#xA;            runClass.doSomething();&#xA;        } catch(ExceptionA eA) {&#xA;            // Do ExceptionA related resolutions.&#xA;        } catch(Exception e) {&#xA;            // Do Exception related resolutions.&#xA;        }&#xA;    }&#xA;&#xA;    public doSomething() throws ExceptionA {&#xA;        throw new ExceptionA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I saw major Spring books and even on the Internet tutorials mentioned with Spring-boot and in the context of micro-services always extend from RuntimeException class even with the @ControllerAdvice.</p>&#xA;&#xA;<p>This is clear violation of Java exception handling basics. But still there is an argument saying that, it is extended with RuntimeException because of this exception is handled by @ExceptionHandler method and it is generated and handled both in runtime.</p>&#xA;&#xA;<p>Still, because of this extension from RuntimeException makes compile time exception handling trail not visible and makes hard to trace back how exception is thrown up. Due to these reasons, I still believe, follow the basic Java checked and unchecked exception handling concept still with @ExceptionHandler method.</p>&#xA;&#xA;<p>E.g.:</p>&#xA;&#xA;<pre><code>public class ExceptionRA extends RuntimeException {}&#xA;&#xA;@ContollerAdvice&#xA;public class ExceptionHandler {&#xA;&#xA;    @ExceptionHandler(ExceptionRA.class)&#xA;    public String handleException (Exception exception, Model model) {&#xA;        return ""exception"";&#xA;    }&#xA;&#xA;}&#xA;&#xA;@Controller&#xA;public class RunClass {&#xA;&#xA;    @RequestMapping(""/url1"")&#xA;    public doSomething() {&#xA;        throw new ExceptionRA();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Should I follow the extending RuntimeException for all exception scenarios with @ExcpetionHadler or follow the basic Java checked and unchecked mechanism with @ExceptionHaldler? Ideas, suggestions and corrections are welcome.</p>&#xA;"
46586380,Securing micro-service spring cloud security Oauth2,<java><spring><security><spring-boot><microservices>,1,327,3,1.0,0,"<p>I am using Spring cloud security and Oauth2 to secure my micro- service. Now the Pom is as follows:</p>&#xA;&#xA;<p>&#xA;http://maven.apache.org/xsd/maven-4.0.0.xsd"">&#xA;    4.0.0</p>&#xA;&#xA;<pre><code>&lt;groupId&gt;com.oreilly.cloud&lt;/groupId&gt;&#xA;&lt;artifactId&gt;spring-microservices-oauth-server&lt;/artifactId&gt;&#xA;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;&lt;packaging&gt;jar&lt;/packaging&gt;&#xA;&#xA;&lt;name&gt;spring-microservices-oauth-server&lt;/name&gt;&#xA;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&#xA;&#xA;&lt;parent&gt;&#xA;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;&#xA;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;&lt;/parent&gt;&#xA;&#xA;&lt;properties&gt;&#xA;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;    &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;spring-cloud.version&gt;Dalston.SR3&lt;/spring-cloud.version&gt;&#xA;&lt;/properties&gt;&#xA;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.hsqldb&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;hsqldb&lt;/artifactId&gt;&#xA;        &lt;scope&gt;runtime&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;&#xA;&lt;dependencyManagement&gt;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;            &lt;type&gt;pom&lt;/type&gt;&#xA;            &lt;scope&gt;import&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&lt;/dependencyManagement&gt;&#xA;&#xA;&lt;build&gt;&#xA;    &lt;plugins&gt;&#xA;        &lt;plugin&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;        &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;&lt;/build&gt;&#xA;&#xA;&lt;repositories&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-snapshots&lt;/id&gt;&#xA;        &lt;name&gt;Spring Snapshots&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;true&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;    &lt;repository&gt;&#xA;        &lt;id&gt;spring-milestones&lt;/id&gt;&#xA;        &lt;name&gt;Spring Milestones&lt;/name&gt;&#xA;        &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;&#xA;        &lt;snapshots&gt;&#xA;            &lt;enabled&gt;false&lt;/enabled&gt;&#xA;        &lt;/snapshots&gt;&#xA;    &lt;/repository&gt;&#xA;&lt;/repositories&gt;&#xA;</code></pre>&#xA;&#xA;<p></p>&#xA;&#xA;<p>The Spring-boot main class is as below:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.boot.SpringApplication;&#xA;import org.springframework.boot.autoconfigure.SpringBootApplication;&#xA;import org.springframework.security.access.prepost.PreAuthorize;&#xA;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;&#xA;import org.springframework.web.bind.annotation.RequestMapping;&#xA;import org.springframework.web.bind.annotation.RestController;&#xA;&#xA;@SpringBootApplication&#xA;@EnableAuthorizationServer&#xA;@EnableResourceServer&#xA;@RestController&#xA;@EnableGlobalMethodSecurity(prePostEnabled=true)&#xA;public class SpringMicroservicesOauthServerApplication {&#xA;&#xA;    @RequestMapping(""/resource/endpoint"")&#xA;    @PreAuthorize(""hasRole('ADMIN')"")&#xA;    public String endpoint(){&#xA;        return ""This message is protected by the resource server."";&#xA;    }&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(SpringMicroservicesOauthServerApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The authorization server configuration is as follows:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.beans.factory.annotation.Autowired;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;&#xA;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;&#xA;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;&#xA;&#xA;@Configuration&#xA;public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter {&#xA;&#xA;    @Autowired&#xA;    private AuthenticationManager authManager;&#xA;&#xA;    @Override&#xA;    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {&#xA;        endpoints.authenticationManager(authManager);&#xA;    }&#xA;&#xA;    @Override&#xA;    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {&#xA;        clients.inMemory().withClient(""webapp"").secret(""websecret"").authorizedGrantTypes(""password"")&#xA;                .scopes(""read,write,trust"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Note the Authentication manager is auto wired into the Authorization config</strong> </p>&#xA;&#xA;<p>In the below class The Authentication Manager is configured and returned as abean so that it can be autowired to the above class:</p>&#xA;&#xA;<pre><code>package com.oreilly.cloud;&#xA;&#xA;import org.springframework.context.annotation.Bean;&#xA;import org.springframework.context.annotation.Configuration;&#xA;import org.springframework.security.authentication.AuthenticationManager;&#xA;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;&#xA;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;&#xA;&#xA;@Configuration&#xA;public class WebSecurityConfig extends WebSecurityConfigurerAdapter {&#xA;&#xA;    @Bean&#xA;    public AuthenticationManager authenticationManagerBean() throws Exception {&#xA;        return super.authenticationManagerBean();&#xA;    }&#xA;&#xA;    @Override&#xA;    protected void configure(AuthenticationManagerBuilder auth) throws Exception {&#xA;        auth.inMemoryAuthentication().withUser(""user1"").password(""password1"").roles(""USER"").and().withUser(""admin"")&#xA;                .password(""password2"").roles(""ADMIN"");&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now the application.properties is as below:</p>&#xA;&#xA;<pre><code>server.port=9090&#xA;</code></pre>&#xA;&#xA;<p>Now i run the Spring boot application as below:</p>&#xA;&#xA;<p>mvn spring-boot:run</p>&#xA;&#xA;<p>The application starts successfully and is ready to accept request on port 9090 on localhost</p>&#xA;&#xA;<p>Now using postman i am sending a post request to get the access_token. A little background is that the Aoauth2 flow being used here is the password grant. So in the AuthorizationServerConfig class above i have defined a password grant flow and registered a simple web app with client name and secret. As can be seen the client configuration is in memory.</p>&#xA;&#xA;<p>The post man request to get access token from authorization server is as follows: Its post request, with Basic auth header header having the &#xA;username as webapp and password as websecret.</p>&#xA;&#xA;<p><a href=""http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1"" rel=""nofollow noreferrer"">http://localhost:9090/oauth/token?grant_type=password&amp;username=user1&amp;password=password1</a></p>&#xA;&#xA;<p>This request returns successfully with a access token json as follows:</p>&#xA;&#xA;<pre><code>{&#xA;    ""access_token"": ""2d632e54-17c3-41f7-af3b-935ca3022d78"",&#xA;    ""token_type"": ""bearer"",&#xA;    ""expires_in"": 43199,&#xA;    ""scope"": ""read,write,trust""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now when i try to access the /resourse/endpoint with the above access token as follows:</p>&#xA;&#xA;<p><a href=""http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78"" rel=""nofollow noreferrer"">http://localhost:9090/resource/endpoint?access_token=2d632e54-17c3-41f7-af3b-935ca3022d78</a></p>&#xA;&#xA;<p>Rather than returning the text which is returned from the service /resourse/endpoint it returns the login page as below:</p>&#xA;&#xA;<pre><code>&lt;html&gt;&#xA;    &lt;head&gt;&#xA;        &lt;title&gt;Login Page&lt;/title&gt;&#xA;    &lt;/head&gt;&#xA;    &lt;body onload='document.f.username.focus();'&gt;&#xA;        &lt;h3&gt;Login with Username and Password&lt;/h3&gt;&#xA;        &lt;form name='f' action='/login' method='POST'&gt;&#xA;            &lt;table&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;User:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='text' name='username' value=''&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td&gt;Password:&lt;/td&gt;&#xA;                    &lt;td&gt;&#xA;                        &lt;input type='password' name='password'/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;tr&gt;&#xA;                    &lt;td colspan='2'&gt;&#xA;                        &lt;input name=""submit"" type=""submit"" value=""Login""/&gt;&#xA;                    &lt;/td&gt;&#xA;                &lt;/tr&gt;&#xA;                &lt;input name=""_csrf"" type=""hidden"" value=""8dbc1c38-6f89-43c5-a8f8-797c920722a1"" /&gt;&#xA;            &lt;/table&gt;&#xA;        &lt;/form&gt;&#xA;    &lt;/body&gt;&#xA;&lt;/html&gt;&#xA;</code></pre>&#xA;&#xA;<p>Can anyone please help what i am missing here?????. </p>&#xA;&#xA;<p><strong>NOTE</strong> I have both authorization server and resourse server configured in same application. this is a POC so i am trying out the Spring-cloud security, later i will separate the two ...but thats for later. </p>&#xA;"
46575898,What the hell is microservice?,<architecture><microservices>,2,913,3,0.0,0,"<p>Microservice for this, microservice for that, but explain to a simple person what is microservice? I'm a simple programmer with a little almost none theoretical background. But I don't need a term microservice to do what I do. Could someone explain me in easy-peasant words what microservice is? Amazon AWS = microservice?</p>&#xA;&#xA;<p>I read this: <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Microservices</a> but apparently I'm too stupid to understand what is this.</p>&#xA;"
45526675,Async HTTP request vs HTTP requests on new thread,<java><multithreading><rest><asynchronous><microservices>,3,533,0,0.0,0,"<p>I have 2 microservices (A and B).</p>&#xA;&#xA;<p>A has an endpoint which accepts POST requests. When users make a POST request, this happens:</p>&#xA;&#xA;<ol>&#xA;<li>Service A takes the object from the POST request body and stores it in a database.</li>&#xA;<li>Service A converts the object to a different object. And the new object gets sent to service B via Jersey HTTP client.</li>&#xA;</ol>&#xA;&#xA;<p>Step 2 takes place on a Java thread pool I have created (Executors.newCachedThreadPool). By doing step 2 on a new thread, the response time of service A's endpoint is not affected.</p>&#xA;&#xA;<p>However, if service B is taking long to respond, service A can potentially create too many threads when it is receiving many POST requests. To help fix this, I can use a fixed thread pool (Exectuors.newFixedThreadPool).</p>&#xA;&#xA;<p>In addition to the fixed thread pool, should I also use an asynchronous non-blocking HTTP client? Such as the one here: <a href=""https://hc.apache.org/httpcomponents-asyncclient-dev/"" rel=""nofollow noreferrer"">https://hc.apache.org/httpcomponents-asyncclient-dev/</a>. The Jersey HTTP client that I use is blocking.</p>&#xA;&#xA;<p>It seems like it is right to use the async HTTP client. <strong>But if I switch to a fixed thread pool, I think the async HTTP client won't provide a significant benefit - am I wrong in thinking this?</strong></p>&#xA;"
45530657,What is the correct way of sharing common yet versioned infrustructural code between microservices?,<.net><nuget><versioning><microservices>,1,59,0,2.0,0,<p>We'd like to extract some infrastructure related code (mostly extension methods or small helper classes) into separate NuGet packages. </p>&#xA;&#xA;<p>These packages in no way contain business logic pertaining to either of the services.</p>&#xA;&#xA;<p>But as soon as as we end up having a hierarchy of dependencies between packages we are probably asking for troubles with versioning:</p>&#xA;&#xA;<p>Service1 references package Av1.1 directly and Av2.0 indirectly via referenced package B.<br/></p>&#xA;&#xA;<p>ServiceN references package Av1.5 directly and Av1.3 indirectly via referenced package C.<br/></p>&#xA;&#xA;<p>NuGet does not support side-by-side versions and only one version is used per project. This problem of versioning is relevant for monolithic applications as well though with seemingly significantly fewer possible integration issues.</p>&#xA;&#xA;<p>There are some ideas like not extracting common code and letting it be duplicated across services or just not changing the version of the package forcing every service to work with the same version.</p>&#xA;&#xA;<p>Are there any good recommendations concerning code reuse between services which go well with versioning?</p>&#xA;
45559979,Access Token/Authorization Between Microservices,<spring-security><oauth-2.0><microservices><spring-cloud><spring-security-oauth2>,3,670,0,0.0,0,"<p>I'm creating an online store REST API that will mainly be used by a mobile app. The plan is for a microservices architecture using the Spring Cloud framework and Spring Cloud OAuth for security.</p>&#xA;&#xA;<p>My question is really on best practices for communication between microservices: Should I have each service register for their own token, or should they just pass the user's token around?</p>&#xA;&#xA;<p>For example, I have 3 services: user-service, account-service, order-service.&#xA;I've been able to implement two procedures for creating an order: One passes the user's token around, and in the other each service gets their own token. I use Feign for both approaches.</p>&#xA;&#xA;<p>So for option 1: order-service -> GET account-service/account/current</p>&#xA;&#xA;<p>order-service calls the account-service which returns the account based on a userId in the token. Then the order-service creates an order for the account.</p>&#xA;&#xA;<p>Or for option 2: order-service -> GET account-service/account/user-id/{userId}</p>&#xA;&#xA;<p>order-service gets the userId from the sent token, calls the account-service with it's own token, then creates the order with the retrieved account.</p>&#xA;&#xA;<p>I'm really not sure which option is best to use. One better separates information but then requires two Feign Clients. However the other doesn't require the 2 clients and it becomes easier to block off end certain endpoints to outside clients, however it requires extra endpoints to be created and almost every service to go digging into the Authentication object.</p>&#xA;&#xA;<p>What are all your thoughts? Has anyone implemented their system in one way or another way entirely? Or perhaps I've got the completely wrong idea.</p>&#xA;&#xA;<p>Any help is appreciated.</p>&#xA;"
45533748,version management in microservices,<version-control><cloud><microservices><service-discovery>,2,1982,0,1.0,0,"<p>Suppose that I have a UserService in my <strong>Microservice Architecture</strong> deployed on the cloud. There is a <strong>Service Discovery</strong> for routing the requests to different host of UserService. </p>&#xA;&#xA;<p>If I have two different versions of UserService. Lets say <em>user-service-1.0</em> and <em>user-service-2.0</em> and part of clients should still use older version, then how this can be managed in Microservice Architecture. </p>&#xA;"
45579511,A/B testing. Routing Clients in a gateway API,<microservices><ab-testing><api-gateway><canary-deployment>,3,760,0,0.0,0,"<p>I am working on a new project that will be based on microservices. It's an internal app and only about 10 microservices. We will be using a gateway API for authentication and possibly some microservice aggregation. (Probably Netflix zuul with Spring Boot)</p>&#xA;&#xA;<p>What I'm not clear on is how we do the routing for A/B testing and Canary testing. Lets assume I have 100 clients and we want to A/B test a new version of a microservice. The client app needs no changes, it's just internal changes to the function that the microservice provides.</p>&#xA;&#xA;<p>I understand we would stand up a new microservice which is (say) v2. What I'm puzzled on is how do I direct (say) clients 1-10 to the new version. We need to be able to configure this centrally and not change anything on the client.</p>&#xA;&#xA;<p>We know their mac addresses (as well as other identifying attributes) and can insert any kind of header we want to identify their messages.</p>&#xA;&#xA;<p>So how would I direct these to v2 of the API for the A/B test or Canary deployment?</p>&#xA;"
45426194,Message format/specification for distributed REST services?,<rest><message-queue><microservices><messages>,1,28,3,0.0,0,"<p>I have a growing number of REST services that talk to each other with JSON. Right now, the communication is direct, but it's possible that a broker might process and distribute later on. </p>&#xA;&#xA;<p>This is the only one I've found so far:&#xA;<a href=""https://github.com/cjus/umf/blob/master/umf.md"" rel=""nofollow noreferrer"">https://github.com/cjus/umf/blob/master/umf.md</a></p>&#xA;&#xA;<p>Are there others that would be better suited? Thanks.</p>&#xA;"
47133571,Guzzle ServerException resulted in a `500 Internal Server Error` response,<php><laravel-5><microservices><guzzle><lumen>,1,1045,0,2.0,0,"<p>I'm trying to implement a MicroService Architecture Using Lumen and laravel </p>&#xA;&#xA;<p>I'm using laravel 5.4 as an ApiGetway and using Lumen 5.4 as a microService</p>&#xA;&#xA;<p>the thing here i'm using GuzzleHTTP version 6.3 in my laravel project, trying to hit the microService API, but i'm getting 500 Internal Server Error</p>&#xA;&#xA;<p>I'm trying this in my localhost </p>&#xA;&#xA;<p>This is how i'm making requests:</p>&#xA;&#xA;<pre><code>public function get_posts(){&#xA;    try {&#xA;&#xA;       $client = new Client(); //GuzzleHttp\Client&#xA;       $res = $client-&gt;request('GET', 'http://localhost/micro/posts_micro_service/public/posts');&#xA;         if($res-&gt;getStatusCode() == ""200""){&#xA;             echo $res-&gt;getBody();&#xA;         }else{&#xA;             return response()-&gt;json(['status',""error""]);&#xA;         }&#xA;     } catch (ClientException $e) {&#xA;            echo Psr7\str($e-&gt;getRequest());&#xA;            echo Psr7\str($e-&gt;getResponse());&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I'm getting this error :</p>&#xA;&#xA;<pre><code> (1/1) ServerException&#xA;Server error: `GET http://localhost/micro/posts_micro_service/public/posts` resulted in a `500 Internal Server Error` response:&#xA;&lt;!DOCTYPE html&gt;&#xA;&lt;html&gt;&#xA;&lt;head&gt;&#xA;&lt;meta name=""robots"" content=""noindex,nofollow"" /&gt;&#xA;&lt;style&gt;&#xA;(truncated...)&#xA;in RequestException.php (line 113)&#xA;</code></pre>&#xA;"
49579074,Cache Implementation in Microservices best practises,<caching><microservices>,1,28,4,0.0,0,<p>I want to ask one design related question as we have multiple micro-services and we want to implement cache for them. </p>&#xA;&#xA;<p>There is a possibility of having different services accessing the same cache for setting and fetching data from this cache So what should be the best way of doing it. </p>&#xA;&#xA;<p>Assuming we have customer service which updates the cache with customer data and we have a cart cache which do needs this data to set in cart object which contains this customer data so for this kind of scenario what would be the best way of implementing this.</p>&#xA;
46934916,Microserivce Using Spring Boot to Consume SOAP,<java><rest><spring-boot><soap><microservices>,3,632,0,0.0,0,"<p>I need to create a REST service that first consumes SOAP. What would the best way to go about this?</p>&#xA;&#xA;<p>I would like to use Spring Boot to create a microservice, but I have a few questions for those with experience:</p>&#xA;&#xA;<ul>&#xA;<li>What other architectures or technologies should I look into using&#xA;(with spring boot)?  </li>&#xA;<li>Is there a standard technology stack for this?</li>&#xA;<li>Are there pitfalls I should be aware of?</li>&#xA;</ul>&#xA;"
47042162,Where in S3 my Lambda code stored,<amazon-web-services><amazon-s3><aws-lambda><microservices>,2,703,0,0.0,0,<p>I have read the Lambda FAQ and it says it stores my code in S3 and it is encrypted.</p>&#xA;&#xA;<p>Where in S3 is it stored and can I decrypt it to edit my code?</p>&#xA;
46947956,"MQ - How to guarantee message delivery in a non-transacted, lightweight environment?",<transactions><zeromq><microservices><mq><2phase-commit>,2,96,11,0.0,0,"<p>How to guarantee message delivery in a non-transacted, lightweight environment?</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<ul>&#xA;<li>Normal situation: Write to database, commit, <strong>send message to ZeroMQ|Redis|OtherMQ</strong>, consumer pulls the message to continue processing...</li>&#xA;<li>0,05% situation: Write to database, commit, <strong>application dies!</strong>, no message sent, no consumer pull the message, incomplete processing.</li>&#xA;</ul>&#xA;&#xA;<p>How to not loose the message (avoid not send the message) in this situation?</p>&#xA;&#xA;<p><strong>Edit</strong>: The message must be delivery exactly once.</p>&#xA;"
38461294,How to send JSON as a Input parameter from one Microservice to another using RestTemplate in Spring Boot,<java><spring-boot><resttemplate><microservices>,3,1356,0,1.0,0,"<p>I want to send <code>JSON</code> as an <code>input</code> from Microservice M1 to a Microservice M2.</p>&#xA;&#xA;<p>M1 and M2 both are on different machines.&#xA;I am new to Spring Boot,</p>&#xA;&#xA;<p>I found some <a href=""https://spring.io/guides/tutorials/bookmarks/"" rel=""nofollow"">code</a> but I am unable to get it.&#xA;Please help.</p>&#xA;"
38380827,Microservices Maven Project Structure,<java><spring><maven><microservices>,2,2112,2,0.0,0,"<p>I am working on a project in which we'll deploy a full Spring Boot microservices architecture, along with supporting services like load balancing, service registry, edge server, and centralized monitoring.</p>&#xA;&#xA;<p>I have a single project that will be shared among all core microservices which contains DAOs and all the dependencies for the core microservices. I am hoping to be able to release one ~60Mb jar, and have the other Spring Boot core microservices be very lightweight (&lt;1Mb). At runtime the core microservices will reference the shared jar on their classpath.</p>&#xA;&#xA;<p>The way I've set the project up is to have separate project, with a structure like so:</p>&#xA;&#xA;<pre><code>|shared_project&#xA;|pom.xml&#xA;&#xA;|ms-1&#xA;|pom.xml&#xA;&#xA;|ms-2&#xA;|pom.xml&#xA;</code></pre>&#xA;&#xA;<p>The shared project uses maven-assembly-plugin to create a big jar and copies it to my local .m2 repo. The ms-1 and ms-2 poms use maven-jar-plugin to create their jars and have one dependency, the shared project. </p>&#xA;&#xA;<p>I'm sure this is not the best way to handle this. It's creating issues during unit tests and I have to imagine it'll create issues down the line. I've seen this done using parents in the pom file, nesting the project inside another directory, and other ways. </p>&#xA;&#xA;<p>What I am wondering is what is the best practice regarding keeping your Spring Boot projects' dependencies and shared code centralized and externalized through use of Maven, such that the projects that you are frequently rolling are kept lightweight and decoupled? </p>&#xA;&#xA;<p>Bonus questions: </p>&#xA;&#xA;<ol>&#xA;<li><p>Does the fact that we'll be using Jenkins/TeamCity for CI and automated testing affect the answer?</p></li>&#xA;<li><p>Does having one shared jar on the filesystem which each project references in its classpath during startup pose any challenges? Depending on demand, we may flexibly spin up 10 instances of microservice-1 and only 3 of microservice-2. </p></li>&#xA;</ol>&#xA;&#xA;<p>EDIT: I think this already has a good answer here: &#xA;<a href=""https://stackoverflow.com/questions/27865238/parent-pom-and-microservices"">Parent pom and microservices</a></p>&#xA;"
38297333,Sharing data among Microservices‏,<rest><design-patterns><enterprise><restful-architecture><microservices>,2,774,4,1.0,0,"<p>I'm seeking an answer to a design question that I didn't find an answer to in any literature on this matter. Allow me to explain the use case, my solution to it and, ask for your opinion as a subject matter expert.</p>&#xA;&#xA;<p><strong>Use Case</strong>:&#xA;We've several Microservices that all return some form of content from different business domains. We're using Spring Cloud Netflix, so a gateway service routes traffic to the content services. Some, if not all, of these services require data that is derived from the request, and is immutable. A trivial example is locale, although there are other proprietary information too.</p>&#xA;&#xA;<p><strong>Solution</strong>:&#xA;I'm currently deriving the shared data in the gateway service and persisting as JSON in a NoSQL database with a unique key. Then I'm adding the key as a request header before routing the request. I've a shared library that the content services include at build time, and includes a Spring bean that reads the key from the request header, fetches the stored data using the key and initializes itself. This makes it possible for the content services to access the shared data (by simply injecting the previously mentioned bean) without knowing the underlying mechanism.&#xA;If a content service invokes another one, it's responsible for adding the unique key as a request header.</p>&#xA;&#xA;<p><strong>Debate</strong>:&#xA;The debate I've with my colleagues is that whether using a shared datastore for this purpose is appropriate. I contend that it is bad for a service to leak it's domain specific data to others, but the data in question isn't domain specific, so there's nothing wrong with having a shared database and passing the key around. The alternative would be to pass all the shared data around which I consider redundant.</p>&#xA;&#xA;<p>What is your thought?</p>&#xA;&#xA;<p><strong>Edit</strong>: I see someone voted to close the question. Unless they can point me to a reference that discusses data sharing among Microservices, such policing is a hindrance to meaningful discussion. Not every question is a boolean yes/no answer, some require deeper thoughts.</p>&#xA;"
38352227,What is the name of this 'intermediary' pattern?,<java><web-services><design-patterns><microservices>,1,99,5,0.0,0,"<p>I've got an intermediary java web service application application (built using Spark Java - but that is incidental) that takes an http parameter - from it generates a URL - calls the URL and then returns the result to the original caller. </p>&#xA;&#xA;<pre><code>Original Client -&gt; My Application -&gt; Http Web Service Producer&#xA;</code></pre>&#xA;&#xA;<p>This is kind of a MicroServices pattern - but I'm looking for a more specific term. I think it is a 'pipeline', 'solicitor' or a 'mediator'. </p>&#xA;&#xA;<p>My question is: <strong>What is the name of this 'intermediary' pattern?</strong></p>&#xA;"
38397672,Multiple database management,<mongodb><haxe><microservices>,1,174,6,0.0,0,"<p>I'm currently working on a multiplayer game which will be using two databases(MONGODB). One for authentication(login) and one to contain all game-specific data.&#xA;What I've done is to separate the user and game specific data. This way i'll be able to build micro services around the user in the future.</p>&#xA;&#xA;<p>I'm a bit uncertain on how to handle/validate the game-specific database operations tho.&#xA;When i log into my game, i perform a POST request to my rest api, which validates the user and returns some data.</p>&#xA;&#xA;<p>The game itself however, is using a TCP socket connection to handle real-time gameplay and will be saving game-specific data to the database on the authoritative server(all game logic is done on the server) . How would you go about to link the data on the game-specific database to a specific user found in the authentication database?</p>&#xA;"
47555732,How to correctly handle inter-service exception in a spring-based microservices architecture,<java><exception-handling><microservices><spring-cloud-feign>,1,612,0,2.0,0,"<p>I have an application developed with a microservices architecture. Each microservice is a spring-boot application that communicates with others via FeignClient interface.</p>&#xA;&#xA;<p>Let A, a microservice (RestAPI) that calls microservice B. In normal conditions, B replies with an Object X, that is the JSON-response that A serves to client.</p>&#xA;&#xA;<p>But, if B throws an exception, I obtain a chinese-box exception to the client like this:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051071,&#xA;    ""status"": 500,&#xA;    ""error"": ""Internal Server Error"",&#xA;    ""exception"": ""Exception"",&#xA;    ""message"": { ""\""timestamp\"":1511965051052,\""status\"":422,\""error\"":\""Unprocessable Entity\"",\""exception\"":\""java.lang.MyException\"",\""message\"":\""Error message from B\"",\""path\"":\""PATH-OF-B-SERVICE\""}"",&#xA;    ""path"": ""PATH-OF-A-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In other words, MyException (status 422) is ""embedded"" in A Exception (status 500).</p>&#xA;&#xA;<p>I would like to reply the client with the inner JSON, that is:</p>&#xA;&#xA;<pre><code>{&#xA;    ""timestamp"": 1511965051052,&#xA;    ""status"": 422,&#xA;    ""error"": ""Unprocessable Entity"",&#xA;    ""exception"": ""java.lang.MyException"",&#xA;    ""message"": ""ErrormessagefromB"",&#xA;    ""path"": ""PATH-OF-B-SERVICE""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>How can I do that?</p>&#xA;"
47736658,Restricting access to api from another application ruby,<ruby><api><http><ip><microservices>,1,33,4,0.0,0,"<p>I have a Grape API application built in Ruby. &#xA;And also some other microservices built in Python, Java etc.&#xA;I have to restrict some of these microservices from accessing a particular API in this grape application. </p>&#xA;&#xA;<p>Now, this is implemented using IP whitelisting. But every time the IP of other microservices gets changed, the code of grape application has also to be changed which is not stable. </p>&#xA;&#xA;<p>Is there any better solution for this? Please help.</p>&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;"
51224374,Microservice requests,<microservices>,2,40,3,0.0,0,"<p>I'm trying to start a little microservice application, but I'm a little bit stuck on some technicalities.</p>&#xA;&#xA;<p>I'm trying to build an issue tracker application as an example.</p>&#xA;&#xA;<p>It has 2 database tables, issues and comments. These will also be separate microservices, for the sake of the example.</p>&#xA;&#xA;<p>It has to be a separate API that can be consumed by multiple types of clients e.g. mobile, web etc..</p>&#xA;&#xA;<p>When using a monolitic approach, all the codebase is coupled together, and when making a request to let's say the REST API, I would handle for example the '/issues/19' request&#xA;to fetch the issue with the id '19' and it's corresponding comments by means of the following pseudocode.</p>&#xA;&#xA;<pre><code>on_request_issue(id) # handler for the route '/issues/&lt;id&gt;'&#xA;    issue = IssuesModel.findById(id)&#xA;    issue.comments = CommentsModel.findByIssueId(id)&#xA;    return issue&#xA;</code></pre>&#xA;&#xA;<p>But I'm not sure on how I should approach this with microservices. Let's say that we have microservice-issues and microservice-comments.</p>&#xA;&#xA;<p>I could either let the client send a request to both '/issues/19' and '/comments/byissueid/19'. But that doesn't work nice in my point of view, since if we're having multiple things&#xA;we're sending alot of requests for one page.</p>&#xA;&#xA;<p>I could also make a request to the microservice-issues and in that one also make a request to the microservice-comments, but that looks even worse to me than the above, since from what&#xA;I've read microservices should not be coupled, and this couples them pretty hard.</p>&#xA;&#xA;<p>So then I read about API gateways, that they could/should receive a request and fan out to the other microservices but then I couldn't really figure out how to use an API gateway. Should&#xA;I write code in there for example to catch the '/issues/19' request, then fan out to both the microservice-issues and microservice-commetns, assemble the stuff and return it? &#xA;In that case, I'm feeling I'm doing the work double, won't the API gateway become a new monolith then?</p>&#xA;&#xA;<p>Thank you for your time</p>&#xA;"
51280734,Spring boot application stopping without any error on console,<maven><spring-boot><amazon-ec2><microservices><aws-regions>,4,149,3,0.0,0,"<p>I have created spring boot application using maven. Where I built a executable jar for application the tried to run it on EC2 instance free tier windows using following command<br>&#xA;java -jar com-spring-boot-apps-0.0.1-SNAPSHOT.jar  --server.port=8181 -Xdebug</p>&#xA;&#xA;<p>Some it application does not run, it exists with following logs on console. </p>&#xA;&#xA;<pre><code>log4j:WARN No appenders could be found for logger (org.springframework.web.context.support.StandardServletEnvironment).&#xA;log4j:WARN Please initialize the log4j system properly.&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v2.0.3.RELEASE)&#xA;&#xA;2018-07-11 13:55:50.762  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]&#xA;2018-07-11 13:55:50.768  INFO 2784 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.31&#xA;2018-07-11 13:55:50.800  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : Loaded APR based Apache Tomcat Native library [1.2.17] using APR version [1.6.3].&#xA;2018-07-11 13:55:50.803  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true].&#xA;2018-07-11 13:55:50.805  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : APR/OpenSSL configuration: useAprConnector [false], useOpenSSL [true]&#xA;2018-07-11 13:55:52.060  INFO 2784 --- [ost-startStop-1] o.a.catalina.core.AprLifecycleListener   : OpenSSL successfully initialized [OpenSSL 1.0.2o  27 Mar 2018]&#xA;2018-07-11 13:55:52.402  INFO 2784 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext&#xA;2018-07-11 13:55:52.532  INFO 2784 --- [           main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]&#xA;</code></pre>&#xA;&#xA;<p>Exception :- </p>&#xA;&#xA;<pre><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'regionProvider': Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.aws.core.region.StaticRegionProvider]: Constructor threw exception; nested exception is java.lang.IllegalArgumentException: The region 'ap-south-1a' is not a valid region!&#xA;</code></pre>&#xA;"
51238009,Create endpoint to get multiple records in microservice,<java><c#><design-patterns><microservices>,3,64,4,0.0,0,"<p>Currently, we have an API endpoint (microservice called supplier service) like this: <code>/suppliers/{supplierNumber}</code>, which will return a single supplier information. </p>&#xA;&#xA;<p>In the UI, there is a screen to display a list of suppliers for different products. It looks something like this:  </p>&#xA;&#xA;<pre><code>product1 -&gt; supplier1&#xA;product2 -&gt; supplier2&#xA;product3 -&gt; supplier3&#xA;</code></pre>&#xA;&#xA;<p>To display suppliers for a list of products, we need a for loop which calls the end point on each iteration.</p>&#xA;&#xA;<p>My concern is that this is inefficient from a performance stand point. Why is it not possible to design an endpoint that takes in a list of supplier numbers and returns a list of supplier information?</p>&#xA;&#xA;<p>Other people have said that it's not microservice design, and I'm not sure why it's not a proper design. Does anyone know the reasoning behind this?</p>&#xA;"
48190148,What is the difference between SOA and Microservices,<web><microservices><distributed-computing><soa>,1,344,3,0.0,0,"<p>Ok, as far as I've understood both in SOA and in Microservices modules should be independant and reusable. But what really differs SOA and Microservices ?</p>&#xA;"
48374452,Dao as a Seperate Module in Monolithic Considering Extendable to microservice in future,<java><spring><microservices>,1,114,3,0.0,0,"<p>I am actually creating one project where we are having 2 or more database. I will use Spring Boot. I would like to know:</p>&#xA;&#xA;<ol>&#xA;<li><p>Why do we have Client of the Gateways while code as we already have REST endpoint in server (May be i am wrong )?</p></li>&#xA;<li><p>My project currently will be monolithic but I want to make it possible to change to a microservice architecture in the future. Should I have the DAO as separate module which will be dependency for other module considering I can have more than one database (RDBMS and NoSQL)?</p></li>&#xA;</ol>&#xA;&#xA;<p>Hope I am asking work question, but I am confused right now, while starting the project.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
44786479,grpc architecture : where should be caching layer be?,<c#><caching><microservices><grpc>,1,286,3,0.0,0,"<p>We have a monolithic system that we are currently breaking into microservices using gRPC. Currently, we are using enyim caching in C# client in our monolithic code.</p>&#xA;&#xA;<p>While creating our first gRPC service, we are confused that where should caching layer be:</p>&#xA;&#xA;<ol>&#xA;<li>Should it be moved to gRPC service code for this service? This way each service will have its caching code. This would lead to lots of duplicate caching code.</li>&#xA;<li>Should we create dll for caching related code and use it in new gRPC microservice? We would still need to place duplcate configurations across each gRPC service.</li>&#xA;<li>Handle caching from monolithic code only and call gRPC service only in case for cache miss?</li>&#xA;</ol>&#xA;&#xA;<p>Suggestions?</p>&#xA;"
44758955,Wildfly Swarm JGroups YAML,<java-ee><yaml><microservices><jgroups><wildfly-swarm>,1,318,3,0.0,0,"<p>I've downloaded the Wildfly swarm examples and now I am trying to move the configurations in Main classes to YAML files.</p>&#xA;&#xA;<p>So far, everything is working, except the ribbon example. I took the configuration from the example project and tried to convert it into YAML file.</p>&#xA;&#xA;<p>Project source: <a href=""https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java"" rel=""nofollow noreferrer"">https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java</a></p>&#xA;&#xA;<p>My YAML file (as I think it should look like)</p>&#xA;&#xA;<pre><code>--- &#xA;swarm:&#xA;  context:&#xA;    path: proxy&#xA;  http:&#xA;    port: 8080&#xA;  jgroups: &#xA;    default-channel: swarm-jgroups&#xA;    stacks:&#xA;      udp:&#xA;        protocols:&#xA;          FD_SOCK:&#xA;            socket-binding: jgroups-udp-fd&#xA;          TCP:&#xA;            properties:&#xA;              bind_port:&#xA;                value: 9090&#xA;          TCPPING:&#xA;            properties:&#xA;              initial_hosts:&#xA;                value: ""localhost[9090],localhost[9091],localhost[9092],localhost[9093]""&#xA;              num_initial_members:&#xA;                value: 4&#xA;              port_range:&#xA;                value: 4&#xA;              timeout:&#xA;                value: 3000&#xA;          FD_ALL: null&#xA;          VERIFY_SUSPECT: null&#xA;          pbcast.NAKACK2: null&#xA;          UNICAST3: null&#xA;          pbcast.STABLE: null&#xA;          pbcast.GMS: null&#xA;          UFC: null&#xA;          MFC: null&#xA;          FRAG2: null&#xA;          RSVP: null&#xA;        transports:&#xA;          UDP:&#xA;            socket-binding: jgroups-udp&#xA;</code></pre>&#xA;&#xA;<p>But I am getting two Exceptions: On startup in the first line:</p>&#xA;&#xA;<pre><code>Error getting subresources for Stack java.lang.RuntimeException: Failed to adopt value java.util.Map&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:347)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:33)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshal(Marshaller.java:23)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller.marshal(SubsystemMarshaller.java:59)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller.marshal(DMRMarshaller.java:70)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer.start(RuntimeServer.java:182)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer$Proxy$_$$_WeldClientProxy.start(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.lambda$bootstrap$1(ServerBootstrapImpl.java:158)&#xA;        at org.wildfly.swarm.spi.api.ClassLoading.withTCCL(ClassLoading.java:43)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.bootstrap(ServerBootstrapImpl.java:113)&#xA;        at org.wildfly.swarm.Swarm.start(Swarm.java:369)&#xA;        at org.wildfly.swarm.Swarm.main(Swarm.java:623)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;        at java.lang.reflect.Method.invoke(Unknown Source)&#xA;        at org.wildfly.swarm.bootstrap.MainInvoker.invoke(MainInvoker.java:39)&#xA;        at org.wildfly.swarm.bootstrap.Main.run(Main.java:46)&#xA;        at org.wildfly.swarm.bootstrap.Main.main(Main.java:37) Caused by: java.lang.ClassCastException: java.util.HashMap cannot be cast to java.lang.String&#xA;        at org.wildfly.swarm.config.runtime.invocation.MapTypeAdapter.toDmr(MapTypeAdapter.java:22)&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:341)&#xA;        ... 24 more&#xA;</code></pre>&#xA;&#xA;<p>And then the jgroup sepcific exception:</p>&#xA;&#xA;<pre><code>    (""subsystem"" =&gt; ""jgroups""),&#xA;    (""stack"" =&gt; ""udp"")&#xA;]) - failure description: ""WFLYCLJG0010: Transport for stack udp is not defined. Please specify both a transport and protocol list, either as optional parameters to add() or via batching.""&#xA;</code></pre>&#xA;&#xA;<p>I am not sure what is wrong.</p>&#xA;&#xA;<p>Maybe you guys can give me a hint?</p>&#xA;"
44781219,Atomic insert of data in micro service architecture + NoSql database [Data consistency in Micro service architecture],<database-design><cassandra><architecture><microservices><nosql>,2,132,3,0.0,0,"<p>I have 3 services A, B, C. </p>&#xA;&#xA;<p>Service A receives a request from client. Then A prepares a data for its own database, service B and C. Basically A is coo-ordinator.</p>&#xA;&#xA;<ol>&#xA;<li>A insert data in its database</li>&#xA;</ol>&#xA;&#xA;<p>If it is success </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>post request B's data to service B and B insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If it is success</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>then post request C's data to service C and C insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If anything fails at any step, we have to revert all data inserted.</p>&#xA;&#xA;<p>I am using Cassandra NoSQL DB.</p>&#xA;&#xA;<p><strong>Now i need a generic solution for all cases that could happen like :</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I.</p>&#xA;&#xA;<p>Suppose C is inserting data (in progress), in the mean time, some read query R on A-database reads the inserted data. After few millisec, C fails to insert, but R already read the false data which would be reverted soon.</p></li>&#xA;</ul>&#xA;&#xA;<p>What to do in this case? &#xA;--> change the DB design, such that this kind of condition would never happen??</p>&#xA;&#xA;<ul>&#xA;<li><p>II.</p>&#xA;&#xA;<p>What if service C data insert fails, and service B have application server downtime so it couldn't revert??</p></li>&#xA;</ul>&#xA;"
51419192,Using microservices architecture in spring,<spring-boot><microservices><spring-cloud-netflix>,3,47,3,0.0,0,"<p>I'm building a project which based on microservices architecture in spring boot.The project was divided multiple modules and I used maven dependency management.</p>&#xA;&#xA;<p>Now I want to use services from one module in other module. I have many spring applications. For example, I have 2 application which is named A and B. I want to use classes from A in B and classes of B in A. In this case I used maven dependencies but it is not completely way to using services in one another because I faced with circular dependency. </p>&#xA;&#xA;<p>What should do to use for solve this problem?</p>&#xA;"
51463258,Call some different restful services from front-end,<domain-driven-design><microservices><dbcontext><restful-architecture>,1,56,3,0.0,0,"<p>Imagine I have an angular project as a front-end which communicates with some other projects which are restful services.</p>&#xA;&#xA;<p>In some pages I need to fetch some data from different restful services, &#xA;Is that okay to request any restful service individually in angular?&#xA;Or call one restful service which itself call other restful services in back-end?</p>&#xA;&#xA;<p>Or I have to call one restful service but add other entities to this DbContext which I need here just to query?</p>&#xA;"
51542629,Multiple Azure applications with version independent common micro-services on the same cluster,<azure><microservices><azure-service-fabric><azure-deployment>,1,36,5,0.0,0,"<p>We have multiple Azure applications that use shared micro-services (Indexing, Indexing Management, etc) via git submodules.  We deployed the first application without any problems, but when attempted to deploy the second application the micro-services where not created in the application.</p>&#xA;&#xA;<p>As these micro-services are submodules they share the same ServiceManifest and have identical names and version numbers.  Currently both are at the same commit, but in the future they can be independent of each other.</p>&#xA;&#xA;<p>Is the shared name causing our deployment issues despite being in separate applications?</p>&#xA;"
51515839,Nodejs not able to connect to mongodb on cloud shell,<node.js><mongodb><google-app-engine><google-cloud-platform><microservices>,3,163,7,0.0,0,"<p>My MongoDB server is hosted on google-cloud VM. I wish to create App Engine microservice. to test connectivity,  </p>&#xA;&#xA;<p>my server.js looks like </p>&#xA;&#xA;<pre><code>const MongoClient = require('mongodb').MongoClient;&#xA;const test = require('assert');&#xA;// Connection url&#xA;const url = 'mongodb://testmongodb:27017';&#xA;// Database Name&#xA;const dbName = 'test';&#xA;// Connect using MongoClient&#xA;MongoClient.connect(url, { useNewUrlParser: true },function(err, client) {&#xA;if(err){console.log(err)}&#xA;else {console.log(""Connected successfully"")}&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>it works perfectly if i connect via another vm. But does not work when trying to execute (npm start) the same code via <strong>Google Cloud Shell</strong>. I get the error </p>&#xA;&#xA;<pre><code>{ MongoNetworkError: failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]&#xA;    at Pool.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/topologies/server.js:562:11)&#xA;    at emitOne (events.js:116:13)&#xA;    at Pool.emit (events.js:211:7)&#xA;    at Connection.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/pool.js:316:12)&#xA;    at Object.onceWrapper (events.js:317:30)&#xA;    at emitTwo (events.js:126:13)&#xA;    at Connection.emit (events.js:214:7)&#xA;    at Socket.&lt;anonymous&gt; (/home/google/mng/node_modules/mongodb-core/lib/connection/connection.js:245:50)&#xA;    at Object.onceWrapper (events.js:315:30)&#xA;    at emitOne (events.js:116:13)&#xA;  name: 'MongoNetworkError',&#xA;  message: 'failed to connect to server [testmongodb:27017] on first connect [MongoNetworkError: getaddrinfo ENOTFOUND testmongodb testmongodb:27017]',&#xA;  errorLabels: [ 'TransientTransactionError' ],&#xA;  [Symbol(mongoErrorContextSymbol)]: {} }&#xA;</code></pre>&#xA;&#xA;<p>i get exactly the same error when deployed the service [gcloud app deploy]</p>&#xA;&#xA;<p>please help. </p>&#xA;"
43144337,The right way to define an API's base path in Api Connect,<spring-boot><ibm-cloud><microservices><apiconnect>,1,269,5,0.0,0,"<p><strong>Problem:</strong></p>&#xA;&#xA;<p>I have two micro services (in Spring Boot) published in <a href=""https://en.wikipedia.org/wiki/Bluemix"" rel=""nofollow noreferrer"">Bluemix</a>'s Api Connect. I want to assign a base path to each one so that we have a way to separate them. I.E.:</p>&#xA;&#xA;<p>Path to API 1: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api1/[endpoint-of-api1]</code>&#xA;Path to API 2: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api2/[endpoint-of-api2]</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>My solution:</strong></p>&#xA;&#xA;<p>Assign a context path to each Api in their <strong>application.yml</strong> file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: /api1&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Even though this works, it doesn't seem right to have a base path for the entire server, when the microservice shouldn't be aware of its external context (the reason for a base path is exclusively to have a separation in Api Connect)</p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
52105225,"In a microservice architecture, when use webservice as data provider vs direct db",<architecture><microservices><soa>,3,21,0,0.0,0,"<p>We are developing a system which is spread in about 7 microservices.</p>&#xA;&#xA;<p>One of them (a-service) it's a CRUD that allows a mobile client to get some data required to operate. Turns out that another microservice needs the same data to perform some checks before processing a request.</p>&#xA;&#xA;<p>We don't implement one-database-per-microservice, instead we have a sharded MongoDB for all applications (not my fault, my company set it).</p>&#xA;&#xA;<p>Should I in this b-service that also needs the data exposed by a-service consume that service or should I connect directly to the database and retrieve it?</p>&#xA;&#xA;<p>My current considerations:</p>&#xA;&#xA;<ul>&#xA;<li>Putting load on the micro-service and the db vs loading only the database.</li>&#xA;<li>Possible encapsulation of data if it's served by the micro-service for future changes.</li>&#xA;</ul>&#xA;&#xA;<p>Maybe someone can give me some 'best practices' in the matter? Thanks!</p>&#xA;"
51980596,How to Map specific fields of an object to another object?,<java><spring><spring-boot><microservices>,4,62,0,0.0,0,"<p>I have a situation where I have an object(obj1) which I have to map to another object(obj2) but in this Mapping some of obj2's fields are already having some values while other fields are null, so I have to pick only those fields which are null in obj2 and then send data from obj1 to those fields. I am not sure if ModelMapper will be useful in this case. </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
52041354,microservice: How to do validations from other microservice,<validation><microservices>,1,22,3,1.0,0,<p>If there are 2 micro services and if you want a validation to be performed against other micro service. What would be the best scenario to handle these cases?</p>&#xA;
51982133,Message-completion results from a consumer back to a producer,<redis><aws-lambda><microservices><message-queue><amazon-sqs>,1,36,4,0.0,0,"<p>We are building an application with a microservice architecture.  </p>&#xA;&#xA;<p>The microservice architecture will follow a message-oriented pattern, with AWS SQS.</p>&#xA;&#xA;<p>We would like to return completion results from the consumer service back to the producer service.</p>&#xA;&#xA;<p>This is the algorithm we are considering:</p>&#xA;&#xA;<ol>&#xA;<li>Producer creates a message with a unique id</li>&#xA;<li>Producer subscribes to a Redis channel that is named with the message id</li>&#xA;<li>Producer places the message onto the SQS queue</li>&#xA;<li>Consumer removes the message from the SQS queue and performs an operation</li>&#xA;<li>Consumer publishes the results of the operation to the Redis channel that is named with the message id</li>&#xA;<li>Producer recieves the completion results and resumes execution</li>&#xA;</ol>&#xA;&#xA;<p>Is this a reasonable way to pass message-completion results from a consumer back to a producer?</p>&#xA;"
46021905,"microservices, server-sent events, and browser limitations",<rest><microservices><server-sent-events>,1,110,3,0.0,0,"<p>In a micro-service oriented architecture, where each micro-service offers an SSE endpoint to stream events to the client, an HTTP connection is opened and kept alive between the client and the service. Unfortunately, this approach is almost unpractical when the client runs within a Web Browser because Web Browsers have a limitation on the number of HTTP connections that can be opened simultaneously on the same server (by domain name if I'm not wrong).</p>&#xA;&#xA;<p>It's a pity because SSE is a great technology for streaming events.</p>&#xA;&#xA;<p>What's the best approach for streaming events in a micro-service oriented architecture then, when the client runs in a browser?</p>&#xA;"
45964527,Microservice passing entity id guid or unique code,<rest><wcf><domain-driven-design><microservices>,1,169,3,0.0,0,"<p>We have two different microservices Customer service and Order service. Customer service store information about customer i.e. Name, DOB, etc. The Order service will mange the order that a customer has place i.e order number, cost etc. Which is the best way to passing customer unique reference/ ID to order services.</p>&#xA;&#xA;<p>Solution 1:&#xA;Customer ID is a GUID uniquely in Customer service. This will be passed to the Order service</p>&#xA;&#xA;<p>Solution 2:&#xA;Generate a business/human friendly unique code in Customer service and pass it to Order service</p>&#xA;&#xA;<p>Solution 3:&#xA;Something else?</p>&#xA;"
48473966,Authentication/Authorization mechanism for microservices,<authentication><authorization><microservices>,2,707,0,0.0,0,<p>I have project with many micro services each one doing its job. One of them responsible for authentication and authorization. But its not clear how other services should check users permissions. Is there any mechanism to deal with this task?</p>&#xA;
48457264,Integrating SignalR for microservice with API Gateway,<architecture><signalr><microservices><asp.net-core-signalr>,1,630,2,0.0,0,"<p>I'm designing a microservice system based on .Net core. The architecture system will look like as the following picture.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eIee4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eIee4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The problem is: There is a requirement which have to integrate SignalR (real-time) for notification&#xA;I've read about SignalR on Microsoft's website. But I consider that where should I put the Hub (API Gateway?, microservice? ...)? How can I apply signalR for this system.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48604664,How to share database connection between in spring cloud,<spring><microservices>,3,389,3,0.0,0,<p>How can I share database connection aong in spring cloud module microservices. If there are many microservices how can i use same db connection or should i use db connection per microservices?</p>&#xA;
48493849,Should API and message consumer be in the same microservice?,<apache-kafka><microservices><distributed-system>,1,96,4,1.0,0,"<p>My team is torn with how we should architect our microservices with using a message bus.</p>&#xA;&#xA;<p>We currently have an API Gateway with many microservices behind it all communicating over http.</p>&#xA;&#xA;<p>After looking into implementing Message Buses (Kafka) the team is torn on whether the consumer and API should live in the same service or if they should be two separate services.</p>&#xA;&#xA;<p>Some think they should be separate as they have different scaling concerns, while others think they should be in the same service since they are communicating with the same database and have the same domain concerns. IE) Not duplicating code between two services.</p>&#xA;&#xA;<p>What are your thoughts?</p>&#xA;"
48667874,Authentication in microservices,<.net><authentication><asp.net-core><jwt><microservices>,3,347,0,0.0,0,"<p>I am developing a microservice system for my company using ASP.NET Core. But a have faced with the following problem: when authenticated user is requesting some service, how should it check if the token is an actual (not blacklisted). I mean the case when user takes a new token but his old token is not expired yet thus the last one is an actual and could be used for accessing the resource services. So I gonna make all ofthe microservices ask the authentication service whether the token is an actual at each request. Perhaps there are any elegant ways to do it?</p>&#xA;"
48699742,How to handle user authentication with microservices in AWS?,<node.js><amazon-web-services><authentication><microservices>,3,374,0,0.0,0,"<p>I'm reading a tutorial provided by AWS explaining how to break up a monolithic NodeJS application into a microservice architectured one.</p>&#xA;&#xA;<p><a href=""https://aws.amazon.com/getting-started/container-microservices-tutorial/"" rel=""nofollow noreferrer"">Here is a link to it.</a></p>&#xA;&#xA;<p>One important piece is missing from <a href=""https://github.com/awslabs/amazon-ecs-nodejs-microservices/tree/master/3-microservices"" rel=""nofollow noreferrer"">the simple application example they've provided</a> and that is <strong>user authentication</strong>.</p>&#xA;&#xA;<p>My question is, where does authentication fit into all this? &#xA;How do you allow users to authenticate to all these services separately? </p>&#xA;&#xA;<p>I am specifically looking for an answer that <strong>does not</strong> involve AWS Cogntio. I would like to have my own service perform user authentication/management.</p>&#xA;"
48699765,UI with microservices,<angular><web-services><web-applications><frontend><microservices>,2,1456,0,0.0,0,<p>I have fornt end Web application written in JSF with Richfaces. Its a kind of dashboard application. We are trying to move this in Angular 2 with Spring Boot rest api. &#xA;I want to write microservices where each functionality would be independent. There are total 10 functionality so i will write 10 different rest services and each one would have its own build process. But i am confused with fornt end part. Should i create separate artifacts or separate build for each UI as well ? Or should i bundle in each respective rest api? how should i take care of front end part in microservices?</p>&#xA;
48810786,is putting sqs-consumer to detect receiveMessage event in sqs scalable,<microservices><amazon-sqs>,1,78,3,0.0,0,"<p>I am using aws sqs as message queue. After <code>sqs.sendMessage</code> sends the data , I want to detect <code>sqs.receiveMessage</code> via either infinite loop or event triggering in scalable way. Then I came accross <a href=""https://www.npmjs.com/package/sqs-consumer"" rel=""nofollow noreferrer"">sqs-consumer</a> &#xA;to handle <code>sqs.receiveMessage</code> events, the moment it receives the messages. But I was wondering , is it the most suitable way to handle message passing between microservices or is there any other better way to handle this thing?</p>&#xA;"
48760583,How to refresh request token with microservice multiple instances,<java><microservices><access-token><spring-cloud>,1,177,3,0.0,0,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<p>When the request token expires and multiple requests happen from different service instances, that all request a new request token via the remote HTTP call, at the same time, the latter request token will make the former request token invalid. Because each request to get a new token will make the previous one invalid. The service to generate request token is a third party one, we can't change it.</p>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Our application architecture is microservice based, each service will have multiple instances, how can I reuse the request token between each service?(maybe store it in an external Redis is an option)</p></li>&#xA;<li><p>During the service starting up, how can we make sure only one refresh token request sent to the third party service?</p></li>&#xA;<li><p>Afterwards, when the request token expires, how can we renew it?</p></li>&#xA;</ol>&#xA;&#xA;<p><strong>Tech Stack:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Java 8</li>&#xA;<li>SpringCloud</li>&#xA;<li>Redis</li>&#xA;<li>Rancher</li>&#xA;<li>MySQL</li>&#xA;</ul>&#xA;"
51122354,Coupling in microservices architecture,<microservices><coupling>,1,33,3,0.0,0,"<p>When working on an application in microservices architecture I stumbled upon issues concerning coupling between services.</p>&#xA;&#xA;<p>This a typical application for ordering products. It seams reasonable to have a service that will operate as a product catalog. Our JavaScript client can ask this service for available products and show them in browser. When user clicks on a product we have to create an order. We would like to manage orders in another service. So an order is created - it means that user X ordered product Y. On the technical level we are simply persisting user id and product id in a database.</p>&#xA;&#xA;<p>To sum up we have:</p>&#xA;&#xA;<h3>Products service</h3>&#xA;&#xA;<p>Product class:<br/>&#xA;Product ID, Product Name </p>&#xA;&#xA;<h3>Orders service</h3>&#xA;&#xA;<p>Order class:<br/>&#xA;Order ID, Product ID,  User ID,   Order date  </p>&#xA;&#xA;<p>Now let's imagine following scenario - in JavaScript client we would like to list all products that user have ordered. Orders service provides a list of products ids for a given user. But user cares about product name, not the id. Unfortunately Orders service doesn't know anything about products names.</p>&#xA;&#xA;<p>We could tackle this in couple of ways:</p>&#xA;&#xA;<ul>&#xA;<li><p>Simply assume that the client is responsible for getting the information it needs. So after it calls Orders service and gets a list of products ids, it performs another call to Products service, passing products ids and getting corresponding products names in response. Then the client assembles both responses into something useful. This approach keeps our services clean, without leaking of domain knowledge from one service to another. But it requires more work on the client side.</p></li>&#xA;<li><p>Orders service when asked for ordered products makes a call on the backend to the Products service. It retrieves product names, assembles a response that contains orderDate and  productName and sends that to client. All that's left for client to do is to present the data. Downside of this approach is that Orders service now gains more knowledge about products than neccessary.</p></li>&#xA;<li><p>Duplicate information about product name in Orders service. When an order is created, we pass not only product id but also product name. That means that Order class will look like this:&#xA;Order class:<br/>&#xA;Order ID, Product ID, Product name, User ID, Order date<br/>&#xA;Now we can easly provide full information about order without additional call to Products service. Also this time Orders service has too much knowledge about products. What's beneficial tough is that Orders service can provide relevant data even if Products service is down.</p></li>&#xA;</ul>&#xA;&#xA;<p>Could any of these approaches be considered best practice? Or are there different solutions?</p>&#xA;"
51120978,Is REST a good fit for microservices?,<rest><microservices><synchronous>,2,48,3,0.0,0,"<p>I am exploring micorservices architecture through books, blogs etc. </p>&#xA;&#xA;<p>What I have seen is that mostly people implement microservices using REST. Isn't it contradictory?</p>&#xA;&#xA;<p>Microservices are supposed to decouple services to achieve scalability, but REST communication protocol is synchronous. </p>&#xA;&#xA;<p>So how can these two go together?</p>&#xA;"
50400384,"In the microservices architecture, why they say is bad to share REST Client libraries?",<java><spring><microservices>,3,60,3,0.0,0,"<p>We have 15 services build with Java Spring, they talk each other using REST .</p>&#xA;&#xA;<p>Each time we add a new service to the pool we create from scratch all the code, including rest client code that will talk to other Services and the POJO classes used to map the resource(s) being requested.</p>&#xA;&#xA;<p>We end up copy and pasting from the source code of other services into the new service.</p>&#xA;&#xA;<p>I think it would be better to put all these POJO's and rest client code into a library for all the services to consume it, it would save us a lot of work coding, but ""they"" we should not do that with microservices.</p>&#xA;&#xA;<p>So, why is that?&#xA;We end up copy and pasting the exactly same code over and over again, I don't see the difference.</p>&#xA;"
50427036,Certificate Discovery Service,<rest><ssl><ssl-certificate><microservices><keystore>,1,32,4,0.0,0,"<p><br/>&#xA;I'm designing a microservice architecture and I've already setted up the https protection by using SSL certificates generated with <a href=""https://letsencrypt.org/"" rel=""nofollow noreferrer"">Let's Encrypt and certbot</a>.</p>&#xA;&#xA;<p>The provided certificates are periodically regenerated and then I've to re-import the new certificates into the keystores of all my services.</p>&#xA;&#xA;<p>In order to avoid this, I'm trying to implement a set of <strong>REST APIs</strong> that may allow the services to <strong>programmatically and automatically retrieve the new certificates</strong> and import them into their own keystore or simply use it programmatically. </p>&#xA;&#xA;<p>As the title says: a sort of <em>""Certificate discovery service""</em> or, if you prefer, a <em>""Remote certificate repository""</em>.</p>&#xA;&#xA;<p>I know that there is the java.security.* package that allows me to deal with this kind of things, but I've two questions for all of you:</p>&#xA;&#xA;<ol>&#xA;<li>Do you think that, from a architectural point of view, this is the best approach to face my problem?</li>&#xA;<li>Which king of Serialization/Deserialization process do you recommend? Is already there any library/framework/tool that does something similar that I can exploit?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you.&#xA;Bye Bye</p>&#xA;"
50401105,How to implement TLS between microservices,<ssl><microservices><pki>,2,309,5,1.0,0,"<p>Can someone please comment on, vet, critique, or otherwise blast holes in the microservices security design I’m considering?</p>&#xA;&#xA;<p>Let’s say I have three microservices, each of which talks to the other two via REST endpoints. Each microservice contains a keystore. In this keystore is the containing microservice’s private/public keypair, signed by a trusted certificate authority. Also in this keystore is the other two microservices’ public key certificates, exported from the source microservice’s signed/trusted keypair.</p>&#xA;&#xA;<p>This implementation works, but something doesn’t quite smell right about it.</p>&#xA;&#xA;<p>Namely, every time I introduce a new microservice I must add a) each existing microservice’s public key certificate to its keystore, and b) the new microservice’s public key certificate to every other microservice (the assumption being the new microservice must communicate bi-directionally, and securely, with each existing microservice).</p>&#xA;&#xA;<p>Now, repeat the above pattern for a second keypair, this one used to sign/verify authentication tokens supplied in REST calls.</p>&#xA;&#xA;<p>I am wondering if, instead of the above, it is a) advisable and b) safe to share a single trusted public key certificate between all microservices? Something completely different?</p>&#xA;&#xA;<p>Please be polite. I am by no means an expert it this area.</p>&#xA;&#xA;<p><strong>EDIT:</strong>&#xA;It occurred to me, after reading replies/comments to my original post, that I omitted detail that might have made the problem more clear, and therefore the commenters better able to address it:</p>&#xA;&#xA;<ol>&#xA;<li><p>The microservices in question exist within a private intranet, and will only ever be accessible by clients (browsers or other microservices) within that intranet.</p></li>&#xA;<li><p>There is in fact a trusted CA—namely, the company that owns this intranet—and it is that CA that signs the microservices’ keypairs.</p></li>&#xA;</ol>&#xA;&#xA;<p>The resolution to this problem, it seems, is implied in @Andreas first comment, in which he wrote, ""As long as the CA that issued them is trusted, they will be trusted too.”</p>&#xA;&#xA;<p>As long as each new microservice is deployed with a) its own keypairs, signed by the CA (one for signing and the other for encryption), and b) the CA’s certificate, I can deploy new microservices with reasonable assurance they will communicate securely with all other microservices (reasonable because of other potential vulnerabilities I am not even aware of).</p>&#xA;&#xA;<p>Somehow I got it into my head that I would have to create a brand new certificate for each microservice’s keypair, and include these in the other microservices' keystores (repeat for every new microservice). Instead all I need is one certificate, that of the CA that signs the keypairs, in each microservice’s keystore.</p>&#xA;"
50350198,Run Git commands in microservice,<git><microservices><spring-cloud><jgit>,1,57,7,0.0,0,"<p>I'm implementing microservice (in Spring Cloud) which acts as facade for Git operations invoked by UI layer. I'm trying to use jgit, but the problem is that it requires filesystem. So I have to clone remote repository to local filesystem. Problem is that then microservice is not stateless, and also other problems arises:</p>&#xA;&#xA;<ul>&#xA;<li>cloning before every operation takes too much time so is not an option </li>&#xA;<li>having multiple instances of such microservice can lead to different repositories (push take some time) </li>&#xA;<li>commits on different nodes at the same time can lead to conflicts</li>&#xA;</ul>&#xA;&#xA;<p>I would like to treat Git repository in similar way to database, so all operations should be done without using filesystem, cloning etc. - just invoke command on remote and it's done.</p>&#xA;&#xA;<p>I would like to add that it's quite hard to search for solution, because ""Git microservice"" phrase is quite common but in other sense (storing sources in repository).</p>&#xA;&#xA;<p>Edit: I've just found&#xA;<a href=""https://stackoverflow.com/questions/9442788/are-there-any-restful-interfaces-to-git"">Are there any restful interfaces to git?</a>&#xA;but any other ideas would be nice</p>&#xA;"
40657733,Reload changes to a shared data base,<java><spring><spring-boot><datasource><microservices>,1,28,5,0.0,0,"<p>I'm using Spring boot, and I have 2 services which share the same data base. each service has its own data source to communicate with the DB.</p>&#xA;&#xA;<p>My problem is when I apply changes via first data source the changes are not being affected or not being reloaded to the second data source.</p>&#xA;&#xA;<p>My question is how can I reload those changes, so whenever i apply changes to one data source they will be reflected by the second\other data source? </p>&#xA;"
43979597,ELK logging in microservices architecture,<elasticsearch><indexing><microservices><elastic-stack>,1,225,3,0.0,0,"<p>I am implementing centralized logging for all of my microservices using ELK. My doubt is whether I will have to create separate index for each microservice or a single index for all the microservices logs. My research so far shows that single common index for all the microservices make sense for centralized logging to achieve searches across microservices. Also I learnt that too many indices are a bit of overhead in elasticsearch. So I would like to hear from someone experienced</p>&#xA;&#xA;<p>I have already this question in Software recommendations  <a href=""https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture"">https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture</a></p>&#xA;"
43892712,Merge Microservice Frontends Together,<microservices>,1,186,6,0.0,0,"<p>I want to merge serveral frontend parts of different microservices together to an whole website. My idea behind this was to have a <strong>frontend</strong>, <strong>backend</strong> and <strong>database</strong> part in each microservice.</p>&#xA;&#xA;<p>I already familiar with microservices but I never used them to create a website, especially the frontend part.&#xA;Are there any articles about that or something like tutorials or maybe someone at stackoverflow can explain me more in depth how or with which ""tool"" I could put the microservices together.</p>&#xA;"
43821553,What is the best way to run npm packages on demand as mircoservices without installing it locally?,<node.js><npm><microservices>,1,86,8,0.0,0,"<p>Let's say I have these npm packages published to npm:&#xA;<code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;each package has a single function:</p>&#xA;&#xA;<pre><code>function run(extraStr) {&#xA;  return 'package_name_and_version' + extraStr; // i.e. service1 v1.0 extraStr&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I want to write nodejs code that use the packages without installing it locally</p>&#xA;&#xA;<pre><code>var server = require(""my-server-sdk"");&#xA;  // get(package_name, version, function_in_package, arguments, callback)&#xA;  server.get('service1', '2.0', 'run', ['app1'], (err, result) =&gt; {&#xA;  console.log(result); // this should print service1 v2.0 app1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>where <code>my-server-sdk</code> is an sdk that interface with my server's api where it <strong>install the required packages and cache it for later use</strong>.&#xA;What is the best way to do that? what the security concerns and how to prevent any?</p>&#xA;&#xA;<p>this is a simple diagram for what I want&#xA;<a href=""https://i.stack.imgur.com/aTdeG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aTdeG.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>NOTE: <code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;are just examples to any packages in npm i.e. <code>lodash</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Caching example:</strong></p>&#xA;&#xA;<p>Let's say we have TTL equal <strong>60 minutes</strong>.</p>&#xA;&#xA;<p><strong>client1</strong> requested a function from <code>lodash</code> and another function from <code>underscore</code> at 01:00.&#xA;Now in the server <code>lodash</code> and <code>underscore</code> are installed with timestamp <strong>01:00</strong>.</p>&#xA;&#xA;<p><strong>client2</strong> requested a function from <code>underscore</code> at <strong>01:30</strong> which get used instantly because <code>underscore</code> is installed before but it timestamp got updated to <strong>1:30</strong>.</p>&#xA;&#xA;<p>At <strong>02:01</strong> <code>lodash</code> get deleted because it didn't get used on the past TTL <code>currenttime - lodash_timestamp &gt; TTL</code> but <code>underscore</code> stays because <code>currenttime - underscore_timestamp &lt; TTL</code></p>&#xA;&#xA;<p>So when <strong>client3</strong> request <code>lodash</code> at <strong>02:30</strong> it get <code>intsalled</code> again with <strong>02:30</strong> as a <code>timestamp</code>.</p>&#xA;"
43340819,How to load react component from an external service inside a React app via AJAX,<javascript><node.js><ajax><reactjs><microservices>,2,558,0,1.0,0,<p>What are the best practices associated with loading/inserting and running  React components from an external service in an existing React application via AJAX.</p>&#xA;&#xA;<p>I have a main React app and want to load various React components (from external services) via AJAX. How could this be done?</p>&#xA;&#xA;<p>Is this feasible at all? If not what is the way to go about it?</p>&#xA;&#xA;<p>Can this work with webpack?</p>&#xA;
43328943,Data-specific user permissions model / schema design,<permissions><domain-driven-design><database-schema><acl><microservices>,1,111,3,0.0,0,"<p>My app manages user data that is shared between users, with different permissions such as read-only, edit, superuser, rename, delete etc. </p>&#xA;&#xA;<p>I'm weighing up two approaches to modelling the user permissions, the first is the simpler approach, the second involves more work but is more extensible, refactorable, <em>I think</em>. </p>&#xA;&#xA;<p>(1) quick solution, hard-coding against <code>user permission</code> properties:</p>&#xA;&#xA;<pre><code>-- basic data&#xA;CREATE TABLE symbol (&#xA;    id INT,&#xA;    name VARCHAR(255)&#xA;);&#xA;&#xA;CREATE TABLE user (&#xA;    id CHAR(10) &#xA;);&#xA;&#xA;CREATE TABLE user_permission (&#xA;    symbol_id INT,&#xA;    user_id CHAR(10),&#xA;    readable BIT,&#xA;    writable BIT,&#xA;    owner BIT,&#xA;    rename BIT,&#xA;    deletion BIT&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>(2) complete solution, hard-coding against <code>entitlements</code>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/boRWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/boRWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The areas I'm considering are:</p>&#xA;&#xA;<ol>&#xA;<li>extensibility - need or not to change model &amp; schema</li>&#xA;<li>microservices - possibilities to spin off into a separate DB?</li>&#xA;<li>performance - filter algos, number of joins in queries</li>&#xA;<li>no-sql caching - no idea but denormalising user permissions sounds crazy</li>&#xA;<li>admin for users - need good UX</li>&#xA;<li>admin for DBAs/Support - don't want complaints and endless support requests</li>&#xA;<li>web services API simplicity / complexity using Spring Data REST - HAL</li>&#xA;</ol>&#xA;&#xA;<p>I'd like to go with the more complex solution since it is unlikely to require re-working in the future, but I'm a bit concerned about both performance and the admin tasks involved in the UI to allow users to manage it. </p>&#xA;&#xA;<p>A utopian solution would be a third-party Java-based webapp providing a user interface to allow admin.</p>&#xA;&#xA;<p>EDIT: interesting to see other people tackling the same problem: <a href=""https://stackoverflow.com/questions/41161769/authorisation-in-microservices-how-to-approach-domain-object-or-entity-level-a"">Authorisation in microservices - how to approach domain object or entity level access control using ACL?</a></p>&#xA;"
43306842,.NET Microservices authorization,<.net><authorization><microservices>,1,190,4,0.0,0,"<p>I am about to start a project that consists of several microservices and I was researching how can I implement authorization of each microservice.&#xA;My architecture is the following:&#xA;A web project that consists of an asp.net core site with angular 2. Each module (menu item and its submenus) will be communicating with a microservice (each microservice will have a database).&#xA;Each microservice will have its own permissions. e.g MS1 will have CRUD Products, MS2 will have CRUD Orders etc..&#xA;My questions are:</p>&#xA;&#xA;<ol>&#xA;<li>As I mentioned above each microservice will have its own database (e.g MS1 will hold the products database, MS1 the order database etc..). What about the permissions? Where these are better to be stored?</li>&#xA;<li>A microservice should not share code with other microservices but I was thinking that the code that does the actual auth checking ( IsAlllowed(PermissionType) ) would be repeated in each microservice. This will cause code redundancy.</li>&#xA;</ol>&#xA;"
42395345,Service fabric reliable collections data loss after service upgrade,<.net><azure><microservices><azure-service-fabric><service-fabric-stateful>,1,395,0,2.0,0,"<p>Why reliable collections is empty after micro-service upgrade and not invoking event OnDataLossAsync to restore state from external backup?</p>&#xA;&#xA;<p>We have large scale system based on stateful services</p>&#xA;&#xA;<pre><code>&lt;StatefulServiceType ServiceTypeName=""UserServiceType"" HasPersistedState=""true"" /&gt;&#xA;</code></pre>&#xA;&#xA;<p>HasPersistedState is set as true, and data replicated across replicas, in case of VM failure data still valid and recovering with OnDataLossAsync but after upgrade collections is empty.</p>&#xA;&#xA;<p>I have tried all upgrade options (remove, keep, auto ugrade) application, result the same - collections is empty.</p>&#xA;&#xA;<p>For now we decided to replicate data to blob storage and recover it after service update which is not perfect solution, data recovery takes a few minutes and it makes some service unavailable/inconsistent for that time.</p>&#xA;&#xA;<p>So we are looking for solution that allows to save data after upgrade.</p>&#xA;"
42462663,Microservice depends on other one to do anything,<dependencies><microservices><relationships>,1,316,3,0.0,0,"<p>At the moment I deal with micro-services and ran into a few questions (regarding relations between services), I have a hard time to find a good answer/best practices for. It would be really great if you could give me a hint or an advice how you would handle this.</p>&#xA;&#xA;<p>Because these question are not directed to a specific project, I try to make it as clear as possible with the following example:</p>&#xA;&#xA;<p>Let‘s assume you want to build some kind of Youtube channel observer, that logs different kinds of channel‘s (meta-)data (videos, hourly views/sub count, currently subscribed to), that are imported in a specific time interval.</p>&#xA;&#xA;<p>So there are two major features the app has to offer, which should form a microservice each:</p>&#xA;&#xA;<ul>&#xA;<li>Add/remove channels to be watched (=> manager service)</li>&#xA;<li>import information (=> import service)</li>&#xA;</ul>&#xA;&#xA;<p>Both services provide an API to communicate with each other.</p>&#xA;&#xA;<p>The manager service is connected to a database which contains the channels that need to be watched, with their basic information (name, contact, ...) and the channels these observed channels are currently subscribed to, whereas the import service has a database containing all the other more time-series oriented information (videos, hourly views/sub count).</p>&#xA;&#xA;<p>To add a channel only the channel url has to specified. All the other information (name, contact, ...) are added by the import service (but can also be modified by the user).</p>&#xA;&#xA;<p>All in all the import service is totally useless without the information of the manager service, but also the manager service can only show the user specified channel information (worst case: only channel url) if no import service is available. In total: they depend heavily on each other.</p>&#xA;&#xA;<p>So much for the general architecture. </p>&#xA;&#xA;<p>The problem I have here is, that the import service depends on the data in the manager service database to such a great degree and also modifies it:</p>&#xA;&#xA;<ol>&#xA;<li>Would it be a good idea to share the manager service database between these two services or should it only be accessible by the provided API?</li>&#xA;<li>No matter if database is shared or not: both services need model classes for the channel. Is it fine to share those? </li>&#xA;<li>Is this architecture even a good idea at all (if we assume that there are also other services that need the basic channel information)? </li>&#xA;</ol>&#xA;"
38647186,In a microservices based architecture how would i go about database access?,<database><hibernate><microservices>,1,714,0,0.0,0,<p>I am trying to push myself into developing a set of microservices for a personal project that will essentially:</p>&#xA;&#xA;<p>Use elastic search&#xA;Poll various data stores&#xA;place data and read data from a data store&#xA;Expose a rest api to users</p>&#xA;&#xA;<p>for the purposes of this example lets say I had a bookings MS and a Sales MS</p>&#xA;&#xA;<p>The first thing that occurred to me was how to handle data storage.</p>&#xA;&#xA;<ol>&#xA;<li>Should each MS have its own data store?</li>&#xA;<li>Should I introduce a Persistence MS which handles all data from all other micro services (seems odd to do this).</li>&#xA;<li>Should each MS share a database but handle its own transactions.</li>&#xA;</ol>&#xA;&#xA;<p>In the case where you have each service handling its own persistence will that not significantly bloat a micro service to the point where you have a lot of boilerplate code and a large overall footprint of libraries (as an example hibernate would be a required library across every project and it seems terrible to have every MS having to load the same set of libraries).</p>&#xA;&#xA;<p>So I suppose the overriding question is what is the accepted methodology for managing database connectivity across a micro service architecture.</p>&#xA;
38492639,Auditing Microservices,<java><web-services><microservices>,1,892,2,0.0,0,<p>I have list of microservices I am calling multiple services from same controller.&#xA;I want to track the change of the object state before and after service.</p>&#xA;&#xA;<p>How the design should be or there any standards to audit microservices?</p>&#xA;&#xA;<p>Thanks Vijay</p>&#xA;
44105840,How to embed images and attach files from spring boot resources folder,<rest><spring-boot><resources><microservices><amazon-ses>,1,932,0,0.0,0,"<p>Not able to embed images and attach files from spring boot resources folder</p>&#xA;&#xA;<p>I have created a Restful web service using Spring Boot (Jar file and not a War file). Some of the services will send emails and some of them will send emails with attachments (Will be created dynamically). Web part (Angular) resides in Apache server which is deployed in different server.</p>&#xA;&#xA;<p>I am using Freemarker template to compose email and using Amazon SES to send emails. </p>&#xA;&#xA;<p>from freemarker template</p>&#xA;&#xA;<pre><code>&lt;IMG src=""cid:gridEmailHeaderImage""&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Code to add image</strong></p>&#xA;&#xA;<pre><code>MimeBodyPart inlineImage = new MimeBodyPart();&#xA;DataSource fds = new FileDataSource(imagePath.getAbsolutePath());&#xA;inlineImage.setDataHandler(new DataHandler(fds));&#xA;inlineImage.setHeader(""Content-ID"", ""&lt;"" + contentId + ""&gt;"");&#xA;inlineImage.setFileName(fds.getName());&#xA;content.addBodyPart(inlineImage);&#xA;</code></pre>&#xA;&#xA;<p>I am able to embed and attach files if I provide absolute path. But if provide relative path it is not working. </p>&#xA;&#xA;<p><strong>My folder structure</strong></p>&#xA;&#xA;<pre><code>C:\workspace\service-1.0\src\main\resources\images\header.png&#xA;C:\workspace\service-1.0\src\main\resources\attachements\test-attachment-1.txt&#xA;</code></pre>&#xA;&#xA;<p>I tried the following with no sucess</p>&#xA;&#xA;<p><strong>Approach 1</strong></p>&#xA;&#xA;<pre><code>ServletContext context;&#xA;String path = context.getRealPath(""/resources/images"")+""/header.png"";&#xA;</code></pre>&#xA;&#xA;<p>It is looking for images in the following folder but the images is not available in that folder.</p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Users\username\AppData\Local\Temp\tomcat-docbase..\resources\images/header.png</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Approach 2</strong></p>&#xA;&#xA;<pre><code>basePath = this.getClass().getClassLoader().getResource(""/images/"").getPath();&#xA;</code></pre>&#xA;&#xA;<p>C:\workspace\service-1.0\src\main\resources\images\header.png</p>&#xA;&#xA;<p>/C:/workspace/service-1.0/build/libs/service-1.0.jar!/BOOT-INF/classes!/images/&#xA;(Works only from eclipse but not from command prompt java -jar build\lib\myapp.jar)</p>&#xA;&#xA;<p><strong>Approach 3</strong></p>&#xA;&#xA;<pre><code>ClassPathResource file = new ClassPathResource(""header.png"");&#xA;String mypath = file.getFile().getAbsolutePath();&#xA;</code></pre>&#xA;&#xA;<p>(This also didn't work)</p>&#xA;&#xA;<p>If I place the image in images folder under resource. I am able to view the image via the following URL.</p>&#xA;&#xA;<pre><code>http://localhost:7075/myservice/v1/images/header.png&#xA;</code></pre>&#xA;&#xA;<p>is it fine to load images from resource folder? Will spring boot jars get exploded at runtime. What is the correct way to load images from spring boot jar file.</p>&#xA;"
44021110,Resource-based vs. Entity-based structure,<data-structures><microservices>,1,66,3,0.0,0,"<p>When it comes to designing the architecture of a system and the underlying services (consider a SOA), the database models can be designed it some ways, right... The general one is <code>entity-based</code>, which speaks for itself - the business logic is built around the entities (f.e. <code>user</code>, <code>company</code>, <code>product</code>). But when <code>resource-based</code> comes in the picture, it gets confusing. And the problem continues when I get results with very abstract or ambiguous information in google.</p>&#xA;&#xA;<p>My focus here is on a CRM service (Customer Relations Management). But I deem it better for me to understand resource-based structure in general, in order to be able to design a service in such a way.</p>&#xA;&#xA;<p>Can someone provide a concise explanation of resource-based structure and maybe compare it with entity-based?</p>&#xA;"
44148076,Mail notification from denormalized view in CQRS,<email><microservices><cqrs>,1,69,3,0.0,0,"<p>I want to develop a mail notification service to send order approval to customer. The order data is in the denormalized view (query side) and it should be filled to the mail template. Then, we send the email in html string format via mail notification service. But, the order status should be changed to ""order approval email sent"". </p>&#xA;&#xA;<p>I also try to implement the CQRS, ES, and DDD concept in microservices architecture.&#xA;Is this procedure correct and still align with the concept?</p>&#xA;&#xA;<ol>&#xA;<li>Develop HTTP POST API in order command to send approval mail so the order status could be changed in command-side.</li>&#xA;<li>The command side generate the event ""order approval mail processed""</li>&#xA;<li>The event processor process the event. It should get the order data from query-side / denormalized view. </li>&#xA;<li>The event processor generates the approval mail from the data and fill the data to the template. </li>&#xA;<li>The event processor call HTTP POST to the mail notification service with mail body (html format) in the payload.</li>&#xA;<li>The event processor call HTTP PUT to the order service (command-side) to change the order status to ""order approval mail sent"".</li>&#xA;</ol>&#xA;&#xA;<p>But, if this procedure is applied, the user can't get the response ""mail sent"" in real-time. How to trigger the client / front-end side that the mail is successfully sent? So, the client side don't have a need to refresh or retry many calls to the API.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44084744,Microservice architecture Flaws,<architecture><microservices><restful-architecture>,1,189,3,1.0,0,"<p>We are facing performance related issues with microservice architecture.</p>&#xA;&#xA;<p>Let's say there is microservice for user and account management. which have api's like </p>&#xA;&#xA;<pre><code>GET /users/{id} &#xA;GET /users       (arrount 6 million users)&#xA;&#xA;GET /accounts/{accountId}&#xA;GET /accounts &#xA;and Other Operations on user and account&#xA;</code></pre>&#xA;&#xA;<p>We have other microservice which track's user activities and list all the activities done by the user in his last login.</p>&#xA;&#xA;<pre><code>GET /user/activity/{userId}  (on an average 1000 to 10000 records)&#xA;</code></pre>&#xA;&#xA;<p>We have protal for sales and marketing team to show individual user activities and  user info and account info based on search criteria,</p>&#xA;&#xA;<pre><code>let's say search criteria is like : get all user activies who are located in colombia&#xA;Algorithm : &#xA;&#xA;1)Get /users ? location = colombia&#xA;2)then for individual user Get /user/activity/{userId}&#xA;</code></pre>&#xA;&#xA;<p>it is like joining two tables from different databases.</p>&#xA;&#xA;<p>it is very slow and creating lot of performance issues.</p>&#xA;&#xA;<p>what i though of is replicating user table in other microservice by a job which makes sure it is up to date and using only one api like</p>&#xA;&#xA;<pre><code>GET /user/activities?location=colombia.&#xA;</code></pre>&#xA;&#xA;<p>but replicating a table(user) is breaking the micro-service architecture main fundamentals</p>&#xA;&#xA;<p>is there any other way to do it or support this type of filter criteria which join's tables from different micro-services.</p>&#xA;"
44198061,Decision path for Azure Service Fabric Programming Models,<azure><microservices><azure-service-fabric>,1,225,4,1.0,0,"<p><strong>Background</strong></p>&#xA;&#xA;<p>We are looking at porting a 'monolithic' 3 tier Web app to a microservices architecture. The web app displays listings to a consumer (think Craiglist).</p>&#xA;&#xA;<p>The backend consists of a REST API that calls into a SQL DB and returns JSON for a SPA app to build a UI (there's also a mobile app). Data is written to the SQL DB via background services (ftp + worker roles). There's also some pages that allow writes by the user.</p>&#xA;&#xA;<p><strong>Information required:</strong></p>&#xA;&#xA;<p>I'm trying to figure out how (if at all), Azure Service Fabric would be a good fit for a microservices architecture in my scenario. I know the pros/cons of microservices vs monolith, but i'm trying to figure out the <em>application</em> of various microservice programming models to our current architecture.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is Azure Service Fabric a good fit for this? If not, other recommendations? Currently i'm leaning towards a bunch of OWIN-based .NET web sites, split up by area/service, each hosted on their own machine and tied together by an API gateway.</li>&#xA;<li>Which Service Fabric programming model would i go for? Stateless services with their own backing DB? I can't see how Stateful or Actor model would help here.</li>&#xA;<li>If i went with Stateful services/Actor, how would i go about updating data as part of a maintenance/ad-hoc admin request? Traditionally we would simply login to the DB and update the data, and the API would return the new data - but if it's persisted in-memory/across nodes in a cluster, how would we update it? Would i have to expose this all via methods on the service? Similarly, how would I import my existing SQL data into a stateful service? </li>&#xA;<li>For Stateful services/actor model, how can I 'see' the data visually, with an object Explorer/UI. Our data is our Gold, and I'm concerned of the lack of control/visibility of it in the reliable services models</li>&#xA;</ul>&#xA;&#xA;<p>Basically, is there some documentation on the <em>decision path</em> towards which programming model to go for? I could model a ""listing"" as an Actor, and have millions of those - sure, but i could also have a Stateful service that stores the listing locally, and i could also have a Stateless service that fetches it from the DB. How does one decide as to which is the best approach, for a given use case?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44050579,EntityFramework Core Loadbalanced,<c#><entity-framework><asp.net-core><microservices>,1,78,9,0.0,0,"<p>I know this is a pretty general question, but please bear with me:</p>&#xA;&#xA;<p>I just tripped over the entityframework cache aka ChangeTracker.</p>&#xA;&#xA;<p>What we have is a small microservice using net core with entity core.  This microservice is loadbalanced (RoundRobin) behind an IIS (so far nothing to incommon I would guess).  Lets call them Instance1 and Instance2.</p>&#xA;&#xA;<p>Now what happens:</p>&#xA;&#xA;<p>I have one entry in the db, for example (Represented as JSON here for simplicity):</p>&#xA;&#xA;<p><code>&#xA;{ Name: ""Test"", FirstName: ""T."" }&#xA;</code></p>&#xA;&#xA;<p>Now I load this into a form (answer from Instance1) and modify the FirstName to Thomas and save it via a PUT, which is done by Instance2.  Now I do another request to get that entry.  This request is answered by Instance1, which will load this from cache (since the changetracker says it is unchanged).  And thus I get</p>&#xA;&#xA;<p><code>&#xA;{Name: ""Test"", FirstName: ""T.""}&#xA;</code></p>&#xA;&#xA;<p>There seems to be many people having problems with the change tracker and one common answer is to rebuild the dbcontext with every request, which to me seems utterly wrong, because this is a very ""expensive"" operation.</p>&#xA;&#xA;<p>Also I noticed that the inserting of new data gets slower and slower over time, because the change tracker is filling up, so I would have to recycle the microservice every once and a while.</p>&#xA;&#xA;<p>So my question is:&#xA;How can I get around this Problem without reinitialising the dbcontext with every request?&#xA;I also found some answers that allow to disable the caching, but only for a single db operation, which means I would have to add this option to every DB operation, which to me feels almost as wrong as reinitialising the db context with every request.&#xA;What did I overlook, there has to be a simple solution!</p>&#xA;"
45789168,What is the difference between an API and Microservice?,<api><microservices>,2,1331,0,1.0,0,"<p>I create my API rest with Django, but I don't understand how convert an API to micro services, I don't understand the real difference between these.&#xA;I see an API like a micro service, but I don't know convert an entire API in micro service, I need create micro web servers? </p>&#xA;&#xA;<p>Please, I can't understand a micro services, and I need understand this.</p>&#xA;"
45729153,Spring Sleuth Logback Integration logs not displaying the service name,<logstash><logback><microservices><spring-cloud-sleuth>,1,741,1,1.0,0,"<p>In my microservice i have added spring -sleuth 1.2.1 and i have received the logs as i expected, which is shown in below</p>&#xA;&#xA;<p>2017-08-16 09:58:51.864  INFO [microServiceName,9434118b965d573e,9434118b965d573e,true] 1328 --- [io-8081-exec-10] com.cibc.icap.MyController       : Eligible for Vote</p>&#xA;&#xA;<p>As per my requirement I need to pass the logs from my application to logstash server so i have created logback.xml and added dependency logstash-logback-encoder-4.5.1 and added the appender in logback.xml net.logstash.logback.appender.LogstashTcpSocketAppender my logback.xml looks like&#xA;now the logs are passing from my application to logstash but the problem is in the log I am not getting my microservice name as expected, The log looks like below after adding the logback.xml </p>&#xA;&#xA;<p>2017-08-17 12:35:27.781  INFO [bootstrap,0e26cf339a6e69bc,0e26cf339a6e69bc,true] 4884 --- [nio-8081-exec-7] com.cibc.icap.AssessmentController</p>&#xA;&#xA;<p>link for my logback.xml </p>&#xA;"
45762128,Microservice architectural clarification,<c#><microservices>,1,75,3,0.0,0,"<p>I have a microservice architectured application. Where i have a CompanyService, an OrderService and a TransactionSevice. A user logs in and he can load all orders for his company. So the order has a CompanyId. Then it loads all Transactions for that order, so the transaction has an OrderId. I am going through some security thoughts. How can i make sure that the user only loads or saves transactions for the orders that belong to his company. I mean the TransactionService should not need to know about the Company (CompanyId). Is it something i should check just before saving? Eg check that the orderid belongs to the company or is there some other pattern?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50790960,Seperation of Concerns - How to separate GET/PUT/PATCH/POST/DELETE/ETC into one Microservice that gets its models and DTOs externally,<c#><rest><.net-core><microservices><separation-of-concerns>,1,56,3,0.0,0,"<p>Lets say you have a typical C# .netcore webapi you are wanting to use in a microservices architecture environment. It uses entity framework connects to a SQL database, has models and DTOs.</p>&#xA;&#xA;<p>If you want to separate the 'restfulness', the actions of actually responding to the individual GET/PUT/PATCH/POST/DELETE/ETC methods, from the data models (and into microservices) what approach would you take? </p>&#xA;&#xA;<p>IE instead of having to create 100 microservices that each expose the same exact RESTful functionality within the APIs but each have their own specific data models and DTOs, id want to create 1 API that exposes restful GET/PUT/PATCH/POST/DELETE/ETC and separate it from static models, dtos and entitybuilder configurations.  So i'd have 100 microservices concerned with passing data to the 1 REST microservice to get whatever job I need to do done in a dynamic fashion.</p>&#xA;&#xA;<p>I am not super experienced with object oriented programming methods and I thought maybe it would be possible to have my CRUD microservice that my child microservice talks to (through an API gateway or some other method that I haven't worked out yet) pass a set of models, DTOs and entity framework entitybuilder parameters into the CRUD microservices Program.cs's Main method? </p>&#xA;&#xA;<p>I am on the right path here? </p>&#xA;&#xA;<p>Thank you in advance for any advise or helpful examples!!!</p>&#xA;"
50810342,Spring Java Microservice war size is too large,<java><spring><microservices>,1,59,3,0.0,0,"<p>Every time when we release on our production server, we need to copy 3-4 war(microservice war) file of size approx 150-200 MB. Even though we simply change a small thing in our code, but all maven dependency are combined to the war so the file size is very big.  </p>&#xA;&#xA;<p>Is there any way to reduce the size of war or how can we simply deploy our code not all the dependency with them?</p>&#xA;"
50814965,Getting connection timed out error in Java microservice,<spring><spring-boot><postman><microservices>,2,119,5,1.0,0,"<p>I have built a microservice using Java 8 and SpringBoot 2. From this microservice, I'm trying to consume another REST API service. However, I'm getting the following error on Chrome</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: The underlying HTTP client completed&#xA;  without emitting a response.</p>&#xA;  &#xA;  <p>2018-06-12 15:21:29.300 ERROR 17996 --- [ctor-http-nio-3]&#xA;  .a.w.r.e.DefaultErrorWebExceptionHandler : Failed to handle request&#xA;  [GET <a href=""http://localhost:8080/category/search]"" rel=""nofollow noreferrer"">http://localhost:8080/category/search]</a>&#xA;  io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection&#xA;  timed out: no further information: test.usdemo.xyz.com/92.54.41.24:443&#xA;                  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.8.0_171]&#xA;                  at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)&#xA;  ~[na:1.8.0_171]&#xA;                  at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:325)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)&#xA;  ~[netty-transport-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)&#xA;  ~[netty-common-4.1.24.Final.jar:4.1.24.Final]&#xA;                  at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_171] Caused by: java.net.ConnectException: Connection timed&#xA;  out: no further information&#xA;                  ... 10 common frames omitted</p>&#xA;</blockquote>&#xA;&#xA;<p>I'm able to consume the same service successfully using PostMan but not through my microservice.</p>&#xA;&#xA;<p>Please assist to advise on this.</p>&#xA;"
27470721,How can I avoid duplication of business logic when batch processing?,<java><batch-processing><spring-batch><microservices>,2,626,0,0.0,1,"<p>I have a web application dedicated to batch processing (batch service here on out, api driven) and I have the main web application that is dedicated to everything else. I've been struggling with making a decision on what the best way is to avoid duplication of business logic in the batch service. Both applications are clustered. The separation for batch processing has been okay for simple jobs, but I have more complex jobs where it would just cause chaos if the business logic were duplicated. Here's my use case for the purposes of this question.</p>&#xA;&#xA;<ol>&#xA;<li>Customer schedules a cron job for user updates.</li>&#xA;<li>Batch service is given a CSV file with 20,000 user records.</li>&#xA;<li>The batch service rips through the file performing validation on the records, basically a dry run.</li>&#xA;<li>The batch service will check the allowable change and error thresholds (percentages are counts)</li>&#xA;<li>If validation thresholds pass, the batch service will begin creating/updating users.</li>&#xA;<li>When users are created or updated, there are a number of modules/features that need to know about these events.</li>&#xA;<li>Job progress is tracked and customer can view progress, logs, and status of job.</li>&#xA;</ol>&#xA;&#xA;<p>Here are a few solutions I have been thinking about:</p>&#xA;&#xA;<ul>&#xA;<li>Jar up the business logic and share it across the two applications. This wouldn't necessarily be easy because the main application is a Grails application and it's got GORM littered throughout.</li>&#xA;<li>Have the batch service hit APIs on the main application for the create and updates and possibly the more complex validation scenarios. Worried about the toll this would take on tomcat, but calls would be going through the load balancer so they would be distributed.</li>&#xA;<li>Have the batch service hit APIs on the main application for validation, then queue create/update requests and let the main application retrieve them. Same as above, queue would help reduce http calls. Also would need a queue to report status back to batch service.</li>&#xA;<li>Duplicate some logic by having batch service do it's own validation and inserts/updates, but then fire a user created event or user updated event so modules/features in the main app can deal with the changes.</li>&#xA;<li>Embed the batch processing service into the main application</li>&#xA;</ul>&#xA;&#xA;<p>Other details:</p>&#xA;&#xA;<ul>&#xA;<li>The batch service and web application are both clustered</li>&#xA;<li>Both are running on AWS, so I have tools like SQS and SNS easily accessible</li>&#xA;<li>Java 1.7 applications</li>&#xA;<li>Tomcat containers</li>&#xA;<li>Main application is Grails</li>&#xA;<li>Batch service uses Spring Batch and Quartz at it's core</li>&#xA;</ul>&#xA;&#xA;<p>So my question is what are accepted ways to avoid duplication of business logic based on the details above? Can/Should the architecture be changed to better accommodate this?</p>&#xA;&#xA;<p>Another idea to consider is what would this look like and a ""microservices"" architecture. That word has been tossed around a number of times in the office and we have been considering the idea of breaking up the main web application into services. So for example, we may end up with a service for user management.</p>&#xA;"
30496218,How to avoid Undertow Connection RESET in apache benchmark test?,<nio><microservices><undertow><sysctl>,3,587,2,0.0,1,"<h2>Using apache benchmarking 100K request 20K concurrent users:</h2>&#xA;&#xA;<pre><code>   $ ab -n 100000 -c 20000 http://localhost:8080/mrs/ping&#xA;    Completed 10000 requests&#xA;    Completed 20000 requests&#xA;    Completed 30000 requests&#xA;    Completed 40000 requests&#xA;    Completed 50000 requests&#xA;    Completed 60000 requests&#xA;    Completed 70000 requests&#xA;    Completed 80000 requests&#xA;    Completed 90000 requests&#xA;    apr_socket_recv: Connection reset by peer (104)  &lt;&lt;&lt; HOW to overcome??&#xA;</code></pre>&#xA;&#xA;<h2>Below is the Undertow (version 1.2.6 + xnio-api 3.3.1) PingServer:</h2>&#xA;&#xA;<pre><code>public class UndertowPingServer {&#xA;&#xA;    private static Logger log = Logger.getLogger(UndertowPingServer.class);&#xA;&#xA;    public static void main(String[] args) throws ServletException {&#xA;&#xA;        PathHandler path = Handlers.path()&#xA;                .addPrefixPath(""/mrs/ping"", new HttpHandler() {&#xA;                    @Override&#xA;                    public void handleRequest(HttpServerExchange exchange) throws Exception {&#xA;                        exchange.getResponseHeaders().put(&#xA;                                Headers.CONTENT_TYPE, ""text/plain"");&#xA;                        exchange.getResponseSender().send(""Server Time:"" + new Date().toString() + ""\n\n"");&#xA;                    }&#xA;                });&#xA;Undertow.Builder builder = Undertow.builder()&#xA;   .setHandler(path)&#xA;   .addHttpListener(8080, ""0.0.0.0"")&#xA;   .setBufferSize(1024 * 16)&#xA;//this seems slightly faster in some configurations&#xA;  .setIoThreads(Runtime.getRuntime().availableProcessors() * 2) &#xA;                    .setSocketOption(Options.BACKLOG, 500000)&#xA;                    .setWorkerThreads(2000)&#xA;//don't send a keep-alive header for HTTP/1.1 requests, as it is not required&#xA;                    .setServerOption(UndertowOptions.ALWAYS_SET_KEEP_ALIVE, false); &#xA;            Undertow server = builder.build();&#xA;            server.start();&#xA;            log.info(""micro-service running!"");&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>All the needed linux kernel sockets and thread settings via sysctl are already done. That is why it can do the first 90K request with 20k users without issue.</p>&#xA;"
50555353,How to handle in Event Driven Microservices if the messaging queue is down?,<multithreading><reactive-programming><message-queue><microservices><event-driven-design>,1,51,0,2.0,1,"<p>Assume there are two services <strong>A</strong> and <strong>B</strong>, in a microservice environment.</p>&#xA;&#xA;<p>In between A and B sits a messaging queue <strong>M</strong> that is a broker.</p>&#xA;&#xA;<p><strong>A&lt;---->'M'&lt;----->B</strong></p>&#xA;&#xA;<p>The problem is what if the broker M is down?</p>&#xA;&#xA;<p>Possible Solution i can think of:&#xA;Ping from Service A at regular intervals to check on Messaging queue <strong>M</strong> as long as it is down. In the meantime, service <strong>A</strong> &#xA;stores the data in a local DB and dumps it into the queue once the broker M is up.</p>&#xA;&#xA;<p>Considering the above problem, if someone can suggest whether threads or reactive programming is best suited for this scenario and ways it could be handled via code, I would be grateful.</p>&#xA;"
50634072,Observer pattern in microservice,<java><design-patterns><microservices><observer-pattern>,1,118,6,0.0,1,"<p>Currently I am reading the book called: Head First Pattern Design, there is one design pattern called: Observer pattern, like this: <a href=""https://www.tutorialspoint.com/design_pattern/observer_pattern.htm"" rel=""nofollow noreferrer"">https://www.tutorialspoint.com/design_pattern/observer_pattern.htm</a></p>&#xA;&#xA;<p>While I was reading that design pattern, I was feeling that currently we often use queuing system to publish and subscribe tasks between each microservices. Got a feeling that the Observer pattern is not quite often be used currently.  <strong>Please correct me if I am not right, if could provide some example about using observer pattern in mircoservice will be excellent!</strong></p>&#xA;"
34586306,Is it possible to implement microservices with oData.net,<c#><.net><architecture><odata><microservices>,2,799,0,1.0,1,"<p>I've been reading about the <a href=""http://microservices.io/patterns/microservices.html"" rel=""nofollow"">Microservice Architecure</a> and with the limited valuable information available on internet, I believe, I have a fair understanding of it from the theory point of view. I understand that on a high level this architecture suggests to move away from <a href=""http://microservices.io/patterns/monolithic.html"" rel=""nofollow"">monoliths</a> and have small, independent services. However, all the examples that I see on the internet are suggesting to write loosely coupled windows services (daemons in case of non MS implementations) connected to an <a href=""https://en.wikipedia.org/wiki/Enterprise_service_bus"" rel=""nofollow"">ESB</a>. I understand that writing small, loosely coupled web services that adhere to <a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow"">SRP</a> also fits the bill of micro services.</p>&#xA;&#xA;<p>That said, oData.Net services, where all oData controllers (micro services?) are deployed as a monolith, is a clear violation of the Microservices Architecure pattern. Is it a correct statement to make that oData.net is not designed to work as micro services? If your answer is no then please explain with help of a an example. Also, help me understand, how to have the API gateway pattern in the mix.</p>&#xA;"
34637868,Mobile App with microservices (on Microsoft Azure service fabric),<microservices><azure-service-fabric><azure-api-apps><azure-api-management><azure-mobile-services>,1,720,0,1.0,1,"<p>I am planning to build an enterprise grade mobile application that requires full offline capability. It would be used worldwide. For the backend application, I intend to realise it as microservices using Azure Service fabric. The backend application would be leveraged by both a web admin UI as well as by the above mobile app. For the mobile app, I intend to use Azure App service's the new mobile app service. This would provide me the capability to do offline data sync and also carry out the functions when network reachability is there.</p>&#xA;&#xA;<p>MobileApp --> Azure MobileApp service --> Azure API app service --> Azure Service Fabric (cluster of nodes hosting microservices). </p>&#xA;&#xA;<p>Following are some questions &amp; observations on which I require advice:</p>&#xA;&#xA;<ol>&#xA;<li><p>The reason I am putting in Azure API service in the middle is because I intend to do API management (I understand Azure has a separate API management offering - any pointers on how I can do true API management in the above architecture would be very helpful. Would API management replace API app service ? )</p></li>&#xA;<li><p>I intend to use Swagger generated code out of API app service, so that both the web admin UI layer and the Azure Mobile App service layer can leverage. Your thoughts ?</p></li>&#xA;<li><p>Here I am using 2 paradigms - App Service (for mobile &amp; API) and App Service fabric. I believe this is the only option given the fact that I have a mobile app requiring heavy duty offline feature.</p></li>&#xA;<li><p>Data Sync from mobile: How do you think I can sync data between Mobile App service and the microservice specific data stores ? Do I need to go via the APIs or I can easily do a data sync with the data stores of individual microservices. Your thoughts please ? </p></li>&#xA;</ol>&#xA;"
26611387,"DDD: Can anyone explain the diffrences between DTO, Aggregate Root and Detached Entity?",<java><jpa><domain-driven-design><microservices>,2,707,3,0.0,1,"<p>I'm a bit puzzled in figuring out the differences between these three. Presumed I have a Customer -> Address relation the (JPA) Detached Entity will have this as well (Eager Loading presumed). Where is the need to have an additional Aggregate Root? Where is the need to have a DTO? Is it all more or less the same?</p>&#xA;&#xA;<p>One of the reasons might be that the JPA compliant Entity has some info the client is simply not interested in, e.g. <code>@Entity</code>, <code>@Id</code>, <code>@OneToMany</code>.</p>&#xA;&#xA;<p>I can convert it easily to JSON/XML using JAX-RS/-WS and almost every client can deal with it, so where is the need for having it? Is it all almost the same or do I miss something important?</p>&#xA;"
36948775,Managing data-store concurrency as microservices scale,<concurrency><scalability><microservices><data-consistency>,1,979,2,0.0,1,"<p>I am still trying to find my way around micro-services. I have a fundamental question.</p>&#xA;&#xA;<p>In an enterprise scenario, micro-services would probably have to write to a persistent data-store - be it a RDBMS or some kind of NoSQL. In most cases the  persistent data-store is enterprise grade, but a single entity (ofcourse replicated and backed up).</p>&#xA;&#xA;<p>Now, let's consider the case of a single micro-service deployed to private/public cloud environment having it's own persistent data-store (say enterprise grade RDBMS). As I scale my micro-service, there will be multiple instances of the micro-service trying to read/write from the same data-store. A traditional data-store can probably be tuned to handle ~50-200 concurrent connections. How do I handle a situation when my microservices has to be scaled much beyond that?</p>&#xA;&#xA;<p>What are the best practices in such a scenario? Any patterns that can be used?</p>&#xA;"
36954140,How to create JAX-RS Sub Resources with WSO2 MSf4J,<java><wso2><jax-rs><microservices><msf4j>,1,195,4,0.0,1,"<p>I have create a sample micro service using WSO2 MSF4J. But i can't access the sub resources (services). Following are my service classes. </p>&#xA;&#xA;<p>Message Resource - </p>&#xA;&#xA;<pre><code>@Path(""/messages"")&#xA;@Consumes(MediaType.APPLICATION_JSON) &#xA;@Produces(MediaType.APPLICATION_JSON) &#xA;public class MessageResource {&#xA;&#xA;    @Path(""/{messageId}/comments"")&#xA;    public CommentResource getCommentResource(){&#xA;&#xA;        System.out.println(""inside the getCommentResource method"");&#xA;        return new CommentResource();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Comment Resource - </p>&#xA;&#xA;<pre><code>@Path(""/"") &#xA;public class CommentResource {&#xA;&#xA;    @GET&#xA;    @Path(""/{commentId}"")&#xA;    public String test2(@PathParam(""messageId"") long messageId, @PathParam(""commentId"") long commentId){&#xA;&#xA;        System.out.println(""method to return comment Id : "" + commentId + "" for message : "" + messageId);&#xA;        return ""method to return comment Id : "" + commentId + "" for message : "" + messageId;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have used following URI to access this service.</p>&#xA;&#xA;<p>GET : <a href=""http://localhost:8080/messages/1/comments/5"" rel=""nofollow"">http://localhost:8080/messages/1/comments/5</a></p>&#xA;&#xA;<p>But i got following result to my REST client.</p>&#xA;&#xA;<pre><code>404 Not Found&#xA;&#xA;Problem accessing: /messages/1/comments/5. Reason: Not Found&#xA;</code></pre>&#xA;&#xA;<p>Please help to resolve this. </p>&#xA;"
30209442,Cross-Microservice Authorization and Authentication,<authentication><authorization><microservices>,1,760,4,1.0,1,"<p>Suppose we have a number of (stateless, HTTP-based) (micro)services and a bunch of ""daemons"", which do all kinds of background processing by actually using said services.</p>&#xA;&#xA;<p>Now, I want to have a way for services and daemons to be able to mutually authenticate and authorize. For example, a daemon that performs full-text indexing of Orders needs:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Read-only</strong> access to the <em>Orders</em>, <em>Customers</em> (which itself needs read-only access to <em>Companies</em> service) and <em>Inventory</em> services </li>&#xA;<li><strong>Read and write</strong> access to the <em>OrdersSearch</em> service in order to be able to update the full-text index.</li>&#xA;</ul>&#xA;&#xA;<p>There are also applications, which operate ""on behalf"" of the user. For example, Inventory web app needs <strong>read and write</strong> access to the <em>Inventory</em> service, but the <em>Inventory</em> service itself needs to verify permissions of the user operating the application.</p>&#xA;&#xA;<p>All that said, how do I achieve what I just described? I'd prefer not to use gigantic enterprisey frameworks or standards. From what I've read, Two-Legged OAuth2 is what I need, but I'm not exactly sure.</p>&#xA;&#xA;<p>I was thinkinking of establishing an <em>Authorization</em> service which will be used to answer questions like ""Hey, I'm <em>Inventory</em> service. What permissions the <em>Customer</em> service that is calling me right now has for me?"", but that has two major weak with distributing shared secrets.</p>&#xA;"
35039565,Collate several micro-services into a single swagger 2.0 spec/collection,<swagger><swagger-ui><microservices><swagger-2.0><akka-http>,1,732,0,1.0,1,"<p>I am developing microservices using akka-http (scala). At the moment, I couldn't find any direct integration of swagger into akka-http. Nevertheless, I am starting my microservices with swagger 2.0 specs.  </p>&#xA;&#xA;<p>Now one of the challenge is to show a consolidated API spec to the consuming applications. I don't want to share multiple specs to the consumers and hence want to aggregate multiple swagger specs into one single spec (if this can be done on the fly, it would be great). Also how would this work with swagger-ui?</p>&#xA;"
44416904,Use KONG as API Gateway to GraphQL/REST services,<microservices><graphql><kong>,2,1594,0,0.0,1,<p>I'm trying to understand if it's possible to use KONG as API Gateway to microservices implementing REST and/or GraphQL interfaces</p>&#xA;&#xA;<p>As API Gateway will expose a GraphQL API and will request to our microservices currently implemented in REST/GraphQL and grpc coming soon.</p>&#xA;
48914388,Separating Node.js applications into multiple,<node.js><mongodb><web-applications><passport.js><microservices>,1,37,1,2.0,1,"<p>So me being stupid didn't think about that I build my whole application front to back on one Node.js application instance. Now I have to figure out how to make each thing its own service. My current application has the front end (main site), front end (application/software part) and the backend all together. I need to figure out how best to separate these into front/main, auth, front/app and backend/app</p>&#xA;&#xA;<p>How would I even go about doing this? I would post code examples but I am sure that is too long and would not let me thanks to a code to word ratio on here. The git repo is not public either so can't post that.  </p>&#xA;&#xA;<p>My stack is mongo, node.js and express, I am using passport.js to go with it also.</p>&#xA;"
48838101,How to perform validation across services in microservices,<domain-driven-design><microservices>,3,316,1,0.0,1,"<p>Suppose there are two microservices: Order and Intentory. There is an API in order service that takes ProductId, Qty etc and place the order.</p>&#xA;&#xA;<p>Ideally order should only be allowed to place if inventory exists in inventory service. People recommend to have Saga pattern or any other distributed transactions. That is fine and eventually consistency will be utilized.</p>&#xA;&#xA;<p>But what if somebody wants to abuse the system. He can push order with productid which are either invalid (or which are out of inventory). System will be taking all these orders and place these orders in queue and Inventory service will be handling these invalid order.</p>&#xA;&#xA;<p>Shouldn't this be handled upfront (in order service) rather than pushing these invalid orders to the next level (specially where productId is invalid)</p>&#xA;&#xA;<p>What are the recommendations to handle these scenarios?</p>&#xA;"
36812791,Doing compex reports with microservices,<report><microservices>,1,1655,0,0.0,1,"<p>I'm starting a new project and am interested in architecting it as microservices. I'm trying to wrap my head around it:</p>&#xA;&#xA;<p>Say that I have an order service and a product service. Now I want to make a report service that gives me all orders that contain a product from a certain product category. </p>&#xA;&#xA;<p>Since order's dont know about products that means that I would need to fetch all orders, loop them and fetch products for each order and then return those how match. </p>&#xA;&#xA;<p>Is this assumption correct or is there any more efficient way of doing this with microservices?</p>&#xA;"
36660279,Microservice grouping of modules,<soa><microservices>,1,116,4,1.0,1,"<p>I'm developing an Employee Management System and following a microservice-style architecture. Initially, I have created the ERD and designed several master maintenance tables like Department, Project, Position etc...</p>&#xA;&#xA;<p>My question is do I have to create a single service for each of these tables? or should I create a single service called master maintenance for all these tables?</p>&#xA;&#xA;<p>Please help me to decide. Thank you in advance.</p>&#xA;"
36716838,Microservice architecturs and layers,<architecture><microservices>,1,483,5,1.0,1,"<p>Let's discuss the architecture of a microservice environment. We are having a discussion internally at our company and I'd like some feedback. What I'm having serious thoughts about are an orchestration layer (code duplication, more moving parts changing an api).</p>&#xA;&#xA;<h2>Option one - with orchestration layer:</h2>&#xA;&#xA;<p>webapp -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> orchestration -> service -> persistance</p>&#xA;&#xA;<p>In this case services are not allowed to talk to each other. Aggregated services in orchestration layer</p>&#xA;&#xA;<h2>Option one - without orchestration layer:</h2>&#xA;&#xA;<p>webapp -> service -> persistance</p>&#xA;&#xA;<p>api -> api gw -> service -> persistance</p>&#xA;&#xA;<p>Here services are allowed to talk to each other, aggregated services exist here.</p>&#xA;&#xA;<h3>Specific questions:</h3>&#xA;&#xA;<ul>&#xA;<li>Where does billing belong?</li>&#xA;<li>Which solution do you prefer? Pros/cons.</li>&#xA;<li>Other suggestions?</li>&#xA;</ul>&#xA;"
36645517,REST api service context and resources url,<java><rest><jersey><jax-rs><microservices>,3,910,7,1.0,1,"<p>We have serveral services running on an application server and every service has a context. The name of the service is automatically added to the url, since there can be multiple services on the same application server.<br>&#xA;Now we are creating a new service, which is called Draws, meaning the url will be</p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws"" rel=""nofollow"">http://url:port/Draws</a></p>&#xA;</blockquote>&#xA;&#xA;<p>However, now the discussion is the api paths (Resources) to this service. Since we are getting draws, in my mind this should be draws.&#xA;Which means it will have the url   </p>&#xA;&#xA;<blockquote>&#xA;  <p><a href=""http://url:port/Draws/draws/"" rel=""nofollow"">http://url:port/Draws/draws/</a>{gameNo}</p>&#xA;</blockquote>&#xA;&#xA;<p>2x draws - <strong>Thoughts?</strong> </p>&#xA;&#xA;<p>There are thoughts here that the service does only have draws and therefor Draws/{gameNo} is enough.<br>&#xA;But in my mind, draws resource is the api interface of the service, like Draws is the book in a library, draws is the chapter... And it should be possible to add more chapters to the book.</p>&#xA;&#xA;<p>Then to implementation, we are using Jersey. That would mean we would have a resource with @Path(""{gameNo}"").</p>&#xA;&#xA;<p><strong>Edit 1:</strong><br>&#xA;There are gateways in front of our services, so the context will never be exposed to end users, it's only there to point to an specific service. Since multiple services can run on the same host:port</p>&#xA;&#xA;<p><strong>Edit 2:</strong><br>&#xA;Context part of the url is part of the service discovery lookup</p>&#xA;&#xA;<p><strong>Edit 3:</strong><br>&#xA;We are actually not versioning in url, but in Accept header, so actually my url is the same as clementinos but the version part of the url</p>&#xA;"
36744042,"REST, Pagination with filters dependent on external system and sql",<rest><design><architecture><pagination><microservices>,2,163,7,0.0,1,"<p>I have a REST web-service which is expected to expose a paginated GET call.</p>&#xA;&#xA;<p>For eg: I have a list of students( ""Name"" , ""Age"" , ""Class"" ) in my sql table. And I have to expose a paginated API to get all students given a class. So far so good. Just a typical REST api does the job and pagination can be achieved by the sql query.</p>&#xA;&#xA;<p>Now suppose we have the same requirement just that we need to send back students who are from particular state. This information is hosted by a web-service, S2. S2 has an API which given a list of student names and a state ""X"" returns the students that belong to state X. </p>&#xA;&#xA;<p>Here is where I'm finding it difficult to support pagination. </p>&#xA;&#xA;<p>eg: I get a request with page_size 10, a class C and a state X which results in 10 students from class C from my db. Now I make a call to S2 with these 10 students and state X, in return, the result may include 0 students, all 10 students, or any number students between 0 and 10 from state 'X'.</p>&#xA;&#xA;<p>How do I support pagination in this case?</p>&#xA;&#xA;<p>Brute force would be to make db calls and S2 calls till the page size is met and then only reply. I don't like this approach .</p>&#xA;&#xA;<p>Is there a common practice followed for this, a general rule of thumb, or is this architecture a bad service design?</p>&#xA;&#xA;<p>(EDIT): Also please tell about managing the offset value. &#xA;if we go with the some approach and get the result set , how can I manage the offset for next page request ?</p>&#xA;&#xA;<p>Thanks for reading :)</p>&#xA;"
41431506,Zuul routing : One endpoint with multiple microservices,<java><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1829,2,0.0,1,"<p>I would like to setup zuul and the underlying microservices in a way that all services will be under the '/gateway' context.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>Microservice 1 has : <a href=""http://localhost:8081/api/hello"" rel=""nofollow noreferrer"">http://localhost:8081/api/hello</a></p>&#xA;&#xA;<p>Microservice 2 has : <a href=""http://localhost:8082/api/bye"" rel=""nofollow noreferrer"">http://localhost:8082/api/bye</a></p>&#xA;&#xA;<p>I would want to be able to access the microservices via zuul as follows:</p>&#xA;&#xA;<p>Microservice 1 : <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice1/api/hello</p>&#xA;&#xA;<p>Microservice 2: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice2/api/bye</p>&#xA;&#xA;<p>I have tried to set this up, although it seems the requests are not getting routed correctly.</p>&#xA;&#xA;<p>The reason I would like the front end to route all client side REST calls to server that begin with '/gateway' is that it provides simpler maintenance to the front end.</p>&#xA;&#xA;<p>My application.yml:</p>&#xA;&#xA;<pre><code>zuul:&#xA; prefix: /gateway&#xA;   routes:&#xA;     microservice1:&#xA;        path: /microservice1/**&#xA;        serviceId: microservice1&#xA;        strip-prefix: true&#xA;     microservice2:&#xA;        path: /microservice2/**&#xA;        serviceId: microservice2&#xA;        strip-prefix: true&#xA;</code></pre>&#xA;&#xA;<p>Thank you </p>&#xA;"
40447582,API Gateway handling Webservices in a Microservice Architecture,<web-services><rest><architecture><microservices>,2,257,0,2.0,1,"<p>I have an architectural question. We are transforming an old Monolith to a Microservice Architecture. Therefore we have in plan to identify the bounded contexts and make Microservices out of these. </p>&#xA;&#xA;<p>To keep up with our public API we will have an API Gateway which routes the stuff properly. The internal communication will be done via REST (at the first shot). Unfortunatelly our existing public API is about WebServices most of the time.</p>&#xA;&#xA;<p>If we do transformation from Webservices to REST communication we already need to know stuff of the Domain Objects. Isn't that already a violation of the Microservice Design. In the end that means adding a field in the Microservice A implies also touching the API Gateway. Which I do not like.</p>&#xA;&#xA;<p>Am I wrong here? What is your opinion on this?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/9ZGGo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9ZGGo.png"" alt=""enter image description here""></a></p>&#xA;"
40413453,Aggregated Notification Microservice,<microservices>,1,728,1,0.0,1,"<p><strong>The Problem</strong></p>&#xA;&#xA;<p>We are currently architecting our new Notification Microservice but having trouble with how to handle aggregated emails. What we need to do is instead of sending one email every action performed (could be 20+ in a few minutes), we would send an email after an hour summarising all the actions that were completed.</p>&#xA;&#xA;<p><strong>What We Have So Far</strong></p>&#xA;&#xA;<p>We so far propose that we have this type of messaging pattern, where Client Service is any service in our cluster and Messagebot is our Notification Microservice.</p>&#xA;&#xA;<ol>&#xA;<li>Client Service sends a notification to Messagebot that it will need to send something in the future</li>&#xA;<li>Messagebot stores the details in its database</li>&#xA;<li>Messagebot periodically checks its database for what needs to be sent</li>&#xA;<li>Messagebot gets the required data from another service (could be Client Service) via API</li>&#xA;<li>Messagebot sends email using the data from #3 and an HTML template</li>&#xA;</ol>&#xA;&#xA;<p><strong>The Debate</strong></p>&#xA;&#xA;<p>For the data that needs to be sent, we are less sure and it is what we need help with. So far we think this should be the structure of the JSON from Client Service to Notification Service (step #1):</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    objectid: SOME_OBJECT_ID&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>or</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    required_objects: { task_id: SOME_TASK_ID, document_id: SOME_DOCUMENT_ID }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Where task_id and document_id are just examples and it would change based on the template. It could just as easily be <code>{product_id: SOME_PRODUCT_ID}</code> for a different template.</p>&#xA;&#xA;<p><strong>Why The Debate</strong></p>&#xA;&#xA;<p>Our thoughts so far are that:</p>&#xA;&#xA;<ol>&#xA;<li>We only need template_id because the source of the data would be implied in the objects (like an ENV var). For example, the Task object would be at <a href=""http://taskservice/:id"" rel=""nofollow noreferrer"">http://taskservice/:id</a>. Otherwise, we can have problems with failing APIs or switching URLs in the future.</li>&#xA;<li>We should use userid instead of email and name because we prevent the issue of email/ name pairs not matching up over multiple messages</li>&#xA;<li>For the objects, we're still sceptical because it means that the client app service would need knowledge of the inner workings in Messagebot but a single objectid might not be very extensible. We could easily imagine many of our messages needing more than one object.</li>&#xA;</ol>&#xA;&#xA;<p><strong>In Conclusion</strong></p>&#xA;&#xA;<p>Thank you for reading. The design of this service is important because it will be central to our entire organisation. </p>&#xA;&#xA;<p>Which debated JSON structure is most appropriate in our situation? Also, knowing our requirements, what would be the proper setup for this type of service? (aka. Are we correct in our other assumptions?)</p>&#xA;"
32838312,Architecture for microservices,<node.js><express><microservices>,2,2619,0,0.0,1,"<p>I've recently started to work with node.js and I have to build an architecture that should use multiple express.js services. Some of these services will have to be located on one server, anothers - on other server machines. I want to build a base service (like API Gateway), but I don't know what the proper way to communicate between this Gateway and microservices, or between two microservices.</p>&#xA;&#xA;<p>Currently I'm working with a solution based on this:</p>&#xA;&#xA;<pre><code># inside Gateway server I call another service:&#xA;http.get('http://127.0.0.1:5001/users', (service_res) -&gt;&#xA;  data = ''&#xA;  service_res.on 'data', (chunk) -&gt;&#xA;    data += chunk&#xA;&#xA;  service_res.on 'end', -&gt;&#xA;    # some logic on data&#xA;&#xA;).end() &#xA;</code></pre>&#xA;&#xA;<p>I have a strong feeling that this approach is not right. What the proper way to build communication logic between API Gateway and microservices?</p>&#xA;"
32831192,microservices and domain logic joins,<join><architecture><microservices>,3,160,0,1.0,1,"<p>Microservices are deployed hosting their own database.</p>&#xA;&#xA;<p>What strategies do you employ when business requirements necessitate joins across data in multiple services?</p>&#xA;&#xA;<p>Example problem:  You are implementing a movie review site.  You have a movie microservice that holds the movie DB.  You also have a review microservice that manages reviews in its own separate DB.  Reviews are linked to movies via a GUID; but as these are implemented as separate data stores, not a key constraint.</p>&#xA;&#xA;<p>You would like to have available, accurate to the last minute, a report that tells you the total number of reviews for each review level grouped by the first letter of the movie having a review word count > 25 words.  You currently host 5 million reviews for 40,000 movies.</p>&#xA;&#xA;<p>E.G.   Reviews with more than 25 words:</p>&#xA;&#xA;<ul>&#xA;<li>A  [8457 ""1 star""] [16615 ""2 star""] [...</li>&#xA;<li>B  [98445 ""1 star""] [80210 ""2 star""] [...</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Having chosen a microservice architecture for your project, what strategies would you now employ to implement this feature? </p>&#xA;"
39096701,DDD User-Domain specific settings,<domain-driven-design><microservices>,1,150,12,1.0,1,"<p>I am currently developing micro service responsible for authentication (bounded context responsible for identity and permissions). We have specific settings based on user roles which are tied to another domains, but used to generate tokens</p>&#xA;&#xA;<p>(something like this <a href=""https://developer.zendesk.com/rest_api/docs/core/custom_roles"" rel=""nofollow"">https://developer.zendesk.com/rest_api/docs/core/custom_roles</a>)</p>&#xA;&#xA;<p>For an example</p>&#xA;&#xA;<pre><code>role_can_write_booking: true,&#xA;fetch_products_type : ""all/forUsersCompanyOnly""&#xA;</code></pre>&#xA;&#xA;<p>etc.</p>&#xA;&#xA;<p>Should I persist this information as a part of Identity BC, or each domain should persist it's part of settings.&#xA;Example:&#xA;<code>role_can_write_booking : true</code> inside Booking Bounded Context,&#xA;<code>fetch_products_type : ""all/forUsersCompanyOnly""</code> inside Booking products bounded context. ?</p>&#xA;"
36129008,How to Send a Response Using Seneca and Express,<node.js><express><microservices>,2,1982,0,1.0,1,"<p>I'm using Seneca to route API calls and express to serve my files.&#xA;The problem is I can't seem to find a way to send a response back to the client after getting my data from the API.&#xA;With express, I would just use <code>res.send</code>, but since I'm in the Seneca context I can't. Haven't found any reference to this issue in the documentation.</p>&#xA;&#xA;<pre><code>""use strict""; &#xA;const bodyParser  = require('body-parser');&#xA;const express = require('express');&#xA;const jsonp = require('jsonp-express');&#xA;const Promise = require('bluebird');&#xA;const path = require('path');&#xA;const seneca = require('seneca')();&#xA;const app = express();&#xA;&#xA;module.exports = (function server( options ) {   &#xA;&#xA;    seneca.add('role:api,cmd:getData', getData);&#xA;&#xA;    seneca.act('role:web',{use:{&#xA;        prefix: '/api',&#xA;        pin: {role:'api',cmd:'*'},&#xA;        map:{&#xA;            getData: {GET:true}          // explicitly accepting GETs&#xA;        }&#xA;     }});&#xA;&#xA;     app.use( seneca.export('web') )&#xA;&#xA;     app.use(express.static(path.join(__dirname, '../../dist/js')))&#xA;     app.use(express.static(path.join(__dirname, '../../dist/public')))&#xA;&#xA;     app.listen(3002, function () {&#xA;         console.log('listening on port 3002');&#xA;     });&#xA;&#xA;    function getData(arg, done){&#xA;        //Getting data from somewhere....&#xA;&#xA;        //Here I would like to send back a response to the client.            &#xA;     }&#xA; }())    &#xA;</code></pre>&#xA;"
36049030,golang workspaces in practice,<go><workspace><microservices>,3,314,2,0.0,1,"<p>According to the Go documentation they would like you to have a workspace that one should put all their projects in.<sup>1</sup> However, as far as I can tell, this all falls apart as soon as you want to make a project that does not use Go exclusively. </p>&#xA;&#xA;<p>Take a project where it is made up of many micoservices for example. Lets say that it is structured like this:</p>&#xA;&#xA;<pre><code>app/&#xA;    authentication/ (Using rust)&#xA;    users/ (Using NodeJS)&#xA;    posts/ (Using Go)&#xA;</code></pre>&#xA;&#xA;<p>Only one part of the app would be written in Go, and that part is nested in a subdirectory of the app. How would I apply the Go workspace philosophy to this situation?</p>&#xA;&#xA;<hr>&#xA;&#xA;<ol>&#xA;<li><a href=""https://golang.org/doc/code.html#Workspaces"" rel=""nofollow"">https://golang.org/doc/code.html#Workspaces</a></li>&#xA;</ol>&#xA;"
33780962,Versioning services,<microservices><azure-service-fabric>,1,308,0,2.0,1,"<p>We are trying to do Microservices with MS' ServiceFabric.</p>&#xA;&#xA;<p>The scenario:&#xA;We have a Service1 running version1 and getting ready to upgrade to v2.</p>&#xA;&#xA;<p>Three other services depend on the interface of Service1. We want to be able to release v2 of Service1, but keep v1 running until we have upgraded and tested the three services against v2.</p>&#xA;&#xA;<p>All the examples I have found, v2 replaces v1 immediately. Can this be configured? And is there a method to tell the service discovery mechanism that I rely on a specific version of a given service?</p>&#xA;"
33805449,How to store shared-by-same-instances data in spring microservices architecture,<jpa><database-design><architecture><spring-cloud><microservices>,3,452,0,0.0,1,"<p>following situation: I am building a system that requires redundant microservices for failover or loadbalancing. So I am starting two (or more instances of a service) of for example a simple core rest service that provides data.</p>&#xA;&#xA;<p>My Question is: How would you store the data? Using two JPA-instances to access the same database (both writing and reading) will result in problems, especially in layer 2 caching and in consistency. Since the database must be redundent itself (requirement) it might be possible to make each service instance accessing its own database, but how would you synchronize them? Is there any common solution for this?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
31135664,Has anyone tested Akka-http-testkit?,<scala><akka><karma-jasmine><microservices><akka-testkit>,1,678,0,0.0,1,"<p>I'm working in a microservice architecture based in akka-http and akka clustering . I have seen in akka documentation this library <a href=""http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala/http/index-testkit.html"" rel=""nofollow"">akka-http-testkit</a>. Actually, it's in an experimental state , but haven't found any documentation . Seems it's on progress . </p>&#xA;&#xA;<p>Has anyone used this library ? Can anyone suggest me any way to test rest microservices ? . My first option is using <a href=""http://karma-runner.github.io/0.12/index.html"" rel=""nofollow"">Karma</a>, and do the testing via javascript, but it would be great to hear different opinion and options (as Akka-http-testkit ... maybe ... :))</p>&#xA;"
31088764,Design strategy for Microservices in .NET,<microservices>,3,591,3,0.0,1,<p>What would be a good way for Microservices .NET to communicate with each other? Would a peer to peer communication be better (for performance) using NETMQ (port of ZeroMQ) or would it be better via a Bus (NServiceBus or  RhinoBus)?&#xA;Also would you break up your data access layer into microservices too?</p>&#xA;&#xA;<p>-Indu</p>&#xA;
36265833,Microservices & Versioning,<cloud><versioning><microservices><semantic-versioning><continuous-delivery>,3,353,0,0.0,1,"<p>I'm building a cloud-native application using microservices. Eventually I have arrived at the point where I must implement proper versioning for my microservices. In most places where I've looked everyone is talking about semantic versioning these days (in general, not just for microservices).</p>&#xA;&#xA;<p>One of the principals of a microservices architecture is to <em>never deliver a breaking changeset</em>. On the other hand, semantic versioning says that one should increase the major version number when a non-backwards compatible (read ""breaking"") changeset is delivered. How are these compatible?</p>&#xA;&#xA;<p>It seems to me that semantic versioning <em>might be</em> overkill for a microservices architecture. If all public APIs are versioned (example /api/v3/getSomething) then do I really need full semantic versioning? I'm considering a scheme whereby I use a single number to identify the API version currently available (v1, v2, v3 etc.) together with a build number (or perhaps date/timestamp) that identifies the continuous integration pipeline that produced the build. Note that v3 would also still support v2 API calls until everyone using the service has moved to using v3, so v3 is the ""target version"" in a sense. So my microservice foo would look like ""foo-v3-20160503142209.jar""</p>&#xA;&#xA;<p>Are there any obvious pitfalls to this? The way I see it, clients will be guaranteed that the API is compatible if I enforce <em>never delivering breaking changeset</em> (if it changes, it is a new API version). And clients can be sure of all latest bug fixes by using the latest build number/timestamp.</p>&#xA;"
31295897,Should I use FrisbyJS for my REST API testing?,<microservices><frisby.js>,1,328,0,2.0,1,"<p>I am developing a complicated project with microservice architecture (only provides Rest API). So I need to make sure that the system works stably in development, staging, and production after having a deployment.</p>&#xA;&#xA;<p>I think that a testing framework as Frisby can help me prevent issues. Do you have any suggestion for my case?</p>&#xA;&#xA;<p>Thank you in advance.</p>&#xA;"
41672971,Append request header post spring security authentication,<spring><spring-security><microservices><netflix-zuul>,2,556,0,0.0,1,"<p>We would like to add header to our request post spring security authentication has happened. </p>&#xA;&#xA;<p>However, headers are not getting appended. &#xA;We were able to do it through a Zuul filter but not with spring security filter. </p>&#xA;&#xA;<pre><code>public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {&#xA;    httpServletRequestWrapper = new HttpServletRequestWrapper(request) {&#xA;        @Override&#xA;        public String getHeader(String name) {&#xA;            if (name.equalsIgnoreCase(ENV - HEADER)) {&#xA;&#xA;                return active;&#xA;            } else if (name.equalsIgnoreCase(USERID)) {&#xA;&#xA;                return (String) authentication.getPrincipal();&#xA;            } else {&#xA;                return super.getHeader(name);&#xA;            }&#xA;        }&#xA;    };&#xA;&#xA;    filterChain.doFilter(httpServletRequestWrapper, servletResponse);&#xA;}&#xA;</code></pre>&#xA;"
41548676,Running Lagom in Production,<java><akka><actor><microservices><lagom>,1,1214,0,1.0,1,"<p>I am working on setting up a Lagom application in production. I have tried contacting Lightbend for ConductR license but haven't heard back in ages. So, now I am looking for an alternative approach. I have multiple questions.</p>&#xA;&#xA;<p>Since the scale of the application is pretty small right now, I think using a static service locator works for me right now (open to other alternatives). Also, I am using MySQL as my event store instead of the default configuration of Cassandra (Reasons not relevant to this thread).</p>&#xA;&#xA;<p>To suppress Cassandra and Lagom's Service Locator, I have added the following lines to my build.sbt:</p>&#xA;&#xA;<pre><code>lagomCassandraEnabled in ThisBuild := false&#xA;</code></pre>&#xA;&#xA;<p>I have also added the following piece to my application.conf with service1-impl module.</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For the dev environment, I have been able to successfully run my application using <code>sbt runAll</code> in a tmux session. With this configuration, there is no service locator running on the default 8000 port but I can individually hit service1 on 8080 port. (Not sure if this is the expected behaviour. Comments?)</p>&#xA;&#xA;<p>I ran <code>sbt dist</code> to create a zip file and then unzipped it and ran the executable in there. Interestingly, the zip was created within the service1-impl folder. So, if I have multiple modules (services?), will sbt dist create individual zip files for each of the service?</p>&#xA;&#xA;<p>When I run the executable created via <code>sbt dist</code>, it tries to connect to Cassandra and also launches a service locator and ignores the static service locator configuration that I added. Basically, looks like it ignores the lines I added to build.sbt. Anyone who can explain this?</p>&#xA;&#xA;<p>Lastly, if I were to have 2 services, service1 and service2, and 2 nodes in the cluster with node 1 running service1 and node 2 running both the services, how would my static service locator look like in the application.conf and since each of the service would have its own application.conf, would I have to copy the same configuration w.r.t. static service locator in all the application.confs?</p>&#xA;&#xA;<p>Would it be something like this?</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;    service1 = ""http://1.2.3.4:8080""&#xA;    service2 = ""http://1.2.3.4:8081""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Since each specific actor would be spawned on one of the nodes, how would it work with this service locator configuration?</p>&#xA;&#xA;<p>Also, I don't want to run this in a tmux session in production. What would be the best way to finally run this code in production?</p>&#xA;"
41624628,How do you develop a microservice in isolation when it depends on other microservices?,<microservices>,2,196,1,2.0,1,"<p>We are evaluating a move to microservices.  Each microservice would be its own project developed in isolation.  During planning, we have determined that some of the microservices will communicate with other via REST calls, pub/sub, messaging (ie. a order service needs product information from product service).</p>&#xA;&#xA;<p>If a microservice depends on retrieving data from another microservice, how can it be run in isolation during development?  For example, what happens when your order service requests product details, but there is nothing to answer that request?</p>&#xA;"
41516276,How should one go about making a microservice out of a reactjs module?,<reactjs><microservices>,1,451,3,1.0,1,"<p>One possible way would be to run a separate node server making just the required API calls for said module, process and emit HTML as string. This could probably be imported in the main reactjs app via an API call. Or may be use a framework like Seneca that could use the node service output similarly. Can't figure out a way to import the node service output in the main reactjs app as a component along with props. That would allow me to add some pure front-end functionality and make a higher order component out of it.</p>&#xA;"
48043523,PACT provider verification against public APIs,<microservices><pact><pact-jvm>,1,114,3,0.0,1,"<p>am trying to do test for consumer driver contract testing using pact jvm and able to generate consumer side contract file.During provider side verification, how to provide public API's instead of localhost most of the examples uses only localhost as provider, any help pls</p>&#xA;&#xA;<pre><code>@RunWith(PactRunner.class) // Say JUnit to run tests with custom Runner&#xA;@Provider(""WeatherProvider"") // Set up name of tested provider&#xA;@PactFolder(""D:\Workspace\pactConsumer\pactConsumer_v2\pacts"") // Point where to find pacts (See also section Pacts source in documentation)&#xA;@VerificationReports(value = {""markdown"",""json""}, reportDir = ""D:\Workspace\pactConsumer\pactConsumer_v2\target"")&#xA;&#xA;public class ProviderVerifyer {&#xA;@State(""Weather information is available for Chennai"") // Method will be run before testing interactions that require ""with-data"" state&#xA;public void getWeather() {&#xA;System.out.println(""Weather information is available for Chennai"" );&#xA;}&#xA;@TestTarget // Annotation denotes Target that will be used for tests&#xA;public final Target target = new HttpTarget(8114); // Out-of-the-box implementation of Target (for more information take a look at Test Target section)&#xA;&#xA;}&#xA;</code></pre>&#xA;"
39721791,Can you reference other aggregates in a factory when implementing domain driven design?,<java><domain-driven-design><microservices>,3,46,0,0.0,1,"<p>I have two aggregates, <code>Employee</code> and <code>Company</code>.  An <code>Employee</code> stores a reference to the <code>Company</code> via it's <code>UUID</code>.</p>&#xA;&#xA;<p>If I want to create an employee, I need to provide it with the company ID:</p>&#xA;&#xA;<pre><code>new Employee(name, companyId)&#xA;</code></pre>&#xA;&#xA;<p>What I can't get my head around is how to get the <code>id</code> of the <code>Company</code> if the client provides only the company name.  In other words, I see this happening:</p>&#xA;&#xA;<pre><code>Employee buildEmployee(String name, String companyName) {&#xA;    Company company = companyRepository.findByName()&#xA;    return new Employeee(name, company.getGUID())&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Something feels wrong to me, as now I've introduced a dependency on the <code>Company</code> aggregate in order to create an <code>Employee</code>.  Even worse would be that if these were two were separate microservices, as I'd have to make a rest call to get the company name.</p>&#xA;&#xA;<p>Is there a way to avoid this coupling, or are my entities modelled incorrectly?</p>&#xA;"
39791667,Context mapping - relations,<domain-driven-design><microservices><bounded-contexts>,2,264,3,0.0,1,"<p>Is it considered a bad idea that 2 bounded contexts can have upstream communication between them?</p>&#xA;&#xA;<p>Example for, order BC will publish event, and inventory BC will subscribe for that event and in the same time, inventory BC can publish events and order BC will subscribe</p>&#xA;"
39690815,java.lang.IllegalArgumentException: Only the target location may be specified,<java><spring><spring-mvc><spring-boot><microservices>,2,330,4,0.0,1,<p>I'm writing my first spring boot application. on running the following command i'm getting the exception.</p>&#xA;&#xA;<pre><code>spring init --build maven --groupId com.redhat.examples\ --version 1.0 --java-version 1.8 --dependencies web\ --name hola-springboot hola-springboot&#xA;java.lang.IllegalArgumentException: Only the target location may be specified&#xA;    at org.springframework.util.Assert.isTrue(Assert.java:68)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.createProjectGenerationRequest(InitCommand.java:218)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.generateProject(InitCommand.java:209)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.run(InitCommand.java:189)&#xA;    at org.springframework.boot.cli.command.options.OptionHandler.run(OptionHandler.java:84)&#xA;    at org.springframework.boot.cli.command.OptionParsingCommand.run(OptionParsingCommand.java:54)&#xA;    at org.springframework.boot.cli.command.CommandRunner.run(CommandRunner.java:219)&#xA;    at org.springframework.boot.cli.command.CommandRunner.runAndHandleErrors(CommandRunner.java:171)&#xA;    at org.springframework.boot.cli.SpringCli.main(SpringCli.java:63)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)&#xA;    at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58)&#xA;</code></pre>&#xA;
35684313,Run all microservices in a multi-project gradle build,<gradle><microservices>,1,616,1,0.0,1,"<p>I have a multi-project gradle build that's roughly set up like this:</p>&#xA;&#xA;<pre><code>RootProject&#xA;- ServiceA&#xA;- ServiceB&#xA;- ServiceC&#xA;- UI&#xA;</code></pre>&#xA;&#xA;<p>Each of these subprojects is using the Spark framework and runs an embedded web server.  It's basically a microservices setup, so they all need to be up and running for the system as a whole to work.</p>&#xA;&#xA;<p>They each have a task defined like this:</p>&#xA;&#xA;<pre><code>task runApp(type: JavaExec) {&#xA;    main = 'App'&#xA;    classpath = sourceSets.main.runtimeClasspath&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I know I can manually start each service either through my IDE or by opening a different terminal for each sub-project and running <code>gradlew ServiceA:runApp</code>, but what I'd like to do is create a <code>runSystem</code> task at the root level that will fire up everything to make it easy to run the whole system during development.</p>&#xA;&#xA;<p>How can I do this with Gradle?</p>&#xA;"
35531784,How to make available the identity of a user across multiple microservices?,<authentication><authorization><microservices>,1,566,1,0.0,1,"<p>So let's take the basic e-commerce microservices. </p>&#xA;&#xA;<ol>&#xA;<li>Identity and access . This microservice will take care of user accounts, roles<br>&#xA;and authentication. The authentication method will be the based on the usual<br>&#xA;token based flow (user enters username + pass and server returns a unique and<br>&#xA;random token via cookie).  This service can also be used to get the user profile.</li>&#xA;<li>Cart microservice. This microservice can be used to put products in a cart.<br>&#xA;Check what products a cart has. Etc ...  </li>&#xA;</ol>&#xA;&#xA;<p>Asuming that ""Identity and access"" microservice will be used for generating the random token as a result of a succesful authentication, and for linking this token to a user, how will this token be used to make the user's identity available to the cart microservice? For example, when a user will add a product to his cart, he will send along the authorization token and the cart microservice will have to identify the user based on that token.  </p>&#xA;&#xA;<p>Could a distributed database be an option? A database which has these tokens stored and links to user built, and to which all microservices have access?  </p>&#xA;&#xA;<p>Or should all microservices get the user's identity from a special identity and access API which will expose users based on the access token?</p>&#xA;"
35639882,JWT Authentication within a Micro Service architecture,<php><node.js><rest><authentication><microservices>,2,682,2,0.0,1,"<p><strong>Question</strong></p>&#xA;&#xA;<p>Question how is it possible to create an authentication service within a micro-service application and have other services check against that token (JWT) and retrieve a user?</p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p>My current thinking is based around the auth service inserting <code>{ token, user }</code> into Redis once a user is authenticated. All other service can check against the user's <code>Authorization: Bearer kdI8$dj$nD&amp;...</code> header token within Redis. </p>&#xA;&#xA;<ul>&#xA;<li>If <code>token</code> is present in Redis, user is authenticated.</li>&#xA;<li>If <code>token</code> is not present in Redis, user is not authenticated.</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/7fsl7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7fsl7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>User sends <code>{ username, password }</code> to auth service</li>&#xA;<li>Auth service authenticates credentials and retrieves <code>{ token, user }</code></li>&#xA;<li>Auth service inserts <code>{ token, user }</code> into Redis</li>&#xA;<li>User makes request to <code>Service-1</code> with <code>{ token }</code></li>&#xA;<li><code>Service-1</code> loooks for <code>{ token }</code> in Redis and retrieves <code>{ token, user }</code></li>&#xA;<li><code>Service-1</code> does its thing and sends back <code>{ data }</code></li>&#xA;</ol>&#xA;&#xA;<p>Are there any possible security, logic or architectural problems with this approach? </p>&#xA;"
51593335,best managing microservice dependencies,<microservices>,3,28,0,0.0,1,"<p>I need some advise on how to best manage microservices and their dependencies.</p>&#xA;&#xA;<p>Assuming I have a microservice ""pages"" that manages article pages with operations to create/delete/edit pages.</p>&#xA;&#xA;<p>Assume I have built on top a microservice ""books"" that manages a collection of pages, with operations to add/delete/edit pages that calls the downstream endpoints of pages service.</p>&#xA;&#xA;<p>If I want to build another microservice that needs to edit a certain page in a book, would it be best to call the edit pages endpoint of books or pages directly?</p>&#xA;"
37699062,API vs Event in Microservice approach,<soa><cqrs><microservices><event-sourcing><eda>,1,721,0,1.0,1,"<p>What about <a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""nofollow"">Smart endpoints and dumb pipes</a> in terms of different type of requests?</p>&#xA;&#xA;<p>After reading that I was thinking that it's enough to subscribe for some events and deal with that. But now I've realised that sometimes you should have opened API (maybe not for the end customers, but for the API Gateway etc). Is this ok? Or you should ""eventize"" (transform into event) any request which coming to Microservices cloud?</p>&#xA;&#xA;<p>So, for instance, you have Invoice and Order services.&#xA;It's clear that when order created you might use an event which might be consumed by Invoice service to create an invoice. It's clear that for receiving list of last user's orders you may use CQRS on Order service side or even just make new service LastOrders which will keep just projection of required data. But should this request transformed into event or LastOrders should provide API for that and listen for events to update it's own DB? </p>&#xA;"
37711051,Example open source microservices applications,<microservices>,3,729,1,1.0,1,"<p>I'm looking for open source applications that demonstrate the <a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow"">microservices</a> pattern. In particular, I'd like to find one or more applications that can be spun up on real cloud environment up (but with fake data and requests) to demonstrate real-world deployment mechanics.</p>&#xA;&#xA;<p>Unfortunately, I haven't found any good options yet. I'll note that <a href=""https://www.discourse.org/"" rel=""nofollow"">Discourse</a> is a modern 3-tier application, using Rails API, Ember.js, Postgres, and Redis, but it still is much closer to a monolith than an example of microservices. The closest I've found so far is <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">https://github.com/kbastani/spring-cloud-microservice-example</a> but that is more of a framework than an actual application that delivers data.</p>&#xA;"
49171571,Search queries in microservice architecture,<architecture><microservices>,2,137,1,2.0,1,"<p>Assuming I have a microservice architecture where I have a Book microservice holding all book details and a Author microservice holding all author details, e.g.</p>&#xA;&#xA;<pre><code>Book Service&#xA;GET /     get all books&#xA;GET /id   get book details, including author_ids&#xA;POST /    create new book&#xA;etc.&#xA;&#xA;Author Service&#xA;GET /     get all authors&#xA;GET /id   get author details, including book_ids&#xA;POST /    create new author&#xA;etc.&#xA;</code></pre>&#xA;&#xA;<p>The real services are much more enterprise grade, I just choose Books and Authors with their own data storage option as a easy understandable example. </p>&#xA;&#xA;<p>Assuming, there will be millions of calls to the services and I have to uphold specific availability and throughput of systems. How can I efficiently search for authors where name starts with 'A' and all books written by the authors where book title starts with 'B'?</p>&#xA;&#xA;<p>I see following options, which all are not perfect:</p>&#xA;&#xA;<ol>&#xA;<li><p>I create a search endpoint in Author service, fetch all authors matching the search criteria, follow each book_id and filter for the books. -> This requires a lot of calls on the Book service.</p></li>&#xA;<li><p>Same as 1. but I create a search endpoint in Book service, fetch all books matching the search criteria, follow each author_id and filter for the authors. -> This requires a lot of calls on the Author service. In worst case, same load as in 1.</p></li>&#xA;<li><p>I create a new microservice Search. Search will have its own database which is optimized for searches. Search will return me the books and authors and can give me the search result with one call. -> This requires Search to frequently sync with Book and Author service.</p></li>&#xA;<li><p>I merge Book and Author into one service which defeats the purpose of mircroservices?</p></li>&#xA;</ol>&#xA;&#xA;<p>Maybe someone with more microservice experience can help me out how to best architect this.</p>&#xA;"
46462610,monorepo VS. github submodules,<git><github><microservices>,1,1447,0,0.0,1,"<p>Our app is built in microservice architecture, one service one repo. We are exploring whether we should create a monorepo, as many companies are following this practice. There are plenty of discussions about the pros and cons for mono vs. many. If we want to find an alternative to allow us have some cons from both options, should we use git submodules to provide 'looks-alike' mono structure? </p>&#xA;"
46451544,C++ MicroServices with desktop application,<c++><microservices><desktop>,1,807,7,1.0,1,<p>I got a desktop application and it's getting bigger and bigger. And i wonder if i can make something like microservices with desktop application? I want to application for now stays desktop. Application it's written in C++.&#xA;I can exclude some of the modules with some preparations.&#xA;But is it possible and if anybody have idea how to start with this?</p>&#xA;
45047011,Microservice architecture for ETL,<web-services><architecture><etl><microservices><restful-architecture>,3,1201,2,2.0,1,"<p>I am redesigning a small monolith ETL software written in Python. I find a microservice architecture suitable as it will give us the flexibility to use different technologies if needed (Python is not the nicest language for enterprise software in my opinion). So if we had three microservices (call them Extract, Transform, Load), we could use Java for Transform microservice in the future.</p>&#xA;&#xA;<p>The problem is, it is not feasible here to pass the result of a service call in an API response (say HTTP). The output from Extract is going to be gigabytes of data.</p>&#xA;&#xA;<p>One idea is to call Extract and have it store the results in a database (which is really what that module is doing in the monolith, so easy to implement). In this case, the service will return only a yes/no response (was the process successful or not).</p>&#xA;&#xA;<p>I was wondering if there were a better way to approach this. What would be a better architecture? Is what I'm proposing reasonable?</p>&#xA;"
44927532,How to get newly created resource to client with CQRS and event sourcing based microservices,<microservices><cqrs><event-sourcing>,1,275,4,0.0,1,"<p>I'm experimenting with microservices, event sourcing and CQRS. However, I'm a little bit confused about how I go from issuing a command to performing a query to return the new state, specifically with regard to interactions with a web API gateway.</p>&#xA;&#xA;<p>As an example, the simple application I am attempting to write (which probably doesn't actually need any of these; it is just something to aid my learning) creates a random-graph and then performs some long-running calculations on the graph. I've modelled this as two separate services: the <code>GraphService</code> and the <code>ComputationService</code>. The imagined process flow is as follows:</p>&#xA;&#xA;<ol>&#xA;<li>User requests new random graph.</li>&#xA;<li>API gateway constructs <code>CreateGraph</code> command and sends it to the&#xA;<code>graph service</code>.</li>&#xA;<li><code>GraphService command handler</code> creates a graph and publishes a&#xA;<code>GraphCreated</code> event.</li>&#xA;<li><code>GraphService event handler</code> subscribes to topic for graph events,&#xA;processes <code>GraphCreated</code> event and stores graph in persistent read&#xA;storage.</li>&#xA;<li><strong>Client somehow gets the newly created graph.</strong></li>&#xA;<li><code>ComputationService event handler</code> subscribes to topic for graph&#xA;events, processes <code>GraphCreated</code> event and begins potentially&#xA;long-running computation, e.g. calculate diameter.</li>&#xA;<li><code>ComputationService</code> publishes <code>DiameterComputed</code> event.</li>&#xA;<li><code>GraphService</code> event handler subscribes to topic for computation&#xA;events, processed <code>DiameterComputed</code> event and updates the graph in&#xA;persistent read storage.</li>&#xA;<li>Client somehow gets updated - easier than getting the new graph, since already have an ID and can poll for changes / websockets / SSE, etc.</li>&#xA;</ol>&#xA;&#xA;<p>That seems relatively simple. However, my confusion lies in how to go about informing the API gateway, and thus the web client, of the new graph (as highlighted in bold above). In a typical CRUD process, the result of the <code>POST request</code> to create a new graph would be to return the URL of the new resource, for instance. However, with CQRS, commands should return nothing or an exception.</p>&#xA;&#xA;<p>How do I pass information back to the client of the service (in this case the API gateway) about the ID of the new graph so that it can perform a query to get the representation of the new resource and send it to the user? Or at least get an ID so that the web client can ask the API gateway, etc?</p>&#xA;&#xA;<p>As I see it at the moment, after sending a command, everyone is just left hanging. There needs to be some sort of subscription model that can be interrogated for the status of the graph creation. I considered having the API gateway generate a request ID which gets embedded with the <code>CreateGraph</code> command, but this then couples the service to the API.</p>&#xA;&#xA;<p>I'm obviously missing something, but have no idea what. None of the examples I've looked at or discussions I've read address this issue and assume that the ID of whatever resource is already known. I couldn't find any discussions here addressing this issue, but if I've just missed them, please point me there rather than duplicating questions. Any pointers would be hugely welcomed.</p>&#xA;"
34049118,Tracking Issues across multiple repositories,<github><jira><microservices>,1,493,6,1.0,1,"<p>We often have epic stories which span multiple repositories.  I am looking for a mechanism to track all the work that is associated with a single story.  GitHub has Issues which is a close to the solution I seek.  The problem with Issues is they do not span multiple repositories. On deployment day I still need to scan ~10 repositories (there are 100 repo's, 10 are commonly used) to discover which ones have commits related to the story.</p>&#xA;&#xA;<p>As a manual workaround I create multiple Issues.  One Issue for each repository.  Then I manually list the Issue#'s related to the epic story in Jira.</p>&#xA;&#xA;<p>Is there a tool or alternative technique I can use to automatically combine these issues and treat them as one?</p>&#xA;"
38099204,Session management using json web tokens in microservices,<json><session><token><jwt><microservices>,1,808,0,0.0,1,"<p>I am trying to figure out how I will manage sessions using json web tokens in a microservice architecture. </p>&#xA;&#xA;<p>Looking at the design in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""nofollow"">article</a> what I currently have in mind is that the client will send a request that first goes through a firewall. This request will contain an opaque/reference token which the firewall sends to an authorization server.  The authorization server responds with a value token containing all the session information for the user.  The firewall then passes the request along with the value token to the API, and the value token will then get propagated to all the different microservices required to fulfill the request. </p>&#xA;&#xA;<p>I have 2 questions:</p>&#xA;&#xA;<ol>&#xA;<li>How should updates to the session information in the value token be handled? To elaborate, when the session info in a token gets updated, it needs to be updated in the authorization server.  Should each service that changes the token talk to the authorization server? </li>&#xA;<li>Should all the microservices use this single token to store their session info? Or would it be better for each service to have a personalized token? If it's the latter, please explain how to adjust the design.</li>&#xA;</ol>&#xA;"
38164006,How To Delay Observable emission in RxJava,<rx-java><haproxy><microservices>,2,1410,0,0.0,1,"<p>We have Micro services architecture, where we make inter-service calls over a network.&#xA;We are using RxJava in top level service, which is resulting in creation of large no of parallel requests to bottom service.&#xA;Because of this i am getting ""No Route to Host error"" or ""connection error"".&#xA;For that purpose i want to slow down emission from RxJava Observable, so that earlier connection will get closed before creating new one.&#xA;Below is the sample code:</p>&#xA;&#xA;<pre><code>    package com.demo.rxjava.rxjaxa.creation;&#xA;    import rx.Observable;&#xA;    import rx.Subscriber;&#xA;    import rx.schedulers.Schedulers;&#xA;&#xA;    public class Delay {&#xA;&#xA;        public static void main(String[] args) throws InterruptedException {&#xA;            Observable.just(1, 2, 3, 4, 5).subscribeOn(Schedulers.io())&#xA;                    .flatMap(integer -&gt; {&#xA;                        return function1(integer);&#xA;                    }).observeOn(Schedulers.io())&#xA;                    .subscribe(new Subscriber&lt;String&gt;() {&#xA;                        @Override&#xA;                        public void onNext(String item) {&#xA;                            System.out.println(""Next: "" + item);&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onError(Throwable error) {&#xA;                            System.err.println(""Error: "" + error.getMessage());&#xA;                        }&#xA;&#xA;                        @Override&#xA;                        public void onCompleted() {&#xA;                            System.out.println(""Sequence complete."");&#xA;                        }&#xA;                    });&#xA;        }&#xA;&#xA;     public Observable&lt;String&gt; function1(String id) {&#xA;                // This is where we make network call&#xA;                Observable&lt;Response&gt; response = Rx.newClient(RxObservableInvoker.class)&#xA;                        .target(""http://example.com/resource"")&#xA;                        .request()&#xA;                        .queryParam(""id"", id)&#xA;                        .rx()&#xA;                        .get();&#xA;                response.obserOn(Schedulers.from(threadExecutor)).flatMap(response-&gt;{&#xA;                    return response.extractResponse();&#xA;                });&#xA;   }&#xA;}&#xA;</code></pre>&#xA;"
38172510,How to handle network calls in Microservices architecture,<networking><architecture><rx-java><haproxy><microservices>,1,889,3,0.0,1,"<p>We are using Micro services architecture where top services are used for exposing REST API's to end user and backend services does the work of querying database.</p>&#xA;&#xA;<p>When we get <strong>1 user request we make ~30k requests to backend service</strong>. We are using RxJava for top service so all 30K requests gets executed in parallel.&#xA;We are using haproxy to distribute the load between backend services.&#xA;However when we get 3-5 user requests we are getting network connection Exceptions, No Route to Host Exception, Socket connection Exception.</p>&#xA;&#xA;<p>What are the best practices for this kind of use case?</p>&#xA;"
33291874,"Microservices: Worker roles, APIs or both?",<microservices>,1,976,1,0.0,1,"<p>I have seen mixed examples of Microservices implemented as worker roles processing requests off a queue and/or as APIs (REST). </p>&#xA;&#xA;<p>Supporting asynchronous scenarios, a queue can be utilized, with a simple dumb queue listener forwarding the request to a Microservice REST API, where as synchronous scenarios would  call the REST API directly. </p>&#xA;&#xA;<p>The term Microservice is vaguely defined I think; do people consider them APIs (e.g. RESTful services) or as any abstract service processing requests, however that request was provided ?</p>&#xA;"
33335786,What is the best way for applications to communicate in micro-service architectures,<python><json><xml-rpc><microservices><amp>,1,273,6,0.0,1,"<p>I have to design and implement a service delivery platform.  I have various services in my current design and all of those tools are using different technologies.  Some are erlang based concurrent map-reduce functions and some are simple bash scripts to aggregate some text files. </p>&#xA;&#xA;<p>I heared about <strong>XML/RPC</strong>, <strong>Protocol Buffer</strong>, <strong>message-pack</strong>, <strong>soup</strong> and <strong>AMQP</strong>.  currently I use <strong>JSON</strong>, but loading and dumping large json files are a bit time/memory consuming.  Is there any new or robust way to make a bridge between various technologies on HTTP infrastructure with wide range programming language support and well documentation?</p>&#xA;&#xA;<p>EDIT1: I also need to mention that i believe complexity is much more corrosive than latency problems or other connection related issues.  So the JSON replacement must not add complexity to design.  </p>&#xA;&#xA;<p>Thanks in advanced.</p>&#xA;"
45321939,Host a service with 2 endpoints in the same or separate processes?,<web-services><iis><asp.net-web-api><nservicebus><microservices>,2,123,3,0.0,1,"<p>I'm building a microservice with both a synchronous REST endpoint (using WebAPI) and an asynchronous publish/subscribe endpoint (using NServiceBus on top of MSMQ) that will be processing data that is stored in a database shared by these endpoints.</p>&#xA;&#xA;<p>I'm trying to decide if I should host both endpoints in the same process, or if I should simply host them in separate processes and have them use the database as common ground to pass data between these processes. My gut feeling says the same process would be 'better', although it would also be more complex:</p>&#xA;&#xA;<ol>&#xA;<li><p>Hosting the endpoints in separate processes is simple: Host the WebAPI endpoint in IIS and host the NServiceBus endpoint as a Windows Service.</p></li>&#xA;<li><p>When hosting them in the same process, it's possible to self-host the NServiceBus endpoint in the WebAPI code but this is not recommended as IIS will shut down the worker process after a period of inactivity,&#xA;thereby also killing the NServiceBus part of the service and leaving it unable to handle incoming messages.<br>&#xA;So I figured I would have to host both the NServiceBus and the WebAPI endpoints in a Windows service, which appears to be possible when <a href=""https://docs.microsoft.com/en-us/aspnet/web-api/overview/hosting-aspnet-web-api/use-owin-to-self-host-web-api"" rel=""nofollow noreferrer"">using OWIN to self-host the WebAPI endpoint</a>.</p></li>&#xA;</ol>&#xA;&#xA;<p>Does anyone have experience with hosting a service with 2 endpoints in the same or different processes, and can tell me the problems/benefits associated with this choice?</p>&#xA;&#xA;<p><em>(<a href=""https://stackoverflow.com/questions/21202411/host-web-api-in-self-hosted-nservicebus"">This question</a> seemed to ask the same, but it never got a satisfactory answer)</em></p>&#xA;&#xA;<p><strong>Edit</strong> In response to @HadiEskandari, I'm not looking for a WebAPI facade for an NServiceBus endpoint. I'm planning to have the WebAPI endpoint to handle simple queries for information which it stores in the database that is shared between these endpoints.&#xA;Thse REST calls will be invoked AJAX-style from a web application, so I need this to execute quickly - forwarding each REST call through an MSMQ queue &#xA;to the NServiceBus endpoint and waiting for a response seems slow and wasteful in this case.</p>&#xA;&#xA;<p>Rather, I'm looking for a way to keep the data access code and business logic not just in the same assembly, but also in the same AppDomain so that both endpoints may share say, the same configuration or cached data.</p>&#xA;"
45300410,Django - How to implement authentication service in microservices architecture,<django><jwt><microservices>,1,481,3,0.0,1,"<p>Basically, I have several independent services. I want to build a service for authentication. When client get a token from authentication service. Client use it for further request to others services. Client need to attach that token in header of request. The services receiving token need to verify the token by sending it to authentication server. So all requests that clients make to protected routes need to be verified by authentication service. The thing is I do not know the best place to put the code that automatically sends token to authentication service and receive the result. &#xA;Here is what i tried so far:&#xA;I implemented a middleware like that:</p>&#xA;&#xA;<pre><code>class VerifyTokenMiddleware(object):&#xA;&#xA;def process_request(self, request):&#xA;    if not request.META.get('HTTP_AUTHORIZATION'):&#xA;        return HttpResponse(status=404)&#xA;    auth_header = request.META.get('HTTP_AUTHORIZATION')&#xA;    token = auth_header[4:]&#xA;    response = requests.post(AUTH_URL, {""token"": token})&#xA;    if response.status_code == 400:&#xA;        return HttpResponse(status=403)&#xA;    return None&#xA;</code></pre>&#xA;&#xA;<p>However, the problem of my solution is every requests to services(not auth service) have to pass through that middleware. Therefore, client cannot access unprotected routes like before. &#xA;Any help is extremely appreciated. :D</p>&#xA;&#xA;<p>I used django restframework jwt <a href=""https://github.com/GetBlimp/django-rest-framework-jwt"" rel=""nofollow noreferrer"">https://github.com/GetBlimp/django-rest-framework-jwt</a>. </p>&#xA;"
45293123,How to design a multi-file processor using Golang?,<go><design><microservices>,1,53,4,0.0,1,"<p>I'm trying to figure out how to design a service that can handle multiples files format, using micro-services for example:</p>&#xA;&#xA;<p>I have a customer using a file format A, another using format B and other using format C.</p>&#xA;&#xA;<p>After processing a specific format for each customer, I need to transform this format into an common format, and insert into database.</p>&#xA;&#xA;<p>The first thing I tried is to design one service per customer but all of them need to know the base format and if an update is needed in this base format, I need to update all of there services.</p>&#xA;&#xA;<p>I'm trying to decouple the service processor and have a single place to translate to base format.</p>&#xA;&#xA;<p>If my customer services know about the base format, if this format changes,  I need to update all of them. If I have a service that translate the format, this service needs to know all customer formats.</p>&#xA;&#xA;<p>How to design this solution?</p>&#xA;"
45168622,How to share constans between Rails microservices?,<ruby-on-rails><ruby><microservices>,2,88,4,0.0,1,"<p>I have my main app and admin app built as a microservice, they are communicating via api. I want to share some constants between those two apps.</p>&#xA;&#xA;<p>For example I have User model that can have role Owner or Regular. In admin app I can search Users and in this search I have dropdown with hardcoded user type (Owner, Regular). This is okay, but when I change naming (e.g. Regular -> Standard) I have to update my Admin app also.</p>&#xA;&#xA;<p>To avoid changing admin app every time I change some core naming in my main app I want to somehow share those constants, so every change in main app will change Admin at the same time.</p>&#xA;&#xA;<p>For now I found 2 solutions, both with pros and cons:</p>&#xA;&#xA;<p>First is sending constants from main app to admin via json api. I have build a class that will fetch and store all constants in class variable, so it's available from every part of the the app. The good thing about this solution is performance (thanks to memoization it's only one api request) and it's easy to use later. The bad thing is I have no idea how to handle tests in this case. Of course I cannot let my tests make request to main app and stubbing this request makes the whole idea pointless, because after every change of constants in main app I will need to change tests in admin app. </p>&#xA;&#xA;<p>Second approach I thought of is building a gem that will store all constants. It's very easy to implement, but this means I will need to make changes to this repo every time I want to change constants in main app. Also I work with big team and they won't be happy that they have to work on 2 repos at the same time.</p>&#xA;&#xA;<p>What do you think about those solutions? First one seems to be perfect for me except tests, so maybe you have some ideas how to stub those constants without real values? I haven't tried gem solution yet so if you see some obstacles please let me know.&#xA;Maybe there is another better solution to this problem?</p>&#xA;"
45275679,Sharing code in Microservices,<java-ee><architecture><jax-rs><microservices>,1,301,8,0.0,1,"<p>We have two services. However, in the past, these two services were one service, but have been split due to differing traffic requirements.</p>&#xA;&#xA;<p>The services are consumed by two kinds of clients; other services and UI clients (web, desktop and mobile).</p>&#xA;&#xA;<p>Consumers of service 1: Services, </p>&#xA;&#xA;<ol>&#xA;<li>Use a very limited number of exposed endpoints (<code>addInput</code>, <code>removeInput</code>).</li>&#xA;<li>Generates high traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Consumers of service 2: UI clients,</p>&#xA;&#xA;<ol>&#xA;<li>Using a large number of exposed endpoints</li>&#xA;<li>Generating less traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Currently, they are sharing code but as far as I can figure out micro-services should not share base code. Therefore we believe something is wrong using this approach.</p>&#xA;&#xA;<p>what are the key issues to understand in order to solve this kind of micro-services architecture issues?</p>&#xA;"
39476480,microservices: C:\....m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature),<java><maven><microservices>,1,665,0,1.0,1,"<p>I was looking to developed the <code>microservices</code> example by following the link: <a href=""https://github.com/bjedrzejewski/tasklist-service"" rel=""nofollow"">https://github.com/bjedrzejewski/tasklist-service</a>. When I simply compile the whole source code I faced compilation error, not sure why ? It looks to me something wrong with my .m2 home not so sure though.</p>&#xA;&#xA;<p>The error coming for reference:-</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure: Compilation failure:&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature)&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\eclipse\jetty\jetty-servlet\9.2.13.v20150730\jetty-servlet-9.2.13.v20150730.jar; invalid LOC header (bad signature)&#xA;[ERROR] -&gt; [Help 1]&#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)&#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)&#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)&#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)&#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)&#xA;Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure&#xA;        at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:656)&#xA;        at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:128)&#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)&#xA;        ... 20 more&#xA;[ERROR]&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException&#xA;</code></pre>&#xA;&#xA;<p>I only updated pom.xml to use Java version 8, nothing special</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;bjedrzejewski&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;tasklist-service&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;dropwizard.version&gt;0.9.1&lt;/dropwizard.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.dropwizard&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;dropwizard-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${dropwizard.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jersey-common&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.23.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;2.3.2&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;${java.version}&lt;/source&gt;&#xA;                    &lt;target&gt;${java.version}&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;archive&gt;&#xA;                        &lt;manifest&gt;&#xA;                            &lt;mainClass&gt;com.bjedrzejewski.tasklistservice.TaskListServiceApplication&lt;/mainClass&gt;&#xA;                        &lt;/manifest&gt;&#xA;                    &lt;/archive&gt;&#xA;                    &lt;descriptorRefs&gt;&#xA;                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;&#xA;                    &lt;/descriptorRefs&gt;&#xA;                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;&#xA;                &lt;/configuration&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;&#xA;                        &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;single&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>Also pom.xml dont have much entry of dependencies but still I see many jars files gets download why this so ?</p>&#xA;&#xA;<pre><code>E:\Advance Java\MicroServices\Git code\tasklist-service&gt;mvn dependency:tree&#xA;[INFO] Scanning for projects...&#xA;[INFO]&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building tasklist-service 1.0-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO]&#xA;[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ tasklist-service ---&#xA;[INFO] bjedrzejewski:tasklist-service:jar:1.0-SNAPSHOT&#xA;[INFO] +- io.dropwizard:dropwizard-core:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-util:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0:compile&#xA;[INFO] |  |  +- com.google.guava:guava:jar:18.0:compile&#xA;[INFO] |  |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile&#xA;[INFO] |  |  \- joda-time:joda-time:jar:2.9:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jackson:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-core:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk7:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-joda:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.slf4j:slf4j-api:jar:1.7.12:compile&#xA;[INFO] |  |  \- ch.qos.logback:logback-classic:jar:1.1.3:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-validation:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.hibernate:hibernate-validator:jar:5.2.2.Final:compile&#xA;[INFO] |  |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile&#xA;[INFO] |  |  |  +- org.jboss.logging:jboss-logging:jar:3.2.1.Final:compile&#xA;[INFO] |  |  |  \- com.fasterxml:classmate:jar:1.1.0:compile&#xA;[INFO] |  |  \- org.glassfish:javax.el:jar:3.0.0:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-configuration:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- org.yaml:snakeyaml:jar:1.15:compile&#xA;[INFO] |  |  \- org.apache.commons:commons-lang3:jar:3.4:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-logging:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-logback:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.slf4j:jul-to-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- ch.qos.logback:logback-core:jar:1.1.3:compile&#xA;[INFO] |  |  +- org.slf4j:log4j-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- org.slf4j:jcl-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-util:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-metrics:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jersey:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.core:jersey-server:jar:2.22.1:compile&#xA;[INFO] |  |  |  +- org.glassfish.jersey.core:jersey-client:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-metainf-services:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-bean-validation:jar:2.22.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jersey2:jar:3.1.2:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile&#xA;[INFO] |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-server:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-io:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-xml:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-continuation:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-servlets:jar:0.9.1:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-annotation:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jetty:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jetty9:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlet:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-security:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlets:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-http:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-lifecycle:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-servlets:jar:3.1.2:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-json:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-healthchecks:jar:3.1.2:compile&#xA;[INFO] |  +- net.sourceforge.argparse4j:argparse4j:jar:0.6.0:compile&#xA;[INFO] |  \- org.eclipse.jetty.toolchain.setuid:jetty-setuid-java:jar:1.0.3:compile&#xA;[INFO] \- org.glassfish.jersey.core:jersey-common:jar:2.23.2:compile&#xA;[INFO]    +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile&#xA;[INFO]    +- javax.annotation:javax.annotation-api:jar:1.2:compile&#xA;[INFO]    +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.23.2:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-api:jar:2.5.0-b05:compile&#xA;[INFO]    |  +- org.glassfish.hk2:hk2-utils:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2.external:javax.inject:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-locator:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.javassist:javassist:jar:3.20.0-GA:compile&#xA;[INFO]    \- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD SUCCESS&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 2.860 s&#xA;[INFO] Finished at: 2016-09-13T23:39:38+05:30&#xA;[INFO] Final Memory: 17M/309M&#xA;[INFO] ------------------------------------------------------------------------&#xA;</code></pre>&#xA;"
39435028,How to use micro-services into core application/framework?,<rest><microservices>,1,120,5,0.0,1,"<p>For example I have two micro-services, how can I use those services in my core application?</p>&#xA;&#xA;<p>I know the communication will be through REST API. </p>&#xA;&#xA;<p>My question is, should I create those services as sub-modules?</p>&#xA;&#xA;<p>If my question seems not clear to you then assume I am not clear about micro-services. Thus better explanation will be very helpful.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
42641804,Authentication approach for REST API used by frontend app and another backend service,<javascript><java><rest><microservices>,2,583,1,0.0,1,<p>I have a rest api backend service <strong>A</strong> which is used by two other services:</p>&#xA;&#xA;<ul>&#xA;<li><strong>B</strong> service which is web app running in a browser (separate node server)</li>&#xA;<li><strong>C</strong> service which is also backend service (separate server too)</li>&#xA;</ul>&#xA;&#xA;<p>My initial approach was to use basic auth for A-B communication but this does not make sense for A-C since there is no way to safely keep credentials in a browser. On the other hand introducing session and tokens seems weird for A-B communication.</p>&#xA;&#xA;<p>No matter what I do it seems like tug of war.</p>&#xA;&#xA;<p>What do you think might be reasonable solution for such setup?</p>&#xA;
42653725,In which microservice should I store a liaison table,<relational-database><relationship><microservices>,2,117,3,0.0,1,"<p>I'm splitting my zoo-management application into micro-services.&#xA;I have the following domain : animals, caretakers, cages </p>&#xA;&#xA;<p>I thinking about where I should store the relationships. </p>&#xA;&#xA;<p>For exemple a cage contain several animals :&#xA;Should I store the cage_animals table into the cages services database or into the animals database ?</p>&#xA;&#xA;<p>And several caretakers are attributed to several animals :&#xA;Should I store the caretakers_animals table into the caretakers service's database or into the animals service's database ?</p>&#xA;"
39888380,"Spring Boot Microservice: dynamic role, permission based security",<java><spring><spring-security><spring-boot><microservices>,1,1120,0,0.0,1,"<p>We have created application using Spring Boot Microservices,&#xA;application contains jsp pages and rest uri.</p>&#xA;&#xA;<p>For this type of architecture expect suggestions to secure pages and uri.&#xA;I want role and permission based access, where permission contains all pages and uri listed and role_permission_mapping has mapping of uri/pages against role.</p>&#xA;&#xA;<p>Admin have rights to add Role, Permission and Mapping dynamically using some UI. </p>&#xA;&#xA;<p>Image below shows sample table structure.</p>&#xA;&#xA;<p>Suggest me if we have built-in mechanism which provides out of box support for this type of requirement.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eBgNL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBgNL.png"" alt=""enter image description here""></a></p>&#xA;"
39998701,throw new TypeError('app.use() requires middleware functions');,<javascript><node.js><express><microservices><seneca>,1,302,5,0.0,1,"<p>I'm just trying to run sample codes from Developing Microservices with Node js, and it says:</p>&#xA;&#xA;<pre><code>var express = require('express')&#xA;var bodyParser = require('body-parser')&#xA;var cookieParser = require('cookie-parser')&#xA;var methodOverride = require('method-override')&#xA;var seneca = require('seneca')()&#xA;var argv = require('optimist').argv&#xA;var app = express()&#xA;var cors = require('cors')&#xA;var routes = require('./../routes/index')&#xA;let path = require('path')&#xA;var webpack = require('webpack')&#xA;var webpackMiddleware = require('webpack-dev-middleware')&#xA;var config = require('./../webpack.config.js')&#xA;&#xA;var compiler = webpack(config)&#xA;&#xA;var conf = {&#xA;   port: argv.p || 7770&#xA;}&#xA;&#xA;app.engine('jsx', require('express-react-views').createEngine())&#xA;app.set('port', conf.port)&#xA;app.use(cors())&#xA;app.use('/public', express.static(path.join(__dirname,'./../public')))&#xA;app.use('/views', express.static(path.join(__dirname, './../views')))&#xA;app.use(webpackMiddleware(compiler));&#xA;app.use(cookieParser())&#xA;app.use(express.query())&#xA;app.use(bodyParser.urlencoded({extended: true}))&#xA;app.use(methodOverride())&#xA;app.use(bodyParser.json())&#xA;app.use(express.static('public'))&#xA;app.use(seneca.export('web'))  // Error line&#xA;&#xA;seneca.use('./../lib/registerAPI')&#xA;&#xA;app.use('/', routes)&#xA;&#xA;module.exports = app&#xA;</code></pre>&#xA;&#xA;<p>but Im getting an error that says:</p>&#xA;&#xA;<pre><code>/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177&#xA;     throw new TypeError('app.use() requires middleware functions');&#xA;     ^&#xA;TypeError: app.use() requires middleware functions &#xA;     at EventEmitter.use (/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177:11)&#xA;     at Object.&lt;anonymous&gt; (/home/quocdinh/workspace/ECommerce/ass-ECommerce/src/app.js:33:5) // --&gt; line: app.use(seneca.export('web'))&#xA;</code></pre>&#xA;&#xA;<p>I have tried to find solutions but ineffective.</p>&#xA;&#xA;<p>I tried adding</p>&#xA;&#xA;<pre><code> app.use(require('seneca-web'))&#xA;</code></pre>&#xA;&#xA;<p>but still not be</p>&#xA;&#xA;<p>I tried to lower the version of the node version that I have to 4.0 from 6.0, but still got the same error</p>&#xA;"
41880229,Send a message from one microservice to another in Azure Service Fabric (APIs),<asp.net-web-api><architecture><microservices><azure-service-fabric><service-fabric-stateful>,2,651,0,3.0,1,"<p><a href=""https://i.stack.imgur.com/Og0vb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Og0vb.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What is the best architecture, using Service Fabric, to guarantee that the message I need to send from Service 1 (mostly API) to Service 2 (mostly API) does not get ever lost (black arrow)?</p>&#xA;&#xA;<p>Ideas:</p>&#xA;&#xA;<h1>1</h1>&#xA;&#xA;<p>1.a. Make service 1 and 2 stateful services. Is it a bad call to have a stateful Web API?</p>&#xA;&#xA;<p>1.b. Use Reliable Collections to send the message from API code to Service 2.</p>&#xA;&#xA;<h1>2</h1>&#xA;&#xA;<p>2.a. Make Service 1 and 2 stateless services</p>&#xA;&#xA;<p>2.b. Add a third service</p>&#xA;&#xA;<p>2.c. Send the message over a queuing system (i.e.: Service Bus) from service 1</p>&#xA;&#xA;<p>2.d. To be picked up by the third service. Notice: this third service would also have access to the DB that service 2 (API) has access to. Not an ideal solution for a microservice architecture, right?</p>&#xA;&#xA;<h1>3</h1>&#xA;&#xA;<p>3.a. Any other ideas?</p>&#xA;&#xA;<p>Keep in mind that the goal is to never lose the message, not even when service 2 is completely down or temporary removed… so no direct calls.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
41776814,Accessing Large files stored in AWS s3 using AWS Lambda functions,<amazon-web-services><amazon-s3><aws-lambda><microservices>,1,1992,1,0.0,1,"<p>I have more than 30GB file stored in s3,and I want to write an Lambda function which will access that file, parse it and then run some algorithm on the same.&#xA;I am not sure if my lambda function can take that big file and work on it as Max execution time for Lambda function is 300 sec(5 min).&#xA;I found AWS S3 feature regarding faster acceleration, but will it help?</p>&#xA;&#xA;<p>Considering the scenario other than lambda function can any one suggest any other service to host my code as micro service and parse the file?</p>&#xA;&#xA;<p>Thanks in Advance</p>&#xA;"
41739975,What are the reason to decouple databases on microservices?,<database><microservices><nosql>,1,435,3,0.0,1,"<p>Here I my current findings on this subject, are these correct or is there an aspect missing?</p>&#xA;&#xA;<p>There are two major principles for microservices: </p>&#xA;&#xA;<ul>&#xA;<li><strong>strong cohesion</strong> -> related code is gouped together, e.g. a class does on well defined job this is strong/hingh cohesion. </li>&#xA;<li><strong>loose coupling</strong> -> interconnect components in a system so that those  components, depend on each other as less as practicable. Coupling refers to the degree of direct knowledge that one element has of another. So a change to one service should not require a change to another.</li>&#xA;</ul>&#xA;&#xA;<p>With a shared database (as in not decoupled) architecture both these principles are not covered. This due to the following facts:</p>&#xA;&#xA;<ul>&#xA;<li>There is a fixed link between the users and the specific technology&#xA;choice as well as to the actual database implementation.</li>&#xA;<li>Businiess/application logic might be spread among multiple users.</li>&#xA;<li>Shared information which needs to be edited can trigger a change of&#xA;the behavior in multiple places.</li>&#xA;<li>Due to the more monolithic architecture which goes with shared&#xA;databases a failure can effect many serveries since they are all tied&#xA;together, even a compelte system failure can happen due to the&#xA;coupeling.</li>&#xA;</ul>&#xA;&#xA;<p>To avoid the above mentioned issues: decoupled databases can be used with microservices instead of shared databases. So each microservice should have its own database. This will also ease scaling of the system, provide much much more system availability, since ""only"" the one, really effected service will fail. </p>&#xA;&#xA;<p><strong>UPDATE</strong>: &#xA;One other benefit of microservices would be that it can improve the flexibility and speed of development. Since correctly decomposed microservices, can be developed and deployed e independently and in parallel with the other services.</p>&#xA;"
42353292,Does Service Discovery microservice break idea of loose coupling?,<microservices><service-discovery>,4,120,0,1.0,1,"<p>As a mechanism to connect microservices together and make them work it is usually suggested to use APIs and Service Discovery. But they usually work as their own microservices, but these ones should apparently be ""hard-coded"" into others, as every microservice is supposed to register with them and query for other microservices' locations. Doesn't this break the idea of loose coupling, since a loss of a discovery service implies others being unable to communicate?</p>&#xA;"
42230797,Spring Cloud Stream Kafka - Eventual consistency - Does Kafka auto retry unacknowledged messages (when using autocommitoffset=false),<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,1,689,0,0.0,1,"<p>Implementing an eventually consistent distributed architecture has turned out to be a pain. There are tons of blog posts telling stories about how to do it, but not showing (code) how to actually do it.</p>&#xA;&#xA;<p>One of the aspects I'm suffering is having to deal with manual retries of the messages when they haven't been ack'd.</p>&#xA;&#xA;<p>For instance: my order service sends a pay event to Kafka. Payment Service is subscribed to it and processes it, answering with payment ok or payment failure</p>&#xA;&#xA;<ol>&#xA;<li><p>Ask for payment: <code>Order Service ----Pay event----&gt; Kafka ----Pay Event ----&gt; Payment Service</code></p></li>&#xA;<li><p>Payment OK: -> <code>Payment Service ----Payment ok event ----&gt; Kafka ----Payment ok Event ----&gt; Order Service</code></p></li>&#xA;<li><p>Payment Fail -> <code>Payment Service ----Payment failure event ----&gt; Kafka ----Payment failure Event ----&gt; Order Service</code></p></li>&#xA;</ol>&#xA;&#xA;<p>The point is: </p>&#xA;&#xA;<p>I know for sure when a message has been delivered to Kafka by using sync sendings. BUT, the only way I have to know that the payment has been processed by Payment Service is by expecting an answer event (Payment ok| Payment failure).</p>&#xA;&#xA;<p>This forces me to implement a retry mechanism in Order server. If it hasn't gotten an answer in some time, retry with a new Pay event.</p>&#xA;&#xA;<p>What's more, this also forces me to take care of duplicated messages in Payment Service in case they were actually processed but the answer didn't get to Order Service.</p>&#xA;&#xA;<p><strong>I was wondering if Kafka has a built in mechanism to send retries if the consumer didn't acknowledge the new offset of the messages</strong>.</p>&#xA;&#xA;<p>In Spring Cloud Stream we can set a <code>autoCommitOffset</code> property to false and handle the ack of the offset in the consumer:</p>&#xA;&#xA;<pre><code> @StreamListener(Sink.INPUT)&#xA; public void process(Message&lt;?&gt; message) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         System.out.println(""Acknowledgment provided"");&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p><strong>What happens if we don't execute <code>acknowledgment.acknowledge();</code> Will the message be automatically resent by Kafka to this consumer?</strong></p>&#xA;&#xA;<p>If it is possible we wouldn't need to retry manually any more and could do stuff like this:</p>&#xA;&#xA;<p>Paymen Service:</p>&#xA;&#xA;<pre><code> @Autowired&#xA; private PaymentBusiness paymentBusiness;&#xA;&#xA; @StreamListener(Sink.INPUT)&#xA; public void process(Order order) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         paymentBusiness(order);            &#xA;         //If we don't get here because of an exception &#xA;         //Kafka would retry...&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>If this were possible, how is the retry period configured in Kafka?</p>&#xA;&#xA;<p>In the worst case (and most likely) scenario, this isn't supported and we would have to retry manually. Do you know any real example of Spring Cloud Stream apps dealing with eventual consistency using Kafka?</p>&#xA;"
37528335,Splitting monolith into microservices,<spring><rest><spring-boot><microservices>,1,691,1,1.0,1,"<p>I have an existing web service that supports ordering and it has multiple operations (approximately 20). This is a single webservice that support the ordering function. It interacts with multiple other services to provide ordering capability. </p>&#xA;&#xA;<p>Since there is a lot of business functionality within this app and it is supported by a 10 member team , I believe it is a monolith (though I assume there is no hard and fast rule to define what a monolith is). </p>&#xA;&#xA;<p>We are planning to get the application deployed in cloud foundry environment and we are planning to split the app into 2-3 microservices , primarily to enable them scale independently. </p>&#xA;&#xA;<p>The first few apis which enable searching for a product typically have more number of hits whereas the api that support actual order submission receives less that 5% of the hits. So the product search api should have significantly larger number of instances as compared to order submission api. </p>&#xA;&#xA;<p>Though I am not sure if we could split is based on sub-domains (which I have read should be the basis) , we are thinking of splitting them based on the call sequence as explained earlier. </p>&#xA;&#xA;<p>I have also read that microservices should be choreographed and not orchestrated. However in order to ensure our existing consumers are not impacted , I believe we should expose a api layer which would orchestrate the calls to these microservices. Is providing an api gateway , the normal approach that is followed to ensure consumers do not end up calling multiple microservices and also provides a layer of abstraction? </p>&#xA;&#xA;<p>This seems to be orchestration more than choreography - though I am not hung up on the theoretical aspects , I would like to understand the different solutions that are pursued for this problem statement in an enterprise world.</p>&#xA;"
41086281,MICROSERVICES - communication between them,<java><rest><microservices>,2,712,4,0.0,1,"<p>I've got one question concerning microservices architecture. I am designing a system based on microservices. I've read few articles and I think I understand the idea. However, I don't how microservices should communicate with each other while they have separate business responsibilities....&#xA;What I mean is that if I have a system for booking train tickets, I would divide backend application into modules: </p>&#xA;&#xA;<ul>&#xA;<li>Client (login,logout,registration) </li>&#xA;<li>Reservations (booking a train seat for user,getting all reservations for user) </li>&#xA;<li>ConnectionsDetails&#xA;(searching for connections,getting connection details) </li>&#xA;<li>Trains&#xA;(information about trains- seats number,class etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Now, I can only think that if user search for connections module ConnectionsDetails communicate with Trains module and ask about particular train details. But how could other microservices communicate? If user wants to login - she/he asks directly Client module, if she/he wants to get all her reservations - asks Reservation module DIRECTLY etc... </p>&#xA;&#xA;<p>So my question is, how should modules communicate if they do different things? I'm sorry if my question is trivial or stupid, I'm just starting with microservices.</p>&#xA;&#xA;<p>EDIT:&#xA;I didn't mean what tools could I use for communication. My question is about logic. In the example I showed, why one microservice could ask another microservice about sth if client can directly ask the another one? As I said earlier, how they should communicate(about what should they ask each other exactly) if they do separate things?</p>&#xA;"
50139640,Architecture of microservices from a business approach or technical?,<rest><docker><cloud><microservices>,3,50,0,1.0,1,"<p>Our team is trying to decouple a <strong>monolithic</strong> spring mvc administrative application <em>(create, update, delete)</em> and we want to adopt an architecture based on <strong>microservices</strong>. </p>&#xA;&#xA;<p>After a bit of research, it seems the best is create microservices <strong><em>according to the problem</em></strong> that a specific part of the software solves, for example, Managing Clients. </p>&#xA;&#xA;<p>The problem comes when we read some definitions, like the following from <strong><a href=""https://en.wikipedia.org/wiki/Monolithic_application"" rel=""nofollow noreferrer"">Wikipedia</a></strong>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In software engineering, a monolithic application describes a&#xA;  single-tiered software application in which the user interface and&#xA;  data access code are combined into a single program from a single&#xA;  platform.</p>&#xA;</blockquote>&#xA;&#xA;<p>Based on that definition, <em>my application is not monolithic</em>, because it is perfectly separated in layers, but it is not found in a micro-services architecture either, which is confusing to me since in the web everything is about <strong>Monolithic vs. Microservices</strong>.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/EIfHO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EIfHO.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>So, should the microservices architecture be designed based on the business problem it solves?</strong> </p>&#xA;&#xA;<p><strong>Should the microservices architecture be designed based on to the way in which the application is organized in layers?</strong></p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
51926575,Linking data in java microservices in a database per service implementation,<java><spring><spring-boot><microservices><cqrs>,3,47,4,1.0,1,"<p>I am building a java / spring microservices where each service has it own database . Let's say i have a user service that stores user information in one of the table and a orders service that stores only the username of the person who orders as described below :-</p>&#xA;&#xA;<pre><code>User Service (UserService Database - User Table )&#xA;id     firstName    lastName     username     age &#xA;1       Chris        Brown       c.brown      20&#xA;2       John         Doe         j.doe        25&#xA;</code></pre>&#xA;&#xA;<p>And orders service as below</p>&#xA;&#xA;<pre><code> Order Service (OrderService Database - Order Table )&#xA;    id     username    productName     productPrice     OrderDate &#xA;    1      c.brown       Sony Mic       100$            20-08-2018&#xA;    2       j.doe       Television      j.doe           11-07-2018&#xA;</code></pre>&#xA;&#xA;<p>Question is what is the best approach to get firstName and lastName from user service while listing the orders . I am aware that microservices should communicate via Rest API , but if i have 1000 users with orders , i will have to loop 1000 times to get the firstName and lastName or take usernames as array , activity which might be expensive . </p>&#xA;&#xA;<p>I have read on using CQRS and event sourcing , but not sure how to best apply it in this scenario . </p>&#xA;"
43617787,What is the difference between workflow and dataflow?,<spring><workflow><microservices><dataflow><spring-cloud-dataflow>,1,586,0,0.0,1,"<p>I'm looking at Spring Cloud Date Flow, before that I watched Activiti and Camunda(this is workflow engine). And I can't understand what is the difference between these concepts as workflow and dataflow? and сan we call Spring Cloud Data Flow the workflow engine?</p>&#xA;&#xA;<p>Sorry, I'm newer in this topic.</p>&#xA;&#xA;<p>I will be glad to any answer!</p>&#xA;"
43545080,Getting the different Content Type in the response of REST call done by REST client and Jersey Java Code,<java><rest><jersey><microservices>,3,595,0,0.0,1,"<p>While working on a Micro-Service, I have to hit the REST api of the 3rd party. I am using the Spring Boot Application with Jersey library. &#xA;Now the problem is that I am getting the content type of the response as ""text/html; charset=utf-8"".</p>&#xA;&#xA;<p>If I hit the same call using the REST client, I get the right content type as application/json;charset=UTF-8. Why so ?</p>&#xA;&#xA;<p>Below is the Java source code for the same -</p>&#xA;&#xA;<pre><code>@Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;@POST&#xA;@Path(""/endPoint"")&#xA;@Consumes(javax.ws.rs.core.MediaType.APPLICATION_JSON + ""; charset=UTF-8"")&#xA;public JSONObject getAccessToken(@FormParam(""item1"") String item1,@FormParam(""item2"") String item2,@FormParam(""item3"") String item3,@FormParam(""item4"") String item4) throws Exception {&#xA;  System.out.println(""Enter to test"");&#xA;&#xA;&#xA;    String extendedUrl = ""?item1=""+item1+""&amp;item2=""+item2+""&amp;item3=""+item3+""&amp;item4=""+item4;&#xA;&#xA;    JSONObject jObject = null;&#xA;    try {&#xA;      jObject = postCall(extendedUrl);&#xA;    }&#xA;    catch (Exception e) {&#xA;      // TODO Auto-generated catch block&#xA;      e.printStackTrace();&#xA;    }&#xA;&#xA;    System.out.println(""Box Auth Response :: ""+jObject.toJSONString());&#xA;&#xA;    return jObject;&#xA;}&#xA;// Short description of the logic to execute the request&#xA;public void postCall(String extendedUrl)&#xA;{ &#xA;String url = ""baseurl"";&#xA;url+=extendedUrl;&#xA;HttpsURLConnection conn = openConnection(apiUrl);&#xA;conn.connect();&#xA;status = conn.getResponseCode();&#xA;String responseContentType = conn.getContentType();&#xA;System.out.println(""responseContentType ::""+responseContentType);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So when I debug the code, responseContentType comes out as text/html; charset=utf-8. Is there any reason for the same ? How will get this as application/json;charset=UTF-8?</p>&#xA;&#xA;<p>Help would be appreciated. </p>&#xA;"
43584079,How to split an existing webApi project?,<.net><asp.net-web-api><architecture><microservices>,1,68,4,0.0,1,"<p>I have an existing legacy .Net webApi project with ~20 controllers and ~10 methods each.&#xA;The traffic is 15 requests per sec.&#xA;I'm wondering if it's a smart thing to do to take microServices approach and split it into few hosted projects.</p>&#xA;&#xA;<p>Since i don't have access to the clients (android, ios, WebSite and third parties) i will have to keep the existing API URL working (<a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a>).</p>&#xA;&#xA;<p>My quick and dirty architecture is:&#xA;1) Build new hosted API process <a href=""http://domainName/API1"" rel=""nofollow noreferrer"">http://domainName/API1</a>, <a href=""http://domainName/API2"" rel=""nofollow noreferrer"">http://domainName/API2</a>, <a href=""http://domainName/API3"" rel=""nofollow noreferrer"">http://domainName/API3</a>...&#xA;2) Ask kindly from the clients to use the new URLs&#xA;3) <a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a> will act as router to the new processes for background competitively </p>&#xA;&#xA;<p>Ideas ? Is there any existing pattern for that?  </p>&#xA;"
43559197,Shared signature key for JWT in various Microservices,<security><spring-security><jwt><spring-cloud><microservices>,1,372,4,0.0,1,<p>I have various microservices. I have implemented security using JWT. Each service validates the JWT token by the key which is being shared across all the services.</p>&#xA;&#xA;<p><strong>Is it fine to share same signature key for JWT across all the microservices?</strong> </p>&#xA;&#xA;<p>I can't implement this at the API gateway as I have to use certain libraries which requires spring security to be triggered in every microservice.</p>&#xA;
43661844,Microservice - What does changing service without changing code really mean?,<java><spring-boot><cloudfoundry><microservices>,2,113,7,0.0,1,"<p>I am trying to understand ""changing database without changing code"". Currently working with micro services using springboot, java, thymeleaf and cloud foundry.</p>&#xA;&#xA;<p>I have a spring boot application and attached a database as a service using cloud foundry.</p>&#xA;&#xA;<p>My problem is I am seeing that the purpose of micro service is allowing the ease to change services without changing code.</p>&#xA;&#xA;<p><strong>Here is where I got stuck</strong></p>&#xA;&#xA;<p>In java I have a sql script, ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>Images <a href=""http://microservices.io/patterns/data/database-per-service.html"" rel=""nofollow noreferrer"">source</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/WDQmC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WDQmC.png"" alt=""Table sample""></a></p>&#xA;&#xA;<p>My database would be attached as a service on cloud foundry using CUPS &#xA;""jdbc:oracle:thin:username/password//host:port/servicename""</p>&#xA;&#xA;<p>So let say I want to change this database to CUSTOMER table(take it as a different database). This will throw an error because CUSTOMER table will not have ""select * from ORDER where Status = 'ACCEPTED';""</p>&#xA;&#xA;<p>I've changed database, but wouldn't I still have to go back to my code and change the sql script?</p>&#xA;&#xA;<p><strong>My Attempt to resolve this issue</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>So instead of hard coding my sql script in java ""select * from ORDER where Status = 'ACCEPTED';""</p></li>&#xA;<li><p>I created a system environment variable and set it as sqlScript with value of select * from ORDER where Status = 'ACCEPTED'</p></li>&#xA;<li><p>Then in java I called the env variable String sqlScript= System.getenv(""sqlScript"");  </p></li>&#xA;<li><p>So now instead of going back into java to change sql script, user can change it through environment variables.</p></li>&#xA;</ol>&#xA;&#xA;<p>this is a very dirty method to go around my issue, what would be a better alternative?</p>&#xA;&#xA;<p>I know my logic of understanding is really wrong. Please guide me to the right path.</p>&#xA;"
42918707,What are the disadvantages of using Kerberos authentication for secure micro-service to micro-service communication?,<kerberos><microservices>,1,404,4,0.0,1,"<p>Sam Newman's ""Building Microservices"" book has described several methods that can be used to perform secure service to service communication. Such as</p>&#xA;&#xA;<ol>&#xA;<li>HTTPS Basic Authentication</li>&#xA;<li>Client Certificates</li>&#xA;<li>HMAC API Keys</li>&#xA;</ol>&#xA;&#xA;<p>I think Kerberos protocol can also be used for service to service authentication. But I found less references of using Kerberos protocol. Are there any disadvantages of using kerberos protocol in microservice architecture than other methods? </p>&#xA;"
49985156,Aggregates in Event Sourcing Pattern,<java><aggregate><microservices><event-sourcing>,1,128,4,0.0,1,"<p>I am dipping my feet into event sourcing pattern and trying to make sense of aggregates.I have read a few blogs and now I am more confused than ever before.</p>&#xA;&#xA;<p>From what I inferred aggregates should somehow enable user to run different queries on the event store to retrieve different stream of events.</p>&#xA;&#xA;<p>Use case :</p>&#xA;&#xA;<ol>&#xA;<li><p>I want to <strong>replay</strong> events on an invoice where the I want to see all actions done by  a specific employee on the balance.</p></li>&#xA;<li><p>I want to <strong>replay all</strong> events on an invoice </p></li>&#xA;</ol>&#xA;&#xA;<p>I hope these are valid use cases.</p>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | EmployeeId | Event            | Payload |&#xA;|----------|------------|------------|------------------|---------|&#xA;| 1        | 12345      | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | 45567      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | 77341      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | 98421      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status of invoice&#xA;Status is(Review,Billed,Paid)</p>&#xA;&#xA;<p>So from my understanding there needs to be 5 components . </p>&#xA;&#xA;<ol>&#xA;<li>Event- A specific event.</li>&#xA;<li>Event Source - The service that calls repo to get related events</li>&#xA;<li>Event Stream - A list of events</li>&#xA;<li>Command - A request operation on invoice</li>&#xA;<li>Aggregate -  An api to decide on inputs to load events </li>&#xA;</ol>&#xA;&#xA;<p>I understand how other things play but having a hard time wrapping my head around Aggregate. What is it ?</p>&#xA;&#xA;<p>Will I have two aggregate classes </p>&#xA;&#xA;<ul>&#xA;<li>AggregateEventsByInvoice</li>&#xA;<li>AggregateEventsByInvoiceEmployee</li>&#xA;</ul>&#xA;&#xA;<p>I really am having a hard time figuring out the need and use of aggregate . All the examples I have seen use UUID which does not make sense to me at all? Any help will be greatly appreciated.</p>&#xA;"
50041559,How to share common Data over several Microservices,<domain-driven-design><microservices>,2,87,5,1.0,1,"<p>I'm writing a Bachelors-Thesis about Microservices.</p>&#xA;&#xA;<p>I'm trying to split a monolith into Microservices and now I ran into a problem that there are some tables in a Database, that are relevant for more than one Microservice.&#xA;There is no chance to split this data into domain specific views.</p>&#xA;&#xA;<p>My approach is that I will create a new Database Schema with that specific tables and let all Microservices read from it.&#xA;That would be a shared kernel approach which is not recommended by the experts of Microservices.</p>&#xA;&#xA;<p>Do you have any experience or recommendations about this problem?</p>&#xA;&#xA;<p>Do you have any recommendations about books which are about similar problems?</p>&#xA;"
49252691,Microservice relationship/dependency strategy,<architecture><microservices>,2,60,3,0.0,1,"<p>I'd like some feedback on couple different solutions to handling data dependencies and relations across micro services.</p>&#xA;&#xA;<p>Consider these services:&#xA;<a href=""https://i.stack.imgur.com/Y7Qx8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y7Qx8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Briefly explained, there is a bank service and an account service. The account service holds the accounts and are always connected to a bank using a bankId.</p>&#xA;&#xA;<p>The dilemma is how to handle and validate this relationship and bankId and the pros and cons that comes with each decision.</p>&#xA;&#xA;<p><strong>Option 1:</strong></p>&#xA;&#xA;<p>Ignore validating completely. POST/PATCH against Accounts will never validate if the given BankId is an existing ID.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>Services don't know about each other and there are no hard dependencies between them, if one service goes down, the other doesn't stop working. (Which is a BIG one)</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>If the BankId is incorrect, accounts are ""lost"" and can't be accessed.</li>&#xA;<li>The reporting service and/or any reader has to account for missing or incorrect banks and present whatever data it has without crashing.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>The services are completely decoupled which will benefit performance, up time and complexity. All readers and applications need to be ""reactive"" and able to handle when cross service relationships are ""broken"".</p>&#xA;&#xA;<p><strong>Option 2:</strong></p>&#xA;&#xA;<p>Always validate using synchronous REST-call. POST/PATCH against Accounts will fail if BankId does not exist or if in anyway BankService can't respond or is broken.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Services are tightly dependent, you could argue that they are no longer proper micro services and might as well be a single service.</li>&#xA;<li>Performance impacted negatively</li>&#xA;<li>AccountService POST/PATCH won't work if BankService is down, GET will still work.</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>Services are tightly dependent which is really bad, this is more like the ""old ways"" and generally I feel like it's the wrong way to do it. Merging the services in this case is even worse, if you start fixing problems by merging you'd probably keep doing it and soon end up with massive services and you've failed with the whole micro service principle. Sure, reads will still work but that's a far fetched excuse.</p>&#xA;&#xA;<p><strong>Option 3:</strong></p>&#xA;&#xA;<p>Keep a readonly copy of BankEntity in AccountService. AccountService keeps this updated via the event bus. Validate against this on POST/PATCH.</p>&#xA;&#xA;<p>Pros</p>&#xA;&#xA;<ul>&#xA;<li>100% data integrity.</li>&#xA;<li>Readers don't need to handle and expect broken relationships.</li>&#xA;<li>No measurable negative performance impact</li>&#xA;</ul>&#xA;&#xA;<p>Cons</p>&#xA;&#xA;<ul>&#xA;<li>Complexity increased</li>&#xA;<li>Due to the asynchronous nature of events we cannot assume that the readonly copy of Banks are 100% updated. POST/PATCH on Account in rapid succession after creating a BankEntity might fail.</li>&#xA;<li>AccountService gets more knowledge of other services, even though it's a loose dependency</li>&#xA;</ul>&#xA;&#xA;<p>Reflection</p>&#xA;&#xA;<p>This is the most complex way, readers won't need to handle broken relationships and the performance / up time-issues are resolved, however, instead you would have to handle the fact that the readonly copy of Banks might not be updated yet and try again later. Comparing this to Option 1 means you'd still have to deal with it in some way, and since this will be more complex across the board I'd say its not the most favourable one.</p>&#xA;&#xA;<p><strong>End Thoughts</strong></p>&#xA;&#xA;<p>The general goal that would be nice to achieve is that the services do not synchronously talk to each other and that data integrity is a good as possible.</p>&#xA;&#xA;<p>However, in a micro service architecture I'm under the impression that relationship integrity simply might be one of those things you accept to lose going to this way.</p>&#xA;&#xA;<p>Our decision is leaning towards Option 1, actually just ignoring it, and anytime where you need to use it, you have to expect and handle that it might not be correct. This seems like it is the most ""micro services"" solution, the services don't really know about each other, the only ones that do are applications and reporting services that need to do cross-service operations.</p>&#xA;&#xA;<p>Any of the services need to take full responsibility that they, at any given time, has all the data they need to fully function themselves. Let's say for arguments sake that AccountEntity NEEDED a location for whatever reason to be a usable and complete domain entity, you can't expect to rely on BankId, you'd have to store Location on AccountEntity and maybe if it changes, you'd get an event and you can update it.</p>&#xA;&#xA;<p><strong>TL;DR</strong>&#xA;What are your experiences, opinions and thoughts on this? What would you do? Which strategy would you go for?</p>&#xA;"
49292843,Swagger Gateway MicroService Aggregation,<java><spring-boot><swagger><microservices>,1,403,5,1.0,1,"<p>I am developing a microservice application using SpringBoot. There is Gateway Microservice which is public facing, it redirects requests to particular microservice (which are running on different hosts).</p>&#xA;&#xA;<p>Now, I've multiple microservices, each microservice has exposed their APIs using Swagger. We would like to aggregate all these API Swagger docs for public clients. </p>&#xA;&#xA;<p>Temporary solution we've incorporated is, just copied the Swagger Annotated classes for each microservice in Gateway Service. What is <strong><em>the right way</em></strong> to do it?</p>&#xA;"
44642751,AWS Kinesis for Microservice Choreography,<amazon-web-services><domain-driven-design><microservices><cqrs><event-sourcing>,1,614,0,0.0,1,"<p>I am trying to develop microservices for online shop using CQRS, DDD, and Event sourcing concept. I looked to AWS Kinesis as event stream. I think it would be good for choreographed microservices. I have 2 services, service for customer data and service for ordering system. I want to see total number of unpaid orders and the total amount of orders for each customer. So, I should send orderCreated event and orderPaid event to the service for customer data and recalculate the total unpaid orders and total amount of orders for related customer.</p>&#xA;&#xA;<p>Could I put the ordering system events to AWS Kinesis and listen it in command-side service for customer? Should I persist the events (orderCreated and orderPaid event) from AWS Kinesis to database in customer command-side service? Or is it ok to just update the customer query-side service only? Should I use AWS Lambda as event processor? Could you give me some best practices for this model?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
40832097,MockMvc returns null instead of object,<spring><spring-mvc><junit><mockito><microservices>,1,2210,2,1.0,1,"<p>I am developing a microservice application and I need to test a post request &#xA;to a controller. Testing manually works but the test case always returns null.</p>&#xA;&#xA;<p>I've read many similar questions here in Stackoverflow and documentation but haven't figured out yet what I am missing.</p>&#xA;&#xA;<p>Here is what I currently have and what I tried in order to make it work:</p>&#xA;&#xA;<pre><code>//Profile controller method need to be tested&#xA;@RequestMapping(path = ""/"", method = RequestMethod.POST)&#xA;public ResponseEntity&lt;Profile&gt; createProfile(@Valid @RequestBody User user, UriComponentsBuilder ucBuilder) {&#xA;    Profile createdProfile = profileService.create(user); // line that returns null in the test&#xA;    if (createdProfile == null) {&#xA;        System.out.println(""Profile already exist"");&#xA;        return new ResponseEntity&lt;&gt;(HttpStatus.CONFLICT);&#xA;    }&#xA;    HttpHeaders headers = new HttpHeaders();&#xA;    headers.setLocation(ucBuilder.path(""/{name}"").buildAndExpand(createdProfile.getName()).toUri());&#xA;    return new ResponseEntity&lt;&gt;(createdProfile , headers, HttpStatus.CREATED);&#xA;}&#xA;&#xA;//ProfileService create function that returns null in the test case&#xA;public Profile create(User user) {&#xA;    Profile existing = repository.findByName(user.getUsername());&#xA;    Assert.isNull(existing, ""profile already exists: "" + user.getUsername());&#xA;&#xA;    authClient.createUser(user); //Feign client request&#xA;&#xA;    Profile profile = new Profile();&#xA;    profile.setName(user.getUsername());&#xA;    repository.save(profile);&#xA;&#xA;    return profile;&#xA;}&#xA;&#xA;// The test case&#xA;@RunWith(SpringRunner.class)&#xA;@SpringBootTest(classes = ProfileApplication.class)&#xA;@WebAppConfiguration&#xA;public class ProfileControllerTest {&#xA;&#xA;    @InjectMocks&#xA;    private ProfileController profileController;&#xA;&#xA;    @Mock&#xA;    private ProfileService profileService;&#xA;&#xA;    private MockMvc mockMvc;&#xA;&#xA;    private static final ObjectMapper mapper = new ObjectMapper();&#xA;&#xA;    private MediaType contentType = MediaType.APPLICATION_JSON;&#xA;&#xA;    @Before&#xA;    public void setup() {&#xA;        initMocks(this);&#xA;        this.mockMvc = MockMvcBuilders.standaloneSetup(profileController).build();&#xA;    }&#xA;    @Test&#xA;    public void shouldCreateNewProfile() throws Exception {&#xA;&#xA;        final User user = new User();&#xA;        user.setUsername(""testuser"");&#xA;        user.setPassword(""password"");&#xA;&#xA;        String userJson = mapper.writeValueAsString(user);&#xA;&#xA;        mockMvc.perform(post(""/"").contentType(contentType).content(userJson))&#xA;                .andExpect(jsonPath(""$.username"").value(user.getUsername()))&#xA;                .andExpect(status().isCreated());&#xA;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Tried to add <code>when</code>/<code>thenReturn</code> before post but still returns 409 response with null object.</p>&#xA;&#xA;<pre><code>when(profileService.create(user)).thenReturn(profile);&#xA;</code></pre>&#xA;"
40840470,MYSQL primary key strategy for microservices architecture,<mysql><microservices>,2,169,5,0.0,1,"<p>We are currently using auto-generated primary keys and we would like to switch to an approach which is more suitable for microservices-based applications: either we are going to use business defined primary key (a tax code for persons) or global unique identifiers.</p>&#xA;&#xA;<ul>&#xA;<li>In the past, MySQL had performance issues when using alphanumeric primary keys instead of autoincrement, is it still the case? </li>&#xA;<li>Is it possible, if we go for the UUID approach, to use a strong uuid generator which will guarantee the uuid will be unique even across different servers?</li>&#xA;</ul>&#xA;"
46668418,Microservice return response first and then process the request,<spring-boot><java-8><microservices>,2,582,5,1.0,1,<p>I am working on a solution for which i am trying to create a microservice which returns response immediately and then processes the request.</p>&#xA;&#xA;<p>I am trying to use Java 8 and Spring for this.</p>&#xA;
45390260,What things should I consider to split my Monolithic nodeJs app to Microservice architecture?,<node.js><microservices>,1,461,3,1.0,1,"<p>I'm trying to build Restful API's using NodeJs for a e-commerce application with a minimal functionality like User Accounts, Products, Inventory System, Cart/ Orders, Payments, Wallet/Credit, Delivery Management, Notifications etc.</p>&#xA;&#xA;<p>I wanted to implement this using a microservice architecture.</p>&#xA;&#xA;<p>I do not want to use a any framework, I want to explore and learn myself. </p>&#xA;&#xA;<p>How should I start?</p>&#xA;&#xA;<p>1) On what parameters should I choose a microservice architecture.</p>&#xA;&#xA;<p>2) How should I use the common ""terms"" like user model, or (products, inventory and orders).</p>&#xA;&#xA;<p>3) Should I build full monolithic App first and then take out the heavy parts out of it, one by one?</p>&#xA;&#xA;<p>A basic guideline that can put me in direction will be very helpful. I'll really appreciate and thank for helping on this subject.</p>&#xA;"
45486658,Is it bad practice to produce and consume messages from the same topic?,<apache-kafka><activemq><messaging><microservices><tibco-ems>,1,363,4,1.0,1,"<p>Say you have a micro-service architecture where multiple services produce and consume <em>unit</em> statusses. </p>&#xA;&#xA;<p>There are multiple ways to design this, which one would you recommend?</p>&#xA;&#xA;<p>These are some options that come to mind:</p>&#xA;&#xA;<ol>&#xA;<li>Create a generic topic <code>unit-status</code> and make services consume and produce messages on this topic. This has the consequence that you consume your own messages and have to filter them. I would consider this a dirty solution, but easy for new new consumers to get all unit status events.</li>&#xA;<li>Create a specific topic for each status, for example <code>unit-status-created</code>, <code>unit-status-packaged</code>, <code>unit-status-loaded</code>, <code>unit-status-deleted</code>, etc. Each service produces only on it's own topic, but can consume from a list of topics, excluding it's own. For example the loading service would consume from list(<code>unit-status-created</code>, <code>unit-status-deleted</code>, <code>unit-status-packaged</code>). This allows services to show interest in only specific events, but it requires a code or config change in potentially all service when a new status topic is added. </li>&#xA;<li>Give each status it's own partition and consume from all partitions except the one you produce in. This design makes things more complicated (bookkeeping which partition contains a specific status), does not auto balance when partitions are added, adding partitions while live makes things a bit more risky, therefore does not have my preference. </li>&#xA;</ol>&#xA;"
47162798,Decomposition into microservices,<design><architecture><microservices><bounded-contexts>,3,86,0,2.0,1,"<p>I have a question regarding decomposition into microservices. Suppose we have 2 microservices: <strong>User</strong> and <strong>Product</strong>. Suppose we now have a requirement to add categories to the system. More specifically, a product has one or more categories (e.g the product red miniature ferrari belongs to categories toys and cars) and a user can have categories which she likes (e.g. toys and shoes). Now when we retrieve the full list of products we want them to be sorted such that the products that fall in the preferred user categories are at the top. </p>&#xA;&#xA;<p>Basically be have a concept that is shared between microservices (in this case category). How to best model this in a microarchitecture environment? I see two solutions:</p>&#xA;&#xA;<p><strong>Solution 1:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Make a separate “categories"" microservice which manages CRUD of categories</li>&#xA;<li>In the product service have an API call to link category ids to a product</li>&#xA;<li>In the user service have an API call to link category ids to a user</li>&#xA;<li>In the product service we have an API call to fetch products ordered on preference. To make this work the product service needs to call the user service to get the user categories (or listen to events emitted by user services)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong> </p>&#xA;&#xA;<ul>&#xA;<li><p>Make a separate “categories” microservice which manages CRUD of categories</p></li>&#xA;<li><p>The categories service also has an API call to link product ids to categories</p></li>&#xA;<li><p>The categories service also has an API call to link user ids to categories</p></li>&#xA;<li><p>In the product service we have an API call to fetch products ordered on preference (to make this work product service needs to call the categories service to get user and product categories (or listen to events)</p></li>&#xA;</ul>&#xA;&#xA;<p>What are the advantages/disadvantage to both solutions? </p>&#xA;"
47265946,Microservice Project Structure Using Spring boot and Spring Cloud,<spring-boot><microservices>,3,1693,0,1.0,1,"<p>I am trying to convert a normal monolithic web application into microservices structure using spring boot and spring cloud. I am actually trying to create Angular 2 front-end application and calls these my developed microservices in the cloud. And I am already started to break the modules into independent process's structure for microservice architecture.</p>&#xA;&#xA;<ul>&#xA;<li>Here my doubt is that , When designing the flow of control and microservice structure architecture, Can I use only one single spring boot project using different controller for this entire web application back end process.? Somewhere I found that when I am reading develop all microservices using 2 different spring boot project. Actually I am new to spring and spring cloud. I have lot of confusions in my task. Can any one help to clarify that is possible to create all services in single project by using different modules ???</li>&#xA;</ul>&#xA;"
47184194,common POM based plugins across multiple microservice projects,<maven><pom.xml><maven-plugin><microservices>,1,42,3,0.0,1,"<p>I am trying to figure out a way to import a set of common Maven plugins, across multiple microservice projects?</p>&#xA;&#xA;<p>Idea is to maintain a single place to manage all the common plugins - like jacoco, javadocs etc.</p>&#xA;&#xA;<p>We totally want to avoid the parent POM way of handling it.</p>&#xA;"
47309649,MicroService path /api/v1/ or /v1/api/,<java><microservices><grizzly>,1,51,4,0.0,1,"<p>I'm building a MicroSerive and I was planning to publish services using this URI naming convention:</p>&#xA;&#xA;<pre><code>https://host:port/api/v1/service1&#xA;https://host:port/api/v1/service2&#xA;https://host:port/api/v2/service1&#xA;https://host:port/api/v2/service2&#xA;</code></pre>&#xA;&#xA;<p>But I've also seen URIs named like this (ie vx and api 'swapped'):</p>&#xA;&#xA;<pre><code>https://host:port/v1/api/service1&#xA;https://host:port/v1/api/service2&#xA;https://host:port/v2/api/service1&#xA;https://host:port/v2/api/service2&#xA;</code></pre>&#xA;&#xA;<p>In my opinion, the first approach is better. Are there any reasons to go for the second approach?</p>&#xA;"
47860278,Best practice to share domain model between two microservices,<microservices>,1,376,3,0.0,1,"<p>Are there any best practices or guidelines on how to share the domain model between two micro-services?</p>&#xA;&#xA;<p>I have a micro-service (1) which provides end points to interact with a resource (e.g, Order) all CRUD and the other micro-service (2) which performs a specific non CRUD task on the resource (Order). The micro-service (2) almost needs all the order attributes to perform its operation. In this case, does it make sense to create a common shared lib of the domain model and share between the two services? I could technically combine 1 and 2 together but the micro-service (2) needs to support scalability as it is quite memory and CPU intensive.</p>&#xA;"
49606124,Neo4J In Microservices Architecture,<java><spring><neo4j><microservices><spring-data-neo4j-5>,4,176,0,0.0,1,"<p>To keep in line with DDD and Bounded Contexts, its well known that when you create your microservices you should keep separation of concerns.</p>&#xA;&#xA;<p>One of the main benefits of Neo4J is keeping your ""connected"" data in Neo4J so relationships between them are efficiently queried.</p>&#xA;&#xA;<p>These two opposing forces seem to make an microservice architecture decision difficult when choosing to use Neo4J.</p>&#xA;&#xA;<p>Do you have multiple microservices connect to Neo4J db and persist their own domain accordingly?</p>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<p>Do you have one microservice with a db connection to Neo4J that controls persistance and querying?</p>&#xA;&#xA;<p>Both dont seem quite right...</p>&#xA;"
49469599,Authentication and authorisation in microservice architecture,<authentication><jwt><graphql><microservices><go-micro>,1,322,2,2.0,1,"<p>I have multiple services:</p>&#xA;&#xA;<ul>&#xA;<li>User</li>&#xA;<li>Post</li>&#xA;<li>Comment</li>&#xA;<li>Authentication</li>&#xA;<li>GraphQL endpoint</li>&#xA;</ul>&#xA;&#xA;<p>And lets say they are connected together like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GAyiV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GAyiV.png"" alt=""example 1""></a></p>&#xA;&#xA;<p>All services are communicating through gRPC on a closed nettwork and the Authorization is done using jwt tokens</p>&#xA;&#xA;<p>Approach 1:&#xA;The graphql service is responsible for user authentication and making sure that the user is authorised to run the specified procedure. There is no user authentication between the services, but there is TLS authentication. There is no authorisation checks done by the services.</p>&#xA;&#xA;<p>Approach 2:&#xA;Each individual service makes sure that the user is authorised to run a specific procedure. An example could be voting on a post where you wold need to be signed in and have over 15 in reputation. Here it would be the Post service responsibility to check whether the user is signed in or not (authenticated) and whether it's authorised to vote. This will result in large overhead since every procedure call needs to check user authentication and authorisation through the Auth service. </p>&#xA;&#xA;<p>Is there a better approach that still preserves the security of approach 2, but creates a small overhead like approach 1?</p>&#xA;&#xA;<p><strong>-----Update-----</strong></p>&#xA;&#xA;<p>Approach 3:&#xA;Same as approach 2, but user authentication is only done in the GraphQL service using the Auth service. Authorisation is done by checking metadata passed arround. And there is TLS authentication between the services. </p>&#xA;"
49580394,sending millions of short messages over tcp socket in golang,<go><tcp><microservices>,1,324,2,2.0,1,"<p>I'm writing two services in golang that need to send to each other about 2 million messages per second. Each message is about 50 bytes, so throughput should only be about 100MB/s. I want to use tcp for this. However, results are very slow. I configured SetNoDelay(false) to make sure that data is buffered before sending, but that didn't make any difference. </p>&#xA;&#xA;<p>I can only send about 50k messages per second, and message size doesn't matter too much, so I assume the code is blocking somewhere. Here's my test code:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import ""net""&#xA;import ""fmt""&#xA;import ""bufio""&#xA;import (&#xA;    //""strings""&#xA;    ""time""&#xA;)&#xA;&#xA;func startserver() {&#xA;    fmt.Println(""Launching server..."")&#xA;    ln, _ := net.Listen(""tcp"", "":8081"")&#xA;    conn, _ := ln.Accept()&#xA;&#xA;    for {&#xA;        bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Println(message)&#xA;        //newmessage := strings.ToUpper(message)&#xA;        //conn.Write([]byte(newmessage + ""\n""))&#xA;    }&#xA;}&#xA;&#xA;func startclient() {&#xA;    time.Sleep(time.Second) // so that server has time to start&#xA;    servAddr := ""127.0.0.1:8081""&#xA;    tcpAddr, _ := net.ResolveTCPAddr(""tcp"", servAddr)&#xA;    conn, _ := net.DialTCP(""tcp"", nil, tcpAddr)&#xA;    conn.SetNoDelay(false)&#xA;    conn.SetWriteBuffer(10000)&#xA;    msg := ""abc\n""&#xA;    start := time.Now()&#xA;    for i := 0; i &lt; 1000000; i++ {&#xA;        conn.Write([]byte(msg))&#xA;        //bufio.NewReader(conn).ReadString('\n')&#xA;        //fmt.Print(""Message from server: "", response)&#xA;    }&#xA;    fmt.Println(""took:"", time.Since(start))&#xA;}&#xA;&#xA;func main() {&#xA;    go startserver()&#xA;    startclient()&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestion?</p>&#xA;"
49637598,"Getting an error ""Cause: AMQ119031: Unable to validate user"" in Spring-Boot app",<spring-boot><microservices><spring-jms><jboss-eap-7><activemq-artemis>,1,167,3,0.0,1,"<p>I'm getting the following error when trying to connect to ActiveMQ Artemis Queue deployed on JBoss EAP 7.1. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: DefaultMessageListenerContainer: Could not refresh JMS&#xA;  Connection for destination 'jms/queue/QueueA' - retrying using&#xA;  FixedBackOff{interval=5000, currentAttempts=139,&#xA;  maxAttempts=unlimited}. Cause: AMQ119031: Unable to validate user</p>&#xA;</blockquote>&#xA;&#xA;<p>Here is the code I'm using:</p>&#xA;&#xA;<pre><code>@Bean public DefaultMessageListenerContainer myFactory() throws NamingException { &#xA;   DefaultMessageListenerContainer listenerContainer = new DefaultMessageListenerContainer();&#xA;   listenerContainer.setConnectionFactory(getConnectionFactory());&#xA;   listenerContainer.setDestinationName(""jms/queue/QueueA"");&#xA;   listenerContainer.setMessageListener(new MessageReceiver());&#xA;   return listenerContainer; &#xA;}&#xA;&#xA;private ConnectionFactory getConnectionFactory() throws NamingException { &#xA;   final Properties env = new Properties();&#xA;   env.put(Context.INITIAL_CONTEXT_FACTORY, org.wildfly.naming.client.WildFlyInitialContextFactory); &#xA;   env.put(Context.PROVIDER_URL, ""http-remoting://localhost:8080""); &#xA;   env.put(Context.SECURITY_PRINCIPAL, ""Username""); &#xA;   env.put(Context.SECURITY_CREDENTIALS, ""Password""); &#xA;   InitialContext ic = new InitialContext(env); &#xA;   return (ConnectionFactory) ic.lookup(""jms/RemoteConnectionFactory"");&#xA;}&#xA;</code></pre>&#xA;"
49610008,Swagger with spring boot microservice,<spring-boot><filter><swagger><microservices><swagger-ui>,1,98,5,0.0,1,<p>I have a <strong>microservice-A</strong> which gets the token as a header from another <strong>microservice-B</strong>. Now I want to implement <strong>swagger2 in microservice-A</strong>. The problem is every request <strong>flows through microservice-B</strong>. So <strong>swagger-ui throws error</strong> in local as </p>&#xA;&#xA;<blockquote>&#xA;  <p>it is not able to get those header parameter which microservice-B is&#xA;  trying to fetch.</p>&#xA;</blockquote>&#xA;
38460678,Architecture Microservices Jhipster,<java><jwt><jhipster><microservices>,1,1781,0,0.0,1,"<p>I want to start an architecture with microservices of Jhipster but I have doubts.&#xA;I have 4 pieces.</p>&#xA;&#xA;<ul>&#xA;<li>""HR"" &lt;- front and backend application</li>&#xA;<li>""SELECTION"" &lt;- front and backend application</li>&#xA;<li>Validation &lt;- Only one database for all front</li>&#xA;<li>Customers &lt;- is shared between ""HR"" and ""SELECT"" back in front in microservice and ""HR"" and ""SELECT"".</li>&#xA;</ul>&#xA;&#xA;<p>Both applications must be validated against the same database (JWT).&#xA;Both applications must share a microservicio ""CUSTOMER"" which will have the backend, but the front will be in each of the two applications.</p>&#xA;&#xA;<ul>&#xA;<li>1 - ""HR"" It would be a gateway?</li>&#xA;<li>2 - ""SELECTION"" It would be a gateway?</li>&#xA;<li>3 - How to implement security that is both against the same database (JWT) validated</li>&#xA;<li>4 - ""CUSTOMER"" It would be a microservicio?</li>&#xA;</ul>&#xA;&#xA;<p>Sorry for my English.</p>&#xA;"
47630168,Inter-service communication with Spring Boot and OAuth2,<spring><oauth-2.0><microservices>,2,691,0,1.0,1,"<p>I am working on a micro-service architecture using Spring Boot. We have implemented OAuth2 in a Auth Server. </p>&#xA;&#xA;<p>My question is - If two microservices want to communicate what should be the best way?</p>&#xA;&#xA;<p>As of now, I have discovered below options:</p>&#xA;&#xA;<ol>&#xA;<li><p>If each microservice is verifying the token then we can pass the same token. But the problem is - in between same token can be expired.</p></li>&#xA;<li><p>If we use client_credentials grant then there we are having two issues: one is, we need to send the username in next microservice. Another one is, we need to request two times - first for getting the access token, next for actual call.</p></li>&#xA;<li><p>If we do the token verification in API gateway only (not in microservices) then from the API gateway we need to send the username in every microservices. And microservices implementation needs to be changed to accept that param/header.</p></li>&#xA;</ol>&#xA;&#xA;<p>Please suggest which option should I pick and if there is any better option please let me know.</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
47656406,"Are all the classes containing business logic, domain objects?",<domain-driven-design><microservices><business-logic>,3,116,2,0.0,1,"<p>So I have few doubts regarding calling something as domain object (and eventually placing the class under domain package) or not.</p>&#xA;&#xA;<p>I have a micro-service whose responsibility is to do some calculations (without getting into actual business requirements, all it does is calculate some return of intereset based on given request). Now to achieve the calculations there are certain sub-calculations which need to take place and hence are composed in different classes respectively. But yes, these calculation do not need to be persisted in DB , and neither they have an ID (so definitely not an Entity or Aggregate). However these individual calculator classes (for the lack of terminology) do contain some complex business logic. Now, my question is, do these individual classes still qualify/classify as domain objects or should they be referred to as services ?</p>&#xA;&#xA;<p>Feel free to ask for more clarifications around use case if need be. </p>&#xA;&#xA;<p>Cheers ! </p>&#xA;"
48251083,Deploying Spring boot application in AWS lambda,<java><spring-boot><aws-lambda><microservices>,2,2243,0,0.0,1,"<p>I have an existing web application built in Javascript, Spring Boot and MySQL. I want to deploy the application (frontend + backend) in AWS Lambda. Please advise how can this be achieved, as I am not sure how each restful API call should be mapped to API gateway, that will in turn invoke the lambda functions (which should be the existing java methods from RestConroller).</p>&#xA;&#xA;<p>Thanks and appreciate your advise.</p>&#xA;"
48271493,Relation of Microservices and DDD CQRS and ES,<domain-driven-design><microservices>,3,206,2,0.0,1,"<p>For the last couple of weeks I've been starting and trying to understand DDD CQRS, ES and Microservices. &#xA;I think I've understood them individually but not as a single unit so this is why I have some misunderstandings that I hope to clarify.</p>&#xA;&#xA;<p>So first what is the relation between Microservices and DDD, can you do one without the other?&#xA;And secondly, does Bounded Contexts translate in the end into a microservice ?</p>&#xA;"
51520654,Distributed transactions in microservices,<microservices><distributed-transactions><saga>,3,55,0,0.0,1,"<p>I have 2 microservices <code>S1</code> and <code>S2</code>. <code>S1</code> invokes <code>S2</code> to update a data and then <code>S1</code> inserts another data,But let's consider <code>S1</code> fails,Then we need to rollback the data updated by <code>S2</code> or else we'll be in inconsistent state.</p>&#xA;&#xA;<p>I also gone through Saga patterns.will it satisfy this inconsistency</p>&#xA;&#xA;<p>Can anyone suggest any better solutions for this?</p>&#xA;"
43132158,How to apply different policies to service and proxy service?,<mule><microservices>,4,213,0,0.0,1,"<p>I have a mule service, named IS, deployed on mule runtime and proxied on API gateway. I'd like to set up different policies to the IS and its proxy service. How can I do it?</p>&#xA;&#xA;<p>My environment:</p>&#xA;&#xA;<ul>&#xA;<li>Mule runtime: 3.7.4</li>&#xA;<li>Mule API gateway: 2.1.1</li>&#xA;</ul>&#xA;"
51993175,org.springframework.web.client.ResourceAccessException: I/O error on GET request for in Microservices,<spring><spring-boot><microservices>,2,49,5,1.0,1,"<p>I am developing microservices code from the link : <a href=""https://github.com/sivaprasadreddy/spring-boot-microservices-series"" rel=""nofollow noreferrer"">https://github.com/sivaprasadreddy/spring-boot-microservices-series</a>. In this code base, I was successfully able to start the services like <code>""config-service""</code>, <code>""service-registry""</code>, <code>""shoppingcart-ui""</code>, <code>""zipkin-server""</code> etc, but when I tried to start the <code>""inventory-service""</code>, I got the below error. </p>&#xA;&#xA;<p><strong>Error below for reference:-</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8200/v1/secret/inventory-service"": Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:732) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:332) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.lambda$doRead$1(VaultTemplate.java:320) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doWithSession(VaultTemplate.java:307) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doRead(VaultTemplate.java:317) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.read(VaultTemplate.java:212) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.doGetSecrets(SecretLeaseContainer.java:545) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.start(SecretLeaseContainer.java:357) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.addRequestedSecret(SecretLeaseContainer.java:316) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.loadProperties(LeaseAwareVaultPropertySource.java:147) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.&lt;init&gt;(LeaseAwareVaultPropertySource.java:133) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:151) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:88) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.doCreatePropertySources(VaultPropertySourceLocatorSupport.java:170) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.createCompositePropertySource(VaultPropertySourceLocatorSupport.java:145) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.locate(VaultPropertySourceLocatorSupport.java:116) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94) [spring-cloud-context-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:636) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:376) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:328) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.sivalabs.inventoryservice.InventoryServiceApplication.main(InventoryServiceApplication.java:12) [classes/:na]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_162]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;</code></pre>&#xA;&#xA;<p><strong>I updated parent pom version to 2.0.4.RELEASE.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N574F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N574F.png"" alt=""enter image description here""></a></p>&#xA;"
48482639,Node.js REST API wrapper for async messaging,<node.js><rest><express><asynchronous><microservices>,3,130,3,1.0,1,"<p>Given an event driven micro service architecture with asynchronous messaging, what solutions are there to implementing a 'synchronous' REST API wrapper such that requests to the REST interface wait for a response event to be published before sending a response to the client?</p>&#xA;&#xA;<p>Example: POST /api/articles</p>&#xA;&#xA;<p>Internally this would send a CreateArticleEvent in the services layer, eventually expecting an ArticleCreatedEvent in response containing the ID of the persisted article.</p>&#xA;&#xA;<p>Only then would the REST interface response to the end client with this ID.</p>&#xA;&#xA;<p>Dealing with multiple simultaneous requests - is keeping an in-memory map of inflight requests in the REST api layer keyed by some correlating identifier conceptually a workable approach?</p>&#xA;&#xA;<p>How can we deal with timing out requests after a certain period?</p>&#xA;"
48743223,Sharing domain model classes (Aggregates) across two microservices,<domain-driven-design><microservices>,1,138,3,0.0,1,"<p>Based on my limited knowledge, microservice can be designed at bounded context level or Aggregate level.</p>&#xA;&#xA;<p>If microservices are created at aggregate level, they might need to refer to an aggregate created in other microservices (as they share the same bounded context).</p>&#xA;&#xA;<p>Should we create the same aggregate multiple times in each microservice (if required)? Or there can never be a case, where we need to use one aggregate into other?</p>&#xA;"
48792602,Persistence layer as microservices?,<spring-boot><microservices><netflix-eureka>,3,251,3,0.0,1,"<p>I'm a beginner in microservice architecture and I have read in a lot of blog that in a microservice architecture, it is mandatory that each micro service has its own database. In my case it may cost very expensive. </p>&#xA;&#xA;<p>My question is, is it possible to make the persistence layer as micro service in itself ? Which would have the function of allowing other microservices to have read/write access to the database.&#xA;Thanks</p>&#xA;"
37897876,Vert.x how to pass/get messages from REST to message bus?,<java><rest><microservices><vert.x>,2,1175,0,0.0,1,"<p>I want to pass messages to bus via REST, and get it back. But I cant correctly setup the message bus receiver, it throws <code>java.lang.IllegalStateException</code>: Response has already been written. In real life message bus should receive messages from different sources and pass a message to another target. Therefore we just need to publish the message to the bus. But how to correctly read messages and handle all of them? For example from a REST interface: read that messages!&#xA;My simple app start:</p>&#xA;&#xA;<pre><code> public static void main(String[] args) {&#xA;        Vertx vertx = Vertx.vertx();&#xA;        vertx.deployVerticle(new RESTVerticle());&#xA;        vertx.deployVerticle(new Receiver());&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.registerDefaultCodec(MessageDTO.class, new CustomMessageCodec());&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>REST part</p>&#xA;&#xA;<pre><code>public class RESTVerticle extends AbstractVerticle {&#xA;&#xA;    private EventBus eventBus = null;&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        Router router = Router.router(vertx);&#xA;        eventBus = vertx.eventBus();&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.post(""/api/message"").handler(this::publishToEventBus);&#xA;       // router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9999);&#xA;        System.out.println(""Service running at 0.0.0.0:9999"");&#xA;&#xA;    }&#xA;&#xA;private void publishToEventBus(RoutingContext routingContext) {&#xA;        System.out.println(""routingContext.getBodyAsString() "" + routingContext.getBodyAsString());&#xA;        final MessageDTO message = Json.decodeValue(routingContext.getBodyAsString(),&#xA;                MessageDTO.class);&#xA;&#xA;        HttpServerResponse response = routingContext.response();&#xA;        response.setStatusCode(201)&#xA;                .putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                .end(Json.encodePrettily(message));&#xA;&#xA;        eventBus.publish(""messagesBus"", message);&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>And the Receiver: I move it to a different class, but it does not help</p>&#xA;&#xA;<pre><code>public class Receiver extends AbstractVerticle {&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        Router router = Router.router(vertx);&#xA;&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9998);&#xA;        System.out.println(""Service Receiver running at 0.0.0.0:9998"");&#xA;&#xA;private void getMessagesFromBus(RoutingContext routingContext) {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.consumer(""messagesBus"", message -&gt; {&#xA;            MessageDTO customMessage = (MessageDTO) message.body();&#xA;            HttpServerResponse response = routingContext.response();&#xA;            System.out.println(""Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "" + customMessage);&#xA;            if (customMessage != null) {&#xA;                response.putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                        .end(Json.encodePrettily(customMessage));&#xA;            }&#xA;            response.closed();&#xA;&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So if i post message to REST and handler publish it to the bus, when I am runtime get <a href=""http://localhost:9998/api/messagelist"" rel=""nofollow"">http://localhost:9998/api/messagelist</a>  it is return json, but second time it trow exception</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Response has already been written&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.checkWritten(HttpServerResponseImpl.java:561)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:154)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:52)&#xA;    at com.project.backend.Receiver.lambda$getMessagesFromBus$0(Receiver.java:55)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handleMessage(HandlerRegistration.java:207)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handle(HandlerRegistration.java:201)&#xA;    at io.vertx.core.eventbus.impl.EventBusImpl.lambda$deliverToHandler$127(EventBusImpl.java:498)&#xA;    at io.vertx.core.impl.ContextImpl.lambda$wrapTask$18(ContextImpl.java:335)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:358)&#xA;    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;&#xA;Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Message{username=Aaaewfewf2d, message=41414wefwef2d2}&#xA;</code></pre>&#xA;&#xA;<p>How to correctly get all messages from the receiver? Or if the bus received messages, should I immediately store them to the db? Can a message bus keep messages and not lost them?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37801454,Is there a way to implement SSO in front of the microservices?,<go><single-sign-on><cas><microservices><beego>,1,1127,5,1.0,1,"<p>Recently I have a project to implement <a href=""https://en.wikipedia.org/wiki/Single_sign-on"" rel=""nofollow noreferrer"">SSO(Single-Sign-On)</a> for multiple web applications based on <a href=""http://beego.me/"" rel=""nofollow noreferrer"">Beego Framework</a>. The most popular SSO project is <a href=""https://en.wikipedia.org/wiki/Central_Authentication_Service"" rel=""nofollow noreferrer"">CAS</a>, which needs a CAS Server in the center, and a CAS Client before each web application. Unfortunately, it seems that there's not any offical CAS clients written in Golang, except <a href=""https://github.com/go-cas/cas"" rel=""nofollow noreferrer"">go-cas/cas</a>, and <a href=""https://github.com/adanteng/cas"" rel=""nofollow noreferrer"">adanteng/cas</a>, which supports Beego.</p>&#xA;&#xA;<p>But the workflow of CAS is a little bit complicated: too many redirections, too many tickets transmitted among the CAS, web apps, and the user browser. I can't figure out why people deploy the Authentication Services in the center of all the web apps, rather than the front, like the following diagram:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/aqOmDm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aqOmDm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In this diagram, all the requests are forced to be processed in the Authenticate Service first, if authenticated successfully, then generate a session ID, saved in the cookies and Redis which is shared by other microservices. There's not any redirections or tickets at all, only requests transmittion.</p>&#xA;&#xA;<p>So is this diagram possible, or some critical problems I ignored?</p>&#xA;&#xA;<h1>Update 0</h1>&#xA;&#xA;<p>The session-sharing way is indeed not scalable and modular as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> counsels. How about transmitting user information, like name, email, etc., in the headers of requests between the auth service and downstream services, like the creative work of Heipei at <a href=""https://heipei.github.io/2015/09/23/nginx-sso-Simple-offline-SSO-for-nginx/"" rel=""nofollow noreferrer"">nginx-sso</a>? Is it possible to make it work as an SSO Gateway as Sam Newman sharing in the book <a href=""http://samnewman.io/books/building_microservices/"" rel=""nofollow noreferrer"">Building Microservices</a>?</p>&#xA;&#xA;<h1>Update 1</h1>&#xA;&#xA;<p>A more detailed diagram is shown as follows, in order to describe my childish idea a little bit clearly, hoping that there is not much misunderstanding from Heipei and Sam Newman. </p>&#xA;&#xA;<p>Rather than handling so many redirections and handshakes, all the requests are processed in the authentication service firstly, which writes user info from MySQL, into the Redis as the session provider, and the HTTP header to transmit to the downstream services, if the request is authenticated successfully.</p>&#xA;&#xA;<p>In this way, the user info is transmitted via HTTP header instead of the above shared-Redis as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> warning, and Redis can be depolyed with the auth service, or shared among auth instances only.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BeMFF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BeMFF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<h1>Update 2</h1>&#xA;&#xA;<p>It seems that Cookie and Session are old-school techs. The cross-domain problem of cookie, and the sharing problem of session are the primary barrier to the scalability and flexibility of the modern web applications. Fortunately, JSON Web Token comes to be the best Single Sign-on solution for multiple lightweight services nowadays, by moving the user info(maybe id is enough) storage from the server side to the client side, and transmitted only if necessary.</p>&#xA;"
40737349,Right place to do the service composition in API world?,<microservices><aws-api-gateway><apigee><kong>,3,515,0,0.0,1,"<p>I am working in an environment where API is becoming a by default standard and we have a lot of micro services available... but still not able to meet the requirement of my customers...</p>&#xA;&#xA;<p>My customer demands a mix and match of data which I need to offer by writing new compositions and further host them as services.... </p>&#xA;&#xA;<p>1) What is the right platform to do this composition, gateways or host them on a dedicated paas instances?</p>&#xA;&#xA;<p>2) The moment I start going for composition, I end up paying for http overhead compared to get data directly from database</p>&#xA;&#xA;<p>Any help will be helpful</p>&#xA;"
40564979,Host WepAPI on Service Fabric,<c#><asp.net-web-api><microservices><azure-service-fabric><devops>,3,755,0,1.0,1,"<p>We just stood up an on-premise MS Service Fabric cluster.  I have some WebAPI's i'd like to host in it.  I'm looking for resources on how to take our standard 4.5 WebAPI's and host them in Service Fabric without have to create a Service Fabric project and migrate it; that just seems too complex.</p>&#xA;&#xA;<p>I looked at some of the Service Fabric sample projects, and it seems all the projects are tightly coupled with Service Fabric.  My goal is keep these apps unaware of Service Fabric.</p>&#xA;&#xA;<p>Any links of information is greatly appreciated, thanks!</p>&#xA;"
43870576,Batch - Get Requests from different Microservices,<rest><get><microservices>,2,368,3,0.0,1,"<p>I am dividing a monolithic service to a microservice architecture. What I have done is separate the services and now the REST call is distributed but the problem is if I call a <code>service A</code> which returns 10000 instances and it is dependent on some other <code>service B</code>, so call comes to <code>service A</code> and for each instance, call goes to <code>service B</code> to get its data, so converting a single call to 10000 additional calls so now the call takes alot of time. </p>&#xA;&#xA;<p>I want to make multiple Get Requests in a single request. </p>&#xA;&#xA;<p>What I have searched is to use batch requests to POST different instances, but this is recommended on Creating &amp; Updating multiple instances together. Can this be done for getting information as well? </p>&#xA;&#xA;<p>And is there any other way to do it?</p>&#xA;&#xA;<p>Edit: A similar use case as to mine e.g. There are two services one service gets the details of students and the other gets the details of teachers. In teachers table there is student's ID that it teaches not as a foreign key but a simple key, Now in the UI for the teacher, it shows the teacher details and the student ID and student names and class it belongs to, so for getting the student name and class details, I would have to call the student's service with the student's ID.</p>&#xA;"
43910795,Microservices async operation HTTP response,<http><asynchronous><architecture><microservices><event-driven>,1,182,9,1.0,1,"<p>We're building a microservice app where clients can create <em>projects</em>. The following diagram shows the technical flow of this process:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/UWDMy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UWDMy.png"" alt=""Create Project Flow""></a></p>&#xA;&#xA;<p>My question: <strong>what HTTP response should the API gateway return to the client (step 1.)?</strong> </p>&#xA;&#xA;<p>My initial idea was to give back a 202, but the problem there is that I don't know the <code>Location</code> yet (<code>/projects/{id}</code>), because the id of the <em>project</em> will be created at the Project Management Service.</p>&#xA;"
43440170,ReflectionTestUtils.setfield is not overriding the local project property attribute,<java><spring><microservices>,3,438,0,0.0,1,"<p>I am struggling with how to override a property file inside a .yml file</p>&#xA;&#xA;<p>We use the Spring framework and use annotations (eg. @InjectMocks).</p>&#xA;&#xA;<p>I have a an attribute declared in a configuration project YML file called ""one-platform-properties"" called paysafe-ss-fx-service.yml.  It sets a variable called <code>maxRecoveryAge=0</code>.  It is essentially a time to live buffer.</p>&#xA;&#xA;<pre><code>  oneplatform:&#xA;  environment: local&#xA;publisher:&#xA;  rates:&#xA;    maxRecoveryAge: 0&#xA;    interPublishDelay: 500&#xA;</code></pre>&#xA;&#xA;<p>The problem is that I want to be able to adjust this at run time in my tests.  Make the buffer to 1 hour, 5 hours and 24 hours.</p>&#xA;&#xA;<p>I am using the <code>ReflectionTestUtils.setfield(PublisherClass, ""maxDocumentAge"", 1, int.class)</code> call in my tests to adjust the timing, but the value is not being overridden.  When I do a watch on the variable it is working in my test harness, but once the test run penetrates into the micro service code, the overridden value is lost.  Any ideas on how to have the overridden value persist throughout all the tests?</p>&#xA;&#xA;<p>My goal is to use different variations on my test run:</p>&#xA;&#xA;<pre><code>ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",1,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",5,int.class);&#xA;ReflectionTestUtils.setField(new FxRatesEventPublisher(),""maxRecoveryAge"",24,int.class);&#xA;</code></pre>&#xA;&#xA;<p>and essentially override the value as defined in the project defined properties file.</p>&#xA;"
42528718,CQRS + Microservices: How to handle relations / validation?,<validation><relationship><one-to-many><microservices><cqrs>,3,462,0,0.0,1,"<p><strong>Scenario:</strong></p>&#xA;&#xA;<ul>&#xA;<li>I have 2 Microservices (which both use CQRS + Event Sourcing internally)</li>&#xA;<li>Microservice 1 manages Contacts (= Aggregate Root)</li>&#xA;<li>Microservice 2 manages Invoices (= Aggregate Root)</li>&#xA;</ul>&#xA;&#xA;<p>The recipient of an invoice must be a valid contact. </p>&#xA;&#xA;<p><strong>CreateInvoiceCommand:</strong></p>&#xA;&#xA;<pre><code>{&#xA;  ""content"": ""my invoice content"",&#xA;  ""recipient"": ""42""&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>I now read lot's of times, that the write side (= the command handler) shouldn't call the read side.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Taking this into account, the Invoices Microservice must listen to all <code>ContactCreated</code> and <code>ContactDeleted</code> events in order to know if the given recipient id is valid.</p>&#xA;&#xA;<p>Then I'd have thousands of Contacts within the Invoices Microservice, even if I know that only a few of them will ever receive an Invoice.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Is there any best practice to handle those scenarios?</p>&#xA;"
42478361,How to login to Microservices ui app using jhipster,<jhipster><microservices>,1,383,4,0.0,1,"<p>I am creating a <code>jhipster</code> application using microservices. I have created JHipster Registry, UAAserver, 2 microservices calling 2 Ui apps on 2 different url. Have added entities in 2 UI apps, using Mongodb for database. Have run all the above JHipster Registry, UAAserver, 2 microservices, 2 Uiapp's and i am able to see all running in Jhipster registry and tables being created in Mongodb but when i try to login to Uiapp1 or UiApp2 its throwing </p>&#xA;&#xA;<blockquote>&#xA;  <p>XMLHttpRequest cannot load <a href=""http://192.168.0.10:9999/login"" rel=""nofollow noreferrer"">http://192.168.0.10:9999/login</a>. No 'Access-Control-Allow-Origin' header is present on the requested resource. &#xA;  Origin '<a href=""http://192.168.0.10:8084"" rel=""nofollow noreferrer"">http://192.168.0.10:8084</a>' is therefore not allowed access.</p>&#xA;</blockquote>&#xA;"
42539505,How to get sorted data from one service to another over http,<microservices><api-design>,2,313,6,1.0,1,"<p>I have service oriented architecture with couple services.</p>&#xA;&#xA;<ul>&#xA;<li><p>Product  - store list of products</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   price: number&#xA;}</code></p></li>&#xA;<li><p>Categories   - store category information + the list of product ids</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   parentCategory: number,&#xA;   productIds: number[]&#xA; }</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Lets assume that I have such category instance</p>&#xA;&#xA;<pre><code>{&#xA;   id: 1,&#xA;   parentCategory: null,&#xA;   productIds: [1, 3, 4, 5, ....]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I need to get 10 products from the category above sorted by product price. </p>&#xA;&#xA;<p>Category service processes that request and because it doesn't know anything about the price it has to make the request to Product service like that: </p>&#xA;&#xA;<pre><code>/api/products?&#xA;   ids=&lt;list of all product ids&gt;&#xA;   limit=10&#xA;   sortBy=price&#xA;</code></pre>&#xA;&#xA;<p>which won't work well when the category has a lot of products.</p>&#xA;&#xA;<p>What is the recipe in such case? &#xA;Thanks.</p>&#xA;"
38466167,Microservice in Google App engine,<python><google-app-engine><google-cloud-platform><microservices>,1,730,8,0.0,1,"<p>I plan to switch from a single app on a project to multiple apps on a project.&#xA;One being the current non-UI app and one will be based on Django.&#xA;I'm writing the code in Python2.7</p>&#xA;&#xA;<p>I saw google example of app.yaml, but there is no examples for 2 or more apps.&#xA;There is already a similar question. but still with no example (<a href=""https://stackoverflow.com/questions/38125926/run-google-app-engine-application-with-microservice"">Run Google App Engine application with microservice</a>)</p>&#xA;&#xA;<p>How do i call Django microservice/module and how do i call the other app (microservice/module)?</p>&#xA;&#xA;<p>My current structure is:</p>&#xA;&#xA;<pre><code>main_app directory&#xA;- dj (django app)&#xA;-- dj.yaml&#xA;-- manage.py&#xA;-- __init__.py (empty)&#xA;-- polls (from django tutorial)&#xA;-- mysite (from django tutorial)&#xA;- otherapp&#xA;-- otherapp.yaml&#xA;-- something.py&#xA;- app.yaml&#xA;- cron.yaml&#xA;</code></pre>&#xA;&#xA;<p>Here is a part of my app.yaml (that should control both apps):</p>&#xA;&#xA;<pre><code>runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;&#xA;handlers:&#xA;- url: /.*&#xA;  script: main.app&#xA;- url: /uploadcsv/.*&#xA;  script: main.app&#xA;&#xA;&#xA;libraries:&#xA;- name: MySQLdb&#xA;  version: ""latest""&#xA;</code></pre>&#xA;"
44186109,Share Domain DLL between webjob and web api?,<c#><azure><domain-driven-design><microservices>,1,208,4,0.0,1,<p>I use webjob to process messages queue and web API to process REST request.&#xA;What is the solution for share domain between this two application types that have the same bounded context? &#xA;Can I reference the same Domain DLL or it is a bad design choose?</p>&#xA;
45661006,What is the difference between Monolith and n Layer?,<architecture><microservices>,1,972,0,1.0,1,"<p>i have a few questions regarding <strong>monolith</strong> and <strong>n layer architecture</strong>.</p>&#xA;&#xA;<p>First, whats the difference between Monolith and n Layer architecture?</p>&#xA;&#xA;<p>Second, let's say I have a single Visual Studio solutions that consist of multiple projects such as:</p>&#xA;&#xA;<ol>&#xA;<li>Presentation Layer</li>&#xA;<li>Service Layer</li>&#xA;<li>Business Layer</li>&#xA;<li>Cross Layer</li>&#xA;<li>Data Layer</li>&#xA;<li>Unit Test</li>&#xA;</ol>&#xA;&#xA;<p>Is that considered as Monolith or n layer architecture?</p>&#xA;&#xA;<p>If I have microservices that consist (let's say) 3 Web API and I build each service in single separate Visual Studio solutions, <strong><em>it is ok</em></strong> to implement my previous project structure (service layer, business layer, data layer, etc)?</p>&#xA;&#xA;<p>Thank you very much and sorry for my bad english.</p>&#xA;"
45751211,Automated tests on contracts between microservices?,<c#><api><integration-testing><microservices><contract>,2,258,4,0.0,1,"<p>Say we have a CreditCardService microservice that depends on a ThreeDSecureService microservice, communicating using JSON.</p>&#xA;&#xA;<p>Minor changes in the API (or even implementation) of the ThreeDSecureService could silently break the CreditCardService (and other potential clients). So, we would like automated tests.</p>&#xA;&#xA;<p>I see two flawed approaches, and am wondering how to improve.</p>&#xA;&#xA;<ol>&#xA;<li>Integration testing in ThreeDSecureService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The accompanying test project of ThreeDSecureService could have an integration test with a fixed JSON input. Faking out any dependencies, it could run an otherwise complete call for that input, confirming that the service swallows the input.</p>&#xA;&#xA;<p>The problem here is that if someone fails to realize how their changes could break clients, they are almost as likely to 'fix' the tests to match their changes.</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Integration testing in CreditCardService.Tests.</li>&#xA;</ol>&#xA;&#xA;<p>The <em>client</em> is the one that actually wants to test assertions about ThreeDSecureService's expected input. However, that would require the client solution to include the ThreeDSecureService project, as well as any projects it depends on. This would negate many of the advantages we get from using microservices!</p>&#xA;&#xA;<p><strong>How do we make assertions from the client (safeguarding the dependency) without breaking the loose coupling we get from using microservices?</strong></p>&#xA;"
45673863,Communication between Spring microservices,<java><spring><api><spring-mvc><microservices>,2,664,4,0.0,1,"<p>I am still learning microservices and I am asking myself, how do we secure our rest-points? I use the famous framework Spring Boot which extends from Spring. What is the best or most used pattern to secure the endpoints of a rest API?</p>&#xA;&#xA;<p>When I use Spring Security with oAuth2, I always need to send the credentials in the body of the request. Is there an approach without the credentials and which is easier to implement? Like API-Tokens?</p>&#xA;&#xA;<p>I always prefer practical tutorials.</p>&#xA;"
45642575,microservices or SOA: how to respond one specific request,<architecture><soa><microservices>,2,137,5,0.0,1,"<p>I am interested in microservices and SOA. I read some tutorials. This is my understanding SOA. The API gateway receives lots of requests (requestA, requestB, ...) and put requests in messaging queues. Micro-services will consume the events in the messaging queues and do some processing. My question is after processing, how the response can be returned to requests (responseA to requestA, responseB to requestB).</p>&#xA;&#xA;<p>I am not sure whether my understanding is right or wrong and whether messaging is used in every architecture. </p>&#xA;&#xA;<p>Anyone can give me more details/examples how to decouple/connect the API gateways and the microservices. How to respond to requests? should the connection between API gateways and clients kept alive?</p>&#xA;&#xA;<p>Sorry if my question is not clear. I am confused and have no idea how to understand each concept.</p>&#xA;&#xA;<p>Any comment welcomed. Thanks</p>&#xA;"
50889657,Microservice synchronous communication - service to service or message broker,<spring><spring-boot><apache-kafka><microservices>,2,53,0,2.0,1,"<p>I am developing a series of microservices using Spring Boot and Kafka. For asynchronous communication, I am using Kafka which is working well. </p>&#xA;&#xA;<p>I have a use case where I require synchronous communication between two microservices (a user registers a profile via the user profile service which needs to create an auth account in the auth microservice). </p>&#xA;&#xA;<p>Should I just call the auth service directly (service to service communication) or should I use Kafka?</p>&#xA;&#xA;<p>Any examples or best practise advice would be appreciated. </p>&#xA;"
50849415,What is the best way to do microservice REST API versioning?,<spring><rest><microservices><aws-api-gateway><api-versioning>,1,233,3,0.0,1,"<p>I'm developing this project using Spring and hosting in AWS EC2 instances. As few new requirements coming up, I have to change  my API contracts. But I don't want to break the current clients. So, I'm trying to implement some REST APIs with versioning. So that whenever I update the endpoints the consumer applications won't crash. But I'm confused on how to do the API versioning. I thought of two ways. </p>&#xA;&#xA;<ol>&#xA;<li><p>Create a next version endpoint in the same server,(in spring using RequestMaping(""/v1/api1""),RequestMaping(""/v2/api1"") something like this.)</p></li>&#xA;<li><p>Other wise completely run the v2 APIs in new server instance but keep the same API endpoint footprint and use AWS APIGateway as a proxy and configure the versioning there, then route to old server and new server depending on the version number in the request.</p></li>&#xA;</ol>&#xA;&#xA;<p>But the first approach will lead to lot of code duplication and code management messy I believe. Because we are keeping the same functionality with variations.</p>&#xA;&#xA;<p>In the second approach I have to keep two set of instances for bot versions if me Version increases then It's hard to manage those instances, specially, when I will have around 15 micro-service instances. And it'll not be cost effective also. Because my company is a startup , so I need to consider this fact also.</p>&#xA;&#xA;<p>Is there any best practices regarding API versioning and managing multiple version of endpoints? I'm open for any suggestions and guidelines. If multiple server is the solution also, I'm open to reconsider the cost limitations. I need the best solution for this problem. </p>&#xA;"
50759872,Should I ignore the guidance and avoid putting validation in the command objects?,<c#><domain-driven-design><microservices>,1,95,12,0.0,1,"<p>I am using CQRS.  Everywhere I read tells me to put validation logic in the command objects.  For example, see this link: <a href=""https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/"" rel=""nofollow noreferrer"">https://lostechies.com/jimmybogard/2016/04/29/validation-inside-or-outside-entities/</a></p>&#xA;&#xA;<p>Please see the command below (taken from the link):</p>&#xA;&#xA;<pre><code>public class ChangeNameCommand { &#xA;   [Required] &#xA;   public string FirstName { get; set; } &#xA;   [Required] &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and the Business Object below (also taken from the link - note that I have changed the the parameter passed to the Customer constructor from a class to an interface):</p>&#xA;&#xA;<pre><code>public class Customer &#xA;{ &#xA;   public string FirstName { get; private set; } &#xA;   public string LastName { get; private set; } &#xA;&#xA;   public void ChangeName(IChangeNameCommand command) { &#xA;     FirstName = command.FirstName; &#xA;     LastName = command.LastName; &#xA;   } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>In my case the commands are stored in one class library and the business objects in others (because the commands are shared by multiple microservice type projects).  If I follow the guidance (and put the validation in the commands) then I believe there is nothing to stop a developer doing this:</p>&#xA;&#xA;<pre><code>public class ChangeNameCommandWithoutValidation : IChangeNameCommand { &#xA;   public string FirstName { get; set; } &#xA;   public string LastName { get; set; } &#xA; } &#xA;</code></pre>&#xA;&#xA;<p>and then passing the command (without the validation) to the domain object.  In this case I believe the Domain Object has no control what is passed to it?</p>&#xA;&#xA;<p>Therefore should I be going against all of the guidance I can find and do the validation in the domain object? I believe I should do this because the commands are in a separate class library to the domain objects.  Have I understood this correctly?</p>&#xA;&#xA;<p>I believe this question is also relevant when passing an event to the customer domain object (when using event sourcing).</p>&#xA;"
28114758,Microservices with spring integration and spring boot,<spring-boot><spring-integration><microservices>,2,2113,0,1.0,2,<p>I'm a bit new with microservices (and SI) and want to make a POC following a microservices architecture style. I've seen that I can use Spring Boot for deployment and SI for the development but found little docs about how to combine them (just an example in Spring Boot home page). Do you know about best practices or recommendations on how to combine this two technologies? </p>&#xA;
26706240,Why does 12factor recommend not to daemonize processes?,<12factor><microservices>,3,244,0,0.0,2,"<p><a href=""http://12factor.net/concurrency"" rel=""nofollow"">12factor recommends not to daemonize processes</a>. What are the disadvantages of doing so?</p>&#xA;"
30053782,"Microservice architecture, authentication and other services",<java><web-services><api><amqp><microservices>,1,648,0,0.0,2,"<p>I m studying the micro-services architecture, and I m have a question.</p>&#xA;&#xA;<p>Admitting that I have multiple services on different host like following :</p>&#xA;&#xA;<ul>&#xA;<li>Authentication service on <a href=""http://80.80.80.80:9000/"" rel=""nofollow"">http://80.80.80.80:9000/</a></li>&#xA;<li>Billing service on <a href=""http://90.90.90.90:1234/"" rel=""nofollow"">http://90.90.90.90:1234/</a></li>&#xA;<li>Planning service on <a href=""http://70.70.70.70:7412/"" rel=""nofollow"">http://70.70.70.70:7412/</a></li>&#xA;</ul>&#xA;&#xA;<p>My question is, when a user request on the gateway, he sends an access token (stateless, oauth2.0, whatever), then the gateway asks the authentication service, and if the user exists and has permissions, he access the ressources on another service.</p>&#xA;&#xA;<p>That's okay, but what if I try to call directly the BillingService from his host ? You can tell me that the port is closed, and I agree with that.</p>&#xA;&#xA;<p>But does it mean that they are port allowed only from a certain host to another ? Meaning that the billing service on port 1234 is allowed only from the gateway machine ?</p>&#xA;&#xA;<p>Am I missing something ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
30449278,Automation of releases of microservices-based application,<git><automation><release-management><salt-stack><microservices>,4,894,0,0.0,2,"<p>We are working on the application that consists of many standalone services. It has advantages over the single monolithic application, but not when we do releases.</p>&#xA;&#xA;<p>We do weekly release cycles. Each service/component located in the separate git repository. 'A release' - is several features that we put into wild. Usually only several components should be updated. We manage servers using saltstack. To make a release salt scripts update component's versions using git.latest state. The problem is to specify right versions.</p>&#xA;&#xA;<p>This is where the manual work that I'd like to automate. To update versions I have to manually check each component's repository, merge development branch into master and tag according to symantec versioning rules. Then I write new version in salt scripts. We have over 10 components so this is rather boring and error prone process.</p>&#xA;&#xA;<p>Probably we doing it wrong, I'll be glad to hear any advices how to do it better, thanks.</p>&#xA;"
31525237,how to get scope associated with access token in Spring OAuth while building microservices?,<spring><spring-security><oauth-2.0><microservices>,1,733,0,0.0,2,"<p>I am in the process of spinning up a <code>microservices</code> system with a central <code>Authorization Server</code> that grants <code>tokens</code> with different scopes for accessing individual micro-service.</p>&#xA;&#xA;<p>Here is the picture explaining the various service calls.&#xA;The numbers marked are requests made in the chronological order.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/8R9CP.png"" alt=""enter image description here""></p>&#xA;&#xA;<p><strong>1)</strong> In a nut-shell, I want the auth Server to return <code>access-token</code> with a User identifer (id) and scope when controller makes a login call. just like the following example taken from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow noreferrer"">spring tutorial</a> (but this is missing id). how can I have the id retured with the token returned?. I prefer not to make another REST call as proposed in the tutorial.</p>&#xA;&#xA;<pre><code>$ curl acme:acmesecret@localhost:9999/uaa/oauth/token  \&#xA;-d grant_type=authorization_code -d client_id=acme     \&#xA;-d redirect_uri=http://example.com -d code=jYWioI&#xA;{""access_token"":""2219199c-966e-4466-8b7e-12bb9038c9bb"",""token_type"":""bearer"",""refresh_token"":""d193caf4-5643-4988-9a4a-1c03c9d657aa"",""expires_in"":43199,""scope"":""openid""}&#xA;</code></pre>&#xA;&#xA;<p><strong>2)</strong> How does the photo Service which receives the access token in the ""Authorization bearer"" header checks with Auth Server to see the token is valid and it has the scope required to access the photo. (for example, if Auth Server responds back with list of scopes this token is eligible for, Post service can check among the list of scopes, if it can provide access).</p>&#xA;&#xA;<p><strong>3)</strong> on a side note, I see the <code>-d code=jYWioI</code> is passed in above the request, but not sure why it is passed and whats the purpose of it?</p>&#xA;"
50651256,microservices - is it one service per CRUD,<node.js><amazon-web-services><aws-lambda><microservices>,4,76,0,1.0,2,"<p>Very new to microservices...  </p>&#xA;&#xA;<p>If I have an API that deals with CRUD for customers and orders, does this translate to 2 microservices one for customers and one for orders?</p>&#xA;&#xA;<p><strong>Customer API</strong></p>&#xA;&#xA;<pre><code>CreateCustomer&#xA;ReadCustomer&#xA;UpdateCustomer&#xA;DeleteCustomer&#xA;</code></pre>&#xA;&#xA;<p><strong>Order API</strong></p>&#xA;&#xA;<pre><code>CreateOrder&#xA;ReadOrder&#xA;UpdateOrder&#xA;DeleteOrder&#xA;</code></pre>&#xA;"
50672490,What's the right way to gather data from different microservices?,<node.js><design><architecture><microservices>,2,64,1,2.0,2,"<p>I'm having a problem understanding how basic communication between microservices should be made and I haven't been able to find a good solution or standard way to do this in the other questions. Let's use this basic example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pOCGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pOCGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I have an invoice service that return <strong>invoices</strong>, every invoice will contain information(ids) about the user and the products. If I have a view in which I need to render the invoices for a specific user, I just make a simple request.</p>&#xA;&#xA;<pre><code>let url = ""http://my-domain.com/api/v2/invoices""&#xA;let params = {userId:1}&#xA;request(url,params,(e,r)=&gt;{&#xA;  const results = r // An array of 1000 invoices for the user 1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>Now, for this specific <strong>view</strong> I will need to make another request to get all the details for each product on each invoice.</p>&#xA;&#xA;<pre><code>results.map((invoice)=&gt;{&#xA;   invoice.items.map((itemId)=&gt;{&#xA;      const url=`http://my-domain.com/api/v2/products/${itemId}`&#xA;      request(url,(e,r)=&gt;{&#xA;       const product = r&#xA;       //Do something else.....&#xA;      });&#xA;   });&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>I know the code example is not perfect but you can see that this will generate a huge number of requests(at least 1000) to the product service and just for 1 user, now imagine if I have 1000 users making this kind of requests.</p>&#xA;&#xA;<p>What is the right way to get the information off all the products without having to make this number of requests in order to avoid performance issues?.</p>&#xA;&#xA;<p>I found some workarounds for this kind of scenarios such as:</p>&#xA;&#xA;<ol>&#xA;<li>Create an API endpoint that accepts a list of IDs in order to make a single request.</li>&#xA;<li>Duplicate the information from the Product service within the invoice service and find a way to keep them in sync.</li>&#xA;</ol>&#xA;&#xA;<p>In a microservices architecture are these the right ways to deal with this kind of issues? For me, they look like simple workarounds.</p>&#xA;&#xA;<p><strong><em>Edit #1: Based on Remus Rusanu response.</em></strong></p>&#xA;&#xA;<p>As per Remus recommendation, I decided to isolate my services and describe them a little bit better.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BHosb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BHosb.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>As shown in the image above the microservices are now isolated(in specific the Billing-service) and they now are the owners of the data. By using this structure I ensure that Billing-service is able to work even if there are async jobs or even if the other two services are down.</p>&#xA;&#xA;<p>If I need to create a new invoice, I can call the other two microservices(Users, Inventory) synchronously and then update the data on the ""cache"" tables(Users, Inventory) in my billing service.</p>&#xA;&#xA;<p>Is it also good to assume these ""cache"" tables are read-only? I assume they are since only the user/inventory services should be able to modify this information to preserve isolation and authority over the information.</p>&#xA;"
32996097,Single Sign On + Microservices,<java><spring><oauth-2.0><microservices>,1,654,0,2.0,2,"<p>I have a couple web apps which I will try to convert in microservices (In the future maybe I will have more). Before this, I would like to create a microservice for authentication and authorization which permits SSO.</p>&#xA;&#xA;<p>I read a lot about <a href=""http://jasig.github.io/cas/4.1.x/index.html"" rel=""nofollow"">CAS</a> but I have the feeling that seems an old solution and I don't know if it is a good idea for microservices' architecture.</p>&#xA;&#xA;<p>On the other hand I have been researching about Oauth2, I know it is only for authorizations (but you need to be authenticated for that) so.. maybe it could be a good option. Also I have found a good guide for implement <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow"">Oauth2 SSO with Spring</a>. However Oauth2 is for third-party so.. neither know if it is the best solution.</p>&#xA;&#xA;<p>As you see, I'm a bit confused . Other terms and tecnologies are in my head like SAML, OpenId... But I don't know which choose.</p>&#xA;"
30649582,Normalized or Denormalized Data in Microservices and Service Composition,<domain-driven-design><soa><composition><microservices>,3,660,2,1.0,2,"<p>So our development team has been working towards Microservices for the past 6-8 months and have picked up a lot of steam. </p>&#xA;&#xA;<p>We have experienced several <code>gotcha</code> moments in that time, and are humble enough to know that we are in for many more as we move closer to moving our platform to production.</p>&#xA;&#xA;<p>One area that I can't quite put my finger on is how we are to treat our data between our service boundaries. I hear a lot of statements form large companies that have successfully implemented Microservices, but I can never seem to get straight advice and reasoning.</p>&#xA;&#xA;<p><strong>Specifically, given two service domains  <code>User</code> and <code>Contacts</code>,and assuming that a <code>User</code> has a <code>Contact</code> object associated with it, what are the options for each of these two service domains in regards to managing their own data?</strong></p>&#xA;&#xA;<p><strong>Should the <code>User</code> have a <code>ContactID</code> stored with it, or should it store the entire <code>Contact</code> object?</strong></p>&#xA;&#xA;<p>I have seen many reliable service oriented development teams (Netflix,Amazon,Nike,etc) make statements such as the following:</p>&#xA;&#xA;<p><strong>""Normalization is the root of all evil...""</strong></p>&#xA;&#xA;<p><strong>""Break all that is shared...""</strong></p>&#xA;&#xA;<p><strong>""Share nothing...""</strong></p>&#xA;"
30732982,What's the correct way to embed a remote AngularJS application into a webpage?,<javascript><php><angularjs><html5><microservices>,1,695,2,0.0,2,"<p>I'm trying to work out the correct way to embed an AngularJS application into another web page (served by another app). I have two apps, running on different servers:</p>&#xA;&#xA;<p>App 1 - PHP app</p>&#xA;&#xA;<p>App 2 - AngularJS app (calendar widget of sorts)</p>&#xA;&#xA;<p>The PHP app is the primary app, into which I want to embed the calendar, which is served from a remote server. I have full access to both servers, and to both apps. The idea is that I want to be able to re-use the Angular app elsewhere, so it needs to be as loosely coupled as possible to the PHP app, preferably embedded in a single line of code. </p>&#xA;&#xA;<p>I am currently using a HTML5  tag, which seems to work well, but I was wondering if there's anything wrong with this approach, or if there's a better means of doing what I'm after.</p>&#xA;&#xA;<p>I should mention that I'm happy to use a HTML5-only solution, I'm no worried about backwards compatibility with older browsers.</p>&#xA;&#xA;<p>No iFrame solutions, unless there's a REALLY valid solution. My ultimate goal is to head towards a microservice-style architecture.</p>&#xA;&#xA;<p>Thanks in advance for your help.</p>&#xA;"
36876367,Cloud Service to Service Fabric authentication?,<c#><azure><microservices><azure-service-fabric>,1,1084,0,1.0,2,<p>What's the recommended way to authorize service-to-service traffic in Service Fabric?</p>&#xA;&#xA;<p>I have a Classic Cloud Service that I'd like to have call a Web API endpoint in a service fabric service. Is there a way to open up specific ports to specific IPs in a service fabric cluster? Or is there a better way to make sure my service fabric endpoints can not be called from the outside internet?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
36877722,Microservices per DB table?,<microservices>,1,631,4,0.0,2,"<ul>&#xA;<li>Person</li>&#xA;<li>NativeCountry</li>&#xA;<li>SpokenLanguages</li>&#xA;</ul>&#xA;&#xA;<p>Had a query about MIcroservice granularity. Will try to explain my query with an example.</p>&#xA;&#xA;<p>Assume I have above 3 tables in database, with Many to one relationship between Person -> NativeCountry table. One to Many relationship between person -> LanguagesSpoken in database.</p>&#xA;&#xA;<p>Front end Application is suppose do CRUD operation on person entity and will also have capability to retrieve people based on nativecountry or spokenlanguage.</p>&#xA;&#xA;<p>Does it makes sense to develop 3 independent microservices for each of the entities and then use Aggregator Microservice at upper layer to build combined data for UX layer or I should think of combining those to build just single microservice?</p>&#xA;"
30237292,Is the Microservices architectural Pattern similar to EJB 1.0?,<ejb><components><microservices>,2,1834,0,0.0,2,"<p>What we see with microservices is an isolated component, communicating over a protocol over the wire to a parent consumer of that component. </p>&#xA;&#xA;<p>We see a very similar pattern with EJB 1.0. </p>&#xA;&#xA;<p>My question is: <strong>Is the Microservices architectural Pattern similar to EJB 1.0?</strong></p>&#xA;"
35140042,Django or Flask or Falcon for Microservices,<django><flask><architecture><microservices><falconframework>,1,3874,2,1.0,2,"<p>Why is Microservice Architecture better than monolithic architecture? I know the answer will be because the microservice architecture is more scalable and each service is independent of each other etc.</p>&#xA;&#xA;<p>My following question is: should we build using Flask or Django REST Framework?</p>&#xA;&#xA;<p>I have also heard of a framework know as <a href=""http://falconframework.org"" rel=""nofollow"">Falcon</a> as per there documentation seems good enough.</p>&#xA;"
44305351,Send data in Request body using HttpURLConnection,<java><web-services><httpurlconnection><microservices><spark-java>,2,6350,0,1.0,2,"<p>I am using <code>HttpURLConnection</code> to make a POST request to a local service deployed in my local created using JAVA Spark.<strong>I want to send some data in request body when I make the POST call using the HttpURLConnection but every time the request body in JAVA Spark is null</strong>. Below is the code I am using for this</p>&#xA;&#xA;<h3>Java Spark POST Service Handler</h3>&#xA;&#xA;<p><code>post(""/"", (req, res) -&gt; {&#xA;        System.out.println(""Request Body: "" + req.body());&#xA;        return ""Hello!!!!"";&#xA;  });</code></p>&#xA;&#xA;<h3>HTTPClass Making the post call</h3>&#xA;&#xA;<pre><code>`public class HTTPClassExample{&#xA;   public static void main(String[] args) {&#xA;        try{&#xA;            URL url = new URL(""http://localhost:4567/"");&#xA;            HttpURLConnection httpCon = (HttpURLConnection) url.openConnection();&#xA;            httpCon.setDoOutput(true);&#xA;            httpCon.setRequestMethod(""POST"");&#xA;            httpCon.connect();&#xA;            OutputStream os = httpCon.getOutputStream();&#xA;            OutputStreamWriter osw = new OutputStreamWriter(os, ""UTF-8"");    &#xA;            osw.write(""Just Some Text"");&#xA;            System.out.println(httpCon.getResponseCode());&#xA;            System.out.println(httpCon.getResponseMessage());&#xA;            osw.flush();&#xA;            osw.close();  &#xA;        }catch(Exception ex){&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}`&#xA;</code></pre>&#xA;"
36582126,How Lagom services consume other services?,<microservices><service-discovery><lagom>,1,1048,2,1.0,2,"<p>I cant think in three cases.</p>&#xA;&#xA;<ol>&#xA;<li>Lagom service consumes another Lagom service in the same cluster</li>&#xA;<li>Lagom service consumes another Lagom service in a different cluster</li>&#xA;<li>Lagom service consumes an external non-Lagom service</li>&#xA;<li>An external non-Lagom service consumes a Lagom service</li>&#xA;</ol>&#xA;&#xA;<p><strong>1. Lagom service consumes another Lagom service in the same cluster</strong></p>&#xA;&#xA;<p>For this case the approach is that ServiceAImpl depends on the ServiceB API, wich is binded to a concrete implementation that will be injected to ServiceAImpl.</p>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Binding-a-service-client"" rel=""nofollow"">ServiceB binding:</a></p>&#xA;&#xA;<pre><code>import com.google.inject.AbstractModule;&#xA;import com.lightbend.lagom.javadsl.server.ServiceGuiceSupport;&#xA;import docs.services.HelloService;&#xA;&#xA;public class Module extends AbstractModule implements ServiceGuiceSupport {&#xA;&#xA;    protected void configure() {&#xA;        bindClient(HelloService.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Using-a-service-client"" rel=""nofollow"">ServiceA implementation:</a></p>&#xA;&#xA;<pre><code>public class MyServiceImpl implements MyService {&#xA;  private final HelloService helloService;&#xA;&#xA;  @Inject&#xA;  public MyServiceImpl(HelloService helloService) {&#xA;    this.helloService = helloService;&#xA;  }&#xA;&#xA;  @Override&#xA;  public ServiceCall&lt;NotUsed, NotUsed, String&gt; sayHelloLagom() {&#xA;    return (id, msg) -&gt; {&#xA;      CompletionStage&lt;String&gt; response = helloService.sayHello().invoke(""Lagom"");&#xA;      return response.thenApply(answer -&gt;&#xA;          ""Hello service said: "" + answer&#xA;      );&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I understand it correctly, in order to consume the service API in this way, both clients must be in the same cluster.&#xA;However Lagom <a href=""http://www.lagomframework.com/documentation/1.0.x/Cluster.html#Cluster-composition"" rel=""nofollow"">says</a> that</p>&#xA;&#xA;<blockquote>&#xA;  <p>A cluster should only span nodes that are running the same service.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this case we have two different types of services. </p>&#xA;&#xA;<ul>&#xA;<li>""The same service"" means a top level service whose API is exposed to external services?</li>&#xA;<li>In Lagom 1 Microservice = 1 service with external API + n internal services?</li>&#xA;</ul>&#xA;&#xA;<p><strong>2. Lagom service consumes another Lagom service in a different cluster</strong></p>&#xA;&#xA;<p>The documentation <a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceLocator.html#Integrating-with-external-Lagom-projects"" rel=""nofollow"">says</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Note that if the service you want to communicate with is actually a Lagom service, you may want to read the documentation for <a href=""http://www.lagomframework.com/documentation/1.0.x/MultipleBuilds.html"" rel=""nofollow"">integrating with an external Lagom projects</a>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Why is only configured the dependency to the service API and not the IP and port of the external Lagom service also?</p>&#xA;&#xA;<p><strong>3. Lagom service consumes an external non-Lagom service</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>The first thing you will have to do is to register each external&#xA;  service in the Service Locator. Assume we want to register an external&#xA;  service named weather that is running on <a href=""http://localhost:3333"" rel=""nofollow"">http://localhost:3333</a>, here&#xA;  is what we would add to the build:</p>&#xA;&#xA;<pre><code> lagomUnmanagedServices in ThisBuild := Map(""weather"" -&gt; ""http://localhost:3333"")&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>What is the contract with that IP? What should be behind it?</p>&#xA;&#xA;<p><strong>4. An external non-Lagom service consumes a Lagom service</strong></p>&#xA;&#xA;<p>I have to use the <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow"">Third-Party Registration Pattern</a> until Lagom support the <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow"">self registration pattern</a>?</p>&#xA;"
48961000,Why shared libraries between microservices are bad?,<interface><architecture><shared-libraries><microservices><distributed-computing>,1,967,0,0.0,2,"<p>Sam Newman states in his book <em>Building Microservices</em></p>&#xA;&#xA;<blockquote>&#xA;  <p>The evils of too much coupling between services are far worse than the problems caused by code duplication</p>&#xA;</blockquote>&#xA;&#xA;<p>I just don't understand how the shared code between the services is evil. Does the author mean the <em>service boundaries themselves</em> are poorly designed if a need for a shared library emerges, or does he really mean I should duplicate the code in the case of common business logic dependency? I don't see what that solves.</p>&#xA;&#xA;<p>Let's say I have a shared library of entities common to two services. The common domain objects for two services may smell, but another service is the GUI to tweak the state of those entities, another is an interface for other services to poll the state for their purpose. Same domain, different function.</p>&#xA;&#xA;<p>Now, if the shared knowledge changes, I would have to rebuild and deploy both services regardless of the common code being an external dependency or duplicated across the services. Generally, same concerns all the cases for two services depending of the same article of the business logic. In this case, I see only harm of duplication of the code, reducing the cohesion of the system.</p>&#xA;&#xA;<p>Of course, <em>diverging</em> from the shared knowledge may cause headaches in the case of shared library, but even this could be solved with inheritance, composition and clever use of abstractions.</p>&#xA;&#xA;<p>So, what does Sam mean by saying code duplication is better than too much coupling via shared libraries? </p>&#xA;"
48861926,How to keep state consistent across distributed systems,<rest><web-services><architecture><microservices><distributed-computing>,1,53,5,0.0,2,"<p>When building distributed systems, it must be ensured the client and the server eventually ends up with consistent view of the data they are operating on, i.e they never get out of sync. Extra care is needed, because network can not be considered reliable. In other words, in the case of network failure, client never knows if the operation was successful, and may decide to retry the call.</p>&#xA;&#xA;<p>Consider a microservice, which exposes simple CRUD API, and unbounded set of clients, maintained in-house by the same team, by different teams and by different companies also.</p>&#xA;&#xA;<p>In the example, client request a creation of new entity, which the microservice successfully creates and persists, but the network fails and client connection times out. The client will most probably retry, unknowingly persisting the same entity second time. Here is one possible solution to this I came up with:</p>&#xA;&#xA;<ul>&#xA;<li>Use client-generated identifier to prevent duplicate post</li>&#xA;</ul>&#xA;&#xA;<p>This could mean the primary key as it is, the half of the client and server -generated composite key, or the token issued by the service. A service would either persist the entity, or reply with OK message in the case the entity with that identifier is already present.</p>&#xA;&#xA;<p>But there is more to this: What if the client gives up after network failure (but entity got persisted), mutates it's internal view of the entity, and later decides to persist it in the service with the same id. At this point and generally, would it be reasonable for the service just silently:</p>&#xA;&#xA;<ul>&#xA;<li><em>Update</em> the existing entity with the state that client posted</li>&#xA;</ul>&#xA;&#xA;<p>Or should the service answer with some more specific status code about what happened? The point is, developer of the service couldn't really influence the client design solutions.</p>&#xA;&#xA;<p>So, what are some sensible practices to keep the state consistent across distributed systems and avoid most common pitfalls in the case of network and system failure?</p>&#xA;"
28387907,Push Data onto Queue vs Pull Data by Workers,<message-queue><soa><microservices>,2,801,0,0.0,2,"<p>I am building a web site backend that involves a client submitting a request to perform some expensive (in time) operation. The expensive operation also involves gathering some set of information for it to complete.</p>&#xA;&#xA;<p>The work that the client submits can be fully described by a <code>uuid</code>. I am hoping to use a service oriented architecture (SOA) (i.e. multiple micro-services).</p>&#xA;&#xA;<p>The client communicates with the backend using RESTful communication over HTTP. I plan to use a queue that the workers performing the expensive operation can poll for work. The queue has persistence and offers decent reliability semantics.</p>&#xA;&#xA;<p>One consideration is whether I gather all of the data needed for the expensive operation upstream and then enqueue all of that data or whether I just enqueue the <code>uuid</code> and let the worker fetch the data.</p>&#xA;&#xA;<p>Here are diagrams of the two architectures under consideration:</p>&#xA;&#xA;<p><strong>Push-based (i.e. gather data upstream):</strong>&#xA;<img src=""https://i.stack.imgur.com/rxZQe.png"" alt=""Push-based (i.e. gather data upstream)""></p>&#xA;&#xA;<p><strong>Pull-based (i.e. worker gathers the data):</strong>&#xA;<img src=""https://i.stack.imgur.com/R9aJN.png"" alt=""Pull-based (i.e. worker gathers the data)""></p>&#xA;&#xA;<p>Some things that I have thought of:</p>&#xA;&#xA;<ol>&#xA;<li>In the push-based case, I would be likely be blocking while I gathered the needed data so the client's HTTP request would not be responded to until the data is gathered and then enqueued. From a UI standpoint, the request would be pending until the response comes back.</li>&#xA;<li>In the pull based scenario, only the worker needs to know what data is required for the work. That means I can have multiple types of clients talking to various backends. If the data needs change I update just the workers and not each of the upstream services.</li>&#xA;</ol>&#xA;&#xA;<p>Any thing else that I am missing here?</p>&#xA;"
28572202,Gradle + Dropwizard + Shadow -> Could not find or load main class,<java><gradle><dropwizard><microservices>,2,1931,0,0.0,2,"<p>I'm trying to create a simple microservice using Dropwizard and Gradle as a build system. &#xA;No database, only REST endpoint to expose.</p>&#xA;&#xA;<p>So I have a controller: </p>&#xA;&#xA;<pre><code>@Path(""/domainurl/"")&#xA;@Produces(MediaType.APPLICATION_JSON)&#xA;public class SimpleController {&#xA;&#xA;    @GET&#xA;    public Example resourceExample() {&#xA;        return new Example(""something"");&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>My application main class:</p>&#xA;&#xA;<pre><code>public class Application extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration configuration, Environment environment) throws Exception {&#xA;        final SimpleCOntroller controller = new SimpleController();&#xA;        environment.jersey().register(controller);&#xA;    }&#xA;&#xA;    public static void main(String[] args) throws Exception {&#xA;        new Application().run(args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Example is a simple value object with one string property, MyConfiguration is an empty class at this moment.</p>&#xA;&#xA;<p>And build.gradle:</p>&#xA;&#xA;<pre><code>buildscript {&#xA;    repositories {&#xA;        jcenter()&#xA;    }&#xA;&#xA;    dependencies {&#xA;        classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.0'&#xA;    }&#xA;}&#xA;&#xA;apply plugin: 'java'&#xA;apply plugin: 'groovy'&#xA;apply plugin: 'application'&#xA;apply plugin: 'com.github.johnrengelman.shadow'&#xA;&#xA;mainClassName = ""com.example.Application""&#xA;&#xA;//&#xA;dependencies&#xA;//&#xA;&#xA;run {&#xA;    args 'server', './src/config/microservice.yml'&#xA;}&#xA;&#xA;task wrapper(type: Wrapper) {&#xA;    gradleVersion = '2.1'&#xA;}&#xA;&#xA;jar {&#xA;    manifest {&#xA;        attributes 'Main-Class': mainClassName&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But after build, when I type:</p>&#xA;&#xA;<pre><code>java -jar MyApp.jar&#xA;</code></pre>&#xA;&#xA;<p>I'm still getting:</p>&#xA;&#xA;<pre><code>Error: Could not find or load main class com.example.Application&#xA;</code></pre>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
40485481,Front End Developer workflow for Service Fabric Web Apps,<azure><microservices><azure-service-fabric>,1,396,7,2.0,2,"<p>I'm a front end developer about to join a project team working with Service Fabric to build a Web Front End to their microservice driven application.</p>&#xA;&#xA;<p>One of the problems I've been having in my own research is that when working with local Service Fabric Clusters, I have to redeploy my Application to test if something does or doesn't work in my Web App. This slows down developer velocity massively, as the process will only take longer and longer as other Back End services are added. I largely work with the Web App communicating to an API Gateway Service (GraphQL.NET). </p>&#xA;&#xA;<p>What I'd like to know is if there's a way to run a local Web Application out outside of a Service Fabric cluster, but still have it communicate to one. This would allow my front end developer tool chain to remain intact, and develop at a much faster pace with incremental building and live-reload tools.</p>&#xA;&#xA;<p>Of course, if anyone's come up with any better solution to the problem, I'd love to hear about it! ;)</p>&#xA;"
27839789,How do I change these producer-consumer microservices to allow parallel processing?,<ruby-on-rails><ruby><multithreading><parallel-processing><microservices>,3,429,2,0.0,2,"<p>I've got a couple microservices (implemented in ruby, although I doubt that is important for my question). One of them provides items, and the other one processes them, and then marks them as processed (via a DELETE call)</p>&#xA;&#xA;<p>The provider has an <code>/items</code> endpoint which lists a bunch of items identified with an id, in JSON format. It also has a <code>DELETE /items/id</code> endpoint which removes one item from the list (presumably because it is processed)</p>&#xA;&#xA;<p>The code (very simplified) in the ""processor"" looks like this:</p>&#xA;&#xA;<pre><code>items = &lt;GET provider/items&gt;&#xA;items.each do |item|&#xA;  process item&#xA;  &lt;DELETE provider/items/#{item.id}&gt;&#xA;end&#xA;</code></pre>&#xA;&#xA;<p>This has several problems, but the one I would like to solve is that it is not thread-safe, and thus I can't run it in parallel. If two workers start processing items simultaneously, they will ""step onto each other's toes"": they will get the same list of items, and then (try to) process and delete each item twice.</p>&#xA;&#xA;<p>What is the simplest way I can change this setup to allow for parallel processing?</p>&#xA;&#xA;<p>You can assume that I have ruby available. I would prefer keeping changes to a minimum, and would rather not install other gems if possible. <a href=""http://sidekiq.org/"" rel=""nofollow"">Sidekiq</a> is available as a queuing system on the consumer.</p>&#xA;"
32863771,SpringBoot RestController generic POST type,<java><spring><rest><spring-boot><microservices>,2,1908,2,1.0,2,"<p>I'm experimenting with building microservices using Spring Boot.</p>&#xA;&#xA;<p>I have a back-end API that receives ResponseEntity POST requests and processes it (saving to database etc). Where Data is an Object of a self-created class.</p>&#xA;&#xA;<p>Now I have a top-level API (that handles authentication,..). The end-users will communicate with the back-end services through this top-level API. So this API basically just has to forward all the requests to the right back-end api's.</p>&#xA;&#xA;<p>In this top API I don't want to need to include all my classes (e.g. the Data class in this case) and I would rather just send it as String json data or something. So I tried this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;    ResponseEntity&lt;String&gt; createUnit(@RequestBody String data) {&#xA;        URI uri = util.getServiceUrl(""dataservice"");&#xA;        String url = uri.toString() + ""/data"";&#xA;&#xA;        ResponseEntity&lt;String&gt; result = restTemplate.postForEntity(url, data, String.class);&#xA;        return new ResponseEntity&lt;String&gt;(result.getBody(), HttpStatus.OK);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>But this results in an <code>org.springframework.web.client.HttpClientErrorException: 415 Unsupported Media Type</code>. </p>&#xA;&#xA;<p>So my question is, is there a way to forward these requests to my back-end without the need to include all my Object classes in my API? I figured this should be able since this is the same as when a web-browser sends requests in json format without knowing what kind of Object the data actually is.</p>&#xA;&#xA;<p>The back-end handling looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, value=""/data"")&#xA;ResponseEntity&lt;Data&gt; saveData(@RequestBody Data data) {&#xA;    //Some code that processes the data&#xA;    return new ResponseEntity&lt;Data&gt;(dataProcessed, HttpStatus.OK);&#xA;}&#xA;</code></pre>&#xA;"
32887039,How to implement HATEOAS in a Spring-Boot microservices project,<java><spring><rest><microservices><spring-hateoas>,1,488,5,0.0,2,"<p>Lately I've been experimenting with building <strong>microservices</strong> using the Java <strong>Spring Boot</strong> framework. I currently have a working Microservices systeem with several resources (which all have its own independent service), e.g.: A Book service and a Review service.&#xA;Each service has its own <strong>RestController</strong> and uses a <strong>MongoRepository</strong> to interact with its database.</p>&#xA;&#xA;<p>The end-users of the application (web-clients) will not communicate with these independent services itself but with an API above them.</p>&#xA;&#xA;<p>This API calls the book and review services, merges the data and returns it back to the client. Note that all the communication is using <code>ResponseEntity&lt;T&gt;</code> (<code>T</code> can be <code>Book</code>, <code>Review</code>, <code>Iterable&lt;Book&gt;</code>, etc, ..)</p>&#xA;&#xA;<p>But after reading a while I learnt about <strong>HATEOAS</strong> and I would like to use it in my microservices set-up. Now my question is, what is the best way to implement this?</p>&#xA;&#xA;<p>Some examples I've found extend the entity classes (which in my case would be the Book entity or the Review entity with Spring's <code>ResourceSupport</code> class). But this causes errors since my entity's have an ID parameter and the <code>getId()</code> method clashes with the <code>getId()</code> method of the ResourceSupport class. </p>&#xA;&#xA;<p>Other examples contain a <code>MongoRepository</code> annotated with <code>@RestResource</code> instead of using a <strong>Controller</strong>.</p>&#xA;&#xA;<p>So my question is, what would in this case be the best way to implement HATEOAS? And e.g. when the Book service adds links (the HATEOAS way), how can the API above change these links? Since the end-users will only do calls to this API and the API just processes these requests and delegates it to the necesarry sub-services.</p>&#xA;"
38964840,Text search for microservice architectures,<elasticsearch><architecture><microservices>,1,1133,0,1.0,2,"<p>I am investigating into implementing text search on a microservice based system. We will have to search for data that span across more than one microservice. </p>&#xA;&#xA;<p>E.g. say we have two services for managing Organisations and managing Contacts. We should be able to search for organisations by contact details in one search operation.</p>&#xA;&#xA;<p>Our preferred search solution is Elasticsearch. We already have a working solution based on embedded objects (and/or parent-child) where when a parent domain is updated the indexing payload is enriched with the dependent object data, which is held in a cache (we avoid making calls to the service managing child directly for this purpose). </p>&#xA;&#xA;<p>I am wondering if there is a better solution. Is there a microservice pattern applicable to such scenarios?</p>&#xA;"
39134238,Client authentication in microservices using JWT and OpenID Connect,<api><authentication><jwt><microservices>,1,994,0,1.0,2,"<p>I've some questions regarding authentication in a microservices architecture. I've right now a monolithic application and my goal is to split the application in small microservices.</p>&#xA;&#xA;<p>My bigest problem is for authentication (for now). After reading a LOT a documentation, It seems that the best solution is to use OpenID Connect to authenticate an user to retrieve a JWT that can by passed with the request to the microservices. </p>&#xA;&#xA;<p>Also, to avoid having multiple endpoints, you can deploy and API Gateway to have only one endpoint for the end user. Ok, so now I've two questions with this architecture.</p>&#xA;&#xA;<p>The standard flow for authentication will be :</p>&#xA;&#xA;<p>An user contact my identity server in OpenID Connect with the implicit flow and get the id_token (JWT) and also the access_token. The user can now contact my API with this access_token. The API Gateway will valide the access_token with the identity server and also retrieve the JWT to add it to the sub request to the microservice API. </p>&#xA;&#xA;<p>1/ How the API Gateway can get the JWT from the access_token? From what I red from the documentation (<a href=""http://openid.net/specs/openid-connect-core-1_0.html"" rel=""nofollow"">http://openid.net/specs/openid-connect-core-1_0.html</a>), It can contact the ""/userinfo"" endpoint but It will get just the JSON format not the JWT...</p>&#xA;&#xA;<p>2/ I want to allow authenticated calls between my microservices. So each microservice needs to be able to generate a JWT to contact other microservices directly. My first thought was to contact the identity server. But with the OAuth2 Client Credentials flow, I don't retrieve a id_token or a JWT. Just a classic OAuth2 access token without JWT. My second thought was that the microservice can directly sign its own JWT with a certificate issued by the same PKI as the one used by the identity server. That mean that a JWT can be sign by several certificats but from the same private PKI. When a microservice receives a JWT, It needs to be able to identify witch certificat was used to sign the JWT. I don't find anything on the RFC regarding this problem. I can add my own private claim in the token to have the certificate but after several days of browsing the web without seeing this kind of solution, I'm wondering if I'm not on the wrong path... To sum up, how can i perfom ""User to service"" authentication AND alors ""service to service"" authentication in JWT?</p>&#xA;&#xA;<p>Thank you very much!</p>&#xA;"
38966184,Should business logic be contained in individual services in a micro service ecosystem?,<architecture><microservices>,2,1341,2,0.0,2,<p>Let's say I just have 2 services <strong>Billing</strong> and <strong>Orders</strong> and one API gateway which may fan out requests to these services for billing or creating orders. </p>&#xA;&#xA;<p>Given this new order scenario:</p>&#xA;&#xA;<ol>&#xA;<li>user creates an order (request -> Rest API)</li>&#xA;<li>User validation has to be done</li>&#xA;<li>Order entity has to be created</li>&#xA;<li>Billing entity has to be created </li>&#xA;<li>Notification has to be done to notify the user</li>&#xA;</ol>&#xA;&#xA;<p>Where should my application logic sit ? and should the calls to these services be done synchronously (within the rest api) ? or each service should be responsible for calling another ? eg:</p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> (if successful) Rest API -> (if successful) calls the billing service</p>&#xA;&#xA;<p><strong>Or</strong></p>&#xA;&#xA;<p>New user order request -> Rest API -> calls order service to create order -> returns the response. Then order service takes of things from there on asynchronously ?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
33814080,Microservices with many repositories out of date,<github><teamcity><microservices><octopus-deploy><devops>,2,220,3,1.0,2,<p>In a microservices architecture what is the best strategy for keeping many developer environments up-to-date across multiple source code repositories?</p>&#xA;&#xA;<p>Suppose there were 10 teams of 10 developers working on 200 microservices in git. Every developer would need to pull regularly from every repository. This could be done with scripts but is there a better way? Are we doing this wrong because it seems like a heavy overhead.</p>&#xA;
33712470,Api naming in microservices design,<rest><design><microservices>,2,1342,4,0.0,2,"<p>Let's say that there are two microservices representing the resources orders(/orders) and customers(/customers). My requirement is to get all the orders made by a customer. &#xA;Had it been a monolithic application, I would have modeled my uri as /customers/{id}/orders. This would have hit the customers resource and made an in-memory service call to get the corresponding orders. &#xA;Now, in case of microservices, this isn't possible. So, is the only way to get the orders is to make a remote service call or is there a better way of doing it?&#xA;Can we create another resource with the representation /ordersByCustomers/{customerid}?</p>&#xA;"
35632607,Is the HTTP method PURGE idempotent in Varnish?,<rabbitmq><varnish><microservices><http-method><purge>,2,614,0,0.0,2,<p>Is the HTTP verb PURGE idempotent? &#xA;If I send the same PURGE request twice will I receive 200 the second time?</p>&#xA;&#xA;<p>I have a microservice that invalidates a Varnish cache before publishing a message into a rabbit queue. In case of purge failure our need is to just log and continue the execution.</p>&#xA;&#xA;<p>The queue consumer has to get the latest status of the resource from the Varnish cache.&#xA;Will a new purge request (before actually requesting the resource from varnish) from the second microservice return success in case the first purge from the first microservice succeeded?</p>&#xA;
35585519,"Cross origin issue with ajax, angular and Zuul",<angularjs><ajax><spring-cloud><microservices><netflix-zuul>,1,1313,4,0.0,2,"<p>I have zuul server implemented which does the routing to all my microservices. I have a seperate UI project which is in angular. I am trying to make an AJAX call from the UI app to a specific microservices which routes through Zuul but I am getting this error.</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load http://localhost:8006/user/v1/userassociations. Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:63342' is therefore not allowed access. The response had HTTP status code 403. &#xA;</code></pre>&#xA;&#xA;<p>But When I directly try to hit the api in local host which is hosted at <a href=""http://localhost:4444/user/v1/userassociations"" rel=""nofollow"">http://localhost:4444/user/v1/userassociations</a> it works perfectly fine. I have the below CORS configuration added to the actual api.</p>&#xA;&#xA;<pre><code>@Override&#xA;public void addCorsMappings(final CorsRegistry registry) {&#xA;    registry.addMapping(""/**"").allowedMethods(""PUT"", ""GET"", ""DELETE"", ""OPTIONS"", ""PATCH"", ""POST"");&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is only happening when i try to hit the api via zuul I tried to add the same configuration to Zuul  but it is not working.</p>&#xA;&#xA;<p>I know it is the same origin issue but there must be a solution our microservices are suppose to go public so anyone can make the request from any domain.</p>&#xA;&#xA;<p>Below is the Working AJAX call:- if i change the url to <a href=""http://localhost:8006/user/v1/userassociations"" rel=""nofollow"">http://localhost:8006/user/v1/userassociations</a> which is via zuul i get the cross origin.</p>&#xA;&#xA;<pre><code>var service = {};&#xA;  service.userContextCall = function()&#xA;  {&#xA;    return $http({&#xA;      url:'http://localhost:4444/user/v1/userassociations',&#xA;      method: 'GET',&#xA;      headers: {'Content-Type':'application/json',&#xA;        'userContextId':'1234567890123456'}&#xA;    }).success(function(response){&#xA;&#xA;      return response;&#xA;    }).error(function(error){&#xA;&#xA;      return error;&#xA;    });&#xA;&#xA;  };&#xA;&#xA;  return service;&#xA;</code></pre>&#xA;&#xA;<p>Header that Iam receiving for when i hit the api via Zuul.</p>&#xA;&#xA;<pre><code>Request URL:http://localhost:8006/user/v1/userassociations&#xA;Request Method:OPTIONS&#xA;Status Code:403 Forbidden&#xA;Remote Address:[::1]:8006&#xA;Response Headers&#xA;view source&#xA;Allow:GET, HEAD, POST, PUT, DELETE, TRACE, OPTIONS, PATCH&#xA;Content-Length:20&#xA;Date:Tue, 23 Feb 2016 18:51:15 GMT&#xA;Server:Apache-Coyote/1.1&#xA;X-Application-Context:apigateway:8006&#xA;Request Headers&#xA;view source&#xA;Accept:*/*&#xA;Accept-Encoding:gzip, deflate, sdch&#xA;Accept-Language:en-US,en;q=0.8&#xA;Access-Control-Request-Headers:accept, usercontextid&#xA;Access-Control-Request-Method:GET&#xA;Connection:keep-alive&#xA;Host:localhost:8006&#xA;Origin:http://localhost:63342&#xA;Referer:http://localhost:63342/icpAccountHolder/app/index.html&#xA;User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36&#xA;</code></pre>&#xA;&#xA;<p>Header when i direclty hit the api the working one.</p>&#xA;&#xA;<pre><code>Request URL:http://localhost:4444/user/v1/userassociations&#xA;Request Method:GET&#xA;Status Code:200 OK&#xA;Remote Address:[::1]:4444&#xA;Response Headers&#xA;view source&#xA;Access-Control-Allow-Credentials:true&#xA;Access-Control-Allow-Origin:http://localhost:63342&#xA;Content-Type:application/json;charset=utf-8&#xA;Date:Tue, 23 Feb 2016 18:54:19 GMT&#xA;Server:Apache-Coyote/1.1&#xA;Transfer-Encoding:chunked&#xA;Vary:Origin&#xA;X-Application-Context:userassociations-v1&#xA;Request Headers&#xA;view source&#xA;Accept:application/json, text/plain, */*&#xA;Accept-Encoding:gzip, deflate, sdch&#xA;Accept-Language:en-US,en;q=0.8&#xA;Connection:keep-alive&#xA;Host:localhost:4444&#xA;Origin:http://localhost:63342&#xA;Referer:http://localhost:63342/icpAccountHolder/app/index.html&#xA;User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36&#xA;userContextId:1234567890123456&#xA;</code></pre>&#xA;&#xA;<p>Can anyone help me with this. </p>&#xA;"
46824730,How should be project structure using microservices with gradle or maven?,<maven><gradle><microservices><multi-module><multi-project>,2,697,0,2.0,2,"<p>I want to be sure what is the best practice for project structure while using microservice architecture.</p>&#xA;&#xA;<p>All microservices can be created as a new maven/gradle project or as a subproject/module.</p>&#xA;&#xA;<p>I think dependency inheritance, project repository should be taken into account.</p>&#xA;&#xA;<p>Due to the nature of the microservices, any service can has a different technology but still most of the services can have same dependencies(e.g. spring-boot)).</p>&#xA;&#xA;<p>Another issue is that should  team  fetch all services or just a service which will be worked on? so repository structure also will be affected by the structure.</p>&#xA;"
46803321,Is it wrong to use sessions in Microservices?,<java><spring-boot><spring-security><microservices><spring-session>,1,1139,1,1.0,2,"<p>I have read that, session is against the concept of RESTfulness.</p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/q/6068113/1358676"">Do sessions really violate RESTfulness?</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/32741333/session-management-in-microservices/32743085#32743085"">Session Management in microservices</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/319530/restful-authentication"">RESTful Authentication</a></p>&#xA;&#xA;<p>Since Microservices inevitably use <code>REST</code>, does the same apply here as well? If so, then why do we have Spring session? It even lists 'Spring Session allows providing session ids in headers to work with <code>RESTful</code> APIs' as one of its features.</p>&#xA;"
37615250,Repository within domain objects,<domain-driven-design><microservices>,2,285,3,0.0,2,"<p>I have seen lot of discussions regarding this topic but i couldn't get a convincing answer. The general advice is not to have repository inside a domain object.  What about an aggregate root? Isnt it right to give the root the responsibility to manipulate the composed objects? &#xA;For example, i have a microservice which takes care of invoices. Invoice is an aggregate root which has the different products. There is no requirement for this service to give details about individual products. I have 2 tables, one to store invoice details and other to store products of those invoices. I have two repositories corresponding to the tables. I have injected product repository inside the invoice domain object. Is it wrong to do so? </p>&#xA;"
37634349,How can I handle large files processing via messaging queries in Microservices environment?,<java><jms><ipc><microservices>,1,733,3,0.0,2,"<p>Many people suggest that the good way for organizing IPC (ImicroservicesC) is asynchronous communication via queries like Kafka and JMS. </p>&#xA;&#xA;<p>But what if I need to pass large data files between services?</p>&#xA;&#xA;<p>Suppose I have a Video Microservice and a Publisher Microservice. The first one receives videos from the user, verifies and sends them to Publisher for converting and publishing. It's oblivious video can be a very large file and it can overload messaging system (Kafka is not suitable for big messages at all). Of course, I can share one database for them and send video_id via Kafka, but it couples these services and its not a real microservices architecture anymore.</p>&#xA;&#xA;<p>Do you have similar situations in practice? How do you handle it?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
39388560,OpenID Connect ID Token: What's the purpose of audience [aud] field validation,<security><microservices><openid-connect>,1,573,0,0.0,2,"<p>I'm trying to implement <a href=""http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth"" rel=""nofollow"">OpenID Connect Implicit Flow</a>. The frontend Single Page App passes the ID Token down to the backend server (using Authorization header) where I need to validate it.</p>&#xA;&#xA;<p>The documentation requires me <a href=""http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation"" rel=""nofollow"">to check</a> that I trust the audience of the token (aud &amp; azp fields). I'm struggling to understand the significance of this validation step and what are the security implications of not doing so. Why should I distrust the token if I'm not the intended recipient?</p>&#xA;&#xA;<p>My reasoning is that if I trust the issuer it doesn't matter who was the token issued for. I would expect the claims to be the same for any clientId (is this wrong?). Ideally when I pass the ID Token around my microservices all they should know is what issuers to trust (and use <a href=""https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig"" rel=""nofollow"">discovery protocol</a> for figuring out the keys).</p>&#xA;&#xA;<p>What is the attack vector if I skip this validation step?</p>&#xA;"
29434226,Generating JPA entities in microservices design,<java-ee><jpa><microservices>,1,343,5,0.0,2,"<p>I am thinking of design and bit confused with generating entities in a microservices architecture (though I am new to microservices design, but I am fascinated with multiple lean war's). I have DB and multiple war's in mind. Should I generate the entities from DB and place them in a jar, and include the jar in every war i create, OR there is another option. Secondly where I place persistence.xml. And if i plan to use cache later to cache entity instances, will above approach pose any issues. Thanks</p>&#xA;"
44939302,"*** process.env.ENV is not defined, assuming 'prod' env",<angularjs><environment-variables><jhipster><microservices><gateway>,1,632,0,0.0,2,"<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in <code>application-dev.yml</code>) and&#xA;Getting following exception in console</p>&#xA;&#xA;<pre><code>*** process.env.ENV is not defined, assuming 'prod' env&#xA;</code></pre>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is given by yarn) and giving exception like below in console.</p>&#xA;&#xA;<pre><code>process.env.ENV is not defined, assuming 'prod' env&#xA;chrome-extension://kbfnbcaeplbcioakkpcpgfkobkghlhen/src/js/bundle.js:4776 *** &#xA;</code></pre>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other microservices applications.</p>&#xA;&#xA;<p>Why am I getting the above exception?</p>&#xA;"
45111662,Microservices with common users table,<architecture><soa><microservices>,3,244,0,1.0,2,<p>Is it possible to design a microservice based  architecture on which each microservice have separate independent database and a common users table?</p>&#xA;
45007694,Microservices - Database compatibility in between old and new versions,<database><rest><architecture><microservices>,1,175,3,1.0,2,"<p>I am trying to dive into Microservice architecture to start coding some of small pieces of logic for my company.</p>&#xA;&#xA;<p>I know one of microservices concerns is about the database handling (each microservice must have its separated db schmema). So I am looking for pieces of advice or experiences about to move out from an old to new microservice version.</p>&#xA;&#xA;<p>So lets say I have a REST API endpoint <code>ms/v1/whatEver</code> which is running today on prod. After a week we decide to go live with the next version of it. So that we create a <code>ms/v2/whatEver</code> which has some new columns and data types in the entities envolved in this service. Thus in order to not force all clients to migrate immediately we want to keep both versions up and running till users move in progressively to <code>v2</code>.</p>&#xA;&#xA;<p>A couple of scenarios come up in to my mind if we have both version up and running (which actually is my main doubt and the reason of this post):</p>&#xA;&#xA;<ol>&#xA;<li><p>Should they read/write in the same DB instance, hence <code>v1</code> implementation must be adapted to match with the new schema structure of <code>v2</code>?</p></li>&#xA;<li><p>Should they read/write in a separate DB instance. So in any manner both DBs have to be synchronised till the day we decide to turn off <code>v1</code> to guarantee we do not miss any data (eventual consistency)? So my question here is how to accomplish that (throughout framework, queue messaging, or something..)</p></li>&#xA;<li><p>Or, code forwarding every <code>v1</code> request (inside of it) to <code>v2</code> which is going to be the owner of the already migrated new schema (unique DB instance)?</p></li>&#xA;</ol>&#xA;&#xA;<p>I have been reading a couple of books like <a href=""https://developers.redhat.com/promotions/migrating-to-microservice-databases/"" rel=""nofollow noreferrer"">Migrating to Microservices Databases - Red Hat</a> but they are written in concept terms but nothing specific with technologies or best things to do whit this. So that my post. </p>&#xA;&#xA;<p>I really appreciate your opinions.&#xA;Thanks</p>&#xA;"
37254914,"I renamed my microservice, what do I do with the semantic version?",<rename><microservices><semantic-versioning>,1,74,3,0.0,2,"<p>I have a number of microservices in a distributed system - one of which I have recently renamed to better reflect its bounded context and disambiguate with another similarly named service.</p>&#xA;&#xA;<p>The service was on version 3.1.0 at the point of renaming. My question is, what do I do with the version now? Is it 4.0.0? Or is this conceptually now a new service, replacing the old one and starting again from 1.0.0?</p>&#xA;&#xA;<p>I would lean towards the latter option, but I'm also versioning the db schema to match the service, and I don't want to end up in the position where the service is 1.0.0 but the db schema is 3.1.0...</p>&#xA;"
38178535,How to share the web API controllers with microservice,<c#><asp.net-web-api><microservices><asp.net5>,1,1301,0,0.0,2,<p>We have an existing Web API that is built using ASP.Net 5 framework. We plan to develop new micro services now. We are trying to re-use the code of existing API as far as possible. Our old API (monolithic) or our new micro services will be deployed based on customer need.</p>&#xA;&#xA;<p>We are finding it tough to share the Controllers between monolithic API and micro services. Thought of using 'add as link file' but that is not working in case of controller files. Any other ways to share the controllers?</p>&#xA;
38049334,Manage multiple dependencies between microservices using Maven,<maven><dependencies><release><microservices>,1,760,0,0.0,2,<p>We are using Maven to define and manage our dependencies between our microservices. Here is an example:</p>&#xA;&#xA;<p><strong>Microservice 1</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-1&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.04-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice 2</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-3&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.28.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>The problem is that the release phase is taking a lot of time and is fully manual:</p>&#xA;&#xA;<ol>&#xA;<li>perform <code>mvn:release</code> for the first microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>change the version in <code>pom.xml</code> of the dependency</li>&#xA;<li>perform <code>mvn:release</code> for the second microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>and so on (actually on 15 microservices...)</li>&#xA;</ol>&#xA;&#xA;<p>I'm wondering if there is any automatized way to perform this release (in cascade)? </p>&#xA;&#xA;<p>Thanks</p>&#xA;
38049329,"DDD, Microservices and data direction",<domain-driven-design><microservices>,2,170,3,1.0,2,"<p>Let's assume I have Identity Management bounded context and discussion bounded context. Each of those is a separate micro service.</p>&#xA;&#xA;<p>Identity has Users, Discussion has Moderators.</p>&#xA;&#xA;<p>If I update first and last name in the Identity bounded context, my plan is to publish a message to Amazon SQS, and have discussion bounded context to listen that queue for any changes, and update first and last name in discussion context via Anti-Corruption layer.</p>&#xA;&#xA;<p>My question is, what if I decide to change first name and last name in the Discussion BC? Should my Identity BS listen for that changes too, or having bi-directional communication is not considered a good practice, and I should always update that information inside Identity BC?</p>&#xA;"
38006427,Building a microservices application on. Net?,<.net><f#><microservices>,1,1024,5,0.0,2,"<p>I plan to build an internal application for my company and want to implement it in micro services. All the servers in my company is Windows servers. </p>&#xA;&#xA;<p>I'm thinking build it using asp.net core, etc. Is there a good example available? What kind of tech stack it will need?</p>&#xA;"
33308154,Blue green deployment on microservices - how to route 10% of traffic to one one instance and remaining 90% of traffic to other instance,<cloud><ibm-cloud><cloudfoundry><microservices>,3,188,0,0.0,2,<p>I have two instances of the same microservice in Bluemix(cloud Foundry). I want to route 90% of the traffic to one service and remaining 10% of the traffic to other service. Can you tell me how to do this in Bluemix</p>&#xA;
34973165,How to share communication models between Akka microservices?,<scala><akka><microservices>,1,327,0,2.0,2,"<p>We are using Akka as our microservice platform. We are not going to support non-JVM platforms for now, so we use direct messaging between Akka actors as communication platform.</p>&#xA;&#xA;<p>This way, our communication units are just <strong>case classes</strong>. Do we have to repeat ourselves and define the case classes for each microservice or we can put all message classes into a single project and share it between microservice projects?</p>&#xA;&#xA;<p>I know that sharing models between microservices is not recommended but as we use Akka communication protocol, I'm not sure if creating the same communication case class in multiple projects is correct. What if a microservice change it's model and the others don't? How can we handle versioning and upgrade to new versions of the communication models without breaking the whole system.</p>&#xA;"
34973135,Service Fabric Service vs. Service Fabric Actors for user representation,<c#><.net><microservices><azure-service-fabric>,1,1445,0,0.0,2,"<p>In my application users can post events on a map. The entry point of the application is a stateless web api service. For representing the users internally, I want to have an user service. When should I use Reliable Stateful Actors and when Reliable Stateful Services to store the profile data and the posted events of each user? </p>&#xA;&#xA;<p>When a client creates a new user at the frontend, the actor or service should create a new user internally. And every time the user is logged in, the web api service should forward all user interactions to the internally representation of the user (Actor or Service). E.g. the user post a new event, the web api service find the user and forward the posted event to him. Because the posted event is public, I also want to have an reliable stateful event service. After storing the posted event inside the user, the user service should forward the event to the event service. </p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<pre><code>Client/User --&gt; WebApiService --&gt; UserService/UserActor --&gt; EventService&#xA;</code></pre>&#xA;&#xA;<p>And when a user want to see all the public events on a map the should be something like this: </p>&#xA;&#xA;<pre><code>Client/User &lt;-- WebApiService &lt;-- EventService&#xA;</code></pre>&#xA;&#xA;<p>Because the events have a geo reference, I want to partition the EventService based on geocodes or something like that. </p>&#xA;&#xA;<p>Which programming model (actor and/or service) should I prefer for such an application and why?</p>&#xA;"
34790550,Threading configuration for microservices written in java/jersey/grizzly,<java><multithreading><jersey><grizzly><microservices>,1,574,7,1.0,2,"<p>I am designing a micro-services based system. Most of the services are deployed as standalone Jersey processes with an embedded Grizzly web server.</p>&#xA;&#xA;<p>Assuming that many of those services will execute on the same machine, shall I change any threading configuration in Grizzly to prevent a situation of too many threads machine-wide?</p>&#xA;&#xA;<p>What is the default threading model for Grizzly? Is there a limit for number of threads that a single web server can create?</p>&#xA;"
45146319,Spring - Make microservice only accessible internally,<spring><spring-security><microservices>,2,221,3,0.0,2,"<p>How can I setup a microservice which can only be called by other internal services. The microservice should not be accessible in public, because it has access to databases with secret information. I already tried to secure the microservice with spring security but in this case I got problems with the FeignClient concerning authorization.</p>&#xA;"
39457873,How to include CorrelationId in microservice architecture?,<microservices><asp.net-core-webapi>,1,777,4,1.0,2,"<p>I am creating a microservices architecture using ASP.NET Core web api. All the services are decoupled from each other, and may be deployed in different environments. Every service has its own logging. When requests flows through these services it could fail in any of the service, We need a way of tracing a series of events back to the source, even if it means traversing multiple services.<br>&#xA;So to handle this issue, the service that originates the request creates a CorrelationId and pass it to the next service. The 2nd service pass it to 3rd service and so on. If exception occurs the corresponding service will log the exception message along with CorrelationId.</p>&#xA;&#xA;<p>I wanted to know what would be a best place for the caller of the service to pass the correlationid? </p>&#xA;&#xA;<p>Should the caller pass correlationid in HttpHeader or should it pass it as a part method parameter something like below</p>&#xA;&#xA;<p><em>This is the service that is getting called</em></p>&#xA;&#xA;<pre><code> public class RequestDTO&#xA; {&#xA;    public string CorrelationId {get;set;}&#xA;    public string SomeOtherData {get;set;}&#xA; }&#xA;&#xA; public Service2Controller:Controller&#xA; {&#xA;    public Task&lt;in&gt; DoSomething(RequestDTO request)&#xA;    {&#xA;         // add the correlationid in current request Items collection&#xA;         // So global exception handling can access it and log it &#xA;         // along with the exception&#xA;&#xA;         HttpContext.Items.Add(""CorrelationId"", request.CorrelationId);&#xA;    }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>in the approach above if there is an exception before this method is invoked, the CorrelationId will not be available for global exception handler for logging.</p>&#xA;&#xA;<p>Any suggestions? or alternate approach</p>&#xA;"
39561186,Best practice for loading multiple dynamic services and them dependencies services,<c#><multithreading><reflection><microservices>,2,58,5,0.0,2,"<p>I want to devlop a custom system for my self.</p>&#xA;&#xA;<p>I want to loading custom services by configuratin with dependency services - for example:</p>&#xA;&#xA;<pre><code>&lt;Services&gt;&#xA;    &lt;Service name=""ServiceA"" args="""" type=""CommonLib.IServiceA"" dependencies=""""/&gt;&#xA;    &lt;Service name=""ServiceB"" args="""" type=""CommonLib.IServiceB"" dependencies=""ServiceA""/&gt;&#xA;    &lt;Service name=""ServiceC"" args="""" type=""CommonLib.IServiceC"" dependencies=""ServiceA,ServiceB""/&gt;&#xA;    &lt;Service name=""ServiceD"" args="""" type=""CommonLib.IServiceD"" dependencies=""ServiceA,ServiceB,ServiceC""/&gt;&#xA;    &lt;Service name=""ServiceE"" args="""" type=""CommonLib.IServiceE"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD""/&gt;&#xA;    &lt;Service name=""ServiceF"" args="""" type=""CommonLib.IServiceF"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD,ServiceE""/&gt;&#xA;&lt;/Services&gt;&#xA;</code></pre>&#xA;&#xA;<p>All those services are implement custom interface:</p>&#xA;&#xA;<pre><code>public interface IService&#xA;{&#xA;    bool Start();&#xA;    bool Stop();&#xA;    bool IsReady {get;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What the best practice for loading dynamic services toghether but depends on those dependencies?</p>&#xA;&#xA;<p>Loop every service and postpone till those dependencies are loaded and ready?</p>&#xA;&#xA;<p>Have any tutorial for that?</p>&#xA;"
39888480,Where to get the vertx dashboard monitor?,<java><microservices><vert.x>,1,553,0,0.0,2,"<p>I have seen a couple of times on vertx website a vertx dashboard monitor, that looks like:    </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FrR9F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FrR9F.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>How to setup the dashboard or how to get it?  </p>&#xA;"
40081965,Where lookup tables should be placed in a microservices architecture?,<microservices><lookup-tables>,1,268,3,1.0,2,"<p>In a microservices architecture, each microservice has its own database and tables should not be duplicated in different databases.&#xA;But there are tables, like lookup tables (called also reference tables), that are needed by multiple microservices.&#xA;Should we put lookup tables in each microservice database, or is it better to create a new microservice with a database holding all the lookup tables ?</p>&#xA;"
40296598,Micro-services approach: Isolation and decoupling,<design><architecture><microservices>,1,163,3,0.0,2,"<p>I've to add a service to my Micro-services architecture and&#xA;my new services needs to compute data he's responsable of. These computations occurs at a relatively high frequency.</p>&#xA;&#xA;<p>In order to compute things, my new service needs to retrieve additional infos from another service (lets say from the same bounded context)</p>&#xA;&#xA;<p>The issue here is that all these calls on every computation might cause some performance issues.</p>&#xA;&#xA;<p>What do you think is the best approach to take here?&#xA;Is it a good idea to let my new service save a kind of snapshot of the additional infos it needs (asynchronous synchronisation with the other service) so that it doesn't have to perform all those calls every time it needs to compute. </p>&#xA;"
41039545,How to manage common frontend components on microservices,<architecture><frontend><single-page-application><microservices><orchestration>,1,438,3,2.0,2,"<p>How to manage frontend on microservices, especially when you have common components? I found a few solutions on the internet but all of them have some drawbacks and none of them is a good fit for us.</p>&#xA;&#xA;<p>Let me clearify my problem. We have over 5 groups of people working on different microservices in a large single project. And almost all of them has some common,shared components on frontend. And these components are huge as they are already a different project but totally shared. Now how to manage these shared components or should we duplicate them?</p>&#xA;&#xA;<p>First solution I found is to make those components shared and maintain from a single point like node packages and npm install when needed from different groups. But at this point the microservice approach is broken since everybody will be dependent to these components and no one will be able to maintain as soon as they need, not good. And very hard to maintain since in the future different groups may different needs from the component.</p>&#xA;&#xA;<p>Second is to duplicate the components according to each project and develop within the microservice group but this time it becomes very frankenstein and the common concepts that we should obey are hard to catch. It's a really enterprise project that all components should match in terms of behaivor and look to the other components reoccured in the project. </p>&#xA;&#xA;<p>So we need a frontend solution for microservices that should be suitable for an enterprise project which is needed to obey same rules(like font size,color,actions etc..) at different points as it is monolithly written, but maintainable by different groups at the same time.</p>&#xA;&#xA;<p>How can we balance that or can we?</p>&#xA;&#xA;<p>Thanks to @kayess: Shortly how to apply shared kernel on microservices as the teams will not be dependent to each other?</p>&#xA;"
41019199,Enabling CORS in Azure Service Fabric Web Api,<angularjs><azure><asp.net-web-api><microservices><azure-service-fabric>,2,883,5,1.0,2,"<p>I have an angular app that sends an http request to my Service Fabric Web API (deployed on a Secure Service Fabric cluster) like so:</p>&#xA;&#xA;<pre><code>    $scope.request_headers = {&#xA;            ""Content-Type"": ""application/xml; charset=utf-8"",&#xA;            ""Access-Control-Allow-Origin"":""*""&#xA;        }&#xA;    $http({&#xA;                url: ""Service_Fabric_web_api_url"",&#xA;                method: ""GET"",&#xA;                headers:$scope.request_headers&#xA;            }).&#xA;            then(function (result) {&#xA;                console.log(result);&#xA;            });&#xA;</code></pre>&#xA;&#xA;<p>I've also enabled CORS globally in my web api startup class like so:</p>&#xA;&#xA;<pre><code>HttpConfiguration config = new HttpConfiguration();&#xA;var cors = new EnableCorsAttribute(""*"", ""*"", ""*"");&#xA;config.EnableCors(cors);&#xA;</code></pre>&#xA;&#xA;<p>When I run my angular app locally and try sending the http request, I still get this error:</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load Service_Fabric_web_api_url. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:xxxxx' is therefore not allowed access. The response had HTTP status code 500.&#xA;</code></pre>&#xA;&#xA;<p>I'm able to access my service directly from my browser with the same url.</p>&#xA;&#xA;<p>Also, the same http request works when I tried deploying my Web Api on an unsecure Service Fabric Cluster with the same lines added to the startup class to enable CORS. </p>&#xA;&#xA;<p>Why is this happening even though I've enabled CORS globally in my Web API and particularly when its on a secure cluster?</p>&#xA;"
43664192,Do we create difference projects when implementing micro services architecture in spring,<java><spring><spring-mvc><spring-boot><microservices>,1,99,5,0.0,2,"<p>I am confused with microservice architecture. I am not able to understand how to implement the microservice architecture in spring. In spring we use <code>@RestController</code> for Rest API. Let's say we have two rest controller like below</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/user"")&#xA;public class UserService {&#xA;// this class will hanlder operations related to user&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/role"")&#xA;public class RoleService {&#xA;// this class will hanlder operations related to role&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Both rest controllers belong to one single project. Can we say our above structure is microservices? Or we have to create two projects one is <code>UserServiceProject</code> and another one is <code>RoleServiceProject</code>. In <code>UserServiceProject</code> we create Rest Controller for rest API of User operations. In <code>RoleServiceProject</code> we create Rest Controller for rest API of Role Operations. </p>&#xA;&#xA;<p>As microservices architecture says each service should be independently deployable. From this definition can we say that if we have 2 services we need to create two projects so that both projects can be independently deployable. </p>&#xA;&#xA;<p>Please also note both services share the same database and also there is a relationship between User and Role.</p>&#xA;"
43633659,What to use for microservices inter-communications .NET,<.net><design-patterns><microservices>,1,875,11,0.0,2,"<p>Doing some research on splitting our monolith into micro-services and trying to understand/determine the best way for communications between services, or if I should even be communicating between services?</p>&#xA;&#xA;<p>Should each micro-service be a web service that only serves Http or should I be using a service bus to pass work requests around?</p>&#xA;"
47380189,Microservices governance vs SOA,<architecture><domain-driven-design><microservices><soa>,2,475,5,2.0,2,"<p>I was working in SOA goverened projects for the last 10 years and now we switch to a Microservices architecture ones.</p>&#xA;&#xA;<p>The good thing in SOA was that we had a Canonical Data Model where which was built with some effort indeed but at the end all systems ended up speaking the same 'language' and communication was centralized via a Service Bus.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QNcwq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QNcwq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In a Microservice architecture teams are independent and as there is no service bus wonder how all this intergration points will work.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/37mGm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/37mGm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>1) Is there a way to enfore some contracts like there is WSDL in SOA (for SOAP) ?</p>&#xA;&#xA;<p>2) If team developing service B is autonoumous and deploys a new service it has to keep the old version as well no ? In SOA this problem was solved that on the service bus we kept v1 and a we did a transformation to v2.It was trasparent for consumers that service B has a new version.</p>&#xA;&#xA;<p>3) What type of govenrnance you would put in place in case the number of microservices is quite high like in the below picture knowing the teams have to be as much as possible autonoumous ('agile')?</p>&#xA;&#xA;<p>I am not looking fot the best answer , I am interested in different opinions as there is no magic solution here.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/k2mB3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k2mB3.png"" alt=""enter image description here""></a></p>&#xA;"
49944789,Handle Status Update In Even Sourcing Pattern,<java><microservices><event-sourcing>,1,61,9,0.0,2,"<p>I was looking at an auditing pattern to save history of my entity and I came across Event Sourcing Pattern. It is an interesting pattern and most of it makes sense to me but I had one question on how to implement a certain use case scenario?</p>&#xA;&#xA;<p>Use Case:</p>&#xA;&#xA;<ol>&#xA;<li>There is an invoice generated with amount of $100 and status as in review.</li>&#xA;<li>Then the invoice status is updated to billed</li>&#xA;<li>Then a payment of $50 is adjustment of $20 is made and status is updated to paid</li>&#xA;<li>We later realized that the amounts were incorrect. So we want to rollback previous transaction and revert bill status to billed again</li>&#xA;<li>We then post a payment of $70 and adjustment of $20 and update invoice status to complete.</li>&#xA;</ol>&#xA;&#xA;<p>From my understanding of event store. It should only contain the actions that were applied on the entity.So the event always has the updated transaction amounts(payment and adjustment) and status.</p>&#xA;&#xA;<p><strong>Database:</strong></p>&#xA;&#xA;<p>Invoice:</p>&#xA;&#xA;<pre><code>| id    | balance | payment | adjustment | status   |&#xA;|-------|---------|---------|------------|----------|&#xA;| 12345 | 10      | 70      | 20         | Paid     |&#xA;</code></pre>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | Event            | Payload |&#xA;|----------|------------|------------------|---------|&#xA;| 1        | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status</p>&#xA;&#xA;<p>So here are my questions</p>&#xA;&#xA;<ol>&#xA;<li>I get how balances can be reversed but I do not see how we can accomplish the same effect for status</li>&#xA;<li>Also how will I handle if api calls(commands) come out of  order for the above events. i.e &#xA;&#xA;<ul>&#xA;<li>Step 3 calls service</li>&#xA;<li>then step 5 </li>&#xA;<li>then step 4.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>from what I understand the balances will be fine but the invoice status will be incorrect.</p>&#xA;&#xA;<p>Please advise me on how to best handle this on event sourcing pattern.</p>&#xA;"
34406896,How to share code between micro services?,<architecture><microservices>,2,1258,3,1.0,2,"<p>For example, I have a project which has 4 micro services: client-web, admin-web, client-api, admin-api.</p>&#xA;&#xA;<p>These four micro services should share one DB code,  should I make the DB code as a submodule of git and use it in each micro service?</p>&#xA;&#xA;<p>does it against micro service principle? </p>&#xA;"
40960054,"Service Fabric, What Microservices is best intended for continuous polling from Service Bus",<c#><azure><microservices><azureservicebus><azure-service-fabric>,3,1421,2,1.0,2,"<p>I am new to Service Fabric.</p>&#xA;&#xA;<p>We have a queue on Azure Service Bus. I want to continuously pull from the queue in my Service Fabric, process the message (execute some business logic) and save some data in the DB, then remove the message from the queue.</p>&#xA;&#xA;<p>The Microservice should check the queue every couple of seconds to monitor for a new message.</p>&#xA;&#xA;<p>My question is, <strong>What is the intended Microservice(s) that would pull data, process some business logic, then save to the DB. Is it A Stateless Service or a Reliable Actor</strong></p>&#xA;"
40880443,Can micro services be applied to the front-end with JS?,<javascript><angularjs><reactjs><frontend><microservices>,1,524,3,0.0,2,"<p>I have a project which requires various developers to build components / modules for an app at any given time.</p>&#xA;&#xA;<p>However, each component can be written in a different framework or library e.g. <code>URI/app1</code> is a search component written in React, and <code>URI/app2</code> is a results component written in AngularJS. </p>&#xA;&#xA;<p>I'm trying to find a way so that given a <code>URI</code> if <code>URI/subdomain</code> is served I can serve a module which is fully encapsulated (technology wise) from other sub paths &amp; the URI.</p>&#xA;&#xA;<p>Does something along these lines exist? Is there a methodology or approach which will allow an app to holistically serve sub-modules (not fragments of a single page, but rather full pages under a unique path) and remain isolated to other front-end code, but still allow data to be passed across the technologies used, so that a developer could essentially come in and create a component / page / module under a subpath using the technology of their choice and have it be accepted cohesively across the existing app written in potentially varying technologies?</p>&#xA;"
46581254,Microservices and service granularity,<domain-driven-design><microservices>,3,110,4,1.0,2,"<p>I have never worked with microservices architecture before and there is something important that it is still not clear in what I am reading.</p>&#xA;&#xA;<p>In a microservice architecture a service is a single endpoint or a single module with several endpoints?</p>&#xA;&#xA;<p>Are the endpoints that are fine grained or the granularity is at a higher level? I thought at the beginning that the endpoints were fine grained and this is why there was the risk of making the API too chatty. </p>&#xA;&#xA;<p>I am now finding articles that say that in microservices architecture a service is associated to ""bounded context"". It seems to me that a bounded context needs more than a single endpoint in an API.</p>&#xA;"
46585082,Async communication between spring boot micro services,<asynchronous><spring-boot><microservices><spring-rabbitmq>,1,662,4,1.0,2,"<p>I am new to spring boot and created 2 micro services.&#xA;They need to communicate with one other in synchronous and asynchronous way.&#xA;For synchronous communication, I can use the RestTemplate.&#xA;But how to do for asynchronous calling ?&#xA;my requirement for Asynchonous is:&#xA;lets say I am querying for something from one micro service. To fetch the queried data it will take sometime because of queried for large sum of data. &#xA;In this case, I need to save the request into some transaction table and return the response with transactionId and callBackAPI. After sometime if I call the callBackAPI with transactionId. Then I should be able to get the previously queried data.</p>&#xA;&#xA;<p>Please help me with this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
45412334,API gateway and microservice authentication,<microservices><api-gateway>,1,470,0,3.0,2,"<p>How API Gateway and Micro services works.</p>&#xA;&#xA;<p>Could anyone explain the basic flow of Micro service architecture with Gateway. I couldn't find the proper answer.</p>&#xA;&#xA;<p>Say we have auth server and customer micro service running on separate instances and in front of all the services we have an API gateway.</p>&#xA;&#xA;<p>My question is.</p>&#xA;&#xA;<p>when user try to log in using username and password, the API gateway call <strong>auth server</strong> and return the <strong>access token</strong> to user.</p>&#xA;&#xA;<p>Then user trying to access the specific url (/customers - customer micro service) that is running on separate instance.&#xA;what API Gateway do ?</p>&#xA;&#xA;<ol>&#xA;<li>validate the token with auth server and get the user id and pass the request to <strong>customer service with the user id</strong> ?</li>&#xA;</ol>&#xA;&#xA;<p>OR </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>validate the token and pass the request to customer microservice <strong>with the access token</strong> ? and customer microservice responsible is to the check the user id (Make an HTTP call to auth server) ? </li>&#xA;</ol>&#xA;"
45400096,Migrating multi-module project to microservices?,<java><microservices>,5,473,1,0.0,2,"<p>I have multi module application. To be more explicit these are maven modules where high level modules depends on low level modules. &#xA;Below are the some of the modules :-</p>&#xA;&#xA;<pre><code>    user-management&#xA;    common-services&#xA;    utils&#xA;    emails&#xA;</code></pre>&#xA;&#xA;<p>For example :- If <code>user management</code> module wants to use any services from <code>utils</code> module, it can call its services as dependency of utils is already injected under user-management.&#xA;To convert/call my project truly following microserives architecture, I believe i need to convert each module as  independently deployable services where each module is a war module&#xA;and provides its services over http(mainly as resful web services) . Is that correct or anything else need to be taken care of as well ? </p>&#xA;&#xA;<p>Probably each modules now has to be secured and authentication layer as well ?</p>&#xA;&#xA;<p>If that's the crux of microservices I really do not understand when someone ask whether you have worked on microservices as to me Its not tool/platform/framework but a simple &#xA;concept to divide you monolithic application in to smaller set of deployable modules whose services is available through HTTP. Is n't it ? May be its another buzz word.</p>&#xA;&#xA;<p><strong>Update:-</strong>&#xA;Obviously there are adavantages going micro services way like independent unit testablemodule, scalable as it can be deployed on separate machine, loose coupling etc but I see I need to handle two complex concerns also </p>&#xA;&#xA;<ol>&#xA;<li>Authentication:- For each module I need to ensure it authenticates the request which is not the case right now</li>&#xA;<li>Transaction:- I can not maintain the transaction atomicity across different services which I could do very easily at present</li>&#xA;</ol>&#xA;"
45544777,"NodeJS Microservices, combining data",<javascript><node.js><redis><microservices>,1,147,13,1.0,2,"<p>I'm building a NodeJS platform that consist of several core 'parts' (users, messages and trading signals).</p>&#xA;&#xA;<p>So my idea is to create microservices for each of them, and it works pretty well.. But I can't get my head around how to 'join' data between the microservices (I'm a frontender originally.....)</p>&#xA;&#xA;<p>For example, I have 3 microservices.. Each with its own MongoDB, on its own machine complete isolated.. Imagine the common situation where the messages is retrieved from a single microservice, the message has a 'user_id' and I need to get the username and profilePicture to be combined in the retrieved message object..?</p>&#xA;&#xA;<p>I read a lot about using Redis, but it seems like a 'messaging' service to me, not much of a 'combine' service.. Can anyone help me through the darkness??</p>&#xA;&#xA;<p>Thanks!!</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jQphv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jQphv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I know its a very general question... But I just can't get a grip of what the 'best practice' is when combining data of multiple micro services..</p>&#xA;"
47145930,Microservices versioning best practices,<architecture><versioning><microservices>,2,885,0,1.0,2,"<p>I read the Susan Fowler's book ""production ready microservices"" and in two places (until now) I found </p>&#xA;&#xA;<ul>&#xA;<li>(page 26) ""Avoid Versioning Microservices and Endpoints"", </li>&#xA;<li>""versioning microservices can easily become an organizational nightmare"" (page 27),</li>&#xA;<li>In microservice ecosystems, the versioning of microservices is discouraged(page 58)</li>&#xA;</ul>&#xA;&#xA;<p>Anyway, I used all types of versioning for all kind of different projects: git tag, deb package versioning, python packages versioning, http api versions and I never had very big problems to manage the project's versions. Beside of this I knew exactly to what version to roll out in case of some failures or bugs from customers.</p>&#xA;&#xA;<p>Anybody have any clue why in this book the microservice versioning is so blamed and what advises would you have regarding the topic?</p>&#xA;"
47295217,How to start a spring boot tomcat server on a specified port through command prompt,<java><spring><spring-mvc><spring-boot><microservices>,1,415,1,2.0,2,"<p>I have a very simple ""Hello World"" kind of REST api created using Spring Boot that is accessible through <a href=""http://localhost:8080/greeting/world"" rel=""nofollow noreferrer"">http://localhost:8080/greeting/world</a> without any problem.</p>&#xA;&#xA;<p>I would like to start two more instances of this API on ports 8081 and 8082 but not able to do so. It says <code>java.net.BindException: Address already in use: bind</code></p>&#xA;&#xA;<p><strong>Command Used:</strong></p>&#xA;&#xA;<pre><code>mvn spring-boot:run -Dserver.port=8081&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong></p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: world-greeting-service&#xA;</code></pre>&#xA;&#xA;<p><strong>WorldGreetingServiceApplication.java</strong></p>&#xA;&#xA;<pre><code>@RestController&#xA;@SpringBootApplication&#xA;public class WorldGreetingServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(WorldGreetingServiceApplication.class, args);&#xA;    }&#xA;&#xA;    @RequestMapping(""/greeting/world"")&#xA;    public String greetWorld() {&#xA;        return ""Hello World!"";&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Am I missing anything?</p>&#xA;"
49490466,Global variables And Application Variables Defining in Spring boot project,<java><spring><spring-boot><microservices><configuration-files>,1,1421,5,3.0,2,"<p>I am trying to develop micro service by using spring and spring boot. In my project , I am converting monolithic to service oriented architecture. Project contain 20 Micro services.I these I need to set application variables and global variables. I have confusions related to this , And I am adding those confusions here,</p>&#xA;&#xA;<ol>&#xA;<li>Is possible to declare my global variables in application.properties file? ,If not possible where I can define my global variables?</li>&#xA;<li>If I am using spring config server for global configuration, How I can import those properties conditionally to client project?</li>&#xA;<li><p>Can I set different property files for different profiles in config server , and conditionally import into client project for different profiles? , Here each profile representing different regions in my case.</p>&#xA;&#xA;<p>Can anyone help me to clarify my confusions please? </p></li>&#xA;</ol>&#xA;"
47017657,How to have lombok to create constructor for non null fields since @RequiredArgsConstructor seems not to work?,<java><spring><microservices><lombok>,1,665,2,1.0,2,"<p>I am playing with the <strong>Lombok</strong> and already went through many link but none of them worked for me.</p>&#xA;&#xA;<p><strong>Person.java</strong></p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>PersonController.java</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/people"")&#xA;public class PersonController {&#xA;    @Autowired&#xA;    private PersonRepository personRepository;&#xA;&#xA;    @RequestMapping(value = """", method = RequestMethod.POST)&#xA;    @ResponseStatus(HttpStatus.CREATED)&#xA;    public void createPerson(@RequestBody Person person) {&#xA;        personRepository.save(new Person(person.getFirstName(), person.getLastName()));  //line-34&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But its not allowing me to create the two argument constructor</p>&#xA;&#xA;<pre><code>Multiple markers at this line&#xA;    - The constructor Person(String, String) is undefined&#xA;    - The method save(S) in the type CrudRepository&lt;Person,Long&gt; is not applicable for the arguments &#xA;     (Person)&#xA;</code></pre>&#xA;&#xA;<p><strong>On line No-34 its breaking...</strong></p>&#xA;&#xA;<p><strong>EDIT-1:</strong></p>&#xA;&#xA;<pre><code> @RequestMapping(value = ""/{id}"", method = RequestMethod.PUT)&#xA;    @ResponseStatus(HttpStatus.NO_CONTENT)&#xA;    public void updatePerson(@PathVariable(""id"") Long id, @RequestBody Person person) {&#xA;        Person existingPerson = personRepository.findOne(id);&#xA;        existingPerson.setFirstName(person.getFirstName());&#xA;        existingPerson.setLastName(person.getLastName());&#xA;        personRepository.save(existingPerson);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Here is the error</p>&#xA;&#xA;<pre><code>The method setFirstName(String) is undefined for the type Person&#xA;</code></pre>&#xA;&#xA;<p>The changes I made</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor()&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private final String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private final String lastName;&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>-===================</p>&#xA;&#xA;<p><strong>Edit-2</strong></p>&#xA;&#xA;<p>Here is the final result:</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;&#xA;    public Person(String firstName, String lastName){&#xA;        this.firstName = firstName;&#xA;        this.lastName = lastName;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
38377156,How to stop a spring boot service from command line?,<java><windows><spring><spring-boot><microservices>,1,4534,0,0.0,2,"<p>I’m a spring-boot newbie, so please go easy on me.</p>&#xA;&#xA;<p>I need to offer a way for an administrator to start and stop my spring-boot microservice from a job scheduler. If I can create <code>start.bat</code> and <code>stop.bat</code> files for the service, then the scheduler could call them.</p>&#xA;&#xA;<p>How do I stop a spring-boot microservice from command line without killing the process? I'd like a graceful exit, if possible.</p>&#xA;&#xA;<p>The host will be a Windows server.</p>&#xA;"
38453830,How defensive to be when interacting with another internal microservice?,<microservices><defensive-programming>,2,54,3,0.0,2,"<p>In this scenario there are two HTTP microservices:</p>&#xA;&#xA;<ol>&#xA;<li>The public service that provides the client with data</li>&#xA;<li>The internal microservice that authenticates calls to the public service</li>&#xA;</ol>&#xA;&#xA;<p>Service 1 makes a call to Service 2 to ask it to authenticate the token provided to it by the client.</p>&#xA;&#xA;<p>The agreement (""contract"") is that Service 2 should reply with <code>200 OK</code> and JSON content about the authenticated user.</p>&#xA;&#xA;<p>In Service 1, if it receives the response <code>200 OK</code>, is it worth going any further to validate the response further?</p>&#xA;&#xA;<p>For example, the JSON body of the response is parsed into an object. Is there value in checking if that object was correctly instantiated instead of being set to null? Or alternatively should that be left to integration tests?</p>&#xA;"
38230495,Zuul spring security and adding Additional Params in Request,<spring><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1545,7,0.0,2,"<p>I am building Microservices using Spring Microservices, I have 2 questions related to that.<br><br>1. I have spring security in the Api Gateway i.e <strong>Zuul server</strong>, now Zuul is not forwarding any request if I have already read the request from the stream once to Authenticate(to get username/pass from POST Request) <br>&#xA;<code>new ObjectMapper().readValue(request.getInputStream(), UserDto.class);</code> &#xA;<br><strong>How can I read the request and then again forward the same request to Downstream services?</strong><br><br>&#xA;2. Zuul is not forwarding <strong>request.setAttribute()</strong> to Downstream services, so a workaround is to use <strong>ctx.addZuulRequestHeader</strong>, which is making <code>Request Header</code> too huge, How can I acheive <strong>request.setAttribute</strong> and get in downstream services.</p>&#xA;&#xA;<pre><code> public Authentication getAuthentication(HttpServletRequest request) {&#xA;    final String token = request.getHeader(AUTH_HEADER_NAME);&#xA;    logger.info(""token=""+token);&#xA;    if (token != null) {&#xA;        logger.info(""Entering getAuthentication"");&#xA;        final UserToken userInfo = tokenHandler.validateToken(token);&#xA;        if (userInfo != null&#xA;                &amp;&amp; token.equals(String.valueOf(redisUtility.getValue(userInfo.getUsername()+""_""+userInfo.getUniqueId())))) {&#xA;            logger.info(""Validating token key=""+userInfo.getUsername()+""_""+userInfo.getUniqueId());&#xA;            User user=userDetailsService.loadUserByUsername(userInfo.getUsername());&#xA;            if(user!=null &amp;&amp; user.getUsername().equals(userInfo.getUsername())&#xA;                &amp;&amp; user.getLastPasswordResetTime()&lt;userInfo.getCreatedTime()){&#xA;                request.setAttribute(""username"",user.getUsername());//**Not able to fetch this in Downstream services**&#xA;                logger.info(""Token Authenticated for User ""+user.getUsername());&#xA;                return new UserAuthentication(user);&#xA;            }&#xA;        } &#xA;    }&#xA;    return null;&#xA;}&#xA;&#xA;&#xA;  public class SimpleFilter extends ZuulFilter {&#xA;&#xA;      private static Logger log = LoggerFactory.getLogger(SimpleFilter.class);&#xA;&#xA;      @Override&#xA;      public String filterType() {&#xA;        return ""pre"";&#xA;      }&#xA;&#xA;      @Override&#xA;      public int filterOrder() {&#xA;        return 1;&#xA;      }&#xA;&#xA;      @Override&#xA;      public boolean shouldFilter() {&#xA;        return true;&#xA;      }&#xA;&#xA;      @Override&#xA;      public Object run() {&#xA;        RequestContext ctx = RequestContext.getCurrentContext();&#xA;        HttpServletRequest request = ctx.getRequest();&#xA;        request.setAttribute(""test"", ""test"");// Not able to get this in services&#xA;        log.info(String.format(""%s request to %s"", request.getMethod(), request.getRequestURL().toString()));&#xA;&#xA;        return null;&#xA;      }&#xA;&#xA; @Bean&#xA;  public SimpleFilter simpleFilter() {&#xA;    return new SimpleFilter();&#xA;  }&#xA;&#xA;@RequestMapping(value = ""/test/avl"",method=RequestMethod.POST)&#xA;  public String test(HttpServletRequest request) {&#xA;    System.out.println(request.getAttribute(""test"")+"""");&#xA;    return ""Spring in Action"";&#xA;  }&#xA;</code></pre>&#xA;"
51149979,Microservicess with Serverless (Lambda or Function),<azure><lambda><microservices><azure-functions>,2,61,0,2.0,2,"<p>I have some concern on getting an idea of migrating current microservices system into serverless.</p>&#xA;&#xA;<p>Right now, between services are communicating with HTTP or API based.&#xA;Serverless like lambda or function can talk to each other with function call or lambda call. This way can be done by changing all HTTP code into lambda call within all services.</p>&#xA;&#xA;<p>Another way is still using HTTP request to call another service that on lambda through API Gateway. This method of calling is not good because the service request gone to Internet and go back again into API Gateway then neighbor service get the request. Too long and does not make sense for me.</p>&#xA;&#xA;<p>I will be glad if lambda app call another lambda app with local network HTTP request, this is still on my research on how to do it.</p>&#xA;&#xA;<p>I would like to know from all of you about your experience on migrating microservices based on HTTP communication between services into serverless like Lambda or Functions ?</p>&#xA;&#xA;<p>Do you change all your code into specific lambda function call ?&#xA;Do you use HTTP over internet and API Gateway again to call neighbor service ?&#xA;Have you guys figured it out on Local / Private network lambda call ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;"
51189616,How can I proceed a delete operation in Lagom Framework?,<java><scala><akka><microservices><lagom>,2,79,4,0.0,2,"<p>I am a little newbie on the Lagom framework and I need to know what the right way to do a delete operation in this framework. I develop with Java and I tested two approaches:</p>&#xA;&#xA;<ol>&#xA;<li>when I handle the delete event I set the state to Optional.empty () but it returns nullPointerException crashes and the line in my readSide (Cassandra DataBase) is not deleted</li>&#xA;<li>I add a Status field to my entity and when I handle the delete event I pass it to -1. When I refer to my entity I test on State.present and status! = -1 to make sure the entity and deleted. For the readSide, the line is deleted properly</li>&#xA;</ol>&#xA;&#xA;<p>In terms of logic, I think the second approach is the most logical but I want to know if there is a good practice that the Lagom framework offers developers to do delete operations</p>&#xA;&#xA;<p><strong>EDIT 1</strong>&#xA;This is my ReadSideHandler code, how can I proceed to handle properly the empty option</p>&#xA;&#xA;<pre><code>@Override&#xA;public ReadSideHandler&lt;AuthenticationEvent&gt; buildHandler() {&#xA;    return readSide.&lt;AuthenticationEvent&gt;builder(""authenticationEventOffset"")&#xA;            .setGlobalPrepare(this::createTables)&#xA;            .setPrepare(tag -&gt; prepareStatements())&#xA;            .setEventHandler(AuthenticationLoginEvent.class,&#xA;                    e -&gt; insertAuthentication(e.getAuthentication()))&#xA;            .setEventHandler(AuthenticationLogoutEvent.class, e -&gt; deleteAuthentication(e.getAccessToken()))&#xA;            .build();&#xA;}&#xA;</code></pre>&#xA;"
51227737,How to implement OpenID Connect authentication with 3rd party IDPs in a microservices architecture,<oauth-2.0><jwt><microservices><openid-connect>,3,192,4,0.0,2,"<p>For the past 10+ days I've read an watched ALL the content I could find on understanding OAuth2 and OpenID Connect, only to find that many people disagree on the implementation, which really confuses me.</p>&#xA;&#xA;<p>To my understanding, all the articles and examples I found assume you want access to eg. google calendar, profile info or emails if you eg. login with google, but I do NOT need to access other than my own API's - I only want to use Google, Facebook etc for logging in, and getting an id which I can link to my user in my own database - nothing more than that.</p>&#xA;&#xA;<p>I'll try illustrate my use case and use that as an example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/H4VwP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H4VwP.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>A note on the diagram: the Authentication service could probably be built into the API Gateway - not that i matters for this example, since this is not about ""where to do it"", but ""how to do it the best way"" possible, for an architecture such as mine, where it's used for my own API's / Microservices, and not accessing Google, Facebook etc. external API's</em></p>&#xA;&#xA;<p>If you can understand what I'm trying to illustrate with this diagram above, please tell me if I've misunderstood this.</p>&#xA;&#xA;<p>The most basic requirements for this architecture you see here are:</p>&#xA;&#xA;<ul>&#xA;<li>Users can login with Google, Facebook, etc.</li>&#xA;<li>The same login will be used for all micro-services</li>&#xA;<li>OpenId user will have a linked account in the database</li>&#xA;<li>User access is defined in my own db, based on groups, roles and permissions</li>&#xA;</ul>&#xA;&#xA;<p>I do not intend to use external API's after the user is authenticated and logged in. No need for ever accessing a users calendar, email etc. so I really just need the authentication part and nothing else (proof of successful login). All user access is defined in my own database.</p>&#xA;&#xA;<p>So a few fundamental questions comes to mind.</p>&#xA;&#xA;<ul>&#xA;<li>First of all, is OpenID Connect even the right tool for the job for authentication only (I'll have no use for authorization, since I will not need read/write access to google / facebook API's other than getting the ID from authenticating)?</li>&#xA;<li>People generally do not agree on whether to use the ID or Access token for accessing your own API's. As far as I understand the ID token is for the client (user-agent) only, and the access token is for eg. accessing google calendar, emails etc.... External API's of the OpenID Provider... but since I'll only be accessing my own API's, do I event need the access token or the ID token - what is the correct way to protect your own API's?</li>&#xA;</ul>&#xA;&#xA;<p>If the ID token is really just for the client, so it can show eg. currently logged in user, without going to the DB, I have 0 use for it, since I'll probably query the user from from the db and store it in redux for my react frontend app.</p>&#xA;&#xA;<p><strong>Dilemma: To store user details, groups, roles and permission inside JWT or not for API authorization?</strong></p>&#xA;&#xA;<ul>&#xA;<li>By only storing the user identifier in the token, it means that I always allow authenticated users that has a valid token, to call endpoints BEFORE authorization and first then determine access based on the db query result and the permissions in my own database.</li>&#xA;<li>By storing more data about the user inside the JWT, it means that in some cases, I'd be able to do the authorization / access (group, role, permission) check before hitting the API - only possible with user info, groups, roles and permission stored inside a JWT issued upon login. In some cases it would not be possible due to eg. the CMS content access permissions being on a per-node level. But still it would mean a little better performance. </li>&#xA;</ul>&#xA;&#xA;<p>As you can see on the diagram I'm sending all API requests through the gateway, which will (in itself or with an authentication service) translate the opaque access token into some JWT with an identifier, so I can identify the user in the graph database - and then verify if the user has the required groups, roles and permissions - not from an external API, but from my own database like you see on the diagram.</p>&#xA;&#xA;<p>This seems like a lot of work on every request, even if the services can share the JWT in case multiple services should need to cross call each other.</p>&#xA;&#xA;<p>The advantage of always looking up the user, and his permissions in the db, is naturally that the moment the user access levels change, he is denied/granted access immediately and it will always be in sync. If I store the user details, groups, roles and permission inside a JWT and persist that in the client localstorage, I guess it could pose a security issue right, and it would be pretty hard to update the user info, groups, roles and permissions inside that JWT?</p>&#xA;&#xA;<p>One big advantage of storing user access levels and info inside the JWT is of course that in many cases I'd be able to block the user from calling certain API's, instead of having to determine access after a db lookup.</p>&#xA;&#xA;<p>So the whole token translation thing means increased security at the cost of performance, but is is generally recommended and worth it? Or is it safe enough to store user info and groups, roles, permissions inside the JWT? </p>&#xA;&#xA;<p>If yes, do I store all that information from my own DB in the ID Token, Access token or a 3rd token - what token is sent to the API and determines if the user should be granted access to a given resource based on his permissions in the db? Do I really need an access token if I don't need to interact with the ID providers API? Or do I store and append all my groups, roles, permissions inside the ID token (that doesn't seem clean to me) issued by OpenID connect, and call the API and authorize my own API endpoints using that, even if some say you should never use the ID token to access an API? Or do I create a new JWT to store all the info fetched from my database, which is to be used for deciding if the user can access a given resource / API endpoint?</p>&#xA;&#xA;<p>Please do not just link to general specs or general info, since I've already read it all - I just failed to understand how to apply all that info to my actual use case (the diagram above). Try to please be as concrete as possible.</p>&#xA;&#xA;<p>Made another attempt to try and simply the flow:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/1d1Tn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1d1Tn.png"" alt=""enter image description here""></a></p>&#xA;"
48209566,What to do when the queue is down?,<architecture><queue><message-queue><microservices><amazon-sqs>,5,142,2,0.0,2,"<p>I have 2 microservices, <code>A</code> and <code>B</code>. When <code>A</code> receives a request from a user, it gets processed (store some things in the database) and a message is sent to a queue that is read by <code>B</code>.</p>&#xA;&#xA;<p>If the queue is down, my initial thought is to make the entire request fall over, rollback, and show an error to the user asking to try again later. Is it a bad practice?</p>&#xA;&#xA;<p>Would it be a better practice to store the messages in <code>A</code>'s database marked as <code>NOT_SENT</code> and have a job to send it later when the queue is up again? Or is it over-engineering?</p>&#xA;&#xA;<p>EDIT: the request to <code>A</code> needs to be synchronous, so the user knows its outcome, but they <strong>don't</strong> need to know yet the results of <code>B</code> processing the message, so it can be asynchronous.</p>&#xA;"
48294450,"Microservices, CQRS: Eventual consistency vs Strong consistency(Read after Write consistency)",<microservices><cqrs><eventual-consistency>,3,910,4,1.0,2,<p>Using CQRS and Event store the choreography between microservices delivers an Eventual consistency where in the changes in one microservice take a bit to propagate to the other downstream systems(essentially other microservices) which are related.&#xA;What are the options if the data is so critical that both the microservices should have a strong consistency for the data? One option that i can think of is a write through Cache like a data grid but that would be very fragile specially in a distributed system.</p>&#xA;
44886715,Should the Auth Server be combined with the User Service in a microservices architecture?,<spring><authentication><oauth-2.0><microservices>,2,592,0,0.0,2,"<p>I am currently building a microservices based application in spring boot with the following services</p>&#xA;&#xA;<ul>&#xA;<li>Auth server (Distributes access tokens)</li>&#xA;<li>User service (User info like username, password, email, etc.)</li>&#xA;<li>Various other unrelated services</li>&#xA;</ul>&#xA;&#xA;<p>When a user sends their credentials to the auth server, the auth server should verify that they are correct and then return an access token. </p>&#xA;&#xA;<p>My question is, should I combine the auth server with the user service so looking up credentials is a simple database call, or should I keep them as separate applications and have them both point to the same shared database? Is there a better alternative?</p>&#xA;"
43100199,zuul API Gateway Filter,<spring><microservices><spring-cloud><netflix-zuul>,2,545,3,0.0,2,"<p>I am facing problem when i trying to access another REST API(registered in ZUUL route) from zuul pre-filter, the call is becoming recursive i.e its running my pre-filter code again and again. My Usecase is as follows-</p>&#xA;&#xA;<ol>&#xA;<li><p>In Zuul <code>PreFilter</code> <code>run()</code> method, I am validating the token passed in the header.</p></li>&#xA;<li><p>After validating the token, I am calling one rest service(User Location Service) to fetch the user details. My User Location Service is itself registered in ZUUL as below:</p>&#xA;&#xA;<pre><code>user-location-service:&#xA;  path: /userLocationService/**&#xA;  url: http://localhost:9002&#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>The problem is that the JWT token validation code is running again and again, Can you please suggest some solution where I can apply the call Userlocation service so that the <code>PreFilter</code> code would not run again and again?</p>&#xA;"
43212533,Eventual Consistency in microservice-based architecture temporarily limits functionality,<microservices><application-design><eventual-consistency><event-based-programming>,1,629,3,0.0,2,"<p>I'll illustrate my question with Twitter. For example, Twitter has microservice-based architecture which means that different processes are in different servers and have different databases.</p>&#xA;&#xA;<p>A new tweet appears, server A stored in its own database some data, generated new events and fired them. Server B and C didn't get these events at this point and didn't store anything in their databases nor processed anything.</p>&#xA;&#xA;<p>The user that created the tweet wants to edit that tweet. To achieve that, all three services A, B, C should have processed all events and stored to db all required data, but service B and C aren't consistent yet. <strong>That means that we are not able to provide edit functionality</strong> at the moment.</p>&#xA;&#xA;<p>As I can see, a possible workaround could be in switching to immediate consistency, but that will take away all microservice-based architecture benefits and probably could cause problems with tight coupling.    </p>&#xA;&#xA;<p>Another workaround is to restrict user's actions for some time till data aren't consistent across all necessary services. Probably a solution, depends on customer and his business requirements.    </p>&#xA;&#xA;<p>And another workaround is to add additional logic or probably service D that will store edits as user's actions and apply them to data only when they will be consistent. Drawback is very increased complexity of the system.</p>&#xA;&#xA;<p>And there are two-phase commits, but that's 1) not really reliable 2) slow.<br>&#xA;I think slowness is a huge drawback in case of such loads as Twitter has. But probably it could be solved, whereas lack of reliability cannot, again, without increased complexity of a solution.</p>&#xA;&#xA;<p>So, the questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Are there any nice solutions to the illustrated situation or only things that I mentioned as workarounds? Maybe some programming platforms or databases?</li>&#xA;<li>Do I misunderstood something and some of workarounds aren't correct?</li>&#xA;<li>Is there any other approach except Eventual Consistency that will guarantee that all data will be stored and all necessary actions will be executed by other services?</li>&#xA;</ol>&#xA;&#xA;<p><em>Why Eventual Consistency has been picked for this use case</em>? As I can see, right now it is the only way to guarantee that some data will be stored or some action will be performed if we are talking about event-driven approach when some of services will start their work when some event is fired, and following my example, that event would be “tweet is created”. So, in case if services B and C go down, I need to be able to perform action successfully when they will be up again.</p>&#xA;&#xA;<p>Things I would like to achieve are: reliability, ability to bear high loads, adequate complexity of solution. Any links on any related subjects will be very much appreciated.</p>&#xA;&#xA;<p>If there are natural limitations of this approach and what I want cannot be achieved using this paradigm, it is okay too. I just need to know that this problem really isn't solved yet.</p>&#xA;"
51976057,Microservices architecture and MySQL database pagination,<javascript><mysql><node.js><amazon-web-services><microservices>,2,103,2,2.0,2,"<p>So imagine, I want to retrieve all orders for an array of customers.&#xA;The <code>arrayList</code> in the example below will have an array of customer IDs.</p>&#xA;&#xA;<p>This array will be passed into the <code>get</code> method below and processed asynchronously retrieving orders for each customer ID in the array.</p>&#xA;&#xA;<p>Here's where I get lost. How can you paginate the database result set and pull only a small set of records at a time from the database without bring having to pull all the records across the network.</p>&#xA;&#xA;<p>What's confusing me is the asynchronous nature as well as we won't know how many orders per customer there are? So how can you efficiently return a set page size at a time?</p>&#xA;&#xA;<p><strong>service.js</strong></p>&#xA;&#xA;<pre><code>function callToAnotherService(id) {&#xA;    return new Promise((resolve, reject) =&gt; {&#xA;        //calls service passing id&#xA;    }&#xA;}&#xA;&#xA;exports.get = arrayList =&gt; Promise.all(arrayList.map(callToAnotherService))&#xA;    .then((result) =&gt; result);&#xA;</code></pre>&#xA;"
45990451,How to silently refresh expired JWT token with OAuth2?,<authentication><oauth-2.0><jwt><microservices><refresh-token>,1,963,0,0.0,2,"<p>We have decided to switch from Hazelcast shared session to Stateless JWT authentication/authorization with OAuth2 and found out a problem that doesnt fit our infrastructure described below.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pLIL5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pLIL5.png"" alt=""Current Hazelcast shared session""></a></p>&#xA;&#xA;<p>So we have multiple Self-contained systems (scs) that may be accessed by direct link i.e. <em>mysite.com/scs1</em> and <em>mysite.com/scs2</em>. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qVsxd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qVsxd.png"" alt=""Stateless JWT so called Session""></a></p>&#xA;&#xA;<p>Each scs has it's own UI and BackEnd, but ""session"" (implemented via Stateless JWT Authorization) has to be valid across multiple scs'es.</p>&#xA;&#xA;<p>OAuth2 Authorizaion Server is a dedicated server (UAA).&#xA;In the OAuth2 terminology, each scs is a Resource Server.</p>&#xA;&#xA;<p>Let's assume that user has logged into <strong>scs1</strong> (via UAA) and got JWT with TTL=10 minutes and RefreshToken with TTL=30 minutes. Then he leaves that tab in browser for 15 minutes. JWT expires, but the tab still contains the previous page from <strong>scs1</strong>. And user clicks a link on that page that follows to <em>mysite.com/scs3</em>.</p>&#xA;&#xA;<p><strong>scs3</strong> receives a request, checks JWT and finds out that it has expired. But we have a RefreshToken (still alive for 15 minutes) that may refresh JWT.</p>&#xA;&#xA;<p>Is it possible to return a response from <strong>scs3</strong> that would ask browser to go to UAA and silently refresh JWT ?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GicBn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GicBn.png"" alt=""JWT has expired""></a></p>&#xA;&#xA;<p>Maybe some kind of REDIRECT to /uaa/authorization with an ability to add RefreshToken Header?</p>&#xA;"
45886359,Golang Nats subscribe issue,<go><message-queue><microservices><nats.io>,1,262,5,0.0,2,"<p>I work currently on a micro service architecture.&#xA;Before I insert NATS into my project I wanted to test some simple scenarios with it.</p>&#xA;&#xA;<p>In one scenario I have a simple publisher, which publishes 100.000 messages in a for loop over a basic Nats server running on localhost:4222.</p>&#xA;&#xA;<p>The big problem with it, is the subscriber. When he receive between 30.000 - 40.000 messages my whole main.go program and all other go routines just stops and do nothing. I can just quit with ctrl + c. But the Publisher is still keep sending the messages. When I open a new terminal and start a new instance of the subscriber all again works well, till the Subscriber receive about 30000 messages. And the worst thing is that there appears not even one error and also no logs on the server so I have no idea whats going on.</p>&#xA;&#xA;<p>After that I was trying replace the Subscribe-method with the QueueSubscribe-method and all works fine.</p>&#xA;&#xA;<p>What is the main difference between Subscribe and QueueSubscribe?</p>&#xA;&#xA;<p>Is NATS-Streaming a better opportunity? Or in which cases I should prefer Streaming and in which the standard NATS-Server </p>&#xA;&#xA;<p>Here is my code:</p>&#xA;&#xA;<p>Publisher:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;func main() {&#xA;    go createPublisher()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createPublisher() {&#xA;&#xA;    log.Println(""pub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    msg := make([]byte, 16)&#xA;&#xA;    for i := 0; i &lt; 100000; i++ {&#xA;        nc.Publish(""alenSub"", msg)&#xA;        if (i % 100) == 0 {&#xA;            fmt.Println(""i"", i)&#xA;        }&#xA;        time.Sleep(time.Millisecond)&#xA;    }&#xA;&#xA;    log.Println(""pub finish"")&#xA;&#xA;    nc.Flush()&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Subscriber:</p>&#xA;&#xA;<pre><code>package main&#xA;&#xA;import (&#xA;    ""fmt""&#xA;    ""log""&#xA;    ""time""&#xA;&#xA;    ""github.com/nats-io/go-nats""&#xA;)&#xA;&#xA;var received int64&#xA;&#xA;func main() {&#xA;    received = 0&#xA;&#xA;    go createSubscriber()&#xA;    go check()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func createSubscriber() {&#xA;&#xA;    log.Println(""sub started"")&#xA;&#xA;    nc, err := nats.Connect(nats.DefaultURL)&#xA;    if err != nil {&#xA;        log.Fatal(err)&#xA;    }&#xA;    defer nc.Close()&#xA;&#xA;    nc.Subscribe(""alenSub"", func(msg *nats.Msg) {&#xA;        received++&#xA;    })&#xA;    nc.Flush()&#xA;&#xA;    for {&#xA;&#xA;    }&#xA;}&#xA;&#xA;func check() {&#xA;    for {&#xA;        fmt.Println(""-----------------------"")&#xA;        fmt.Println(""still running"")&#xA;        fmt.Println(""received"", received)&#xA;        fmt.Println(""-----------------------"")&#xA;        time.Sleep(time.Second * 2)&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
48505946,Single Database backed Micro-server architecture?,<architecture><microservices>,2,121,3,0.0,2,"<p>In an application I am planning to build, I am trying to decide an architecture for our server. One idea I had was to spawn multiple servers at different addresses like <code>orders.example.com</code>, <code>settings.example.com</code> etc, i.e. , one server process per component of the system, which will be backed by a single database cluster.</p>&#xA;&#xA;<p>I am wondering if this is a good idea, and what are the caveats of it, if anyone has ever used it ?</p>&#xA;"
48531937,AWS ALB per ECS Service vs. multiple services per ALB for a microservices architecture,<amazon-web-services><microservices><amazon-elb><amazon-route53><amazon-alb>,1,272,4,0.0,2,"<p>Initially I thought that multiple services per ALB listener with different path patterns to distribute API calls appropriately was the obvious choice. In terms of health checks though (if one of those services goes down), I don't know of a smart way to divert traffic for just that service to a different region. </p>&#xA;&#xA;<p>If I have an active active setup with weighted route 53 records that will failover on a health check, I don't see any other solution than to either cut off that entire ALBs traffic and divert to another region, or ignore the 1 down service and continue to send traffic to the partially failing ALB.</p>&#xA;&#xA;<p>Having a one to one mapping of ALBs to services fixes this solution, but it adds additional overhead in terms of cost and complexity.</p>&#xA;&#xA;<p>What is the recommended pattern to follow for an active active microservices architecture?</p>&#xA;"
48687955,Communication among microservices: Apache Kafka vs Hazelcast's Topic,<apache-kafka><microservices><messaging><hazelcast>,1,400,0,2.0,2,"<p>Disclaimer.&#xA;I have experience with <a href=""https://hazelcast.com/"" rel=""nofollow noreferrer"">Hazelcast</a> and <a href=""http://vertx.io/"" rel=""nofollow noreferrer"">Vert.x</a>. I'm new to <a href=""https://kafka.apache.org/"" rel=""nofollow noreferrer"">Apache Kafka</a>. Sorry if my question look preconceived, it's not.</p>&#xA;&#xA;<p>There are two widespread ways to arrange communication among microservices: REST and messaging. In my region, when someone says they're using messaging for communication among microservices - it de facto means Apache Kafka. </p>&#xA;&#xA;<p><em>Could you please help me to find a clue why Apache Kafka is better fit for communication needs among microservices than Hazelcast's Topic? Is it better? Because of which guarantees, features or architecture decisions?</em></p>&#xA;&#xA;<p>The Hazelcast's example for cluster wide messaging looks as following:</p>&#xA;&#xA;<pre><code>// node #1&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"")&#xA;         .publish(new Date());&#xA;&#xA;// node #2&#xA;Hazelcast.newHazelcastInstance()&#xA;         .getTopic(""topic"");&#xA;         .addMessageListener(message -&gt; /*Do something here*/);&#xA;</code></pre>&#xA;&#xA;<p>Also there is Vert.x (very roughtly speaking actors framework) written on top of Hazelcast's topics and member discovery.</p>&#xA;&#xA;<p><em>Is Kafka messaging better for communication among microservices?</em></p>&#xA;"
48753245,How to expose APIs endpoints from private AWS ALB,<amazon-web-services><microservices><amazon-vpc><aws-ecs>,3,240,0,0.0,2,"<p>We are having several microservices on AWS ECS. We have single ALB which has different target group for different microservices. We want to expose some endpoints externally while some endpoints just for internal communication. </p>&#xA;&#xA;<p>The problem is that if we put our load balancer in public VPC than it means that we are exposing all register endpoints externally. If we move load balancer to private VPC, we have to use some sort of proxy in public VPC, which required additional infra/cost and custom implementation of all security concerns like D-DOS etc.</p>&#xA;&#xA;<p>What possible approaches we can have or does AWS provide some sort of out of the box solution for this ?</p>&#xA;"
48731168,How to apply a microservices architecture to a voting application?,<node.js><microservices>,2,66,4,2.0,2,"<p>I am developing the FreeCodeCamp full stack voting application and would like to apply a microservices architecture. The user stories of the voting application are as follows:</p>&#xA;&#xA;<ul>&#xA;<li>As an authenticated user, I can keep my polls and come back later to access them.</li>&#xA;<li>As an authenticated user, I can share my polls with my friends.</li>&#xA;<li>As an authenticated user, I can see the aggregate results of my polls.</li>&#xA;<li>As an authenticated user, I can delete polls that I decide I don't want anymore.</li>&#xA;<li>As an authenticated user, I can create a poll with any number of possible items.</li>&#xA;<li>As an unauthenticated or authenticated user, I can see and vote on everyone's polls.</li>&#xA;</ul>&#xA;&#xA;<p>I am conceptualizing an architecture and come up with this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hn6Pe.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hn6Pe.jpg"" alt=""Concept Architecture Voting App""></a></p>&#xA;&#xA;<p>The application is composed of 6 microservices:&#xA;1. UI&#xA;2. Aggregator&#xA;3. Authorization (login, logout)&#xA;4. Social Media (sharing)&#xA;5. Polls (with db)&#xA;6. Users (with db)</p>&#xA;&#xA;<p>Curious how a developer having built microservices would break down these user stories into microservices. Thank you!</p>&#xA;"
48809275,SpringBoot microservice How to set properties in application context using java configuration,<java><spring><spring-boot><microservices><applicationcontext>,2,455,4,0.0,2,"<p>I have a spring-boot microservice with Java based config. Now there is an auth token container, which I need to call to get the access token. That auth token library has a class like this. Notice that the class <code>AuthServletContextListener</code> comes from a third party  <code>jar</code> file which I can not modify.</p>&#xA;&#xA;<pre><code>public class AuthServletContextListener implements ServletContextListener {&#xA;    public void contextInitialized(ServletContextEvent arg0) {&#xA;        try {&#xA;            ServletContext e = arg0.getServletContext();&#xA;            Properties config = new Properties();&#xA;            this.addProp(config, e, ""auth.token.url"", ""Token Service URL"");&#xA;            this.addProp(config, e, ""auth.system.username"", ""System Username"");&#xA;            this.addProp(config, e, ""cauth.system.password"", ""System Password"");&#xA;            TokenContainer.init(config);&#xA;        } catch (IOException arg3) {&#xA;            arg3.printStackTrace();&#xA;        }&#xA;&#xA;    }&#xA;&#xA;&#xA;    private void addProp(Properties config, ServletContext context, String propName, String descrip) {&#xA;        String propVal = (String) context.getAttribute(propName);&#xA;        if (StringUtils.isEmpty(propVal)) {&#xA;            propVal = context.getInitParameter(propName);&#xA;        }&#xA;&#xA;        if (StringUtils.isNotEmpty(propVal)) {&#xA;            config.put(propName, propVal);&#xA;        } else {&#xA;            throw new RuntimeException(""error: "");&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The AuthContextListener has an annotation that automatically looks for an application startup event. This automatically starts the container correct settings if the above context params are included. I can then grab the token through that container like this:</p>&#xA;&#xA;<pre><code>TokenContainer.getSystemToken() &#xA;</code></pre>&#xA;&#xA;<p>This will initialize successfully if the above context params are included in the web.xml like so:</p>&#xA;&#xA;<pre><code>&lt;context-param&gt;&#xA;   &lt;param-name&gt;auth.system.username&lt;/param-name&gt;&#xA;   &lt;param-value&gt;UserName&lt;/param-value&gt;&#xA;&lt;/context-param&gt; &#xA;</code></pre>&#xA;&#xA;<p>The same Application context configuration as above can be performed by creating a Spring bean with the following information:</p>&#xA;&#xA;<pre><code>&lt;bean&gt;&#xA;    &lt;property name=""attributes""&gt;&#xA;        &lt;map&gt;&#xA;            &lt;entry key=""auth.token.url"" value=""${auth.token.url}""/&gt;&#xA;            &lt;entry key=""auth.system.username"" value=""${auth.system.username}""/&gt;&#xA;            &lt;entry key=""auth.system.password"" value=""${auth.system.password}""/&gt;&#xA;        &lt;/map&gt;&#xA;    &lt;/property&gt;&#xA;&lt;/bean&gt;&#xA;</code></pre>&#xA;&#xA;<p>My question is how can I achieve the same using Java based configuration in a latest spring boot application. All I have is <code>application.yml</code> file with the auth endpoint, username and password values. I tried using <code>@Configuration</code> bean but no luck. How can I set those three props in application context and make that listener start automatically for me.</p>&#xA;"
48762736,What is the best way to send password from app server to authentication micro service?,<node.js><microservices>,1,53,7,0.0,2,"<p>I am currently in a process to develop micro service architecture in one of my projects. I have one public layer of App Servers which actually routes the user requests to relevant micro services and replies back to client. My mirco services are in private layer.</p>&#xA;&#xA;<p>Currently i am using REST API to send data back and forth. However, I was wondering, what is the best way to send username and password from app server to micro service? Should I use plain text format as micro service is in private layer? Please suggest best way.</p>&#xA;"
51099034,Map JPA Embedded entity class id to Embeddable entity class id,<java><hibernate><spring-data-jpa><microservices><hibernate-mapping>,2,119,5,0.0,2,"<p>I have a class:</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class A {&#xA;    @Embedded&#xA;    @AttributeOverride(name = ""id"", column = @Column(name = ""b_id""))&#xA;    private B b;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There is column b_id BIGINT NOT NULL in table A</p>&#xA;&#xA;<pre><code>@Embeddable&#xA;@Entity&#xA;public class B {&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>we are getting error: Caused by: org.hibernate.MappingException: component property not found: id</p>&#xA;&#xA;<p>Basically, we need to map B in A using id</p>&#xA;&#xA;<p>Kindly help</p>&#xA;"
50392109,Understanding Cassandra - can it replace RDBMS?,<cassandra><bigdata><microservices><cql>,2,81,3,1.0,2,"<p>I've spent the last week cramming on Cassandra, trying to understand the basics, as well as if it fits our needs, or not. I think I understand it on a basic level at this point, but if it works like I believe I'm being told...I just can't tell if it's a good fit.</p>&#xA;&#xA;<p>We have a microservices platform which is essentially a large data bus between our customers. They use a set of APIs to push and pull shared data. The filtering, thus far, is pretty simple...but there's no way to know what the future may bring.</p>&#xA;&#xA;<p>On top of this platform is an analytics layer with several visualizations (bar charts, graphs, etc.) based on the data being passed around.</p>&#xA;&#xA;<p>The microservices platform was built atop MySQL with the idea that we could use clustering, which we honestly did not have a lot of luck with. On top of that, changes are painful, as is par for the course in the RDBMS world. Also, we expect extraordinary amounts of data with thousands-upon-thousands of concurrent users - it seems that we'll have an inevitable scaling problem.</p>&#xA;&#xA;<p>So, we began looking at Cassandra as a distributed nosql potential replacement.</p>&#xA;&#xA;<p>I watched the DataStax videos, took a course on another site, and started digging in. What I'm finding is:</p>&#xA;&#xA;<ul>&#xA;<li>Data is stored redundantly across several tables, each of which uses different primary and clustering keys, to enable different types of queries, since rows are scattered across different nodes in the cluster</li>&#xA;<li>Rather than joining, which isn't supported, you'd denormalize and create ""wide"" tables with tons of columns</li>&#xA;<li>Data is eventually consistent, so new writes may not be readily readable in a predictable, reasonable amount of time.</li>&#xA;<li>CQL, while SQL-like, is mostly a lie. How you store and key data determines which types of queries you can use. It seems very limited and inflexible.</li>&#xA;</ul>&#xA;&#xA;<p>While these concepts make sense to me, I'm struggling to see how this would fit most long-term database needs. If data is redundant across several different tables...how is it managed and kept consistent across those many tables? Are materialized views the answer in this case?</p>&#xA;&#xA;<p>I <em>want</em> to like this idea and love the distributed features, but frankly am mostly scared off, at this point. I feel like I've learned a lot and nothing at all, in the last week, and am entirely unsure how to proceed.</p>&#xA;&#xA;<p>I looked into JanusGraph, Elassandra, etc. to see if that would provide a simpler interface on top of Cassandra, relegating it to basically a storage engine, but am not confident many of these things are mature enough or even proper, for what we need.</p>&#xA;&#xA;<p>I suppose I'm looking for direction and insight from those of you who have built things w/ Cassandra, to see if it's a fit for what we're doing. I'm out of R&amp;D time, unfortunately. Thanks!</p>&#xA;"
50455134,Can Software Architects predict of how microservice architectures will mature over time?,<architecture><microservices><soa><software-design>,1,81,4,1.0,2,"<p>In March 2014 ( just over four years ago at the time of this question ), James Lewis and Martin Fowler wrote: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Many people believe that [decay of modularity over time] is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can't truly assess how microservice architectures mature.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now that many MSAs have been built by a variety of businesses, do we have a general understanding of the maturation of these architectures? What do we know about what works as time goes forward? What do we know about what does not work?</p>&#xA;"
37854185,Server to Server communication in microservices,<java><spring><microservices><spring-cloud-netflix>,2,967,11,1.0,2,"<p>I am working on microservice architecture, but I am facing some challenges in that.</p>&#xA;&#xA;<p>First let me give you a brief about the architecture.</p>&#xA;&#xA;<ol>&#xA;<li><p>User logs in and get a signed token which will be used to call all REST APIS.</p></li>&#xA;<li><p>There will be lot of API server where APIs are secured using Spring security and Authorized as per the user roles.</p></li>&#xA;<li><p>Services have to interact with each other to get/update information.</p></li>&#xA;<li><p>Every service will have the power to validate a token issue by auth server.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem:-</p>&#xA;&#xA;<ol>&#xA;<li><p>Everything works fine if User logs in and the same token is used and passsed to every service which is validated across.So, services dont need to trust each other as the token is passed.</p></li>&#xA;<li><p>Now, the problem is there are some services which needs to be called from server itself without logging in. Lets say a server to server call. How will a service authenticate and authorize the call from other services.</p></li>&#xA;</ol>&#xA;&#xA;<p>I read about spring Microservices but Zuul is also not the saviour here as every API server has spring security embedded and not just the API gateway.</p>&#xA;&#xA;<p>One solution can be that every service has its own default user with certaing roles which is used to Login->Fetch a token->call other server api with token.</p>&#xA;&#xA;<p>Can you please give me some pointers in server to server calls where each server is authenticated and authorized using spring security.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;"
40691082,Splitting and naming Microservices,<soa><microservices>,1,1036,0,1.0,2,"<p>I recently started a side-project. It was supposed to be a virtual recipe-book with the capabilities to store and retrieve recipes (CRUD), rate them and search through them. This is nothing new, but i wanted to build it as a desktop application to learn more about databases, unit testing, UIs and so on. Now that the core domain is pretty much done (i use a DDD approach) and i implemented most of the CRUD Repositories, i want to make this a bit more extensible by hosting the core functionality online, so i am able to write multiple backends (desktop application, web application, web api, etc).</p>&#xA;&#xA;<p>Service Oriented Architecture (or Microservices) sound like a good approach to me to do that. The problem i am facing is how to decide, which parts of my project belong into a separate service and how to name them.</p>&#xA;&#xA;<p>Take the following parts of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Core domain (Aggregates, Entities, Value Objects, Logic) -> <em>Java</em></li>&#xA;<li>Persistence (DAOs, Repositories, multiple Database backend implementations) -> <em>Java</em></li>&#xA;<li>Search (Search Services which use SQL queries on the persistence DB for searching) -> <em>Java</em></li>&#xA;<li>Desktop Application -> <em>JS (Electron) or JavaFX</em></li>&#xA;<li>Web Application -> <em>Flask or Rails</em></li>&#xA;<li>Web API (Manage, Rate, Search for recipes using REST) -> <em>?</em></li>&#xA;</ul>&#xA;&#xA;<p>My initial approach would be to put the core domain, the persistence, the search and the web api into a single sub-project and host that whole stack on Heroku or something similar. That way my clients could consume the web interface. The Desktop and Web apps would be different projects on their own. The Dektop app could share the core domain if they are both written in Java.</p>&#xA;&#xA;<p>Is this a valid approach, or should i split the first service into smaller parts? How do you name these services?</p>&#xA;"
40734086,Implementing API Gateway for ASP.NET API Microservices,<.net><asp.net-web-api><asp.net-core><microservices><api-gateway>,2,3920,0,0.0,2,"<p>I have developed my micro services using ASP.NET Core WEB API. I am still planning and investigating at this step to add an API Gateway that can acts just as proxy and routes client requests to the designated service (just to isolate and prevent clients from calling the services directly). The gateway will also perform logging and security checks.</p>&#xA;&#xA;<p>I don't need any Discovery Mechanisms for the time being (but if there is a platform I could leverage that would be great).</p>&#xA;&#xA;<p>For constraint purposes let's say that my micro services are hosted on static IPs.</p>&#xA;&#xA;<p>As far as creating my own AP-Gateway, what things do I need to do?&#xA;How would such gateway be implemented?&#xA;How should I host it?  How many?&#xA;I need some patterns that I can translate into an generic implementation.</p>&#xA;&#xA;<p>I was thinking about a simply structured DB that maps every api requested to a micro service API at the other end, then using HttpWebRequest to construct the request and return back the response. Then I can create a message handler that can log all the requests.</p>&#xA;"
40586946,gofabric8> Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip,<maven><openshift><kubernetes><microservices><fabric8>,4,180,0,0.0,2,<p>I'm trying to set up environment for microservices. I'm using fabric8 to do that.</p>&#xA;&#xA;<p>I'm using <code>mvn fabric8:cluster-start -Dfabric8.cluster.kind=openshift</code> command. while executing i'm getting following error...</p>&#xA;&#xA;<pre><code>  [INFO] gofabric8&gt; Downloading https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-mac.zip...&#xA;    [INFO] gofabric8&gt; **Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip fileUnable to download client zip: not a valid zip file**&#xA;    [INFO] gofabric8&gt; using the executable /Users/apple/.fabric8/bin/minishift&#xA;    [INFO] gofabric8&gt; running: /Users/apple/.fabric8/bin/minishift start --vm-driver=xhyve --memory=4096 --cpus=1&#xA;    [INFO] gofabric8&gt; Starting local OpenShift cluster...&#xA;    [INFO] gofabric8&gt; Downloading ISO&#xA;    [INFO] gofabric8&gt; &#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] BUILD FAILURE&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] Total time: 18:50 min&#xA;    [INFO] Finished at: 2016-11-14T16:05:32+05:30&#xA;    [INFO] Final Memory: 21M/224M&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [ERROR] Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = ''' -&gt; [Help 1]&#xA;    org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = '''&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;</code></pre>&#xA;&#xA;<p>Any Idea?</p>&#xA;
40645778,Microservices waiting on responses from other services,<soa><restful-architecture><microservices>,3,76,1,0.0,2,"<p>I recently encountered a question where a person asked me what would you do in the following scenario:</p>&#xA;&#xA;<p>You have service A, service B, and service C interacting with one another. Service A can only perform its full functionality if it receives response from B and C. However, C has a lot of requests queued and will take a long time to respond. How would service A handle this scenario? Will service A wait and wait until C will respond even after getting the response from B? How will you make this architecture faster?</p>&#xA;"
40574379,SNS + CloudFormation,<microservices><amazon-sns><amazon-cloudformation>,3,327,3,1.0,2,"<p>I'm using <em>AWS CloudFormation</em> to build a stack for a microservice. My <em>AWS CloudFormation</em> template creates resources like: a Lambda function, an SNS topic and API Gateway.</p>&#xA;&#xA;<p>This microservice does some work and publishes messages to the SNS topic. Other microservices subscribe to this topic.</p>&#xA;&#xA;<p>The problem I'm facing is that when I upgrade my microservice's <em>CloudFormation</em> template (sometimes I need to redeploy it, and recreate all resources), the SNS topic changes its <code>ARN</code>. Hence, all microservices that use this topic need to change as well.</p>&#xA;&#xA;<p>I think I could create a separate <em>CloudFormation</em> template for the SNS topic (I have more than one per microservice).</p>&#xA;&#xA;<ul>&#xA;<li>Will this be a good approach? </li>&#xA;<li>If not, what's the recommended way?</li>&#xA;</ul>&#xA;"
43792085,How to check service-to-service authentication in Google Cloud Endpoints?,<google-app-engine><oauth-2.0><google-cloud-endpoints><microservices><google-oauth2>,1,171,3,2.0,2,"<p>I'm trying to split a monolith Google App Engine application (using Python &amp; standard environment) into several services within one application. Default service is calling API implemented using the Endpoints framework in another service.</p>&#xA;&#xA;<p>Everything works nicely except that I don't understand how to correctly check authentication of the default service (and make it work both in local development server and in production).</p>&#xA;&#xA;<p>To call the service I'm using <code>google-api-python-client</code> and default application credentials.</p>&#xA;&#xA;<pre><code>from googleapiclient.discovery import build&#xA;from oauth2client.client import GoogleCredentials&#xA;service = build(&#xA;    name, version,&#xA;    credentials=GoogleCredentials.get_application_default(),&#xA;    discoveryServiceUrl=discovery_url)&#xA;service.client_token().execute()&#xA;</code></pre>&#xA;&#xA;<p>My service API code looks like the following</p>&#xA;&#xA;<pre><code>@endpoints.api(&#xA;    name='test',&#xA;    version='v1',&#xA;)&#xA;class TestApi(remote.Service):&#xA;&#xA;    @endpoints.method(&#xA;        message_types.VoidMessage,&#xA;        TestResponse,&#xA;        path='test',&#xA;        http_method='GET',&#xA;        name='test')&#xA;    def get_test(self, request):&#xA;        # user = endpoints.get_current_user()&#xA;        # if not user:&#xA;        #     raise endpoints.UnauthorizedException&#xA;        return TestResponse(test='test')&#xA;</code></pre>&#xA;&#xA;<p>In production <code>endpoints.get_current_user()</code> seems to return a correct application user, but I don't know how to correctly validate that it's the same application. In local development environment <code>endpoints.get_current_user()</code> returns <code>None</code>.</p>&#xA;"
43498534,"In a NodeJs microservices Architecture, should I use a package.json per service?",<node.js><microservices>,1,297,2,2.0,2,"<p>I'm currently developing a microservices architecture in NodeJs. My first approach, was a <code>package.json</code> per service. Although, it can be very tricky when accessing to a common area (with logging or database utils), for all microservices. For instance:</p>&#xA;&#xA;<pre><code>common-area &gt;&#xA;    logger.js&#xA;    package.json - install module typeorm&#xA;&#xA;service1 &gt;&#xA;    app.js - use logger.js&#xA;    package.json - also install module typeorm&#xA;</code></pre>&#xA;&#xA;<p>When running <code>node app.js</code> (Service 1) we end up with 2 typeorm modules loaded, once we made two different installations, one in common area (used by logger) and another in service1.</p>&#xA;&#xA;<p>Should I use only one <code>package.json</code>, for all micro-services, resulting in only one <code>node_modules</code> folder?</p>&#xA;"
43418403,Microservices and coupling,<spring-mvc><microservices><coupling>,2,324,3,0.0,2,"<p>I am trying to use some kind of microservice architecture. I am trying to use HTTP and JSON as a communication medium (I know better than to call it ReST). </p>&#xA;&#xA;<p>So, I'm using spring-mvc and I wanted to use a class as a <code>ResponseBody</code> on the called and as a <code>RequestBody</code> on the callee. So it so happens that I can duplicate and mirror the class on both the projects, or create a jar and include it in both.</p>&#xA;&#xA;<p>I see coupling in both cases, the first one is duplicate coupling and the other is (I'm sure it has a name) coupling. </p>&#xA;&#xA;<p>And the <code>Request</code> and <code>Response</code> models are not what the projects have in common. I am using event-driven architecture for both and the events are somewhat similar (kinda exactly the same). </p>&#xA;&#xA;<p>What should I do?</p>&#xA;"
42490380,Handling JWT and Refresh token flow,<security><jwt><microservices>,1,1223,0,1.0,2,<p>I am building a front end built in react that accesses multiple microservice apis that I am also building. For auth I have built a jwt login system but was wondering what is the process of handling refresh tokens. </p>&#xA;&#xA;<ol>&#xA;<li><p>Is the refresh token inside the jwt with the user info or is it in its own token with a different encryption for extra protection?</p></li>&#xA;<li><p>If it is in its own token what should the other micro services respond with to the react app if the jwt is invalid and needs to be refreshed. Is there a common http status code used?</p></li>&#xA;<li><p>I have read that a refresh token should be more secure then your jwt cause it can be used to issue jwts and will have a longer active time. Is there any extra security past encryption that can be done server side or client side that isnt already done for jwts?</p></li>&#xA;<li><p>When should you refresh the refresh token with a new token and timestamp that it becomes invalid?</p></li>&#xA;</ol>&#xA;
38511443,AWS Pub/Sub Message Pattern,<amazon-web-services><aws-lambda><amazon-sqs><microservices>,2,1848,0,0.0,2,"<p>Can someone explain to me the advantage or disadvantage of using SNS -> Lambda  vs. SNS -> SQS -> Lambda.</p>&#xA;&#xA;<p>I'm looking to setup an architecture for pub/sub micro-service messaging, but having a queue in front of every Lambda seems excessive.</p>&#xA;"
38508387,"What is SOA, Microservices, REST and Web Services ""in plain English""?",<web-services><rest><soa><microservices>,2,1920,0,1.0,2,"<p>Could somebody explain SOA, Microservices, REST and Web Services in simple terms. It is really fascinating and confusing me. Any help would be appreciated.</p>&#xA;"
38629740,How to implement security for my Microservices with Spring?,<spring-security><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,221,0,2.0,2,"<p>We have one monolithic application having more than 10 services like user management, fleet booking, feedback and etc developed on spring rest.</p>&#xA;&#xA;<p>We want to migrate to Microservices(Spring Boot + Cloud + Netflix OSS).</p>&#xA;&#xA;<p>Below are my questions :&#xA;How can we implement security for all our rest services (with own user database)?&#xA;How to implement api gateway from security stand point ?</p>&#xA;"
38629237,How to create a Transaction 'Wrapper' for multiple Services?,<c#><web-services><wcf><transactions><microservices>,2,434,3,0.0,2,"<p>Currently, I'm working on a project that using MicroServices as the main concept.</p>&#xA;&#xA;<p>For a clearer picture, I'll give you the example:</p>&#xA;&#xA;<p>I got <em>Service A</em> that has its own model and controller. </p>&#xA;&#xA;<p>Basically, Service A only contains basic CRUD operations for <em>Database A</em>. </p>&#xA;&#xA;<p>Second, I got <em>Service B</em>, same like Service A but different database (<em>Database B</em>). </p>&#xA;&#xA;<p>Now, I created 1 Services to consume both Service A and Service B. Currently I'm using TransactionScope for 'wrap' the transaction, but it didn't work.</p>&#xA;&#xA;<p>Here's the code :</p>&#xA;&#xA;<pre><code>//This is the service to call Service A and Service B&#xA;using (TransactionScope ts = new TransactionScope())&#xA;{&#xA;     callServiceAMethod(); // works good&#xA;     callServiceBMethod(); // something happened, and failed&#xA;&#xA;     //from here I don't know what should I do&#xA;     //What I'm expecting is : if one of the service i just called didn't work as expected, &#xA;     //the transaction will be rolled back else will committed     &#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Any help will be appreciated :)</p>&#xA;"
38480000,Service Fabric Nested Applications,<deployment><configuration><microservices><azure-service-fabric>,1,195,6,0.0,2,"<p>I am trying to re-architect our current monolithic web application into a more modular (micro-service) style design.</p>&#xA;&#xA;<p>I have a good idea of the boundaries and a plan on how to build it...</p>&#xA;&#xA;<p>Each part of the app will have it's own domain package, a backing rest api, and a web front-end for managing the data. Plus other stuff like unit tests and possibly a connection helper library, etc.</p>&#xA;&#xA;<p>For argument's sake, say my monolithic app has 3 main components (modules):</p>&#xA;&#xA;<ol>&#xA;<li>An accounts module for creating and managing users</li>&#xA;<li>A Products module for administering and managing the product&#xA;catalog</li>&#xA;<li>An Orders module for creating, viewing and amending orders.</li>&#xA;</ol>&#xA;&#xA;<p>In the monolithic app these are all part of the same application (and VS solution and project) and usually have distinct controllers configured using MVC / WebApi Etc:</p>&#xA;&#xA;<pre><code>// MyApp.Web Project (base url ~/)&#xA;myapp.com/...&#xA;myapp.com/accounts/...&#xA;myapp.com/products/...&#xA;myapp.com/orders/...&#xA;&#xA;// MyApp.Api Project (base url ~/api)&#xA;myapp.com/api/...&#xA;myapp.com/api/accounts/...&#xA;myapp.com/api/products/...&#xA;myapp.com/api/orders/...&#xA;</code></pre>&#xA;&#xA;<p>Currently we host this in IIS using nested applications and virtual folders but I want to replicate this sort of idea or structure using a service fabric cluster. But each isolated area (accounts, products, orders) will be developed and deployed independently of one another.</p>&#xA;&#xA;<p><strong>How do I configure service fabric cluster to enable this type of situation?</strong></p>&#xA;&#xA;<p>For instance if I have a cluster of 50 nodes and on those 50 nodes I have instances spread out of each service and the service's api. How do I say:</p>&#xA;&#xA;<pre><code>v2.myapp.com/accounts --&gt; any available accounts web UI instance?&#xA;v2.myapp.com/products --&gt; any available products web UI instance?&#xA;v2.myapp.com/api/products --&gt; any available products api instance?&#xA;</code></pre>&#xA;&#xA;<p>Should I have VM Scale Sets for web and api or one for each component too, like VM Scale Sets for just products api and another for orders web UI, etc?</p>&#xA;&#xA;<p>Also please note that our system is BIG so there are lots of components, hence the reason for splitting out the monolithic style, so I need a consistent structure to enable all this.</p>&#xA;&#xA;<p>We have major scaleability issues and very slow (manual) virtual server provisioning. Plus a single monolithic SQl Server database. The features of SF I want is modular design, easy provisioning and deployment and a drastic increase in response times and throughput of our system. And of course good failover.</p>&#xA;&#xA;<p>At the end of the day I want customers to see a consistent url structure but under the covers I want to be able to have it all separate and working together over many nodes.</p>&#xA;&#xA;<p>Thanks in advance.<br>&#xA;Any help on how to configure this is very much appreciated.</p>&#xA;&#xA;<p>G.</p>&#xA;"
44115310,SessionId lost when I make a request between backend of microservices,<java><spring><rest><security><microservices>,3,271,2,1.0,2,"<p>I am trying to make request between microservices in order to retrieve a list of users with the same roles. For this, first I make a request between FrontEnd and Backend inside the microservice 1. Following, I call an endpoint in the microservice 2 from Microservice 1 backend, but the session Id is lost in it, and I can retrieve the context. &#xA;I am using spring security and Redis for the session Control. &#xA;Manually, I retrieve the session Id from the microservice 1 and I add it as an attribute of the header of the second call, to the microservice 2. But it does not work.</p>&#xA;&#xA;<pre><code>String sessionID= RequestContextHolder.currentRequestAttributes().getSessionId();&#xA;RestTemplate rest = new RestTemplate();&#xA;HttpHeaders headers= new HttpHeaders();            &#xA;headers.set(""Session"",sessionID);&#xA;HttpEntity&lt;ResponseData&gt; entity = new HttpEntity&lt;ResponseData&gt;(headers);&#xA;ResponseEntity&lt;ResponseData&gt; responseEntity =rest.exchange(targetApi,  HttpMethod.GET, entity,ResponseData.class);&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qFEXf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qFEXf.jpg"" alt=""enter image description here""></a></p>&#xA;"
24787801,Spring Boot Environment-specific configurations,<spring-mvc><jpa><spring-boot><environment><microservices>,2,8119,0,2.0,3,"<p>I have a spring boot application that uses the <strong>actuator, auto-configuration and JPA</strong>. I want to be able to use an in-memory DB in my <strong>test</strong> profile, a MySQL DB configuration during <strong>development</strong> and a separate <strong>production</strong> DB configuration when the app is deployed in production. Presumably from the java command line I should be able to specify the environment and the right configuration file or config block in <strong>application.properties</strong> (or .yml) will be picked up.</p>&#xA;&#xA;<p>I have not found a good post with example describing how to do this switching so I thought I'd ask if anyone has a good example. My main aim is to pre-define the <code>spring.datasource</code> and <code>spring.jpa</code> properties at build time and then at run-time switch the app config per environment ""dynamically"" using the java command line argument. Secondary goal would be to do the same with the <code>management</code> configurations, etc.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
34158847,Inter-microservices Communication using REST & PUB/SUB,<rest><server><publish-subscribe><microservices>,3,925,0,1.0,3,"<p>This is still a theory in my mind.</p>&#xA;&#xA;<p>I'm rebuilding my backend by splitting things into microservices. The microservices I'm imagining for starting off are:<br/>&#xA;- Order (stores order details and status of each order)<br/>&#xA;- Customer (stores customer details, addresses, orders booked)<br/>&#xA;- Service Provider (stores service provider details, status &amp; location of each service provider, order(s) currently being processed by the service provider, etc.)<br/>&#xA;- Payment (stores payment info for each order)<br/>&#xA;- Channel (communicates with customers via email / SMS / mobile push)<br/></p>&#xA;&#xA;<p>I hope to be able to use PUB/SUB to create a message with corresponding data, which can be used by any other microservice subscribing to that message.</p>&#xA;&#xA;<p>First off, I understand the concept that each microservice should have complete code &amp; data isolation (thus, on different instances / VMs); and that all microservices should communicate strictly using HTTP REST API contracts.</p>&#xA;&#xA;<p>My doubts are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>To show a list of orders, I'll be using the Order DB to get all orders. In each Order document (I'll be using MongoDB for storage), I'll be having a customer_id Foreign Key. Now the issue of resolving customer_name by using customer_id.<br/>&#xA;If I need to show 100 orders on the page and go with the assumption that each order has a unique customer_id associated with it, then will I need to do a REST API call 100 times so as to get the names of all the 100 customer_ids?&#xA;Or, is data replication a good solution for this problem?</p></li>&#xA;<li><p>I am envisioning something like this w.r.t. PUB/SUB: The business center personnel mark an order as assigned &amp; select the service provider to allot to that order. This creates a message on the cross-server PUB/SUB channel.<br/>&#xA;Then, the Channel microservice (which is on a totally different instance / VM) captures this message &amp; sends a Push message &amp; SMS to the service provider's device using the data within the message's contents.<br/>&#xA;Is this possible at all?<br/>&#xA;<strong>UPDATE TO QUESTION 2:</strong> I want the Order microservice to be completely independent of any other microservices that will be built upon / side-by-side it. Channel microservice is an example of a microservice that depends upon events taking place within Order microservice.</p></li>&#xA;</ol>&#xA;&#xA;<p>Also, please guide me as to what all technologies / libraries to use.</p>&#xA;&#xA;<p>What I'll be developing on:<br/>&#xA;Java<br/>&#xA;MongoDB<br/>&#xA;Amazon AWS instances for each microservice.<br/></p>&#xA;&#xA;<p>Would appreciate anyone's help on this.<br/>&#xA;Thanks!</p>&#xA;"
31510697,Automating microservices load balancing / scaling,<docker><load-balancing><coreos><microservices><akka-cluster>,1,381,0,1.0,3,"<p>Reading up on micro services for a few days now I was wondering how do people go about automating the load balancing and scaling these things?</p>&#xA;&#xA;<p>I have a specific scenario in mind what I would like to achieve but not sure if it's possible or maybe I'm thinking about it wrong. So here it goes...</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Let's say I have a cluster of 3 CoreOS machines named A,B and C.</p>&#xA;&#xA;<p>First thing I want is transparent deployment for which I can probably use fleet. </p>&#xA;&#xA;<p>Then I would like to detect, when one of the services is under huge load and deploy another instance of it and have that one and the first one deployed, automatically load balanced in a way that would not disrupt other services that are using it (traffic goes through load balancer from now on).</p>&#xA;&#xA;<p>Another way could be that I manually deploy another version of the services which then gets load balanced automatically and traffic router to the load balancer.</p>&#xA;&#xA;<p>Then the last question, how is this all different to something like Akka cluster and how does development of those differ from micro services?</p>&#xA;"
50700178,Should API gateway be responsible for authorisation?,<authentication><architecture><authorization><microservices><api-gateway>,1,100,0,1.0,3,"<p>Currently I have a monolith application with Java/Spring Boot the following endpoints:</p>&#xA;&#xA;<ul>&#xA;<li><code>/login</code></li>&#xA;<li><code>/logout</code></li>&#xA;<li><code>/some-resource</code></li>&#xA;</ul>&#xA;&#xA;<p>To access <code>some-resource</code>, the flow is following:</p>&#xA;&#xA;<ol>&#xA;<li>The user makes a <code>POST</code> request to <code>/login</code> endpoint. If the credentials are correct, a JWT token is returned in header, otherwise a 401.</li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<p>Now I want to split the monolith into 2 services: ""AuthServer"" and ""SomeResourceServer"". There will be an API gateway on the top. I am thinking about 2 possible ways to handle authorisation</p>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 1</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway calls the ""AuthServer"" to validate the JWT token. If the token is valid, the API gateway calls ""SomeResourceServer"" and returns the results. Otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 2</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway simply forwards the request to ""SomeResourceServer"". Then ""SomeResourceServer"" calls ""AuthServer"" to validate the JWT token. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p>In Option 1 the API gateway is responsible to handle authorisation (communicate with ""AuthServer""), in option 2 the communication is done between the servers. So which option is more correct? Are there any good/bad practices? Or maybe another way/option?</p>&#xA;"
34722107,Is DAO microservice good approach in microservices architecture?,<web-services><rest><database-design><architecture><microservices>,5,1813,0,1.0,3,"<p>I'm creating a web-application and decided to use micro-services approach. Would you please tell me what is the best approach or at least common to organize access to the database from all web-services (login, comments and etc. web-services). Is it well to create DAO web-service and use only it to to read/write values in the database of the application. Or each web-service should have its own dao layer.</p>&#xA;"
34575783,Azure Service Fabric actor microservice,<c#><microservices><azure-service-fabric>,2,1744,3,0.0,3,<p>Microsoft is offering a microservice solution for it's cloud platform Azure. There are two frameworks - reliable services and reliable actors. </p>&#xA;&#xA;<p>I was wondering if a reliable actor is an independently microservice? Or form multiple actors together a microservice?</p>&#xA;
32217639,Online Store and Microservices,<restful-architecture><microservices>,1,443,0,3.0,3,"<p>I am working for a big online store. At the moment our architecture is something weird where we have microservices which actually all share the same DB (doesn't work well at all...).&#xA;I am considering improving that but have some challenges on how to make them independant.</p>&#xA;&#xA;<p>Here is a use case. I have customers, customers purchase products. Let say I have 3 microservices : customer authentication, order management, product management.&#xA;An order is linked to a customer and a product.&#xA;Could you describe a solution for the following problems :</p>&#xA;&#xA;<ol>&#xA;<li>How do you make the link between an order and a customer?</li>&#xA;<li>Let say both services share a customer ID, how do you handle data consistency? If you remove a customer on the customer service side, you end up with inconsistency. If your service has to notify the other services then you end up with tighlty coupled services which to me sounds like what you wanted to avoid in the first place. You could kind of avoid that by having an event mechanism which notify everyone but what about network errors when you don't even know who is supposed to receive the event?</li>&#xA;<li>I want to do a simple query : retrieve the customers from US that bought product A. Given that 3million people bought product A and we have 1 million customers in the US; How could you make that reasonably performant? (Our current DB would execute that in few milliseconds)</li>&#xA;</ol>&#xA;&#xA;<p>I can't think of any part of our code where we don't have this kind of relation. One of the solution I can think of is duplicating data. E.g. When a customer purchase something, the order management service will store the customer details and the product details. You end up with massive data replication, not sure if that's a good thing and I would still be worried about consistency.</p>&#xA;&#xA;<p>I couldn't find a paper addressing those issues. What are the different options?</p>&#xA;"
32604241,Best Protocol for a App to Use a Service on the Same Server?,<php><api><http><service><microservices>,1,53,0,0.0,3,"<p>I have a PHP app that needs to talk to a service which has a API that produces XML responses to HTTP requests. If this service was on a separate server I would normally use a HTTP client like Guzzle to create and consume, requests and responses.</p>&#xA;&#xA;<p>But my service will be (for the time being) on the same server. In this scenario is making HTTP requests in this fashion still my best option? Will all my requests to the API leave the server which will add latency which could be avoided?</p>&#xA;"
32574103,Microservices - how to solve security and user authentication?,<authentication><java-ee><microservices>,2,1504,1,2.0,3,"<p>There is a lot of discussion about microservice architecture. What I am missing - or maybe what I did not yet understand is, how to solve the issue of security and user authentication?</p>&#xA;&#xA;<p>For example: I develop a microservice which provides a Rest Service interface to a workflow engine. The engine is based on JEE and runs on application servers like GlassFish or Wildfly. &#xA;One of the core concepts of the workflow engine is, that each call is user centric. This means depending of the role and access level of the current user, the workflow engine produces individual results (e.g. a user-centric tasklist or processing an open task which depends on the users role in the process).</p>&#xA;&#xA;<p>In my eyes, thus a service is not accessible from everywhere. For example if someone plans to implement a modern Ajax based JavaScript application which should use the workflow microservice there are two problems:</p>&#xA;&#xA;<p>1) to avoid the cross-scripting problem from JavaScript/Ajax the JavaScript Web application needs to be deployed under the same domain as the microservice runs</p>&#xA;&#xA;<p>2) if the microservice forces a user authentication (which is the case in my scenario) the application need to provide a transparent authentication mechanism. </p>&#xA;&#xA;<p>The situation becomes more complex if the client need to access more than one user-centric microservices forcing user authentication.&#xA;I always end up with an architecture where all services and the client application running on the same application server under the same domain.</p>&#xA;&#xA;<p>How can these problems be solved? What is the best practice for such an architecture?</p>&#xA;"
36844842,Patterns for knowing if a pub-sub message was successful,<design-patterns><publish-subscribe><amazon-sqs><amazon-sns><microservices>,1,354,4,0.0,3,"<p>I'm developing microservices for a project and we're experimenting with pub-sub communication using AWS SNS+SQS. We're unsure how to signal to services whether or not other services have successfully completed tasks or not.<br>&#xA;For example, if service A emits an SNS Event and service D, E, and F all are listening to the subscribed SQS Queue, how does service A know if the activities kicked off by service A inside of service D, E, and F were successful?  </p>&#xA;&#xA;<p>I'll give a more concrete example:&#xA;A new user registers for a website.  This network call first reaches the <code>user service</code> in the backend.  If the user was successful, it sends off an event saying a new user was created.  That triggers the <code>email service</code> to send an email to for the user to confirm his registration. What happens if it fails to send an email? &#xA;Has the <code>user service</code>:</p>&#xA;&#xA;<p>1) Already responded to the frontend saying it was successful</p>&#xA;&#xA;<p>2) Or is it waiting for a confirmation?  What is a good pub-sub pattern for confirmations?  </p>&#xA;&#xA;<p>I know we could have just done a synchronous call, but this example is simplified for brevity's sake.  </p>&#xA;"
44253950,Using soap services(.asmx) with Azure Service fabric,<web-services><rest><soap><microservices><azure-service-fabric>,1,256,0,1.0,3,<p>I am migrating my existing services to Azure service fabric. My existing application support the soap service(asmx) for the legacy users. I want to use the same web service as part of my microservice. That web service test.asmx(say) can be called from Rest Apis as well(If soln is there). But I'm not finding any way to use the soap service as part of Azure service fabric microservice approach. Help me out of possible solutions for tackling the web service scenario. Thanks!</p>&#xA;
44420585,Microservices: how to effectively deal with data dependencies between microservices,<node.js><mean-stack><microservices>,2,125,0,1.0,3,"<p>I am developing an application utilizing the microservices development approach with the mean stack.  I am running into a situation where data needs to be shared between multiple microservices.  For example, let's say I have user, video, message(sending/receiving,inbox, etc.) services.  Now the video and message records belong to an account record.  As users create video and send /receive message there is a foreign key(userId) that has to be associated with the video and message records they create. I have scenarios where I need to display the first, middle and last name associated with each video for example.  Let's now say on the front end a user is scrolling through a list of videos uploaded to the system, 50 at a time.  In the worst case scenario, I could see a situation where a pull of 50 occurs where each video is tied to a unique user.</p>&#xA;&#xA;<p>There seems to be two approaches to this issue:</p>&#xA;&#xA;<p>One, I make an api call to the user service and get each user tied to each video in the list.  This seems inefficient as it could get really chatty if I am making one call per video.  In the second of the api call scenario, I would get the list of video and send a distinct list of user foreign keys to query to get each user tied to each video.  This seems more efficient but still seems like I am losing performance putting everything back together to send out for display or however it needs to be manipulated.</p>&#xA;&#xA;<p>Two, whenever a new user is created, the account service sends a message with the user information each other service needs to a fanout queue and then it is the responsibility of the individual services to add the new user to a table in it's own database thus maintaining loose coupling.  The extreme downside here would be the data duplication and having to have the fanout queue to handle when updates needs to be made to ensure eventual consistency.  Though, in the long run, this approach seems like it would be the most efficient from a performance perspective.  </p>&#xA;&#xA;<p>I am torn between these two approaches, as they both have their share of tradeoffs.  Which approach makes the most sense to implement and why?</p>&#xA;"
44331178,Testing same API for multiple response sets,<javascript><node.js><rest><microservices><pact>,1,148,0,1.0,3,"<p>We've been trying to test an API exposed from a microservice (say GET /contacts) which is being consumed by another microservice.</p>&#xA;&#xA;<p>In order to avoid integration tests, we created consumer-driven contract tests where the consumer microservice created pacts and published them to a broker from where the producer would verify the pact separately.</p>&#xA;&#xA;<p>We've used <a href=""https://docs.pact.io/"" rel=""nofollow noreferrer"" title=""Pact IO"">Pact IO</a> to achieve this and it has been quite good so far.</p>&#xA;&#xA;<p>Now we are facing issues when trying to do exhaustive tests where we would want to see how an empty list is returned from GET /contacts.</p>&#xA;&#xA;<p>The problem is: while adding interactions, we could use Provider States but we couldn't find a way to differentiate between writing tests for getting a list of contacts from GET /contacts once and getting an empty list in another test.</p>&#xA;&#xA;<p>This is how we create pact tests in our consumer microservice:</p>&#xA;&#xA;<pre><code>mockServer.start()&#xA;        .then(() =&gt; {&#xA;          provider = pact({&#xA;            // config&#xA;          })&#xA;          return provider.addInteraction({&#xA;            state: 'Get all contacts',&#xA;            uponReceiving: 'Get all contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: //list of all contacts&#xA;            }&#xA;          })&#xA;        .then(() =&gt; {&#xA;          return provider.addInteraction({&#xA;            state: 'Get empty list of contacts',&#xA;            uponReceiving: 'Get empty list of contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: [] // empty list&#xA;            }&#xA;          })&#xA;        })&#xA;</code></pre>&#xA;&#xA;<p>We cannot find a way to differentiate between these interations in our tests! :(</p>&#xA;&#xA;<p>Any help would be appreciated!</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48824086,Keycloak: AnonymousAuthenticationToken cannot be cast to KeycloakAuthenticationToken,<java><spring><spring-security><microservices><keycloak>,6,1064,0,0.0,3,"<p>I am developing a microservice infrastructure based on Spring Cloud. I want to secure the application with Keycloak, which is basically working fine if the user is authenticated. </p>&#xA;&#xA;<p>If the user is not authenticated Keycloak throws the folling error:</p>&#xA;&#xA;<pre><code>java.lang.ClassCastException: org.springframework.security.authentication.AnonymousAuthenticationToken cannot be cast to org.keycloak.adapters.springsecurity.token.KeycloakAuthenticationToken&#xA;at org.keycloak.adapters.springsecurity.facade.SimpleHttpFacade.getSecurityContext(SimpleHttpFacade.java:63) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.corsRequest(AuthenticatedActionsHandler.java:102) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.AuthenticatedActionsHandler.handledRequest(AuthenticatedActionsHandler.java:54) ~[keycloak-adapter-core-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:78) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakSecurityContextRequestFilter.doFilter(KeycloakSecurityContextRequestFilter.java:79) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticatedActionsFilter.doFilter(KeycloakAuthenticatedActionsFilter.java:82) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.keycloak.adapters.springsecurity.filter.KeycloakPreAuthActionsFilter.doFilter(KeycloakPreAuthActionsFilter.java:84) ~[keycloak-spring-security-adapter-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.9.RELEASE.jar:1.5.9.RELEASE]&#xA;at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.13.RELEASE.jar:4.3.13.RELEASE]&#xA;at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) ~[tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractAuthenticatedActionsValve.invoke(AbstractAuthenticatedActionsValve.java:67) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:595) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.keycloak.adapters.tomcat.AbstractKeycloakAuthenticatorValve.invoke(AbstractKeycloakAuthenticatorValve.java:181) [spring-boot-container-bundle-3.4.3.Final.jar:3.4.3.Final]&#xA;at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.23.jar:8.5.23]&#xA;at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;</code></pre>&#xA;&#xA;<p>The security config looks as follows:</p>&#xA;&#xA;<pre><code>@KeycloakConfiguration&#xA;public class SecurityConfig extends KeycloakWebSecurityConfigurerAdapter&#xA;{&#xA;    private final KeycloakClientRequestFactory keycloakClientRequestFactory;&#xA;&#xA;    public SecurityConfig(KeycloakClientRequestFactory keycloakClientRequestFactory)&#xA;    {&#xA;        this.keycloakClientRequestFactory = keycloakClientRequestFactory;&#xA;    }&#xA;&#xA;    /**&#xA;   * define the actual constraints of the app.&#xA;   * @param http&#xA;   * @throws Exception&#xA;   */&#xA;  @Override&#xA;  protected void configure(HttpSecurity http) throws Exception&#xA;  {&#xA;      super.configure(http);&#xA;      http&#xA;      .cors()&#xA;      .and()&#xA;      .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)&#xA;      .sessionAuthenticationStrategy(sessionAuthenticationStrategy())&#xA;      .and()&#xA;      .authorizeRequests()&#xA;          .antMatchers(""/*"").hasRole(""user"")&#xA;          .anyRequest().permitAll();&#xA;  }&#xA;&#xA;    /**&#xA;     * define the session auth strategy so that no session is created&#xA;     * &#xA;     * @return concrete implementation of session authentication strategy&#xA;     */&#xA;    @Bean&#xA;    @Override&#xA;    protected SessionAuthenticationStrategy sessionAuthenticationStrategy()&#xA;    {&#xA;        return new NullAuthenticatedSessionStrategy();&#xA;    }&#xA;&#xA;    /**&#xA;     * registers the Keycloakauthenticationprovider in spring context and sets its&#xA;     * mapping strategy for roles/authorities (mapping to spring seccurities'&#xA;     * default ROLE_... for authorities ).&#xA;     * &#xA;     * @param auth&#xA;     *          SecurityBuilder to build authentications and add details like&#xA;     *          authproviders etc.&#xA;     * @throws Exception&#xA;     */&#xA;    @Autowired&#xA;    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception&#xA;    {&#xA;        KeycloakAuthenticationProvider keyCloakAuthProvider = keycloakAuthenticationProvider();&#xA;        keyCloakAuthProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper());&#xA;&#xA;        auth.authenticationProvider(keyCloakAuthProvider);&#xA;    }&#xA;&#xA;    /**&#xA;     * Sets keycloaks config resolver to use springs application.properties&#xA;     * instead of keycloak.json (which is standard)&#xA;     * &#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public KeycloakConfigResolver KeyCloakConfigResolver()&#xA;    {&#xA;        return new KeycloakSpringBootConfigResolver();&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakAuthenticationProcessingFilterRegistrationBean(&#xA;            KeycloakAuthenticationProcessingFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;&#xA;    /**&#xA;     * Spring Boot attempts to eagerly register filter beans with the web&#xA;     * application context. Therefore, when running the Keycloak Spring Security&#xA;     * adapter in a Spring Boot environment, it may be necessary to add two&#xA;     * FilterRegistrationBeans to your security configuration to prevent the&#xA;     * Keycloak filters from being registered twice.&#xA;     * &#xA;     * @param filter&#xA;     * @return&#xA;     */&#xA;    @Bean&#xA;    public FilterRegistrationBean keycloakPreAuthActionsFilterRegistrationBean(KeycloakPreAuthActionsFilter filter)&#xA;    {&#xA;        FilterRegistrationBean registrationBean = new FilterRegistrationBean(filter);&#xA;        registrationBean.setEnabled(false);&#xA;        return registrationBean;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions would be much apprechiated.</p>&#xA;&#xA;<p>Kind regards&#xA;Blacky</p>&#xA;"
48921774,Microservices unsuitable for business domain?,<database><domain-driven-design><microservices><distributed-computing><soa>,2,80,2,1.0,3,"<p>The business domain has five high-level bounded contexts</p>&#xA;&#xA;<ul>&#xA;<li>Customers</li>&#xA;<li>Applications</li>&#xA;<li>Documents</li>&#xA;<li>Decisions</li>&#xA;<li>Preforms</li>&#xA;</ul>&#xA;&#xA;<p>Further, these bounded contexts has sub-contexts like ordering and delivery of the documents. Despite the project of consisting ten of thousands of classes and dozens of EJB's, most of the business logic resides in relational database views and triggers for a reason: A lot of joins, unions and constraints involved in all business transactions. In other words, there is complex web of dependencies and constraints between the bounded contexts, which restricts the state transfers. In layman terms: the business rules are very complicated.</p>&#xA;&#xA;<p>Now, if I were to split this monolith to database per service microservices architecture, bounded contexts being the suggested service boundaries, I will have to implement all the business logic with explicit API calls. I would end up with hundreds of API's implementing all these stupid little business rules. As the performance is main factor (we use a lot of effort to optimize the SQL as it is now), this is out of the question. Secondly, segregated API's would probably be nightmare to maintain in this web of ever evolving business rules, where as database triggers actually support the high cohesion and DRY mentality, enforcing the business rules transparently.</p>&#xA;&#xA;<p>I came up with a conclusion microservice architecture being unsuitable for this type of document management system. Am I correct, or approaching the idea from wrong angle?</p>&#xA;"
36832219,How to use redis for number of micro-services?,<caching><redis><microservices>,3,4406,0,1.0,3,"<p>I am very much new to redis. I have been investigating on redis for past few days.I read the documentation on cache management(lru cache), commands ,etc. I want to know how to implement caching for multiple microservice(s) data .&#xA;I have few questions:</p>&#xA;&#xA;<ol>&#xA;<li>Can all microservices data(cached) be kept under a single instance of redis&#xA;    server?</li>&#xA;<li><p>Should every microservice have its own cache database in redis?</p></li>&#xA;<li><p>How to refresh cache data without setting EXPIRE? Since it would consume more memory.</p></li>&#xA;</ol>&#xA;&#xA;<p>Some more information on best practices on redis with microservices will be helpful.</p>&#xA;"
36642718,Two microservices for read and write to one database table,<architecture><microservices>,2,1649,0,1.0,3,"<p>I'm a little bit confused about the microservice best practice approach. </p>&#xA;&#xA;<p>Following scenario:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Massive incoming messages from mqtt devices. A rest api where customers could read the messages (mostly only a part of them).</p>&#xA;</blockquote>&#xA;&#xA;<p>My idea was, to create one microservice for storing the messages in a database table. And a second microservice with a rest api to read this messages.&#xA;I want to do this, because of scaling issues. (The incoming storing part needs much more power, than the reading rest api)</p>&#xA;&#xA;<p>I read that the ""perfect"" microservice should be the only one, who accesses his data in a database. So other microservices should ask for this data, via its API and not on database level.&#xA;So my approach would be not the perfect one. I see a few options to handle this:</p>&#xA;&#xA;<ul>&#xA;<li>only one mircroservice, for storing and reading</li>&#xA;<li>making an api in the storing microservice, where the rest microservice could fetch the data.</li>&#xA;</ul>&#xA;&#xA;<p>But all of them, doesn't look good for me. </p>&#xA;&#xA;<p>Whats your opinion?</p>&#xA;&#xA;<p>Regards,&#xA;Markus</p>&#xA;"
36615117,microservice messaging db-assigned identifiers,<microservices><spring-cloud-stream>,2,154,0,2.0,3,"<p>The company I work for is investigating moving from our current monolithic API to microservices. Our current API is heavily dependent on spring and we use SQL server for most persistence. Our microservice investigation is leaning toward spring-cloud, spring-cloud-stream, kafka, and polyglot persistence (isolated database per microservice). </p>&#xA;&#xA;<p>I have a question about how messaging via kafka is typically done in a microservice architecture. We're planning to have a coordination layer between the set of microservices and our client applications, which will coordinate activities across different microservices and isolate clients from changes to microservice APIs. Most of the stuff we've read about using spring-cloud-stream and kafka indicate that we should use streams at the coordination layer (source) for resource change operations (inserts, updates, deletes), with the microservice being one consumer of the messages. </p>&#xA;&#xA;<p>Where I've been having trouble with this is inserts. We make heavy use of database-assigned identifiers (identity columns/auto-increment columns/sequences/surrogate keys), and they're usually assigned as part of a post request and returned to the caller. The coordination layer may be saving multiple things using different microservices and often needs the assigned identifier from one insert before it can move on to the next operation. Using messaging between the coordination layer and microservices for inserts makes it so the coordination layer can't get a response from the insert operation, so it can't get the assigned identifier that it needs. Additionally, other consumers on the stream (i.e. consumers that publish the data to a data warehouse) really need the message to contain the assigned identifier.</p>&#xA;&#xA;<p>How are people dealing with this problem? Are database-assigned identifiers an anti-pattern in microservices? Should we expose separate microservice endpoints that return database-assigned identifiers so that the coordination layer can make a synchronous call to get an identifier before calling the asynchronous insert? We could use UUIDs but our DBAs hate those as primary keys, and they couldn't be used as an order number or other user-facing generated ids.</p>&#xA;"
36705199,Lock a Service-Bus Queue and prevent others from accessing it,<c#><azureservicebus><microservices>,4,541,5,1.0,3,"<p>I have multiple queues that multiple clients insert messages into them.</p>&#xA;&#xA;<p>On the server side, I have multiple micro-services that access the queues and handle those messages. I want to lock a queue whenever a service is working on it, so that other services won't be able to work on that queue.</p>&#xA;&#xA;<p>Meaning that if service A is processing a message from queue X, no other service can process a message from that queue, until service A has finished processing the message. Other services can process messages from any queue other than X.</p>&#xA;&#xA;<p>Does anyone has an idea on how to lock a queue and prevent others from accessing it? preferably the other services will receive an exception or something so that they'll try again on a different queue.</p>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>Another way can be to assign the queues to the services, and whenever a service is working on a queue no other service should be assigned to the queue, until the work item was processed. This is also something that isn't easy to achieve.</p>&#xA;"
35314963,What is best practice to communicate between React components and services?,<rest><reactjs><redux><flux><microservices>,2,6713,0,3.0,3,"<p>Instead of using flux/redux architecture, how react components should communicate with services?</p>&#xA;&#xA;<p><strong>For example:</strong>&#xA;There is a container having few representational (react) components:</p>&#xA;&#xA;<ol>&#xA;<li>ChatBox - enables to read/write messages</li>&#xA;<li>AvatarBox with password changer - which enables to change user's password</li>&#xA;<li>News stream - lists news and apply filter to them</li>&#xA;</ol>&#xA;&#xA;<p>Thinking of them as resources representation, I want each of them to access Microservice API by itself (getting or updating data). Is this correct?&#xA;It will provide clean responsibility managing models, but it gives performance doubts using http requests to load each component's content</p>&#xA;&#xA;<p>This question also reffers to: <a href=""https://stackoverflow.com/questions/35286730/how-to-execute-efficient-communication-for-multiple-microservices"">How to execute efficient communication for multiple (micro)services?</a></p>&#xA;"
35348080,How to handle shared datasources using microservices architecture,<java><architecture><redis><microservices><bigdata>,1,622,0,1.0,3,"<p>I have couple of services in my microservice architecture.</p>&#xA;&#xA;<p>Two of the service(Service A, Service B) got different api's and provide different domain logic. However they do share some logic that should be returned - user-state from Redis.</p>&#xA;&#xA;<ul>&#xA;<li>When user state is changed Iam publishing from a 3rd service to all the my micro-services</li>&#xA;</ul>&#xA;&#xA;<p>solutions:</p>&#xA;&#xA;<ol>&#xA;<li><p>I could create another service which would be responsible for ""user-state"" and will hold all user data on Redis.&#xA;Disadvantages: &#xA;My clients going to have additional call on every api requests(to get the user-state).</p></li>&#xA;<li><p>Duplicate the user-state datasource for each microservices(holding more than one redis instance) and return it independently for each request.&#xA;Disadvantages: &#xA;I am going to duplicate my data and duplicate Redis instances(each microservice will access it's own)</p></li>&#xA;<li><p>have one redis datasource while all services going to use it. &#xA;Disadvantages: &#xA;Duplicating redis-logic(in order to retrieve the data) among the services and break microservices principle by using one shared datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What would you suggest doing?</p>&#xA;"
35223505,Spring Boot project setup design decisions,<java><spring><spring-boot><microservices>,1,252,1,1.0,3,"<p>We will be using Spring Boot to create services. Our initial idea would be that each service (not necessarily microservice) would be self-contained, and deployed as a .jar file. Maven for build.</p>&#xA;&#xA;<p>I'm wondering what would be a good Spring Boot project structure, as each service would be self-contained, but I'm guessing services will still have some code/entities that can or should be reused between services</p>&#xA;&#xA;<p>Options:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each service is a standalone Spring Boot project. Implements only the entities, controllers, and utils that the actual service requires.</p>&#xA;&#xA;<p>Good: each service is fully self-contained</p>&#xA;&#xA;<p>Bad: what about custom utility classes that need to be re-used between services? What about domain objects that services may need to share?</p></li>&#xA;<li><p>All services are created in the same codebase. All services can re-use utilities, controllers, etc. from all other services&#xA;Good: easy re-use&#xA;Bad: A JVM is now able to serve all service calls? service boundaries are now handled by load balancers?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!  </p>&#xA;"
39126827,"Laravel passport, Oauth and microservices",<laravel><oauth><oauth-2.0><microservices>,2,1351,0,0.0,3,"<p>I am having a difficulty in terms of architecture and wondering if someone has some insights.</p>&#xA;&#xA;<p><strong>The plan</strong></p>&#xA;&#xA;<ul>&#xA;<li>I will have multiple microservices (different laravel projects, catalog.microservice.com, billing.microservice.com) each providing an API. </li>&#xA;<li>On top of these will be an angular fronted consuming those APIs. </li>&#xA;<li>I will have another micro service (passport.microservice.com) for auth now thanks to laravel 5.3 passport this is even easier.  </li>&#xA;</ul>&#xA;&#xA;<p><strong>The flow:</strong></p>&#xA;&#xA;<ul>&#xA;<li>User goes to catalog.microservice.com </li>&#xA;<li>user need to authenticate and provides a user and password</li>&#xA;<li>request is made by angular (aka client) to passport.microservice.com through password grand type to get an authorization token</li>&#xA;<li>now that I have a token I am authorized to call a resource from catalog.microservice.com</li>&#xA;<li>catalog.microservice.com needs to know if the token is valid and makes a request (some kind of middleware?) to passport.microservice.com</li>&#xA;<li>passport.microservice.com returns the user, scope etc.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Questions:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is this a good approach?</li>&#xA;<li>The token validation in catalog.microservice.com can be a middleware? </li>&#xA;</ul>&#xA;"
39044130,Java EE Microprofile,<java><microservices>,2,1358,0,0.0,3,<p>I know it could be a pretty vague topic but please can someone explain it in plain English. I've read some articles regarding the trending topic java EE's 'microprofile' but was not able to clearly understand its purpose.</p>&#xA;&#xA;<p>My understanding in this emerging concept is that java community finds way to reshape the Java EE model to become a microservices friendly framework or platform. </p>&#xA;&#xA;<p>If we can already create a distributed microservice application in few minutes using spring boot or other API / library then why do we need microprofile?</p>&#xA;
39088230,How to ensure thrift objects are backward compatible?,<java><thrift><microservices>,1,643,0,0.0,3,"<p>We're currently using <strong>thrift</strong> for developing our micro-services.&#xA;When I recently came across this below issue.</p>&#xA;&#xA;<p>Assume below is the thrift contract for Summary Object and there is an API which gets and updates summary using the summary object passed.</p>&#xA;&#xA;<p><strong>Version - 1.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<p>Now let's say there are 5 services which are using this <strong>1.0</strong> contract of Summary.<br/>&#xA;In the next release we add another Object called a <strong>list of summaryvalues</strong>.</p>&#xA;&#xA;<p>So the new contract would look like</p>&#xA;&#xA;<p><strong>Version - 2.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost,&#xA;    3: optional list&lt;i32&gt; summaryValues&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>So when this below list is populated, we save the list of values <code>summaryValues</code> aganist that <code>summaryId</code>.</li>&#xA;<li>And when the client sends this list as <code>null</code> we remove the existing values saved for that 'summaryId`.</li>&#xA;</ol>&#xA;&#xA;<p>Now the <strong>problem</strong> occurs when other services which are using <strong>OLDER</strong> version of the thrift contract (<strong>Version 1.0</strong>) try to call getSummary and updateSummary.<br/>&#xA;The intention of the Older Client by calling updateSummary was to set another value for <code>summaryCost</code>. However since this client doesn't contain the object <code>summaryValues</code> it sends the Summary object with <code>summaryValues</code> as null to Server.<br/></p>&#xA;&#xA;<p><strong>This is resulting in the Server removing all existing values of <code>summaryValues</code> for that <code>summaryId</code>.</strong></p>&#xA;&#xA;<p>Is there a way to handle this in thrift? The isSet() Methods don't work here, as they try to perform a simple null check.<br/>&#xA;Every time we release a newer client with modification to existing objects, we're having to forcefully upgrade client versions of other servers even though the change is not related to them.</p>&#xA;"
38975554,Multiple FabricTransportServiceRemotingListeners in a Single Service,<microservices><azure-service-fabric>,1,434,0,0.0,3,"<p>I'd like to be able to expose multiple FabricTransportServiceRemotingListeners from a single Stateless service inside my cluster. I've attempted to register the listeners as follows:</p>&#xA;&#xA;<pre><code>    protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;    {&#xA;        return new[]&#xA;        {&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryCommandService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryCommandEndpoint""&#xA;                    }), ""SqlCategoryCommandService""),&#xA;&#xA;            new ServiceInstanceListener(&#xA;                serviceContext =&gt;&#xA;                    new FabricTransportServiceRemotingListener(serviceContext, new SqlCategoryQueryService(), new FabricTransportListenerSettings()&#xA;                    {&#xA;                        EndpointResourceName = ""CategoryQueryEndpoint""&#xA;                    }), ""SqlCategoryQueryService"")&#xA;        };&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>However when I make a proxy to the <code>ICategoryQueryService</code> which is implemented by the second listener this exception regarding an unimplemented Interface method is thrown leading me to believe that the first listener is incorrectly responding to all Proxy calls.</p>&#xA;&#xA;<pre><code>""Interface id '740213831' is not implemented by object 'TaxonomyService.SqlCategoryCommandService'""&#xA;</code></pre>&#xA;&#xA;<p>I'm creating the Proxy using the following code:</p>&#xA;&#xA;<pre><code>var proxy = ServiceProxy.&#xA;     Create&lt;ICategoryQueryService&gt;(new Uri(""fabric:/Taxonomy/TaxonomyService""));&#xA;</code></pre>&#xA;&#xA;<p>Is the scenario I've described possible?</p>&#xA;"
35913253,Microservice based or Monolithic,<cordova><spring-boot><microservices>,3,584,0,0.0,3,"<p>I read a lot about Microservices and their structure and it seems, that there are a lot of advantages when it comes to maintainability. </p>&#xA;&#xA;<p>I want to build a mobile app with Spring Boot and Phonegap, which pulls news from RESTful Web Services. </p>&#xA;&#xA;<p>So I'm thinking f building it as a microservice so I can add other services without rebuilding the whole application. Because in future I might want to add other services.</p>&#xA;&#xA;<p>But is it really worth to build a Microservice based application for such a small mobile app? </p>&#xA;"
38714097,Deploy Service Fabric Application through VSTS release pipeline using Hosted Agent,<azure><vsts><microservices><azure-service-fabric><vsts-release>,1,888,8,0.0,3,"<p>I have set up continuous integration using Hosted Agent for service fabric by following this document <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/"" rel=""nofollow noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/</a></p>&#xA;&#xA;<p>In Release pipeline after importing certificate I am getting the following error and deployment failing. I am not able to identify where the issue is&#xA;<a href=""https://i.stack.imgur.com/Afc7G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Afc7G.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;  &#xA;  <p>Finishing task: ServiceFabricDeploy </p>&#xA;  &#xA;  <h2>[error]System.Exception: Task ServiceFabricDeploy failed.</h2>&#xA;  &#xA;  <p>This caused the job to fail. Look at the logs for the task for more details. </p>&#xA;  &#xA;  <p>[error]   at Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.Run(IJobContext jobContext, IJobRequest job, IJobExtension jobExtension, CancellationTokenSource tokenSource)</p>&#xA;</blockquote>&#xA;&#xA;<p>Under Deploy service fabric task it is showing the below error&#xA;<a href=""https://i.stack.imgur.com/bSCBZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bSCBZ.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>Imported cluster client certificate with thumbprint 'A6B32E70CFE715F608A247C1ED94AB3D0164A58E'.</p>&#xA;  &#xA;  <p>Thumbprint Subject                                            </p>&#xA;  &#xA;  <p>A6B32E70CFE715F608A247C1ED94AB3D0164A58E  >CN=clusternamedns.eastus.cloudapp.azure.com                                     </p>&#xA;  &#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;</blockquote>&#xA;&#xA;<h2><strong>Update</strong></h2>&#xA;&#xA;<p>After setting system.debug to true in variables, I got the following log</p>&#xA;&#xA;<pre><code>    2016-08-03T05:44:31.6556865Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.6566887Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.6577063Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.6587072Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.6597111Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.6606871Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.6647953Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.6656886Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.6666879Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.6676869Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.6770225Z ##[debug]Leaving C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1.&#xA;&#xA;2016-08-03T05:44:31.6850322Z ##[debug]Caught exception from task script.&#xA;&#xA;2016-08-03T05:44:31.6890370Z ##[debug]Error record:&#xA;&#xA;2016-08-03T05:44:31.7380329Z ##[debug]Connect-ServiceFabricCluster : An error occurred during this operation.  Please check the trace logs for more details.&#xA;&#xA;2016-08-03T05:44:31.7390333Z ##[debug]At C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1:73 char:12&#xA;&#xA;2016-08-03T05:44:31.7410325Z ##[debug]+     [void](Connect-ServiceFabricCluster @clusterConnectionParameters)&#xA;&#xA;2016-08-03T05:44:31.7420325Z ##[debug]+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;2016-08-03T05:44:31.7430323Z ##[debug]    + CategoryInfo          : InvalidOperation: (:) [Connect-ServiceFabricCluster], FabricException&#xA;&#xA;2016-08-03T05:44:31.7440363Z ##[debug]    + FullyQualifiedErrorId : CreateClusterConnectionErrorId,Microsoft.ServiceFabric.Powershell.ConnectCluster&#xA;&#xA;2016-08-03T05:44:31.7450426Z ##[debug] &#xA;&#xA;2016-08-03T05:44:31.7470318Z ##[debug]Script stack trace:&#xA;&#xA;2016-08-03T05:44:31.7500512Z ##[debug]at &lt;ScriptBlock&gt;, C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1: line 73&#xA;&#xA;2016-08-03T05:44:31.7910331Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7920318Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 22&#xA;&#xA;2016-08-03T05:44:31.7930364Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 18&#xA;&#xA;2016-08-03T05:44:31.7940315Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7960349Z ##[debug]Exception:&#xA;&#xA;2016-08-03T05:44:31.8000522Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.8010571Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.8020684Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.8030335Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.8040334Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.8060326Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.8070343Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.8080330Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.8090325Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.8100358Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.8340330Z ##[error]An error occurred during this operation.  Please check the trace logs for more details.&#xA;</code></pre>&#xA;"
49875284,Logback to Elasticsearch through yaml or properties,<spring><elasticsearch><logging><microservices><logback>,1,187,3,0.0,3,"<p>I have many spring based microservice project where I used Logback to Elasticsearch for saving all logs to Elastic search index. I have configured using xml based on some tutorials I got. The configuration is based on xml like as shown below. Instead of xml how can we configure Logback to Elasticsearch using yaml or key value property files.</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;configuration&gt;&#xA;    &lt;springProperty scope=""context"" name=""microserviceName""&#xA;        source=""spring.application.name"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""profile""&#xA;        source=""spring.profiles.active"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESHost""&#xA;        source=""logging.esHost"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESPort""&#xA;        source=""logging.esPort"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESLoggingLevel""&#xA;        source=""logging.esLoggingLevel"" /&gt;  &#xA;    &lt;springProperty scope=""context"" name=""consoleLoggingLevel""&#xA;        source=""logging.consoleLoggingLevel"" /&gt; &#xA;&#xA;    &lt;appender name=""ELASTIC"" class=""com.internetitem.logback.elasticsearch.ElasticsearchAppender""&gt;&#xA;        &lt;url&gt;http://${myESHost}:${myESPort}/_bulk&lt;/url&gt;&#xA;        &lt;index&gt;logs-%date{yyyy-MM-dd}&lt;/index&gt;&#xA;        &lt;type&gt;tester&lt;/type&gt;&#xA;        &lt;loggerName&gt;es-logger&lt;/loggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;errorLoggerName&gt;es-error-logger&lt;/errorLoggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;connectTimeout&gt;30000&lt;/connectTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;errorsToStderr&gt;false&lt;/errorsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeCallerData&gt;false&lt;/includeCallerData&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;logsToStderr&gt;false&lt;/logsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxQueueSize&gt;104857600&lt;/maxQueueSize&gt; &lt;!-- optional (default 104857600) --&gt;&#xA;        &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;!-- optional (default 3) --&gt;&#xA;        &lt;readTimeout&gt;30000&lt;/readTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;sleepTime&gt;250&lt;/sleepTime&gt; &lt;!-- optional (in ms, default 250) --&gt;&#xA;        &lt;rawJsonMessage&gt;false&lt;/rawJsonMessage&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeMdc&gt;false&lt;/includeMdc&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxMessageSize&gt;100&lt;/maxMessageSize&gt; &lt;!-- optional (default -1 --&gt;&#xA;        &lt;authentication class=""com.internetitem.logback.elasticsearch.config.BasicAuthentication"" /&gt; &lt;!-- optional --&gt;&#xA;        &lt;properties&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;host&lt;/name&gt;&#xA;                &lt;value&gt;${HOSTNAME}&lt;/value&gt;&#xA;                &lt;allowEmpty&gt;false&lt;/allowEmpty&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;severity&lt;/name&gt;&#xA;                &lt;value&gt;%level&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;thread&lt;/name&gt;&#xA;                &lt;value&gt;%thread&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;stacktrace&lt;/name&gt;&#xA;                &lt;value&gt;%ex&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;logger&lt;/name&gt;&#xA;                &lt;value&gt;%logger&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;        &lt;/properties&gt;&#xA;        &lt;headers&gt;&#xA;            &lt;header&gt;&#xA;                &lt;name&gt;Content-Type&lt;/name&gt;&#xA;                &lt;value&gt;text/plain&lt;/value&gt;&#xA;            &lt;/header&gt;&#xA;        &lt;/headers&gt;&#xA;    &lt;/appender&gt;&#xA;&#xA;    &lt;root level=""info""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;        &lt;appender-ref ref=""ELASTIC"" /&gt;&#xA;    &lt;/root&gt;&#xA;&#xA;    &lt;logger name=""es-error-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;    &lt;logger name=""es-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender name=""ES_FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;&#xA;            &lt;!-- ... --&gt;&#xA;            &lt;encoder&gt;&#xA;                &lt;pattern&gt;%msg&lt;/pattern&gt; &lt;!-- This pattern is important, otherwise it won't be the raw Elasticsearch format anyomre --&gt;&#xA;            &lt;/encoder&gt;&#xA;        &lt;/appender&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;"
49836268,How to deal with authentication in a micro-services architecture,<microservices><grpc>,2,172,4,3.0,3,"<p>I am currently reading a lot about microservices but still, I don't understand some parts. I made the following draw:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GkgRC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GkgRC.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each microservice has 2 accesses:</p>&#xA;&#xA;<ul>&#xA;<li>REST: For http uses</li>&#xA;<li>gRPC: For intra/background communication/exchanges</li>&#xA;</ul>&#xA;&#xA;<p>If I want to login I can just send an Http Request to my Authentication service. But what about if I want to access the Stuff service that needs you to be already connected?</p>&#xA;&#xA;<p>Let say that the user wants to display the stuff available in the database STUFF, the service Stuff will first check if the ""token"" of the connected user is right, by exchanging with the Authentication service, and then return the stuff or a ""login requires request"".</p>&#xA;&#xA;<p>So the thing I don't understand is, if each services that needs a client already connected needs to exchange with Authentication, then it will create a huge internet traffic in order to check each user request.. So I though about make one Authentication service per service, but since I should have only one Database, then it's the database that will slow the traffic?</p>&#xA;&#xA;<p>Also, if I understand, each micro service should be on separate servers, not the same one?</p>&#xA;&#xA;<p>I hope I am clear, don't hesitate to ask for more details !</p>&#xA;&#xA;<p>Thanks in advance :)</p>&#xA;&#xA;<p>Max</p>&#xA;&#xA;<h1>Edit 1</h1>&#xA;&#xA;<p><strong>Based on @notionquest's answer:</strong></p>&#xA;&#xA;<p>So it should more looks like that right?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pdOdR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pdOdR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Also, based on Peter's comment, each service can implement its own middleware (JWT as mentioned) so the API Gateway is only a ""pass-through"". However, I don't feel like it could be a nice for me since each service make a token check for each internal exchange, doesn't it?</p>&#xA;&#xA;<p>For the stuff, it's easy since it checks only 1 time the token. Now, let's say that, after the user got the stuff, he choose one and wanna buy it. Then the ""Buying service"" will call the stuff service in order the verify the price of the item, but... It will have to check the user token since the stuff is a ""on authenticated access"", so it means that ""Buying"" service and ""Stuff"" service both check the token, which add an extra check.</p>&#xA;&#xA;<p>I though about an internal guaranteed access between services but is it worth it?</p>&#xA;&#xA;<p>Also, maybe you said to implement the middleware for each service since they have a REST access, but the API Gateway would just destroy the idea of having REST access</p>&#xA;"
42053559,Eventual consistency with both database and message queue records,<database><domain-driven-design><message-queue><microservices><eventual-consistency>,3,466,2,0.0,3,"<p>I have an application where I need to store some data in a database (mysql for instance) and then publish some data in a message queue. My problem is: If the application crashes after the storage in the database, my data will never be written in the message queue and then be lost (thus eventual consistency of my system will not be guaranted).&#xA;How can I solve this problem ?</p>&#xA;"
41609091,Sharing files between microservices,<node.js><microservices><seneca>,2,1858,1,1.0,3,"<p>I'm trying to move a project from its current monolithic state to microservices architecture. The project is in Node.js, so I've started looking into <a href=""http://senecajs.org/"" rel=""nofollow noreferrer"" title=""Seneca.js"">Seneca.js</a>, especially with its <a href=""https://github.com/senecajs/seneca-mesh"" rel=""nofollow noreferrer"" title=""seneca-mesh"">seneca-mesh</a> module. Moving image manipulation (crop, resize, etc.) into a microservice seemed the most sensible first step, since it drastically slows down my application now.</p>&#xA;&#xA;<p>When the application is monolithic, there is no problem in passing certain files into file-manipulation logic — just read it from local storage disk. With microsevices, however, if we keep in mind <em>scalability</em>, it becomes more difficult. Of course, I could build an image manipulation microservice, scale it up <em>within the same host machine</em>, and share directories I need between it, so they, too, can read from a local disk.</p>&#xA;&#xA;<p>What if I want a truly scalable microservice, that can be run and scaled on <em>different</em> machines with different IP-adresses that <em>don't share the same filesystem</em>? I thought that maybe I could take advantage of Node's streaming API and send these files back and forth via HTTP or TCP or sockets or you name it.</p>&#xA;&#xA;<p>As far as I've learned, Seneca.js cannot do it <em>the right way</em>. Of course, I could send a file from the main app to image manipulation service via Seneca.js like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('/files/hello.jpg')&#xA;  .on('data', function(data) {&#xA;    seneca.act({ role: 'file', cmd: 'chunk', data: data }, cb);&#xA;  })&#xA;  .on('end', function(err) {&#xA;    seneca.act({ role: 'file', cmd: 'end' });&#xA;  })&#xA;  .on('error', function(err) {&#xA;    seneca.act({ role: 'test', cmd: 'error' });&#xA;  });&#xA;</code></pre>&#xA;&#xA;<p>And receive it in chunks:</p>&#xA;&#xA;<pre><code>seneca.add({ role: 'file', cmd: 'chunk' }, writeToFileCb);&#xA;seneca.add({ role: 'file', cmd: 'end' }, endFileWriteCb);&#xA;</code></pre>&#xA;&#xA;<p>But this approach seems ugly and wheel-reinventive.</p>&#xA;&#xA;<p>Another way would be to come up with some HTTP server and send files as <code>multipart/form-data</code> or <code>application/octet-stream</code>, like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('file.json')&#xA;  .pipe(request.post('http://image-manipulator'))&#xA;</code></pre>&#xA;&#xA;<p>But this means reinventing the framework for microservice communication. All in all, I ask for advice on file sharing between distributed microservices and possible frameworks for this.</p>&#xA;"
41661858,Microservice Interaction,<c#><.net><microservices><restful-architecture>,2,439,2,0.0,3,"<p>I would like to know what is the best practice on making one Microservice to interact with another Microservice?</p>&#xA;&#xA;<p> I am developing in C#. What I currently have done is, created a service bus which passes new events created from one Microservice. I then use task runner (WebJob) which consumes the messages off the bus and then I am using Http to Post to another Microservice endpoint. Each microservice is a web api. </p>&#xA;&#xA;<p>I would like to ask if I am doing it correctly, if not I am happy to hear the suggestions. </p>&#xA;"
39839881,Is it OK to pass on OAuth Access Token between services?,<oauth><oauth-2.0><authorization><access-token><microservices>,3,1446,0,0.0,3,"<p>Considering the following scenario in a context of the SSO/OAuth/microservices:</p>&#xA;&#xA;<ol>&#xA;<li>User successfully logs-in to the web application using OAuth's Implicit Flow.</li>&#xA;<li>Web app requests some data from <strong>Service A</strong> and <strong>Service B</strong> passing on user's Access Token to authorize both requests.</li>&#xA;<li><strong>Service A</strong> also calls <strong>Service B</strong> (passing on the same Access Token!) in order to build response to the initial Web App request.</li>&#xA;</ol>&#xA;&#xA;<p>Now, is this OK to pass on the user's Access Token from <strong>Service A</strong> to <strong>Service B</strong>? </p>&#xA;&#xA;<p>Or should <strong>Service A</strong> use ""Client Credentials"" grant to obtain its own Access Token to authorize call to the <strong>Service B</strong>?</p>&#xA;&#xA;<p><strong>UPDATE</strong>:<br>&#xA;Please assume both services are owned by the same organization and both trust the same Authorization Server. Also both services are behind the same API Gateway which validates Access Tokens.</p>&#xA;"
39672919,How to design a sails.js project with microservices architecture?,<node.js><architecture><sails.js><microservices>,2,1195,0,3.0,3,"<p>I learned about microservices from <a href=""http://microservices.io/"" rel=""nofollow"">here</a></p>&#xA;&#xA;<p>Now, I want to use microservices architecture in my next sails.js project.</p>&#xA;&#xA;<p><strong>One way I could think of is:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Breaking my one sails.js application into multiple small sails.js sub-projects/repositories. </p></li>&#xA;<li><p>Having one controller-model in one sub-project. For example, If we consider simple eCommerce app with entities say User, Products, Orders, etc. then there will be separate sails.js repositories for each of them with respective sails.js model-controller.  Then this single sub-repository will from my one microservice.</p></li>&#xA;<li><p>Each sub-repository then will obviously have its own configs.</p></li>&#xA;<li><p>These microservices will them communicate with each other using some HTTP node module.</p></li>&#xA;<li><p>Then writing my own <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow"">API gateway</a> for routing in node.js, which will be responsible for invoking methods/web-services from these sub-repositories depending on the request from clients.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is this the best way OR is there alternative way to design your project using microservices architecture?</p>&#xA;&#xA;<p>What will be the best way to implement inter-service communication, API gateway with sail.js? If one microservice designed with above mentioned approach get bigger, and if I have to split it up in 2, how sails.js model should be changed?</p>&#xA;"
35743527,Microservice with own UI with Spring and Thymleaf,<spring><thymeleaf><microservices><ssi>,2,590,7,0.0,3,"<p>I have three web application microservices and one gateway that include the UI. So, what i want to do is to change the app's that every microservice has his own UI and the gateway should make server side includes. Im using Thymeleaf as template engine and do the includes like this: </p>&#xA;&#xA;<p><code>&lt;div th:replace=""http://localhost:8080/#/organizations""&gt;&lt;/div&gt;</code></p>&#xA;&#xA;<p>My Problem is that the CSS and JS files are not Included from the original localhost:8080 server rather from the server with includes the content localhost:9090.</p>&#xA;&#xA;<p>This is how i include the JS and CSS files at *:8080:</p>&#xA;&#xA;<p><code>&lt;script th:src=""@{webjars/jquery/$jquery.version$/jquery.min.js}""&lt;/script&gt;</code></p>&#xA;&#xA;<p>Hope you understand my problem and someone can help...</p>&#xA;"
51602270,spring-data-rest and micro-services: Entity with @OneToOne relationship with Entity in another spring-data-rest service,<java><spring-boot><microservices><spring-data-rest>,1,56,0,0.0,3,"<p>In my spring-data-rest application I have the following entities</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class com.foo.client.Foo {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    @OneToOne&#xA;    public Bar bar;        &#xA;}&#xA;&#xA;@Entity&#xA;public class Bar {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    public String name;        &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have JpaRepository for each entity class:</p>&#xA;&#xA;<pre><code>@RepositoryRestResource(collectionResourceRel = ""foos"", path = ""foos"")&#xA;public interface FooRepository extends JpaRepository&lt;Foo, String&gt; {&#xA;}&#xA;&#xA;&#xA;@RepositoryRestResource(collectionResourceRel = ""bars"", path = ""bars"")&#xA;public interface BarRepository extends JpaRepository&lt;Bar, String&gt; {&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8000/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8000/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>When the two entities are defined in the same spring-data-rest service endpoint then all is well and I can get the bar instance associated with the foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X GET -H ""Content-Type:application/json"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>Question: Looking at the postgresdb where entities are stored I see an association table FOO_BAR where there are two columns holding the id of each entity. However, I do not see where the URL for bar is stored and would like to understand where it is stored.</p>&#xA;&#xA;<p>Now if I split my app into two separate spring-data-rest services one foo-service for Foo and another bar-service for bar at separate ports, and also split the Repository classes between two project, then creating the association does not work and I get a 404. See modified code below:</p>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8001/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8001/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>This last request above gives me a 404 when Foo and Bar are managed by different spring-data-rest services.</p>&#xA;&#xA;<p>How can I get the second case to work?</p>&#xA;&#xA;<p>Note I used <a href=""http://www.baeldung.com/spring-data-rest-relationships"" rel=""nofollow noreferrer"">this</a> excellent resource for my example.</p>&#xA;"
51627473,Spring Boot YAML Auto Data Source Configuration Issue - Data Source URL not picked up,<java><spring><spring-boot><yaml><microservices>,1,59,7,0.0,3,"<p>Currently, We are creating a spring boot project for our newer modules. </p>&#xA;&#xA;<p>Technology We have used as follows :</p>&#xA;&#xA;<ol>&#xA;<li>Java 1.8</li>&#xA;<li>Maven 3.5.2</li>&#xA;<li>Spring Boot: 1.5.6.RELEASE (spring-boot-starter-parent)</li>&#xA;</ol>&#xA;&#xA;<p>public class Application {</p>&#xA;&#xA;<pre><code>public static void main(String[] args) {&#xA;    SpringApplication.run(Application.class, args);&#xA;}&#xA;&#xA;@Autowired&#xA;private DataSource datasource;&#xA;</code></pre>&#xA;&#xA;<p>}</p>&#xA;&#xA;<p>application.properties</p>&#xA;&#xA;<ul>&#xA;<li>spring.datasource.url=<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>spring.datasource.username=XXX</li>&#xA;<li>spring.datasource.password=XXX</li>&#xA;<li>spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver</li>&#xA;</ul>&#xA;&#xA;<p>application.yml</p>&#xA;&#xA;<ul>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles:</li>&#xA;<li>active: ""dev""</li>&#xA;<li>main:&#xA;&#xA;<h2>     - banner-mode: ""off""</h2></li>&#xA;</ul></li>&#xA;<li><p>spring:</p>&#xA;&#xA;<ul>&#xA;<li>profiles: dev</li>&#xA;<li>datasource:&#xA;&#xA;<ul>&#xA;<li>url:<strong>jdbc:oracle:XXX:@XXX:XXX/XXX</strong></li>&#xA;<li>username:XXX</li>&#xA;<li>password:XXX</li>&#xA;<li>driver-class-name:oracle.jdbc.driver.OracleDriver</li>&#xA;</ul></li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>When we are adding data source information as properties file the application working as expected. But information as YAML means showing below error.</p>&#xA;&#xA;<p><strong>ERROR</strong></p>&#xA;&#xA;<p>Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'testapplication': <strong>Unsatisfied dependency expressed through field 'datasource'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource</strong> [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Tomcat.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.tomcat.jdbc.pool.DataSource]: Factory method 'dataSource' threw exception; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: <strong>Cannot determine embedded database driver class for database type NONE. If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (the profiles ""dev"" are currently active)</strong>.</p>&#xA;"
31764926,Microservices API calls and dependency design,<design><dependencies><microservices>,2,359,0,2.0,3,"<p>Are there any best practice on designing microservices service regarding API dependency (APIs that the service is calling to)?</p>&#xA;&#xA;<p>For example if I have a ""Order Management"" (OM) service, obviously it will need to call ""User Management"" (UM) service since it will need to query user info (shipping address, email, etc) many times. If I let my OM calls UM all the time when it needs user info this will create lots of dependency on UM service. </p>&#xA;&#xA;<p>As far as I understand services are supposed to be autonomous and as decoupled as possible - but now I got a OM service that will go down everytime UM service go down.</p>&#xA;&#xA;<p>Upon searching on Google I found 3 alternatives:</p>&#xA;&#xA;<ol>&#xA;<li>Use the event-based programming to replciate user data as soon as user data is created in UM module so it is always replicated into a table inside OM</li>&#xA;<li>Use database's replciation mechanism to replicate data from UM onto OM database</li>&#xA;<li>Copy user data into order object as nested json to eliminate dependency for order query and update (but I suppose initial order creation will still need to call UM)</li>&#xA;</ol>&#xA;&#xA;<p>Are there any best practices on the challenge here or are there any rules of thumb of deciding which design approach to take?</p>&#xA;"
39268365,Nested GraphQL servers / microservices,<microservices><graphql><apollo-server>,1,291,1,1.0,3,<p>I would like to replace all my REST APIs with GraphQL (apollo-server preferred). It's clear to me how to use GraphQL in monolithic apps but it's not clear how to do it for microservices.</p>&#xA;&#xA;<p>The main API server consists of multiple microservices where each microservice exposes its own REST API through which the central API server communicates with it. I would like to replace all these REST APIs with GraphQL thus I would get microservices as nested GraphQL servers communicating with each other through GraphQL instead of REST.</p>&#xA;&#xA;<p>The problem that I'm facing is how to easily build a GraphQL query string for microservices based on the received attributes in the resolver of the main GraphQL server. There is no way to tell GraphQL to return all the fields for microservice. The best way would be to simple forward just a part of a the main query further to a microservice. </p>&#xA;&#xA;<p>Any ideas? Do you think that REST is still more appropriate for microservices then GraphQL?</p>&#xA;
46404449,Micro service architecture for Angular2,<angular><design-patterns><architecture><microservices>,1,657,4,2.0,3,"<p>If we take an enterprise  angular 2 web app it has several modules(screens) such as Customer management, Reservations, Booking management, Reporting and etc....</p>&#xA;&#xA;<p>What we normally do is we create common components in a component library and use them on main angular application. The main angular app contains all the modules(screens) with REST API integrations(assuming backed is REST). When app is getting bigger &amp; bigger compile time and rendering consuming more time &amp; resources. Also if one particular area is having a issue we cannot have a release since all are bundle to one app.</p>&#xA;&#xA;<p>As you all know <strong>Micro service architecture</strong> is a method of developing software systems that has grown in popularity. So, my question is can we apply same architecture for these type of enterprise angular 2 apps?. </p>&#xA;&#xA;<p>It is like this. We have a customer management as a separate angular app. Again Booking management is another angular app. Reporting is another app. These apps are going to be separate war files when deploying to the web server. </p>&#xA;&#xA;<p>Once we have developed such loosely coupled apps this will reduce the over head of project size, compile time &amp; resources. Also this will make unit testing more easier. Particular set of developers are only considering the only one unit of the module.</p>&#xA;&#xA;<p>Kindly share your expert thoughts about this</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46471625,Multiple microservice symfony application share vendor folder,<php><symfony><composer-php><share><microservices>,2,314,5,1.0,3,"<p>We are working on a new web project, with a microservice architecture.</p>&#xA;&#xA;<p>We will need around 5 Front Web project, and about 5 API microservice orchestrate with an API manager.</p>&#xA;&#xA;<p>We plan to use Symfony2 Framework, but I think it will be too Heavy. I mean because by the instance of the composer that will download all around the same library from symfony component, core... and same library used for each project (phpmailer for example).</p>&#xA;&#xA;<p>Actually, I was asking myself about a great sharing strategy for the vendor folder assuming that each SF2 project would use a share vendor folder and compute all library in a unique folder.&#xA;We need all the same version for each library in each project.</p>&#xA;&#xA;<p>Does somebody have some experiment on this kind of sharing? Best practices? Is it preferable to have one vendor folder per project? </p>&#xA;&#xA;<p>Open discution !</p>&#xA;&#xA;<p>Cheers.</p>&#xA;"
44946517,Unable to get jhipster gateway home page,<angular><jhipster><microservices>,2,390,1,0.0,3,<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in application-dev.yml)&#xA;There is no errors in console.</p>&#xA;&#xA;<p><code>index.html</code> completely loading may be routing is not working fine.</p>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is provided by yarn) </p>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other micro services applications.</p>&#xA;
44988481,Spring Cloud - how to allow access to endpoint for specific microservice only?,<spring><oauth-2.0><microservices><spring-cloud>,2,286,4,1.0,3,"<p>I have simple microservice architecture:</p>&#xA;&#xA;<ul>&#xA;<li>edge service</li>&#xA;<li>service registry</li>&#xA;<li>auth service (I am using JWT and OAuth2)</li>&#xA;<li>user service</li>&#xA;<li>frontend and some core services</li>&#xA;</ul>&#xA;&#xA;<p>When the user tries to log in, the credentials are passing from edge service to auth service. Auth service fetches user's data from user service (using <strong>@FeignClient</strong>) and if username/password matches, it generates token. Nothing fancy about it.</p>&#xA;&#xA;<p>There a 'little' problem with this approach: the endpoint <code>/api/user/{username}</code> in user service, which is used by auth service to fetch user's data, might be used by any user to get any other user's data (password, roles etc.). The one solution would be somehow create JWT token for auth-service with role <code>AUTH_SERVICE</code> and at the user service side check JWT and if the role is different than <code>AUTH_SERVICE</code> reject the request.</p>&#xA;&#xA;<p>Are there any other solutions?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>I thought that my design is quite common but apparently I should have been more specific in the first place:</p>&#xA;&#xA;<ul>&#xA;<li>Auth-servie is my Authorization Server and the other services are Resource servers</li>&#xA;<li>I use API gateway pattern and my auth-service is also behin proxy</li>&#xA;<li>After the client application obtains JWT it adds it to every request and based on that the authentication and authorization is performed; every Resource server has a public key which is used to verify signature; if it's valid, the service knows that JWT has been generated by trusted auth-service and the service based on JWT creates OAuth2Authenication object which contains all the user information</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT2:</strong></p>&#xA;&#xA;<p>I ended up merging auth-service to user-service, which was the suggestion given from a couple of SO users. After thinking about it it seemed unnecessary to have a seperate auth-service for just JWT generation. I've accepted @Abhijit Sarkar answer because it has some valid points even though he wasn't right about additional call to auth-service to verify validity of the token.</p>&#xA;"
34020234,Communication between Node.js microservices,<json><node.js><express><architecture><microservices>,1,1519,2,0.0,3,"<p>I'm creating an application with Node.js using microservices architecture. I'm trying to find the best way of communication between nodes. I have a Java background so the best option I can imagine is something like SOAP, where you create a proxy object and by calling it's method a request to a remote node would be made via http.</p>&#xA;&#xA;<p>Currently I only see an option of direct calls like </p>&#xA;&#xA;<pre><code>http.get(""remote-node/api/method1"", function(res) {&#xA;}).on('error', function(e) {&#xA;  console.log(""Got error: "" + e.message);&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However I don't think it's convenient. Are there better approaches?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
38106036,Documenting a message bus API?,<c#><json><documentation><microservices><netmq>,1,337,0,1.0,3,"<p>I've been searching for the past couple of days for some way to document the API for a microservices architecture I'm working on.  First, I'll give a very quick description of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Written in C#, .NET 4.6.1</li>&#xA;<li>Using NetMQ with x-pub/x-sub proxy as a ""message broker""</li>&#xA;<li>All communication is plain C# objects serialized to JSON</li>&#xA;<li>Some clients are JavaScript in the browser, others are .NET applications</li>&#xA;</ul>&#xA;&#xA;<p>The short of it is that I'd like to know how other people document the models that are published to their message bus.  I've seen quite a few projects (like Swagger) that help document REST calls, but we're not using REST.  Our application is almost entirely event-based with pub-sub messaging using JSON.</p>&#xA;&#xA;<p>My first thought was to document the JSON with JSON-Schema and use a tool to convert that to nicely-formatted API docs.  That would probably work okay, but what bothers me is that there don't seem to be any tools to automate the schema generation as part of a build process.  If our models diverge from the API documentation, I want it to be a build error.  Even better, if there was some way to auto-generate the basic documentation as part of the build process, the docs could be kept in sync.</p>&#xA;&#xA;<p>How do you guys do it?  The lack of documentation tools specific to a message bus architecture in favor of REST is making me question our decision to use a messaging architecture based on message queues.  :)</p>&#xA;"
38070572,How to architecture Microservice & OpenID connect?,<microservices><openid-connect><oauth2>,1,1235,0,1.0,3,"<p>We have three microservices: microA, microB &amp; microC.</p>&#xA;&#xA;<ul>&#xA;<li>microA &amp; microB are powering product 1.</li>&#xA;<li>microA &amp; microC are powering product 2.</li>&#xA;</ul>&#xA;&#xA;<p>Obviously, we would need a security layer, in our case implementing an ""OpenID Connect"" provider fits well with the business needs. We add to the stack the OpenID provider.</p>&#xA;&#xA;<p>The user/rights management is quite easy &amp; natural: we associate the OpenId identifier of the user on each microservices to a subset of rights:</p>&#xA;&#xA;<p>For example on the service microA, we store that the user OpenID XXX can do this and that. it's isolated on the microservice level. Respect the boundaries of our context. Fine.</p>&#xA;&#xA;<p>When the user login with OpenID on product1, we grant an access token to the user + an Id token.</p>&#xA;&#xA;<p>The situation becomes more complex when product1 expose an API that third-party use.</p>&#xA;&#xA;<p>Now, let say that my user comes to the third-party webapp and is prompted to login &amp; allow the third-party to get some rights on product1 API.</p>&#xA;&#xA;<p>If I understand correctly OpenID connect, it's all about authentication over OAuth2, but how do we handle classic OAuth2 scope management then?</p>&#xA;&#xA;<p>The best scenario I have found is:</p>&#xA;&#xA;<ol>&#xA;<li><p>make the whole OpenID connect to have the authentication info </p></li>&#xA;<li><p>and then make another full OAuth2 process to another Authorization server to ask the user to grant some scopes to the third party?</p></li>&#xA;</ol>&#xA;&#xA;<p>which means that on the third-party:</p>&#xA;&#xA;<ul>&#xA;<li>the user will be prompted to login on the OpenID Provider </li>&#xA;<li>then redirected and prompted to accept the scope requested</li>&#xA;</ul>&#xA;&#xA;<p>Is that correct? If yes, OAuth2 server flow is like 4 HTTP requests to the end user, so performing it twice is like executing eight requests to get the Authentication + Authorization flow done. Seems too massive.</p>&#xA;"
38168658,Multiple microservices and database associations,<database><rest><spring-boot><microservices>,2,480,0,0.0,3,"<p>I have a question concerning microservices and databases. I am developing an application: a user sees a list of countries and can click through it so he can see a list of attractions of that country. I created a country-service, auth-service (contains users for oAuth2) and an attraction-service. Each service has its own database. I mapped the association between an attraction and its country by the <strong>iso code</strong> (for example: BE = belgium): /api/attraction/<strong>be</strong>.</p>&#xA;&#xA;<p>The approach above seems to work but I am a bit stuck with the following: a user must be able to add an attraction to his/her list of favorites, but I do not see how that's possible since I have so many different databases. </p>&#xA;&#xA;<p>Do I create a favorite-service, do I pass id's (I don't think I should do this), what kind of business key can I create, how do I associate the data in a correct way...?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
38125926,Run Google App Engine application with microservice,<python><google-app-engine><publish-subscribe><microservices>,1,515,2,3.0,3,"<p>I have a one big monolith application, and now its time to separate some modules to micro services!&#xA;I read a lot about pub/sub and microservices in Google docs, but can't find answers to my questions:</p>&#xA;&#xA;<ol>&#xA;<li>How app.yaml file looks like for my module(microservice)?</li>&#xA;<li>How app.yaml looks like for my app?(I mean, with microservice)</li>&#xA;<li>Where I need to declare this module - in application app.yaml or in both app.yaml?</li>&#xA;<li>How can I use single datastore with my app and my module?</li>&#xA;</ol>&#xA;&#xA;<p>My app.yaml now looks like:</p>&#xA;&#xA;<pre><code>application: my-application&#xA;version: 1&#xA;runtime: python27&#xA;api_version: 1&#xA;threadsafe: true&#xA;</code></pre>&#xA;&#xA;<p>with some credentials and libs.</p>&#xA;&#xA;<p>Waiting for your answers!</p>&#xA;"
45241581,Microservices vs functions as service (faas),<aws-lambda><microservices>,1,909,0,1.0,3,"<p>Microservice architecture is/was next big thing. Easy to deploy, easy to develeop, not as complicated to scale and develop as monolith systems.</p>&#xA;&#xA;<p>Oriented mostly towards containers, it all looked new and promising, but i recently discovered there is a new hype about function as service or faas (aws lambda for example). </p>&#xA;&#xA;<p>Wikipedia says the following about Faas ""Building an application following this model is one way of achieving a ""serverless"" architecture, and is typically used when building microservices applications.""</p>&#xA;&#xA;<p>My conclusion was that in faas one should not worry about maintaining hardware and network resources. But is that the only advantage? Could microservice architecture pattern be fully achieved using functions as service?</p>&#xA;"
45167593,Authorization of actions across microservices,<web-services><rest><authorization><microservices><event-sourcing>,2,108,1,1.0,3,"<p>A modern multi-user web application imposes a lot of restrictions on the actions that users can perform. In other words, the actions require authority. For example, a user can only change its own personal data, and only members of a group can post content to that group. In a classic monolith application, such restrictions are easily enforced by joining several database tables and acting according to the results of queries. However, with microservices, it becomes much less clear where and how such limitations should be handled.</p>&#xA;&#xA;<p>For the sake of argument, consider a Facebook clone. The whole application consists of several parts:</p>&#xA;&#xA;<ul>&#xA;<li>A front-end, written in JS and other web technologies</li>&#xA;<li>A backend consisting of a number of microservices</li>&#xA;<li>An API for retrieving and submitting data to the backend, i.e. a gateway</li>&#xA;</ul>&#xA;&#xA;<p>As for the business logic, there are (among others) two well-known entities:</p>&#xA;&#xA;<ul>&#xA;<li>Events (as in concerts, birthday parties etc.)</li>&#xA;<li>Posts (text entries existing on walls, pages, events etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Suppose that these two entities are managed by separate services, EventService and PostService. Then consider the following constraint:</p>&#xA;&#xA;<blockquote>&#xA;  <p>A post to an event can be deleted by two kinds of users: the author of the post, and the host(s) of the event.</p>&#xA;</blockquote>&#xA;&#xA;<p>In a monolith, this constraint would've been conceptually very easy to deal with. Upon receiving a request to delete a post, supplying the post id and user id,</p>&#xA;&#xA;<ol>&#xA;<li>Fetch the event which the post belongs to.</li>&#xA;<li>Check if the user is the author of the post.</li>&#xA;<li>If yes, delete the post. If not, fetch the hosts of the event.</li>&#xA;<li>Check if the user is among the hosts.</li>&#xA;<li>If yes, delete the post.</li>&#xA;</ol>&#xA;&#xA;<p>However, with a microservice strategy, I have a hard time figuring out how to divide the responsibilities of an operation like this across the services.</p>&#xA;&#xA;<h2>Alternative 1</h2>&#xA;&#xA;<p>An easy way around it would be to put logic like this in the gateway. That way, the same procedure as described above could essentially be performed, but with calls to the services instead of directly to the database. Rough sketch:</p>&#xA;&#xA;<pre class=""lang-js prettyprint-override""><code>// Given postId and userId&#xA;// Synchronous solution for presentational purposes&#xA;&#xA;const post = postClient('GET', `/posts/${postId}`);&#xA;const hosts = eventClient('GET', `/events/${post.parentId}/hosts`);&#xA;const isHost = hosts.find(host =&gt; host.id == userId);&#xA;&#xA;if (isHost) {&#xA;    postClient('DELETE', `/posts/${postId}`);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I'm not happy with this solution. Once I start putting logic like this in the gateway, it'll become very tempting to <em>always</em> do it, as it's a quick and simple way to get things done. All business logic would eventually amass in the gateway, and the services would become ""stupid"" CRUD endpoints. This would defeat the purpose of having separate services with well-defined areas of responsibility.  Furthermore, it could be slow as it could give rise to a high number of calls to the services when operations are getting more complex.</p>&#xA;&#xA;<p>I would essentially be reinventing the monolith, replacing database queries with slow and limited network calls.</p>&#xA;&#xA;<h2>Alternative 2</h2>&#xA;&#xA;<p>Another option would be to allow unlimited communication <em>between</em> services, allowing PostService to simply ask EventService whether the user is a host of the event in question before performing the delete. However, I'm afraid that having a potentially large number of microservices communicating with each other could introduce a lot of coupling in the longer run. Experts seem to generally advise against direct inter-service communication.</p>&#xA;&#xA;<h2>Alternative 3</h2>&#xA;&#xA;<p>With a solid system for publishing and subscribing to events, the services could stay updated about what happens in other services. For example, every time a user is promoted to host in EventService, an event would be posted (e.g. <code>events.participant-status-changed, {userId: 14323, eventId: 12321, status: 'host'}</code>). PostService could subscribe to the event and remembering this fact when a request to delete a post is received.</p>&#xA;&#xA;<p>However, I'm not quite happy with this one either. It'd create a very intricate and error-prone system, where an unhandled (but potentially rare) event could make services go out of sync. Also, there's a risk that logic would end up in the wrong place. For example, the constraint in this question would be handled by PostService even though conceptually it's a property of the event entity.</p>&#xA;&#xA;<p>I should stress though that I'm very optimistic about the usefulness of events when implementing applications using microservices. I'm just not sure they are the answer to this category of problems.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How would you tackle this hypothetical, but quite realistic difficulty?</p>&#xA;"
45351222,Is it possible to proxy a POJO in microservices application?,<java><spring-boot><microservices>,1,140,2,0.0,3,"<p>I would like to avoid duplicating my POJOs in a microservices application, so I am wondering if there is a way to do that (like proxying)?</p>&#xA;&#xA;<p>I mean, is there a way for a <code>Service A</code> to access POJOs (or other classes/interfaces) defined inside a <code>Service B</code> without physically creating these POJOs classe files in <code>Service A</code>? </p>&#xA;&#xA;<p>The big big challenge in a microservice architecture is that point and I didn't find a way to solve it.</p>&#xA;"
39591223,Can SOA and Microservices co-exist?,<design><architecture><soa><microservices>,3,379,0,0.0,3,<p>It is often documented to build a microservice based architecture from a monolith. Is it also possible to have microservices in SOA based architecture?</p>&#xA;
39540366,Go-kit real world example with inter microservice data transfers,<go><microservices>,1,947,0,4.0,3,"<p>I try to work with go-kit (gokit.io) and to build real-work application with it.&#xA;I look through examples. These examples are great. But I do not understand how to do services to service communications / data transfers in go-kit framework. </p>&#xA;&#xA;<p>I can see ""real-world"" shipping app, but I do not understand how it could be ""real world"" micro-services. I can see in sources that, for example, they build the booking service just passing foreign repositories into service</p>&#xA;&#xA;<pre><code>type service struct {&#xA;    cargoRepository         cargo.Repository&#xA;    locationRepository      location.Repository&#xA;    routingService          routing.Service&#xA;    handlingEventRepository cargo.HandlingEventRepository&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and later they get data from repositories (this repository belongs to foreign micro-service) just calling the method:</p>&#xA;&#xA;<p><code>locationRepository.Find(...)</code></p>&#xA;&#xA;<p>Could someone please explain me:</p>&#xA;&#xA;<ul>&#xA;<li>how to build micro-service to micro-service communications in go-kit framework? Just show me the way / pattern, please. I do not understand it at all.</li>&#xA;</ul>&#xA;&#xA;<p>I see it as they just share direct access to data. But in real world micro-services, I expected that micro-services will communicate to each other to get needed data. And I do not understand how to do it in go-kit framework.</p>&#xA;"
39601492,how monolith spring 3 application will communicate with microservice?,<spring><spring-boot><microservices><netflix-ribbon>,1,238,2,0.0,3,<p>I have one monolith spring web application developed using spring 3.1 and spring-security 3.1 with Java 7 and it is deployed on tomcat 7. </p>&#xA;&#xA;<p>Now I have a new requirement where I have to create a micro-service for a new module using spring boot with java 8. This micro-service will be deployed separately on different EC2 instance. </p>&#xA;&#xA;<p>I am looking for suggestion/idea to access new microservice from my existing spring web application. </p>&#xA;&#xA;<p>How to perform <em>inter process communication</em> within these two spring application?</p>&#xA;&#xA;<p>Can someone provide me any help/pointer?</p>&#xA;
39967784,Microservice vs SOA differs,<soa><microservices>,5,712,0,1.0,3,"<p>I was looking for differences b/w SOA and Microservices architecture style&#xA;and found a good link <a href=""https://www.infoq.com/articles/boot-microservices"" rel=""nofollow noreferrer"">https://www.infoq.com/articles/boot-microservices</a></p>&#xA;&#xA;<p>It Says:<br>&#xA;As a successor to ""Service Oriented Architecture"" (SOA), microservices can be categorized in the same family of ""distributed systems"", and carry forward many of the same concepts and practices of SOA. Where they differ, however, is in terms of the scope of responsibility given to an individual service. In SOA, a service may be responsible for handling a wide range of functionality and data domains, while a general guideline for a microservice is that it is responsible for managing a <strong>single data domain</strong> and the corresponding functions around that domain.</p>&#xA;&#xA;<p>Please help me to understand :<br>&#xA;The meaning of single data domain (recommended for microservice).&#xA;is it saying that a separate Microservice has to be build to manage a single domain/entity (and associated/composite domain/entities with this single domain/entity). Becasue if this case, then there will be many(~20 to ~50) microservices even to implement a basic functionality (enterprise) application</p>&#xA;&#xA;<p>Edit:&#xA;I have gone through the link <a href=""https://stackoverflow.com/questions/25501098/difference-between-microservices-architecture-and-soa"">Difference between Microservices Architecture and SOA</a>, but it explains, that it is same on the first two tenets, and different on 3rd point (in SOA, Services share schema and contract, not class), but that is SOAP contracts, but then what is the difference b/w SOA (with REST) vs Microservices (which is mostly with REST)</p>&#xA;"
40068013,ci/cd independent microservices in monorepo with git bash,<git><bash><continuous-integration><microservices><monorepo>,1,249,0,1.0,3,"<p>Using Bash and git, how do I get a collection of directories containing files that differ from that last time the branch was merged into <code>master</code>?</p>&#xA;&#xA;<p>Even better would be a collection of changed that match a pattern such as containing a particular file name , i.e. building a collection of changed directories containing <code>package.json</code> and a different collection of changed containing <code>requirements.txt</code>.</p>&#xA;"
41914911,microservice based event store,<microservices><cqrs><event-store><eventsource>,1,244,0,0.0,3,"<p>Unfamiliar with all the details of domain driven design, would it make sense  in a microservice architecture to think of each service as it's own domain and in turn build an event store per service?</p>&#xA;&#xA;<p>Not totally sure what the trade-offs might be from a single monolithic event store for the entire system. For example, more difficulty replaying conditions in the system or debugging cross service dependencies.</p>&#xA;"
41881610,Spring-Cloud Zuul breaks UTF-8 symbols in forwarded multipart request filename,<spring-boot><utf-8><microservices><netflix-zuul><netflix-eureka>,1,770,1,1.0,3,"<p>this is first time for me on SO, so please be patient for my first question.</p>&#xA;&#xA;<p>I think i have some kind of configuration problem, but after a day of experiments i'm stuck. Our application is based on Spring-Cloud [Brixton release]. We have configuration like this: Portal (web application serving angular-based web-ui), which has zuul proxy with single route configured to our gateway service, like so:</p>&#xA;&#xA;<pre><code>zuul:&#xA;   ignoredServices: '*'&#xA;   prefix: /api&#xA;   routes:&#xA;       api-proxy:&#xA;          path: /**&#xA;          serviceId: api-gateway&#xA;</code></pre>&#xA;&#xA;<p>which has another Zuul configured and relays requests to inner bussiness logic services:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredServices: '*'&#xA;  routes:&#xA;     service1:&#xA;       path: /service1/**&#xA;       serviceId: service1&#xA;     service2:&#xA;       path: /service2/**&#xA;       serviceId: service2&#xA;</code></pre>&#xA;&#xA;<p>All this configuration is working with no problem.&#xA;The problem now that i am facing is with file upload multipart requests. To be more precise - those multipart requests, when file to be uploaded has non latin symbols (e.g. ąčęėįš) from <code>UTF-8</code>. When request reaches service which has to deal with <code>@RequestPart MultipartFile file</code>, then <code>file.getOriginalFilename()</code> returns questionmarks in the places of aforementioned symbols. Now, i have tried to directly upload such file to such controller, and filename comes without questionmarks, that is, not broken, which suggests, that some bad interpretation/parsing of multipart request occurs somewhere in Zuul filters, when proxy relays incomming request.</p>&#xA;&#xA;<p>Maybe someone had similar experience with Zuul and can direct me some way to resolve this problem?</p>&#xA;"
42332737,Exchange reference token for JWT - downstream microservices authorization,<jwt><microservices><identityserver4>,2,743,0,2.0,3,"<p>I am currently creating a new application based on a Microservices architecture, with authentication provided by Identity Server 4. </p>&#xA;&#xA;<p>Following lots of research and also setting up proof of concepts, I have Identity Server setup to secure the API's and a native application successfully accessing these services using tokens.</p>&#xA;&#xA;<p>Initially the client was issued an access token which was used to access the API's, I have however now switched this out to use reference tokens.  Now, onto the issue!</p>&#xA;&#xA;<p>The approach I would like to take here is to adopt a Microservices gateway, which receives a reference token and then turns this into a JWT for inclusion in any requests to the downstream microservices.  Within the Gateway, how can I ""exchange"" the inbound reference token for a JWT? Is there something within Identity Server that can assist here? Or do I need to use the introspection endpoint, sending in the reference token and retrieving the claims to construct a JWT within the gateway service for passing in the Authorization header to all downstream services?</p>&#xA;&#xA;<p>If there is any further information that I can provide to help with understanding the goal of the architecture, please just let me know.</p>&#xA;"
41164987,User's locale in microservice - JHipster,<java><spring-security><jwt><jhipster><microservices>,1,264,0,0.0,3,"<p>In one of the microservices, in a JHipster microservice architecture, I want to generate a document, in the users' language.</p>&#xA;&#xA;<p>In the gateway, the users' language is retrieved by a cookie (AngularCookieLocaleResolver). But when a request, routed through the gateway, arrives at the microservice, no cookies are found on the request.</p>&#xA;&#xA;<p>I see a few options here:</p>&#xA;&#xA;<ol>&#xA;<li>Add a locale claim to the JWT-token</li>&#xA;<li>Contact the gateway with the username, to retrieve the locale</li>&#xA;<li>Do not generate locale specific content at a microservice</li>&#xA;</ol>&#xA;&#xA;<p>I would prefer the first option, but maybe there are some better options...</p>&#xA;&#xA;<p>Can anyone help me choose or list up alternatives?</p>&#xA;"
41036330,Store private key in microservices,<microservices><private-key><public-key>,1,140,0,1.0,3,"<p>There are some microservice which communicating with each other with rsa encrypted messages. The private keys are in files currently, what is the best practice to store the private and public keys in the containers? The current solution is in the /etc/ssl, but this is a little bit hard to manage and not to safety.</p>&#xA;"
50134195,Authorization between micro services and users,<architecture><microservices>,1,127,0,1.0,3,"<p>What would be best way to handle access and authorization between microservices and users?</p>&#xA;&#xA;<p>I'm building an application on microservice architecture. Services speak to each other through REST. there are endpoints that should be accessed only by other microservices and not directly by users, some endpoints are public and some would require users to register or have admin privileges. On top of that Users will have roles like admins and regular users.</p>&#xA;&#xA;<p>I'm trying to figure out if Oauth2 and scopes is the best approach for what I'm trying to achieve. e.g. each microservice will have ""user"" that have permission on certain scopes like ""service1-place-order"". </p>&#xA;"
51939287,Design of cloud Microservice on Heroku advice,<heroku><design><architecture><microservices><paas>,1,43,0,0.0,3,"<p>I am new to the world of microservice and I have tried to learn about it and how it could be apply to my needs. I need to design a cloud plaform easily maintenable and scalable with the following (as far as I see them) :</p>&#xA;&#xA;<ul>&#xA;<li>Rails API + PostgreSQL (microservice 1)</li>&#xA;<li>Frontend framework (microservice 2)</li>&#xA;<li>Some Python script (microservice 3)</li>&#xA;<li>Some other Python script (microservice 4)</li>&#xA;</ul>&#xA;&#xA;<p>Inspired by <a href=""https://stackoverflow.com/questions/41795612/how-to-deploy-microservices-on-heroku"">this question &amp; answer</a>, <strong>each microservice is a separate Heroku app</strong>. What about the security between them when they talk to each other and the response time?</p>&#xA;&#xA;<p>Also, since the service is meant to grow, it would be expensive sooner or later, how to optimize cost in this situation ? I just discovered <a href=""https://captainduckduck.com/"" rel=""nofollow noreferrer"">CaptainDuckDuck</a> but I'm afraid of the ""lack"" of experience from its user base since it's quite new and not as much popular as other PaaS. Is the only solution is to go to something like DigitalOcean or AWS EC2 and manage by ourselves the job that Heroku does ?</p>&#xA;&#xA;<p>Because doing microservice like this, is not really a microservice design since all the services are not hosted on the same machine, am I right ?&#xA;A more <em>microservice-friendly</em> approach would be to use <a href=""https://www.heroku.com/private-spaces"" rel=""nofollow noreferrer"">Heroku Private Spaces</a> (even if that doesn't answer the cost issue) ?</p>&#xA;&#xA;<p>For information, I have this design already up and running. So it's not a matter of <em>""will it work?""</em>, but more <em>""is it the right way?""</em>.</p>&#xA;&#xA;<p>Thanks for your feedbacks</p>&#xA;"
51889526,Why would we go for micro-services if there is requirement for lower latency code?,<java><microservices>,1,63,8,1.0,3,"<p>In a monolith, we just need to either make a function call or method invocation as opposed to inter process communication. Can someone familiar with micro-services architecture help to understand reasons how you can use micro services for developing low latency applications?</p>&#xA;&#xA;<p>I think Chronicle framework claims that you can develop micro-services based products and use chronicle queues to communicate without incurring network hop latency. </p>&#xA;"
42949138,Rails: Microservice architecture with dedicated authorization service and app services using Knock (JWT),<ruby-on-rails><ruby><jwt><microservices>,1,461,0,0.0,3,"<p>I'm now trying to separate monolithic application into microservices (dedicated rails app's) and wanted to know - is there a solution to move authorization service from each service?</p>&#xA;&#xA;<p>For example, I have 6 different Rails API services with 'knock' gem that have user model for authentication purpose.&#xA;All those services sharing one user database.</p>&#xA;&#xA;<p>I want to implement dedicated service with user model, but how other services will verify users with given tokens?</p>&#xA;&#xA;<p>Also I want to able to control what services user can and can't use. So there should be AccessRole service?</p>&#xA;&#xA;<p>Draft case:</p>&#xA;&#xA;<ol>&#xA;<li>User go to 'articles' (frontend UI client)</li>&#xA;<li>auth_service is validating token from client</li>&#xA;<li>access_service got message from auth_service somehow and validating user's role to access 'articles' resource.</li>&#xA;<li>articles_service send response to client with json data.</li>&#xA;</ol>&#xA;&#xA;<p>Here some more questions:</p>&#xA;&#xA;<ol>&#xA;<li>How access_service will communicate with auth_service? Should they use one user database to verify user's credentials and role?</li>&#xA;<li>articles_service and so on - should they become private services without access to public and act as black boxes to user?</li>&#xA;</ol>&#xA;"
46115104,Hazelcast cluster: serialization and replication issue,<java><microservices><hazelcast><distributed-cache><hazelcast-imap>,1,198,0,2.0,3,"<p>Our application consists of several micro services. Each microservice has a configuration for its own hazelcast instance. All hazelcast instances form a cluster with distributed data. Hazelcast replicated map is used as a way to replicate data objects (DTOs include several fields) between those micro services. Microservices are hosted on AWS.</p>&#xA;&#xA;<p>There was a problem with data object serialization that's why we created a separated project with custom serialization config. All data objects (java classes) we want to replicate are listed in this config code. Artifact built from this very configuration project is included in each micro service as a maven dependency. This helps to solve serialization problem.</p>&#xA;&#xA;<p>This solution led us to the new problem what appear if it's needed to add new data object. Firstly we should add this very data object to config project, then rebuild this project. After that, we should rebuild all micro services with updated dependency and redeploy. And if at least one of micro services wasn't rebuilt there will be a serialization error because of this very micro service hazelcast instance doesn't know how to serialize new data object. The process of rebuilding and redeploying all application isn't so convenient for us.</p>&#xA;&#xA;<p>Please, share your experience! Is there any way to make it easier? </p>&#xA;"
46069921,Is there a difference between API gateway pattern and BFF?,<microservices><netflix-zuul><api-gateway>,1,1333,1,1.0,3,<p>My understanding is that API gateway pattern is like a proxy to all microservices. So client calls the API gateway which takes care of further routing. BFF is a specific case of API gateway pattern where we have a routing mechanism for each type of client. Am I right?</p>&#xA;
49443206,Difference between OSGI and microservices,<osgi><microservices><osgi-bundle>,2,1173,1,0.0,3,<p>When would you like to choose for OSGI modules than micro services and is there anything i can do with micro services that i can not do with OSGI modules?</p>&#xA;
41008507,Is there an established pattern for paging in Service Fabric ReliableCollections,<azure><microservices><azure-service-fabric><service-fabric-stateful>,2,403,0,2.0,3,"<p>In reliable collections (specifically IReliableDictionary), an approach for implementing 'common' queries is to update a secondary dictionary which structures the keys to be ordered a specific way in an enumeration.  For large data sets, <strong>I would like to avoid shuttling a large amount of data around</strong>.  </p>&#xA;&#xA;<p>To achieve this I would like to <strong>implement some sort of continuation token</strong> which the caller can supply to me when requesting the data.  I am currently implementing this by first generating an ordered enumeration and returning the first n items where n = the MAX_PAGE size.   <strong>The continuation is essentially the last key in that list of n items</strong>. The next time the caller passes in the continuation token, <strong>I generate the ordered enumerable with the filter function specifying that the key should be greater than the continuation</strong>.  </p>&#xA;&#xA;<p>This has 2 problems (that I can see):</p>&#xA;&#xA;<ol>&#xA;<li>The <strong>collection could change between when the caller first requests a page and a subsequent request</strong>.  This, I'm not certain I can avoid since updates to the collection need to be able to occur at any time regardless of who is attempting to page through the data.</li>&#xA;<li>I'm not certain how the filter function is used. I would assume that since a developer could filter on anything, the <strong>GetEnumerableAsync() method must supply all keys in the dictionary before returning the enumerable</strong>.  For a sufficiently large data set, this seems slow.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Are there any prescribed approaches for paging data like this?</strong>  I am beginning to feel like I might be barking up the wrong tree with Reliable Collections for some of my use cases.  </p>&#xA;"
40932850,Mongodb IsoDate and the issue with if-modified-since on microservices,<java><mongodb><microservices>,1,170,2,1.0,3,"<p>When I insert a document on my MongoDB using spring data, I do the following:</p>&#xA;&#xA;<pre><code>Update update = new Update();&#xA;update.currentDate(""lastModified"");&#xA;mongoTemplate.upsert(query, update, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>I'm using the currentDate of MongoDB, because I want to save the date that MyDocument was last modified with the date where my MongoDB database is located. </p>&#xA;&#xA;<p>Based on the <a href=""https://www.ietf.org/rfc/rfc2616.txt"" rel=""nofollow noreferrer"">spec</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>The If-Modified-Since request-header field is used with a method to&#xA;     make it conditional: if the requested variant has not been modified&#xA;     since the time specified in this field, an entity will not be&#xA;     returned from the server; instead, a 304 (not modified) response will&#xA;     be returned without any message-body.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, the purpose of saving this date is to verify if MyDocument was modified or not based on the received date.</p>&#xA;&#xA;<p>So, when I execute the update, the following IsoDate is created on the database:</p>&#xA;&#xA;<pre><code>ISODate(""2016-12-02T12:11:33.083Z"")&#xA;</code></pre>&#xA;&#xA;<p>So, when a client wants to know if the document has changed, they send me back this date, and I query on the database:</p>&#xA;&#xA;<pre><code>    Query query = new Query(where(""id"").is(filter.getId()));&#xA;    Criteria criteria = Criteria.where(""lastModified"").gt(filter.getLastModified());&#xA;    query.addCriteria(criteria);&#xA;    return mongoTemplate.findOne(query, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>This works perfectly, except for one problem: The spec says that the header if-modified-since has the following format:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT</p>&#xA;</blockquote>&#xA;&#xA;<p>Which means that the milliseconds is not passed on the if-modified-since header. However, MongoDB IsoDate saves the current date with milliseconds. So, when two dates are exactly the same, the query will not return 304 Not Modified, but it will return the entire resource, because the query will be the following:</p>&#xA;&#xA;<pre><code>{ ""id"" : 123, ""lastModified"" : { ""$gt"" : { $java : 2016-12-02T12:11:39.000Z } } }&#xA;</code></pre>&#xA;&#xA;<p>Since the client does not send the milliseconds, the java put the milliseconds as zeros ( 2016-12-02T12:11:39.<strong>000</strong>Z), which means that &#xA;the date on my database is greater than the date sended by my client:</p>&#xA;&#xA;<p>2016-12-02T12:11:33.083Z > 2016-12-02T12:11:39.000Z </p>&#xA;&#xA;<p>Because of the 83 milliseconds. </p>&#xA;&#xA;<p><strong>The final question is</strong>: What it is the correct way to solve this problem, and work correctly as the specs for if-modified-since suggests?</p>&#xA;"
40890804,Register MicroServices in Azure Active Directory (AAD) for Security,<azure><asp.net-web-api><owin><azure-active-directory><microservices>,1,654,4,0.0,3,"<p>I have a service fabric application (Stateless and Statefull) deployed in Service fabric cluster. I am trying to implement security in the applications. The application uses the Active Directory Authentication Library (ADAL) to get a token from Azure AD using the OAuth 2.0 client credential flow, where the client credential is a password. I am able to implement the same scenario in ordinary web api applications by registering them in Azure portal. Can anyone tell me how to register a service fabric microservice application with WebApi exposed using Owin. i have difficulties registering the reply url and sign on url as the urls are dynamic(for statefull partitionid and replica id). I receive unauthorized access while calling the corresponding service. I am not sure of what url has to be registered for a statefull or stateless application when adding the application in in azure active directory. Could you please suggest me where I'm wrong and what to do to implement.</p>&#xA;"
47837207,Entity-level access restriction in the microservice architecture based on user or group membership,<security><design><architecture><permissions><microservices>,3,982,1,1.0,3,"<p>In the systems, there may be data that is restricted in nature. &#xA;Sometimes access to specific entities should be easily restricted or granted based on user or group membership. </p>&#xA;&#xA;<p>What is the best way to implement this in the microservice architecture?</p>&#xA;&#xA;<h2>#1</h2>&#xA;&#xA;<p>Should access control, managing permissions etc. be the responsibility of the microserive itself? Developers will have to implement access control, store, and update permissions for every service. Seems like not very robust and error-prone approach.</p>&#xA;&#xA;<h2>#2</h2>&#xA;&#xA;<p>Create dedicated microservice handling permission management? This service will be called by other microserives to check access permissions for each entity and filtering entities before returning results. Centralized permissions storage and management is an advantage but microservice will have to make a call to ""Permission Service"" for each entity to check access rights what may have a negative influence on performance. And developers still have to integrate access checks into their services what leaves space for an error.</p>&#xA;&#xA;<h2>#3</h2>&#xA;&#xA;<p>Make access control responsibility of the API Gateway or Service Mesh. It is possible to think of an implementation that will automatically filter responses of all services. But in the case when the microservice returns list of entities permissions should be checked for each entity. Still a potential performance problem.</p>&#xA;&#xA;<h2>Example</h2>&#xA;&#xA;<p>Consider the following synthetic example. &#xA;Healthcare system dealing with test results, X-Ray images etc. Health information is very sensitive and should not be disclosed.</p>&#xA;&#xA;<p>Test results should be available only to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>laboratory</li>&#xA;</ul>&#xA;&#xA;<p>Attending doctor may send the patient to another specialist. A new doctor should have access to test results too. So access can be granted dynamically.</p>&#xA;&#xA;<p>So each entity (e.g. test results, X-Ray image) has a set of rules what users and groups are allowed to access it.</p>&#xA;&#xA;<p>Imagine there is a microservice called ""Test Results Service"" dealing with test results. Should it be responsible for access control, manage permissions etc.? Or permissions management should be extracted to separate microservice?</p>&#xA;&#xA;<p>Healthcare system may also handle visits to a doctor. Information about patient's visit to the doctor should be available to:</p>&#xA;&#xA;<ul>&#xA;<li>patient</li>&#xA;<li>doctor</li>&#xA;<li>clinic receptionist</li>&#xA;</ul>&#xA;&#xA;<p>This is the example of a different entity type that requires entity level access restriction based on user or group membership.</p>&#xA;&#xA;<p>It is easy to imagine even more examples when entity level access control is required.</p>&#xA;"
49612709,Should each microservice manage its own user-permissions and user-roles?,<jwt><microservices>,2,215,3,0.0,3,"<p>I have a design issue I am not sure of how to solve.</p>&#xA;&#xA;<p>Let's say my main application consists of 6 modules:</p>&#xA;&#xA;<ul>&#xA;<li>client</li>&#xA;<li>gateway</li>&#xA;<li>auth-service</li>&#xA;<li>forum</li>&#xA;<li>gallery</li>&#xA;<li>messages</li>&#xA;</ul>&#xA;&#xA;<p>The client is supposed to communicate with the gateway-service only.</p>&#xA;&#xA;<p>Should I have my gateway do the user-authentication (which ideally results in a JWT) and the other 3 productive-services (forum, gallery, messages) just verify that token and retrieve permissions and roles <strong>they manage themselves</strong> for that given user?</p>&#xA;&#xA;<p>To perhaps illustrate my few troubles, I create a sequence diagram:&#xA;<a href=""https://i.stack.imgur.com/j82Fv.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j82Fv.jpg"" alt=""this image shows the sequence diagram, which I am having trouble with""></a></p>&#xA;&#xA;<p><a href=""https://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharinghttps://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharing"" rel=""nofollow noreferrer"" title=""link to Google Drive file"">Click here</a> for the original draw.io graphics if you prefer that.</p>&#xA;&#xA;<p>I do not want to use any 3rd-party auth-services; I just want my auth-service (which is pretty much done) to register users and let them login. Or should I be managing permissions and roles in that service as well?</p>&#xA;&#xA;<p>I tried to wrap my brain around this issue for months, but I simply cannot find a suitable structure so I can let the user register, login/logout and communicate with various productive services. I am currently using Java for the backend stuff, but the good thing about microservices is, that I do not have to use one programming language for them all.</p>&#xA;&#xA;<p>Any help here is welcome!</p>&#xA;&#xA;<p>P.s.: I read <a href=""https://stackoverflow.com/questions/29644916/microservice-authentication-strategy"">Microservice Authentication strategy</a> and <a href=""https://stackoverflow.com/questions/33921375/zuul-api-gateway-authentication"">Zuul - Api Gateway Authentication</a>, but both did not seem to apply in my case.</p>&#xA;"
47007159,Looking for JWT Auth microservice example,<node.js><authorization><jwt><microservices>,1,982,0,1.0,3,"<p>I am wanting to build a authentication/authorization service using NodeJS, Mongo, and JWT.  This service would be a micro-service that handles requests not only from my API Gateway before allowing requests, but from other services that might want to check auth and roles. I am assuming that all other services will use this Auth Service to validate the JWT as well as roles, etc.</p>&#xA;&#xA;<p>Hopefully this diagram better explains what I am looking for.&#xA;<a href=""https://i.stack.imgur.com/NDuCY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NDuCY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Can anyone point me to a resource that might help me learn how to do this with NodeJS?</p>&#xA;"
38254720,Migrate from monolith to Micro service architecture,<microservices>,2,115,1,0.0,3,<p>We are on the initial stages of designing a micro service for my client from their standard monolith app that is sitting on 4 JBOSS servers in their own data center. Is micro service architecture target at only cloud based deployment? Can i deploy a micro service on premise production ready tomcat /JBOSS? Is that a good fit?</p>&#xA;
47566892,Microservices : Embedded tomcat vs standalone tomcat : Difference,<java><tomcat><kubernetes><microservices><embedded-tomcat-8>,1,1205,0,0.0,3,"<p>Can embedded tomcat or any such embedded server be used for microservices in production environment? How, embedded server is different wrt the normal standalone full fledged server (performance . reliability wise)? Is the embedded server light weight compared to standalone? What are the features that embeded servers do not have compared to their standalone ones? Can we change the default security settings, tls ciphers etc advanced things in embedded tomcat?</p>&#xA;"
48279479,How to query in a Event Driven Microservice architecture?,<microservices><cqrs><event-driven>,3,308,0,1.0,3,"<p>Let suppose the following simple UC based on a CQRS architecture:</p>&#xA;&#xA;<p>We have a backend managing a Business Object, let says a Movie.</p>&#xA;&#xA;<ul>&#xA;<li>This backend is composed of 2 Microservices: a CommandManager (Create/Update/Delete Movie) and a QueryManager (Query Movie)</li>&#xA;<li>We have a frontend that offer a web page for creating a new Movie and this action lead automatically to another web page describing the Movie. </li>&#xA;</ul>&#xA;&#xA;<p>A simple way to do that is:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend make a POST request to the CommandManager</li>&#xA;<li>The CommandManager write the new movies to the datastore and return the movie key</li>&#xA;<li>The frontend make a GET using this key to the QueryManager</li>&#xA;<li>The QueryManager looks for the Movie in the Datastore using the key and return it.</li>&#xA;<li>The frontend deliver the page with the Movie Information.</li>&#xA;</ul>&#xA;&#xA;<p>Ok, now I want to transform this UC in a more Event Driven way. Here is the new flow:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend write a Message in the BUS with the new movie information</li>&#xA;<li>The CommandManager listen the BUS and create the new movies in the datastore. Eventually, it publish a new message in the BUS specifying that a new Movie has been created.</li>&#xA;</ul>&#xA;&#xA;<p>At this point, the frontend is no more waiting for a response due to the fact that this kind of flow is asynchronous. How could we complete this flow in order to forward the user to the Movie Information Web page? We should wait that the creation process is done before querying the QueryManager. </p>&#xA;&#xA;<p>In a more general term, in a asynchronous architecture based on bus/event, how to execute Query used to provide information in a web page?</p>&#xA;"
48271960,Event Sourcing and dealing with data dependencies,<apache-kafka><microservices><event-sourcing><distributed-system><distributed-transactions>,1,181,0,0.0,3,"<p>Given a REST API with the following operations resulting in events posted to Kafka:</p>&#xA;&#xA;<ul>&#xA;<li>AddCategory</li>&#xA;<li>UpdateCategory</li>&#xA;<li>RemoveCategory</li>&#xA;<li>AddItem (refers to a category by some identifier)</li>&#xA;<li>UpdateItem</li>&#xA;<li>RemoveItem</li>&#xA;</ul>&#xA;&#xA;<p>And an environment where multiple users may use the REST API at the same time, and the consumers must all get the same events. The consumers may be offline for an extended period of time (more than a day). New consumers may be added, and others removed.</p>&#xA;&#xA;<p>The problems:</p>&#xA;&#xA;<ul>&#xA;<li>Event ordering (only workaround single topic/partition?)&#xA;&#xA;<ol>&#xA;<li>AddItem before AddCategory, invalid category reference.</li>&#xA;<li>UpdateItem before AddCategory, used to be a valid reference, now invalid.</li>&#xA;<li>RemoveCategory before AddItem, category reference invalid.</li>&#xA;<li>....infinite list of other concurrency issues.</li>&#xA;</ol></li>&#xA;<li>Event Store snapshots for fast resync of restarted consumers&#xA;&#xA;<ol>&#xA;<li>Should there be a compacted log topic for both categories and items, each entity keyed by its identifier?</li>&#xA;<li>Can the whole compacted log topic be somehow identified as an offset?</li>&#xA;<li>Should there only be one one entry in the compacted log topic, and the data of it contain a serialized blob of all categories and items given an offset (would require single topic/partition).</li>&#xA;<li>How to deal with the handover from replaying the rendered entities event store to the ""live stream"" of commands/events? Encode offset in each item in the compacted log view, and pass that to replay from the live event log?</li>&#xA;</ol></li>&#xA;</ul>&#xA;&#xA;<p>Are there other systems that fit this problem better?</p>&#xA;"
48201224,Kafka AND REST for communication between microservices?,<rest><architecture><apache-kafka><message-queue><microservices>,1,429,2,1.0,3,"<p>I am currently working on an architecture see below. First I'm not sure if this kind of architecture is called an <em>event-driven</em> or a <em>data-driven</em> architecture or maybe both.</p>&#xA;&#xA;<p>There some input messages are sent from the <strong>Frontend</strong> to <strong>T1</strong>. These messages are first validated, then collected and in the end evaluated.</p>&#xA;&#xA;<p>My current approach is to persist the raw messages with all meta information in <strong>MS A</strong>, the sorted collections in <strong>MS B</strong> and the evaluations in <strong>MS C</strong>. This separates the data to the appropriately concerned microservices.  </p>&#xA;&#xA;<p>In <strong>T2</strong> I only produce the messages which <strong>MS B</strong> requires.<br>&#xA;In <strong>T3</strong> I only produce the messages which <strong>MS C</strong> requires.<br>&#xA;But when evaluation the collections all meta information from <strong>MS A</strong> is required. So how to proceed with this kind?</p>&#xA;&#xA;<ol>&#xA;<li>Should I send only the minimum of data to the queue and provide an API?</li>&#xA;<li>Should I send all data to the queues (forward data for following services)?</li>&#xA;<li>Should I send all information for the next service to the queue and provide an API?</li>&#xA;<li>Something else?</li>&#xA;</ol>&#xA;&#xA;<p>Or did I misunderstand the approach ""Communicating microservices through Kafka""?</p>&#xA;&#xA;<p>Please feel free to offer criticism!<br>&#xA;Thanks for advice!</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/BgT2M.png"" height=""500""/></p>&#xA;"
51542197,Async Flows Design in Lagom or Microservices,<domain-driven-design><microservices><lagom>,1,67,7,5.0,3,"<p>How to design asyn flows in Lagom ? </p>&#xA;&#xA;<p>Problem faced: In our product we have a Lead Aggregate which has a User Id (represents the owner of the lead), Now User has a limitation which says one user can have max of 10 Lead associated with this. We designed this by creating a separate Service ResourceManagement and when a User asks for Picking a Lead, we send a Command to LeadAggregate which generates a Event LeadPickRequested. On ProcessManager Listen to the event and asks for the Resource From ResourceManagement, on Success send Command to LeadAggregate - MarkAsPicked and on this send Push notification to the User that Lead is Picked but from building the UI perspective its very difficult and same cannot be done for exposing our API to third party. </p>&#xA;&#xA;<p>One Sol. we have done is when request is received on Service save a RequestID Vs Request Future . in Command Add the request Id and when the LeadAggregate finally change into Picked State or Picked Failure a PM listen to the event , checks if a RequestFuture is there for the request Id , then complete the future with correct response. This way it works as Sync API for the end User. </p>&#xA;&#xA;<p>Any Better Sol. for this</p>&#xA;"
45853546,"Two processes reside in different AP servers and refer to a same boolean flag. (Spring, Java)",<java><spring><microservices><consistency>,4,41,0,0.0,3,"<p>I am using Spring Framework to develop a web application. I have two services which are going to store some processed results into one table T in Database. The logic now is:</p>&#xA;&#xA;<p><strong>Service A</strong></p>&#xA;&#xA;<pre><code>for all items:&#xA;    result = func(item)&#xA;    store result to Table T (with status = new)&#xA;is_running = False&#xA;</code></pre>&#xA;&#xA;<p><strong>Service B</strong></p>&#xA;&#xA;<pre><code>for some items:&#xA;    if is_running == False:&#xA;        result = func(item)&#xA;        store result to Table T (with status = new)&#xA;    else:&#xA;        store result to Table T (with status = inprogress)&#xA;</code></pre>&#xA;&#xA;<p>The boolean flag <code>is_running</code> will be a field in Service A.</p>&#xA;&#xA;<p>Since we have MicroService Architechture for the domain server, Service A and Service B may reside in different AP servers. How can I ensure Servie A and Service B refer to the same <code>is_running</code>?</p>&#xA;&#xA;<p>Is it possible to use <a href=""https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html#beans-factory-scopes"" rel=""nofollow noreferrer"">Spring's bean scope</a> to achieve this?</p>&#xA;"
46002727,What is the difference between an API-Gateway and an Edge Service?,<microservices>,1,935,0,0.0,3,"<p>I understand the concept behind an API gateway as described by Richardson:</p>&#xA;&#xA;<p><a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a></p>&#xA;&#xA;<p>But what is the difference to an Edge service. Is this a concrete implementation of the API gateway pattern?</p>&#xA;"
48458627,How to filter and sort data from multiple microservices?,<architecture><microservices>,1,362,0,3.0,3,"<p>We have microservices which work with different, but related data. For example, ads and their stats. We want to be able to filter, sort and aggregate this related data for UI(and not only for it). For example, we want to show to a user ads which have 'car' in their text and which have more than 100 clicks.</p>&#xA;&#xA;<p><strong>Challenges:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There could be a lot of data. Some users have millions of rows after filtration</li>&#xA;<li>Services doesn't have all the data. For example, for statistics service ad without stats == non existent ad. It doesn't know anything about such ads. But sorting and filtration should work anyway(ad without stats should be considered as ad without zero clicks)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Requirements:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Eventual consistency within couple of seconds is OK</li>&#xA;<li>Data loss is not acceptable</li>&#xA;<li>5 to 10 seconds filtration and sorting for big clients with millions of rows is OK</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solutions we could think of:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Load all data required by query from all services and filter and sort it in memory.</li>&#xA;<li>Push updates from services to Elasticsearch(or something like this). Elastic handles query and returns ids of desired entities which then loaded from services.</li>&#xA;<li>One big database for all services which has everything</li>&#xA;</ul>&#xA;&#xA;<p>What should we pay attention to? Are there other ways to solve our problem?</p>&#xA;"
50989454,Python asyncio Protocol behaviour with multiple clients and infinite loop,<python-3.x><server><client-server><microservices><python-asyncio>,1,105,0,1.0,3,"<p>I'm having difficulty understanding the behaviour of my altered echo server, which attempts to take advantage of python 3's <code>asyncio</code> module.</p>&#xA;&#xA;<p>Essentially I have an infinite loop (lets say I want to stream some data from the server to the client indefinitely whilst the connection has been made) e.g. <code>MyServer.py</code>:</p>&#xA;&#xA;<pre class=""lang-py prettyprint-override""><code>#! /usr/bin/python3&#xA;import asyncio&#xA;import os&#xA;import time&#xA;&#xA;class MyProtocol(asyncio.Protocol):&#xA;&#xA;    def connection_made(self, transport):&#xA;        peername = transport.get_extra_info('peername')&#xA;        print('Connection from {}'.format(peername))&#xA;        self.transport = transport&#xA;&#xA;    def connection_lost(self, exc):&#xA;        asyncio.get_event_loop().stop()&#xA;&#xA;    def data_received(self, data):&#xA;        i = 0&#xA;        while True:&#xA;            self.transport.write(b'&gt;&gt; %i' %i)&#xA;            time.sleep(2)&#xA;            i+=1&#xA;&#xA;loop = asyncio.get_event_loop()&#xA;coro = loop.create_server(MyProtocol, &#xA;    os.environ.get('MY_SERVICE_ADDRESS', 'localhost'), &#xA;    os.environ.get('MY_SERVICE_PORT', 8100))&#xA;server = loop.run_until_complete(coro)&#xA;&#xA;try:&#xA;    loop.run_forever()&#xA;except:&#xA;    loop.run_until_complete(server.wait_closed())&#xA;finally:&#xA;    loop.close()&#xA;</code></pre>&#xA;&#xA;<p>Next when I connect with <code>nc ::1 8100</code> and send some text (e.g. ""testing"") I get the following:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;*** Connection from('::1', 58503, 0, 0) ***&#xA;testing&#xA;&gt;&gt; 1&#xA;&gt;&gt; 2&#xA;&gt;&gt; 3&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Now when I attempt to connect using <code>nc</code> again, I do not get any welcome message and after I attempt to send some new text to the server I get an endless stream of the following error:</p>&#xA;&#xA;<pre class=""lang-sh prettyprint-override""><code>user@machine$ nc ::1 8100&#xA;Is there anybody out there?&#xA;socket.send() raised exception&#xA;socket.send() raised exception&#xA;...&#xA;^C&#xA;</code></pre>&#xA;&#xA;<p>Just to add salt to the wound the <code>socket.send() raised exception</code> message continues to spam my terminal until I kill the python server process...</p>&#xA;&#xA;<p>As I'm new to web technologies (been a desktop dinosaur for far too long!), I'm not sure why I am getting the above behaviour and I haven't got a clue on how to produce the intended behaviour, which loosely looks like this:</p>&#xA;&#xA;<ol>&#xA;<li>server starts</li>&#xA;<li>client 1 connects to server</li>&#xA;<li>server sends welcome message to client&#xA;4  client 1 sends an arbitrary message</li>&#xA;<li>server sends messages back to client 1 for as long as the client is connected</li>&#xA;<li>client 1 disconnects (lets say the cable is pulled out)</li>&#xA;<li>client 2 connects to server</li>&#xA;<li>Repeat steps 3-6 for client 2</li>&#xA;</ol>&#xA;&#xA;<p>Any enlightenment would be extremely welcome!</p>&#xA;"
50312750,How can I keep databases of two web applications in sync?,<java><sql-server><microservices><database-trigger>,2,65,0,0.0,3,"<p>I have two webapps, each with its own backend microservice and each microservice has its own database. For any changes in tables of database of microservice1, I want to change(create/update) entries in tables of database of microservice 2. How can I do that? </p>&#xA;&#xA;<h1>Context:</h1>&#xA;&#xA;<p><strong>Webapp 1:</strong> UI for human resource coordinators to schedule an interview. </p>&#xA;&#xA;<p><strong>Microservice 1:</strong> Backend service that schedules an interview.</p>&#xA;&#xA;<p><strong>DB for microservice 1:</strong> Stores information related to interview of a candidate. </p>&#xA;&#xA;<pre><code>  interviews: [ {&#xA;      ""interviewId"": ""1"",&#xA;      ""candidateId"": ""abc"",&#xA;      ""interviewers"": [&#xA;      {&#xA;         ""interviewer_name"": ""Thor"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      },&#xA;      {&#xA;         ""interviewer_name"": ""Loki"",&#xA;         ""schedule"": {&#xA;            ""startTime"": """",&#xA;            ""endTime"": """",&#xA;            ""roomNumber"": 101&#xA;         }&#xA;      }&#xA;   ]&#xA;} ]&#xA;</code></pre>&#xA;&#xA;<p><strong>Webapp 2:</strong> UI for interviewers to coordinate on questions to ask in an interview. </p>&#xA;&#xA;<p><strong>Microservice 2:</strong> Backend service for interviewers to coordinate on question selection. i.e. each interviewer selects what question he/she is going to ask from a candidate in an interview (this is to ensure no two interviewers end up asking same question from a candidate).</p>&#xA;&#xA;<p><strong>DB for microservice 2:</strong> Schemas</p>&#xA;&#xA;<p>// QuestionBank : Table containing questions, that interviewers can select.</p>&#xA;&#xA;<p>// Interviewers : Table containing all interviewers in the firm.</p>&#xA;&#xA;<p>// InterviewToInterviewer : (many to many mapping of interviews with interviewers). One interview can have many interviewers, and each interviewer can participate in many interviews.</p>&#xA;&#xA;<p>// InterviewToInterviewerToQuestion :  (many to many mapping of interviewToInterviewers with questions). For each interview an Interviewer can select many questions and each of the question in a questionbank can be a part of many interviewToInterviewer entry.</p>&#xA;&#xA;<h1>Current Workflow:</h1>&#xA;&#xA;<p>As soon as interview is scheduled from webapp1:</p>&#xA;&#xA;<ol>&#xA;<li>An email is sent to all the interviewers. Email contains a link to a webapp 2, clicking on this link opens webapp2 that provides an interface for interviewers to select questions they plan to ask in an interview.</li>&#xA;</ol>&#xA;&#xA;<h1>Requirement:</h1>&#xA;&#xA;<ol>&#xA;<li><p>If the questions are not selected by interviewer, then I want to send reminders to them. For this I want webapp2 to know that an interview is scheduled. </p></li>&#xA;<li><p>I want webapp2 to know about any lineup changes (in a given interview, interviewer is changed or an interview is cancelled etc) that happens. </p></li>&#xA;</ol>&#xA;&#xA;<h1>Solutions I thought off:</h1>&#xA;&#xA;<ol>&#xA;<li><p>As soon as interview is scheduled/changed from webapp1, webapp1 will calls webapp2 (webapp2 exposes an API for that) to let webapp2 know that a new interview is created or an existing interview is updated. </p></li>&#xA;<li><p>For any new entry/update in interview table in DB1, a DB trigger is launched to DB2. I am not sure whether this is possible also. </p></li>&#xA;</ol>&#xA;&#xA;<p>Out of the two approaches above can someone help me with the pros and cons of one choosing over other. Or there is some other alternative approach to achieve this.</p>&#xA;&#xA;<p>Leads here are appreciated. </p>&#xA;"
50435696,Django admin + authentication system in microservice architecture,<django><django-rest-framework><django-admin><microservices><django-apps>,1,165,0,1.0,3,"<p>I have a <strong>large</strong> Django project which is basically a monolith containing apps.&#xA;I need to break it to microservices.</p>&#xA;&#xA;<p>I have 2 questions that I couldn't find a clear answers to:</p>&#xA;&#xA;<ol>&#xA;<li><p>Currently we're using Django admin extensively and I wonder if it's&#xA;possible to continue using it once the monolith is broken. It means&#xA;reading and manipulating data from all the microservices in a ""used&#xA;to work on"" UI. It would also be helpful for this process to be done more smoothly.</p></li>&#xA;<li><p>Authentication and authorization - Would we still be able to use&#xA;this built in ""app"" in a microservice architecture? Is it possible&#xA;to take this pare only to another service and communicate with it&#xA;over HTTP?</p></li>&#xA;</ol>&#xA;"
40702179,micro service web app with AWS,<amazon-web-services><amazon-s3><amazon-ec2><microservices>,1,601,0,2.0,3,"<p>I am developing a web application for image upload and retrieval with AWS cloud services using a micro service architecture.&#xA;I am new to AWS and micro service architecture, please help me map the components of the architecture to AWS components.</p>&#xA;&#xA;<p>Do i consider each micro service to run on one EC2 instance with auto scaling and load balancing?&#xA;Or do I run each micro service on one EC2 cluster?</p>&#xA;&#xA;<p>If i put my static html files in an S3, how can i call database methods to load the html pages with content? &#xA;Is it by calling am API gateway from the client?</p>&#xA;&#xA;<p>I have searched the web, but was unable to find a tutorial which implements multiple services as micro services using AWS EC2 / ECS.</p>&#xA;&#xA;<p>Please help me figure out how to map my requirements and if there are any tutorials on implementing a similar app, will be very helpful.</p>&#xA;&#xA;<p>Thank you in advance! :)</p>&#xA;"
40760397,java.lang.ClassNotFoundException on Maven dependencies,<java><spring><maven><spring-boot><microservices>,1,542,4,3.0,3,"<p>We have a set of Spring Boot applications organized as microservices running successfully for a few months. We used Sprig Boot 1.3.3.</p>&#xA;&#xA;<p>Now we have a problem with maven build process switching to Spring Boot 1.4.2. We are developing microservice based software architecture. We have <strong>core.common</strong> service which is referenced by other services using dependecies like this:</p>&#xA;&#xA;<pre><code>&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;com.group&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;core.common&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&#xA;        &lt;scope&gt;compile&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt; &#xA;</code></pre>&#xA;&#xA;<p>This service is responsible for providing common classes and methods needed to each of other services. </p>&#xA;&#xA;<p>We also use separate service (<strong>root.service</strong>) to build <strong>all other services</strong> and to package them into <code>jar</code> files. This is the part of <code>pom.xml</code> from that <strong>root.service</strong>:</p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.2.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;modules&gt;&#xA;        &lt;module&gt;../core.adminservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.locationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.reportservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.userservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.notificationservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.trackingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.mappingservice&lt;/module&gt;&#xA;        &lt;module&gt;../core.common&lt;/module&gt;&#xA;    &lt;/modules&gt;&#xA;</code></pre>&#xA;&#xA;<p>Until switched to Spring Boot 1.4.2 version we were able to do <code>mvn clean install</code> over <strong>root.service</strong> to test and build the rest of the services from <strong>modules</strong> specification. </p>&#xA;&#xA;<p>After switching to Spring Boot 1.4.2 version, when I try to execute <code>mvn clean install</code> in <strong>root.service</strong> I am getting <code>java.lang.ClassNotFoundException</code>. Exception message says that none of the services form <strong>modules</strong> specification cannot find any of classes from <strong>core.common</strong> service used in particular service from <strong>modules</strong>.&#xA;When I try to run <code>mvn compile</code> or <code>mvn test</code> everything runs just fine and I get successful builds and tests. When I try to run services from <strong>eclipse</strong> also everything is just fine.</p>&#xA;&#xA;<p>Do you have any ideas? Please help.</p>&#xA;&#xA;<p><strong>EDIT</strong>&#xA;Full stack trace for one use case:</p>&#xA;&#xA;<pre><code>Running com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.002 sec &lt;&lt;&lt; FAILURE! - in com.blockpeek.core.adminservice.tests.services.AdminServiceTest&#xA;initializationError(com.blockpeek.core.adminservice.tests.services.AdminServiceTest)  Time elapsed: 0.002 sec  &lt;&lt;&lt; ERROR!&#xA;java.lang.NoClassDefFoundError: com/blockpeek/core/common/services/AbstractCRUDService&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;Caused by: java.lang.ClassNotFoundException: com.blockpeek.core.common.services.AbstractCRUDService&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.ClassLoader.defineClass1(Native Method)&#xA;    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#xA;    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#xA;    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#xA;    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#xA;    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#xA;    at java.security.AccessController.doPrivileged(Native Method)&#xA;    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#xA;    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#xA;    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#xA;    at java.lang.Class.getDeclaredFields0(Native Method)&#xA;    at java.lang.Class.privateGetDeclaredFields(Class.java:2583)&#xA;    at java.lang.Class.getDeclaredFields(Class.java:1916)&#xA;    at org.junit.runners.model.TestClass.getSortedDeclaredFields(TestClass.java:77)&#xA;    at org.junit.runners.model.TestClass.scanAnnotatedMembers(TestClass.java:70)&#xA;    at org.junit.runners.model.TestClass.&lt;init&gt;(TestClass.java:57)&#xA;    at org.junit.runners.ParentRunner.createTestClass(ParentRunner.java:88)&#xA;    at org.junit.runners.ParentRunner.&lt;init&gt;(ParentRunner.java:83)&#xA;    at org.junit.runners.BlockJUnit4ClassRunner.&lt;init&gt;(BlockJUnit4ClassRunner.java:65)&#xA;    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.&lt;init&gt;(SpringJUnit4ClassRunner.java:138)&#xA;    at org.springframework.test.context.junit4.SpringRunner.&lt;init&gt;(SpringRunner.java:49)&#xA;    at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)&#xA;    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#xA;    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)&#xA;    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)&#xA;    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)&#xA;    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&#xA;    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)&#xA;    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&#xA;</code></pre>&#xA;&#xA;<p>Maven Version:</p>&#xA;&#xA;<pre><code>$ mvn -version&#xA;Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T17:41:47+01:00)&#xA;Maven home: C:\Program Files\apache-maven-3.3.9&#xA;Java version: 1.8.0_101, vendor: Oracle Corporation&#xA;Java home: C:\Program Files\Java\jdk1.8.0_101\jre&#xA;Default locale: en_US, platform encoding: Cp1252&#xA;OS name: ""windows 10"", version: ""10.0"", arch: ""amd64"", family: ""dos""&#xA;</code></pre>&#xA;&#xA;<p><strong>EDIT 2:</strong> This is what I get if i run <code>mvn -e clean install</code>:</p>&#xA;&#xA;<pre><code>[ERROR] -&gt; [Help 1]                                                                                                                             &#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:compile (def&#xA;ult-compile) on project core.adminservice: Compilation failure                                                                                  &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)                                                      &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)                                                      &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)                             &#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)                              &#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)                &#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)                                              &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)                                                                       &#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)                                                                       &#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)                                                                         &#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)                                                                             &#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)                                                                              &#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)                                                                                &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                          &#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                        &#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                &#xA;        at java.lang.reflect.Method.invoke(Method.java:498)                                                                                     &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)                                                  &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)                                                          &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)                                                &#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)                                                            &#xA;Caused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure                                                    &#xA;        at org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:1029)                                        &#xA;        at org.apache.maven.plugin.compiler.CompilerMojo.execute(CompilerMojo.java:137)                                                         &#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)                                    &#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)                                                      &#xA;        ... 20 more                                                                                                                             &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.                                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:                                       &#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException                                                          &#xA;[ERROR]                                                                                                                                         &#xA;[ERROR] After correcting the problems, you can resume the build with the command                                                                &#xA;[ERROR]   mvn &lt;goals&gt; -rf :core.adminservice  &#xA;</code></pre>&#xA;"
43814764,Testing microservices?,<testing><go><integration-testing><microservices>,3,437,1,0.0,3,<p>I know this question is a little subjective but I am lost on what to do here. At the moment I am using Go + Go-kit to write some microservices. I'd like to test the endpoints of these microservices in an integration test type fashion but I am unsure how to go about it. The only thing I can think of is to have shell scripts that hit the endpoints and check for responses. But this seems like kludge and not a real smart practice. I feel like there should be a better way to do this. Does anyone have any suggestions?</p>&#xA;
43384538,Database location in Microservices Architecture,<azure><docker><microservices>,3,361,4,0.0,3,"<p>We have a monolithic application which we are now converting to microservice architecture using containers. </p>&#xA;&#xA;<p>Our microservices are <em>stateful</em> (i.e they need to insert/retrieve data from db). As per microservice architecture, each microservice should have its own data (i.e database in our case).</p>&#xA;&#xA;<p>My question is that <strong>where</strong> the database of each microservice should be deployed, whether it should be in the same host in which the microservice is deployed, in the same container in which the microservice is deployed or it should be in the separate server like azure db or something?</p>&#xA;&#xA;<p>What would be the pros &amp; cons of each approach and what is the best approach according to microservice best practices?&#xA;*</p>&#xA;"
43396744,Microservices UI Frontend with Java and ReactJS Server Side Rendering,<java><reactjs><microservices><serverside-rendering>,2,3077,9,3.0,3,"<p>My current design is to have clients connect to my (Java) Web API Gateway using a browser, the Web API Gateway will call each (Java) microservice to get their JSON data and return it to the UI component that made the request on the client. </p>&#xA;&#xA;<p>The only client side rendering will be from each ReactJS UI component for recurring requests to the gateway. </p>&#xA;&#xA;<p>On the server side the full HTML view will be rendered prior to being sent back to the client. </p>&#xA;&#xA;<pre><code>Client browser&#xA;&#xA;     ▼ (Request Dashboard View)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Request microservice JSON data)&#xA;&#xA;Microservice A JSON Data&#xA;Microservice B JSON Data&#xA;Microservice C JSON Data&#xA;Microservice D JSON Data&#xA;&#xA;     ▼ (Return JSON Data to gateway)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Render HTML and return to Client)&#xA;&#xA;Client browser&#xA;&#xA;     ▼ (ReactJS UI Components request data from API Gateway)&#xA;</code></pre>&#xA;&#xA;<p>This is where it gets unclear, would it be best to have each UI component communicate with the Web API Gateway or the parent Microservice it came from to get data? </p>&#xA;&#xA;<p>Considerations</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components talk to the Web API Gateway seems reasonable but will couple the microservices to the gateway, meaning to expose a new API on the microservice the gateway will also need to be updated. </li>&#xA;<li>Having the UI components talk directly to its Microservice for data removes the need to also update the Web API Gateway, keeping them less coupled. But this then exposes the Microservice to external calls from the client browser. </li>&#xA;</ul>&#xA;&#xA;<p>Design Decisions</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components within the API gateways creates a UI monolith as opposed to having each microservice responsible for its own UI component. Using the monolithic approach simplifies the solution and also avoids the complexities of having to aggregate each microservices UI component when the client requests a particular view. </li>&#xA;</ul>&#xA;&#xA;<p>Tools:</p>&#xA;&#xA;<ul>&#xA;<li>Java</li>&#xA;<li>Nashorn</li>&#xA;<li>Dropwizard </li>&#xA;<li>ReactJS</li>&#xA;<li>Gradle</li>&#xA;<li>Webpack</li>&#xA;<li>NodeJS</li>&#xA;<li>NPM </li>&#xA;</ul>&#xA;&#xA;<p><strong>How do I aggregate multiple microservice ui components on the Web API Gateway using Java and ReactJS then serve this pre-rendered HTML data along with the JavaScript application to the client?</strong></p>&#xA;&#xA;<p><strong>Helpful References:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Server side rendering with Java 8 and Nashhorn <a href=""http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/"" rel=""nofollow noreferrer"">http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/</a></li>&#xA;</ul>&#xA;"
42562820,DDD. Shared kernel? Or pure event-driven microservices?,<domain-driven-design><microservices><bounded-contexts>,3,1670,1,1.0,3,"<p>I'm breaking my system into (at least) two bounded-contexts: study-design and survey-planning.</p>&#xA;&#xA;<p>There's a concept named ""subject"" (potential subject for interviewing) in the study-design context. We also maintain associations between subjects and populations in that domain.</p>&#xA;&#xA;<p>Now, in the survey-planning, we also need (some) information about the subject (for example: for planning a visit, or even for anticipated selection of questionnaire, in case the population the subject belongs to is known beforehand).</p>&#xA;&#xA;<p>So, I need that ""subject"" in both contexts. </p>&#xA;&#xA;<p>What approach should I pick? Having a shared kernel, as explained in Eric Evans DDD book? I don't mind (at least for now) having the two contexts sharing the same database.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FKtJ9.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FKtJ9.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Or... should I go pure microservice? Meaning: those two can't / shouldn't share database..., and in that case I might have to go the mirroring / duplicating route through event passing: <a href=""https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts"" rel=""nofollow noreferrer"">https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts</a></p>&#xA;&#xA;<p>Any thoughts on which one is better, for the above situation?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
42404800,How to build front end for Microservices,<user-interface><architecture><microservices>,1,477,1,0.0,3,"<p>Let's say I have a dozen microservices. I am wondering where should the front end go. Let's say front end is HTML, Javascript, CSS. One way is to make it a separate service handled by a UI team. So it can form the API gateway where the request from browser comes in first. But this seems against the idea of independent self contained services.<br>&#xA;browser ------> API Gateway ------> Microservices&#xA;<br>&#xA;In <a href=""https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/"" rel=""nofollow noreferrer"">this</a> link, they say that Javascript and CSS should be served by microservices. API gateway should serve only the HTML page. THere is a nice diagram showing this >>&#xA;<a href=""https://i.stack.imgur.com/1suda.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1suda.png"" alt=""microservices with UI""></a>&#xA;I have two questions<br>&#xA;1. How will this be implemented? How will API gateway serve the JS and CSS files in microservices, and maybe HTML fragments too. How will initial page load happen and from where.<br>&#xA;2. Now we are mingling HTML into microservices. But what if I want to serve Android and iOS apps too? THanks.</p>&#xA;"
45688730,Decompose microservices: Business capability vs Domain,<domain-driven-design><microservices><software-design>,1,1010,2,3.0,3,"<p>As I read, there are two patterns to define one microservice, by <a href=""http://microservices.io/patterns/decomposition/decompose-by-business-capability.html"" rel=""nofollow noreferrer"">business capability</a> and by <a href=""http://microservices.io/patterns/decomposition/decompose-by-subdomain.html"" rel=""nofollow noreferrer"">subdomain</a>. But I still find it very ambiguous. I get confused how these two patterns differentiate from each other. Both of them revolve around activities involving an area of business logic. All of components in each service are small enough to get packaged with each other without affecting other services. Could anyone please give me a further explanation about these two?</p>&#xA;"
29071226,What is a good practice to promote a microservice to a public API?,<design><architecture><microservices>,3,996,0,3.0,4,"<p>Microservices seem to be a very good fit for my software after watching and reading number of articles from Martin Fowler, Sam Newman, Adrian Cockcroft and Sudhir Tones. However, when thinking deeper into the implementation, there are number of concerns:</p>&#xA;&#xA;<ol>&#xA;<li>My software has an UI, let's call it a web-based component. This component will need to coordinate/orchestrate calls to 10-20 different microservices internally (let's call it ""private microservices"") and return data to the AJAX call. Is it a good design to couple the orchestration logic in this component? Or should I create another microservice that does the job and the web-based component should be very thin to delegate the call to this microservice?</li>&#xA;<li>I will need to expose some public APIs. Should I have a separate layer to delegate the call like in the case above? </li>&#xA;</ol>&#xA;&#xA;<p>I think it might be more or less about the design pattern for public/private microservices. </p>&#xA;&#xA;<p>What would be a good pattern to address the above concerns?</p>&#xA;&#xA;<p><strong>Updated on 9 Apr 2015</strong>:</p>&#xA;&#xA;<p>API Gateway Pattern actually addresses my concerns. I also agree with other answers regarding EAI patterns or security consideration.</p>&#xA;&#xA;<p>To extend more regarding my findings, I think Netflix architecture is having, so-called ""edge service"", which is the front tier that is serving requests coming from either web-based or devices and the middle-tier services are actually your microservices. So i think to promote a middle-tier service to be an edge-service, this has to be a delegate. It will keep the middle-tier clean and consistent. </p>&#xA;&#xA;<p>Have a look at <a href=""https://github.com/cfregly/fluxcapacitor#project-overview"" rel=""nofollow"">https://github.com/cfregly/fluxcapacitor#project-overview</a> to have more ideas.</p>&#xA;"
31717615,Databases in a microservices pattern/architecture,<web-services><rest><design-patterns><microservices>,2,453,0,3.0,4,"<p>I'm trying to understand the layout of the microservices pattern. Given that each microservice would run on its on VM (for sake of example) how does the database fit into this architecture? </p>&#xA;&#xA;<p>Would each service, in turn, connect to the consolidated database to read/write data? </p>&#xA;&#xA;<p>Thanks for any insight</p>&#xA;"
33118913,Authentication and Authorization in Microservices,<authentication><oauth-2.0><authorization><microservices>,1,608,0,1.0,4,"<p>I've been reading a fair bit on Microservices recently, and especially around AuthN and AuthZ. For the most part, this all makes a lot of sense, and I can see how it all should work.</p>&#xA;&#xA;<p>For what I'm playing with, I going with delegated authorization - so I'm to be passing tokens around from client to service, and then passing the same token on from service to service. I also have an endpoint on the OAuth2 Service that will accept a token and return the details of the token - the User ID, the Start and End of the validity period, the scopes that the token is valid for, etc.</p>&#xA;&#xA;<p>The problem that I'm running into here is - in order to correctly issue a token, there needs to be some communication with the User Service to ensure that the User that the token is for is actually valid. And in order to verify a Token, there needs to be some communication with the User Service to ensure that the User is still valid. And yet, in order to safely communicate with the User Service to get details about a User, a Token is needed that gives permission for this access.</p>&#xA;&#xA;<p>I assume there is some standard practice on how to solve this circular dependency between the OAuth2 and User Service, but I've not seen any mention of it at all. Is this a common problem? Or have I just missed something obvious?</p>&#xA;&#xA;<p>(Note - for now I'm only implementing Client Credentials Grant and Resource Owner Password Credentials Grant, since I'm only playing around to see how it all works and they're easier to call with cURL. I don't know that this makes any difference though)</p>&#xA;"
26529567,What are the strategies available for doing pagination or filtering data using microservices architecture?,<filter><pagination><filtering><paging><microservices>,1,743,0,1.0,4,<p>Usually when you have a monolithic application or data model then you can create a SQL joining different tables and apply filters to them. Then once you get resultset back you can page that data as well. But if you are using microservice architecture the data model might be disparate. I heard netflix actually takes it to an extreme where they have every table  exposed as a microservice. How can you handle paging and filtering in this case?</p>&#xA;&#xA;<p>I know they use API Gateway pattern which  could act as aggregation layer (probably this is where RxJava like projects come in). It would be great to have ideas from people using microservices or tackle this problem.</p>&#xA;
30288968,Micro Services and noSQL - Best practice to enrich data in micro service architecture,<microservices>,4,2100,0,5.0,4,"<p>I want to plan a solution that manages enriched data in my architecture.<br>&#xA;To be more clear, I have dozens of micro services.<br>&#xA;let's say - Country, Building, Floor, Worker.<br>&#xA;All running over a separate NoSql data store.  </p>&#xA;&#xA;<p>When I get the data from the worker service I want to present also the floor name (the worker is working on), the building name and country name.</p>&#xA;&#xA;<p><strong>Solution1.</strong><br>&#xA;Client will query all microservices.<br>&#xA;Problem - multiple requests and making the client be aware of the structure.<br>&#xA;I know multiple requests shouldn't bother me but I believe that returning a json describing the entity in one single call is better.</p>&#xA;&#xA;<p><strong>Solution 2.</strong><br>&#xA;Create an orchestration that retrieves the data from multiple services.<br>&#xA;Problem - if the data (entity names, for example) is not stored in the same document in the DB it is very hard to sort and filter by these fields.</p>&#xA;&#xA;<p><strong>Solution 3.</strong><br>&#xA;Before saving the entity, e.g. worker, call all the other services and fill the relative data (Building Name, Country name).<br>&#xA;Problem - when the building name is changed, it doesn't reflect in the worker service. </p>&#xA;&#xA;<p><strong>solution 4.</strong><br>&#xA;(This is the best one I can come up with).<br>&#xA;Create a process that subscribes to a broker and receives all entities change.<br>&#xA;For each entity it updates all the relavent entities.<br>&#xA;When an entity changes, let's say building name changes, it updates all the documents that hold the building name.<br>&#xA;Problem:&#xA;Each service has to know what can be updated.&#xA;When a trailing update happens it shouldnt update the broker again (recursive update),  so this can complicate to the microservices.</p>&#xA;&#xA;<p><strong>solution 5.</strong><br>&#xA;Keeping everything normalized. Fileter and sort in ElasticSearch.&#xA;Problem: keeping normalized data in ES is too expensive performance-wise</p>&#xA;"
30267737,Microservice Database shared with other services,<mysql><web-services><deployment><microservices>,1,1114,3,1.0,4,"<p>Something I have searched for but cannot find a straight answer to is this:</p>&#xA;&#xA;<p>For a given service, if there are two instances of that service deployed to two machines, do they share the same persistent store or do they have separate stores with some syncing mechanism (master/slave, clustering)?</p>&#xA;&#xA;<p>E.g. I have a OrderService backed by MySQL. We're getting many orders in so I need to scale this service up, so we deploy a second OrderService. Where does its data come from?</p>&#xA;&#xA;<p>It may sound silly but, to me, every discussion makes it seem like the service and database are a packaged unit that are deployed together. But few discussions mention what happens when you deploy a second service.</p>&#xA;"
36571963,Python Development in multiple repositories,<python><git><pip><setuptools><microservices>,2,594,4,0.0,4,"<p>We are trying to find the best way to approach that problem.&#xA;Say I work in a Python environment, with pip &amp; setuptools.&#xA;I work in a normal git flow, or so I hope.&#xA;So:</p>&#xA;&#xA;<ol>&#xA;<li>Move to feature branch in some app, make changes.</li>&#xA;<li>Move to feature branch in a dependent lib - Develop thing. </li>&#xA;<li>Point the app, using ""-e git+ssh"" to the feature branch of the dependent lib.</li>&#xA;<li>Create a Pull Request.</li>&#xA;</ol>&#xA;&#xA;<p>When this is all done, I want to merge stuff to master, but I can't without making yet another final change to have the app (step 3 above) requirements.txt now point to the main branch of the feature.</p>&#xA;&#xA;<p>Is there any good workflow for ""micro services"" or multiple dependent source codes in python that we are missing?</p>&#xA;"
35361819,how to scale microservice (service fabric) instance when queue length increass,<azure><scale><microservices><azure-service-fabric>,2,1690,0,0.0,4,"<p><a href=""https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/"" rel=""nofollow"">https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/</a></p>&#xA;&#xA;<p>But how can I scale up my microservice when queue length increases. have any inbuild way in azure service fabric ?</p>&#xA;"
41445442,How to sync the database with the microservices (and the new one)?,<mysql><database><message-queue><microservices><nsq>,1,888,12,0.0,4,"<p>I'm developing a website with the microservice architecture, and each of the service owns a database. The database stores the data which the microservice needs.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><code>Post</code>, <code>Video</code> services need the user information, so both of the services subscribed to the <code>NEW_USER_EVENT</code>. </p>&#xA;&#xA;<p>The <code>NEW_USER_EVENT</code> will be triggered when there's a new user registered.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0SY8a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0SY8a.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Once the services received the <code>NEW_USER_EVENT</code>, they put the incoming user information to each of their own database. So they can do things without asking the <code>User</code> service.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NR8Xk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NR8Xk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>So far so good. But here comes the question:</p>&#xA;&#xA;<ul>&#xA;<li>What if I'm going to create a new service? How do I get the registered user informations and put them in the new service?</li>&#xA;</ul>&#xA;&#xA;<p>Maybe I can get the informations from the existing services. But the events are pushed by the messaging queue (<code>NSQ</code>). </p>&#xA;&#xA;<p>If I'm going to copy the data from one of the microservices, how do I make sure which service has the latest user informations? (<em>Because some services haven't received the latest event</em>) </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/vJoGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vJoGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><em>Read More:</em></p>&#xA;&#xA;<p><a href=""http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/"" rel=""nofollow noreferrer"">The Hardest Part About Microservices: Your Data</a></p>&#xA;&#xA;<p><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""nofollow noreferrer"">Intro to Microservices, Part 4: Dependencies and Data Sharing</a></p>&#xA;"
40457443,azure service fabric reliable dictionary linq query very slow,<c#><performance><linq-to-entities><microservices><azure-service-fabric>,1,1465,7,1.0,4,"<p>I have a reliable dictionary in service fabric stateful service. I have a simple linq expression.<br>&#xA;I am using Ix-Async package for building an asyncenumerable.  </p>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>using (ITransaction tx = this.StateManager.CreateTransaction())  &#xA;        {  &#xA;&#xA;          var result = (await customers.CreateLinqAsyncEnumerable(tx))&#xA;                .Where(x =&gt; x.Value.NameFirst != null &amp;&amp; x.Value.NameFirst.EndsWith(n, StringComparison.InvariantCultureIgnoreCase))&#xA;                    .Select(y =&gt; y.Value);&#xA;&#xA;           return await result.ToList();&#xA;&#xA;&#xA;        }  &#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The data is organized into 2 partitions with around 75,000 records in each partition. I am using Int64 range as the partition key. In the above code, the ""Result.ToList()"" takes around 1 minute to execute for each partition. Another weired thing is, the actual result is empty!. The same sql run in sql server returns rows with customer first names ending with ""c"". But, this is besides the point. My biggest concern is performance of ""ReliableDictionary"" linq query.<br>&#xA;Regards</p>&#xA;"
31206417,SOA by microservices - how to normalize/transform messages,<architecture><soa><transformation><microservices>,3,555,0,1.0,4,"<p>We are developing solution which adapts Messages Pattern and Microservices to define and run business flows.</p>&#xA;&#xA;<p>It should have such components:</p>&#xA;&#xA;<ul>&#xA;<li>Gateways to initiate transaction, with given flow id,</li>&#xA;<li>BPM to store rules (which services should be called for given flow)</li>&#xA;<li>Service selector - kind of processor, it takes request from gateway, get flow definition and then call appropriate services one by one,</li>&#xA;<li>Functional Services.</li>&#xA;</ul>&#xA;&#xA;<p>We should be able to define multiple flows where each step is to call different service.</p>&#xA;&#xA;<p>Output of one service may be input for another one. Problem is that they can have different schema so it should be transformed/normalized somehow.</p>&#xA;&#xA;<p>But which part should be responsible to do such transformation? It should be configurable, because we want to add new flows without redeployment.</p>&#xA;&#xA;<p>First idea is to store responses from each services, and then each step will use XSLT transformation to produce input xml out of previous responses. But it may be configuration hell, cause creating and testing such XSLT won't be easy</p>&#xA;&#xA;<p>Do you have any suggestions how to solve this properly?</p>&#xA;"
31190685,Microservices explained,<php><microservices>,4,1266,0,1.0,4,<p>I'm trying to understand micro services. Can someone please explain to me how it works? I've looked at several tutorials and still confused.</p>&#xA;&#xA;<p>Let's say you have a shopping application. What are the different microservices entailed for such an application?</p>&#xA;&#xA;<p>I will need to do the following</p>&#xA;&#xA;<ul>&#xA;<li>Account creation</li>&#xA;<li>Charge the customer</li>&#xA;<li>Get a list of items for sale&#xA;etc</li>&#xA;</ul>&#xA;
29787063,"Is kafka a good fit for a small scale microservices environment, or should I look for lightweight alternatives",<apache-kafka><microservices>,2,1786,0,4.0,4,"<p>I'm working on a series of applications that will be deployed as microservices. Each one will have a separate database and I'm looking to coordinate data through single unified event store/log like Apache Kafka. I've started experimenting with Kafka, and most users seem to be using kafka at fairly large scale with clustering and fairly complex fault tolerance setups. We don't anticipate having particularly large volume initially, so I'm wondering if Kafka is the right choice? Is this a good fit for kafka or should I be looking at lighterweight alternatives given our current scale.</p>&#xA;"
38820356,Does Kong support API Aggregation,<microservices><kong>,1,1695,1,2.0,4,"<p>We are just researching a couple of API gateways, in particular <a href=""https://getkong.org"" rel=""noreferrer"">Kong</a>.&#xA;Looking through their documentation it seems they support request/response transformation. </p>&#xA;&#xA;<p>However, if I understand this correctly, this seems limited to headers.</p>&#xA;&#xA;<p>Does Kong support API Aggregation like <a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""noreferrer"">Netflix</a> does it?</p>&#xA;"
38734740,How to config SpringBoot logback setting in application.yml?,<spring-boot><yaml><logback><microservices>,2,2551,1,0.0,4,"<p>I want to specify my logback.xml file in my project, and in my SpringBoot application I was using the application.yml, I just add</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: logback.xml&#xA;</code></pre>&#xA;&#xA;<p>but it doesn't work for me, the error is :</p>&#xA;&#xA;<pre><code> Logging system failed to initialize using configuration from 'logback.xml'&#xA;java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Exception in thread ""main"" java.lang.IllegalStateException: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:289)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Caused by: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    ... 19 more&#xA;</code></pre>&#xA;&#xA;<p>And if I use</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: ./logback.xml&#xA;</code></pre>&#xA;&#xA;<p>to specify the config location, it appears the same error.&#xA;What should I do ?</p>&#xA;"
39763013,many log files on azure service fabric,<azure><microservices><azure-service-fabric>,2,628,0,0.0,4,"<p>I have a azure service fabric development cluster running locally with two applications.</p>&#xA;&#xA;<p>After a two week holiday I come back and see that my hard drive is completely full, consequently nothing really works anymore.</p>&#xA;&#xA;<p>the sfdevcluster\log\traces folder has many *.etl files all larger than 100MB.&#xA;And all kinds of other log files > 250 MB are present</p>&#xA;&#xA;<p>So my questions: how to disable tracing/logging on azure service fabric and are there tools to administer log files?</p>&#xA;"
35613841,Most efficient way to communicate between multiple .NET apps,<.net><rest><azure><architecture><microservices>,4,1116,0,2.0,4,"<p>Currently i have a setup where my clients (web apps, iOS app etc) talks to my backend API .NET web app (Nancy) via REST calls. Nothing special.</p>&#xA;&#xA;<p>I now have a requirement to split this API up into microservices, where each service can be individually upgraded/deployed. </p>&#xA;&#xA;<p>My main API (public) will just perform authentication, then call into one of my microservices, which will be in my private network.</p>&#xA;&#xA;<p><strong>What's the different ways i could communicate between my main API and other microservice API's? Pros/cons of each approach?</strong></p>&#xA;&#xA;<p>The communication needs to be realtime - e.g request comes in from a browser/device, main API performs auth, then calls into microservice API then returns response. So i can't use things like queues or pub/sub. It doesn't necessarily need to use HTTP, but it needs to be realtime communication (request/response). I also have other services (WebJobs, cloud services, etc) that need to talk to these microservices (they are also in the private network).</p>&#xA;&#xA;<p>The only approach that comes to mind is simple REST-based calls. Totally fine, but latency is the main issue here.</p>&#xA;&#xA;<p>Can anyone recommend any other solutions to this problem? Is there anything in Azure suited to this?</p>&#xA;&#xA;<p>Many thanks</p>&#xA;"
35465175,"microservice architecture questions about code resue, security and database sharing",<microservices>,1,117,0,1.0,4,<p>I have the following questions about micro service architecture</p>&#xA;&#xA;<ol>&#xA;<li><p>How common code/utility-libs are being reused between different micro services? Where this common code is also being developed</p></li>&#xA;<li><p>In my micro-service some services are for clients and some can be internal ( for other micro services to use). What is the best option to make internal services secure?</p></li>&#xA;<li><p>What if two micro-services has to use the same database? Say they do totally different operations but using the same database table?</p></li>&#xA;<li><p>Micro services are mostly about the back end but the GUI is going to be the same. In that case each micro service deployment requires website update as well. Is that consider as a disadvantage?</p></li>&#xA;</ol>&#xA;
37739538,API Gateway example for node.js,<node.js><microservices>,1,2858,0,1.0,4,"<p>Looking for a good example of how to implement a node API gateway for a microservice application, I understand the purpose of having a gateway, I am just not sure of how to implement this without just adding another level of RESTful route calls. To me a gateway is supposed to just direct the route to the microservice. </p>&#xA;&#xA;<p><strong>API Gateway port 3000</strong></p>&#xA;&#xA;<pre><code>router.use('/microservicename/*', function (req, res, next) {&#xA;     **code that will direct to microservice**&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 server.js port 3001</strong></p>&#xA;&#xA;<pre><code>var express = require('express');&#xA;var app = express();&#xA;&#xA;var routes = require('./routes/routes');&#xA;&#xA;app.use('/microservicename', routes);&#xA;&#xA;var server = app.listen(3001, function () {&#xA;    console.log('Server running at http://127.0.0.1:3001/');&#xA;});&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice1 router.js (3001)</strong></p>&#xA;&#xA;<pre><code>router.get('/route1', function (req, res, next) {&#xA;  //get route code&#xA;});&#xA;&#xA;router.post('/route2', function (req, res, next) {&#xA;  //post route code&#xA;});&#xA;&#xA;router.put('/route3', function (req, res, next) {&#xA;  //put route code&#xA;});&#xA;&#xA;router.delete('/route4', function (req, res, next) {&#xA;  //delete route code&#xA;});&#xA;</code></pre>&#xA;"
39215533,spring cloud config : how to use multiple configs,<java><microservices><spring-cloud-config>,1,4253,0,1.0,4,"<h3>What I want to try:</h3>&#xA;&#xA;<p>I want to try the <code>spring cloud config</code> for microservice project where I have a <code>common config</code> for all services and <code>multiple configs</code> for each service.<br>&#xA;I got idea on how to use multiple <code>profiles</code> using <code>spring.profiles.active</code> and <code>include</code>. I am trying to understand how can I load multiple configs on config client?</p>&#xA;&#xA;<h3>What I have:</h3>&#xA;&#xA;<p>In my git repo I have <code>spring-config-repo</code> where I have ...</p>&#xA;&#xA;<pre><code>application.yml&#xA;orderclient.yml&#xA;subscriberclient.yml&#xA;jmsclient.yml&#xA;productclient.yml&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>config Server</code> pointed to my config repo. </p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;  name: config-service&#xA;  cloud:&#xA;   config:&#xA;    server:&#xA;      git:&#xA;        uri: https://github.com/&lt;user&gt;/spring-config-repo&#xA;&#xA;server:&#xA; port: 8888&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>spring client</code> where I want to use multiple configs. Here in my case for <code>orderService</code> I want to load <code>application.yml,orderclient.yml,jmsconfig.yml</code> and For Product microService I need 'orderconfig.yml,jmsclient.yml,productclient.yml'</p>&#xA;&#xA;<pre><code>spring:&#xA;application:&#xA;  name: orderclient&#xA;profiles:&#xA;  active: test&#xA;cloud:&#xA;  config:&#xA;    uri: http://localhost:8888&#xA;&#xA;###Any kind of config properties to load jmsclient, productclient?&#xA;</code></pre>&#xA;&#xA;<p>Above I can access properties from orderclient.yml.</p>&#xA;&#xA;<h2>My Question:</h2>&#xA;&#xA;<h3>Question1:</h3>&#xA;&#xA;<p>How to access properties of <code>jmsclient.yml,productclient.yml</code> in <code>orderclient</code> application. </p>&#xA;&#xA;<h3>Question2:</h3>&#xA;&#xA;<p>Is there anyway to get list of all <code>propertySources.name</code> exposed by config server? where in above case it should dispaly</p>&#xA;&#xA;<pre><code>""propertySources"": {&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/aplication.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test,&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/orderclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA;  ""name"": ""https://github.com/&lt;&gt;/spring-config-repo/jmsclient.yml"",&#xA;     ""profiles"": &lt;available profiles for this say&gt; Dev, Test&#xA; ....}&#xA;</code></pre>&#xA;&#xA;<p>Please let me know if my question is not clear or need more information. Thanks.</p>&#xA;"
39228311,Best practices for storing content in secure area,<node.js><microservices>,1,44,1,0.0,4,<p>In our project we have separate login page and several SPAs which user can access only after proper authentication.&#xA;All static content is placed in public CDN. But html files of SPAs are stored in DB and delivered to user by index service.&#xA;We don't want to store html files in DB because it is inconvenient for us.</p>&#xA;&#xA;<p>What is the best way to store html files in secure area?</p>&#xA;
46315996,Transformation from Legacy to Microservices architecture,<rest><design><microservices><soa>,2,156,0,2.0,4,"<p>I want to discuss a transformation from fat DB to microservices architecture.</p>&#xA;&#xA;<p><strong>A bit of history:</strong>&#xA;So we have a legacy loan application system, which captures customer detail into a FAT database with some 1000+ tables. The application is doing a lot more than just just capturing loan with 100+ screens/processes built that are beyond loan capturing. Like administration, reporting, config etc.</p>&#xA;&#xA;<p><strong>Current State:</strong>&#xA;The whole Presentation Layer, Logic Layer, DB Layer, ORM layer is part of the one project.</p>&#xA;&#xA;<p><strong>Current Task In Hand:</strong>&#xA;The app is built in Win Forms, and my job is transform it to Modern UI as we need modern feature. </p>&#xA;&#xA;<p><strong>Approach:</strong>&#xA;The approach I am taking is to built some Micro Services on current DB Structure. Using the same DB will allow the current application to run as it is, and we can write a new DB Layer, Logic Layer in some Micro Services. We can then write Modern User Interface (angular/react) that will consume those services. &#xA;The second step then will be then stop the use of capturing operation from legacy app.</p>&#xA;&#xA;<p>Third step is to move the specific DB tables out of the legacy databases to their own databases.</p>&#xA;&#xA;<p>This approach seems best by keeping the current operation running as it is. Also, this approach allows us to run both applications parallel on the production environment. </p>&#xA;&#xA;<p><strong>Confusion:</strong>&#xA;The question I have is on detailed design. I am struggling to understand the context split in Micro Services. The information in the scope of first iteration is:&#xA;- Some Qualification Questions&#xA;- Contact details&#xA;- App requirements&#xA;- Bank Details&#xA;- Income details&#xA;- Expense details&#xA;- Previous loan information</p>&#xA;&#xA;<p>The microservices I am thinking to have is&#xA; - Application Service&#xA;    - Qual questions&#xA;    - App requirements&#xA;    - Previous Loan information&#xA;    - Income/Expense details&#xA; - Demographics Information&#xA;    - Bank Details&#xA;    - Contact Details</p>&#xA;&#xA;<p><strong>Questions:</strong>&#xA;- Does the approach sounds correct from legacy to microservices?&#xA;- The microservice split. Can someone suggest if this is right?</p>&#xA;&#xA;<p>Thanks a lot in advance.&#xA;Regards&#xA;Gaurav Sharma</p>&#xA;"
37289634,How to Set Request Headers Using a Feign Client?,<spring-mvc><spring-cloud><microservices><netflix-feign><spring-cloud-netflix>,1,6976,0,3.0,4,"<p>We are developing a suite of Microservices using Spring Cloud framework and one of the the things that we need to do is to set request headers. I know I can pass a parameter <code>@RequestHeader</code> to a Feign method but the value needs to come from another bean. I don't know if SPEL can be used for a Feign param value.&#xA;I was thinking that this is a common enough use case for most clients so there'd be some examples, but so far I've not found any. Of course I can dig through the Spring course code and try to override the default Feign configuration but it kinda defeats the purpose of a declarative client if I've to write a lot of code to achieve this.&#xA;Any thoughts?</p>&#xA;"
34909182,Microservice solution structure in .NET applications,<visual-studio><microservices>,1,1384,2,1.0,4,"<p>I'm developing an application using the microservices approach, and I'm having a hard time defining how those microservices will look like on a visual studio project.</p>&#xA;&#xA;<p>My initial approach is to create one visual studio solution for every microservice. Every solution will have the following projects:</p>&#xA;&#xA;<ul>&#xA;<li>Host</li>&#xA;<li>Business API</li>&#xA;<li>Data Access Layer</li>&#xA;<li>Model</li>&#xA;<li>Interfaces (for DI) </li>&#xA;<li>Data Access Mock</li>&#xA;<li>Tests for Business API</li>&#xA;</ul>&#xA;&#xA;<p>So there are 7 projects per microservice. Somehow it feels a lot of projects being reimplemented for every solution.</p>&#xA;&#xA;<p>Is this approach correct? Has anybody built microservices with .net? How does your projects configuration look like?</p>&#xA;"
39615381,Advantages of Service Fabric Microservices vs Collection of Azure Cloud services/web apps,<azure><microservices><azure-service-fabric><azure-cloud-services><azure-appfabric>,2,4502,0,2.0,4,"<p>I have a application that can be broken down into multiple communicating services. My current implementation is monolithic and I want to reorganize the same so that individual components can be deployed,iterated upon, scaled independently. I see two ways to do this with Azure:</p>&#xA;&#xA;<ol>&#xA;<li>Service Fabric service composed of set of communicating micro-services(stateless, web-api etc.)</li>&#xA;<li>A collection of individual Azure Web Apps/ Cloud Services that call each other at the http end points.</li>&#xA;</ol>&#xA;&#xA;<p>Are there any obvious advantages of 1 over 2? Any rule of thumb to chose one over the other would also be very helpful.</p>&#xA;"
42788267,"Can I use Oauth2 Authorization Code flow for a SPA (React app), if I have a server-side proxy?",<oauth-2.0><single-sign-on><microservices><openid-connect><identityserver4>,1,1407,1,1.0,4,"<p>After watching an obscene amount of tutorials on OAuth2, there is one best practice that everyone repeatedly states - if you have a React app (or Angular, or Ember) - you <strong>must</strong> use <em>Implicit flow</em> with it.</p>&#xA;&#xA;<p>I understand that storing client credentials in publicly visible javascript would not work. However, my scenario is a bit different:</p>&#xA;&#xA;<ol>&#xA;<li>I'm only using Oauth2 for single sign on and token generation for microservices. I chose it instead of simply generating tokens, since well-supported third party libraries are built around the Oauth2 idea.</li>&#xA;<li>My idea is to have a React app, and a ASP.NET MVC app which serves the javascript and acts as a proxy for API requests. The user authenticates for the server-side app (by using Oauth2 authorization code flow).</li>&#xA;<li>Then if I need to retrieve data from an API, I call my ASP.NET MVC app from React (by sending a simple cookie). The MVC app holds the token without ever exposing it to the user's browser.</li>&#xA;<li>Obviously, when called, my MVC app then redirects the request to the necessary API, providing the bearer token.</li>&#xA;</ol>&#xA;&#xA;<p>To better understand why this is what I came up with, here are some requirements I've received that might be unusual:</p>&#xA;&#xA;<ol>&#xA;<li>I really don't want the access token to be shared - even if it's relatively short lived.</li>&#xA;<li>I also want to be able to limit each user account to 3 concurrent user sessions. Easy to do using cookies and server-side sessions.</li>&#xA;</ol>&#xA;&#xA;<p>I can't wrap my head around why this idea would be that bad. Is there any technical problem that might prevent this from working? Or maybe a security risk?</p>&#xA;"
40234243,OAuth 2.0 service to service authentication and best practices,<authentication><oauth><microservices>,1,519,0,0.0,4,"<p>I have to deal with such type of auth flows:</p>&#xA;&#xA;<ol>&#xA;<li>Create auth flows for Web users;</li>&#xA;<li>In the same way deal with service to service authentication</li>&#xA;</ol>&#xA;&#xA;<p>Briefly following diagram can depict main components that we'll have:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NzDM7.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/NzDM7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>For users Authentication we'd like to use OAuth2 (the Implicit Flow) and in general it looks more or less clear.</p>&#xA;&#xA;<p>The question about service to service authorization can it be OAuth2 Authorization Code Flow used?</p>&#xA;&#xA;<p>The main problem there that inside of datacenter1 it will be plenty of backend services that's why it will be good as services will work on the similar permission model as a users (at least some some functionality might be retracted ).</p>&#xA;&#xA;<p>And additional question: what is the general recommendation for this use case if Authorization Server is inside of Datacenter1 or outside?</p>&#xA;"
41837637,Microservices vs multi-layered architecture,<asp.net-web-api><architecture><microservices><multi-layer>,1,2806,0,1.0,4,"<p>My project has one backend service (Web API) and one frontend SPA application. Backend service has presentation, application services, domain and infrastructure layers located in different .net assemblies. Domain layer has business domain objects, infrastructure – communication with external data and other stuff, application services – set of services used by presentation layer, presentation – Web API controllers. I think it’s very common layered architecture.</p>&#xA;&#xA;<p>Our new architect announced we are going to move backend to microservices architecture braking down our layers and dividing domain, application service and infrastructure layers to a few services and convert presentation layer to backend for frontend layer (as <a href=""http://samnewman.io/patterns/architectural/bff/"" rel=""nofollow noreferrer"">here</a> described). In feature, we are going to have mobile application. Sql Server database is going to leave as is for now.</p>&#xA;&#xA;<p>I don’t have experience with microservice architecture, so my questions are: &#xA;Is multi-layered architecture out of fashion already? What benefits and problems can bring such architecture design for my application?</p>&#xA;"
41824300,.NET Core API Gateway,<c#><api><.net-core><microservices><gateway>,2,6347,9,3.0,4,"<p>I've got some work to do for school around Microservices. </p>&#xA;&#xA;<p>I've got the architectural concept, but need an implementation to show off. I'll be using angular2 as a client, would like to use a .NET core API gateway to dispatch my requests to different services. </p>&#xA;&#xA;<p>What's the best approach for this? I red something about using Rx.Net, but no definitive example or implementation that I can follow.</p>&#xA;&#xA;<p>So what should I do to implement an API gateway in .NET Core?</p>&#xA;"
37409153,"No cluster endpoint is reachable, please check if there is connectivity/firewall/DNS issue",<azure><microservices>,1,2227,2,0.0,4,"<p>I am currently working on cloud technology, in one of my current project I was created the service fabric cluster in azure after created the service fabric in azure, next I am trying to connect the cluster through the Windows Power shell It gives the error like this below figure.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6YnM8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6YnM8.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Please tell me how to resolve the above issue.</p>&#xA;&#xA;<p>Regards,</p>&#xA;&#xA;<p>Pradeep</p>&#xA;"
41067341,"what is the difference between distributed computing, microservice and parallel computing",<terminology><distributed-computing><microservices>,1,2395,0,1.0,4,"<p>My basic understanding for:</p>&#xA;&#xA;<p>Distributed computing is a model of connected nodes -from hardware perspective they share only network connection- and communicate through messages. each node code be responsible for one part of the business logic as in ERP system there is a node for hr, node for accounting. communication could be HTML, SOA, RCP</p>&#xA;&#xA;<p>Microservice is a service that is responsible for one part of the business logic and communicate with each other usually by http. microservices could share the hardware resources and are accessed by thier api.</p>&#xA;&#xA;<p>Parallel systems are systems which optimize the use of resources. for example multithreaded app running on several thread where sharing memory resources.</p>&#xA;&#xA;<p>I am a little bit confused since microservices are distributed systems, but when running multiple microservices on single hardware resources they are also parallel systems. Am i getting it right here:</p>&#xA;"
50264214,How to edit the source code in module after installed it using zef?,<web><microservices><perl6><cro>,2,109,0,0.0,4,"<p>For example, I've installed the <a href=""http://cro.services"" rel=""nofollow noreferrer"">Cro</a> module, when I run my simple code:</p>&#xA;&#xA;<pre><code> my %headers = {Authorization =&gt; OAuth realm="""", oauth_consumer_key=""xxxxxxxxxxxxxxxx"", oauth_nonce=""29515362"", oauth_signature=""KojMlteEAHlYjMcLc6LFiOwRnJ8%3D"", oauth_signature_method=""HMAC-SHA1"", oauth_timestamp=""1525913154"", oauth_token=""xxxx-xxxxxxxxxxxxxxxxxx"", oauth_version=""1.0"", User-Agent =&gt; Cro};&#xA;&#xA; my $resp = await Cro::HTTP::Client.get: 'http://api.fanfou.com/statuses/home_timeline.json',&#xA;     headers =&gt; [&#xA;            user-agent   =&gt; 'Cro',&#xA;            content-type =&gt; 'application/json;charset=UTF-8',&#xA;            |%headers&#xA;     ];&#xA;&#xA; say $resp.header('content-type'); # Output: application/json; charset=utf-8;&#xA; my Str $text = await $resp.body-text(); &#xA;</code></pre>&#xA;&#xA;<p>And it says 'Could not parse media type <code>application/json; charset=utf-8;</code></p>&#xA;&#xA;<pre><code>Died with the exception:&#xA;    Could not parse media type 'application/json; charset=utf-8;'&#xA;      in method parse at /Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69 (Cro::MediaType) line 74&#xA;      in method content-type at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 74&#xA;      in method body-text-encoding at /Users/ohmycloud/.perl6/sources/427E29691A1F7367C23E3F4FE63E7BDB1C5D7F63 (Cro::HTTP::Message) line 83&#xA;      in block  at /Users/ohmycloud/.perl6/sources/F870148C579AB45DEB39F02722B617776C3D6D5F (Cro::MessageWithBody) line 49&#xA;</code></pre>&#xA;&#xA;<p>It seems that <code>application/json; charset=utf8;</code> is not a valid <code>content-type</code>, so I add a test:</p>&#xA;&#xA;<pre><code>use Cro::MediaType;&#xA;use Test;&#xA;&#xA;sub parses($media-type, $desc, &amp;checks) {&#xA;    my $parsed;&#xA;    lives-ok { $parsed = Cro::MediaType.parse($media-type) }, $desc;&#xA;    checks($parsed) if $parsed;&#xA;}&#xA;&#xA;parses 'application/json; charset=utf-8;', 'application/json media type with charset', {&#xA;    is .type, 'application', 'Correct type';&#xA;    is .subtype, 'json', 'Correct subtype';&#xA;    is .subtype-name, 'json', 'Correct subtype name';&#xA;    is .tree, '', 'No tree';&#xA;    is .suffix, '', 'No suffix';&#xA;    is .Str, 'application/json; charset=utf-8;', 'Stringifies correctly';&#xA;};&#xA;&#xA;done-testing;&#xA;</code></pre>&#xA;&#xA;<p>And the output is:</p>&#xA;&#xA;<pre><code>not ok 1 - application/json media type with charset&#xA;# Failed test 'application/json media type with charset'&#xA;# at cro_media.pl6 line 6&#xA;# Could not parse media type 'application/json; charset=utf-8;'&#xA;1..1&#xA;# Looks like you failed 1 test of 1&#xA;</code></pre>&#xA;&#xA;<p>the source code seems locate in the <code>/Users/ohmycloud/.perl6/sources/5B710DB8DF7799BC8B40647E4F9945BCB8745B69</code> file, and I add <code>';'?</code> after the <code>TOP</code> token:</p>&#xA;&#xA;<pre><code>token TOP { &lt;media-type&gt; ';'? }&#xA;</code></pre>&#xA;&#xA;<p>save, and run my code again, but the error is the same. So how to make the change work? In Perl 5, I can just edit my <code>.pm</code> module, but in Perl 6, I dont't know what to do. </p>&#xA;"
43609390,User as a microservice,<architecture><microservices>,1,506,1,1.0,4,"<p>I'm working on PAAS solution as a product. we have divided business processes in several microservices. One core part of the processes is closely connected to nearly all microservices.</p>&#xA;&#xA;<p>Is this a good practice to create a separate service to manage data such as user management? After the implementation, only this service will have access to users and other related DB tables. All other services will have to call this new user microservice for user related tasks.</p>&#xA;&#xA;<p>This approach will enforced us to refactor DB schema by adding denormalization. We would not get underlying tables that is served among multiple microservices. If serveral services needs data, it would be shared via a microservice.</p>&#xA;"
47451190,Kafka instead of Rest for communication between microservices,<rest><apache-kafka><microservices>,1,912,0,1.0,4,"<p>I want to change the communication between (micro)-services from REST to Kafka.&#xA;I'm not sure about the topics and wanted to hear some opinions about that.</p>&#xA;&#xA;<p>Consider the following setup:&#xA;I have an API-Gateway that provides CRUD functions via REST for web applications. So I have 4 endpoints which users can call.&#xA;The API-Gateway will produce the request and consumes the responses from the second service.&#xA;The second service consumes the requests, access the database to execute the CRUD operations on the database and produces the result.</p>&#xA;&#xA;<p>How many topics should I create?&#xA;Do I have to create 8 (2 per endpoint (request/response)) or is there a better way to do it?</p>&#xA;&#xA;<p>Would like to hear some experience or links to talks / documentation on that.</p>&#xA;"
43041563,User authentication in microservice application hosted on Amazon WS,<amazon-web-services><authentication><architecture><microservices><aws-cognito>,1,259,0,3.0,4,"<p>I am building web application based on microservice architecture. At this moment I am considering few ways of user authentication flow. I predict following, example user roles:</p>&#xA;&#xA;<ul>&#xA;<li>admin - is able to create content, upload files etc (admin account can be created only by another admin)</li>&#xA;<li>unauthorized user - can view content</li>&#xA;<li>authorized user - can comment content</li>&#xA;</ul>&#xA;&#xA;<p>Here is, how I was thinking about authentication flow so far:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - have access to DB with users credentials and permissions</li>&#xA;<li>api gateway - retrieve requests from user, check if user is logged in (ie verifies OAuth2 access token with auth service) and transfer flow to other services based on user request (attaching JWT token with some basic user info)</li>&#xA;<li>another service - accept only requests from api gateway, and trusts user data from JWT token (does not need to connect with auth service to get information about user).</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>After deploying some stuff on AWS infrastructure my way of thinking have changed a little bit. As far as I understand AWS products (Lambda - serverless applications and API gateway), I should implement authentication flow as follows:</p>&#xA;&#xA;<ul>&#xA;<li>authentication service - gets request from user, retrieve data from dynamoDB and provide user cookie with JWT signed by private key</li>&#xA;<li>any other service - retrieves request with JWT token, verifies signature using public key, and perform some action.</li>&#xA;</ul>&#xA;&#xA;<h1>And now the question comes:</h1>&#xA;&#xA;<p>How deos AWS Cognito fits here? Is it something useful for me? As far as I understand, Cognito simplifies flow of authenticating users via 3rd parties (facebook, twitter etc. etc.). Does AWS Cognito serves login page, separated from my application, or it is only background/webservices impelementation?</p>&#xA;&#xA;<p>So far I am thinking about Cognito as a replacement for my <code>authentication service</code> - any of my services, should impelemnt Cognito authentication flow provided by SDK from amazon, and my static website would implement JavaScript SDK for user login/register. Am I right?</p>&#xA;"
42981194,How do you handle validation in composite microservice request?,<architecture><microservices><software-design><distributed-transactions>,3,1030,0,0.0,4,"<p>Consider an application with two entities:</p>&#xA;&#xA;<ul>&#xA;<li><code>User</code> (contains basic user data, such as name)</li>&#xA;<li><code>Passport</code> (contains authentication credentials, i.e. password)</li>&#xA;</ul>&#xA;&#xA;<p>And two internal microservices:</p>&#xA;&#xA;<ul>&#xA;<li><code>UserService</code> (responsible for creating and managing users and their basic data)</li>&#xA;<li><code>AuthService</code> (responsible for user authentication and password handling)</li>&#xA;</ul>&#xA;&#xA;<p>The <code>User</code> entity belongs to the <code>UserService</code> and <code>Passport</code> entity belongs to the <code>AuthService</code>.</p>&#xA;&#xA;<p>Those two services should be separated, because they solve very different tasks: <em>profile data</em> and <em>authentication</em>.</p>&#xA;&#xA;<p>Also, consider we have a registration form with three fields:</p>&#xA;&#xA;<ul>&#xA;<li>E-Mail</li>&#xA;<li>Name</li>&#xA;<li>Password</li>&#xA;</ul>&#xA;&#xA;<p>This form will trigger HTTP-request to the <code>GatewayService</code>, which intercepts all requests to the application and routes them to internal microservices (or composes/aggregates them).</p>&#xA;&#xA;<p>Now, when gateway service receives the request with all the form data it needs to do the following:</p>&#xA;&#xA;<ol>&#xA;<li>Call <code>UserService</code> to create new user (it will respond with generated <code>userId</code>).</li>&#xA;<li>Call <code>AuthService</code> to create a passport for newly created user. It will need the <code>userId</code> received in step #1 and a <code>password</code> field from the original request.</li>&#xA;</ol>&#xA;&#xA;<p>This looks pretty straightforward, but what will happen if <code>AuthService</code> is unavailable on step #2? We will need to somehow separate those requests!</p>&#xA;&#xA;<p>The classic approach is to use the eventual consistency and to create <code>Passport</code> entity via asynchronous call (we can place this request to the queue and process it in separate service). In order to do this we will send an asynchronous request to the <code>AuthService</code> passing <code>userId</code> and <code>password</code> to it, instead of step #2, so the step #1 will immediately return response to the client.</p>&#xA;&#xA;<p>However, what if <code>password</code> field is not properly formatted (breaks validation rules)? The validation logic is only present in the <code>AuthService</code>, so we can't know if password is correct until the call is made to it. And now, the request is processed asynchronously, so we can't get back to user and tell him to correct the password.</p>&#xA;&#xA;<p><strong>SO, how do you properly handle validation in distributed composite requests to microservice application?</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>The naive solution is to move validation logic to the <code>GatewayService</code> itself, but it's a terrible idea, because it will make it fat and will leak business logic from <code>AuthService</code>.</p></li>&#xA;<li><p>The other idea is to provide an additional method for password validation and to call it prior to steps #1 and #2. It looks like a viable solution, but it will force us to have two methods for each business method in our microservices, one for prior validation and one for actual operation. Also, there is a time space between validation and operation, so the earlier correct value could become incorrect when operation is actually performed.</p></li>&#xA;<li><p>We could split the form in two to avoid composite requests and ask user for password after asking for personal data and creating an account for him. However, this could lead to security problems, where user account could be intercepted by some other party who could guess the next <code>userId</code>. We could, use some additional security token, but it will introduce odd functionality to services and will make the whole setup more complex.</p>&#xA;&#xA;<p>Also, this approach looks like an attempt to escape the problem, you can't always avoid composite requests.</p></li>&#xA;<li><p>We could use full-scale distributed transactions, e.g. <a href=""https://en.wikipedia.org/wiki/Two-phase_commit_protocol"" rel=""nofollow noreferrer"">2PC</a>, but it will make the system dramatically complex and will mitigate the use of MSA in the first place.</p></li>&#xA;<li><p>And the final idea is to merge those two services together, but it will make no sense in microservice architecture to do so.</p></li>&#xA;</ol>&#xA;"
34503547,Spring MVC - Calling a rest service from inside another rest service,<java><spring><rest><spring-mvc><microservices>,2,19997,4,3.0,4,"<p>I'm currently having a really weird issue with calling one REST service from inside another one and I could really use a hand in working out what I'm doing wrong.</p>&#xA;&#xA;<p><strong>So first off, a bit of context:</strong></p>&#xA;&#xA;<p>I have a webapp which calls off to a REST service to create a user account (for the sake of this explanation, the endpoint is localhost:8080/register). Earlier in the user journey I've called a different service to create the user's login credentials <code>localhost:8090/signup</code> but I need to check a few things in the call to /register so inside the call I'm calling out to a different endpoint on 8090 to get this information (<code>localhost:8090/availability</code>). Long story short, the webapp calls localhost:8080/register which in turn calls <code>localhost:8090/availability</code>.</p>&#xA;&#xA;<p>When I call the availability endpoint directly, from either a REST client or the webapp itself, everything works as expected, but for some strange reason, when I call it from inside the call to the register endpoint I get a HTTP415. Anyone have any insight into what's going wrong?</p>&#xA;&#xA;<p>The register controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And the availability controller looks like this:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public Boolean isUsernameAvailable(@RequestBody String username) {&#xA;&#xA;    // a load of business logic that returns a boolean&#xA;    return Boolean.TRUE;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Full disclosure - in practice, what I've shown as the contents of createUser() are actually several calls up the call stack, using the same class as I use to call the services from the webapp (which works perfectly well in that context), and I'm not actually just returning true in isUsernameAvailable (because that would be silly) but this is the simplest version of the code that replicates the issue. </p>&#xA;&#xA;<p>My current assumption is that I'm doing something that I'm going to kick myself over when I see it but I've been staring at this code too long to be able to see it any more.</p>&#xA;&#xA;<p><strong>Edit</strong> Vikdor's comment below solved this problem for me. I changed the createUser method to:</p>&#xA;&#xA;<pre><code>@RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE)&#xA;@ResponseStatus(HttpStatus.OK)&#xA;public UserModel createUser(@RequestBody UserModel userModel) throws InvalidSignupException {&#xA;&#xA;    // a load of business logic that validates the user model&#xA;&#xA;    RestTemplate restTemplate = new RestTemplate();&#xA;    restTemplate.setMessageConverters(Arrays.asList(new MappingJackson2HttpMessageConverter()));&#xA;    ResponseEntity&lt;Boolean&gt; response = restTemplate.postForEntity(""http://localhost:8090/availability"",&#xA;            userModel.getUsername(), Boolean.class);&#xA;    System.out.println(response.getBody());&#xA;&#xA;    // a load more business logic&#xA;&#xA;    return userModel;&#xA;}&#xA;</code></pre>&#xA;"
44582199,"Angular microservices, loadChildren from url",<angular><architecture><microservices>,1,383,0,2.0,4,"<p>I recently started thinking of how to effectively implement Angular in a microservices architecture.</p>&#xA;&#xA;<p>Let's say we have a service for login, a service for user management and a service for browsing, adding and editing certain media. Each service has its own backend and frontend served in its own private container. So each part is then isolated with a clearly defined API to interact with for the backend, and its own isolated user interface consuming this API.</p>&#xA;&#xA;<p>Now, let's say I would like to tie up each of these microservices into a single application. I have two ways (as far as I can see) to do this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can configure a server to place each service under a sub-url, and have the application be an array of SPA's, a sort of MPA (Multi Page App). </p></li>&#xA;<li><p>I can create a master app where I set up the routes for each of my micro-apps and load them on demand (custom PreloadingStrategy, I'm looking at you).</p></li>&#xA;<li><p><sup>I also found <a href=""https://stackoverflow.com/questions/39904153/front-end-micro-services-with-angular-2#answer-39937403"" title=""this"">this</a>, a process which I personally don't think highly of, because you'll lose many of the benefits of microservices in a continuous delivery scheme of things. This aims to create a SPA monolith out of microservices.</sup></p></li>&#xA;</ol>&#xA;&#xA;<p>Now, the first alternative seems like a chore, and no fun at all. The second is intriguing to me. I came accross this article: <a href=""https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular"" rel=""nofollow noreferrer"">https://coryrylan.com/blog/custom-preloading-and-lazy-loading-strategies-with-angular</a> and immediately started thinking; how can I exploit this to load pre-built angular modules from a url instead of packaging them from the file system?</p>&#xA;&#xA;<p>So my question is; has anybody done this before? Is it possible? Are there security issues in doing this?&#xA;Or are there other alternatives of tying up my microservices into a larger application?</p>&#xA;"
46605663,Best practices sharing types across multiple Haskell packages/microservices,<haskell><architecture><microservices>,1,131,3,1.0,4,"<p>I am working in a Haskell project that is composed of multiple microservices. There are certain types that are needed by multiple services at the same time and therefore are defined in separate libraries that are imported by whichever needs them (each type is versioned). But there are things about it that make me uncomfortable and I was wondering which are the best practises regarding that topic. In particular:</p>&#xA;&#xA;<ul>&#xA;<li>I don't know how to handle instances of shared types. In order to avoid orphans the instances must be defined in the type's module for each of the types. But then there are instances that are not needed by all the microservices that import the package and have to be included regardless, potentially adding redundant dependencies to the microservice. An example would be a datatype <strong>T</strong> that is shared by a frontend and a backend. It has an instance of <strong>Store</strong> in order to be stored in a database that is not needed by the frontend, but still makes the frontend depend of the store package.</li>&#xA;<li>In order to avoid the previous issue I could introduce a wrapper every time the type has to ""leave"" a microservice to represent that type going through the wire. In the previous example I would have a <strong>Storable T</strong> which would have an instance for <strong>Store</strong>. This adds quite a lot of overhead to the overall development process though.</li>&#xA;<li>Is it even a good idea to share the types or should each microservice define its own representation of each type, so nothing has to be shared? So for a type <strong>T</strong> a microservice <strong>MA</strong> would have a representation <strong>A.T</strong> and an instance to serialise it in order to send the data to a microservice <strong>B</strong> which would decode that data into a representation <strong>MB.T</strong>.</li>&#xA;</ul>&#xA;&#xA;<p>And finally, regarding the logistical side of the matter,</p>&#xA;&#xA;<ul>&#xA;<li>What's the most convenient way to structure the project? Would a monorepo be a better choice than having separate repos/submodules?</li>&#xA;<li>Maybe related to the previous one, is there any way to find out automatically which microservices should be redeployed when one of the shared libraries is modified because the changes in the library affect a piece of code that is being used by the microservice?</li>&#xA;</ul>&#xA;"
47311911,Event sourcing / CQRS read model - projections,<domain-driven-design><microservices><cqrs><event-sourcing>,2,407,0,0.0,4,"<p>I have a microservice-based application running on AWS Lambda. Two of the microservices, the most crucial ones, use event-sourcing/cqrs. </p>&#xA;&#xA;<p><strong>Background: (this is also for me to organize my thoughts)</strong></p>&#xA;&#xA;<p>I'm using <a href=""https://github.com/bakerface/easy-source"" rel=""nofollow noreferrer"">this library</a>  and storing events in DynamoDB and projections in AWS S3.</p>&#xA;&#xA;<p>The write part works like a charm: Each command invocation loads the current state of the aggregate from DynamoDB (by running events through a handler and/or loading an cached aggregate), it decides to accept or reject the command based on some business logic, then writes to DynamoDB with <code>KeyConditionExpression: 'aggregateId = :a AND version &gt;= :v'</code> where the version is a count of events processed for that aggregate. If there's a conflict, the write fails. Seems like a good system to me!</p>&#xA;&#xA;<p>Each event is then broadcast to SNS (topic name is the service name) so other services can react to the event, if they want.</p>&#xA;&#xA;<p>The part that I really struggle with is the read. Projections are stored in S3 and tagged with the last commitId processed for each event source. When a read query comes in, it loads the entire projected state from S3 <em>(for all aggregates)</em>, queries the event sources for all newer events, computes the latest state (again, for all aggregates - and writing an updated object to S3 if it's newer), and returns relevant parts of the state based on the query params.</p>&#xA;&#xA;<p><strong>My problem: (or one of them)</strong></p>&#xA;&#xA;<p>I think I'm doing projections wrong. </p>&#xA;&#xA;<p>Most of my projections only group ids by important attribute, so the files stay relatively small. But I also need a way to retrieve an individual aggregate. Using projections for that seems crazy, because I need to load the entire state each time (i.e. every projected aggregate) apply new events to that, then retrieve the record I want (it may not have even changed).</p>&#xA;&#xA;<p>This is what I'm doing now, it's performing fine (&lt;100k records) but I can't imagine it will continue much longer. </p>&#xA;&#xA;<p>The other problem is queries. I need to build a projection mapping value to matching aggregateIds for every attribute I need to query on!! There's got to be a better way!</p>&#xA;&#xA;<p>No matter what way I think about this problem, projections always need the entire current state + any new events before it can return even a single record that hasn't changed.</p>&#xA;"
47938835,How to create replay mechanism within event-drive microservice,<java><architecture><transactions><microservices><event-driven-design>,2,170,3,1.0,4,"<p>We have 7 microservices communicated via eventbus.&#xA;We have a real-time transaction sequence:</p>&#xA;&#xA;<p>Service 1->service2->service3 (and so on.) Until transactions considered as completed</p>&#xA;&#xA;<p>We must make sure all transactions happened.</p>&#xA;&#xA;<p>Ofcourse we can have failures at any point. So we are thinking about mechanisem to replay ""half-baked"" transactions into completion.</p>&#xA;&#xA;<p>It's getting tricky. Two ways we thought about:</p>&#xA;&#xA;<ol>&#xA;<li><p>Having another service (supervisor service) that will log each part in our real time sequence and will be smart enough when transactions are not completed (timedout) to understand how we can continune from left point</p>&#xA;&#xA;<p>Disadvantages:&#xA;lots of ""smart"" logic on one central service</p></li>&#xA;<li><p>having retry mechanisem on every service while each one taking care of it's own and replay it's own until success or exhusated</p>&#xA;&#xA;<p>Disadvantages:&#xA; lots of retry duplicated code on each service</p></li>&#xA;</ol>&#xA;&#xA;<p>What do you experts think?</p>&#xA;&#xA;<p>Thank</p>&#xA;"
47554214,Design choice for a microservice event-driven architecture,<domain-driven-design><microservices><cqrs>,3,248,0,1.0,4,"<p>Let's suppose we have the following:</p>&#xA;&#xA;<p>DDD aggregates A and B, A can reference B.</p>&#xA;&#xA;<p>A microservice managing A that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create A</li>&#xA;<li>delete A</li>&#xA;<li>link A to B</li>&#xA;<li>unlink A from B</li>&#xA;</ul>&#xA;&#xA;<p>A microservice managing B that exposes the following commands:</p>&#xA;&#xA;<ul>&#xA;<li>create B</li>&#xA;<li>delete B</li>&#xA;</ul>&#xA;&#xA;<p>A successful creation, deletion, link or unlink always results in the emission of a corresponding event by the microservice that performed the action.</p>&#xA;&#xA;<p>What is the best way to design an event-driven architecture for these two microservices so that:</p>&#xA;&#xA;<ol>&#xA;<li>A and B will always eventually be consistent with each other. By consistency, I mean A should not reference B if B doesn't exist.</li>&#xA;<li>The events from both microservices can easily be projected in a separate read model on which queries spanning both A and B can be made</li>&#xA;</ol>&#xA;&#xA;<p>Specifically, the following examples could lead to transient inconsistent states, but consistency must in all cases eventually be restored:</p>&#xA;&#xA;<p><strong>Example 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B doesn't, A is not linked to B</li>&#xA;<li>Command: link A to B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 2</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is linked to B</li>&#xA;<li>Command: delete B</li>&#xA;</ul>&#xA;&#xA;<p><strong>Example 3</strong></p>&#xA;&#xA;<ul>&#xA;<li>Initial consistent state: A exists, B exists, A is not linked to B</li>&#xA;<li>Two simultaneous commands: link A to B and delete B</li>&#xA;</ul>&#xA;&#xA;<p>I have two solutions in mind.</p>&#xA;&#xA;<p><strong>Solution 1</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has previously received a ""B created"" event and no ""B deleted"" event.</li>&#xA;<li>Microservice B only allows deleting B if it has not previously received a ""A linked to B"" event, or if that event was followed by a ""A unlinked from B"" event.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B (for the race condition in which B is deleted before it has received the A linked to B event).</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A always allows linking A to B.</li>&#xA;<li>Microservice B listens for ""A linked to B"" events and, upon receiving such an event, verifies that B exists. If it doesn't, it emits a ""link to B refused"" event.</li>&#xA;<li>Microservice A listens for ""B deleted"" and ""link to B refused"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p><strong>EDIT: Solution 3, proposed by Guillaume:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A only allows linking A to B if it has not previously received a  ""B deleted"" event.</li>&#xA;<li>Microservice B always allows deleting B.</li>&#xA;<li>Microservice A listens to ""B deleted"" events and, upon receiving such an event, unlinks A from B.</li>&#xA;</ul>&#xA;&#xA;<p>The advantage I see for solution 2 is that the microservices don't need to keep track of of past events emitted by the other service. In solution 1, basically each microservice has to maintain a read model of the other one.</p>&#xA;&#xA;<p>A potential disadvantage for solution 2 could maybe be the added complexity of projecting these events in the read model, especially if more microservices and aggregates following the same pattern are added to the system.</p>&#xA;&#xA;<p>Are there other (dis)advantages to one or the other solution, or even an anti-pattern I'm not aware of that should be avoided at all costs?&#xA;Is there a better solution than the two I propose?</p>&#xA;&#xA;<p>Any advice would be appreciated.</p>&#xA;"
43246560,Microservices Architecture: Chatty services or data duplication,<architecture><domain-driven-design><microservices>,3,395,0,1.0,4,"<p>TL;DR Should a service opt for saving data in its local database that it needs occasionally, or request the data every time from the service that the data originated from?</p>&#xA;&#xA;<p>Let's have some generic example of a web store / ordering app. Service A is a user session management service. It handles business logic of what a user is doing, what he can do, etc. The user can create his own shirt for purchase. Service B is a data aggregator that contains a lot of the inventory and what's available.</p>&#xA;&#xA;<p>The user starts creating a shirt, so service A request from service B, what styles/colors are available. Service B sends down a list of possible choices which service A then displays for the user. The user then selects one, customizes it and moves on to a new shirt. Again service A has to request from service B, what styles/colors are available. </p>&#xA;&#xA;<p>Now let's assume within a life cycle of a user session, these styles/colors won't change and we know this is going to be the same data being retrieved over and over again. Not by just this user, but all users. So in this case, since the styles/colors are really part of Service B's domain, they should stay there and live there, or would it be advised to prevent all these needless calls and upon the first request (temporarily) save in Service A the data for the lifecycle of the session to prevent chatty services.</p>&#xA;&#xA;<p>This is an over-simplified example but the problem remains real-world. Which is more suggested way of architecting this design? &#xA;This usually applies for example when some fairly-static data is passing through some service, and this service will need this data again a few times within the lifecycle of these transactions. So I'm unsure whether the service should just save it temporarily for the life-cycle knowing the data won't change or not caring if it changes within the lifecycle or opt for more chatty services and keep requesting every time.</p>&#xA;"
52031350,How ACID works in a restful micro-service architecture,<java><rest><microservices><acid>,1,59,2,1.0,4,"<p>I'm pretty new at implementing microservice architecture and this question is breaking my mind</p>&#xA;&#xA;<p>How a microservice architecture address transactional mechanism between different end-points calls.</p>&#xA;&#xA;<p>An example is banking services based on a microservice architecture&#xA;basically, the banking operation is for different calls to different services to complete a transaction, if one of them fails, then there is no way to eliminate the partial process, I do not know if there is any mechanism to solve this problem</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>create a payment</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /payments/customer/10/payment/100/ </p>&#xA;  &#xA;  <p><strong>debit money from the account</strong></p>&#xA;  &#xA;  <p><strong>PUT</strong> /customers/10/accounts/20</p>&#xA;  &#xA;  <p><strong>Send a customer notification</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /alerts/customers/10</p>&#xA;</blockquote>&#xA;"
43763418,How to update Update X509 certificates for On-Premise Service Fabric cluster,<microservices><azure-service-fabric>,1,288,2,0.0,4,"<p>The documentation for updating x509 certificates in Service Fabric is unclear to me with regards to non-Azure (On-Prem) installations: <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server</a></p>&#xA;&#xA;<p>I have followed these steps, but they have not worked.</p>&#xA;&#xA;<ol>&#xA;<li>Updated the cluster setup json template so that the thumbprint of the original certificate is now ""ThumbprintSecondary"".</li>&#xA;<li><p>Added the new certificate thumbprint under ""Thumbprint"". e.g.</p>&#xA;&#xA;<p>""security"": {&#xA;     ""metadata"": ""The Credential type X509 indicates this is cluster is &#xA;      secured using X509 Certificates. The thumbprint format is - d5 ec 42 3b 79 cb e5 07 fd 83 59 3c 56 b9 d5 31 24 25 42 64."",&#xA;        ""ClusterCredentialType"": ""X509"",&#xA;        ""ServerCredentialType"": ""X509"",&#xA;        ""CertificateInformation"": {&#xA;            ""ClusterCertificate"": {&#xA;                ""Thumbprint"": ""New Thumbprint"",&#xA;                ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;                ""X509StoreName"": ""My""&#xA;        },&#xA;        ""ServerCertificate"": {&#xA;        ""Thumbprint"": ""New Thumbprint"",&#xA;        ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;        ""X509StoreName"": ""My""&#xA;    },</p></li>&#xA;<li><p>Install the new certificate pfx and update the ACL for ""NETWORK SERVICE""</p></li>&#xA;<li>Run Start-ServiceFabricClusterConfigurationUpgrade -ClusterConfigPath ""Path to json Configuration File""</li>&#xA;</ol>&#xA;"
43785728,Where is the best place to do data aggregation for UI in microservices architecture,<rest><api><web><single-page-application><microservices>,1,716,3,0.0,4,"<p>I am building an application using microservice architecture. It has five Rest API and one UI(single page application) microservices. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DbuHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DbuHq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Could anyone advise me which is the best option to do the data aggregation? </p>&#xA;&#xA;<ol>&#xA;<li>Make UI application as a static web application and do all API requests from the front end (from the browser using javascript framework) and all data aggregation do in front end itself and render? </li>&#xA;<li>Make UI application as a dynamic web application and do all API request and data aggregation in web application backend?</li>&#xA;</ol>&#xA;"
43350853,Authentication with Kong,<django><authentication><microservices><restful-authentication><kong>,1,741,0,4.0,4,"<p>I'm looking at <a href=""https://getkong.org/"" rel=""nofollow noreferrer"">Kong</a> to replace my current hand-rolled NodeJS API gateway. Currently I have a user service that handles authentication (written in Django) by providing a JWT back upon login, which the client then passes in through a header. My current API gateway then intercepts any calls, does a validation call back to the user service, and replaces the JWT Header with <code>X-User-Id</code> and <code>X-User-Email</code>. </p>&#xA;&#xA;<p>As far as I can tell, Kong can do roughly the same thing. I'm trying to figure out the flow of how this should work <em>in a perfect world</em>. I still have the opportunity to replace much of the infrastructure, so rewriting some services is not completely out of the question. </p>&#xA;&#xA;<p>So, in my mind, what would happen is the following:</p>&#xA;&#xA;<ol>&#xA;<li>User registers on my site. I then create a new consumer with their username/id on Kong</li>&#xA;<li>User logs in. This is where I get stuck. Do I log in (or in this case, simply authenticate the user as being said user), ask Kong for the JWT for this consumer, and return that? What if I wanted some more data in the payload of the JWT? What happens on Kong's side when the JWT expires?</li>&#xA;<li>When the user requests a service, Kong will the sniff out the JWT from the headers, replace it with <code>X-Consumer-*</code> - is that correct? </li>&#xA;</ol>&#xA;&#xA;<p>Please do correct me if my thinking is wrong, or if there is a better way to achieve this. I'm fairly new to the whole microservices thing. </p>&#xA;"
42498492,Avoid bottlenecks in microservices,<microservices>,1,295,0,2.0,4,"<p>I'm going to apply Microservices for my Datawarehouse application. There are 4 main Microservices in application:</p>&#xA;&#xA;<p>1) Data Service: Import/Export external data sources to DWH and Query data from DWH.</p>&#xA;&#xA;<p>2) Analytics Service: for chart visualization on UI</p>&#xA;&#xA;<p>3) Machine Learning: for recommendation system</p>&#xA;&#xA;<p>4) Reports: for report generating</p>&#xA;&#xA;<p>The diagram as below:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/hW6lc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hW6lc.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each service has its own DB and they communicate directly with each other via TCP and Thift serialization. The problem here is Data Service suffer a high load from other services and can become a SPOF of application. Data in DWH is big too (maybe up to hundred miliions of records). How to avoid the bottlenecks for Data Service in this case? Or How do I define a properly bounded context to avoid the bottlenecks?</p>&#xA;"
38554037,How to deal with shared models in micro service architectures,<node.js><microservices>,3,1289,1,0.0,4,"<p>My goal is to create an architecture in which services should be able to deploy independent of each other and are completely autonomous, but what do you do when you have 2 services that reads from DB the same object type?</p>&#xA;&#xA;<p>In my case I have a socket server (micro service 1) and a http server (micro service 2). Using the http server my users creates an asset called: A, this asset gets stored on a DB and a mongoID is returned. Then, using another protocol and the ID, there are calls to the socket server that needs to check that validity of that ID, thus, needs to read from DB. This two services will have to share the model of A in order to map it to an object, but this means the 2 services will have to share code, and that's not ok.</p>&#xA;&#xA;<p>Do I need another service? or should I make only service1 able to read from DB and then make the second one talks to service 1?</p>&#xA;"
44355294,How to offer multiple versions of an API with different database schemas?,<database><versioning><microservices>,1,387,2,2.0,5,"<p>In Kevin Goldsmith's 2015 talk about <a href=""https://youtu.be/7LGPeBgNFuU?t=925"" rel=""noreferrer"">microservices at Spotify</a> (from 15:25 - 17:43), he mentions that when they create a new version of an API they just create a new server, and keep the old server running with the old version for as long as there are still clients calling it (in this case, a smart lamp with Spotify embedded on it).</p>&#xA;&#xA;<p>I am confused about how they would be able to maintain and offer older versions for potentially years, when surely there would be database schema changes during that timeframe?</p>&#xA;&#xA;<p>I can see a few possible solutions, but none of them seem very reasonable:</p>&#xA;&#xA;<ol>&#xA;<li>Using the same database across all versions, only ever add new tables, and new nullable fields. Never delete fields, nor rename fields, nor set fields to non-nullable, nor delete tables, nor rename tables.</li>&#xA;<li>Using a different database per version, keep each version's data separate.</li>&#xA;<li>Using a different database per version, keep each version's data separate, but write a way to migrate and pass the requests from one version to another, so that each version receives the request with the valid parameters for that version.</li>&#xA;</ol>&#xA;&#xA;<p>Solution 1 sounds like it would induce way too much code smell, with legacy code everywhere (which Kevin, in my opinion, seems to suggest they certainly do not do).</p>&#xA;&#xA;<p>Solution 2 sounds like a nightmare to pull data out of for other services, or for reporting. What if the information about an entity that you want is in another version's database than the one you request?</p>&#xA;&#xA;<p>Solution 3 sounds like more of a nightmare as you would have to write code to migrate a request for your version, to the versions above and below yours. This would mean that you can't just leave the existing (the one currently in production) version as-is when creating a new version, as you would need to add migrations to move the request both forward and backward so that all versions received the correct parameters for the request.</p>&#xA;&#xA;<p>Hopefully I am just missing something simple here, and there is a magic solution to make this problem easier, but I really cannot see how they could accomplish this?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
48900551,Why ESB is considered bad in microservices architecture,<architecture><microservices><distributed-computing><soa><esb>,1,1068,5,2.0,5,"<p>In microservices architecture, autonomous business services should talk directly with each other. The communication may be synchronous (orchestration) or event-based (choreography). An API gateway may aggregate the API's for the client (backends for frontends). With microservices we are seeking two ultimate goals</p>&#xA;&#xA;<ul>&#xA;<li>Low coupling</li>&#xA;<li>High cohesion</li>&#xA;</ul>&#xA;&#xA;<p>Which grants continuous deployment, fine-grained scaling, rapid technology adaptation, reusability, auditability an much more, of course for the price of higher complexity.</p>&#xA;&#xA;<p>However, it is highly discouraged to use ESB (Enterprise Service Bus) or other middleware. Microservices and ESB is often seen as an rival solutions. Why is an ESB seen so bad? As long as it is just used as an meditation channel with some additional monitoring and authentication layers (no business logic), what's the problem of using it in the microservice architecture?</p>&#xA;"
36627628,setting up Elasticsearch server for processing data from microservices,<ruby-on-rails><elasticsearch><architecture><microservices>,1,880,0,3.0,5,"<p>I am very new to elasticsearch and its scaling, and I've got a question I don't even know how to approach. </p>&#xA;&#xA;<p>Here's the situation:</p>&#xA;&#xA;<p>There're several servers with Rails microservice applications. Each of them is getting each its own pretty big piece of data (more specifically, aggregating posts from different social networks - so the indexable search fields are the same in all databases).</p>&#xA;&#xA;<p>I need to find a solution that would allow to keep the data where it currently is and setting up an elasticsearch server dedicated exclusively to searching through multiple databases without the respective Rails apps turning on this search server. It potentially means setting up ES on each of the other servers, defining the search patterns there but making the multiple-model search on a totally different server.</p>&#xA;&#xA;<p>The final goal of these manipulations should be sending the entire ActiveRecord objects / or all the related attributes to the main application.</p>&#xA;&#xA;<p>Is it even possible to achieve? Maybe anyone has had a similar problem? </p>&#xA;&#xA;<p>I am a little lost about how to get started with it.</p>&#xA;"
36680157,Communication between REST Microservices: Latency,<http><connection-pooling><microservices><http2>,3,2688,2,2.0,5,"<p>The problem I'm trying to solve is latency between Microservice communication on the backend. Scenario. Client makes a request to service A, which then calls service B that calls service C before returning a response to B which goes to A and back to the client.</p>&#xA;&#xA;<pre><code>Request: Client -&gt; A -&gt; B -&gt; C&#xA;Response: C -&gt; B -&gt; A -&gt; Client&#xA;</code></pre>&#xA;&#xA;<p>The microservices expose a REST interface that is accessed using HTTP. Where each new HTTP connection between services to submit requests is an additional overhead. I'm looking for ways to reduce this overhead without bringing in another transport mechanism into the mix (i.e. stick to HTTP and REST as much as possible). Some answers suggest using <a href=""https://stackoverflow.com/questions/35673254/communication-between-microservices"">Apache Thrift</a> but I'd like to avoid that. Other possible solutions are using Messaging Queues which I'd also like to avoid. (To keep operational complexity down).</p>&#xA;&#xA;<p>Has anyone experience in microservices communication using HTTP Connection pooling or HTTP/2? The system is deployed on AWS where service groups are fronted by a ELB. </p>&#xA;"
36792713,Dynamic component loading from external content,<angular><distributed><microservices><angular2-template>,3,1136,4,0.0,5,"<p>The system I am working on consists of a number of distributed microservices with potentially multiple versions of each component active at the same time.</p>&#xA;&#xA;<p>The Angular2 app I am attempting to build shall be able to interact with each of these components by means of websockets. Because it seems unfeasible to prepare this application for all future versions and features of each component, the respective protocol implementation and even new components, I would like to push this responsibility to the components itself. </p>&#xA;&#xA;<p>Each component is able to communicate its capabilities (in the form of a NG2 component) as well as the protocol implementation and the necessary GUI elements (HTML/CSS) via a package sent over the very same websocket connection.</p>&#xA;&#xA;<p>Is there a pattern that enables this kind of 'on-demand-loading' of components and their templates in ng2?</p>&#xA;"
41433856,emailing in microservice architecture,<rest><email><microservices><restful-architecture><email-integration>,1,1709,0,3.0,5,"<p>Sorry about my english - if some thing is not clear please ask me in comments - i will clarify this.</p>&#xA;&#xA;<p>I build system in microservice architecture. I have one service with user information, one service for ""offers"", and one service for ""ideas"". Services ""offers"" and ""ideas"" comunicate (by Restful API) with ""User"" service on login and other operations. And i wonder - how to deal with emails? Each service have it separate frontend and send emails after some actions (eg. when some third person open link with some offer the user who create this offer will get email, or when some user create idea the manager will get email). Moreover, on each service frontend, manager can create ""periodic"" mailing with season statistical data or just some other information. Each service email looks differently and have different content.</p>&#xA;&#xA;<p>I have many choices and don't know which will be better. This are some propositions:</p>&#xA;&#xA;<ol>&#xA;<li>Each service has his own separate emailing system and send all kinds&#xA;of email (after action, and periodic) independent. </li>&#xA;<li>The ""user service"" have ""engine"" to send action and periodic emails and other services give the task. Inside task there is link to service who give task and that link will generate email content (for example witch statistical data in periodic email). This solution is complicated...</li>&#xA;<li>The ""user service"" has only engine to periodic emails (tasks have link to generate email body...) but email after actions are send from each microservice indepenndent</li>&#xA;<li>Create new microservice only for sending email (periodic and ""after action"") with proper API. Ofcourse each service like ""offers"" should send also link (to themself) in mailing task - this link will be call when the periodic email will be send and the response of this link will be generated body of email....</li>&#xA;</ol>&#xA;&#xA;<p>Which one will be better? Or may be there is some better alternative? </p>&#xA;"
27865814,Does my concept follow a Microservice architecture?,<php><magento><soa><single-page-application><microservices>,2,5151,0,3.0,5,"<p>I read <a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">the article on Microservices</a> on Martin Fowler's page and find it quite interesting. Now I plan structuring an E-Commerce Web Application as proof-of-concept and am wondering if my concept is considered being a Microservice architecture.</p>&#xA;&#xA;<p>The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li>a javascript based single page application, which sends AJAX requests to</li>&#xA;<li>a server with a REST API which feeds JSON data received by calling other services (I think you call this behaviour API Gateway)</li>&#xA;<li>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento (PHP) Shopsystem. In future I plan to then swap the providers with other systems.</p>&#xA;&#xA;<p>So my questions are:</p>&#xA;&#xA;<ul>&#xA;<li><p>MS are considered to be 'independently deployable'. I understand that in the world of JAVA we are talking about one JAR- or WAR-file, but how is a PHP service 'independently deployable'?</p></li>&#xA;<li><p>Does my concept NOT follow the principles of a MS architecture, because the providers are all part of one big (Magento) system?</p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading. I'm happy for any suggestions.</p>&#xA;"
31046924,Building authentication with Microservices Architecture,<microservices>,3,3023,0,4.0,5,<p>I'm developing an app with microservices and I don't know how to distribute microservices to allow auth.</p>&#xA;&#xA;<p>I've read that each microservice should have its own database to avoid coupling.</p>&#xA;&#xA;<p>The problem is that Authentication (via JWT) and Users Microservices must have access to the same database and table (Users). I suppose this problem has been solved before due to similar applications having to deal with the same issue.</p>&#xA;&#xA;<p>How can I solve this?</p>&#xA;
29830038,Logging in microservices,<logging><tracing><microservices>,3,1836,0,5.0,5,"<p>assume we've got a number of Web API microservices, and they are written in different languages/framworks (some are ASP.NET Web API, some are NodeJS, some are Flask etc.).</p>&#xA;&#xA;<p>I would like to log every request made to any service, and I would prefer a centralized log.</p>&#xA;&#xA;<p>What method/tools should I use?</p>&#xA;&#xA;<p>Regards,&#xA;Daníel</p>&#xA;"
35673254,Communication Between Microservices,<rpc><thrift><microservices>,1,2549,4,2.0,5,"<p>Say you have microservice A,B, and C which all currently communicate through HTTP. Say service A sends a request to service B which results in a response. The data returned in that response must then be sent to service C for some processing before finally being returned to service A. Service A can now display the results on the web page. </p>&#xA;&#xA;<p>I know that latency is an inherent issue with implementing a microservice architecture, and I was wondering what are some common ways of reducing this latency? </p>&#xA;&#xA;<p>Also, I have been doing some reading on how Apache Thrift and RPC's can help with this. Can anyone elaborate on that as well?  </p>&#xA;"
46453981,How an authorization service implements ownership checks in a role-based microservice architecture,<design><architecture><authorization><microservices><soa>,2,162,0,2.0,5,"<p>Let's say I have three types of users on a blogging app</p>&#xA;&#xA;<ol>&#xA;<li><strong>Author</strong> (is able to modify their own posts but not others)</li>&#xA;<li><strong>Administrator</strong> (is able to modify all posts)</li>&#xA;<li><strong>Reader</strong> (can not modify any posts)</li>&#xA;</ol>&#xA;&#xA;<p>To manage this system I want to have three main services: </p>&#xA;&#xA;<ul>&#xA;<li>An <strong>API Gateway</strong> that exposes all the APIs clients will consume, composing services as needed. </li>&#xA;<li>A <strong>Post Management Service</strong> which provides the CRUD operations for blog posts (including the data of who owns what posts)</li>&#xA;<li>An <strong>Authorization Service</strong> which stores roles and permissions, exposing an API which takes in an array of roles (the roles a requesting user has) and an array of permissions (the permissions needed to access an API) and determines if those inputted roles cover all the permissions inputted. </li>&#xA;</ul>&#xA;&#xA;<p>Now what I am struggling with is ownership of a resource (and where ownership should be checked).</p>&#xA;&#xA;<p>Without communicating with other services how would an authorization service determine if a user should be able to access something they own without knowing how to determine if a user owns a given resource. </p>&#xA;&#xA;<p>I've come up with a few different solutions to this problem, although I'm not quite happy with any of them. </p>&#xA;&#xA;<ol>&#xA;<li>The API Gateway would query a different service that manages the posts to determine if a requesting user owns the post they are trying to access, this would mean there is authorization logic that happens outside of the authorization service.</li>&#xA;<li>The service managing blog posts would handle authorization based on ownership, this would also mean authorization logic is happening outside the authorization service as well as the fact that unauthorized requests are being marked as authorized initially (since they will still pass through the authorization service)</li>&#xA;<li>The Authorization service could be given the knowledge of how to check ownership, the API would have to be able to be told whether or not it should check for ownership along with the permissions. This would add complexity to the authorization service and increase the cross-service communication which I'd like to relegate as much as possible to the API gateway since it should be the primary service composer. </li>&#xA;</ol>&#xA;&#xA;<p>Looking for ideas on alternative methods or insight into what the best solution to this problem might be.</p>&#xA;"
46311488,Confused about ESBs as a solution to point-to-point integration,<architecture><microservices><esb>,4,675,0,0.0,5,"<p>Still very new to studying application architecture and having trouble stomaching some ideas in a book about microservices. In my readings, I have come across the older idea of the ESBs(Enterprise Service Bus) and its role in coordinating messages between new services and legacy applications. ESBs are touted as a solution to problems poised by point-to-point integration. Microservices seem to be the approach taken by newer companies as the de facto standard to creating an agile, scalable, and resilient app. But aren't microservices using point-to-point integration? Each node in an application built from microservices is communicating directly with other nodes, right? I feel I am connecting some dots that shouldn't be connected. Any help much appreciated, thanks in advance.</p>&#xA;"
33881958,Spring Oauth2 client credentials flow example,<java><spring-security><oauth-2.0><spring-security-oauth2><microservices>,1,1125,1,0.0,5,"<p>I am trying to implement service to service security into spring boot services using spring oauth2. I want a service to access a secured resource of another service without any user action involved.</p>&#xA;&#xA;<p>There are a lot of examples for authorization code grant type, but not very much about the client credentials grant type, which seems to be the right one for this use case.</p>&#xA;&#xA;<p>I can set up the auth server and use a curl request to get a token.&#xA;The tests I found used Http Objects to check status codes.</p>&#xA;&#xA;<p>How can I use the client credentials grant type in a java client with RestTemplate and spring oauth2?</p>&#xA;&#xA;<p>I would think it must be as simple as adding a dependency, an annotation and a config file, yet I can't make it run.</p>&#xA;"
38186942,Correlation Token for Service Fabric Actors and Services,<logging><token><actor><microservices><azure-service-fabric>,1,292,0,1.0,5,"<p>We started playing with Service Fabric as a microservice platform and after having succesfully implemented our firsts ""hello world"" samples about actor pattern, stateless/stateful services, web api (and so on) we are moving to looking solutions for other core aspects like auth/autz and application logging.</p>&#xA;&#xA;<p>I have a doubt about the Logging; in all the SOA we have designed till now we always added a ""correlation token"" to all the services involved (often at architectural level, automatically added as header onto WCF, hidden to the developers) so, now we are trying to do the same with Service Fabric.</p>&#xA;&#xA;<p>Looking for the best solution to let flow a ""Correlation Token"" through all the actor/service calls, since we haven't found out anything ready out-of-the-box, we are wondering if we are looking for something theoretically wrong.</p>&#xA;&#xA;<p>Any suggestion out there?</p>&#xA;"
39485459,Microservice Versioning,<architecture><versioning><soa><microservices>,4,834,0,1.0,5,"<p>What is the best practice to adapt for versioning in a Microservice Based Architecture, in terms of supporting multiple versioned deployment of the same service during runtime and how the consumers would be able to use different versions?&#xA;1) If we use Routing based Versioning as one of the approaches mentioned <a href=""http://niels.nu/blog/2016/microservice-versioning.html"" rel=""nofollow noreferrer"">here</a>&#xA;then I guess we would have the following drawbacks </p>&#xA;&#xA;<ol>&#xA;<li>Internal Services have to go through Reverse Proxy for consumption.</li>&#xA;<li>Consumers always have to be aware of the required versioning.</li>&#xA;</ol>&#xA;&#xA;<p>Is it a best practice to expose the version information to consumers?  </p>&#xA;&#xA;<p>In any case, as I feel, the following always applies:</p>&#xA;&#xA;<ol>&#xA;<li>For MAJOR version change, the consumers have to be changed.</li>&#xA;<li>For MINOR version change (backwards compatible), only the consumer(s) that requires the added functionality needs to change.</li>&#xA;<li>For PATCH version change, it's optional and would probably be seamless for any consumers to make use of it.</li>&#xA;</ol>&#xA;&#xA;<p>What kind of Microservice versioning strategy can help us in enabling the above?</p>&#xA;&#xA;<p>NOTE - Please feel free to let me know if this needs to be split in multiple questions.</p>&#xA;"
39450504,Serverless Framework - Two services under one APIGW endpoint,<microservices><amazon-cloudformation><aws-api-gateway><serverless-framework>,5,628,0,1.0,5,"<p>If I have two services, 'Users' and 'Products', each with several functions with endpoints defined for each one (as any traditional API would), is it possible for them to be organised separately in a code base (for clarity) but once deployed share the same API base URL? For example, consider I have the following structure:</p>&#xA;&#xA;<pre><code>/src&#xA;-- /users&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;-- /products&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/users/serverless.yml</code> has the following defined:</p>&#xA;&#xA;<pre><code>functions:&#xA;  create:&#xA;    handler: handler.create&#xA;    events:&#xA;      - http: POST user&#xA;&#xA;  read:&#xA;    handler: handler.read&#xA;    events:&#xA;      - http: GET user&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/products/serverless.yml</code> has basically the same thing, just swap 'user' for 'products'.</p>&#xA;&#xA;<p>Currently, both of those services will be deployed to distinctly different API endpoints, one with a URL <code>https://fghijklmnop.execute-api...</code> and another with a URL <code>https://abcdevwxyz.execute-api....</code> </p>&#xA;&#xA;<p>My question is, would it be possible to have these services be deployed but remain under a single API with a single URL (so both would be served under URL <code>https://abcdevwxyz.execute-api....</code>)?</p>&#xA;&#xA;<p>I'm assuming the answer to be, 'No, because Cloud Formation...', but I thought I would post the question here simply for the sake of discussion and to aid my own understanding of building serverless applications.</p>&#xA;&#xA;<p>I'm aware of using Custom Domains, as per <a href=""https://stackoverflow.com/questions/38408493/serverless-framework-v1-multiple-resources-in-one-service"">the answer here</a>, but for a quicker development cycle this is not really an ideal solution.</p>&#xA;&#xA;<p>My only solution so far would be to simply create a service called 'api' which would contain all the endpoints my API would need which would simply invoke my other services' Lambda functions directly rather than via previously-configured endpoints. It would be an abstraction layer, really, but add potentially unnecessary layers to my application. Again, curious to see what the community feels on this.</p>&#xA;"
47527983,Designing java project for monoliths and microservices at same time,<java><scope><package><domain-driven-design><microservices>,3,268,2,0.0,5,"<p>I would like to know how you divide project modules in java for monolith with possibility of transforming modules to micro-services later?<br>&#xA;My personal naming looks like this:</p>&#xA;&#xA;<pre><code>com.company.shopapp.product&#xA;...product.domain (ddd, services, repositories, entities, aggregates, command handlers - everything with package scope)&#xA;...product.api (everything with public scope)&#xA;...product.controller (CQRS endpoints for commands in web perspective - (package scope))&#xA;...product.query(CQRS - package scope)&#xA;&#xA;com.company.shopapp.sales&#xA;- domain&#xA;- api &#xA;- controller&#xA;- query &#xA;</code></pre>&#xA;&#xA;<p>What we have here is basically product management context and sales context as packages. </p>&#xA;&#xA;<p>Modules communicate each other using public interfaces (api package) only. In my project I use ""..api.ProductFacade"" to centralize communication points.</p>&#xA;&#xA;<p>When my ""sales"" module grow i will turn it into microservice by implementing ""..api.ProductFacade"" interface as a ""rest"" or ""soap"" client and on the other side I will create Endpoint/RestController based on ProductFacade interface.&#xA;Package ""com.company.shopapp.product.api"" will be transformed into extended library and added to both projects. </p>&#xA;&#xA;<p>Edit: &#xA;I can achive this out of the box using @Feign library.&#xA;<a href=""https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance"" rel=""nofollow noreferrer"">https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance</a></p>&#xA;&#xA;<p>The whole idea feels nice, but maybe you have better way to design project and ensure that breaking it into micro-services will not break whole application. </p>&#xA;"
47544877,Websockets in microservices architecture,<web-applications><websocket><microservices><api-gateway>,1,1872,5,0.0,5,"<p>Let's say we have a notification service which read an event from message queue and notify all web clients in real time. I know how web socket work but i am puzzled when there is an API gateway in between then how web socket connection is maintained between client, API gateway and notification service.</p>&#xA;&#xA;<p>Please help! Thanks</p>&#xA;&#xA;<p><strong>Edit:</strong>&#xA;Architecture:&#xA;<a href=""https://i.stack.imgur.com/wEeu3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wEeu3.jpg"" alt=""enter image description here""></a></p>&#xA;"
34295221,Microservices: decomposing a graph db based application,<graph-databases><microservices>,1,583,0,0.0,5,"<p>I'm planning to decompose an application I started to build as a monolith with a graph database into microservices. But the dilema i'm facing is trying to find a proper solution to split the different services and not loosing the benefits provided by the graph database. </p>&#xA;&#xA;<p>The idea I've considered initially is to split each different entity into it's own microservice, using a document store to persist the data on each service. And then define a higher level service to manage the relationships. </p>&#xA;&#xA;<p>For example with a relationship (A)-->(B), would produce 3 microservices, a service for entities of type A, another for the entities of type B, and a third higher level with a graph database, storing nodes of type A and B, containing only the ID's and the relationships between those. </p>&#xA;&#xA;<p><strong>Question 1</strong>: Is there anything wrong with this approach in terms of coupling, fault tolerance, or anything else that I can't think of right now?</p>&#xA;&#xA;<p><strong>Question 2</strong>: When you toss a third entity into the game, for example (A)-->(B), (A)-->(C) and (C)-->(B), which one would be the best approach in this scenario? </p>&#xA;&#xA;<ul>&#xA;<li>Do I stick to the strategy of just one higher level service to maintain all the relationships? </li>&#xA;<li>Do I generate several higher level services to maintain each type of relationship?</li>&#xA;</ul>&#xA;&#xA;<p><strong>Question 3</strong>: In the case of relationships between entities of the same type, for example (Person)--isFriendOf-->(Person), having in mind the concept of separation of concerns, is it appropiate to separate the management of the relationships into a different service?</p>&#xA;&#xA;<p>Any input, feedback and ideas are very welcome.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I've been doing some research on the subject, and for the sake of clarity, I'll propose a more concrete scenario, so it will be easier to discuss about it. &#xA;The graph model would be something like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/87MOt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/87MOt.png"" alt=""Graph relationships""></a></p>&#xA;&#xA;<p>The goal here would be to implement a song playlist recommendation service, trying to find the songs that a given user haven't listened yet, based on genres and artists from the songs that the user already listened, and also from other songs listened by other users, followed by the current user.</p>&#xA;"
46236744,Swagger for Event?,<events><swagger><microservices><event-driven>,4,327,1,0.0,5,"<p>The <a href=""https://github.com/OAI/OpenAPI-Specification"" rel=""nofollow noreferrer"">Swagger / OpenAPI specification</a> is useful to document and run automated tests against HTTP APIs. However, I run an event-driven microservices architecture and it is important to document the event payload passed among different services, even when they are not accessed via HTTP paths. Since eerything I've seen is API-based via HTTP paths, I'm wondering if Swagger handle this or, if not, is there anything similar for events?</p>&#xA;"
46244677,Verifying Access Token (JWT) in Each Service of a Microservices Architecture,<rest><authentication><architecture><cloud><microservices>,2,422,1,0.0,5,"<p>I have an application which is implemented using microservice architecture. There is an authentication service (A) which uses jwt standard, and there are other services in the application like S1, S2, S3 and so on.&#xA;Now for example S1 receives a request, it should validate the token to see if the user is authorized or not. The validation can be achieved by:</p>&#xA;&#xA;<ul>&#xA;<li>Sending the token from S1 to A, then A validates the token and sends the result to S1 (which is a kind of overhead)</li>&#xA;<li>Validating the token inside S1 (which is a duplicate action inside every service, also requires secret key or public/private keys inside each service,  for signing/verification)</li>&#xA;</ul>&#xA;&#xA;<p>I'm not asking about how these approaches work exactly. The questions is, which one of them is better? Or what is the best practice in this situation?</p>&#xA;"
40947247,"Event sourcing, CQRS and database in Microservice",<microservices><cqrs><event-sourcing>,1,1104,1,1.0,5,"<p>I am quite new in context of Micro-service architecture and reading this post : <a href=""http://microservices.io/patterns/data/event-sourcing.html"" rel=""noreferrer"">http://microservices.io/patterns/data/event-sourcing.html</a> to get familiar with Event sourcing and data storage in Microservice architecture. &#xA;I have read many documents about 3 important aspect of system :</p>&#xA;&#xA;<ol>&#xA;<li>Using event sourcing instead of a simply shared DB and ORM and&#xA;    row update</li>&#xA;<li>Events are JAVA objects. </li>&#xA;<li>In case of saving data permanently&#xA;    , we need to use DB (either relational or noSQL)</li>&#xA;</ol>&#xA;&#xA;<p>Here are my questions :</p>&#xA;&#xA;<ol>&#xA;<li><p>How database comes along with event sourcing? I have read CQRS&#xA;pattern, but I can not understand how CQRS pattern is related to&#xA;event store and event objects ?  </p></li>&#xA;<li><p>Can any body provide me a&#xA;    complete picture and set of operations happens with all players to&#xA;    gather: CQRS pattern , Event sourcing (including event storage&#xA;    module) and finally different microservices?</p></li>&#xA;<li>In a system&#xA;        composed of many microservices, should we have one event storage or&#xA;        each microservice has its own ? or both possible ?</li>&#xA;<li>same&#xA;    question about CQRS. This pattern is implemented in all&#xA;    microservices or only in one ?  </li>&#xA;<li>Finally, in case of using&#xA;        microservice architecture, it is mandatory to have only one DB or&#xA;        each Microserivce should have its own ?</li>&#xA;</ol>&#xA;&#xA;<p>As you can see, I have understood all small pieces of game , but I can not relate them together to compose a whole image. Specially relevance between CQRS and event sourcing and storing data in DB. &#xA;I read many articles for example :</p>&#xA;&#xA;<ul>&#xA;<li><a href=""https://ookami86.github.io/event-sourcing-in-practice/"" rel=""noreferrer"">https://ookami86.github.io/event-sourcing-in-practice/</a></li>&#xA;<li><a href=""https://msdn.microsoft.com/en-us/library/jj591577.aspx"" rel=""noreferrer"">https://msdn.microsoft.com/en-us/library/jj591577.aspx</a></li>&#xA;</ul>&#xA;&#xA;<p>But in all of them small players are discussed. Even a hand drawing piece of image will be appreciated. </p>&#xA;"
47050984,Enabling session in lumen framework,<laravel><microservices><lumen>,3,2894,12,1.0,5,"<p>I have two (but let's image more) micro-services (API) which need to be aware of authenticated user. Ideally I would simple like to resume their sessions.</p>&#xA;&#xA;<p>All micro-services are using same storage for sessions: redis.</p>&#xA;&#xA;<p>All API calls will have Cookie header, so all services will be able to resume sessions based on that cookie. I have successfully implemented this via PHP $_SESSIONs.</p>&#xA;&#xA;<p>Now the question: how would you go about implementing this with Laravel/Lumen?</p>&#xA;"
47647560,How to share entity between REST service between two microservices?,<java><rest><microservices>,3,643,2,2.0,5,<p>I have created two micro-services using java. I need to make a REST api call from service A to service B. The data sent will be in JSON format. Using jax-rs I need to create entity class in both the service.</p>&#xA;&#xA;<p>Since both the entity class be same in both the projects. Do i </p>&#xA;&#xA;<ul>&#xA;<li>Create an common jar and use is for all my entity/domain objects? Does this make my microservice more tightly coupled?</li>&#xA;<li>Do i create the same class in both the microservice projects? This will just mean repeating the work in both the projects?</li>&#xA;</ul>&#xA;&#xA;<p>Is there a better way to communicate between the sevices?</p>&#xA;
42486386,Does CQRS With OLTP and OLAP Databases Make Sense?,<api><olap><microservices><cqrs><oltp>,1,219,2,1.0,5,"<p>I have several OLTP databases with API's talking to them. I also have ETL jobs pushing data to an OLAP database every few hours.</p>&#xA;&#xA;<p>I've been tasked with building a custom dashboard showing hight level data from the OLAP database. I want to build several API's pointing to the OLAP database. Should I:</p>&#xA;&#xA;<ol>&#xA;<li>Add to my existing API's and call the OLAP database and use a CQRS type pattern, so reads come from OLAP, while writes come from OLTP. My concern here is that there could be a mismatch in the data between reads and writes. How mismatched the data is depends on how often you run the ETL jobs (Hours in my case).</li>&#xA;<li>Add to my existing API's and call the OLAP databases then ask the client to choose whether they want OLAP or OLTP data where API's overlap. My concern here is that the client should not need to know about the implementation detail of where the data is coming from.</li>&#xA;<li>Write new API's that only point to the OLAP database. This is a lot of extra work.</li>&#xA;</ol>&#xA;"
44085454,Join table between Different Microservices,<architecture><microservices>,3,2111,0,1.0,5,"<p>I am still trying to make sense of micro service architecture.</p>&#xA;&#xA;<p>The idea to separate different application (include the database) excites me. But I am still confused if there are two micro-services e.g. Product and User. both product and user own table product and user respectively in their database. According to best practice in micro service, we only can access the database from the service. </p>&#xA;&#xA;<p>The problem is, let us suppose we have product table that has user_id column. We want to do search product which also return the name of the user who create the product. This requires join between product table in product micro-service and user table in user micro-service. How do you handle this? </p>&#xA;"
45622414,Should there be authentication/authorization between microservices?,<soa><microservices>,3,1038,0,0.0,5,"<p>I know this may be not a good question.</p>&#xA;&#xA;<p>I was asked a question: do we really need authentication among microservices. And I have no idea the answer. I did read some tutorials on SOA, microservices, and how to add authentication among the services. But I did not have too many ideas <strong>why we need authentication/authorization between microservices? Any use cases where they are required? Any use cases where they are not required?</strong> Any potential risk without authentication/authorization? </p>&#xA;&#xA;<p>Any comments welcomed. It is better to give some practical examples. Thanks</p>&#xA;"
45655728,What is the real difference between an API and an microservice?,<api><microservices>,5,11680,0,2.0,5,"<p>I am learning about microservices and I don't understand what the real difference between creating a REST API and creating microservices is. I’m working in Go, but my question applies over all languages.</p>&#xA;"
29888108,How to call a microservice in .NET,<c#><.net><rest><asp.net-web-api><microservices>,4,11466,1,3.0,6,"<p>I've created a very simple REST microservice that receives information about an email and sends it. The microservice send method looks something like this:</p>&#xA;&#xA;<pre><code>//EmailController&#xA;[HttpPost]&#xA;public IHttpActionResult Send(Email email)&#xA;{&#xA;    // send email via exchange&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now in my application, I call it using RestSharp like this:</p>&#xA;&#xA;<pre><code>var client = new RestClient(""http://localhost:51467/api/"");&#xA;var request = new RestRequest(""email/send"", Method.POST);&#xA;request.RequestFormat = DataFormat.Json;&#xA;dynamic obj = new ExpandoObject();&#xA;obj.FromAddress = from;&#xA;obj.ToAddress = to;&#xA;obj.Subject = subject;&#xA;obj.Body = body;&#xA;&#xA;request.AddBody(obj);&#xA;client.Execute(request);&#xA;</code></pre>&#xA;&#xA;<p>Questions I have:</p>&#xA;&#xA;<ol>&#xA;<li><p>Is this the best way to do the call? Obviously i'll later have to add error handling etc, but I'm talking more the way I'm using RestSharp to do the call.</p></li>&#xA;<li><p>I'm finding it a bit uncomfortable that my app needs to kind of know what object the microservice expects to receive - there's no sort of definition/interface/contract that it uses to know for sure. Is this generally accepted as being ok for REST or should I implement some sort of interface that my app has so it can call my microservice in a bit more of a defined way. Is that even something possible with REST?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!</p>&#xA;"
26491425,Why should a 12 Factor app be self contained?,<java><paas><12factor><microservices>,2,1169,0,0.0,6,"<p>In the 12 Factor article on Port Binding&#xA;<a href=""http://12factor.net/port-binding"" rel=""nofollow noreferrer"">http://12factor.net/port-binding</a> there is a requirement that every app&#xA;be self-contained and not have a runtime injected e.g. Tomcat. For&#xA;what reason is this advised... what are advantages of self-contained apps for microservices?</p>&#xA;"
32470907,"Microservices - Maintaining Multiple Data stores, initial data load etc",<microservices>,1,547,2,1.0,6,"<p>On aspects of granulatiry of mictoservices have read about the 2 pizza rule, services that can be developed in 2 weeks etc.  When the case studies of amazon, nelflix, gilt are read we hear about 100s of services. While the service granularity does make sense, what is still not clear to me is about the data stores of each of these microservices. Will there not be just too many data stores if each of the services store/maintain their own data ?? It might be the same logical entity like a product, customer etc that is sliced &amp; the relevant portion/attributes stored/maintained by a corresponding microservice. There could be a service that maintains basic customer information, another that maintains the additional customer information like say his subscription information or his interests etc. </p>&#xA;&#xA;<p>Couple of questions that come to mind around the data stores</p>&#xA;&#xA;<ol>&#xA;<li>Will this not be a huge maintenance issue in terms of backups,&#xA;restores etc? </li>&#xA;<li>How is the initial data populated into these stores ? Are there any best practices around this ? Organisations are bound to have huge volumes of customer or product data &amp; they will most likely be mastered in other systems. </li>&#xA;<li>How does this approach of multiple data stores impact the 'omni-channel' approach where it  implies getting a single view of all data? Organizations might have had data consolidation initiatives going on to achieve the same</li>&#xA;</ol>&#xA;&#xA;<p>Edit: Edited the subject a bit</p>&#xA;"
30173267,Microservice Architecture- cross-domain chattiness,<architecture><soa><microservices>,3,808,6,3.0,6,"<p>I have a relatively new project that employs a microservice architecture. I feel pretty good about the size and granularity of the individual services, with the exception or our security service.</p>&#xA;&#xA;<p>I have three main services, let's say <code>foo-service</code>, <code>bar-service</code>, and <code>baz-service</code>. These services never need to communicate, but all three services regularly talk via HTTP requests to the <code>security-service</code>. I want this to stop for a variety of reasons- the biggest is that each request to my individual services spawns a request to the security service, which can turn into several extra hops once you account for load balancing, etc. I've been reading ""Software Architecture Patterns"" by Mark Richards, and he recommends in these instances you should share databases and violate DRY: copy the required functionality into each service. Still, he uses this example with smaller ""utility"" classes, which may not really apply in this instance. </p>&#xA;&#xA;<p>The security service isn't that big, so I could definitely copy it into each of the other services. That said, it's just big enough that I don't feel great copying and pasting it - 314 'relevant' lines of code according to coveralls (java so there's a lot more actual code ;-). I could easily turn it into a module that each service brings in- but then my services have a shared dependency and that has bit me in the past. Of course the security code will grow over time as we add authentication methods, but we aren't reinventing the wheel when it comes to auth so It's mostly integrating with other libraries and authentication services. That is, I don't imagine this particular code base getting huge.</p>&#xA;&#xA;<p>So my question, should I copy and paste the code or build a module that every service brings in? Thanks!</p>&#xA;"
38863827,How to handle REST API paths when related resources belong to different microservices?,<rest><microservices>,2,309,0,1.0,6,"<p>I have two microservices:</p>&#xA;&#xA;<ul>&#xA;<li>UserService, which defines paths such as /users, /users/:id;</li>&#xA;<li>MessageService, which defines paths such as /messages, /messages/:id.</li>&#xA;</ul>&#xA;&#xA;<p>Also, each message in MessageService has an attribute user_id which references a user in UserService.</p>&#xA;&#xA;<p>Now, lets say I want to list all messages of a given user. Right now I can think of the following approaches:</p>&#xA;&#xA;<ol>&#xA;<li>A path such as <strong>/users/:id/messages</strong> seems like the best approach if I want to follow the best REST API practices. However, it seems to me that I couldn't define such path inside MessageService because I would be tight-coupling it to UserService. I believe paths starting with /users should belong to UserService only.</li>&#xA;<li><strong>/messages?user_id=:id</strong> so I could use the existing /messages path and add a filter by attribute (user_id). Not sure if a good practice.</li>&#xA;<li>Put an API gateway in front of the microservices and create a proxy from <strong>/users/:id/messages</strong> to <strong>/messages?user_id=:id</strong>. This allows clients to use the most REST-friendly path while keeping the microservices loosely coupled.</li>&#xA;</ol>&#xA;&#xA;<p>Which of these approaches would be the most appropriate?</p>&#xA;"
42140285,How to implement a microservice Event Driven architecture with Spring Cloud Stream Kafka and Database per service,<apache-kafka><spring-cloud><microservices><spring-cloud-stream><spring-kafka>,2,2318,0,5.0,6,"<p>I am trying to implement an event driven architecture to handle distributed transactions. Each service has its own database and uses Kafka to send messages to inform other microservices about the operations.</p>&#xA;&#xA;<p>An example:</p>&#xA;&#xA;<pre><code> Order service -------&gt; | Kafka |-------&gt;Payment Service&#xA;       |                                       |&#xA;Orders MariaDB DB                   Payment MariaDB Database&#xA;</code></pre>&#xA;&#xA;<p>Order receives an order request. It has to store the new Order in its DB and publish a message so that Payment Service realizes it has to charge for the item:</p>&#xA;&#xA;<p>private OrderBusiness orderBusiness;    </p>&#xA;&#xA;<pre><code>@PostMapping&#xA;public Order createOrder(@RequestBody Order order){&#xA;    logger.debug(""createOrder()"");&#xA;    //a.- Save the order in the DB&#xA;    orderBusiness.createOrder(order);&#xA;    //b. Publish in the topic so that Payment Service charges for the item.&#xA;    try{&#xA;        orderSource.output().send(MessageBuilder.withPayload(order).build());&#xA;    }catch(Exception e){&#xA;        logger.error(""{}"", e);&#xA;    }&#xA;    return order;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>These are my doubts:</p>&#xA;&#xA;<ol>&#xA;<li>Steps a.- (save in Order DB) and b.- (publish the message) should be performed in a transaction, atomically. How can I achieve that?</li>&#xA;<li>This is related to the previous one: I send the message with: orderSource.output().send(MessageBuilder.withPayload(order).build()); This operations is asynchronous and ALWAYS returns true, no matter if the Kafka broker is down. How can I know that the message has reached the Kafka broker?</li>&#xA;</ol>&#xA;"
41655915,Microservices: Atomic Events,<database><events><microservices>,2,582,1,3.0,6,"<p>I'm learning about microservice data replication right now, and one thing I'm having trouble with is coming up with the right architecture for ensuring event atomicity.  The way I understand it, the basic flow is:</p>&#xA;&#xA;<ol>&#xA;<li>Commit changes to a database.</li>&#xA;<li>Publish an event detailing the changes on the global message bus.</li>&#xA;</ol>&#xA;&#xA;<p>But what if, for example, a power outage occurred in-between Steps 1 and 2?  In a naively-built system, that would mean the changes persist but the event detailing them will never be published.  I've pondered the following ideas to create better guarantees, but I'm not quite sure of all the pros and cons of each:</p>&#xA;&#xA;<p>A:  Use an embedded database (like SQLite) in my microservice instance to track the full transaction, from the commit to the main database to the event publishing.</p>&#xA;&#xA;<p>B:  Create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  The service would then push the Event to the bus, and then make another commit to the main database to mark the Event as Published.</p>&#xA;&#xA;<p>C:  As above, create an Events table in my main database, using database transactions to insert the Event and commit the relevant changes at the same time.  Then, notify (either manually via REST/Messages from within the service or via database hooks) a dedicated EventPusher service that a new event has been appended.  The EventPusher service will query the Events table and push the events to the bus, marking each one as Published upon acknowledgement.  Should a certain amount of time pass without any notification, the EventPusher will do a manual query.</p>&#xA;&#xA;<p>What are the pros and cons of each of the choices above?  Is there another superior option I have yet to consider?</p>&#xA;"
35882330,how to get my configuration values in yml - using dropwizard (microservice) Jersey D.I @Injection?,<java><jersey><dropwizard><inject><microservices>,1,4347,0,2.0,6,"<p>here's my code snippets.</p>&#xA;&#xA;<p>here's my yml file:</p>&#xA;&#xA;<pre><code>productionServer:&#xA;  host: production-server.amazonaws.com&#xA;  publicIp: xx.xx.xx.xx&#xA;  privateIp: xx.xx.xx.xx&#xA;  userName: xx.xx.xx.xx&#xA;  password: xx.xx.xx.xx&#xA;  remoteFilePath: fake/path/&#xA;  fileName: test.txt&#xA;  privateKey: private-public-key.ppk&#xA;&#xA;server:&#xA;  applicationConnectors:&#xA;    - type: http&#xA;      port: 8080&#xA;    - type: https&#xA;      port: 8443&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;  adminConnectors:&#xA;    - type: http&#xA;      port: 8081&#xA;    - type: https&#xA;      port: 8444&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;</code></pre>&#xA;&#xA;<p>MyConfiguration class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Configuration;&#xA;&#xA;public class MyConfiguration extends Configuration{&#xA;&#xA;    @NotNull&#xA;    @JsonProperty&#xA;    private ProductionServer productionServer;&#xA;&#xA;    // getters&#xA;&#xA;public class ProdctionServer{&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private host;&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private publicIp;&#xA;&#xA;      // getters&#xA;</code></pre>&#xA;&#xA;<p>Application class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Application;&#xA;&#xA;public class MyApplication extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    public static void main(String[] args) throws Exception{&#xA;        new MysApplication().run(args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public String getName(){ return ""micro-service""; }&#xA;&#xA;    @Override&#xA;    public void initialize(Bootstrap&lt;MyConfiguration&gt; bootstrap){}&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration conf, Environment environment ){&#xA;        final MyResource myResource = new MyResource();&#xA;        // health check&#xA;&#xA;        // environment.healthChecks().register(""template"",healthCheck);&#xA;&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println( ""==&gt; "" + conf.getProductionServer() );&#xA;&#xA;        // register&#xA;        environment.jersey().register( MyResource );&#xA;</code></pre>&#xA;&#xA;<p>and when running this app:</p>&#xA;&#xA;<p>i received a logged as follows:</p>&#xA;&#xA;<pre><code>==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@623e088f, io.dropwizard.jetty.HttpsConnectorFactory@39fcbef6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34f22f9d, io.dropwizard.jetty.HttpsConnectorFactory@77d67cf3], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@663411de]}}&#xA;==&gt; com.mycompany.myproject.model.ProductionServer@5b04476e&#xA;</code></pre>&#xA;&#xA;<p>meaning it is successfully gets the value of my yaml.&#xA;but my problem is during the D.I or dependency injection of MyConfiguration class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service. </p>&#xA;&#xA;<p>here's my code snippet of dependency binding the MyService.class and the MyConfiguration.class </p>&#xA;&#xA;<p>DependencyBinder.class</p>&#xA;&#xA;<p>import org.glassfish.hk2.utilities.binding.AbstractBinder;</p>&#xA;&#xA;<p>public class DependencyBinder extends AbstractBinder {</p>&#xA;&#xA;<pre><code>@Override&#xA;protected void configure() {&#xA;    bind(MyConfiguration.class).to(MyConfiguration.class);&#xA;    bind(MyService.class).to(MyService.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>public class MyService {&#xA;&#xA;    @Inject&#xA;    MyConfiguration conf;&#xA;&#xA;    public void invoke(){&#xA;        System.out.println( ""=============================== "" );&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println(""==&gt; "" + conf.getProductionServer() );&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>and during the invoking of the method invoke()...&#xA;i got a logged as follows:</p>&#xA;&#xA;<pre><code>=============================== &#xA;==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34e82c4d], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@19b70fbd], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@543f81c9]}}&#xA;==&gt; null&#xA;</code></pre>&#xA;&#xA;<p>now my problem is during the D.I or dependency injection of MyConfiguration class in MyService.class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service.&#xA;please give me some resolution? thnx.</p>&#xA;"
34023438,microservices: How to model related domain objects?,<soa><microservices>,1,353,0,1.0,6,"<p>I have 2 domain objects: Project and Contract. A project can have many contracts so in the database it is modeled as a classic one-to-many relationship. Our question is this: How do you model the above in the context of microservices? Do you (a) have 2 microservices ProjectService and ContractService? or (b) Do you have one ProjectService which encompasses both Projects and Contracts?</p>&#xA;&#xA;<p>We are thinking that answer (a) (i.e. 2 microservices ProjectService and ContractService) implies that one would have to call 2 services to retrieve and save the complete Project object hierarchy. On the other hand, answer (a) completely decouples Projects from Contracts which may be a good thing in theory, but practically useless since a Contract cannot logically exist without a Project.</p>&#xA;&#xA;<p>What is the correct approach here? Is answer (a) an example of the nano service anti pattern?</p>&#xA;"
33952306,"Microservice, amqp and service registry / discovery",<rest><architecture><amqp><microservices><service-discovery>,1,767,1,1.0,6,"<p>I m studying Microservices architecture and I m actually wondering something.</p>&#xA;&#xA;<p>I m quite okay with the fact of using (back) service discovery to make request able on REST based microservices. I need to know where's the service (or at least the front of the server cluster) to make requests. So it make sense to be able to discover an ip:port in that case.</p>&#xA;&#xA;<p>But I was wondering what could be the aim of using service registry / discovery when dealing with AMQP (based only, without HTTP possible calls) ?</p>&#xA;&#xA;<p>I mean, using AMQP is just like ""I need that, and I expect somebody to answer me"", I dont have to know who's the server that sent me back the response.</p>&#xA;&#xA;<p>So what is the aim of using service registry / discovery with AMQP based microservice ?</p>&#xA;&#xA;<p>Thanks for your help</p>&#xA;"
34794630,Micro service security,<c#><microservices>,2,1298,7,2.0,6,"<p>Over the last few days I've been playing with the micro service pattern and all is going well but security seems to baffle me.</p>&#xA;&#xA;<p><strike>&#xA;So If I may ask a question:&#xA;How do I handle user authentication on an individual service? At the moment I pass a request to the <code>Gateway API</code> which in turns connects to the service.&#xA;</strike></p>&#xA;&#xA;<p><strong>Question Edited Please See Below</strong></p>&#xA;&#xA;<p>Bearing in mind that the individual services should not know about each other. The <code>Gateway</code> is the aggregator as such. </p>&#xA;&#xA;<p><strong>Current architecture.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/60tiY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60tiY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>A little code to simulate the request:</p>&#xA;&#xA;<p><strong>Frontend - Client App</strong></p>&#xA;&#xA;<pre><code>public class EntityRepository&lt;T&gt;&#xA;{&#xA;    private IGateway _gateway = null;&#xA;    public EntityRepository(IGateway gateway)&#xA;    {&#xA;        this._gateway = gateway;&#xA;    }&#xA;    public IEnumerable&lt;T&gt; FindAll()&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;IEnumerable&lt;T&gt;&gt;().Result;&#xA;    }&#xA;    public T FindById(int id)&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;T&gt;().Result;&#xA;    }&#xA;    public void Add(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Update(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Save(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;}&#xA;&#xA;&#xA;   //Logic lives elsewhere&#xA;   public HttpResponseMessage Get(Type type)&#xA;   {&#xA;      return Connect().GetAsync(Path(type)).Result;&#xA;   }&#xA;   public HttpResponseMessage Post(Type type, dynamic obj)&#xA;   {&#xA;      return Connect().PostAsync(Path(type), obj);&#xA;   }&#xA;    private string Path(Type type)&#xA;    {&#xA;        var className = type.Name;&#xA;        return ""api/service/"" + Application.Key + ""/"" + className;&#xA;    }&#xA;    private HttpClient Connect()&#xA;    {&#xA;        var client = new HttpClient();&#xA;        client.BaseAddress = new Uri(""X"");&#xA;&#xA;        // Add an Accept header for JSON format.&#xA;         client.DefaultRequestHeaders.Accept.Add(&#xA;         new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;&#xA;        return client;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>I use generics to determine where it needs to fire once it hit's the gateway.&#xA;So if the <code>Type</code> is <strong>Category</strong> it will fire the <strong>Category</strong> service thus calling:</p>&#xA;&#xA;<pre><code>public IEnumerable&lt;dynamic&gt; FindAll(string appKey, string cls)&#xA;{&#xA;    var response = ConnectTo.Service(appKey, cls);&#xA;    return (appKey == Application.Key) ? (response.IsSuccessStatusCode) ? response.Content.ReadAsAsync&lt;IEnumerable&lt;dynamic&gt;&gt;().Result : null : null;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The Gateway does not contain the physical files/Class's of the types.</p>&#xA;&#xA;<p>After a little code, I was hoping someone could give me a little demonstration or the best approach to handle security/user authentication with the current architecture.</p>&#xA;&#xA;<p><strong>Case Scenario 1</strong>&#xA;User hits the web app and logs in, at that point the users encrypted email and password is sent to the <code>Gateway API</code> which is then passed to the <code>User Service</code> and decides whether the user is authenticated - all well and good but now I want to fetch all Messages from the <code>Message Service</code> that the user has received. I cannot really say in the Gateway if the user is authenticated, fetch the messages because that does not solve the issue of calling the <code>Message Service</code> outside of the <code>Gateway API</code></p>&#xA;&#xA;<p>I also cannot add authentication to each individual service because that would require all respective services talking to the <code>User Service</code> and that defeats the purpose of the pattern.</p>&#xA;&#xA;<p><strong>Fixes:</strong>&#xA;Only allow the Gateway to call the Services. Requests to services outside of the Gateway should be blocked.</p>&#xA;&#xA;<p>I know security is a broad topic but within the current context, I'm hoping someone could direct me with the best course of action to resolve the issue.</p>&#xA;&#xA;<p>Currently I have Hardcoded a <code>Guid</code> in all off the applications, which in turn fetches data if the app is equal.</p>&#xA;"
39920488,What is the role of falcor in a microservice architecture?,<microservices><falcor>,2,1336,0,4.0,6,"<p>Say we have following taxi-hailing application that is composed of loosely coupled microservices:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QgctP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QgctP.png"" alt=""https://www.nginx.com/blog/introduction-to-microservices/""></a></p>&#xA;&#xA;<p><em>The example is taken from <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/introduction-to-microservices/</a></em></p>&#xA;&#xA;<p>Each services has its own rest api and all services are combined in a single api gateway. The client does not talk to a single service but to the gateway. The gateway requests information from several services and combines them to a single response. For the client it looks like it is talking to a monolithic application.</p>&#xA;&#xA;<p><strong>I am trying to understand: where could we incorporate falcor into this application?</strong></p>&#xA;&#xA;<p><strong>One Model Everywhere</strong> from <a href=""http://netflix.github.io/falcor/"" rel=""nofollow noreferrer"">http://netflix.github.io/falcor/</a> </p>&#xA;&#xA;<blockquote>&#xA;  <p>Falcor lets you represent all your remote data sources as a single&#xA;  domain model via a virtual JSON graph. You code the same way no matter&#xA;  where the data is, whether in memory on the client or over the network&#xA;  on the server.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this taxi-hailing application each microservice represents a single domain model already. Can you think of any benefit we could thrive by wrapping each microservice with falcor? I cannot.</p>&#xA;&#xA;<p>However I think it is very convenient to incorporate falcor into the api gateway because we can abstract away the different domain models created by the microservices into one single or at least a few models.</p>&#xA;&#xA;<p>What is your opinion?</p>&#xA;"
40222469,"GraphQL: Filtering, sorting and paging on nested entities from separate data sources?",<microservices><graphql><graphql-js><apollo-server>,1,2634,3,1.0,6,"<p>I'm attempting to use graphql to tie together a number of rest endpoints, and I'm stuck on how to filter, sort and page the resulting data.  Specifically, I need to filter and/or sort by nested values.   </p>&#xA;&#xA;<p>I cannot do the filtering on the rest endpoints in all cases because they are separate microservices with separate databases.  (i.e. I could filter on <code>title</code> in the rest endpoint for articles, but not on author.name). Likewise with sorting.  And without filtering and sorting, pagination cannot be done on the rest endpoints either.</p>&#xA;&#xA;<p>To illustrate the problem, and as an attempt at a solution, I've come up with the following using <code>formatResponse</code> in <a href=""https://github.com/apollostack/graphql-server"" rel=""noreferrer"">apollo-server</a>, but am wondering if there is a better way.</p>&#xA;&#xA;<p>I've boiled down the solution to the most minimal set of files that i could think of:</p>&#xA;&#xA;<p>data.js represents what would be returned by 2 fictional rest endpoints:</p>&#xA;&#xA;<pre><code>export const Authors = [{ id: 1, name: 'Sam' }, { id: 2, name: 'Pat' }];&#xA;&#xA;export const Articles = [&#xA;  { id: 1, title: 'Aardvarks', author: 1 },&#xA;  { id: 2, title: 'Emus', author: 2 },&#xA;  { id: 3, title: 'Tapir', author: 1 },&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>the schema is defined as:</p>&#xA;&#xA;<pre><code>import _ from 'lodash';&#xA;import {&#xA;  GraphQLSchema,&#xA;  GraphQLObjectType,&#xA;  GraphQLList,&#xA;  GraphQLString,&#xA;  GraphQLInt,&#xA;} from 'graphql';&#xA;&#xA;import {&#xA;  Articles,&#xA;  Authors,&#xA;} from './data';&#xA;&#xA;const AuthorType = new GraphQLObjectType({&#xA;  name: 'Author',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    name: {&#xA;      type: GraphQLString,&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const ArticleType = new GraphQLObjectType({&#xA;  name: 'Article',&#xA;  fields: {&#xA;    id: {&#xA;      type: GraphQLInt,&#xA;    },&#xA;    title: {&#xA;      type: GraphQLString,&#xA;    },&#xA;    author: {&#xA;      type: AuthorType,&#xA;      resolve(article) {&#xA;        return _.find(Authors, { id: article.author })&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;const RootType = new GraphQLObjectType({&#xA;  name: 'Root',&#xA;  fields: {&#xA;    articles: {&#xA;      type: new GraphQLList(ArticleType),&#xA;      resolve() {&#xA;        return Articles;&#xA;      },&#xA;    }&#xA;  }&#xA;});&#xA;&#xA;export default new GraphQLSchema({&#xA;  query: RootType,&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>And the main index.js is:</p>&#xA;&#xA;<pre><code>import express from 'express';&#xA;import { apolloExpress, graphiqlExpress } from 'apollo-server';&#xA;var bodyParser = require('body-parser');&#xA;import _ from 'lodash';&#xA;import rql from 'rql/query';&#xA;import rqlJS from 'rql/js-array';&#xA;&#xA;import schema from './schema';&#xA;const PORT = 8888;&#xA;&#xA;var app = express();&#xA;&#xA;function formatResponse(response, { variables }) {&#xA;  let data = response.data.articles;&#xA;&#xA;  // Filter&#xA;  if ({}.hasOwnProperty.call(variables, 'q')) {&#xA;    // As an example, use a resource query lib like https://github.com/persvr/rql to do easy filtering&#xA;    // in production this would have to be tightened up alot&#xA;    data = rqlJS.query(rql.Query(variables.q), {}, data);&#xA;  }&#xA;&#xA;  // Sort&#xA;  if ({}.hasOwnProperty.call(variables, 'sort')) {&#xA;    const sortKey = _.trimStart(variables.sort, '-');&#xA;    data = _.sortBy(data, (element) =&gt; _.at(element, sortKey));&#xA;    if (variables.sort.charAt(0) === '-') _.reverse(data);&#xA;  }&#xA;&#xA;  // Pagination&#xA;  if ({}.hasOwnProperty.call(variables, 'offset') &amp;&amp; variables.offset &gt; 0) {&#xA;    data = _.slice(data, variables.offset);&#xA;  }&#xA;  if ({}.hasOwnProperty.call(variables, 'limit') &amp;&amp; variables.limit &gt; 0) {&#xA;    data = _.slice(data, 0, variables.limit);&#xA;  }&#xA;&#xA;  return _.assign({}, response, { data: { articles: data }});&#xA;}&#xA;&#xA;app.use('/graphql', bodyParser.json(), apolloExpress((req) =&gt; {&#xA;  return {&#xA;    schema,&#xA;    formatResponse,&#xA;  };&#xA;}));&#xA;&#xA;app.use('/graphiql', graphiqlExpress({&#xA;  endpointURL: '/graphql',&#xA;}));&#xA;&#xA;app.listen(&#xA;  PORT,&#xA;  () =&gt; console.log(`GraphQL Server running at http://localhost:${PORT}`)&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>For ease of reference, these files are available at <a href=""https://gist.github.com/scags9876/d96da7c2dbc98c43f8d735447928480a"" rel=""noreferrer"">this gist</a>.</p>&#xA;&#xA;<p>With this setup, I can send this query:</p>&#xA;&#xA;<pre><code>{&#xA;  articles {&#xA;    id&#xA;    title&#xA;    author {&#xA;      id&#xA;      name&#xA;    }&#xA;  } &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Along with these variables (It seems like this is not the intended use for the variables, but it was the only way I could get the post processing parameters into the formatResponse function.):</p>&#xA;&#xA;<pre><code>{ ""q"": ""author/name=Sam"", ""sort"": ""-id"", ""offset"": 1, ""limit"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>and get this response, filtered to where Sam is the author, sorted by id descending, and getting getting the second page where the page size is 1.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Or these variables:</p>&#xA;&#xA;<pre><code>{ ""sort"": ""-author.name"", ""offset"": 1 }&#xA;</code></pre>&#xA;&#xA;<p>For this response, sorted by author name descending and getting all articles except the first.</p>&#xA;&#xA;<pre><code>{&#xA;  ""data"": {&#xA;    ""articles"": [&#xA;      {&#xA;        ""id"": 1,&#xA;        ""title"": ""Aardvarks"",&#xA;        ""author"": {&#xA;          ""id"": 1,&#xA;          ""name"": ""Sam""&#xA;        }&#xA;      },&#xA;      {&#xA;        ""id"": 2,&#xA;        ""title"": ""Emus"",&#xA;        ""author"": {&#xA;          ""id"": 2,&#xA;          ""name"": ""Pat""&#xA;        }&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, as you can see, I am using the formatResponse function for post processing to do the filtering/paging/sorting.   .</p>&#xA;&#xA;<p>So, my questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Is this a valid use case?</li>&#xA;<li>Is there a more canonical way to do filtering on deeply nested properties, along with sorting and paging?</li>&#xA;</ol>&#xA;"
41161769,Authorisation in microservices - how to approach domain object or entity level access control using ACL?,<spring><security><authorization><acl><microservices>,1,948,2,1.0,6,"<p>I am currently building microservices based system on java Spring Cloud. Some microservices use PostgreSQL and some of them MongoDB. REST and JMS is used for communication. The plan is to use SSO and OAuth2 for authentication</p>&#xA;&#xA;<p>The challenge I am facing is that authorisation have to be done on domain object/entity level. It means some kind of ACL (Access Control List) is needed. The best practice for this kind of architecture is to avoid something like this and have coarse grained security probably on application/service layer level in every microservice but unfortunately it is not possible.</p>&#xA;&#xA;<p>My final idea is to use Spring Security ACL and have the ACL tables in shared database between all microservices. The database would be accessed only by Spring infrastructure or through Spring api. The DB schema looks stable and unlikely will change. In this case I would simply break the rule about sharing db between microservices.</p>&#xA;&#xA;<p>I was considering different kinds of distributed solutions but left them: </p>&#xA;&#xA;<ul>&#xA;<li>One microservice with ACL and accessing it using rest - The problem is too many http calls and performance degradation. I would have to extend Spring Security ACL to replace db access by rest calls</li>&#xA;<li>ACL in every microservice for its own entities - Sounds quite reasonable but imagine a case having some read models of entities synchronised to some other microservices or same entity that exists in different bounded contexts (different microservices). ACLs can become really unmanageable and can be source of errors.</li>&#xA;<li>One microservice with ACL tables that are synchronised to other microservices as a read model. The problem is that there is no support in Spring Security ACL for MongoDB. I have seen some custom solutions on github and yes it is doable. But...when creating a new entity I have to create record in the microservice  that owns ACL and then it is asynchronously synchronised as a read model to microservice owning the entity. It does not sound as a easy solution</li>&#xA;<li>Choose some URL based access control on API gateway. But I would have to modify Spring Security ACL somehow. The API gateway would have to know too much about other services. Granularity of access control is bound to REST api granularity. Maybe I can not imagine all the consequences and other problems that would this approach bring</li>&#xA;<li>Finally the solution with shared db that I mentioned is my favorite. Actually it was the first one I have disqualified because it is “shared” database. But after going through possibilities it seemed to me that this is the only one that would work. There is some more additional complexity in case I would like to use some kind of caching because distributed cache would be needed.</li>&#xA;</ul>&#xA;&#xA;<p>I would really use some advice and opinions how to approach the architecture because this is really tricky and a lot of things can go wrong here.</p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>Lukas</p>&#xA;"
34442192,Api gateway or No Api Gateway,<microservices>,1,1401,1,0.0,6,"<p>I am developing an application based on the <code>microservice architecture</code>. Here, each <code>service</code> is an independently deployable <code>play-scala application</code> exposing <code>rest apis</code>. I want to implement an <code>Api gateway</code> on top of these services for mapping incoming requests.I am following the architecture discussed here :<a href=""http://%20https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""nofollow noreferrer"">Building Microservices</a></p>&#xA;&#xA;<p>There are very few projects with substantial maturity that are based on the microservice architecture. One of them is <a href=""https://github.com/theiterators/reactive-microservices#master"" rel=""nofollow noreferrer"">Reactive Microservices</a>.But this project is not using the <code>api gateway pattern</code> and seems to be following the <a href=""http://www.infoq.com/articles/seven-uservices-antipatterns"" rel=""nofollow noreferrer"">Anti Pattern</a> There is an <a href=""https://github.com/theiterators/reactive-microservices/issues/10"" rel=""nofollow noreferrer"">issue</a> opened for this project regarding the missing Api Gateway here .The contributors here claim that they did not follow the <code>api gateway pattern</code> because it has the risk of <code>single-point of failure</code>. </p>&#xA;&#xA;<p>This varying opinion is very confusing to me. So,I am looking for the suggestions on whether I should be using Api Gateway or not. <code>What is the right practice here ?</code> </p>&#xA;"
44610425,Good practices to propagate errors through micro services,<rest><api><http><microservices><restful-architecture>,2,445,3,0.0,6,"<p>We have a micro services architecture and we are having some discussions about how to expose internal errors to the client.</p>&#xA;&#xA;<p>Here's an example:</p>&#xA;&#xA;<p>Let's suppose we have 3 services, service A, B and C.&#xA;When the client sends a request to the service A, which is public, this service sends a request to service B that sends a request to service C (which are internal and needs authentication, but the credentials are stored internally like environment variables, they are not send by the client).</p>&#xA;&#xA;<p>And for some reason the communication between B and C receives a 401 (could be 422, 403 or any client related errors), which means that the request was not authorized.</p>&#xA;&#xA;<p>Something like that:<a href=""https://i.stack.imgur.com/NmQB7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NmQB7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The communication between B and C is internal, the user don't know about these services. Should I expose our internal structure sending a 401 to the client? Given it's not the client's fault? Should I send a 500?</p>&#xA;"
45453061,What is the difference between microservices and webservices?,<web-services><microservices>,3,3866,1,1.0,6,"<p>The closest I got to finding the actual difference is this <a href=""http://www.tatvasoft.com/blog/the-difference-between-micro-services-and-web-services/"" rel=""nofollow noreferrer"">article</a>.</p>&#xA;&#xA;<p>But I didn't understand what would make me choose one over the other and if microservices can also use a REST API and communicate via http.</p>&#xA;&#xA;<p>I mainly didn't understand what a microservice is and if it can come instead of a webservice, other than the purpose of </p>&#xA;&#xA;<blockquote>&#xA;  <p>breaking large software applications into loosely coupled modules</p>&#xA;</blockquote>&#xA;"
43290480,Using celery to build microservices,<python-2.7><celery><microservices><celerybeat>,1,1023,0,3.0,6,"<p>I am going break down a project into small microservices.</p>&#xA;&#xA;<p>All microservices are cron-based. I am thinking of celery as a task distribution as well a mechanism to run periodic tasks (celerybeat).</p>&#xA;&#xA;<p>I don't want to build multiple celery app per microserverice as that will increase overhead of having multiple brokers and multiple flower system to use for monitoring.</p>&#xA;&#xA;<p>I tried with single app on multiple servers but I failed. My needs with celery are :</p>&#xA;&#xA;<ol>&#xA;<li>I need to have independent servers for each microservice </li>&#xA;<li>Task belonging to certain microservice should execute only on their servers; no sharing of task among other servers</li>&#xA;<li>In case microservice is down i don't want celerybeat to clog the broker with thousands of pending tasks, resulting in halting service at other microservices. </li>&#xA;<li>In do not have any need of communication between microservices.</li>&#xA;</ol>&#xA;&#xA;<p>I tried separating queues per worker which doesn't seem to be possible&#xA;I tried one worker per server but i need more than one worker on per microservices</p>&#xA;"
37830008,Handling multiple event dependency in event-driven architecture,<publish-subscribe><microservices><event-driven>,2,348,0,2.0,6,<p>What would be best practice if you have an event-driven architecture and a service subscribing to events has to wait for multiple event (of the same kind) before proceeding with creating the next event in the chain?</p>&#xA;&#xA;<p>An example would be a book order handling service that has to wait for each book in the order to have been handled by the warehouse before creating the event that the order has been picked so that the shipping service (or something similar) picks up the order and starts preparing for shipping.</p>&#xA;
40660618,AWS API Gateway + Elastic Beanstalk and Microservices,<amazon-web-services><elastic-beanstalk><microservices><aws-api-gateway>,1,4604,1,3.0,6,"<p>I'm going to build microservices' architecture on AWS and I want to ask you to clarify my doubts.</p>&#xA;&#xA;<p><strong>My current general concept</strong></p>&#xA;&#xA;<p>I would like to use API Gateway, which exposes microsevices' APIs running in Elastic Beanstalk. I would like to place the Elastic Beanstalk in VPC without direct access from Internet to its instances.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6BQi4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6BQi4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Questions &amp; Doubts:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Elastic Beanstalk gets subdomain on application creation. This subdomain should be used by API Gateway with integration type: AWS service, in action configuration - Am I right?</li>&#xA;<li>What would represent a single microservice? An Elastic Beanstalk's application is a specific scalable microservice?</li>&#xA;<li>How the microservices should communicate with each other? There would be some task where Im going to use SQS (Simple Queue Service). But in other cases, is it better when two microservices communicates with each other through API Gateway rather than directly - am I right?</li>&#xA;<li>Test environment: What structure should I use in test environment (or staging env.)? I think about creating separate VPC with another Elastic Beanstalk and other Amazon services.</li>&#xA;<li>Test environment and API Gateway: How should I set up an API Gateway? It should allow clients to access the microservices in test environment if request has specific subdomain, like: test.mydomain.com/hello_world/say_hello. I'm not sure how to use API Gateway in CI/CD to make it fast and simple, without manual copying some configuration from test stage to the production stage. (I'm not expecting any complex solution, only some hints about what components, parts, concepts could I use for it. More details I'll find on my own).</li>&#xA;<li>Have you any experience in deploying apps to Elastic Beanstalk using Codep Deploy and/or Jenkins? I'm interesting in which way could be better: Jenkins, AWS Code Deploy or Jenkins+CodeDeploy.</li>&#xA;</ol>&#xA;"
38565470,Can Service Fabric Cluster Maintains the old versions of a service?,<azure><microservices><azure-service-fabric>,1,327,1,0.0,6,"<p>I have a Micro Service in service fabric cluster which is a V1 for example. Now I upgraded it to the new version lets say v2. After a successful upgrade, Service Fabric replaced the old version with the new version of micro service. But I want to have and communicate with both versions of services. Can I achieve this in Service Fabric? If yes can anyone help me out on this?</p>&#xA;&#xA;<p>-Kishore.</p>&#xA;"
44065208,Data integrity across the databases of different Microservices,<database><foreign-keys><relational-database><rdbms><microservices>,1,801,4,0.0,6,"<p>Let's say I am using relational databases for my microservices. I have <code>CustomersMService</code> which has its own database with table <code>Customer</code>, then I have <code>OrdersMService</code> which also has its own database but with table <code>Order</code> and that table has column <code>CustomerId</code>. My question is how can I ensure data integrity between databases, that <code>Orders</code> table won't point to non-existent Customers?</p>&#xA;"
30908112,Micro Service cross service dependencies,<architecture><microservices>,3,3388,1,2.0,7,"<p>Just to simplify my situation I currently have 3 micro services.</p>&#xA;&#xA;<ol>&#xA;<li>Authentication</li>&#xA;<li>Locations</li>&#xA;<li>Inventory</li>&#xA;</ol>&#xA;&#xA;<p>The authentication service authenticates the user and sends back a JWT access token and I use that across the other services. Its stateless and all works well.</p>&#xA;&#xA;<p>I setup locations among some other things in the location service and this works well and as expected.</p>&#xA;&#xA;<p>But now I am at the inventory service and I need to add some inventory but it is linked to a location. I can easily pass the locationId in the API call but I have no way of authorizing the current user to add something to that location unless I then call the location service to validate this.</p>&#xA;&#xA;<p>This then creates service dependencies between each other and it is something I am trying to avoid at all costs otherwise you just lose most of the benefits of micro services.</p>&#xA;&#xA;<p>What would be the recommended approach to validate that the current user has permissions for that location? The only thing I have thought of so far is either</p>&#xA;&#xA;<ol>&#xA;<li>Getting the location API to issue out another access token with additional claims of what locations they have access to.</li>&#xA;<li>Or issuing out another completely separate token of some kind and passing that via the header to the inventory micro service to do a validation similar to how the JWT is authenticated.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>As mentioned below on providing aggregate roots (or I am assuming that means the same as API gateways) it would provide the 3rd option of another service on top to communicate to both to provide the information.</p>&#xA;&#xA;<p>However it then leaves a 3rd service dependent upon 2 others, so I just increased my service dependencies.</p>&#xA;"
30621628,BDD and microservices,<c#><bdd><distributed><specflow><microservices>,3,686,2,2.0,7,"<p>Our solution relies on microservices. On the other hand, our CIO expects us to practice Behavior Driven Development on every new feature. </p>&#xA;&#xA;<p>Is it possible to manage BDD in a microservices architecture ? Based on your experience, is it a good practice to adopt BDD against such an architecture, or do you think we should directly look at integration testing ?</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>More precisely, in my opinion, BDD Tests are expected to verify the business logic, and only the business logic. In many frameworks, BDD Tests scenarios are created by the skateholders, with a DSL. BDD Tests tend to converge to exclusive ""Infrastructure Ignorant"" practices. On the other hand, Integration Tests are supposed to verify that the solution matches the target infrastructure (they are done by DevOps ?), and only the infrastructure. When business functions are ""distributed"" over microservices, you should mock almost everything (infra and business) in your BDD Tests environment (it should be the local environment) and mocking business weakens a lot your goals. Do you think these practices are compatible ?</p>&#xA;"
36957369,Fabric Message is too large,<c#><azure><microservices><azure-service-fabric>,2,1577,0,0.0,7,"<p>I'm trying to pass 5MB~ data from a service to an actor, and I'm getting the error:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Fabric Message is too large</p>&#xA;</blockquote>&#xA;&#xA;<p>How can I increase the maximum size that can be transferred between micro-services?</p>&#xA;&#xA;<p>I looked at the following <a href=""https://github.com/Azure/azure-content/blob/master/articles/service-fabric/service-fabric-reliable-actors-reliabledictionarystateprovider-configuration.md"" rel=""noreferrer"">page</a> to see my options.</p>&#xA;&#xA;<p>I tried setting:</p>&#xA;&#xA;<pre><code>&lt;Section Name=""ServiceReplicatorConfig""&gt;&#xA;    ...&#xA;    &lt;Parameter Name=""MaxReplicationMessageSize"" Value=""1073741824"" /&gt;&#xA;&lt;/Section&gt;&#xA;</code></pre>&#xA;&#xA;<p>Please help.</p>&#xA;"
29636899,Do microservices break the bounded context?,<domain-driven-design><microservices>,2,3461,3,3.0,7,"<p>I am a bit confused. I am working in a young banking company and we decided to implement a DDD architecture to break complexity.</p>&#xA;&#xA;<p>So, here is my question (it follows a design suggestion made by someone in the team). Let's say we have 3 different domains. D1, D2, D3, that expose domain (web)services. Each domain manipulates strongly typed business entities, that rely on the same tables. In front of these domains, we want a microservice to garantee that data persisted in tables is consistent, in a centralized manner. D1, D2 and D3 ask the microservice to persist data conforming to specific rules. We want the microservice to act as a CRUD proxy to the tables. The microservice provides specific DTOs to D1, D2 and D3 domains, obfuscating the tables to D1, D2, D3.</p>&#xA;&#xA;<p>Does this approach sound good ? Would you consider using microservices in a DDD architecture to manage CRUD and data consistency for 1+ domains ? Does ""CRUDing"" and validating data with a microservice break the bounded context ? What are the best practices with dealing with microservices in a DDD architecture, if any ?</p>&#xA;&#xA;<p>Many thanks for your contribution,</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>The following article helped me to refine my thoughts : <a href=""http://martinfowler.com/bliki/MicroservicePremium.html"" rel=""noreferrer"">http://martinfowler.com/bliki/MicroservicePremium.html</a></p>&#xA;&#xA;<p>Microservices are useful on complex situations where monolithic systems failed at being maintainable. They are not good candidates for upfront design implementations. On the other hand, DDD tries to tackle complexity at the very beginning of the projects. Successful DDD should not meet microservices implementations.</p>&#xA;"
29704842,Integration testing Spring Boot based Microservices,<junit><spring-boot><microservices>,2,3024,4,1.0,7,"<p>I have read many of the guides about working with Spring Boot and RESTful services, and many of them contain information about running unit tests, most notably ""Building an Application with Spring Boot"".  However, I haven't seen anything that gives an example on how to unit test a Spring Boot application that consumes/depends on other Spring Boot applications, as is common in cloud micro-services architecture. So, for example, we have the following Spring Boot services:</p>&#xA;&#xA;<p>ServiceMediator,&#xA;Adapter1,&#xA;Adapter2</p>&#xA;&#xA;<p>ServiceMediator calls Adapter1 or Adapter2, depending on the input.</p>&#xA;&#xA;<p>Is there a way to start up the Spring Boot services Adapter1 and Adapter2  before starting and testing the ServiceMediator in a Spring JUnit test?</p>&#xA;"
42062199,Reactive Programming Advantages/Disadvantages,<java><reactive-programming><microservices><rx-java2><project-reactor>,4,6250,1,6.0,7,"<p>I keep studying and trying Reactive Style of coding using Reactor and RxJava. I do understand that reactive coding makes better utilization of CPU compared to single threaded execution. </p>&#xA;&#xA;<p>Is there any concrete comparison between reactive programming vs imperative programming in web based applications? </p>&#xA;&#xA;<p>How much is the performance gain, throughput I achieve by using reactive programming over non-reactive programming?</p>&#xA;&#xA;<p>Also what are the advantages and disadvantages of Reactive Programming? </p>&#xA;&#xA;<p>Is there any statistical benchmark? </p>&#xA;"
40205675,Microservices Authentication best practices and security (OAuth 2.0 and OpenIdConnect),<security><oauth><oauth-2.0><microservices><openid-connect>,2,1694,2,3.0,7,"<p>There are several ways to build authentication in micro-services. However very popular is using JWT tokens and OAuth protocol together with OpenID Connect identity layer.</p>&#xA;&#xA;<p>In <a href=""http://nordicapis.com/api-security-oauth-openid-connect-depth/"" rel=""nofollow"">this tutorial</a> explaining how it can be achieved there is one tip:  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Pass by reference when tokens have to leave your network, and then convert them to by-value tokens as they enters your space. Do this conversion in your API gateway.</p>&#xA;</blockquote>&#xA;&#xA;<p>However it's not clear to me what's reason behind it. I suspect it might be due to some security benefits (not to give client possibility to read any specific info). Because in the JWT token itself it might be info about roles/permission. But for this purpose token can also be encrypted.</p>&#xA;&#xA;<p>Another reason might be that JWT token is too big and in order to don't carry this token every time such approach might be used. (or if JWT token is stored in cookie it has size limits).</p>&#xA;&#xA;<p>I haven't seen any info that JWT token authentication is compromised and it's a bad practice to keep it on client (in browser).</p>&#xA;&#xA;<p>On the other hand I see that Ping Identity is also using <strong>pass by reference</strong> approach. Can you help me understand the reasoning behind it?</p>&#xA;"
41903352,How do I register a microservice (or its methods) to Task in Netflix Conductor?,<microservices><netflix><amazon-swf><axon><netflix-conductor>,2,1341,1,0.0,7,"<p>I was looking for a more sophisticated workflow than Saga from AxonFramework  -- which we are currently using -- and I found one in Netflix Conductor. &#xA;Sadly, I have searched the Internet for a decent example but to no avail.</p>&#xA;&#xA;<p>My question is, in Netflix Conductor, how might one define and create Task or WorkflowTask and most importantly, link a microservice to it? Here is a Netflix Conductor code from github:</p>&#xA;&#xA;<pre><code>    WorkflowDef def = new WorkflowDef();&#xA;    def.setName(""test"");&#xA;    WorkflowTask t0 = new WorkflowTask();&#xA;    t0.setName(""t0"");&#xA;    t0.setType(Type.SIMPLE);&#xA;    t0.setTaskReferenceName(""t0"");&#xA;&#xA;    WorkflowTask t1 = new WorkflowTask();&#xA;    t1.setName(""t1"");&#xA;    t1.setType(Type.SIMPLE);&#xA;    t1.setTaskReferenceName(""t1"");&#xA;&#xA;    def.getTasks().add(t0);&#xA;    def.getTasks().add(t1);&#xA;</code></pre>&#xA;&#xA;<p>Pardon my confusion as I am new to Netflix Conductor.</p>&#xA;"
40966759,Microservices: Centralized Authorization vs Authorization in each service,<architecture><microservices>,1,1391,0,1.0,7,"<p>Let's say I have a Microservices system built with an API Gateway.  </p>&#xA;&#xA;<p>Every request after coming through the Gateway have to be pre-authenticated by an Authentication Service (The Firewall pattern)  </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DySBr.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DySBr.png"" alt=""Firewall Pattern""></a>  </p>&#xA;&#xA;<p>But how about Authorization? For instance, I have 3 models and 3 services according to them in a <em>Hotel Management</em> system:  </p>&#xA;&#xA;<p><strong>User</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>each user can have many hotels  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Hotel</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a hotel is owned by a single user (owner)  </li>&#xA;<li>each hotel can have many employees (also a user)  </li>&#xA;<li>a hotel can have many rooms</li>&#xA;<li>for the sake of simplicity let's pretend that an employee have the same rights as the owner over a hotel  </li>&#xA;</ul>&#xA;&#xA;<p><strong>Room</strong>  </p>&#xA;&#xA;<ul>&#xA;<li>a room can only belong to a single hotel</li>&#xA;<li>owner and employees can only edit rooms in hotels that they owned/employed at</li>&#xA;</ul>&#xA;&#xA;<p>An example request to edit a room <strong>Y</strong>, after being authenticated it will have a verified claim that state something like <strong>'I am user X'</strong>.  </p>&#xA;&#xA;<p>To know whether <strong>X</strong> has the right to edit over <strong>Y</strong> I have to make requests to Hotel Service asking ""Does <strong>Y</strong>'s Hotel associated with (owned by/employing) <strong>X</strong>?"".  </p>&#xA;&#xA;<p>The question is: <strong>Where do I make these requests?</strong><br>&#xA;Have the Gateway ask the <em>Hotel Service</em> before forwarding client request to <em>Room Service</em>, or let the <em>Room Service</em> ask the <em>Hotel Service</em> by itself. When to choose one over another ? What's the benefit ?</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Also, this modeling seems kinda wrong to me. All these relations laying around Microservices just make my system really complicated. As it grows it becomes harder for me to visualize the workflow between services. Is there a solution to this problem? A centralized relationship service that utilizes graph database like Neo4j perhaps?</p>&#xA;"
47071729,AWS Load Balancer 502,<amazon-web-services><amazon-ec2><microservices><elastic-load-balancer><internal-load-balancer>,1,873,4,3.0,7,"<p>I have microservices(in different programming languages) running on an EC2 instance.&#xA;On production I notice a few 502 Bad Gateway Errors when these services try to interact with each other.&#xA;Also in the logs of the requested service it doesn't show any api call is being hit</p>&#xA;&#xA;<p>example service A calls service B, but in service B logs there is nothing to indicate that a call came from service A.</p>&#xA;&#xA;<p>Can it be AWS load balancer issue? Any help would be appreciated. Thanks in advance.</p>&#xA;&#xA;<p>Solution tried:&#xA;We tried making http/https connection agents in each service but still we get this issue.</p>&#xA;&#xA;<p>Update:&#xA;In lb logs, the api is logged, but the target response code shows ""-"" whereas lb response code shows 502 or 504. Does it mean that lb is not able to handle the traffic or my application?</p>&#xA;&#xA;<p>Also what can be the possible solution?</p>&#xA;"
38328727,What is the best way to design background jobs in microservices architecture?,<architecture><microservices>,1,1727,1,1.0,7,"<p>I am using microservices architecture. As per my requirements, there are some Restful services required and some background jobs to be developed. </p>&#xA;&#xA;<p>For an example of Groceries delivery system,</p>&#xA;&#xA;<ul>&#xA;<li>Customers service - some restful service</li>&#xA;<li>Provider service - some restful service</li>&#xA;<li>OrderProvision - some background service which checks whether all of customer items got provided by different providers. </li>&#xA;</ul>&#xA;&#xA;<p>Once done, send an initiation to customer with the status and initiate delivery system to start delivering</p>&#xA;&#xA;<p>For the case of OrderProvision what is the best way to implement microservices?&#xA;In case of .Net framework, I can create a windows service/ scheduler task to run in background and do the checks. If it needs to be deployed on other servers like Linux, it does not work. What would be the best way to code such background tasks in microservices architecture?</p>&#xA;"
26975640,Why are Micro-Services Architectures not based on Enterprise Service Buses?,<esb><microservices>,4,2300,0,2.0,8,"<p>What reasons are there against (or for) using the features of an Enterprise Service Bus when building an overall service adhering to a micro-service architecture (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">http://martinfowler.com/articles/microservices.html</a>)? Why should we use dumb pipes and smart endpoints as opposed to using smarter pipes and be able to develop simpler services? </p>&#xA;"
22987482,Can you use Hapi.JS as a Micro-services framework?,<node.js><api><plugins><microservices>,1,2226,0,2.0,8,"<p>I've seen various interesting presentations recently about the joys of Micro Services (<a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow noreferrer"">http://martinfowler.com/articles/microservices.html</a>) and also wonder how we might use those concepts with Hapi.JS. </p>&#xA;&#xA;<p>The CTO of Mail Online (largest online newspaper on the planet) name checks HAPI and its plugin system in relation to micro-services :</p>&#xA;&#xA;<p><a href=""http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline"" rel=""nofollow noreferrer"">http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline</a></p>&#xA;&#xA;<blockquote>&#xA;  <p>A micro-services architecture is used, which was inspired by Fred George, which is a&#xA;  slightly different take on the hapi plugin architecture, structuring applications to be &#xA;  maintainable as they get bigger is a key challenge going forward and micro-services is a &#xA;  solution to this. The MailOnline are also heavy users of Joyent (On Premise SDC and public &#xA;  cloud).</p>&#xA;</blockquote>&#xA;&#xA;<p>There are also new node frameworks set up specifically for micro-services (senecajs.org)</p>&#xA;&#xA;<p>Has anyone seen any case studies (and ideally tutorials) on leveraging Hapi in this way?</p>&#xA;"
28930710,How to avoid concurrency issues when scaling writes horizontally?,<azure><scalability><sharding><microservices><horizontal-scaling>,5,639,2,3.0,8,"<p>Assume there is a worker service that receives messages from a queue, reads the product with the specified Id from a document database, applies some manipulation logic based on the message, and finally writes the updated product back to the database (a).</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/RZYlA.png"" alt=""horizontally scaling writes""></p>&#xA;&#xA;<p>This work can be safely done in parallel when dealing with different products, so we can scale horizontally (b). However, if more than one service instance works on the same product, we might end up with concurrency issues, or concurrency exceptions from the database, in which case we should apply some retry logic (and still the retry might fail again and so on). </p>&#xA;&#xA;<p><strong>Question</strong>: How do we avoid this? Is there a way I can ensure two instances are not working on the same product?</p>&#xA;&#xA;<p><strong>Example/Use case</strong>: An online store has a great sale on productA, productB and productC that ends in an hour and hundreds of customers are buying. For each purchase, a message is enqueued (productId, numberOfItems, price).  <strong>Goal</strong>: How can we run three instances of our worker service and make sure that all messages for productA will end up in instanceA, productB to instanceB and productC to instanceC (resulting in no concurrency issues)?</p>&#xA;&#xA;<p><strong>Notes</strong>: My service is written in C#, hosted on Azure as a Worker Role, I use Azure Queues for messaging, and I'm thinking to use Mongo for storage. Also, the Entity IDs are <code>GUID</code>.</p>&#xA;&#xA;<p>It's more about the technique/design, so if you use different tools to solve the problem I'm still interested.</p>&#xA;"
34593341,Trade offs and best practices building microservices with Azure Service Fabric,<c#><azure><asp.net-web-api2><microservices><azure-service-fabric>,2,2284,2,3.0,8,"<p>I want to build a microservice application based on Azure Service Fabric. For some stateful services or actors I want to access the state from outside via web api.</p>&#xA;&#xA;<p>What are the general trade-offs and best practices for such a Service Fabric project regarding to:</p>&#xA;&#xA;<ol>&#xA;<li><p>using one vs. multiple services in a single application? Therefore if I use one service per application, I will have multiple applications for my project. When is it useful to use one service per application?</p></li>&#xA;<li><p>using one vs. multiple actors in a single service? When is it useful to have more than one actor per service?</p></li>&#xA;<li><p>using one stateless web api service for the whole project vs. multiple stateless web services for each stateful service or for each application?</p></li>&#xA;</ol>&#xA;&#xA;<p>I know these decisions are based on the specific project. But maybe there are general advantages and disadvantages for the three points above.</p>&#xA;"
30648096,centralized API documentation for microservices,<api><documentation><microservices>,3,3386,5,2.0,8,"<p>My team and I are currently building multiple services in parallel. We have the benefit of building all the services from scratch. I would like the ability to automatically display all API endpoints, from all services, in one page/site.  This would be helpful because (among other things):</p>&#xA;&#xA;<ol>&#xA;<li><p>I don't have to go to multiple documentation sites to see what are the available endpoints in my entire ""system"". </p></li>&#xA;<li><p>It'll be a good first step to determine if any of the services should be split, combined or simply refactored.  </p></li>&#xA;</ol>&#xA;&#xA;<p>Some of our services are in Django and the <a href=""http://swagger.io/"" rel=""noreferrer"">rest-swagger</a> module is a great help. But I don't see how I can combine rest-swagger documentation from multiple services into a single documentation page/site.</p>&#xA;&#xA;<p>I'm currently looking through <a href=""http://microservices.io/index.html"" rel=""noreferrer"">this site</a> and anything related to the <a href=""http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/"" rel=""noreferrer"">Netflix experience</a> but could not find a solution to my problem. Maybe centralized documentation isn't a big deal with 600+ services at Netflix, but that's hard to believe.</p>&#xA;&#xA;<p>Can anyone suggest a tool or method to have a combined API documentation for all services in a microservice architecture? </p>&#xA;&#xA;<p>My ideal scenario of what happens when a service is changed: </p>&#xA;&#xA;<ol>&#xA;<li>I click on the link to see the list of endpoints in my system.</li>&#xA;<li>A teammate updates a service and also it's documentation.</li>&#xA;<li>I refresh the page I am currently and I see that change made from step #2.</li>&#xA;</ol>&#xA;"
41262716,Don't allow direct calls to Microservices. Only allow through API Gateway,<java><spring><rest><microservices><gateway>,4,1584,6,1.0,8,"<p>Maybe this is a strange question (I'm new with Microservices). But I'm looking for some info on how proceed with this. Does not need to be Spring specific, but that's the framework I'm using at the moment.</p>&#xA;&#xA;<p>Example:&#xA;Lets say we have two Microservices</p>&#xA;&#xA;<p>a) <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>b) <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>and we have setup Spring Zuul (acting as the API Gateway) with the following rules that forward the incoming calls:</p>&#xA;&#xA;<p>/rest/one -> <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>/rest/two -> <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>The question...&#xA;Is there a way to stop users from directly accessing the services mentioned in A and B (only allow the ones that come through the API Gateway)?</p>&#xA;&#xA;<p>Can this be done with Springs Zuul (Acting as a API Gateway) by setting up some extra filters or do we set it up in Microservices endpoints?</p>&#xA;&#xA;<p>Would even like to know if there is a way to not even processing the direct calls on the Microservices endpoints that don't come via the API Gateway.</p>&#xA;&#xA;<p>Maybe this is solved with server specific rules and has nothing to do with Spring? </p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>/D</p>&#xA;"
40458770,"Microservice to Microservice calls, authorization from a queue message",<spring-security><jwt><microservices><netflix-zuul><keycloak>,2,1044,0,3.0,8,"<p><strong>Context:</strong> I'm creating a cloud platform to support multiple applications with SSO. I'm using <strong>Keycloak for authentication</strong> and <strong>Netflix Zuul for authorization</strong> (API Gateway) thru <strong>Keycloak Spring Security Adapter</strong>.</p>&#xA;&#xA;<p>Each microservice expect an Authorization header, which contains a valid JWT, from which it will take the username (sub) to process the request. Each microservice-to-microservice call should go thru Netflix Zuul first, passing the Authorization header to maintain a stateless validation. That strategy allow to every microservice to know who is the user (sub) who is invoking the microservice indirectly.</p>&#xA;&#xA;<p><strong>Problem/Question 1:</strong> What happens if a microservice is invoked from a queue message? One idea that I had is to storage in the queue the information related to the message + userInfo, and, create a dedicated microservice to process that kind of messages, with that approach this special microservice should read the userInfo from the queue and process the message.</p>&#xA;&#xA;<blockquote>&#xA;  <p>UPDATE 1: Per an email reply from another forum, storing the JWT in a queue isn't a good idea, since it could be mined easily.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Problem/Question 2:</strong> But, what happens if the previous special microservice wants to call another normal microservice which expect to receive a JWT in a header? Should this special microservice create by himself a JWT to impersonate the user and be able to call the regular microservices?</p>&#xA;&#xA;<p>Another solution that I thought was to storage the original JWT in the queue, but, what happens if the queue calls to the special microservice later? Just after the JWT is not valid anymore (it expired) and the microservice called will reject the request?</p>&#xA;&#xA;<p><strong>Possible solutions:</strong> (Updated per João Angelo discussion, see below)</p>&#xA;&#xA;<blockquote>&#xA;  <p>I should authenticate the requests from my users (<strong>Authorization code flow</strong>) and my services (<strong>Client credentials grant</strong>), both requests should contain user information in the payload. When the request it comes from the user, I need to validate that the payload user info match with the JWT claims. When the request comes from a service, I just need to trust in that service (as long as it is under my control).</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate very much your help. Thanks.</p>&#xA;"
36083504,Database connection pool strategy for micro services,<database><postgresql><jdbc><connection-pooling><microservices>,1,1749,2,0.0,8,"<p>We are trying to convert our monolithic application to a micro services based architecture. We use Postgresql as one of our database in the monolithic application with BoneCP for connection pooling. </p>&#xA;&#xA;<p>When this monolith is split to a number of independent micro-services with each of them running in a different JVM, I can think about two options for connection pooling</p>&#xA;&#xA;<ol>&#xA;<li>BoneCP or any decent connection pool for each microservice - My initial research shows that this is the primary choice. It is possible to have a fine grained control of connection requirements for each service.But, down side is that as the number of services increase, number of connection pool also increases and eventually there will be too many idle connections assuming that minimum connections in each pool is greater than 0.</li>&#xA;<li>Rely on database specific extensions like PGBouncer - This approach has the advantage that connection pool is managed by a central source rather than a pool for each micro service and hence number of idle connections can be brought down. It is also language/technology agnostic. Down side is that these extensions are database specific and some of the functionalities in JDBC may not work. For eg: Prepared statments may not work with PGBouncer in Transaction_Pooling mode. </li>&#xA;</ol>&#xA;&#xA;<p>In our case most of the micro-services(at least 50) will be connecting to the same Postgres server even though the database can be different. So, if we go with option 1, there is a higher chance of creating too many idle connections.The traffic to most of our services are very moderate and the rationale behind moving to micro-service is for easier deployment, scaling etc.</p>&#xA;&#xA;<p>Has anyone faced a similar problem while adopting micro-services architecture? Is there a better way of solving this problem in micro-service world?</p>&#xA;"
36157778,Accessing stateless service via ServiceProxy fails + ASP.NET 5 Web API project throws Health State error,<c#><asp.net><.net><microservices><azure-service-fabric>,6,5965,4,3.0,8,"<p>I'm new to microsoft azure service fabric. For my master's degree I have to develop a microservice-approach prototype in service fabric. After hours of researching I am still not getting my issue(s) solved.</p>&#xA;&#xA;<p>I want to access my (in a local fabric cluster deployed) stateless service in a web front-end like in <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/"" rel=""noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/</a>. The simplest way for doing that is by adding an ASP .NET 5 Web Api project to the Service Fabric application and make a <code>ServiceProxy</code> method call in the <code>ValuesController</code>. So I added this code to my solution:</p>&#xA;&#xA;<p><strong>ValuesController.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>[Route(""api/[controller]"")]&#xA;public class ValuesController : Controller&#xA;{&#xA;  // GET api/values/IObject&#xA;  [HttpGet(""{interfaceName}"")]&#xA;  public async Task&lt;string&gt; Get(string interfaceName)&#xA;  {&#xA;    var serviceName = ""fabric:/DataServiceFabric/MasterDataMService"";&#xA;    var masterDataService = ServiceProxy.Create&lt;IMasterDataMService&gt;(new Uri(serviceName));&#xA;    var result = await masterDataService.GetMasterDataByName(interfaceName);&#xA;    return result.Content;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After a F5-deploy my browser doesn't automatically navigate to my web front-end. By looking into the Service Fabric Explorer my ASP .NET 5 application throws a Health State error:</p>&#xA;&#xA;<pre><code>Kind        Health State  Description&#xA;=============================================================================&#xA;Partitions  Error         Unhealthy partitions: 100% (1/1), MaxPercentUnhealthyPartitionsPerService=0%.&#xA;Partition   Error         Unhealthy partition: PartitionId='413...', AggregatedHealthState='Error'.&#xA;Event       Error         Error event: SourceId='System.FM', Property='State'. Partition is below target replica or instance count.&#xA;</code></pre>&#xA;&#xA;<p>After this <a href=""https://stackoverflow.com/questions/34892366/partition-is-below-target-replica-or-instance-count-error-after-deploying-serv"">this</a> question the <em>""Partition is below target replica or instance count""</em> indicates that a unhandled exception in my service is preventing it from starting. But I'm not able to find a stack strace in my Service Fabric Explorer to debug this failure. This is my <code>ServiceManifest.xml</code> of my ASP .NET web service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (Web1):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Name=""Web1"" Version=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;ServiceTypes&gt;&#xA;      &lt;StatelessServiceType ServiceTypeName=""Web1Type""&gt;&#xA;         &lt;Extensions&gt;&#xA;            &lt;Extension Name=""__GeneratedServiceType__""&gt;&#xA;               &lt;GeneratedNames xmlns=""http://schemas.microsoft.com/2015/03/fabact-no-schema""&gt;&#xA;                  &lt;DefaultService Name=""Web1Service"" /&gt;&#xA;                  &lt;ServiceEndpoint Name=""Web1TypeEndpoint"" /&gt;&#xA;               &lt;/GeneratedNames&gt;&#xA;            &lt;/Extension&gt;&#xA;         &lt;/Extensions&gt;&#xA;      &lt;/StatelessServiceType&gt;&#xA;   &lt;/ServiceTypes&gt;&#xA;   &lt;CodePackage Name=""C"" Version=""1.0.0""&gt;&#xA;      &lt;EntryPoint&gt;&#xA;         &lt;ExeHost&gt;&#xA;            &lt;Program&gt;approot\runtimes\dnx-clr-win-x64.1.0.0-rc1-update1\bin\dnx.exe&lt;/Program&gt;&#xA;            &lt;Arguments&gt;--appbase approot\src\Web1 Microsoft.Dnx.ApplicationHost Microsoft.ServiceFabric.AspNet.Hosting --server Microsoft.AspNet.Server.WebListener&lt;/Arguments&gt;&#xA;            &lt;WorkingFolder&gt;CodePackage&lt;/WorkingFolder&gt;&#xA;            &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048"" /&gt;&#xA;         &lt;/ExeHost&gt;&#xA;      &lt;/EntryPoint&gt;&#xA;   &lt;/CodePackage&gt;&#xA;   &lt;Resources&gt;&#xA;      &lt;Endpoints&gt;&#xA;         &lt;Endpoint Name=""Web1TypeEndpoint"" Protocol=""http"" Type=""Input"" Port=""80"" /&gt;&#xA;      &lt;/Endpoints&gt;&#xA;   &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>And here my <code>ApplicationManifest.xml</code> of my service fabric solution:</p>&#xA;&#xA;<p><strong>ApplicationManifest.xml:</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ApplicationManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" ApplicationTypeName=""DataServiceFabricType"" ApplicationTypeVersion=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;Parameters&gt;&#xA;      &lt;Parameter Name=""ActorTestServiceActorService_PartitionCount"" DefaultValue=""10"" /&gt;&#xA;      &lt;Parameter Name=""MasterDataMService_InstanceCount"" DefaultValue=""-1"" /&gt;&#xA;   &lt;/Parameters&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;     &lt;ServiceManifestRef ServiceManifestName=""Web2Pkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;     &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""Web1"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""ActorTestServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""MasterDataMServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;      &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;DefaultServices&gt;&#xA;      &lt;Service Name=""Web1Service""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""Web1Type""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""ActorTestServiceActorService"" GeneratedIdRef=""761ee3cf-5a3a-49d8-9c57-aa3480d1acf1""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""ActorTestServiceActorServiceType""&gt;&#xA;            &lt;UniformInt64Partition PartitionCount=""[ActorTestServiceActorService_PartitionCount]"" LowKey=""-9223372036854775808"" HighKey=""9223372036854775807"" /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""MasterDataMService""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""MasterDataMServiceType"" InstanceCount=""[MasterDataMService_InstanceCount]""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;   &lt;/DefaultServices&gt;&#xA;&lt;/ApplicationManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>So I created a new solution with an ASP.NET 5 web application and the same <code>ValuesController.cs</code>. I ensured my stateless service is running on my local cluster and than I started my new web application. After calling the GET-Method in my Controller I got the following exception:</p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 0,2593ms 500&#xA;Microsoft.AspNet.Server.Kestrel: Error: An unhandled exception was thrown by the application.&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1}&#xA;</code></pre>&#xA;&#xA;<p>My stateless service is a SingletonPartition, so do I need a partition key here? And if yes, how do I get the key? The Service Fabric Explorer doesn't provide me with this information for my stateless service. Here is the <code>ServiceManifest.xml</code> of my stateless service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (MasterDataMService):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest Name=""MasterDataMServicePkg""&#xA;                 Version=""1.0.0""&#xA;                 xmlns=""http://schemas.microsoft.com/2011/01/fabric""&#xA;                 xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&#xA;                 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;&#xA;  &lt;ServiceTypes&gt;&#xA;    &lt;!-- This is the name of your ServiceType. &#xA;         This name must match the string used in RegisterServiceType call in Program.cs. --&gt;&#xA;    &lt;StatelessServiceType ServiceTypeName=""MasterDataMServiceType"" /&gt;&#xA;  &lt;/ServiceTypes&gt;&#xA;&#xA;  &lt;!-- Code package is your service executable. --&gt;&#xA;  &lt;CodePackage Name=""Code"" Version=""1.0.0""&gt;&#xA;    &lt;EntryPoint&gt;&#xA;      &lt;ExeHost&gt;&#xA;        &lt;Program&gt;MasterDataMService.exe&lt;/Program&gt;&#xA;      &lt;/ExeHost&gt;&#xA;    &lt;/EntryPoint&gt;&#xA;  &lt;/CodePackage&gt;&#xA;&#xA;  &lt;!-- Config package is the contents of the Config directoy under PackageRoot that contains an &#xA;       independently-updateable and versioned set of custom configuration settings for your service. --&gt;&#xA;  &lt;ConfigPackage Name=""Config"" Version=""1.0.0"" /&gt;&#xA;&#xA;  &lt;Resources&gt;&#xA;    &lt;Endpoints&gt;&#xA;      &lt;!-- This endpoint is used by the communication listener to obtain the port on which to &#xA;           listen. Please note that if your service is partitioned, this port is shared with &#xA;           replicas of different partitions that are placed in your code. --&gt;&#xA;      &lt;Endpoint Name=""ServiceEndpoint"" Type=""Input"" Protocol=""http"" Port=""80""/&gt;&#xA;    &lt;/Endpoints&gt;&#xA;  &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that I decided to set up a service communication with OWIN:</p>&#xA;&#xA;<p><strong>MasterDataMService.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>internal sealed class MasterDataMService : StatelessService, IMasterDataMService&#xA;{&#xA;  [...]      &#xA;&#xA;  protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;  {&#xA;    return new[]&#xA;    {&#xA;      new ServiceInstanceListener(initParams =&gt; new OwinCommunicationListener(""MasterDataMService"", new StartUp(), initParams))&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I can acess my microservice by using a <code>HttpClient</code> in my <code>DefaultController</code>:</p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>var client = new HttpClient();&#xA;var request = ""http://localhost:80/MasterDataMService/api/values/query"";&#xA;var result = string.Empty;&#xA;HttpResponseMessage response = await client.GetAsync(request);&#xA;if (response.IsSuccessStatusCode)&#xA;{&#xA;  result = await response.Content.ReadAsStringAsync();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But thats not what I originally wanted. I don't want to specifiy the service endpoint in my request. Instead I would like to communicate with my stateless service over a <code>ServiceProxy</code>. How do I achieve that here? What did I wrong? And how can I solve this Health State error with my ASP .NET 5 application which is deployed into my service fabric cluster?</p>&#xA;&#xA;<p>Thanks for your time.</p>&#xA;&#xA;<p><strong>Edit:</strong></p>&#xA;&#xA;<p><em>Extended stacktrace of invalid partition key exception:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,35ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1} ---&gt; System.Runtime.InteropServices.COMException: exception of HRESULT: 0x80071BBF&#xA;   at System.Fabric.Interop.NativeClient.IFabricServiceManagementClient4.EndResolveServicePartition(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.FabricClient.ServiceManagementClient.ResolveServicePartitionEndWrapper(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.Interop.AsyncCallOutAdapter2`1.Finish(IFabricAsyncOperationContext context, Boolean expectedCompletedSynchronously)&#xA;   --- End of inner exception stack trace ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Client.ServicePartitionResolver.&lt;ResolveAsyncHelper&gt;d__2a.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;GetClientAsync&gt;d__a.MoveNext()&#xA;</code></pre>&#xA;&#xA;<p>Please give me feedback if you need more. (full stack trace is 82 lines long)</p>&#xA;&#xA;<p><em>Invalid scheme exception stack trace:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.ArgumentException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,45ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.ArgumentException: the provided uri scheme 'http' is invalid; expected 'net.tcp'.&#xA;Parametername: via&#xA;   at System.ServiceModel.Channels.TransportChannelFactory`1.ValidateScheme(Uri via)&#xA;   at System.ServiceModel.Channels.ConnectionOrientedTransportChannelFactory`1.OnCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ChannelFactoryBase`1.InternalCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.ServiceChannelFactoryOverDuplexSession.CreateInnerChannelBinder(EndpointAddress to, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateServiceChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateChannel(Type channelType, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, Binding binding, EndpointAddress endpointAddress)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Wcf.Client.WcfCommunicationClientFactory`1.&lt;CreateClientAsync&gt;d__2.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;CreateClientWithRetriesAsync&gt;d__1e.MoveNext()&#xA;</code></pre>&#xA;"
31317470,How should you deal with auth and sharing Users info across microservices?,<node.js><mongodb><nginx><microservices>,1,1189,3,6.0,8,"<p><strong>TLTR:</strong> What is a good way to communicate across services for Auth and User Info regardless of location of server or technology used</p>&#xA;&#xA;<p>I'm trying to learn about microservices and I'm a little bit unclear as to how I should approach accessing user information and control access with multiple services. Please let me know if I am approaching this completely wrong.</p>&#xA;&#xA;<p>For example I have a basic service for Blog CRUD operations and a Service for uploading and storing images and videos. I haven't done anything with Authorization or Users yet (except I am accounting for UserIds eventually being present in my Models (e.g. in my blog model ObjectID's for author, commenters, etc).</p>&#xA;&#xA;<p>I want to keep this as separated as possible (for learning purposes more then anything) and while at the moment I am building it all in Node.js I hope to be able to swap in and out different technologies such as nginx, a java/go/python service or a different storage (currently mongo, but would like to be able to switch to sql as an option )</p>&#xA;&#xA;<p>How I currently have these structured is I have both services built as Express.js apps and currently I am using node-http-proxy to proxy to the express services (this is just to save with setting up nginx for now but I don't want to be dependent on nginx either).</p>&#xA;&#xA;<p><em>How should I approach:</em></p>&#xA;&#xA;<ul>&#xA;<li><p>Authenticated user or some of the routes (e.g. when creating a new post or updating/deleting) and Not when getting the post to Read (eventually I would like to incorporate roles too)</p></li>&#xA;<li><p>populating the User information e.g. from the user's ID stored in the blog author and replacing it with the user information (in a single app I could just use mongoose populate</p></li>&#xA;</ul>&#xA;&#xA;<p>The main aim is I would like to keep the Auth and Users in separate services that could be called in any other service and stored in another DB for example if they were located on different physical servers.</p>&#xA;&#xA;<p>someone had suggested to me I could do this using HTTP/S but is there a better way to do this and can anyone point me to any implementation examples, Node.js would be preferable but not essential</p>&#xA;&#xA;<p>This likely requires some service registry but I am a bit lost as to how this would be implemented</p>&#xA;"
45515650,Client per MicroService vs Generic Client | Who is responsible for microservice client?,<distributed-computing><microservices>,1,156,1,2.0,8,"<p>I have a microService architecture with 10 microServices and each of those provides a client. Inside of that client which is managed/controlled by microService team we just receive the parameters and pass them to a generic http invoker which receives the endpoint and N params and then does the call.&#xA;All microService use http and web api (I guess technology doesn't matter).</p>&#xA;&#xA;<p>For me doesn't make sense to be the microService team to provide a client, should be the responsibility of the consumer, if they want to create some abstractions or invoke it directly is their problem, not a microService problem. And the way I see a web API is as a contract. So I think we should delete all clients (pass responsibility to consumers) on the microService side and create a service layer on the consumer's side that uses the generic invoker to reach the endpoints.</p>&#xA;&#xA;<p>The image below represents all components where the <strong>red line defines</strong> the boundaries, <strong>who is responsible for what</strong>:</p>&#xA;&#xA;<ul>&#xA;<li>The gateway has Adapter Layer </li>&#xA;<li>Adapter Layer references the microService client package </li>&#xA;<li>MicroService client package references Generic HTTP invoker package&#xA;<a href=""https://i.stack.imgur.com/EnjD5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/EnjD5.jpg"" alt=""enter image description here""></a></li>&#xA;</ul>&#xA;&#xA;<p>The other side of that is because we might have N number of consumers and they are all repeating the code of the client. And if the microService provides a client, we have a unique/central place to control that.</p>&#xA;&#xA;<p><strong>Which approach is correct? Is the client a responsability of the microService or the consumer?</strong></p>&#xA;&#xA;<p>This is an internal product.</p>&#xA;"
43426699,DB design for microservice architecture,<database><design><microservices>,2,7671,0,4.0,8,"<p>I am planning to use the Microservices architecture for the implementation of our website. I wanted to know if it is right to share databases between services or if it is preferable to have a separate database for each service. In this regard, can I consider having one common database for all services or does it violate the very essence of Microservice architecture ?</p>&#xA;"
36461493,Customizing Zuul Exception,<java><spring-boot><spring-cloud><microservices><netflix-zuul>,4,9134,5,6.0,10,"<p>I have a scenario in Zuul where the service that the URL is routed too might be down . So the reponse body gets thrown with 500 HTTP Status and ZuulException in the JSON body response.</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": 1459973637928,&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""com.netflix.zuul.exception.ZuulException"",&#xA;  ""message"": ""Forwarding error""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>All I want to do is to customise or remove the JSON response and maybe change the HTTP status Code.</p>&#xA;&#xA;<p>I tried to create a exception Handler with @ControllerAdvice but the exception is not grabbed by the handler.</p>&#xA;&#xA;<p><strong>UPDATES:</strong></p>&#xA;&#xA;<p>So I extended the Zuul Filter I can see it getting into the run method after the error has been executed how do i change the response then. Below is what i got so far. I read somewhere about SendErrorFilter but how do i implement that and what does it do?</p>&#xA;&#xA;<pre><code>public class CustomFilter extends ZuulFilter {&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        return ""post"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;&#xA;        return 1;&#xA;    }&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        return true;&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;        final RequestContext ctx = RequestContext.getCurrentContext();&#xA;        final HttpServletResponse response = ctx.getResponse();&#xA;        if (HttpStatus.INTERNAL_SERVER_ERROR.value() == ctx.getResponse().getStatus()) {&#xA;            try {&#xA;                response.sendError(404, ""Error Error""); //trying to change the response will need to throw a JSON body.&#xA;            } catch (final IOException e) {&#xA;                e.printStackTrace();&#xA;            } ;&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added this to the class that has @EnableZuulProxy</p>&#xA;&#xA;<pre><code>@Bean&#xA;public CustomFilter customFilter() {&#xA;    return new CustomFilter();&#xA;}&#xA;</code></pre>&#xA;"
35289988,Authorization and user microservices design,<microservices>,2,856,2,4.0,10,"<p>I'm trying to design microservice from an existing application with a quite standard user management: has authentication and authorization, and stores user data.</p>&#xA;&#xA;<p>I'm developping an <em>Authorization server</em> to manage user <strong>authentication</strong> and <strong>authorization</strong> using <code>OAuth2</code> as authorization. On other side I have to store user's information/profile.</p>&#xA;&#xA;<p><strong>Question:</strong> Should <em>Authorization server</em> manage:</p>&#xA;&#xA;<ul>&#xA;<li><strong>both authorization and user API?</strong> Thus other microservices can contact <em>Authorization server</em> on <code>/me</code> to get current user but also <code>/users</code> to get full list of users.</li>&#xA;<li><strong>Or only authorization and I have to create <em>User microservices</em>?</strong> Thus <em>Authorization server</em> only exposes <code>/me</code> API related to user and <em>User microservices</em> will expose <code>/users</code>?</li>&#xA;</ul>&#xA;&#xA;<p>The first solution is a bit simpler but the <em>Authorization server</em> will become less generic (less reusable) because user application data model will be part of it (database data model of <code>User</code> table).</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>The other requirement is <strong><em>Authorization server</em> should check if a user exists before authorizing it</strong>. </p>&#xA;&#xA;<p>There is no user auto-creation, users must be invited by <em>administrator</em> to get access.&#xA;With this requirement, the first solution is simple because <em>Authorization server</em> has access to user database but the second solution <em>Authorization server</em> implies:</p>&#xA;&#xA;<ol>&#xA;<li>Share database with <em>User service</em> (hum don't like that)</li>&#xA;<li>Call <em>User service</em> before authorization using REST API (for example) </li>&#xA;<li><em>Authorization server</em> should maintain minimal <code>User</code> table (can be renamed <code>Account</code>) and administrator will not create user on <em>User service</em> but only user account on <em>Authorization server</em></li>&#xA;</ol>&#xA;&#xA;<p>I think <strong>1.</strong> solution is out but any advices about <strong>2.</strong> and <strong>3.</strong>?</p>&#xA;&#xA;<p><strong>3.</strong> in first place seems the best, but if I want to switch to another <em>Authorization server</em>, for example a public one (OAuth2) like Google, Github, Facebook, etc... Security can be compromise because we can't control user account creation.</p>&#xA;&#xA;<p>Any feedback?</p>&#xA;"
28607400,Sessions in a Microservice architecture for an E-Commerce system,<php><magento><soa><single-page-application><microservices>,4,1282,2,5.0,10,"<p>I plan on developing a microservice E-Commerce system as proof of concept. The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li><p>a javascript based single page application, which sends AJAX requests to</p></li>&#xA;<li><p>a server (API Gateway) with a REST API which feeds JSON data received by calling other services</p></li>&#xA;<li><p>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</p></li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento Shopsystem. </p>&#xA;&#xA;<p>When I try to log in a user into they Magento system by sending a request to the REST Api obviously the server doesn't remember the session when sending the next request.</p>&#xA;&#xA;<p>Also I handle the shopping cart on the server side with Magento and add/update/remove items by REST Api calls. Here, also the added items get lost when sending the next request as the session got lost.</p>&#xA;&#xA;<p>So my question is:</p>&#xA;&#xA;<p>What are possible approaches to solve issues regarding session handling in a microservice architecture?</p>&#xA;"
40495213,Service fabric projects in separate git repos,<c#><azure><microservices><azure-service-fabric>,4,514,1,3.0,10,<p>Following a normal microservices framework we would like to place each microservice in it's own git repo and then have one repository for the Service Fabric project.  When we update one of the microservice the though would be that the Service Fabric project would redeploy just that service.</p>&#xA;&#xA;<p>Is there any examples of splitting the Service Fabric project up like this?  I've noticed in all of their examples everything is in one solution/repository.</p>&#xA;
32741333,Session Management in microservices,<java><session><cookies><weblogic><microservices>,1,9293,3,5.0,10,"<p>We have the following setup.</p>&#xA;&#xA;<ol>&#xA;<li>STM (Stingrey Traffic Manager) does load balancing + session stickiness</li>&#xA;<li>Weblogic 'cluster'</li>&#xA;<li>Auth handled by a third party tool</li>&#xA;</ol>&#xA;&#xA;<p>Therefore I do not have to worry about session with regards to horizontal scaling/ running multiple instances of the application. STM/ Weblogic cluster makes sure that the subsequent request come to same managed server.</p>&#xA;&#xA;<p>What we currently have is a monolithic application and we are trying to move to microservices. Also we do not wan't to move out of current infrastructure (i.e. STM/ Weblogic cluster/ Auth tool). What we have planned is:</p>&#xA;&#xA;<ol>&#xA;<li>A Gateway WAR which routes requests to other microservices</li>&#xA;<li>N x Microservices (WAR) for each functional sub-domain</li>&#xA;<li>Only the API Gateway receives user requests and other microservices are not accessible from outside</li>&#xA;</ol>&#xA;&#xA;<p>So my question is</p>&#xA;&#xA;<ol>&#xA;<li>Should API Gateway be state-full while other microsevices are stateless?</li>&#xA;<li>If so, how should the user session data be shared between API Gateway and microservices?</li>&#xA;</ol>&#xA;&#xA;<p>Please suggest any better alternatives and resources/links as well.  Thanks.</p>&#xA;"
38786207,Netflix Feign - Propagate Status and Exception through Microservices,<java><spring><spring-boot><microservices><netflix-feign>,4,13177,0,1.0,10,"<p>I'm using <a href=""https://github.com/OpenFeign/feign/blob/master/okhttp/src/main/java/feign/okhttp/OkHttpClient.java"" rel=""noreferrer"">Netflix Feign</a> to call to one operation of a Microservice A to other other operation of a Microservice B which validates a code using Spring Boot. </p>&#xA;&#xA;<p>The operation of Microservice B throws an exception in case of the validation has been bad. Then I handled in the Microservices and return a <code>HttpStatus.UNPROCESSABLE_ENTITY</code> (422) like next:</p>&#xA;&#xA;<pre><code>@ExceptionHandler({&#xA;       ValidateException.class&#xA;    })&#xA;    @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY)&#xA;    @ResponseBody&#xA;    public Object validationException(final HttpServletRequest request, final validateException exception) {&#xA;        log.error(exception.getMessage(), exception);&#xA;        error.setErrorMessage(exception.getMessage());&#xA;        error.setErrorCode(exception.getCode().toString());&#xA;        return error;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So, when Microservice A calls to B in a interface as next:</p>&#xA;&#xA;<pre><code>@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /other"")&#xA;void otherOperation(@Param(""other"")  String other );&#xA;&#xA;@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /code/validate"")&#xA;Boolean validate(@Param(""prefix"") String prefix);&#xA;&#xA;static PromotionClient connect() {&#xA;&#xA;    return Feign.builder()&#xA;        .encoder(new GsonEncoder())&#xA;        .decoder(new GsonDecoder())&#xA;        .target(PromotionClient.class, Urls.SERVICE_URL.toString());&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the validations fails It returns a internal error 500 with next message:</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": ""2016-08-05T09:17:49.939+0000"",&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""feign.FeignException"",&#xA;  ""message"": ""status 422 reading Client#validate(String); content:\n{\r\n  \""errorCode\"" : \""VALIDATION_EXISTS\"",\r\n  \""errorMessage\"" : \""Code already exists.\""\r\n}"",&#xA;  ""path"": ""/code/validate""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I need to return the same as the Microservice operation B.</p>&#xA;&#xA;<p>Wich would be the best ways or techniques to propagate Status and Exceptions through microservices using Netflix Feign?</p>&#xA;"
43612866,Microservices with shared database? using multiple ORM's?,<database><orm><microservices>,2,7791,3,3.0,10,"<p>I'm learning about microservices and I'm gonna build a project with a microservices architecture.</p>&#xA;&#xA;<p>The thing is, one of my team mates want to use one database for all services, sharing all tables so ""data doesn't get repeated"", each service would be built with different frameworks and languages like django and rails which use very different ORM standards.</p>&#xA;&#xA;<p>What would be the correct approach? Since I think working with one database would involve a lot of ""hacking"" the ORMs in order to make them work correctly.</p>&#xA;"
44884316,How to implement contract testing when kafka is involved in microservice architecture?,<java><jvm><apache-kafka><microservices><pact>,1,1471,0,2.0,10,<p>I am currently working on a project where we have kafka implementation in micro service architecture. Were you successful in creating contract test cases for mS to kafka topic interaction please using pact-jvm ?</p>&#xA;&#xA;<p>My implementation is microservice1 publishes a message to a REST Client which in turn posts the message to Kafka Topic. microservice2 uses GET method to retrieve messages from the Kafka Topic.</p>&#xA;
50629814,"Javascript library to collect objects properties, do batch processing and map results back to objects",<javascript><node.js><microservices>,3,65,0,0.0,-2,"<p>For array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1},&#xA;    {id: 2, name: ""test"", tagId: 15},&#xA;    {id: 3, name: ""test"", tagId: 5},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Need to reduce list of specific properties (tagId) to unique array [1,15,5], call some batch processing method, for example, doing http request for API for list of entities:</p>&#xA;&#xA;<pre><code>async (ids) =&gt; await axios.get('http://apihost/tag', {id: ids})&#xA;</code></pre>&#xA;&#xA;<p>For result array of objects:</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""tag1""},&#xA;    {id: 15, name: ""tag2""},&#xA;    {id: 5, name: ""tag3""},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>Finally need to map this objects by ID attribute to original array of objects matching by result.id => original.tagId, in fact doing an SQL join of two arrays to get this (like <a href=""https://github.com/mtraynham/lodash-joins"" rel=""nofollow noreferrer"">https://github.com/mtraynham/lodash-joins</a>):</p>&#xA;&#xA;<pre><code>[&#xA;    {id: 1, name: ""test"", tagId: 1, tag: {id: 1, name: ""tag1""}},&#xA;    {id: 2, name: ""test"", tagId: 15, tag: {id: 15, name: ""tag2""}},&#xA;    {id: 3, name: ""test"", tagId: 5, tag: {id: 5, name: ""tag3""}},&#xA;]&#xA;</code></pre>&#xA;&#xA;<p>I'm already wrote a PHP library for this with API like:</p>&#xA;&#xA;<pre><code>new BulkMap(source).map(&#xA;  'tagId',&#xA;  'tag',&#xA;  async (ids) =&gt; axios.get('http://apihost/tag', {id: ids})&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>But now i need this in JS. Is there any Javascript/NodeJS library to do so? It looks like pretty common used pattern for microservices.</p>&#xA;"
36415988,Is there some crashreporting library for java applications?,<java><monitoring><microservices><reliability>,1,56,3,0.0,-2,"<p>I wan't to be able to perform Asserts in production runtime, and send out crash reports (with CRITICAL or WARNING messages) through different channels. Emails being one of them.</p>&#xA;&#xA;<p>As you can see, I wan't this library to be performing collection of most commonly required stats - like Stacktrace, Host details, configurations etc. </p>&#xA;"
43593778,Microservices design,<java><spring><microservices>,1,122,9,1.0,-2,"<p>I am new to microservices and I am getting a hardtime in understanding what they exactly are. I would take an example situation, if you can break it down to how microservices should be written for this scenario then it woud be really great. </p>&#xA;&#xA;<p>Scenario: I have to work with two content management systems: Documentum and IBM FileNet.</p>&#xA;&#xA;<p>For each content management system I want to write an implementation to - </p>&#xA;&#xA;<ol>&#xA;<li>Create a new file or a folder.</li>&#xA;<li>Update a fileor a folder. </li>&#xA;<li>Delete a fileor a folder.</li>&#xA;<li>Update fileor folder metadata.</li>&#xA;<li>Search a file.</li>&#xA;<li>Get content of a file.</li>&#xA;<li>Create and Update permission sets applied on file or folder.&#xA;etc. </li>&#xA;</ol>&#xA;&#xA;<p>How should I break this down to microservices? &#xA;Should I write implementation for each content management systems in a seperate microservice? </p>&#xA;&#xA;<p>Please help.</p>&#xA;&#xA;<p>Thanks </p>&#xA;"
49910421,Is this microserviced?,<java><spring-boot><microservices>,3,59,5,3.0,-2,"<p>I have created a simple blogging application using Spring Boot and RESTful APIs.  I have connected the same to a MySQL database to run some SQL queries like those for adding a blog, deleting a blog, etc.</p>&#xA;&#xA;<p>My questions are as follows:</p>&#xA;&#xA;<ol>&#xA;<li><p>Does it mean that I have used a <em>microservice</em> architecture?  When does an architecture become a <em>microservice</em>? (I ask because many similar websites call an application as microservice-based.  Other than the main application, e.g., currency exchange instead of blogging, I see no other difference; for e.g., <a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">this one</a> - it does have many more aspects, but they are not contributing to its <em>microservice</em>-ness, IMHO).  </p></li>&#xA;<li><p>Can I call an application as horizontally scalable if I am using <em>microservice-based</em> architecture?</p></li>&#xA;</ol>&#xA;&#xA;<p>Note:  The tutorial I followed is <a href=""https://medium.com/@salisuwy/building-a-spring-boot-rest-api-part-iii-integrating-mysql-database-and-jpa-81391404046a"" rel=""nofollow noreferrer"">here</a> and the GitHub repo is <a href=""https://github.com/salisuwy/building-spring-boot-resp-api-v3"" rel=""nofollow noreferrer"">here</a>.</p>&#xA;"
40884616,REST based message queue for microservices,<java><activemq><message-queue><microservices>,1,660,3,0.0,-2,"<p>I'm given a task to implement Message queue to publish and consume message over queue but my requirement is, i'm gonna need to interact with queue using REST API (eg: ActiveMQ having REST API but problem with ActiveMq is when implementing consumer  we don't have way to keep waiting for message queue to fetch,we cant listen to the queue using REST client ).&#xA;So  i'm leaving my problem to you guys to give me better alternative for this &#xA;NOTE - solution should use only open source product only </p>&#xA;"
50891382,Unit test does not cover locally imported packages,<go><microservices><go-gin><go-toolchain>,1,55,4,0.0,-2,"<p>I am new to golang and trying to understand how i can make this scenario work?</p>&#xA;&#xA;<p>Here is my structure&#xA;GOPATH set to /Users/xyz/project</p>&#xA;&#xA;<pre><code>/Users/xyz/project/src/main.go // import calculator and call SUM with two integeres&#xA;/Users/xyz/project/src/main_test.go // test function&#xA;/Users/xyz/project/src/calculator/sum.go // SUM function (add two integers)&#xA;</code></pre>&#xA;&#xA;<p>i have a main go file that imports ""calculator"" which is a local packages. When i run </p>&#xA;&#xA;<pre><code>go test -cover&#xA;</code></pre>&#xA;&#xA;<p>it only gives the coverage of main but not for the package ""calculator"" imported by main. i know i can write a test inside calculator and that would do the trick but is there any way possible to get the coverage of locally imported package from main?</p>&#xA;&#xA;<p>Bigger Context - The reason i want to do this is because i have a micro service written in go using gin framework and i want to spin it up as a service and make http calls and further see how the coverage looks like (like component test). I can easily spin it up by writing a main_test go file which starts the service but i am not getting the coverage of the imported packages.</p>&#xA;"
26247474,Is Apache Camel irrelevant when Spring Cloud is used?,<apache-camel><mule><spring-boot><microservices><spring-cloud>,1,1095,0,0.0,-1,"<p>I am involved in the design of a service that uses Spring Cloud and Apache Camel. I was taken aback today when a colleague asked (maybe advocating would be a better term) whether we really need Apache Camel. From his perspective, most of the downstream systems we talk to are REST-based and therefore, no integration framework should be needed. If my recollection is correct, he also implied that Microservices and Integration Frameworks are incompatible.</p>&#xA;&#xA;<p>I started passionately suggesting that Spring Cloud helps solve a deployment/ops issue while Integration frameworks solve integration issues and that they have orthogonal requirements.</p>&#xA;&#xA;<p>Here are some of the protocols the system will be using to communicate:</p>&#xA;&#xA;<pre><code>REST&#xA;SOAP&#xA;AMQP&#xA;Azure SDK&#xA;AWS SDK (S3, SimpleBD, etc.)&#xA;Dropbox SDK&#xA;Paypal SDK&#xA;Braintree SDK&#xA;Caching (Memcached, EhCache)&#xA;Async (VM, Direct-VM, SEDA, SEDA-VM)&#xA;Facebook&#xA;Twitter&#xA;FTP&#xA;SMTP&#xA;File IO&#xA;SOLR/Elesticsearch&#xA;Quartz&#xA;</code></pre>&#xA;&#xA;<p>Unknown protocols: as we integrate in customers environment we need to integrate with their systems. The communication protocols are yet unknown.</p>&#xA;&#xA;<p>The following statement by Martin Fowler and James Lewis seems to suggest that ESB and Microservices are incompatible: ""We can't resist mentioning Jim Webber's statement that ESB stands for ""Egregious Spaghetti Box"". Now, how far do you think this statement applies to an integration framework such as Apache Camel?</p>&#xA;&#xA;<p>And more generally, does my colleague have a point? Does this mean that integration patterns have no place in microservices?</p>&#xA;"
25974964,Are micro-services in low latency systems a good recommendation?,<java><design><low-latency><microservices>,1,609,2,0.0,-1,"<p>I am building a low latency system that does some currency exchange transactions to some exchanges and a friend recently told me that my micro-services approach is going to make things slower... I don't fully agree with him, and I think that it should be no major impact in performance and micro-services is the right path to go in order to have a more maintainable system. &#xA;I would be happy in getting some feedback from you to see what do you think about this topic.</p>&#xA;&#xA;<p>More specifically, in use case, I have an app that queries some data from some provider, transforms it to a JSon and sends it to the next application. The second application unmarshall the JSonMessage do some calculations, marshalls again and sends it to the third application. The third and last application its very simple it just needs to perform an operation in some currency exchanges with that message.  </p>&#xA;&#xA;<p>So my friend says that I should embed all 3 apps into 1 due to lack of performance when marshalling and unmarshalling... I can clearly distinguish different reasons to exist independently to each of the 3 apps, and I don't think it will be problematic to work in this style. Also I want to mention that I don't use any database or any sort of state, the hold system its completely stateless.</p>&#xA;"
36026454,SFTP ChannelSftp.put stop it's execution process but successfully being uploaded or copy the source file,<java><sftp><dropwizard><jsch><microservices>,1,571,5,1.0,-1,"<p>details:</p>&#xA;&#xA;<p>in my API i have struggle on debugging why is that the ChannelSftp.put method hangs up or stop it's execution process but when checking it's output it is successfully being uploaded. </p>&#xA;&#xA;<p>here's my code snippet:</p>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>@Inject&#xA;MyConfiguration conf;&#xA;&#xA;public String copyAndMove( String fileName ){&#xA;    try{&#xA;        MyServer origin = conf.getOriginServer().setFileName( fileName );&#xA;        MyServer destination = conf.getDestinationServer().setFileName( fileName );&#xA;&#xA;        SFTPServer originSftpServer = new SFTPServer( origin ).build();&#xA;        SFTPServer destinationSftpServer = new SFTPServer( destination ).build();&#xA;&#xA;        // originSftpServer.copyTo(destinationSftpServer);&#xA;        originSftpServer.copyTo(originSftpServer);&#xA;&#xA;        return ""Successfully copied file."";&#xA;        }catch( Exception ex ){&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>SFTPServer.class</p>&#xA;&#xA;<pre><code>public class SFTPServer {&#xA;&#xA;    private MyServer server;&#xA;    private static SFTPServer instance;&#xA;&#xA;    private Session session = null;&#xA;    private Channel channel = null;&#xA;    private ChannelSftp channelSftp = null;&#xA;&#xA;    // getters and setters&#xA;&#xA;    public SFTPServer(){}&#xA;&#xA;    public SFTPServer(MyServer server) throws  Exception{&#xA;        if(CommonUtil.isNull( server )){&#xA;            throw new Exception(""MyServer cannot be null!"");&#xA;        }&#xA;&#xA;        this.server = server;&#xA;    }&#xA;&#xA;    public SFTPServer build(){&#xA;        try{&#xA;            this.session = SFTPUtil.constructSession(getServer());&#xA;            this.channel = SFTPUtil.constructChannel(getSession());&#xA;            this.channelSftp = (ChannelSftp) channel;&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;&#xA;    public SFTPServer copyTo( SFTPServer destination ) {&#xA;        InputStream is = null;&#xA;        try{&#xA;            ChannelSftp channel = destination.getChannelSftp();&#xA;            String originSourceFile = String.format(""%s/%s"", getServer().getSourceFilePath(), getServer().getFileName());&#xA;            String destinationProcessedFile = String.format(""%s/%s"", destination.getServer().getProcessedFilePath(), destination.getServer().getFileName());&#xA;&#xA;            is = getChannelSftp().get(originSourceFile);&#xA;            channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }finally{&#xA;            CommonUtil.closeQuitely(is); // close input stream&#xA;            destination.destroy(); // disconnect session, channel, channelSftp&#xA;        }&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is this. it's seems that it cannot proceed until the program done for it's execution. when i debug on it it stop and it's execution for this code: <strong>channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);</strong> but on the sftp server it is successfully being copied from source to destination file path. please help me with this problem because it cannot return the <strong>Successfully copied file.</strong> on the service part. thanx. </p>&#xA;"
42105805,Microservices Communication Design,<python><api><microservices>,2,629,0,0.0,-1,<p>I would like to know how to create a communication for each services. I am using API Gateway for the outside of the system to communicate with the services within. Is it necessary for a service to call another service through API Gateway or just directly into the service itself ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;
35838016,Which microservice library is best or mostly used?,<microservices>,1,472,3,0.0,-1,<p>I am split my business logic into micro services. Which micro services library is good or mostly used? what about apache karaf? </p>&#xA;
49036468,Inter-Process communication in a microservices architecture,<web-services><ipc><microservices>,6,171,0,0.0,-1,"<p>we are moving from monolithic to microservice architecture application, we're still in planning phase and we want to know what is the best practices of building it.</p>&#xA;&#xA;<p>suppose we have two services :</p>&#xA;&#xA;<ol>&#xA;<li><strong>User</strong> </li>&#xA;<li><strong>Device</strong>&#xA;&#xA;<ul>&#xA;<li>getUserDevices(UserId)</li>&#xA;<li>addDevice(DeviceInfo, UserId)</li>&#xA;<li>...</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p><strong>Each user has multiple devices</strong></p>&#xA;&#xA;<p>what is the most common, cleaner and proper way of asking the server to get all user devices ?</p>&#xA;&#xA;<p>1- <strong>{api-url}/User/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>needs another HTTP request to communicate with Device service.</p>&#xA;  &#xA;  <p>for user X, get linked devices from <strong>User</strong> service.</p>&#xA;</blockquote>&#xA;&#xA;<p>// <strong>OR</strong></p>&#xA;&#xA;<p>2- <strong>{api-url}/Device/{UserId}/devices</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>for user X, get linked devices from <strong>Device</strong> service.</p>&#xA;</blockquote>&#xA;"
46321680,How correctly make project structure in IntelliJ IDEA for Spring Boot microservices?,<java><spring-boot><intellij-idea><microservices>,1,662,2,0.0,-1,<p>I used to work with Monolithic architecture and I don't have experience with Microservices. I need to create project with some modules (microservices).</p>&#xA;&#xA;<ol>&#xA;<li>auth </li>&#xA;<li>messages</li>&#xA;</ol>&#xA;&#xA;<p>I use IntelliJ IDEA for my project.</p>&#xA;&#xA;<p>Can you explain me what is the best practice for microservices project structure in this IDE?</p>&#xA;&#xA;<p>Should I use Maven or it is better to add IntelliJ IDEA project modules?</p>&#xA;
45115860,how to use golang microservices?,<go><microservices>,3,381,1,3.0,-1,"<p>My company use Go to build some HTTP API services. We want these services share one HTTP port. </p>&#xA;&#xA;<p>So the solution right now is we create a project named router, and router import some modules, every request pass through router to their own modules.<br>&#xA;But the question is that if one of these modules process crashed, the router just crash.</p>&#xA;&#xA;<p>Is there any solutions?</p>&#xA;&#xA;<p>Require:</p>&#xA;&#xA;<ol>&#xA;<li>One http port.</li>&#xA;<li>Every service is independent.</li>&#xA;</ol>&#xA;&#xA;<p>I know go-kit and go micro, also I have tried, but still not too understand.</p>&#xA;"
41749456,How to integrate Machine learning into a ruby on rails application,<python><ruby-on-rails><r><ruby><microservices>,1,1288,0,1.0,-1,"<p>Given Python and R have huge machine learning libraries that make it easy to train a machine learning model, and given rails provides a very fast way of building a web app, is there a 'best practice' for integrating a machine learning model (written in python or R) into a rails application? </p>&#xA;&#xA;<p>If so what tools can we use? What are pros and cons of each?</p>&#xA;"
49922136,Nuget package restore ERROR,<.net><.net-core><nuget><microservices><nuget-package>,1,47,6,0.0,-1,<p>We created one rest client application and pushed it to nuget with version 1.0.0 and used it in one of our Micro Services and then recently we updated our Rest client application with new version 1.1.0 and tried to update it in our Micro services using nuget package restore. </p>&#xA;&#xA;<p>Now we got the latest version of our RestClient application dll ie Project.json file got updated with my latest version 1.1.0. But now when i try to build the application i am getting error for namespace not found for restclient</p>&#xA;&#xA;<p>When i checked project.json its already updated with my new version 1.1.0</p>&#xA;&#xA;<p>NOTE: I am using .net core</p>&#xA;&#xA;<p>Why i am not getting reference to my latest RestClient dll (1.1.0) in my MicroServices? </p>&#xA;&#xA;<p>Is there any work around for it?</p>&#xA;&#xA;<p>One work around i did is i deleted Project.json.lock files and i tried to restore again. But no luck</p>&#xA;
47767993,Split Rails app to small microservices with Go,<ruby-on-rails><go><microservices>,1,126,0,2.0,-1,"<p>I'm wondering to do some scaling on our Rails app and I'd like to use Go lang. So, today we have quite big application written in RoR and Postgresql, where a lot of processing&amp;computations goes through Ruby which turned to be slow. </p>&#xA;&#xA;<p>I'm wondering to take some parts of our application, and to re-write them in Golang for the sake of better performances. </p>&#xA;&#xA;<p>I'd like to hear some good advices&amp;practices, especially how to start splitting them. How Go&amp;Rails can communicate and how to move some <strong>hard</strong> computations to Go ? Is there some way they can share same database/data ? </p>&#xA;&#xA;<p>Best Regards</p>&#xA;"
38403001,How to listen two micro services on same port in Node.js,<node.js><microservices>,1,760,9,1.0,-1,"<p>I am new to micro service. I want to create one application with two micro services. But i don't know how to listen both (or more) micro services on a same port to make it as one application. &#xA;Is there any good tutorial pages available in online ? Please suggest me any blogpost or tutorial pages or help me to create a application with two micro services.</p>&#xA;&#xA;<p>I am trying to create a Bus booking application which has two services, </p>&#xA;&#xA;<ol>&#xA;<li>Bus Service (which gives bus names &amp; availability)</li>&#xA;<li>User Service (which gives &amp; connect user details with bus).</li>&#xA;</ol>&#xA;&#xA;<p>I created two this as two nodejs application. Now i need to know how to combine this two as one application (with microservice).for that i can't listen this to one port.</p>&#xA;"
51454764,View injection container for angular,<angular><dependency-injection><microservices><view-injection><micro-frontend>,1,49,3,1.0,-1,"<p>I'm trying to have an angular module for each backend microservice. So to keep each module independent and clean while they use each other's components when available and a default ""service-is-not-available"" component, when the component is not found in the container.</p>&#xA;&#xA;<p><strong>Example Scenario:</strong> Let's say there are a sales and accounting module.&#xA;The sales module needs a component with selector: 'total-price'.&#xA;Sales module and Accounting module are both used by the main module, but the sales doesn't know about accounting.&#xA;When I call the 'total-price' tag in sales I want the main module to find it in the accounting and display it in the sales.</p>&#xA;&#xA;<p>Here the 'total-price' tag selector works like an abstraction (OO interface) which it's implementation is placed at accounting module, and the main module should have an IOC to search and find the implementation an inject it to the sales, and return a not found view if the view is unavailable (kind of like null object pattern). This may also help with handling authorization and returning a proper view whenever the user is not permitted to see some component.</p>&#xA;&#xA;<p><strong>Code Sample:</strong>&#xA;<a href=""https://stackblitz.com/edit/angular-vxstyk?file=src%2Fapp%2Fsales%2Fsales%2Fsales.component.html"" rel=""nofollow noreferrer"">This</a> is a sample code for the scenario but it doesn't compile, because as my question states I'm looking for a way of orchestrating, and composing the UI and injecting the <code>&lt;total-price&gt;</code> component to sales without referencing the accounting module directly.</p>&#xA;"
44000273,Micro service Architecture based on RESTful API's in java,<java><rest><design-patterns><microservices>,3,152,4,0.0,-1,"<p>Best Architecture for implementing a <strong>WebService</strong> that takes requests from one side, save and enhance that and then call another service with new parameters.&#xA;is there any special <code>Design Pattern</code> for this?</p>&#xA;"
45598647,Microservice between my own application and a logging application to structure logging,<c#><microservices>,2,307,4,0.0,-1,<p>I'm trying to find a good example which explains me how I can build a micro-service that I can put between my own application and a logging application like seq. In this way I'll try to put the logging data in the same destination an I can switch easily from those logging application so I don't have to edit my entire code. Is there a way to do this and maybe a example which explains this. I've already googled for it but I didn't found any clear explanations.</p>&#xA;
50801690,Working with microservices. Hibernate or Scripts,<java><database><hibernate><microservices>,1,58,3,0.0,-1,"<p>What is the best approach for database creation and relationship management when working with microservices?Hibernate or scripts, as i feel it shouldn't be the responsibility of microservices to create a database </p>&#xA;"
