Id,Title,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
45174699,jwt - Django-rest-framework-jwt authentication in microsevices,<jwt><microservices>,1,163,3,0.0,0,"<p>I am newbie in JSON web token and micro services. I read in an articles that if i share the private, all services can verify user on their own. Then i tried to implement an application to practice.&#xA;Basically, I have two services A and B. A is used for authentication. Then, I tried implement a API that required authentication in service B. But when I used a token generated by authentication A in API, 401 status code and ""Invalid signature."" were returned. &#xA;So anyone can explain to me what I did wrong?</p>&#xA;"
39405067,org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization,<java><spring-boot><microservices>,1,14900,0,2.0,0,"<p>I'm developing <strong>spring boot microservices</strong> example from the link: <a href=""https://dzone.com/articles/spring-boot-creating"" rel=""nofollow"">https://dzone.com/articles/spring-boot-creating</a>. In this project I simply updated the parent dependency to its latest version and other code files are unchanged. I faced the following error when I click <strong><a href=""http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4"" rel=""nofollow"">http://localhost:8080/order?idCustomer=2&amp;idProduct=3&amp;amount=4</a></strong></p>&#xA;&#xA;<pre><code>2016-09-09 11:46:20.888 ERROR 14152 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : StandardWrapper.Throwable&#xA;&#xA;org.glassfish.jersey.server.model.ModelValidationException: Validation of the application resource model has failed during application initialization.&#xA;[[FATAL] A resource model has ambiguous (sub-)resource method for HTTP method GET and input mime-types as defined by""@Consumes"" and ""@Produces"" annotations at Java methods public java.util.List br.com.alexandreesl.handson.rest.ProductRest.getProducts() and public java.util.List br.com.alexandreesl.handson.rest.CustomerRest.getCustomers() at matching regular expression /. These two methods produces and consumes exactly the same mime-types and therefore their invocation as a resource methods will always fail.; source='org.glassfish.jersey.server.model.RuntimeResource@14c14bf']&#xA;    at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:555) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.access$500(ApplicationHandler.java:184) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:350) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler$3.call(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:315) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.process(Errors.java:297) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.internal.Errors.processWithException(Errors.java:255) ~[jersey-common-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.server.ApplicationHandler.&lt;init&gt;(ApplicationHandler.java:347) ~[jersey-server-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.WebComponent.&lt;init&gt;(WebComponent.java:392) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:177) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:369) ~[jersey-container-servlet-core-2.23.1.jar:na]&#xA;    at javax.servlet.GenericServlet.init(GenericServlet.java:158) ~[tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1194) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapper.allocate(StandardWrapper.java:806) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:133) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:522) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:1110) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:785) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1425) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_102]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_102]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.4.jar:8.5.4]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_102]&#xA;</code></pre>&#xA;&#xA;<p>the updated <strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;junit&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;junit&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Application.java</strong></p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;public class Application {&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(Application.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ApplicationConfig.java</strong></p>&#xA;&#xA;<pre><code>@Configuration&#xA;public class ApplicationConfig {&#xA;    @Named&#xA;    static class JerseyConfig extends ResourceConfig {&#xA;        public JerseyConfig() {&#xA;            this.packages(""br.com.alexandreesl.handson.rest"");&#xA;        }&#xA;    }&#xA;&#xA;    @Bean&#xA;    public RestTemplate restTemplate() {&#xA;        RestTemplate restTemplate = new RestTemplate();&#xA;        return restTemplate;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Order.java</strong></p>&#xA;&#xA;<pre><code>public class Order {&#xA;    private long id;&#xA;    private long amount;&#xA;    private Date dateOrder;&#xA;    private Customer customer;&#xA;    private Product product;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>OrderRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class OrderRest {&#xA;    private long id = 1;&#xA;&#xA;    @Inject&#xA;    private RestTemplate restTemplate;&#xA;&#xA;    @GET&#xA;    @Path(""order"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Order submitOrder(@QueryParam(""idCustomer"") long idCustomer,&#xA;            @QueryParam(""idProduct"") long idProduct,&#xA;            @QueryParam(""amount"") long amount) {&#xA;&#xA;        Customer customer = restTemplate.getForObject(""http://localhost:8080/customer?id={id}"", Customer.class, idCustomer);&#xA;        Product product = restTemplate.getForObject(""http://localhost:8080/product?id={id}"", Product.class,idProduct);&#xA;&#xA;        Order order = new Order();&#xA;        order.setCustomer(customer);&#xA;        order.setProduct(product);&#xA;        order.setId(id);&#xA;        order.setAmount(amount);&#xA;        order.setDateOrder(new Date());&#xA;        id++;&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Customer.java</strong></p>&#xA;&#xA;<pre><code>public class Customer {&#xA;    private long id;&#xA;    private String name;&#xA;    private String email;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>CustomerRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class CustomerRest {&#xA;    private static List&lt;Customer&gt; customers = new ArrayList&lt;Customer&gt;();&#xA;&#xA;    static {&#xA;        Customer customer1 = new Customer();&#xA;        customer1.setId(1);&#xA;        customer1.setNome(""Customer 1"");&#xA;        customer1.setEmail(""customer1@gmail.com"");&#xA;&#xA;        Customer customer2 = new Customer();&#xA;        customer2.setId(2);&#xA;        customer2.setNome(""Customer 2"");&#xA;        customer2.setEmail(""Customer2@gmail.com"");&#xA;&#xA;        Customer customer3 = new Customer();&#xA;        customer3.setId(3);&#xA;        customer3.setNome(""Customer 3"");&#xA;        customer3.setEmail(""Customer3@gmail.com"");&#xA;&#xA;        Customer customer4 = new Customer();&#xA;        customer4.setId(4);&#xA;        customer4.setNome(""Customer 4"");&#xA;        customer4.setEmail(""Customer4@gmail.com"");&#xA;&#xA;        Customer customer5 = new Customer();&#xA;        customer5.setId(5);&#xA;        customer5.setNome(""Customer 5"");&#xA;        customer5.setEmail(""Customer5@gmail.com"");&#xA;&#xA;        customers.add(customer1);&#xA;        customers.add(customer2);&#xA;        customers.add(customer3);&#xA;        customers.add(customer4);&#xA;        customers.add(customer5);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Customer&gt; getCustomers() {&#xA;        return customers;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""customer"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Customer getCustomer(@QueryParam(""id"") long id) {&#xA;        Customer cli = null;&#xA;        for (Customer c : customers) {&#xA;            if (c.getId() == id)&#xA;                cli = c;&#xA;        }&#xA;        return cli;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>Product.java</strong></p>&#xA;&#xA;<pre><code>public class Product {&#xA;    private long id;&#xA;    private String sku;&#xA;    private String description;&#xA;    // setters and getters&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><strong>ProductRest.java</strong></p>&#xA;&#xA;<pre><code>@Named&#xA;@Path(""/"")&#xA;public class ProductRest {&#xA;    private static List&lt;Product&gt; products = new ArrayList&lt;Product&gt;();&#xA;&#xA;    static {&#xA;        Product product1 = new Product();&#xA;        product1.setId(1);&#xA;        product1.setSku(""abcd1"");&#xA;        product1.setDescription(""Product1"");&#xA;        Product product2 = new Product();&#xA;        product2.setId(2);&#xA;        product2.setSku(""abcd2"");&#xA;        product2.setDescription(""Product2"");&#xA;        Product product3 = new Product();&#xA;        product3.setId(3);&#xA;        product3.setSku(""abcd3"");&#xA;        product3.setDescription(""Product3"");&#xA;        Product product4 = new Product();&#xA;        product4.setId(4);&#xA;        product4.setSku(""abcd4"");&#xA;        product4.setDescription(""Product4"");&#xA;        products.add(product1);&#xA;        products.add(product2);&#xA;        products.add(product3);&#xA;        products.add(product4);&#xA;    }&#xA;&#xA;    @GET&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public List&lt;Product&gt; getProducts() {&#xA;        return products;&#xA;    }&#xA;&#xA;    @GET&#xA;    @Path(""product"")&#xA;    @Produces(MediaType.APPLICATION_JSON)&#xA;    public Product getProduct(@QueryParam(""id"") long id) {&#xA;        Product prod = null;&#xA;        for (Product p : products) {&#xA;            if (p.getId() == id)&#xA;                prod = p;&#xA;        }&#xA;        return prod;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Please guide on this issue.</p>&#xA;"
39425569,Spring Boot Java8 Microservice Simple Message Subscription service,<spring-boot><java-8><jms><microservices>,2,659,0,0.0,0,<p>I am new to Microservice and JMS likes to know how can I</p>&#xA;&#xA;<ul>&#xA;<li>create a subscription      </li>&#xA;<li>read the subscription </li>&#xA;</ul>&#xA;&#xA;<p>Using Spring Boot and JMS </p>&#xA;
39416301,Microservices - API Gateway Layer,<spring-boot><cloudfoundry><microservices><pivotal-cloud-foundry>,1,1395,1,0.0,0,"<p>I have read few details of use of api gateway in microservices architecture. I have read that it basically helps with security , transformation , throttling etc. Is orchestration also one of it responsibilities? When I read about microservices , I saw that it should have dumb pipes and smart endpoints and services must be choreographed and not orchestrated. So my assumption is that orchestration is not a responsibility  of api gateway.</p>&#xA;"
42691892,Microservices Per DB table,<domain-driven-design><microservices>,3,200,2,0.0,0,"<p>I ran into the microservices architecture for e-commerce application where each table has it's own micro service basically with CRUD operations (something like rest client for each table). &#xA;Now I am thinking about combine and model them around business domains, before that I wanted to know does anyone encountered such situation and is it right architecture or not.&#xA;Any suggestions will be very helpful.&#xA;Thanks.</p>&#xA;"
40044128,Fetch Configuration from Spring Cloud Config over SSL,<java><ssl><spring-boot><microservices><spring-cloud-config>,2,1658,0,0.0,0,"<p>I am building microservices using Spring Boot where configuration is distributed using Spring Cloud Config. Config application has SSL enabled.</p>&#xA;&#xA;<p>I want my spring boot application to communicate to Config server over https. Problem is that before loading SSL configuration from bootstrap.yml, application initiates a rest call to Config Server to fetch the configuration and fails miserably with error:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""https://host:8888/abcd/development,production"": sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; nested exception is javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: &#xA;</code></pre>&#xA;&#xA;<p>I have configured a truststore with CA certificate in bootstrap.yml:</p>&#xA;&#xA;<pre><code># MicroServices Properties&#xA;spring:&#xA;  application:&#xA;     name: abcd&#xA;  profiles:&#xA;    active: development,production&#xA;  cloud:&#xA;    config:&#xA;      uri: https://&lt;host&gt;:8888 &#xA;      fail-fast: true&#xA;      password: abc@123&#xA;      username: user&#xA;server:&#xA;  ssl:&#xA;    trust-store: D:/Certs/caCert/server.p12&#xA;    trust-store-password: keystore&#xA;    key-store-provider: PKCS12&#xA;</code></pre>&#xA;&#xA;<p>Any suggestions what should I do to create successful SSL communication with Config Server?</p>&#xA;"
39932500,Microservices with Spring-Boot and Release Management,<spring-boot><microservices><spring-boot-maven-plugin>,1,485,5,1.0,0,"<p>Looking for advice in how to do release management of microservices built with Spring Boot. </p>&#xA;&#xA;<p>Most projects I've worked use the release plugin (maven) to create tags as well as to release maven projects (jar, war, rpm). Usually, this relies on the maven parent/child relationship for all sub-projects (jars, wars) during the release process (monolith source code, all living in a single git repository). I'm wondering how do people maintain different boot projects (microservices) and make releases.  </p>&#xA;&#xA;<p>The way I see it, the following are possible strategies:</p>&#xA;&#xA;<ol>&#xA;<li>One Spring Boot project (microservice maven project) per git repository so that releases are managed independently. </li>&#xA;<li>A Multi-Module maven project with each module being a microservice. All submodules (microservices) will have to be released together. The parent pom will have to use a Boot's parent pom. </li>&#xA;<li>Rely on the maven-release-plugin ability to release only certain sub-modules based on a release. This will make each maven sub-module have different versions (potentially).</li>&#xA;</ol>&#xA;&#xA;<p>What has your team found useful? I like Boot's programming model, but I'm hopeful I can use a release strategy that is consistent with Boot model of keeping things simple.</p>&#xA;"
40132631,SocketTimeoutException : null while opening New Spring Starter Project,<spring><web-services><spring-boot><microservices><eclipse-jee>,1,1497,0,0.0,0,"<p>SocketTimeoutException : null while opening New Spring Starter Project</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/uWW5K.png"" alt=""enter image description here""></p>&#xA;&#xA;<pre><code>JAVA_HOME=C:\Program Files (x86)\Java\jdk1.7.0_40&#xA;Path=%JAVA_HOME%\bin;C:\..&#xA;</code></pre>&#xA;"
40208887,"When utilizing a microservices architecture, will the underlying read/write database become a bottleneck?",<sql><amazon-web-services><scalability><microservices>,3,348,1,0.0,0,"<p>As I described in the question, if I were to implement a microservices architecture, would the centralized read/write database become a bottleneck?</p>&#xA;&#xA;<p>To expand with an example, let's say I have three microservices: <code>users</code>, <code>teams</code>, and <code>team_members</code>. Each has its own microservice, but they all rely on each other in the database, so exclusive, parallel databases wouldn't be appropriate. Since microservices is meant to distribute the work to several different servers, doesn't the central database ultimately defeat the purpose of these microservices, as they all end up calling to the same server?</p>&#xA;"
40108015,Microservice's High availability concern on cloud,<cloud><microservices>,1,230,3,0.0,0,"<p>I was reading about Microservices and everything makes sense to me but I have one little doubt.</p>&#xA;&#xA;<p>On cloud, every component has a availability SLA (lets assume 99.9%). So, if we have a single component to do a job, our application SLA would be the same (approx.). But if we create multiple components to do one job, our application's SLA would be reduced because all the components can go down at different time. In microservices, one service can communicate to other services to complete a task. Now, any of the participant service can be down at different time, So our application availability will be lesser compared to monolithic service?</p>&#xA;"
41880524,Microservices based architecture and individual cache for each node,<java><hibernate><caching><architecture><microservices>,1,764,0,0.0,0,"<p>Is it considered bad practice to use separated, local cache for each node in distributed microservice application? I've heard that in monolithic application it's OK to use local EHCache as 2nd level cache provider for Hibernate, but in distributed environment it's common practice to use distributed caches, such as Memcached, Redis or Hazelcast. What are the consequences of using separated cache for each node?</p>&#xA;"
37403682,A real world project using microservices architecture,<node.js><architecture><microservices>,1,483,5,0.0,0,"<p>Anyone knows an open source project that is on microservices architecture? I need a more real app that has addressed cross-cutting concerns,etc not just an educational sample.</p>&#xA;&#xA;<p>Please introduce if you know any. Especially if it's on Node.js or C#.net stack.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
50289914,Deal with enumeration in Microservices architecture,<architecture><microservices><enumeration>,2,41,3,1.0,0,"<p>I recently faced a problem when I designed the microservices architecture of our new system. &#xA;To give more context on that, let's suppose that we have two different services. </p>&#xA;&#xA;<ul>&#xA;<li><p>A service is responsible to make payments and the other one </p></li>&#xA;<li><p>B service is responsible to keep track of the orders. </p></li>&#xA;</ul>&#xA;&#xA;<p>We have a use case that we need to update an order state from the service A. </p>&#xA;&#xA;<p>We have these states in an enumeration list inside the service B. </p>&#xA;&#xA;<p>How can I avoid the sharing of this enumeration between two services? &#xA;I need to have decoupled services.</p>&#xA;&#xA;<p>Please feel free to ask for clarifications. </p>&#xA;"
43607751,How to create SPARK/Flink Stream Data Processing as a Microservice (REST API),<apache-spark><playframework-2.0><microservices><apache-flink><lagom>,1,224,0,2.0,0,"<p>I am creating streaming analytics application using Spark, Flink &amp; Kafka. Each analytics/functionality will implement as a Microservice so that this analytics can able to use in the different project later.</p>&#xA;&#xA;<p>I run my Spark/Flink job perfectly in Simple Scala application and submit this job over Spark &amp; Flink cluster respectively. But I have to start/run this job when REST POST startJob() request invoke to my web service.</p>&#xA;&#xA;<p>How can I integrate my Spark &amp; Flink data processing functionality in a web service oriented application? </p>&#xA;&#xA;<p>Till now I tried <a href=""http://www.lagomframework.com/"" rel=""nofollow noreferrer"">Lagom Microservice</a> but i found so many issues you can check </p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/43255302/best-approach-to-ingest-streaming-data-in-lagom-microservice"">Best approach to ingest Streaming Data in Lagom Microservice&#xA;</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/43570899/java-io-notserializableexception-using-apache-flink-with-lagom"">java.io.NotSerializableException using Apache Flink with&#xA;Lagom</a></li>&#xA;</ol>&#xA;&#xA;<p>I think i am not taking the right direction for Stream Processing Microservice Application. Looking for right direction to implement this analytics over REST Service.</p>&#xA;"
43674924,What is the best way to manage microservice issue or bug on git,<git><microservices><issue-tracking>,2,208,4,0.0,0,"<p>Micro-Service is about having many projects on git within different repositories.</p>&#xA;&#xA;<p>So, what is the best way to manage an issue, when there is a bug which needed to fix the code on multiple services?</p>&#xA;"
43018514,"AWS Lambda + Spring, how to load application.yml",<java><spring><amazon-web-services><aws-lambda><microservices>,1,695,0,1.0,0,"<p>I have problem with customizing API gateway domain, for my restful app deployed on AWS lambda. Customized domain, works this way, that depending on basePath it chooses different APIs which finally touches Lambda. For example:</p>&#xA;&#xA;<p><code>api.mycustomdomain.com/view/ping</code> -> goes to application <code>view</code> with path <code>/view/ping</code>&#xA;<code>api.mycustomdomain.com/admin/ping</code> -> goes to application <code>admin</code> with path <code>/admin/ping</code></p>&#xA;&#xA;<p>I am using this example as boilerplate: <a href=""https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-java-container/tree/master/samples/spring/pet-store</a></p>&#xA;&#xA;<p>What I would like to achieve is handler which depending on <code>Host</code> header strips prefix from request path.</p>&#xA;&#xA;<p>I have prepared following application.yml file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: ""/view""&#xA;  productionHost: ""api.mycustomdomain.com""&#xA;</code></pre>&#xA;&#xA;<p>The problem/question is. How can I now load those into my Lambda function? Here is my naive try:</p>&#xA;&#xA;<pre><code>public class LambdaHandler implements RequestHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; {&#xA;    SpringLambdaContainerHandler&lt;AwsProxyRequest, AwsProxyResponse&gt; handler;&#xA;    boolean isinitialized = false;&#xA;&#xA;    @Value(""${server.contextPath}"")&#xA;    private String prefix;&#xA;&#xA;    @Value(""${server.productionHost}"")&#xA;    private String productionHost;&#xA;&#xA;    public AwsProxyResponse handleRequest(AwsProxyRequest awsProxyRequest, Context context) {&#xA;        if(awsProxyRequest.getHeaders().get(""Host"").equals(productionHost))&#xA;            awsProxyRequest.setPath(awsProxyRequest.getPath().substring(prefix.length()));&#xA;&#xA;        if (!isinitialized) {&#xA;            isinitialized = true;&#xA;            try {&#xA;                handler = SpringLambdaContainerHandler.getAwsProxyHandler(PingPongApp.class);&#xA;            } catch (ContainerInitializationException e) {&#xA;                e.printStackTrace();&#xA;                return null;&#xA;            }&#xA;        }&#xA;        return handler.proxy(awsProxyRequest, context);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Obviously this doesn't work, LambdaHandler is working out of Spring context.</p>&#xA;&#xA;<p>Any ideas how can I deal with that?</p>&#xA;"
42928059,Request per second and performance limit of Spring rest backend,<spring><performance><rest><microservices>,2,3308,0,0.0,0,"<p>I would like to develop a Spring REST backend application with tomcat.&#xA;I expect 1000-5000 active users. The users will create requests from clients(Android, web, Ios) to backend. Most of requests will create a simple db select.</p>&#xA;&#xA;<ul>&#xA;<li>How to calculate the limit of requests per second?</li>&#xA;<li>How to estimate the performance limits?</li>&#xA;<li>Should I use Microservice architecure or monolithic?</li>&#xA;</ul>&#xA;&#xA;<p>Thanks</p>&#xA;"
43032883,How could authentication work across microservices?,<javascript><node.js><authentication><jwt><microservices>,3,111,3,0.0,0,"<p>I have two separate Node.js services.</p>&#xA;&#xA;<p>Service <code>A</code> is responsible for authenticating users.  If a user successfully logs in, the user is redirected to Service <code>B</code> (hosted on a <strong>subdomain</strong> of the domain Service <code>A</code> is hosted on).</p>&#xA;&#xA;<p>I am using <a href=""https://jwt.io/"" rel=""nofollow noreferrer"">JWT</a> for authentication.</p>&#xA;&#xA;<p><strong>Question:</strong> How can Service <code>B</code> be aware if a user is or is not authenticated?</p>&#xA;&#xA;<p>I imagine one way that Service <code>B</code> could be aware if they are or aren't authenticated is by asking Service <code>A</code> to check the JWT on each  Request to Service <code>B</code>. But how is Service <code>A</code> supposed to send the JWT to the client when the client is going to be redirected to a new origin?</p>&#xA;&#xA;<p>Is it safe to do something like:</p>&#xA;&#xA;<pre><code>window.location.href = 'https://b.example.com?jwt=tokenhere'&#xA;</code></pre>&#xA;&#xA;<p>I don't believe storing the JWT on <code>localStorage</code> since it does not allow cross origin access.</p>&#xA;"
50039099,Separate one module from JSF application,<rest><jsf><java-ee><architecture><microservices>,1,47,4,0.0,0,"<p>We have big JSF monolithic application. We want to change the architecture of this application. Currently, my goal - change one module in our application. I need to move the logic from one module to another application which will be implemented on another stack of technologies (it will be rest-service with some js-framework on frontend).</p>&#xA;&#xA;<p>The application should work in the same way. We should have the link to the page as it was earlier but this page should be rendered by another service. We should have the same session between these 2 applications. The user should be able to go throw the pages without an additional step of authentification.</p>&#xA;&#xA;<p>We are planning to move also other modules, not only this one. I need a help. Do you have any thoughts how it should be implemented? any examples?</p>&#xA;"
34376576,Best architecture to share large files among microservices,<nfs><microservices><data-sharing>,1,1629,0,0.0,0,"<p>I am about to start re-designing an old monolithic software with a microservices-oriented architecture (educational purposes). To give a bit of context, the old software runs on a powerful server that performs the following operations:</p>&#xA;&#xA;<ol>&#xA;<li>Receives batch data (binary file) from a producer.</li>&#xA;<li>Accumulates batch data from each producer.</li>&#xA;<li>Periodically, execute a batch operation over each producer's accumulated data, and store the result (another binary file).</li>&#xA;</ol>&#xA;&#xA;<p>Now, I want to create a separated microservice for this batch operation.  I would like to have this microservice executed in dozens of machines in paralell, so that I can process a big amount of producers.</p>&#xA;&#xA;<p>Each microservice instance will receive a binary file with each producer's data and output another binary file. The problem is that these files can be big (e.g. each producer may produce 20Mb of accumulated data). I came across several ways of dealing with this but I am not convinced by any of them:</p>&#xA;&#xA;<ol>&#xA;<li>Send the binary data among microservices using HTTP calls. I did not try it but it does not seem reasonable.</li>&#xA;<li>Store all the data in a central data repository from where each microservice can download it. Maybe I could use some sort of NFS, but I am not sure if that's a good option. Also, doesn't this go against the microservices philosophy?</li>&#xA;<li>Have a copy of all the data near each microservice. I am afraid I'll eventually run into consistency problems.</li>&#xA;</ol>&#xA;&#xA;<p>What do you believe is the best option (if any)? Thanks!</p>&#xA;"
46193708,How To Make Relations Between Two Entities From Different Microservices In Spring Boot?,<spring-boot><spring-data><spring-data-jpa><microservices>,1,588,1,0.0,0,"<p>I am trying to make a simple <strong>Spring Boot</strong> web app using <strong>Microservice Architecture</strong>.</p>&#xA;&#xA;<p>I have two microservices with entities as defined below:</p>&#xA;&#xA;<pre><code>Microservice 1 :&#xA;&#xA;@Entity&#xA;public class Article {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and</p>&#xA;&#xA;<pre><code>Microservice 2 :&#xA;&#xA;@Entity&#xA;public class Tag {&#xA;&#xA;    @Id&#xA;    @GeneratedValue(strategy = GenerationType.IDENTITY)&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I want to have a <strong>Many To Many</strong> relation between these two entities in my <strong>Gateway</strong>.</p>&#xA;&#xA;<p>I had tried to use feign client as below:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@FeignClient(value = ""article-service"")&#xA;public interface ArticleClient {&#xA;&#xA;    @RequestMapping(value = ""/articles/"", method = RequestMethod.GET)&#xA;    Set&lt;Article&gt; getArticleById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;&#xA;@FeignClient(value = ""tag-service"")&#xA;public interface TagClient {&#xA;&#xA;    @RequestMapping(value = ""/tags/"", method = RequestMethod.GET)&#xA;    Tag getTagById(@RequestParam(""id"") Long id);&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And defined <strong>Article</strong> and <strong>Tag</strong> entities in my <strong>Gateway</strong> like this:</p>&#xA;&#xA;<pre><code>Gateway :&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Entry {&#xA;&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    private String Content;&#xA;&#xA;    @ManyToMany(cascade = CascadeType.ALL)&#xA;    @JoinTable(name = ""article_tag"",&#xA;        joinColumns = @JoinColumn(name = ""article_id"", referencedColumnName = ""id""),&#xA;        inverseJoinColumns = @JoinColumn(name = ""tag_id"",&#xA;                referencedColumnName = ""id""))&#xA;    private Set&lt;Tag&gt; tags;&#xA;}&#xA;&#xA;&#xA;@JsonIgnoreProperties(ignoreUnknown = true)&#xA;public class Tag {&#xA;    private Long id;&#xA;&#xA;    private String title;&#xA;&#xA;    @ManyToMany(mappedBy = ""tags"")&#xA;    private Set&lt;Article&gt; articles;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have a table named <strong>article_tag</strong> in my database (<strong>Postgres</strong>).</p>&#xA;&#xA;<p>Now how can I define my repositories in the <strong>Gateway</strong>?&#xA;How to write getArticlesByTagId() or getTagsByArticleId() functions?&#xA;I did whatever I could to make this relation work but I think they are not going to get along with each other :)</p>&#xA;"
46092604,event-driven microservices id generation,<java><microservices>,2,203,3,0.0,0,"<p>I'm a newbie with microservices. I'm trying to create a microservices architecture where there is an API gateway that should just receive the request and create an event accordingly. Then the event will be intercepted by a microservice that stores the needed data into a database. </p>&#xA;&#xA;<p>Maybe I'm making a mistake with the design but I expect that after a client calls the API gateway the request proceeds asynchronously and the data consistency won't be guaranteed. </p>&#xA;&#xA;<p>So how the client knows if the resource has been created and its id?</p>&#xA;&#xA;<p>Should the client listen to the events as well?</p>&#xA;&#xA;<p>Is this the right architecture or am I going through the wrong path?</p>&#xA;&#xA;<p>Thank you in advance for your comments!</p>&#xA;&#xA;<p>Note: I'm not using any structured framework. I like them but this is mostly an experiment and I'd like keep everything simple. Anyway I'm opened if your suggestion involve spring or whatever java framework. </p>&#xA;&#xA;<p>(Edit)</p>&#xA;&#xA;<p>Another interesting point. Let's give that the API response is asynchronous, if the client has to insert an aggregated data made by two resources (identified by their own id), how this can be achieved through an event-driven architecture?</p>&#xA;"
46171136,"All my microservices have their own db's, should I create common microservice to handle connections?",<database><architecture><microservices>,1,95,4,1.0,0,"<p>I have a number of microservices that maintain their own databases (mongodb, elastic, mysql) and each of the microservices I have to set-up a new connection constantly. </p>&#xA;&#xA;<p>I was considering would it be wise if I created another microservice, that could handle these connections for the microservices, before they start up.</p>&#xA;&#xA;<p>Example:&#xA;My API Gateway microservice gets a request for search, it then calls search microservice, which before the search starts, calls the database setup miscroservice and returns an established connection back to it, based on what microservice called it (in this case - the search microservice).</p>&#xA;&#xA;<p>Would it be better, if I just found out what connection is needed inside the API Gateway? Or should I just leave the logic separately in each microservice.</p>&#xA;"
49349235,"Micro-services architecture, need advise",<microservices>,5,104,0,1.0,0,"<p>We are working on a system that is supposed to 'run' jobs on distributed systems.</p>&#xA;&#xA;<p>When jobs are accepted they need to go through a pipeline before they can be executed on the end system.</p>&#xA;&#xA;<p>We've decided to go with a micro-services architecture but there one thing that bothers me and i'm not sure what would be the best practice.</p>&#xA;&#xA;<p>When a job is accepted it will first be persisted into a database, then - each micro-service in the pipeline will do some additional work to prepare the job for execution.</p>&#xA;&#xA;<p>I want the persisted data to be updated on each such station in the pipeline to reflect the actual state of the job, or the its status in the pipeline.</p>&#xA;&#xA;<p>In addition, while a job is being executed on the end system - its status should also get updated.</p>&#xA;&#xA;<p>What would be the best practice in sense of updating the database (job's status) in each station:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each such station (micro-service) in the pipeline accesses the database directly and updates the job's status</p></li>&#xA;<li><p>There is another micro-service that exposes the data (REST) and serves as DAL, each micro-service in the pipeline updates the job's status through this service</p></li>&#xA;<li><p>Other?....</p></li>&#xA;</ol>&#xA;&#xA;<p>Help/advise would be highly appreciated.</p>&#xA;&#xA;<p>Thanx a lot!!</p>&#xA;"
49353369,Microservices and messaging,<microservices><messaging>,1,43,3,0.0,0,<p>I'm in the process of restructuring my first application to use microservices and messaging using an event driven architecture. I will have a content microservice to retrieve content from various sources and add to a message queue for processing. My query is that should the content microservice store the content in its own database as well or is that redundant as I am using messaging?  </p>&#xA;
44502869,How to load a zip file in java servlet and expose as URL,<java><url><servlets><microservices><embedded-jetty>,2,98,5,0.0,0,"<p>My requirement is loading a zip file from file system in java servlet and expose as URL (without extracting the zip file).</p>&#xA;&#xA;<p>For example, a zip file is located in C:\temp\example.zip. Content of this zip file is </p>&#xA;&#xA;<ol>&#xA;<li>example.html and its dependent files</li>&#xA;<li>one.js</li>&#xA;<li>two.js.</li>&#xA;</ol>&#xA;&#xA;<p>How to construct URL like ""<a href=""http://localhost:8080/app/example.zip/example.html"" rel=""nofollow noreferrer"">http://localhost:8080/app/example.zip/example.html</a>""? &#xA;Server could be jetty. Any help is highly appreciated. Thanks.</p>&#xA;&#xA;<p>I can even change the server or can use some other approach also to achieve the above solution. As said earlier, the only constraint is ""should not be extracted"".</p>&#xA;"
44585239,Splitting monolith to microservices database issues,<database><oracle><join><microservices>,1,227,6,0.0,0,"<p>I am splitting monolith application to microservices and I was able to split it to three microservices, for easier explanation suppose these are:</p>&#xA;&#xA;<ul>&#xA;<li>Users (CRUD)</li>&#xA;<li>Messages (CRUD)</li>&#xA;<li>Other things (CRUD)</li>&#xA;</ul>&#xA;&#xA;<p>All of these are distinct bounded contexts and I'm using database table for microservice. So in DB i have:</p>&#xA;&#xA;<pre><code>USERS table&#xA;id&#xA;surname&#xA;lastname&#xA;...&#xA;&#xA;OTHER_THINGS table&#xA;id&#xA;col1&#xA;col2&#xA;...&#xA;&#xA;MESSAGES table&#xA;id&#xA;title&#xA;created_time&#xA;USER_ID&#xA;OTHER_THING_ID&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>Now my web page needs searching/filtering of messages by all of the specified columns of all of these tables. For example:</p>&#xA;&#xA;<p>Web page user can enter:</p>&#xA;&#xA;<ul>&#xA;<li>surname of USER, </li>&#xA;<li>col2 of OTHER_THINGS </li>&#xA;<li>title of messages </li>&#xA;</ul>&#xA;&#xA;<p>And I should return only filtered rows.</p>&#xA;&#xA;<p>With monolith I have used simple database JOINS, but in this situation I can't find the best option. Can you suggest me possible options and which ones are better?</p>&#xA;"
46575898,What the hell is microservice?,<architecture><microservices>,2,913,3,0.0,0,"<p>Microservice for this, microservice for that, but explain to a simple person what is microservice? I'm a simple programmer with a little almost none theoretical background. But I don't need a term microservice to do what I do. Could someone explain me in easy-peasant words what microservice is? Amazon AWS = microservice?</p>&#xA;&#xA;<p>I read this: <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Microservices</a> but apparently I'm too stupid to understand what is this.</p>&#xA;"
45526675,Async HTTP request vs HTTP requests on new thread,<java><multithreading><rest><asynchronous><microservices>,3,533,0,0.0,0,"<p>I have 2 microservices (A and B).</p>&#xA;&#xA;<p>A has an endpoint which accepts POST requests. When users make a POST request, this happens:</p>&#xA;&#xA;<ol>&#xA;<li>Service A takes the object from the POST request body and stores it in a database.</li>&#xA;<li>Service A converts the object to a different object. And the new object gets sent to service B via Jersey HTTP client.</li>&#xA;</ol>&#xA;&#xA;<p>Step 2 takes place on a Java thread pool I have created (Executors.newCachedThreadPool). By doing step 2 on a new thread, the response time of service A's endpoint is not affected.</p>&#xA;&#xA;<p>However, if service B is taking long to respond, service A can potentially create too many threads when it is receiving many POST requests. To help fix this, I can use a fixed thread pool (Exectuors.newFixedThreadPool).</p>&#xA;&#xA;<p>In addition to the fixed thread pool, should I also use an asynchronous non-blocking HTTP client? Such as the one here: <a href=""https://hc.apache.org/httpcomponents-asyncclient-dev/"" rel=""nofollow noreferrer"">https://hc.apache.org/httpcomponents-asyncclient-dev/</a>. The Jersey HTTP client that I use is blocking.</p>&#xA;&#xA;<p>It seems like it is right to use the async HTTP client. <strong>But if I switch to a fixed thread pool, I think the async HTTP client won't provide a significant benefit - am I wrong in thinking this?</strong></p>&#xA;"
45530657,What is the correct way of sharing common yet versioned infrustructural code between microservices?,<.net><nuget><versioning><microservices>,1,59,0,2.0,0,<p>We'd like to extract some infrastructure related code (mostly extension methods or small helper classes) into separate NuGet packages. </p>&#xA;&#xA;<p>These packages in no way contain business logic pertaining to either of the services.</p>&#xA;&#xA;<p>But as soon as as we end up having a hierarchy of dependencies between packages we are probably asking for troubles with versioning:</p>&#xA;&#xA;<p>Service1 references package Av1.1 directly and Av2.0 indirectly via referenced package B.<br/></p>&#xA;&#xA;<p>ServiceN references package Av1.5 directly and Av1.3 indirectly via referenced package C.<br/></p>&#xA;&#xA;<p>NuGet does not support side-by-side versions and only one version is used per project. This problem of versioning is relevant for monolithic applications as well though with seemingly significantly fewer possible integration issues.</p>&#xA;&#xA;<p>There are some ideas like not extracting common code and letting it be duplicated across services or just not changing the version of the package forcing every service to work with the same version.</p>&#xA;&#xA;<p>Are there any good recommendations concerning code reuse between services which go well with versioning?</p>&#xA;
45559979,Access Token/Authorization Between Microservices,<spring-security><oauth-2.0><microservices><spring-cloud><spring-security-oauth2>,3,670,0,0.0,0,"<p>I'm creating an online store REST API that will mainly be used by a mobile app. The plan is for a microservices architecture using the Spring Cloud framework and Spring Cloud OAuth for security.</p>&#xA;&#xA;<p>My question is really on best practices for communication between microservices: Should I have each service register for their own token, or should they just pass the user's token around?</p>&#xA;&#xA;<p>For example, I have 3 services: user-service, account-service, order-service.&#xA;I've been able to implement two procedures for creating an order: One passes the user's token around, and in the other each service gets their own token. I use Feign for both approaches.</p>&#xA;&#xA;<p>So for option 1: order-service -> GET account-service/account/current</p>&#xA;&#xA;<p>order-service calls the account-service which returns the account based on a userId in the token. Then the order-service creates an order for the account.</p>&#xA;&#xA;<p>Or for option 2: order-service -> GET account-service/account/user-id/{userId}</p>&#xA;&#xA;<p>order-service gets the userId from the sent token, calls the account-service with it's own token, then creates the order with the retrieved account.</p>&#xA;&#xA;<p>I'm really not sure which option is best to use. One better separates information but then requires two Feign Clients. However the other doesn't require the 2 clients and it becomes easier to block off end certain endpoints to outside clients, however it requires extra endpoints to be created and almost every service to go digging into the Authentication object.</p>&#xA;&#xA;<p>What are all your thoughts? Has anyone implemented their system in one way or another way entirely? Or perhaps I've got the completely wrong idea.</p>&#xA;&#xA;<p>Any help is appreciated.</p>&#xA;"
45533748,version management in microservices,<version-control><cloud><microservices><service-discovery>,2,1982,0,1.0,0,"<p>Suppose that I have a UserService in my <strong>Microservice Architecture</strong> deployed on the cloud. There is a <strong>Service Discovery</strong> for routing the requests to different host of UserService. </p>&#xA;&#xA;<p>If I have two different versions of UserService. Lets say <em>user-service-1.0</em> and <em>user-service-2.0</em> and part of clients should still use older version, then how this can be managed in Microservice Architecture. </p>&#xA;"
49579074,Cache Implementation in Microservices best practises,<caching><microservices>,1,28,4,0.0,0,<p>I want to ask one design related question as we have multiple micro-services and we want to implement cache for them. </p>&#xA;&#xA;<p>There is a possibility of having different services accessing the same cache for setting and fetching data from this cache So what should be the best way of doing it. </p>&#xA;&#xA;<p>Assuming we have customer service which updates the cache with customer data and we have a cart cache which do needs this data to set in cart object which contains this customer data so for this kind of scenario what would be the best way of implementing this.</p>&#xA;
46934916,Microserivce Using Spring Boot to Consume SOAP,<java><rest><spring-boot><soap><microservices>,3,632,0,0.0,0,"<p>I need to create a REST service that first consumes SOAP. What would the best way to go about this?</p>&#xA;&#xA;<p>I would like to use Spring Boot to create a microservice, but I have a few questions for those with experience:</p>&#xA;&#xA;<ul>&#xA;<li>What other architectures or technologies should I look into using&#xA;(with spring boot)?  </li>&#xA;<li>Is there a standard technology stack for this?</li>&#xA;<li>Are there pitfalls I should be aware of?</li>&#xA;</ul>&#xA;"
47042162,Where in S3 my Lambda code stored,<amazon-web-services><amazon-s3><aws-lambda><microservices>,2,703,0,0.0,0,<p>I have read the Lambda FAQ and it says it stores my code in S3 and it is encrypted.</p>&#xA;&#xA;<p>Where in S3 is it stored and can I decrypt it to edit my code?</p>&#xA;
46947956,"MQ - How to guarantee message delivery in a non-transacted, lightweight environment?",<transactions><zeromq><microservices><mq><2phase-commit>,2,96,11,0.0,0,"<p>How to guarantee message delivery in a non-transacted, lightweight environment?</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<ul>&#xA;<li>Normal situation: Write to database, commit, <strong>send message to ZeroMQ|Redis|OtherMQ</strong>, consumer pulls the message to continue processing...</li>&#xA;<li>0,05% situation: Write to database, commit, <strong>application dies!</strong>, no message sent, no consumer pull the message, incomplete processing.</li>&#xA;</ul>&#xA;&#xA;<p>How to not loose the message (avoid not send the message) in this situation?</p>&#xA;&#xA;<p><strong>Edit</strong>: The message must be delivery exactly once.</p>&#xA;"
38461294,How to send JSON as a Input parameter from one Microservice to another using RestTemplate in Spring Boot,<java><spring-boot><resttemplate><microservices>,3,1356,0,1.0,0,"<p>I want to send <code>JSON</code> as an <code>input</code> from Microservice M1 to a Microservice M2.</p>&#xA;&#xA;<p>M1 and M2 both are on different machines.&#xA;I am new to Spring Boot,</p>&#xA;&#xA;<p>I found some <a href=""https://spring.io/guides/tutorials/bookmarks/"" rel=""nofollow"">code</a> but I am unable to get it.&#xA;Please help.</p>&#xA;"
38380827,Microservices Maven Project Structure,<java><spring><maven><microservices>,2,2112,2,0.0,0,"<p>I am working on a project in which we'll deploy a full Spring Boot microservices architecture, along with supporting services like load balancing, service registry, edge server, and centralized monitoring.</p>&#xA;&#xA;<p>I have a single project that will be shared among all core microservices which contains DAOs and all the dependencies for the core microservices. I am hoping to be able to release one ~60Mb jar, and have the other Spring Boot core microservices be very lightweight (&lt;1Mb). At runtime the core microservices will reference the shared jar on their classpath.</p>&#xA;&#xA;<p>The way I've set the project up is to have separate project, with a structure like so:</p>&#xA;&#xA;<pre><code>|shared_project&#xA;|pom.xml&#xA;&#xA;|ms-1&#xA;|pom.xml&#xA;&#xA;|ms-2&#xA;|pom.xml&#xA;</code></pre>&#xA;&#xA;<p>The shared project uses maven-assembly-plugin to create a big jar and copies it to my local .m2 repo. The ms-1 and ms-2 poms use maven-jar-plugin to create their jars and have one dependency, the shared project. </p>&#xA;&#xA;<p>I'm sure this is not the best way to handle this. It's creating issues during unit tests and I have to imagine it'll create issues down the line. I've seen this done using parents in the pom file, nesting the project inside another directory, and other ways. </p>&#xA;&#xA;<p>What I am wondering is what is the best practice regarding keeping your Spring Boot projects' dependencies and shared code centralized and externalized through use of Maven, such that the projects that you are frequently rolling are kept lightweight and decoupled? </p>&#xA;&#xA;<p>Bonus questions: </p>&#xA;&#xA;<ol>&#xA;<li><p>Does the fact that we'll be using Jenkins/TeamCity for CI and automated testing affect the answer?</p></li>&#xA;<li><p>Does having one shared jar on the filesystem which each project references in its classpath during startup pose any challenges? Depending on demand, we may flexibly spin up 10 instances of microservice-1 and only 3 of microservice-2. </p></li>&#xA;</ol>&#xA;&#xA;<p>EDIT: I think this already has a good answer here: &#xA;<a href=""https://stackoverflow.com/questions/27865238/parent-pom-and-microservices"">Parent pom and microservices</a></p>&#xA;"
38297333,Sharing data among Microservices‏,<rest><design-patterns><enterprise><restful-architecture><microservices>,2,774,4,1.0,0,"<p>I'm seeking an answer to a design question that I didn't find an answer to in any literature on this matter. Allow me to explain the use case, my solution to it and, ask for your opinion as a subject matter expert.</p>&#xA;&#xA;<p><strong>Use Case</strong>:&#xA;We've several Microservices that all return some form of content from different business domains. We're using Spring Cloud Netflix, so a gateway service routes traffic to the content services. Some, if not all, of these services require data that is derived from the request, and is immutable. A trivial example is locale, although there are other proprietary information too.</p>&#xA;&#xA;<p><strong>Solution</strong>:&#xA;I'm currently deriving the shared data in the gateway service and persisting as JSON in a NoSQL database with a unique key. Then I'm adding the key as a request header before routing the request. I've a shared library that the content services include at build time, and includes a Spring bean that reads the key from the request header, fetches the stored data using the key and initializes itself. This makes it possible for the content services to access the shared data (by simply injecting the previously mentioned bean) without knowing the underlying mechanism.&#xA;If a content service invokes another one, it's responsible for adding the unique key as a request header.</p>&#xA;&#xA;<p><strong>Debate</strong>:&#xA;The debate I've with my colleagues is that whether using a shared datastore for this purpose is appropriate. I contend that it is bad for a service to leak it's domain specific data to others, but the data in question isn't domain specific, so there's nothing wrong with having a shared database and passing the key around. The alternative would be to pass all the shared data around which I consider redundant.</p>&#xA;&#xA;<p>What is your thought?</p>&#xA;&#xA;<p><strong>Edit</strong>: I see someone voted to close the question. Unless they can point me to a reference that discusses data sharing among Microservices, such policing is a hindrance to meaningful discussion. Not every question is a boolean yes/no answer, some require deeper thoughts.</p>&#xA;"
38352227,What is the name of this 'intermediary' pattern?,<java><web-services><design-patterns><microservices>,1,99,5,0.0,0,"<p>I've got an intermediary java web service application application (built using Spark Java - but that is incidental) that takes an http parameter - from it generates a URL - calls the URL and then returns the result to the original caller. </p>&#xA;&#xA;<pre><code>Original Client -&gt; My Application -&gt; Http Web Service Producer&#xA;</code></pre>&#xA;&#xA;<p>This is kind of a MicroServices pattern - but I'm looking for a more specific term. I think it is a 'pipeline', 'solicitor' or a 'mediator'. </p>&#xA;&#xA;<p>My question is: <strong>What is the name of this 'intermediary' pattern?</strong></p>&#xA;"
47736658,Restricting access to api from another application ruby,<ruby><api><http><ip><microservices>,1,33,4,0.0,0,"<p>I have a Grape API application built in Ruby. &#xA;And also some other microservices built in Python, Java etc.&#xA;I have to restrict some of these microservices from accessing a particular API in this grape application. </p>&#xA;&#xA;<p>Now, this is implemented using IP whitelisting. But every time the IP of other microservices gets changed, the code of grape application has also to be changed which is not stable. </p>&#xA;&#xA;<p>Is there any better solution for this? Please help.</p>&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;"
51238009,Create endpoint to get multiple records in microservice,<java><c#><design-patterns><microservices>,3,64,4,0.0,0,"<p>Currently, we have an API endpoint (microservice called supplier service) like this: <code>/suppliers/{supplierNumber}</code>, which will return a single supplier information. </p>&#xA;&#xA;<p>In the UI, there is a screen to display a list of suppliers for different products. It looks something like this:  </p>&#xA;&#xA;<pre><code>product1 -&gt; supplier1&#xA;product2 -&gt; supplier2&#xA;product3 -&gt; supplier3&#xA;</code></pre>&#xA;&#xA;<p>To display suppliers for a list of products, we need a for loop which calls the end point on each iteration.</p>&#xA;&#xA;<p>My concern is that this is inefficient from a performance stand point. Why is it not possible to design an endpoint that takes in a list of supplier numbers and returns a list of supplier information?</p>&#xA;&#xA;<p>Other people have said that it's not microservice design, and I'm not sure why it's not a proper design. Does anyone know the reasoning behind this?</p>&#xA;"
48374452,Dao as a Seperate Module in Monolithic Considering Extendable to microservice in future,<java><spring><microservices>,1,114,3,0.0,0,"<p>I am actually creating one project where we are having 2 or more database. I will use Spring Boot. I would like to know:</p>&#xA;&#xA;<ol>&#xA;<li><p>Why do we have Client of the Gateways while code as we already have REST endpoint in server (May be i am wrong )?</p></li>&#xA;<li><p>My project currently will be monolithic but I want to make it possible to change to a microservice architecture in the future. Should I have the DAO as separate module which will be dependency for other module considering I can have more than one database (RDBMS and NoSQL)?</p></li>&#xA;</ol>&#xA;&#xA;<p>Hope I am asking work question, but I am confused right now, while starting the project.</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;"
44786479,grpc architecture : where should be caching layer be?,<c#><caching><microservices><grpc>,1,286,3,0.0,0,"<p>We have a monolithic system that we are currently breaking into microservices using gRPC. Currently, we are using enyim caching in C# client in our monolithic code.</p>&#xA;&#xA;<p>While creating our first gRPC service, we are confused that where should caching layer be:</p>&#xA;&#xA;<ol>&#xA;<li>Should it be moved to gRPC service code for this service? This way each service will have its caching code. This would lead to lots of duplicate caching code.</li>&#xA;<li>Should we create dll for caching related code and use it in new gRPC microservice? We would still need to place duplcate configurations across each gRPC service.</li>&#xA;<li>Handle caching from monolithic code only and call gRPC service only in case for cache miss?</li>&#xA;</ol>&#xA;&#xA;<p>Suggestions?</p>&#xA;"
44758955,Wildfly Swarm JGroups YAML,<java-ee><yaml><microservices><jgroups><wildfly-swarm>,1,318,3,0.0,0,"<p>I've downloaded the Wildfly swarm examples and now I am trying to move the configurations in Main classes to YAML files.</p>&#xA;&#xA;<p>So far, everything is working, except the ribbon example. I took the configuration from the example project and tried to convert it into YAML file.</p>&#xA;&#xA;<p>Project source: <a href=""https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java"" rel=""nofollow noreferrer"">https://github.com/wildfly-swarm/wildfly-swarm-examples/blob/master/ribbon/events/src/main/java/org/wildfly/swarm/examples/netflix/ribbon/events/Main.java</a></p>&#xA;&#xA;<p>My YAML file (as I think it should look like)</p>&#xA;&#xA;<pre><code>--- &#xA;swarm:&#xA;  context:&#xA;    path: proxy&#xA;  http:&#xA;    port: 8080&#xA;  jgroups: &#xA;    default-channel: swarm-jgroups&#xA;    stacks:&#xA;      udp:&#xA;        protocols:&#xA;          FD_SOCK:&#xA;            socket-binding: jgroups-udp-fd&#xA;          TCP:&#xA;            properties:&#xA;              bind_port:&#xA;                value: 9090&#xA;          TCPPING:&#xA;            properties:&#xA;              initial_hosts:&#xA;                value: ""localhost[9090],localhost[9091],localhost[9092],localhost[9093]""&#xA;              num_initial_members:&#xA;                value: 4&#xA;              port_range:&#xA;                value: 4&#xA;              timeout:&#xA;                value: 3000&#xA;          FD_ALL: null&#xA;          VERIFY_SUSPECT: null&#xA;          pbcast.NAKACK2: null&#xA;          UNICAST3: null&#xA;          pbcast.STABLE: null&#xA;          pbcast.GMS: null&#xA;          UFC: null&#xA;          MFC: null&#xA;          FRAG2: null&#xA;          RSVP: null&#xA;        transports:&#xA;          UDP:&#xA;            socket-binding: jgroups-udp&#xA;</code></pre>&#xA;&#xA;<p>But I am getting two Exceptions: On startup in the first line:</p>&#xA;&#xA;<pre><code>Error getting subresources for Stack java.lang.RuntimeException: Failed to adopt value java.util.Map&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:347)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:33)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshalSubresources(Marshaller.java:129)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.appendNode(Marshaller.java:38)&#xA;        at org.wildfly.swarm.config.runtime.invocation.Marshaller.marshal(Marshaller.java:23)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller.marshal(SubsystemMarshaller.java:59)&#xA;        at org.wildfly.swarm.container.runtime.marshal.SubsystemMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller.marshal(DMRMarshaller.java:70)&#xA;        at org.wildfly.swarm.container.runtime.marshal.DMRMarshaller$Proxy$_$$_WeldClientProxy.marshal(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer.start(RuntimeServer.java:182)&#xA;        at org.wildfly.swarm.container.runtime.RuntimeServer$Proxy$_$$_WeldClientProxy.start(Unknown Source)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.lambda$bootstrap$1(ServerBootstrapImpl.java:158)&#xA;        at org.wildfly.swarm.spi.api.ClassLoading.withTCCL(ClassLoading.java:43)&#xA;        at org.wildfly.swarm.container.runtime.ServerBootstrapImpl.bootstrap(ServerBootstrapImpl.java:113)&#xA;        at org.wildfly.swarm.Swarm.start(Swarm.java:369)&#xA;        at org.wildfly.swarm.Swarm.main(Swarm.java:623)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;        at java.lang.reflect.Method.invoke(Unknown Source)&#xA;        at org.wildfly.swarm.bootstrap.MainInvoker.invoke(MainInvoker.java:39)&#xA;        at org.wildfly.swarm.bootstrap.Main.run(Main.java:46)&#xA;        at org.wildfly.swarm.bootstrap.Main.main(Main.java:37) Caused by: java.lang.ClassCastException: java.util.HashMap cannot be cast to java.lang.String&#xA;        at org.wildfly.swarm.config.runtime.invocation.MapTypeAdapter.toDmr(MapTypeAdapter.java:22)&#xA;        at org.wildfly.swarm.config.runtime.invocation.EntityAdapter.fromEntity(EntityAdapter.java:341)&#xA;        ... 24 more&#xA;</code></pre>&#xA;&#xA;<p>And then the jgroup sepcific exception:</p>&#xA;&#xA;<pre><code>    (""subsystem"" =&gt; ""jgroups""),&#xA;    (""stack"" =&gt; ""udp"")&#xA;]) - failure description: ""WFLYCLJG0010: Transport for stack udp is not defined. Please specify both a transport and protocol list, either as optional parameters to add() or via batching.""&#xA;</code></pre>&#xA;&#xA;<p>I am not sure what is wrong.</p>&#xA;&#xA;<p>Maybe you guys can give me a hint?</p>&#xA;"
44781219,Atomic insert of data in micro service architecture + NoSql database [Data consistency in Micro service architecture],<database-design><cassandra><architecture><microservices><nosql>,2,132,3,0.0,0,"<p>I have 3 services A, B, C. </p>&#xA;&#xA;<p>Service A receives a request from client. Then A prepares a data for its own database, service B and C. Basically A is coo-ordinator.</p>&#xA;&#xA;<ol>&#xA;<li>A insert data in its database</li>&#xA;</ol>&#xA;&#xA;<p>If it is success </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>post request B's data to service B and B insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If it is success</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>then post request C's data to service C and C insert data in its DB</li>&#xA;</ol>&#xA;&#xA;<p>If anything fails at any step, we have to revert all data inserted.</p>&#xA;&#xA;<p>I am using Cassandra NoSQL DB.</p>&#xA;&#xA;<p><strong>Now i need a generic solution for all cases that could happen like :</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I.</p>&#xA;&#xA;<p>Suppose C is inserting data (in progress), in the mean time, some read query R on A-database reads the inserted data. After few millisec, C fails to insert, but R already read the false data which would be reverted soon.</p></li>&#xA;</ul>&#xA;&#xA;<p>What to do in this case? &#xA;--> change the DB design, such that this kind of condition would never happen??</p>&#xA;&#xA;<ul>&#xA;<li><p>II.</p>&#xA;&#xA;<p>What if service C data insert fails, and service B have application server downtime so it couldn't revert??</p></li>&#xA;</ul>&#xA;"
51419192,Using microservices architecture in spring,<spring-boot><microservices><spring-cloud-netflix>,3,47,3,0.0,0,"<p>I'm building a project which based on microservices architecture in spring boot.The project was divided multiple modules and I used maven dependency management.</p>&#xA;&#xA;<p>Now I want to use services from one module in other module. I have many spring applications. For example, I have 2 application which is named A and B. I want to use classes from A in B and classes of B in A. In this case I used maven dependencies but it is not completely way to using services in one another because I faced with circular dependency. </p>&#xA;&#xA;<p>What should do to use for solve this problem?</p>&#xA;"
43144337,The right way to define an API's base path in Api Connect,<spring-boot><ibm-cloud><microservices><apiconnect>,1,269,5,0.0,0,"<p><strong>Problem:</strong></p>&#xA;&#xA;<p>I have two micro services (in Spring Boot) published in <a href=""https://en.wikipedia.org/wiki/Bluemix"" rel=""nofollow noreferrer"">Bluemix</a>'s Api Connect. I want to assign a base path to each one so that we have a way to separate them. I.E.:</p>&#xA;&#xA;<p>Path to API 1: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api1/[endpoint-of-api1]</code>&#xA;Path to API 2: <code>https://api.us.apiconnect.ibmcloud.com/[organization]/[catalog]/api2/[endpoint-of-api2]</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>My solution:</strong></p>&#xA;&#xA;<p>Assign a context path to each Api in their <strong>application.yml</strong> file:</p>&#xA;&#xA;<pre><code>server:&#xA;  contextPath: /api1&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Even though this works, it doesn't seem right to have a base path for the entire server, when the microservice shouldn't be aware of its external context (the reason for a base path is exclusively to have a separation in Api Connect)</p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
51980596,How to Map specific fields of an object to another object?,<java><spring><spring-boot><microservices>,4,62,0,0.0,0,"<p>I have a situation where I have an object(obj1) which I have to map to another object(obj2) but in this Mapping some of obj2's fields are already having some values while other fields are null, so I have to pick only those fields which are null in obj2 and then send data from obj1 to those fields. I am not sure if ModelMapper will be useful in this case. </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
52041354,microservice: How to do validations from other microservice,<validation><microservices>,1,22,3,1.0,0,<p>If there are 2 micro services and if you want a validation to be performed against other micro service. What would be the best scenario to handle these cases?</p>&#xA;
46021905,"microservices, server-sent events, and browser limitations",<rest><microservices><server-sent-events>,1,110,3,0.0,0,"<p>In a micro-service oriented architecture, where each micro-service offers an SSE endpoint to stream events to the client, an HTTP connection is opened and kept alive between the client and the service. Unfortunately, this approach is almost unpractical when the client runs within a Web Browser because Web Browsers have a limitation on the number of HTTP connections that can be opened simultaneously on the same server (by domain name if I'm not wrong).</p>&#xA;&#xA;<p>It's a pity because SSE is a great technology for streaming events.</p>&#xA;&#xA;<p>What's the best approach for streaming events in a micro-service oriented architecture then, when the client runs in a browser?</p>&#xA;"
48457264,Integrating SignalR for microservice with API Gateway,<architecture><signalr><microservices><asp.net-core-signalr>,1,630,2,0.0,0,"<p>I'm designing a microservice system based on .Net core. The architecture system will look like as the following picture.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eIee4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eIee4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The problem is: There is a requirement which have to integrate SignalR (real-time) for notification&#xA;I've read about SignalR on Microsoft's website. But I consider that where should I put the Hub (API Gateway?, microservice? ...)? How can I apply signalR for this system.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48667874,Authentication in microservices,<.net><authentication><asp.net-core><jwt><microservices>,3,347,0,0.0,0,"<p>I am developing a microservice system for my company using ASP.NET Core. But a have faced with the following problem: when authenticated user is requesting some service, how should it check if the token is an actual (not blacklisted). I mean the case when user takes a new token but his old token is not expired yet thus the last one is an actual and could be used for accessing the resource services. So I gonna make all ofthe microservices ask the authentication service whether the token is an actual at each request. Perhaps there are any elegant ways to do it?</p>&#xA;"
51122354,Coupling in microservices architecture,<microservices><coupling>,1,33,3,0.0,0,"<p>When working on an application in microservices architecture I stumbled upon issues concerning coupling between services.</p>&#xA;&#xA;<p>This a typical application for ordering products. It seams reasonable to have a service that will operate as a product catalog. Our JavaScript client can ask this service for available products and show them in browser. When user clicks on a product we have to create an order. We would like to manage orders in another service. So an order is created - it means that user X ordered product Y. On the technical level we are simply persisting user id and product id in a database.</p>&#xA;&#xA;<p>To sum up we have:</p>&#xA;&#xA;<h3>Products service</h3>&#xA;&#xA;<p>Product class:<br/>&#xA;Product ID, Product Name </p>&#xA;&#xA;<h3>Orders service</h3>&#xA;&#xA;<p>Order class:<br/>&#xA;Order ID, Product ID,  User ID,   Order date  </p>&#xA;&#xA;<p>Now let's imagine following scenario - in JavaScript client we would like to list all products that user have ordered. Orders service provides a list of products ids for a given user. But user cares about product name, not the id. Unfortunately Orders service doesn't know anything about products names.</p>&#xA;&#xA;<p>We could tackle this in couple of ways:</p>&#xA;&#xA;<ul>&#xA;<li><p>Simply assume that the client is responsible for getting the information it needs. So after it calls Orders service and gets a list of products ids, it performs another call to Products service, passing products ids and getting corresponding products names in response. Then the client assembles both responses into something useful. This approach keeps our services clean, without leaking of domain knowledge from one service to another. But it requires more work on the client side.</p></li>&#xA;<li><p>Orders service when asked for ordered products makes a call on the backend to the Products service. It retrieves product names, assembles a response that contains orderDate and  productName and sends that to client. All that's left for client to do is to present the data. Downside of this approach is that Orders service now gains more knowledge about products than neccessary.</p></li>&#xA;<li><p>Duplicate information about product name in Orders service. When an order is created, we pass not only product id but also product name. That means that Order class will look like this:&#xA;Order class:<br/>&#xA;Order ID, Product ID, Product name, User ID, Order date<br/>&#xA;Now we can easly provide full information about order without additional call to Products service. Also this time Orders service has too much knowledge about products. What's beneficial tough is that Orders service can provide relevant data even if Products service is down.</p></li>&#xA;</ul>&#xA;&#xA;<p>Could any of these approaches be considered best practice? Or are there different solutions?</p>&#xA;"
50427036,Certificate Discovery Service,<rest><ssl><ssl-certificate><microservices><keystore>,1,32,4,0.0,0,"<p><br/>&#xA;I'm designing a microservice architecture and I've already setted up the https protection by using SSL certificates generated with <a href=""https://letsencrypt.org/"" rel=""nofollow noreferrer"">Let's Encrypt and certbot</a>.</p>&#xA;&#xA;<p>The provided certificates are periodically regenerated and then I've to re-import the new certificates into the keystores of all my services.</p>&#xA;&#xA;<p>In order to avoid this, I'm trying to implement a set of <strong>REST APIs</strong> that may allow the services to <strong>programmatically and automatically retrieve the new certificates</strong> and import them into their own keystore or simply use it programmatically. </p>&#xA;&#xA;<p>As the title says: a sort of <em>""Certificate discovery service""</em> or, if you prefer, a <em>""Remote certificate repository""</em>.</p>&#xA;&#xA;<p>I know that there is the java.security.* package that allows me to deal with this kind of things, but I've two questions for all of you:</p>&#xA;&#xA;<ol>&#xA;<li>Do you think that, from a architectural point of view, this is the best approach to face my problem?</li>&#xA;<li>Which king of Serialization/Deserialization process do you recommend? Is already there any library/framework/tool that does something similar that I can exploit?</li>&#xA;</ol>&#xA;&#xA;<p>Thank you.&#xA;Bye Bye</p>&#xA;"
50350198,Run Git commands in microservice,<git><microservices><spring-cloud><jgit>,1,57,7,0.0,0,"<p>I'm implementing microservice (in Spring Cloud) which acts as facade for Git operations invoked by UI layer. I'm trying to use jgit, but the problem is that it requires filesystem. So I have to clone remote repository to local filesystem. Problem is that then microservice is not stateless, and also other problems arises:</p>&#xA;&#xA;<ul>&#xA;<li>cloning before every operation takes too much time so is not an option </li>&#xA;<li>having multiple instances of such microservice can lead to different repositories (push take some time) </li>&#xA;<li>commits on different nodes at the same time can lead to conflicts</li>&#xA;</ul>&#xA;&#xA;<p>I would like to treat Git repository in similar way to database, so all operations should be done without using filesystem, cloning etc. - just invoke command on remote and it's done.</p>&#xA;&#xA;<p>I would like to add that it's quite hard to search for solution, because ""Git microservice"" phrase is quite common but in other sense (storing sources in repository).</p>&#xA;&#xA;<p>Edit: I've just found&#xA;<a href=""https://stackoverflow.com/questions/9442788/are-there-any-restful-interfaces-to-git"">Are there any restful interfaces to git?</a>&#xA;but any other ideas would be nice</p>&#xA;"
40657733,Reload changes to a shared data base,<java><spring><spring-boot><datasource><microservices>,1,28,5,0.0,0,"<p>I'm using Spring boot, and I have 2 services which share the same data base. each service has its own data source to communicate with the DB.</p>&#xA;&#xA;<p>My problem is when I apply changes via first data source the changes are not being affected or not being reloaded to the second data source.</p>&#xA;&#xA;<p>My question is how can I reload those changes, so whenever i apply changes to one data source they will be reflected by the second\other data source? </p>&#xA;"
43979597,ELK logging in microservices architecture,<elasticsearch><indexing><microservices><elastic-stack>,1,225,3,0.0,0,"<p>I am implementing centralized logging for all of my microservices using ELK. My doubt is whether I will have to create separate index for each microservice or a single index for all the microservices logs. My research so far shows that single common index for all the microservices make sense for centralized logging to achieve searches across microservices. Also I learnt that too many indices are a bit of overhead in elasticsearch. So I would like to hear from someone experienced</p>&#xA;&#xA;<p>I have already this question in Software recommendations  <a href=""https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture"">https://softwarerecs.stackexchange.com/questions/42338/elk-logging-in-microservice-architecture</a></p>&#xA;"
43892712,Merge Microservice Frontends Together,<microservices>,1,186,6,0.0,0,"<p>I want to merge serveral frontend parts of different microservices together to an whole website. My idea behind this was to have a <strong>frontend</strong>, <strong>backend</strong> and <strong>database</strong> part in each microservice.</p>&#xA;&#xA;<p>I already familiar with microservices but I never used them to create a website, especially the frontend part.&#xA;Are there any articles about that or something like tutorials or maybe someone at stackoverflow can explain me more in depth how or with which ""tool"" I could put the microservices together.</p>&#xA;"
43821553,What is the best way to run npm packages on demand as mircoservices without installing it locally?,<node.js><npm><microservices>,1,86,8,0.0,0,"<p>Let's say I have these npm packages published to npm:&#xA;<code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;each package has a single function:</p>&#xA;&#xA;<pre><code>function run(extraStr) {&#xA;  return 'package_name_and_version' + extraStr; // i.e. service1 v1.0 extraStr&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I want to write nodejs code that use the packages without installing it locally</p>&#xA;&#xA;<pre><code>var server = require(""my-server-sdk"");&#xA;  // get(package_name, version, function_in_package, arguments, callback)&#xA;  server.get('service1', '2.0', 'run', ['app1'], (err, result) =&gt; {&#xA;  console.log(result); // this should print service1 v2.0 app1&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>where <code>my-server-sdk</code> is an sdk that interface with my server's api where it <strong>install the required packages and cache it for later use</strong>.&#xA;What is the best way to do that? what the security concerns and how to prevent any?</p>&#xA;&#xA;<p>this is a simple diagram for what I want&#xA;<a href=""https://i.stack.imgur.com/aTdeG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aTdeG.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>NOTE: <code>service1@v1.0</code>&#xA;<code>service1@v2.0</code>&#xA;<code>service2@v1.0</code>&#xA;are just examples to any packages in npm i.e. <code>lodash</code></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Caching example:</strong></p>&#xA;&#xA;<p>Let's say we have TTL equal <strong>60 minutes</strong>.</p>&#xA;&#xA;<p><strong>client1</strong> requested a function from <code>lodash</code> and another function from <code>underscore</code> at 01:00.&#xA;Now in the server <code>lodash</code> and <code>underscore</code> are installed with timestamp <strong>01:00</strong>.</p>&#xA;&#xA;<p><strong>client2</strong> requested a function from <code>underscore</code> at <strong>01:30</strong> which get used instantly because <code>underscore</code> is installed before but it timestamp got updated to <strong>1:30</strong>.</p>&#xA;&#xA;<p>At <strong>02:01</strong> <code>lodash</code> get deleted because it didn't get used on the past TTL <code>currenttime - lodash_timestamp &gt; TTL</code> but <code>underscore</code> stays because <code>currenttime - underscore_timestamp &lt; TTL</code></p>&#xA;&#xA;<p>So when <strong>client3</strong> request <code>lodash</code> at <strong>02:30</strong> it get <code>intsalled</code> again with <strong>02:30</strong> as a <code>timestamp</code>.</p>&#xA;"
43340819,How to load react component from an external service inside a React app via AJAX,<javascript><node.js><ajax><reactjs><microservices>,2,558,0,1.0,0,<p>What are the best practices associated with loading/inserting and running  React components from an external service in an existing React application via AJAX.</p>&#xA;&#xA;<p>I have a main React app and want to load various React components (from external services) via AJAX. How could this be done?</p>&#xA;&#xA;<p>Is this feasible at all? If not what is the way to go about it?</p>&#xA;&#xA;<p>Can this work with webpack?</p>&#xA;
43328943,Data-specific user permissions model / schema design,<permissions><domain-driven-design><database-schema><acl><microservices>,1,111,3,0.0,0,"<p>My app manages user data that is shared between users, with different permissions such as read-only, edit, superuser, rename, delete etc. </p>&#xA;&#xA;<p>I'm weighing up two approaches to modelling the user permissions, the first is the simpler approach, the second involves more work but is more extensible, refactorable, <em>I think</em>. </p>&#xA;&#xA;<p>(1) quick solution, hard-coding against <code>user permission</code> properties:</p>&#xA;&#xA;<pre><code>-- basic data&#xA;CREATE TABLE symbol (&#xA;    id INT,&#xA;    name VARCHAR(255)&#xA;);&#xA;&#xA;CREATE TABLE user (&#xA;    id CHAR(10) &#xA;);&#xA;&#xA;CREATE TABLE user_permission (&#xA;    symbol_id INT,&#xA;    user_id CHAR(10),&#xA;    readable BIT,&#xA;    writable BIT,&#xA;    owner BIT,&#xA;    rename BIT,&#xA;    deletion BIT&#xA;);&#xA;</code></pre>&#xA;&#xA;<p>(2) complete solution, hard-coding against <code>entitlements</code>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/boRWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/boRWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The areas I'm considering are:</p>&#xA;&#xA;<ol>&#xA;<li>extensibility - need or not to change model &amp; schema</li>&#xA;<li>microservices - possibilities to spin off into a separate DB?</li>&#xA;<li>performance - filter algos, number of joins in queries</li>&#xA;<li>no-sql caching - no idea but denormalising user permissions sounds crazy</li>&#xA;<li>admin for users - need good UX</li>&#xA;<li>admin for DBAs/Support - don't want complaints and endless support requests</li>&#xA;<li>web services API simplicity / complexity using Spring Data REST - HAL</li>&#xA;</ol>&#xA;&#xA;<p>I'd like to go with the more complex solution since it is unlikely to require re-working in the future, but I'm a bit concerned about both performance and the admin tasks involved in the UI to allow users to manage it. </p>&#xA;&#xA;<p>A utopian solution would be a third-party Java-based webapp providing a user interface to allow admin.</p>&#xA;&#xA;<p>EDIT: interesting to see other people tackling the same problem: <a href=""https://stackoverflow.com/questions/41161769/authorisation-in-microservices-how-to-approach-domain-object-or-entity-level-a"">Authorisation in microservices - how to approach domain object or entity level access control using ACL?</a></p>&#xA;"
42462663,Microservice depends on other one to do anything,<dependencies><microservices><relationships>,1,316,3,0.0,0,"<p>At the moment I deal with micro-services and ran into a few questions (regarding relations between services), I have a hard time to find a good answer/best practices for. It would be really great if you could give me a hint or an advice how you would handle this.</p>&#xA;&#xA;<p>Because these question are not directed to a specific project, I try to make it as clear as possible with the following example:</p>&#xA;&#xA;<p>Let‘s assume you want to build some kind of Youtube channel observer, that logs different kinds of channel‘s (meta-)data (videos, hourly views/sub count, currently subscribed to), that are imported in a specific time interval.</p>&#xA;&#xA;<p>So there are two major features the app has to offer, which should form a microservice each:</p>&#xA;&#xA;<ul>&#xA;<li>Add/remove channels to be watched (=> manager service)</li>&#xA;<li>import information (=> import service)</li>&#xA;</ul>&#xA;&#xA;<p>Both services provide an API to communicate with each other.</p>&#xA;&#xA;<p>The manager service is connected to a database which contains the channels that need to be watched, with their basic information (name, contact, ...) and the channels these observed channels are currently subscribed to, whereas the import service has a database containing all the other more time-series oriented information (videos, hourly views/sub count).</p>&#xA;&#xA;<p>To add a channel only the channel url has to specified. All the other information (name, contact, ...) are added by the import service (but can also be modified by the user).</p>&#xA;&#xA;<p>All in all the import service is totally useless without the information of the manager service, but also the manager service can only show the user specified channel information (worst case: only channel url) if no import service is available. In total: they depend heavily on each other.</p>&#xA;&#xA;<p>So much for the general architecture. </p>&#xA;&#xA;<p>The problem I have here is, that the import service depends on the data in the manager service database to such a great degree and also modifies it:</p>&#xA;&#xA;<ol>&#xA;<li>Would it be a good idea to share the manager service database between these two services or should it only be accessible by the provided API?</li>&#xA;<li>No matter if database is shared or not: both services need model classes for the channel. Is it fine to share those? </li>&#xA;<li>Is this architecture even a good idea at all (if we assume that there are also other services that need the basic channel information)? </li>&#xA;</ol>&#xA;"
38647186,In a microservices based architecture how would i go about database access?,<database><hibernate><microservices>,1,714,0,0.0,0,<p>I am trying to push myself into developing a set of microservices for a personal project that will essentially:</p>&#xA;&#xA;<p>Use elastic search&#xA;Poll various data stores&#xA;place data and read data from a data store&#xA;Expose a rest api to users</p>&#xA;&#xA;<p>for the purposes of this example lets say I had a bookings MS and a Sales MS</p>&#xA;&#xA;<p>The first thing that occurred to me was how to handle data storage.</p>&#xA;&#xA;<ol>&#xA;<li>Should each MS have its own data store?</li>&#xA;<li>Should I introduce a Persistence MS which handles all data from all other micro services (seems odd to do this).</li>&#xA;<li>Should each MS share a database but handle its own transactions.</li>&#xA;</ol>&#xA;&#xA;<p>In the case where you have each service handling its own persistence will that not significantly bloat a micro service to the point where you have a lot of boilerplate code and a large overall footprint of libraries (as an example hibernate would be a required library across every project and it seems terrible to have every MS having to load the same set of libraries).</p>&#xA;&#xA;<p>So I suppose the overriding question is what is the accepted methodology for managing database connectivity across a micro service architecture.</p>&#xA;
44148076,Mail notification from denormalized view in CQRS,<email><microservices><cqrs>,1,69,3,0.0,0,"<p>I want to develop a mail notification service to send order approval to customer. The order data is in the denormalized view (query side) and it should be filled to the mail template. Then, we send the email in html string format via mail notification service. But, the order status should be changed to ""order approval email sent"". </p>&#xA;&#xA;<p>I also try to implement the CQRS, ES, and DDD concept in microservices architecture.&#xA;Is this procedure correct and still align with the concept?</p>&#xA;&#xA;<ol>&#xA;<li>Develop HTTP POST API in order command to send approval mail so the order status could be changed in command-side.</li>&#xA;<li>The command side generate the event ""order approval mail processed""</li>&#xA;<li>The event processor process the event. It should get the order data from query-side / denormalized view. </li>&#xA;<li>The event processor generates the approval mail from the data and fill the data to the template. </li>&#xA;<li>The event processor call HTTP POST to the mail notification service with mail body (html format) in the payload.</li>&#xA;<li>The event processor call HTTP PUT to the order service (command-side) to change the order status to ""order approval mail sent"".</li>&#xA;</ol>&#xA;&#xA;<p>But, if this procedure is applied, the user can't get the response ""mail sent"" in real-time. How to trigger the client / front-end side that the mail is successfully sent? So, the client side don't have a need to refresh or retry many calls to the API.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
44084744,Microservice architecture Flaws,<architecture><microservices><restful-architecture>,1,189,3,1.0,0,"<p>We are facing performance related issues with microservice architecture.</p>&#xA;&#xA;<p>Let's say there is microservice for user and account management. which have api's like </p>&#xA;&#xA;<pre><code>GET /users/{id} &#xA;GET /users       (arrount 6 million users)&#xA;&#xA;GET /accounts/{accountId}&#xA;GET /accounts &#xA;and Other Operations on user and account&#xA;</code></pre>&#xA;&#xA;<p>We have other microservice which track's user activities and list all the activities done by the user in his last login.</p>&#xA;&#xA;<pre><code>GET /user/activity/{userId}  (on an average 1000 to 10000 records)&#xA;</code></pre>&#xA;&#xA;<p>We have protal for sales and marketing team to show individual user activities and  user info and account info based on search criteria,</p>&#xA;&#xA;<pre><code>let's say search criteria is like : get all user activies who are located in colombia&#xA;Algorithm : &#xA;&#xA;1)Get /users ? location = colombia&#xA;2)then for individual user Get /user/activity/{userId}&#xA;</code></pre>&#xA;&#xA;<p>it is like joining two tables from different databases.</p>&#xA;&#xA;<p>it is very slow and creating lot of performance issues.</p>&#xA;&#xA;<p>what i though of is replicating user table in other microservice by a job which makes sure it is up to date and using only one api like</p>&#xA;&#xA;<pre><code>GET /user/activities?location=colombia.&#xA;</code></pre>&#xA;&#xA;<p>but replicating a table(user) is breaking the micro-service architecture main fundamentals</p>&#xA;&#xA;<p>is there any other way to do it or support this type of filter criteria which join's tables from different micro-services.</p>&#xA;"
44050579,EntityFramework Core Loadbalanced,<c#><entity-framework><asp.net-core><microservices>,1,78,9,0.0,0,"<p>I know this is a pretty general question, but please bear with me:</p>&#xA;&#xA;<p>I just tripped over the entityframework cache aka ChangeTracker.</p>&#xA;&#xA;<p>What we have is a small microservice using net core with entity core.  This microservice is loadbalanced (RoundRobin) behind an IIS (so far nothing to incommon I would guess).  Lets call them Instance1 and Instance2.</p>&#xA;&#xA;<p>Now what happens:</p>&#xA;&#xA;<p>I have one entry in the db, for example (Represented as JSON here for simplicity):</p>&#xA;&#xA;<p><code>&#xA;{ Name: ""Test"", FirstName: ""T."" }&#xA;</code></p>&#xA;&#xA;<p>Now I load this into a form (answer from Instance1) and modify the FirstName to Thomas and save it via a PUT, which is done by Instance2.  Now I do another request to get that entry.  This request is answered by Instance1, which will load this from cache (since the changetracker says it is unchanged).  And thus I get</p>&#xA;&#xA;<p><code>&#xA;{Name: ""Test"", FirstName: ""T.""}&#xA;</code></p>&#xA;&#xA;<p>There seems to be many people having problems with the change tracker and one common answer is to rebuild the dbcontext with every request, which to me seems utterly wrong, because this is a very ""expensive"" operation.</p>&#xA;&#xA;<p>Also I noticed that the inserting of new data gets slower and slower over time, because the change tracker is filling up, so I would have to recycle the microservice every once and a while.</p>&#xA;&#xA;<p>So my question is:&#xA;How can I get around this Problem without reinitialising the dbcontext with every request?&#xA;I also found some answers that allow to disable the caching, but only for a single db operation, which means I would have to add this option to every DB operation, which to me feels almost as wrong as reinitialising the db context with every request.&#xA;What did I overlook, there has to be a simple solution!</p>&#xA;"
50790960,Seperation of Concerns - How to separate GET/PUT/PATCH/POST/DELETE/ETC into one Microservice that gets its models and DTOs externally,<c#><rest><.net-core><microservices><separation-of-concerns>,1,56,3,0.0,0,"<p>Lets say you have a typical C# .netcore webapi you are wanting to use in a microservices architecture environment. It uses entity framework connects to a SQL database, has models and DTOs.</p>&#xA;&#xA;<p>If you want to separate the 'restfulness', the actions of actually responding to the individual GET/PUT/PATCH/POST/DELETE/ETC methods, from the data models (and into microservices) what approach would you take? </p>&#xA;&#xA;<p>IE instead of having to create 100 microservices that each expose the same exact RESTful functionality within the APIs but each have their own specific data models and DTOs, id want to create 1 API that exposes restful GET/PUT/PATCH/POST/DELETE/ETC and separate it from static models, dtos and entitybuilder configurations.  So i'd have 100 microservices concerned with passing data to the 1 REST microservice to get whatever job I need to do done in a dynamic fashion.</p>&#xA;&#xA;<p>I am not super experienced with object oriented programming methods and I thought maybe it would be possible to have my CRUD microservice that my child microservice talks to (through an API gateway or some other method that I haven't worked out yet) pass a set of models, DTOs and entity framework entitybuilder parameters into the CRUD microservices Program.cs's Main method? </p>&#xA;&#xA;<p>I am on the right path here? </p>&#xA;&#xA;<p>Thank you in advance for any advise or helpful examples!!!</p>&#xA;"
50555353,How to handle in Event Driven Microservices if the messaging queue is down?,<multithreading><reactive-programming><message-queue><microservices><event-driven-design>,1,51,0,2.0,1,"<p>Assume there are two services <strong>A</strong> and <strong>B</strong>, in a microservice environment.</p>&#xA;&#xA;<p>In between A and B sits a messaging queue <strong>M</strong> that is a broker.</p>&#xA;&#xA;<p><strong>A&lt;---->'M'&lt;----->B</strong></p>&#xA;&#xA;<p>The problem is what if the broker M is down?</p>&#xA;&#xA;<p>Possible Solution i can think of:&#xA;Ping from Service A at regular intervals to check on Messaging queue <strong>M</strong> as long as it is down. In the meantime, service <strong>A</strong> &#xA;stores the data in a local DB and dumps it into the queue once the broker M is up.</p>&#xA;&#xA;<p>Considering the above problem, if someone can suggest whether threads or reactive programming is best suited for this scenario and ways it could be handled via code, I would be grateful.</p>&#xA;"
50634072,Observer pattern in microservice,<java><design-patterns><microservices><observer-pattern>,1,118,6,0.0,1,"<p>Currently I am reading the book called: Head First Pattern Design, there is one design pattern called: Observer pattern, like this: <a href=""https://www.tutorialspoint.com/design_pattern/observer_pattern.htm"" rel=""nofollow noreferrer"">https://www.tutorialspoint.com/design_pattern/observer_pattern.htm</a></p>&#xA;&#xA;<p>While I was reading that design pattern, I was feeling that currently we often use queuing system to publish and subscribe tasks between each microservices. Got a feeling that the Observer pattern is not quite often be used currently.  <strong>Please correct me if I am not right, if could provide some example about using observer pattern in mircoservice will be excellent!</strong></p>&#xA;"
34586306,Is it possible to implement microservices with oData.net,<c#><.net><architecture><odata><microservices>,2,799,0,1.0,1,"<p>I've been reading about the <a href=""http://microservices.io/patterns/microservices.html"" rel=""nofollow"">Microservice Architecure</a> and with the limited valuable information available on internet, I believe, I have a fair understanding of it from the theory point of view. I understand that on a high level this architecture suggests to move away from <a href=""http://microservices.io/patterns/monolithic.html"" rel=""nofollow"">monoliths</a> and have small, independent services. However, all the examples that I see on the internet are suggesting to write loosely coupled windows services (daemons in case of non MS implementations) connected to an <a href=""https://en.wikipedia.org/wiki/Enterprise_service_bus"" rel=""nofollow"">ESB</a>. I understand that writing small, loosely coupled web services that adhere to <a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow"">SRP</a> also fits the bill of micro services.</p>&#xA;&#xA;<p>That said, oData.Net services, where all oData controllers (micro services?) are deployed as a monolith, is a clear violation of the Microservices Architecure pattern. Is it a correct statement to make that oData.net is not designed to work as micro services? If your answer is no then please explain with help of a an example. Also, help me understand, how to have the API gateway pattern in the mix.</p>&#xA;"
26611387,"DDD: Can anyone explain the diffrences between DTO, Aggregate Root and Detached Entity?",<java><jpa><domain-driven-design><microservices>,2,707,3,0.0,1,"<p>I'm a bit puzzled in figuring out the differences between these three. Presumed I have a Customer -> Address relation the (JPA) Detached Entity will have this as well (Eager Loading presumed). Where is the need to have an additional Aggregate Root? Where is the need to have a DTO? Is it all more or less the same?</p>&#xA;&#xA;<p>One of the reasons might be that the JPA compliant Entity has some info the client is simply not interested in, e.g. <code>@Entity</code>, <code>@Id</code>, <code>@OneToMany</code>.</p>&#xA;&#xA;<p>I can convert it easily to JSON/XML using JAX-RS/-WS and almost every client can deal with it, so where is the need for having it? Is it all almost the same or do I miss something important?</p>&#xA;"
36954140,How to create JAX-RS Sub Resources with WSO2 MSf4J,<java><wso2><jax-rs><microservices><msf4j>,1,195,4,0.0,1,"<p>I have create a sample micro service using WSO2 MSF4J. But i can't access the sub resources (services). Following are my service classes. </p>&#xA;&#xA;<p>Message Resource - </p>&#xA;&#xA;<pre><code>@Path(""/messages"")&#xA;@Consumes(MediaType.APPLICATION_JSON) &#xA;@Produces(MediaType.APPLICATION_JSON) &#xA;public class MessageResource {&#xA;&#xA;    @Path(""/{messageId}/comments"")&#xA;    public CommentResource getCommentResource(){&#xA;&#xA;        System.out.println(""inside the getCommentResource method"");&#xA;        return new CommentResource();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Comment Resource - </p>&#xA;&#xA;<pre><code>@Path(""/"") &#xA;public class CommentResource {&#xA;&#xA;    @GET&#xA;    @Path(""/{commentId}"")&#xA;    public String test2(@PathParam(""messageId"") long messageId, @PathParam(""commentId"") long commentId){&#xA;&#xA;        System.out.println(""method to return comment Id : "" + commentId + "" for message : "" + messageId);&#xA;        return ""method to return comment Id : "" + commentId + "" for message : "" + messageId;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have used following URI to access this service.</p>&#xA;&#xA;<p>GET : <a href=""http://localhost:8080/messages/1/comments/5"" rel=""nofollow"">http://localhost:8080/messages/1/comments/5</a></p>&#xA;&#xA;<p>But i got following result to my REST client.</p>&#xA;&#xA;<pre><code>404 Not Found&#xA;&#xA;Problem accessing: /messages/1/comments/5. Reason: Not Found&#xA;</code></pre>&#xA;&#xA;<p>Please help to resolve this. </p>&#xA;"
30209442,Cross-Microservice Authorization and Authentication,<authentication><authorization><microservices>,1,760,4,1.0,1,"<p>Suppose we have a number of (stateless, HTTP-based) (micro)services and a bunch of ""daemons"", which do all kinds of background processing by actually using said services.</p>&#xA;&#xA;<p>Now, I want to have a way for services and daemons to be able to mutually authenticate and authorize. For example, a daemon that performs full-text indexing of Orders needs:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Read-only</strong> access to the <em>Orders</em>, <em>Customers</em> (which itself needs read-only access to <em>Companies</em> service) and <em>Inventory</em> services </li>&#xA;<li><strong>Read and write</strong> access to the <em>OrdersSearch</em> service in order to be able to update the full-text index.</li>&#xA;</ul>&#xA;&#xA;<p>There are also applications, which operate ""on behalf"" of the user. For example, Inventory web app needs <strong>read and write</strong> access to the <em>Inventory</em> service, but the <em>Inventory</em> service itself needs to verify permissions of the user operating the application.</p>&#xA;&#xA;<p>All that said, how do I achieve what I just described? I'd prefer not to use gigantic enterprisey frameworks or standards. From what I've read, Two-Legged OAuth2 is what I need, but I'm not exactly sure.</p>&#xA;&#xA;<p>I was thinkinking of establishing an <em>Authorization</em> service which will be used to answer questions like ""Hey, I'm <em>Inventory</em> service. What permissions the <em>Customer</em> service that is calling me right now has for me?"", but that has two major weak with distributing shared secrets.</p>&#xA;"
48914388,Separating Node.js applications into multiple,<node.js><mongodb><web-applications><passport.js><microservices>,1,37,1,2.0,1,"<p>So me being stupid didn't think about that I build my whole application front to back on one Node.js application instance. Now I have to figure out how to make each thing its own service. My current application has the front end (main site), front end (application/software part) and the backend all together. I need to figure out how best to separate these into front/main, auth, front/app and backend/app</p>&#xA;&#xA;<p>How would I even go about doing this? I would post code examples but I am sure that is too long and would not let me thanks to a code to word ratio on here. The git repo is not public either so can't post that.  </p>&#xA;&#xA;<p>My stack is mongo, node.js and express, I am using passport.js to go with it also.</p>&#xA;"
36812791,Doing compex reports with microservices,<report><microservices>,1,1655,0,0.0,1,"<p>I'm starting a new project and am interested in architecting it as microservices. I'm trying to wrap my head around it:</p>&#xA;&#xA;<p>Say that I have an order service and a product service. Now I want to make a report service that gives me all orders that contain a product from a certain product category. </p>&#xA;&#xA;<p>Since order's dont know about products that means that I would need to fetch all orders, loop them and fetch products for each order and then return those how match. </p>&#xA;&#xA;<p>Is this assumption correct or is there any more efficient way of doing this with microservices?</p>&#xA;"
40413453,Aggregated Notification Microservice,<microservices>,1,728,1,0.0,1,"<p><strong>The Problem</strong></p>&#xA;&#xA;<p>We are currently architecting our new Notification Microservice but having trouble with how to handle aggregated emails. What we need to do is instead of sending one email every action performed (could be 20+ in a few minutes), we would send an email after an hour summarising all the actions that were completed.</p>&#xA;&#xA;<p><strong>What We Have So Far</strong></p>&#xA;&#xA;<p>We so far propose that we have this type of messaging pattern, where Client Service is any service in our cluster and Messagebot is our Notification Microservice.</p>&#xA;&#xA;<ol>&#xA;<li>Client Service sends a notification to Messagebot that it will need to send something in the future</li>&#xA;<li>Messagebot stores the details in its database</li>&#xA;<li>Messagebot periodically checks its database for what needs to be sent</li>&#xA;<li>Messagebot gets the required data from another service (could be Client Service) via API</li>&#xA;<li>Messagebot sends email using the data from #3 and an HTML template</li>&#xA;</ol>&#xA;&#xA;<p><strong>The Debate</strong></p>&#xA;&#xA;<p>For the data that needs to be sent, we are less sure and it is what we need help with. So far we think this should be the structure of the JSON from Client Service to Notification Service (step #1):</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    objectid: SOME_OBJECT_ID&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>or</p>&#xA;&#xA;<pre><code>{&#xA;    template_id: SOME_TEMPLATE_ID,&#xA;    user_id: SOME_USER_ID,&#xA;    required_objects: { task_id: SOME_TASK_ID, document_id: SOME_DOCUMENT_ID }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Where task_id and document_id are just examples and it would change based on the template. It could just as easily be <code>{product_id: SOME_PRODUCT_ID}</code> for a different template.</p>&#xA;&#xA;<p><strong>Why The Debate</strong></p>&#xA;&#xA;<p>Our thoughts so far are that:</p>&#xA;&#xA;<ol>&#xA;<li>We only need template_id because the source of the data would be implied in the objects (like an ENV var). For example, the Task object would be at <a href=""http://taskservice/:id"" rel=""nofollow noreferrer"">http://taskservice/:id</a>. Otherwise, we can have problems with failing APIs or switching URLs in the future.</li>&#xA;<li>We should use userid instead of email and name because we prevent the issue of email/ name pairs not matching up over multiple messages</li>&#xA;<li>For the objects, we're still sceptical because it means that the client app service would need knowledge of the inner workings in Messagebot but a single objectid might not be very extensible. We could easily imagine many of our messages needing more than one object.</li>&#xA;</ol>&#xA;&#xA;<p><strong>In Conclusion</strong></p>&#xA;&#xA;<p>Thank you for reading. The design of this service is important because it will be central to our entire organisation. </p>&#xA;&#xA;<p>Which debated JSON structure is most appropriate in our situation? Also, knowing our requirements, what would be the proper setup for this type of service? (aka. Are we correct in our other assumptions?)</p>&#xA;"
32831192,microservices and domain logic joins,<join><architecture><microservices>,3,160,0,1.0,1,"<p>Microservices are deployed hosting their own database.</p>&#xA;&#xA;<p>What strategies do you employ when business requirements necessitate joins across data in multiple services?</p>&#xA;&#xA;<p>Example problem:  You are implementing a movie review site.  You have a movie microservice that holds the movie DB.  You also have a review microservice that manages reviews in its own separate DB.  Reviews are linked to movies via a GUID; but as these are implemented as separate data stores, not a key constraint.</p>&#xA;&#xA;<p>You would like to have available, accurate to the last minute, a report that tells you the total number of reviews for each review level grouped by the first letter of the movie having a review word count > 25 words.  You currently host 5 million reviews for 40,000 movies.</p>&#xA;&#xA;<p>E.G.   Reviews with more than 25 words:</p>&#xA;&#xA;<ul>&#xA;<li>A  [8457 ""1 star""] [16615 ""2 star""] [...</li>&#xA;<li>B  [98445 ""1 star""] [80210 ""2 star""] [...</li>&#xA;<li>...</li>&#xA;</ul>&#xA;&#xA;<p>Having chosen a microservice architecture for your project, what strategies would you now employ to implement this feature? </p>&#xA;"
39096701,DDD User-Domain specific settings,<domain-driven-design><microservices>,1,150,12,1.0,1,"<p>I am currently developing micro service responsible for authentication (bounded context responsible for identity and permissions). We have specific settings based on user roles which are tied to another domains, but used to generate tokens</p>&#xA;&#xA;<p>(something like this <a href=""https://developer.zendesk.com/rest_api/docs/core/custom_roles"" rel=""nofollow"">https://developer.zendesk.com/rest_api/docs/core/custom_roles</a>)</p>&#xA;&#xA;<p>For an example</p>&#xA;&#xA;<pre><code>role_can_write_booking: true,&#xA;fetch_products_type : ""all/forUsersCompanyOnly""&#xA;</code></pre>&#xA;&#xA;<p>etc.</p>&#xA;&#xA;<p>Should I persist this information as a part of Identity BC, or each domain should persist it's part of settings.&#xA;Example:&#xA;<code>role_can_write_booking : true</code> inside Booking Bounded Context,&#xA;<code>fetch_products_type : ""all/forUsersCompanyOnly""</code> inside Booking products bounded context. ?</p>&#xA;"
36049030,golang workspaces in practice,<go><workspace><microservices>,3,314,2,0.0,1,"<p>According to the Go documentation they would like you to have a workspace that one should put all their projects in.<sup>1</sup> However, as far as I can tell, this all falls apart as soon as you want to make a project that does not use Go exclusively. </p>&#xA;&#xA;<p>Take a project where it is made up of many micoservices for example. Lets say that it is structured like this:</p>&#xA;&#xA;<pre><code>app/&#xA;    authentication/ (Using rust)&#xA;    users/ (Using NodeJS)&#xA;    posts/ (Using Go)&#xA;</code></pre>&#xA;&#xA;<p>Only one part of the app would be written in Go, and that part is nested in a subdirectory of the app. How would I apply the Go workspace philosophy to this situation?</p>&#xA;&#xA;<hr>&#xA;&#xA;<ol>&#xA;<li><a href=""https://golang.org/doc/code.html#Workspaces"" rel=""nofollow"">https://golang.org/doc/code.html#Workspaces</a></li>&#xA;</ol>&#xA;"
33805449,How to store shared-by-same-instances data in spring microservices architecture,<jpa><database-design><architecture><spring-cloud><microservices>,3,452,0,0.0,1,"<p>following situation: I am building a system that requires redundant microservices for failover or loadbalancing. So I am starting two (or more instances of a service) of for example a simple core rest service that provides data.</p>&#xA;&#xA;<p>My Question is: How would you store the data? Using two JPA-instances to access the same database (both writing and reading) will result in problems, especially in layer 2 caching and in consistency. Since the database must be redundent itself (requirement) it might be possible to make each service instance accessing its own database, but how would you synchronize them? Is there any common solution for this?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
31135664,Has anyone tested Akka-http-testkit?,<scala><akka><karma-jasmine><microservices><akka-testkit>,1,678,0,0.0,1,"<p>I'm working in a microservice architecture based in akka-http and akka clustering . I have seen in akka documentation this library <a href=""http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala/http/index-testkit.html"" rel=""nofollow"">akka-http-testkit</a>. Actually, it's in an experimental state , but haven't found any documentation . Seems it's on progress . </p>&#xA;&#xA;<p>Has anyone used this library ? Can anyone suggest me any way to test rest microservices ? . My first option is using <a href=""http://karma-runner.github.io/0.12/index.html"" rel=""nofollow"">Karma</a>, and do the testing via javascript, but it would be great to hear different opinion and options (as Akka-http-testkit ... maybe ... :))</p>&#xA;"
41548676,Running Lagom in Production,<java><akka><actor><microservices><lagom>,1,1214,0,1.0,1,"<p>I am working on setting up a Lagom application in production. I have tried contacting Lightbend for ConductR license but haven't heard back in ages. So, now I am looking for an alternative approach. I have multiple questions.</p>&#xA;&#xA;<p>Since the scale of the application is pretty small right now, I think using a static service locator works for me right now (open to other alternatives). Also, I am using MySQL as my event store instead of the default configuration of Cassandra (Reasons not relevant to this thread).</p>&#xA;&#xA;<p>To suppress Cassandra and Lagom's Service Locator, I have added the following lines to my build.sbt:</p>&#xA;&#xA;<pre><code>lagomCassandraEnabled in ThisBuild := false&#xA;</code></pre>&#xA;&#xA;<p>I have also added the following piece to my application.conf with service1-impl module.</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For the dev environment, I have been able to successfully run my application using <code>sbt runAll</code> in a tmux session. With this configuration, there is no service locator running on the default 8000 port but I can individually hit service1 on 8080 port. (Not sure if this is the expected behaviour. Comments?)</p>&#xA;&#xA;<p>I ran <code>sbt dist</code> to create a zip file and then unzipped it and ran the executable in there. Interestingly, the zip was created within the service1-impl folder. So, if I have multiple modules (services?), will sbt dist create individual zip files for each of the service?</p>&#xA;&#xA;<p>When I run the executable created via <code>sbt dist</code>, it tries to connect to Cassandra and also launches a service locator and ignores the static service locator configuration that I added. Basically, looks like it ignores the lines I added to build.sbt. Anyone who can explain this?</p>&#xA;&#xA;<p>Lastly, if I were to have 2 services, service1 and service2, and 2 nodes in the cluster with node 1 running service1 and node 2 running both the services, how would my static service locator look like in the application.conf and since each of the service would have its own application.conf, would I have to copy the same configuration w.r.t. static service locator in all the application.confs?</p>&#xA;&#xA;<p>Would it be something like this?</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;    service1 = ""http://1.2.3.4:8080""&#xA;    service2 = ""http://1.2.3.4:8081""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Since each specific actor would be spawned on one of the nodes, how would it work with this service locator configuration?</p>&#xA;&#xA;<p>Also, I don't want to run this in a tmux session in production. What would be the best way to finally run this code in production?</p>&#xA;"
41624628,How do you develop a microservice in isolation when it depends on other microservices?,<microservices>,2,196,1,2.0,1,"<p>We are evaluating a move to microservices.  Each microservice would be its own project developed in isolation.  During planning, we have determined that some of the microservices will communicate with other via REST calls, pub/sub, messaging (ie. a order service needs product information from product service).</p>&#xA;&#xA;<p>If a microservice depends on retrieving data from another microservice, how can it be run in isolation during development?  For example, what happens when your order service requests product details, but there is nothing to answer that request?</p>&#xA;"
39721791,Can you reference other aggregates in a factory when implementing domain driven design?,<java><domain-driven-design><microservices>,3,46,0,0.0,1,"<p>I have two aggregates, <code>Employee</code> and <code>Company</code>.  An <code>Employee</code> stores a reference to the <code>Company</code> via it's <code>UUID</code>.</p>&#xA;&#xA;<p>If I want to create an employee, I need to provide it with the company ID:</p>&#xA;&#xA;<pre><code>new Employee(name, companyId)&#xA;</code></pre>&#xA;&#xA;<p>What I can't get my head around is how to get the <code>id</code> of the <code>Company</code> if the client provides only the company name.  In other words, I see this happening:</p>&#xA;&#xA;<pre><code>Employee buildEmployee(String name, String companyName) {&#xA;    Company company = companyRepository.findByName()&#xA;    return new Employeee(name, company.getGUID())&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Something feels wrong to me, as now I've introduced a dependency on the <code>Company</code> aggregate in order to create an <code>Employee</code>.  Even worse would be that if these were two were separate microservices, as I'd have to make a rest call to get the company name.</p>&#xA;&#xA;<p>Is there a way to avoid this coupling, or are my entities modelled incorrectly?</p>&#xA;"
39690815,java.lang.IllegalArgumentException: Only the target location may be specified,<java><spring><spring-mvc><spring-boot><microservices>,2,330,4,0.0,1,<p>I'm writing my first spring boot application. on running the following command i'm getting the exception.</p>&#xA;&#xA;<pre><code>spring init --build maven --groupId com.redhat.examples\ --version 1.0 --java-version 1.8 --dependencies web\ --name hola-springboot hola-springboot&#xA;java.lang.IllegalArgumentException: Only the target location may be specified&#xA;    at org.springframework.util.Assert.isTrue(Assert.java:68)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.createProjectGenerationRequest(InitCommand.java:218)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.generateProject(InitCommand.java:209)&#xA;    at org.springframework.boot.cli.command.init.InitCommand$InitOptionHandler.run(InitCommand.java:189)&#xA;    at org.springframework.boot.cli.command.options.OptionHandler.run(OptionHandler.java:84)&#xA;    at org.springframework.boot.cli.command.OptionParsingCommand.run(OptionParsingCommand.java:54)&#xA;    at org.springframework.boot.cli.command.CommandRunner.run(CommandRunner.java:219)&#xA;    at org.springframework.boot.cli.command.CommandRunner.runAndHandleErrors(CommandRunner.java:171)&#xA;    at org.springframework.boot.cli.SpringCli.main(SpringCli.java:63)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)&#xA;    at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)&#xA;    at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58)&#xA;</code></pre>&#xA;
35531784,How to make available the identity of a user across multiple microservices?,<authentication><authorization><microservices>,1,566,1,0.0,1,"<p>So let's take the basic e-commerce microservices. </p>&#xA;&#xA;<ol>&#xA;<li>Identity and access . This microservice will take care of user accounts, roles<br>&#xA;and authentication. The authentication method will be the based on the usual<br>&#xA;token based flow (user enters username + pass and server returns a unique and<br>&#xA;random token via cookie).  This service can also be used to get the user profile.</li>&#xA;<li>Cart microservice. This microservice can be used to put products in a cart.<br>&#xA;Check what products a cart has. Etc ...  </li>&#xA;</ol>&#xA;&#xA;<p>Asuming that ""Identity and access"" microservice will be used for generating the random token as a result of a succesful authentication, and for linking this token to a user, how will this token be used to make the user's identity available to the cart microservice? For example, when a user will add a product to his cart, he will send along the authorization token and the cart microservice will have to identify the user based on that token.  </p>&#xA;&#xA;<p>Could a distributed database be an option? A database which has these tokens stored and links to user built, and to which all microservices have access?  </p>&#xA;&#xA;<p>Or should all microservices get the user's identity from a special identity and access API which will expose users based on the access token?</p>&#xA;"
35639882,JWT Authentication within a Micro Service architecture,<php><node.js><rest><authentication><microservices>,2,682,2,0.0,1,"<p><strong>Question</strong></p>&#xA;&#xA;<p>Question how is it possible to create an authentication service within a micro-service application and have other services check against that token (JWT) and retrieve a user?</p>&#xA;&#xA;<p><strong>Possible Solution</strong></p>&#xA;&#xA;<p>My current thinking is based around the auth service inserting <code>{ token, user }</code> into Redis once a user is authenticated. All other service can check against the user's <code>Authorization: Bearer kdI8$dj$nD&amp;...</code> header token within Redis. </p>&#xA;&#xA;<ul>&#xA;<li>If <code>token</code> is present in Redis, user is authenticated.</li>&#xA;<li>If <code>token</code> is not present in Redis, user is not authenticated.</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/7fsl7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7fsl7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<ol>&#xA;<li>User sends <code>{ username, password }</code> to auth service</li>&#xA;<li>Auth service authenticates credentials and retrieves <code>{ token, user }</code></li>&#xA;<li>Auth service inserts <code>{ token, user }</code> into Redis</li>&#xA;<li>User makes request to <code>Service-1</code> with <code>{ token }</code></li>&#xA;<li><code>Service-1</code> loooks for <code>{ token }</code> in Redis and retrieves <code>{ token, user }</code></li>&#xA;<li><code>Service-1</code> does its thing and sends back <code>{ data }</code></li>&#xA;</ol>&#xA;&#xA;<p>Are there any possible security, logic or architectural problems with this approach? </p>&#xA;"
37699062,API vs Event in Microservice approach,<soa><cqrs><microservices><event-sourcing><eda>,1,721,0,1.0,1,"<p>What about <a href=""http://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes"" rel=""nofollow"">Smart endpoints and dumb pipes</a> in terms of different type of requests?</p>&#xA;&#xA;<p>After reading that I was thinking that it's enough to subscribe for some events and deal with that. But now I've realised that sometimes you should have opened API (maybe not for the end customers, but for the API Gateway etc). Is this ok? Or you should ""eventize"" (transform into event) any request which coming to Microservices cloud?</p>&#xA;&#xA;<p>So, for instance, you have Invoice and Order services.&#xA;It's clear that when order created you might use an event which might be consumed by Invoice service to create an invoice. It's clear that for receiving list of last user's orders you may use CQRS on Order service side or even just make new service LastOrders which will keep just projection of required data. But should this request transformed into event or LastOrders should provide API for that and listen for events to update it's own DB? </p>&#xA;"
37711051,Example open source microservices applications,<microservices>,3,729,1,1.0,1,"<p>I'm looking for open source applications that demonstrate the <a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow"">microservices</a> pattern. In particular, I'd like to find one or more applications that can be spun up on real cloud environment up (but with fake data and requests) to demonstrate real-world deployment mechanics.</p>&#xA;&#xA;<p>Unfortunately, I haven't found any good options yet. I'll note that <a href=""https://www.discourse.org/"" rel=""nofollow"">Discourse</a> is a modern 3-tier application, using Rails API, Ember.js, Postgres, and Redis, but it still is much closer to a monolith than an example of microservices. The closest I've found so far is <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">https://github.com/kbastani/spring-cloud-microservice-example</a> but that is more of a framework than an actual application that delivers data.</p>&#xA;"
46451544,C++ MicroServices with desktop application,<c++><microservices><desktop>,1,807,7,1.0,1,<p>I got a desktop application and it's getting bigger and bigger. And i wonder if i can make something like microservices with desktop application? I want to application for now stays desktop. Application it's written in C++.&#xA;I can exclude some of the modules with some preparations.&#xA;But is it possible and if anybody have idea how to start with this?</p>&#xA;
45047011,Microservice architecture for ETL,<web-services><architecture><etl><microservices><restful-architecture>,3,1201,2,2.0,1,"<p>I am redesigning a small monolith ETL software written in Python. I find a microservice architecture suitable as it will give us the flexibility to use different technologies if needed (Python is not the nicest language for enterprise software in my opinion). So if we had three microservices (call them Extract, Transform, Load), we could use Java for Transform microservice in the future.</p>&#xA;&#xA;<p>The problem is, it is not feasible here to pass the result of a service call in an API response (say HTTP). The output from Extract is going to be gigabytes of data.</p>&#xA;&#xA;<p>One idea is to call Extract and have it store the results in a database (which is really what that module is doing in the monolith, so easy to implement). In this case, the service will return only a yes/no response (was the process successful or not).</p>&#xA;&#xA;<p>I was wondering if there were a better way to approach this. What would be a better architecture? Is what I'm proposing reasonable?</p>&#xA;"
34049118,Tracking Issues across multiple repositories,<github><jira><microservices>,1,493,6,1.0,1,"<p>We often have epic stories which span multiple repositories.  I am looking for a mechanism to track all the work that is associated with a single story.  GitHub has Issues which is a close to the solution I seek.  The problem with Issues is they do not span multiple repositories. On deployment day I still need to scan ~10 repositories (there are 100 repo's, 10 are commonly used) to discover which ones have commits related to the story.</p>&#xA;&#xA;<p>As a manual workaround I create multiple Issues.  One Issue for each repository.  Then I manually list the Issue#'s related to the epic story in Jira.</p>&#xA;&#xA;<p>Is there a tool or alternative technique I can use to automatically combine these issues and treat them as one?</p>&#xA;"
38099204,Session management using json web tokens in microservices,<json><session><token><jwt><microservices>,1,808,0,0.0,1,"<p>I am trying to figure out how I will manage sessions using json web tokens in a microservice architecture. </p>&#xA;&#xA;<p>Looking at the design in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""nofollow"">article</a> what I currently have in mind is that the client will send a request that first goes through a firewall. This request will contain an opaque/reference token which the firewall sends to an authorization server.  The authorization server responds with a value token containing all the session information for the user.  The firewall then passes the request along with the value token to the API, and the value token will then get propagated to all the different microservices required to fulfill the request. </p>&#xA;&#xA;<p>I have 2 questions:</p>&#xA;&#xA;<ol>&#xA;<li>How should updates to the session information in the value token be handled? To elaborate, when the session info in a token gets updated, it needs to be updated in the authorization server.  Should each service that changes the token talk to the authorization server? </li>&#xA;<li>Should all the microservices use this single token to store their session info? Or would it be better for each service to have a personalized token? If it's the latter, please explain how to adjust the design.</li>&#xA;</ol>&#xA;"
33291874,"Microservices: Worker roles, APIs or both?",<microservices>,1,976,1,0.0,1,"<p>I have seen mixed examples of Microservices implemented as worker roles processing requests off a queue and/or as APIs (REST). </p>&#xA;&#xA;<p>Supporting asynchronous scenarios, a queue can be utilized, with a simple dumb queue listener forwarding the request to a Microservice REST API, where as synchronous scenarios would  call the REST API directly. </p>&#xA;&#xA;<p>The term Microservice is vaguely defined I think; do people consider them APIs (e.g. RESTful services) or as any abstract service processing requests, however that request was provided ?</p>&#xA;"
33335786,What is the best way for applications to communicate in micro-service architectures,<python><json><xml-rpc><microservices><amp>,1,273,6,0.0,1,"<p>I have to design and implement a service delivery platform.  I have various services in my current design and all of those tools are using different technologies.  Some are erlang based concurrent map-reduce functions and some are simple bash scripts to aggregate some text files. </p>&#xA;&#xA;<p>I heared about <strong>XML/RPC</strong>, <strong>Protocol Buffer</strong>, <strong>message-pack</strong>, <strong>soup</strong> and <strong>AMQP</strong>.  currently I use <strong>JSON</strong>, but loading and dumping large json files are a bit time/memory consuming.  Is there any new or robust way to make a bridge between various technologies on HTTP infrastructure with wide range programming language support and well documentation?</p>&#xA;&#xA;<p>EDIT1: I also need to mention that i believe complexity is much more corrosive than latency problems or other connection related issues.  So the JSON replacement must not add complexity to design.  </p>&#xA;&#xA;<p>Thanks in advanced.</p>&#xA;"
45321939,Host a service with 2 endpoints in the same or separate processes?,<web-services><iis><asp.net-web-api><nservicebus><microservices>,2,123,3,0.0,1,"<p>I'm building a microservice with both a synchronous REST endpoint (using WebAPI) and an asynchronous publish/subscribe endpoint (using NServiceBus on top of MSMQ) that will be processing data that is stored in a database shared by these endpoints.</p>&#xA;&#xA;<p>I'm trying to decide if I should host both endpoints in the same process, or if I should simply host them in separate processes and have them use the database as common ground to pass data between these processes. My gut feeling says the same process would be 'better', although it would also be more complex:</p>&#xA;&#xA;<ol>&#xA;<li><p>Hosting the endpoints in separate processes is simple: Host the WebAPI endpoint in IIS and host the NServiceBus endpoint as a Windows Service.</p></li>&#xA;<li><p>When hosting them in the same process, it's possible to self-host the NServiceBus endpoint in the WebAPI code but this is not recommended as IIS will shut down the worker process after a period of inactivity,&#xA;thereby also killing the NServiceBus part of the service and leaving it unable to handle incoming messages.<br>&#xA;So I figured I would have to host both the NServiceBus and the WebAPI endpoints in a Windows service, which appears to be possible when <a href=""https://docs.microsoft.com/en-us/aspnet/web-api/overview/hosting-aspnet-web-api/use-owin-to-self-host-web-api"" rel=""nofollow noreferrer"">using OWIN to self-host the WebAPI endpoint</a>.</p></li>&#xA;</ol>&#xA;&#xA;<p>Does anyone have experience with hosting a service with 2 endpoints in the same or different processes, and can tell me the problems/benefits associated with this choice?</p>&#xA;&#xA;<p><em>(<a href=""https://stackoverflow.com/questions/21202411/host-web-api-in-self-hosted-nservicebus"">This question</a> seemed to ask the same, but it never got a satisfactory answer)</em></p>&#xA;&#xA;<p><strong>Edit</strong> In response to @HadiEskandari, I'm not looking for a WebAPI facade for an NServiceBus endpoint. I'm planning to have the WebAPI endpoint to handle simple queries for information which it stores in the database that is shared between these endpoints.&#xA;Thse REST calls will be invoked AJAX-style from a web application, so I need this to execute quickly - forwarding each REST call through an MSMQ queue &#xA;to the NServiceBus endpoint and waiting for a response seems slow and wasteful in this case.</p>&#xA;&#xA;<p>Rather, I'm looking for a way to keep the data access code and business logic not just in the same assembly, but also in the same AppDomain so that both endpoints may share say, the same configuration or cached data.</p>&#xA;"
45300410,Django - How to implement authentication service in microservices architecture,<django><jwt><microservices>,1,481,3,0.0,1,"<p>Basically, I have several independent services. I want to build a service for authentication. When client get a token from authentication service. Client use it for further request to others services. Client need to attach that token in header of request. The services receiving token need to verify the token by sending it to authentication server. So all requests that clients make to protected routes need to be verified by authentication service. The thing is I do not know the best place to put the code that automatically sends token to authentication service and receive the result. &#xA;Here is what i tried so far:&#xA;I implemented a middleware like that:</p>&#xA;&#xA;<pre><code>class VerifyTokenMiddleware(object):&#xA;&#xA;def process_request(self, request):&#xA;    if not request.META.get('HTTP_AUTHORIZATION'):&#xA;        return HttpResponse(status=404)&#xA;    auth_header = request.META.get('HTTP_AUTHORIZATION')&#xA;    token = auth_header[4:]&#xA;    response = requests.post(AUTH_URL, {""token"": token})&#xA;    if response.status_code == 400:&#xA;        return HttpResponse(status=403)&#xA;    return None&#xA;</code></pre>&#xA;&#xA;<p>However, the problem of my solution is every requests to services(not auth service) have to pass through that middleware. Therefore, client cannot access unprotected routes like before. &#xA;Any help is extremely appreciated. :D</p>&#xA;&#xA;<p>I used django restframework jwt <a href=""https://github.com/GetBlimp/django-rest-framework-jwt"" rel=""nofollow noreferrer"">https://github.com/GetBlimp/django-rest-framework-jwt</a>. </p>&#xA;"
45293123,How to design a multi-file processor using Golang?,<go><design><microservices>,1,53,4,0.0,1,"<p>I'm trying to figure out how to design a service that can handle multiples files format, using micro-services for example:</p>&#xA;&#xA;<p>I have a customer using a file format A, another using format B and other using format C.</p>&#xA;&#xA;<p>After processing a specific format for each customer, I need to transform this format into an common format, and insert into database.</p>&#xA;&#xA;<p>The first thing I tried is to design one service per customer but all of them need to know the base format and if an update is needed in this base format, I need to update all of there services.</p>&#xA;&#xA;<p>I'm trying to decouple the service processor and have a single place to translate to base format.</p>&#xA;&#xA;<p>If my customer services know about the base format, if this format changes,  I need to update all of them. If I have a service that translate the format, this service needs to know all customer formats.</p>&#xA;&#xA;<p>How to design this solution?</p>&#xA;"
45168622,How to share constans between Rails microservices?,<ruby-on-rails><ruby><microservices>,2,88,4,0.0,1,"<p>I have my main app and admin app built as a microservice, they are communicating via api. I want to share some constants between those two apps.</p>&#xA;&#xA;<p>For example I have User model that can have role Owner or Regular. In admin app I can search Users and in this search I have dropdown with hardcoded user type (Owner, Regular). This is okay, but when I change naming (e.g. Regular -> Standard) I have to update my Admin app also.</p>&#xA;&#xA;<p>To avoid changing admin app every time I change some core naming in my main app I want to somehow share those constants, so every change in main app will change Admin at the same time.</p>&#xA;&#xA;<p>For now I found 2 solutions, both with pros and cons:</p>&#xA;&#xA;<p>First is sending constants from main app to admin via json api. I have build a class that will fetch and store all constants in class variable, so it's available from every part of the the app. The good thing about this solution is performance (thanks to memoization it's only one api request) and it's easy to use later. The bad thing is I have no idea how to handle tests in this case. Of course I cannot let my tests make request to main app and stubbing this request makes the whole idea pointless, because after every change of constants in main app I will need to change tests in admin app. </p>&#xA;&#xA;<p>Second approach I thought of is building a gem that will store all constants. It's very easy to implement, but this means I will need to make changes to this repo every time I want to change constants in main app. Also I work with big team and they won't be happy that they have to work on 2 repos at the same time.</p>&#xA;&#xA;<p>What do you think about those solutions? First one seems to be perfect for me except tests, so maybe you have some ideas how to stub those constants without real values? I haven't tried gem solution yet so if you see some obstacles please let me know.&#xA;Maybe there is another better solution to this problem?</p>&#xA;"
45275679,Sharing code in Microservices,<java-ee><architecture><jax-rs><microservices>,1,301,8,0.0,1,"<p>We have two services. However, in the past, these two services were one service, but have been split due to differing traffic requirements.</p>&#xA;&#xA;<p>The services are consumed by two kinds of clients; other services and UI clients (web, desktop and mobile).</p>&#xA;&#xA;<p>Consumers of service 1: Services, </p>&#xA;&#xA;<ol>&#xA;<li>Use a very limited number of exposed endpoints (<code>addInput</code>, <code>removeInput</code>).</li>&#xA;<li>Generates high traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Consumers of service 2: UI clients,</p>&#xA;&#xA;<ol>&#xA;<li>Using a large number of exposed endpoints</li>&#xA;<li>Generating less traffic.</li>&#xA;</ol>&#xA;&#xA;<p>Currently, they are sharing code but as far as I can figure out micro-services should not share base code. Therefore we believe something is wrong using this approach.</p>&#xA;&#xA;<p>what are the key issues to understand in order to solve this kind of micro-services architecture issues?</p>&#xA;"
39476480,microservices: C:\....m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature),<java><maven><microservices>,1,665,0,1.0,1,"<p>I was looking to developed the <code>microservices</code> example by following the link: <a href=""https://github.com/bjedrzejewski/tasklist-service"" rel=""nofollow"">https://github.com/bjedrzejewski/tasklist-service</a>. When I simply compile the whole source code I faced compilation error, not sure why ? It looks to me something wrong with my .m2 home not so sure though.</p>&#xA;&#xA;<p>The error coming for reference:-</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure: Compilation failure:&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\glassfish\jersey\core\jersey-client\2.22.1\jersey-client-2.22.1.jar; invalid LOC header (bad signature)&#xA;[ERROR] error: error reading C:\Users\user\.m2\repository\org\eclipse\jetty\jetty-servlet\9.2.13.v20150730\jetty-servlet-9.2.13.v20150730.jar; invalid LOC header (bad signature)&#xA;[ERROR] -&gt; [Help 1]&#xA;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project tasklist-service: Compilation failure&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)&#xA;        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)&#xA;        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)&#xA;        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)&#xA;        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)&#xA;        at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)&#xA;        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)&#xA;Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure&#xA;        at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:656)&#xA;        at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:128)&#xA;        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)&#xA;        ... 20 more&#xA;[ERROR]&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException&#xA;</code></pre>&#xA;&#xA;<p>I only updated pom.xml to use Java version 8, nothing special</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;bjedrzejewski&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;tasklist-service&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;dropwizard.version&gt;0.9.1&lt;/dropwizard.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.dropwizard&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;dropwizard-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${dropwizard.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jersey-common&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.23.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;2.3.2&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;${java.version}&lt;/source&gt;&#xA;                    &lt;target&gt;${java.version}&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;archive&gt;&#xA;                        &lt;manifest&gt;&#xA;                            &lt;mainClass&gt;com.bjedrzejewski.tasklistservice.TaskListServiceApplication&lt;/mainClass&gt;&#xA;                        &lt;/manifest&gt;&#xA;                    &lt;/archive&gt;&#xA;                    &lt;descriptorRefs&gt;&#xA;                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;&#xA;                    &lt;/descriptorRefs&gt;&#xA;                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;&#xA;                &lt;/configuration&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;&#xA;                        &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;single&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p>Also pom.xml dont have much entry of dependencies but still I see many jars files gets download why this so ?</p>&#xA;&#xA;<pre><code>E:\Advance Java\MicroServices\Git code\tasklist-service&gt;mvn dependency:tree&#xA;[INFO] Scanning for projects...&#xA;[INFO]&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Building tasklist-service 1.0-SNAPSHOT&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO]&#xA;[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ tasklist-service ---&#xA;[INFO] bjedrzejewski:tasklist-service:jar:1.0-SNAPSHOT&#xA;[INFO] +- io.dropwizard:dropwizard-core:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-util:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0:compile&#xA;[INFO] |  |  +- com.google.guava:guava:jar:18.0:compile&#xA;[INFO] |  |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile&#xA;[INFO] |  |  \- joda-time:joda-time:jar:2.9:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jackson:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-core:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk7:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.6.3:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-joda:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.slf4j:slf4j-api:jar:1.7.12:compile&#xA;[INFO] |  |  \- ch.qos.logback:logback-classic:jar:1.1.3:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-validation:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.hibernate:hibernate-validator:jar:5.2.2.Final:compile&#xA;[INFO] |  |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile&#xA;[INFO] |  |  |  +- org.jboss.logging:jboss-logging:jar:3.2.1.Final:compile&#xA;[INFO] |  |  |  \- com.fasterxml:classmate:jar:1.1.0:compile&#xA;[INFO] |  |  \- org.glassfish:javax.el:jar:3.0.0:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-configuration:jar:0.9.1:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- org.yaml:snakeyaml:jar:1.15:compile&#xA;[INFO] |  |  \- org.apache.commons:commons-lang3:jar:3.4:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-logging:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-logback:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.slf4j:jul-to-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- ch.qos.logback:logback-core:jar:1.1.3:compile&#xA;[INFO] |  |  +- org.slf4j:log4j-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  +- org.slf4j:jcl-over-slf4j:jar:1.7.12:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-util:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-metrics:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jersey:jar:0.9.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.core:jersey-server:jar:2.22.1:compile&#xA;[INFO] |  |  |  +- org.glassfish.jersey.core:jersey-client:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-metainf-services:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.ext:jersey-bean-validation:jar:2.22.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jersey2:jar:3.1.2:compile&#xA;[INFO] |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile&#xA;[INFO] |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile&#xA;[INFO] |  |  |  \- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.6.3:compile&#xA;[INFO] |  |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.22.1:compile&#xA;[INFO] |  |  |  \- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.22.1:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-server:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-io:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-xml:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-continuation:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-servlets:jar:0.9.1:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-annotation:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-jetty:jar:0.9.1:compile&#xA;[INFO] |  |  +- io.dropwizard.metrics:metrics-jetty9:jar:3.1.2:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlet:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  |  \- org.eclipse.jetty:jetty-security:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  +- org.eclipse.jetty:jetty-servlets:jar:9.2.13.v20150730:compile&#xA;[INFO] |  |  \- org.eclipse.jetty:jetty-http:jar:9.2.13.v20150730:compile&#xA;[INFO] |  +- io.dropwizard:dropwizard-lifecycle:jar:0.9.1:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-servlets:jar:3.1.2:compile&#xA;[INFO] |  |  \- io.dropwizard.metrics:metrics-json:jar:3.1.2:compile&#xA;[INFO] |  +- io.dropwizard.metrics:metrics-healthchecks:jar:3.1.2:compile&#xA;[INFO] |  +- net.sourceforge.argparse4j:argparse4j:jar:0.6.0:compile&#xA;[INFO] |  \- org.eclipse.jetty.toolchain.setuid:jetty-setuid-java:jar:1.0.3:compile&#xA;[INFO] \- org.glassfish.jersey.core:jersey-common:jar:2.23.2:compile&#xA;[INFO]    +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile&#xA;[INFO]    +- javax.annotation:javax.annotation-api:jar:1.2:compile&#xA;[INFO]    +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.23.2:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-api:jar:2.5.0-b05:compile&#xA;[INFO]    |  +- org.glassfish.hk2:hk2-utils:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2.external:javax.inject:jar:2.5.0-b05:compile&#xA;[INFO]    +- org.glassfish.hk2:hk2-locator:jar:2.5.0-b05:compile&#xA;[INFO]    |  \- org.javassist:javassist:jar:3.20.0-GA:compile&#xA;[INFO]    \- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD SUCCESS&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 2.860 s&#xA;[INFO] Finished at: 2016-09-13T23:39:38+05:30&#xA;[INFO] Final Memory: 17M/309M&#xA;[INFO] ------------------------------------------------------------------------&#xA;</code></pre>&#xA;"
39888380,"Spring Boot Microservice: dynamic role, permission based security",<java><spring><spring-security><spring-boot><microservices>,1,1120,0,0.0,1,"<p>We have created application using Spring Boot Microservices,&#xA;application contains jsp pages and rest uri.</p>&#xA;&#xA;<p>For this type of architecture expect suggestions to secure pages and uri.&#xA;I want role and permission based access, where permission contains all pages and uri listed and role_permission_mapping has mapping of uri/pages against role.</p>&#xA;&#xA;<p>Admin have rights to add Role, Permission and Mapping dynamically using some UI. </p>&#xA;&#xA;<p>Image below shows sample table structure.</p>&#xA;&#xA;<p>Suggest me if we have built-in mechanism which provides out of box support for this type of requirement.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/eBgNL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBgNL.png"" alt=""enter image description here""></a></p>&#xA;"
41739975,What are the reason to decouple databases on microservices?,<database><microservices><nosql>,1,435,3,0.0,1,"<p>Here I my current findings on this subject, are these correct or is there an aspect missing?</p>&#xA;&#xA;<p>There are two major principles for microservices: </p>&#xA;&#xA;<ul>&#xA;<li><strong>strong cohesion</strong> -> related code is gouped together, e.g. a class does on well defined job this is strong/hingh cohesion. </li>&#xA;<li><strong>loose coupling</strong> -> interconnect components in a system so that those  components, depend on each other as less as practicable. Coupling refers to the degree of direct knowledge that one element has of another. So a change to one service should not require a change to another.</li>&#xA;</ul>&#xA;&#xA;<p>With a shared database (as in not decoupled) architecture both these principles are not covered. This due to the following facts:</p>&#xA;&#xA;<ul>&#xA;<li>There is a fixed link between the users and the specific technology&#xA;choice as well as to the actual database implementation.</li>&#xA;<li>Businiess/application logic might be spread among multiple users.</li>&#xA;<li>Shared information which needs to be edited can trigger a change of&#xA;the behavior in multiple places.</li>&#xA;<li>Due to the more monolithic architecture which goes with shared&#xA;databases a failure can effect many serveries since they are all tied&#xA;together, even a compelte system failure can happen due to the&#xA;coupeling.</li>&#xA;</ul>&#xA;&#xA;<p>To avoid the above mentioned issues: decoupled databases can be used with microservices instead of shared databases. So each microservice should have its own database. This will also ease scaling of the system, provide much much more system availability, since ""only"" the one, really effected service will fail. </p>&#xA;&#xA;<p><strong>UPDATE</strong>: &#xA;One other benefit of microservices would be that it can improve the flexibility and speed of development. Since correctly decomposed microservices, can be developed and deployed e independently and in parallel with the other services.</p>&#xA;"
42353292,Does Service Discovery microservice break idea of loose coupling?,<microservices><service-discovery>,4,120,0,1.0,1,"<p>As a mechanism to connect microservices together and make them work it is usually suggested to use APIs and Service Discovery. But they usually work as their own microservices, but these ones should apparently be ""hard-coded"" into others, as every microservice is supposed to register with them and query for other microservices' locations. Doesn't this break the idea of loose coupling, since a loss of a discovery service implies others being unable to communicate?</p>&#xA;"
42230797,Spring Cloud Stream Kafka - Eventual consistency - Does Kafka auto retry unacknowledged messages (when using autocommitoffset=false),<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,1,689,0,0.0,1,"<p>Implementing an eventually consistent distributed architecture has turned out to be a pain. There are tons of blog posts telling stories about how to do it, but not showing (code) how to actually do it.</p>&#xA;&#xA;<p>One of the aspects I'm suffering is having to deal with manual retries of the messages when they haven't been ack'd.</p>&#xA;&#xA;<p>For instance: my order service sends a pay event to Kafka. Payment Service is subscribed to it and processes it, answering with payment ok or payment failure</p>&#xA;&#xA;<ol>&#xA;<li><p>Ask for payment: <code>Order Service ----Pay event----&gt; Kafka ----Pay Event ----&gt; Payment Service</code></p></li>&#xA;<li><p>Payment OK: -> <code>Payment Service ----Payment ok event ----&gt; Kafka ----Payment ok Event ----&gt; Order Service</code></p></li>&#xA;<li><p>Payment Fail -> <code>Payment Service ----Payment failure event ----&gt; Kafka ----Payment failure Event ----&gt; Order Service</code></p></li>&#xA;</ol>&#xA;&#xA;<p>The point is: </p>&#xA;&#xA;<p>I know for sure when a message has been delivered to Kafka by using sync sendings. BUT, the only way I have to know that the payment has been processed by Payment Service is by expecting an answer event (Payment ok| Payment failure).</p>&#xA;&#xA;<p>This forces me to implement a retry mechanism in Order server. If it hasn't gotten an answer in some time, retry with a new Pay event.</p>&#xA;&#xA;<p>What's more, this also forces me to take care of duplicated messages in Payment Service in case they were actually processed but the answer didn't get to Order Service.</p>&#xA;&#xA;<p><strong>I was wondering if Kafka has a built in mechanism to send retries if the consumer didn't acknowledge the new offset of the messages</strong>.</p>&#xA;&#xA;<p>In Spring Cloud Stream we can set a <code>autoCommitOffset</code> property to false and handle the ack of the offset in the consumer:</p>&#xA;&#xA;<pre><code> @StreamListener(Sink.INPUT)&#xA; public void process(Message&lt;?&gt; message) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         System.out.println(""Acknowledgment provided"");&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p><strong>What happens if we don't execute <code>acknowledgment.acknowledge();</code> Will the message be automatically resent by Kafka to this consumer?</strong></p>&#xA;&#xA;<p>If it is possible we wouldn't need to retry manually any more and could do stuff like this:</p>&#xA;&#xA;<p>Paymen Service:</p>&#xA;&#xA;<pre><code> @Autowired&#xA; private PaymentBusiness paymentBusiness;&#xA;&#xA; @StreamListener(Sink.INPUT)&#xA; public void process(Order order) {&#xA;     Acknowledgment acknowledgment = message.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);&#xA;     if (acknowledgment != null) {&#xA;         paymentBusiness(order);            &#xA;         //If we don't get here because of an exception &#xA;         //Kafka would retry...&#xA;         acknowledgment.acknowledge();&#xA;     }&#xA; }&#xA;</code></pre>&#xA;&#xA;<p>If this were possible, how is the retry period configured in Kafka?</p>&#xA;&#xA;<p>In the worst case (and most likely) scenario, this isn't supported and we would have to retry manually. Do you know any real example of Spring Cloud Stream apps dealing with eventual consistency using Kafka?</p>&#xA;"
41086281,MICROSERVICES - communication between them,<java><rest><microservices>,2,712,4,0.0,1,"<p>I've got one question concerning microservices architecture. I am designing a system based on microservices. I've read few articles and I think I understand the idea. However, I don't how microservices should communicate with each other while they have separate business responsibilities....&#xA;What I mean is that if I have a system for booking train tickets, I would divide backend application into modules: </p>&#xA;&#xA;<ul>&#xA;<li>Client (login,logout,registration) </li>&#xA;<li>Reservations (booking a train seat for user,getting all reservations for user) </li>&#xA;<li>ConnectionsDetails&#xA;(searching for connections,getting connection details) </li>&#xA;<li>Trains&#xA;(information about trains- seats number,class etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Now, I can only think that if user search for connections module ConnectionsDetails communicate with Trains module and ask about particular train details. But how could other microservices communicate? If user wants to login - she/he asks directly Client module, if she/he wants to get all her reservations - asks Reservation module DIRECTLY etc... </p>&#xA;&#xA;<p>So my question is, how should modules communicate if they do different things? I'm sorry if my question is trivial or stupid, I'm just starting with microservices.</p>&#xA;&#xA;<p>EDIT:&#xA;I didn't mean what tools could I use for communication. My question is about logic. In the example I showed, why one microservice could ask another microservice about sth if client can directly ask the another one? As I said earlier, how they should communicate(about what should they ask each other exactly) if they do separate things?</p>&#xA;"
50139640,Architecture of microservices from a business approach or technical?,<rest><docker><cloud><microservices>,3,50,0,1.0,1,"<p>Our team is trying to decouple a <strong>monolithic</strong> spring mvc administrative application <em>(create, update, delete)</em> and we want to adopt an architecture based on <strong>microservices</strong>. </p>&#xA;&#xA;<p>After a bit of research, it seems the best is create microservices <strong><em>according to the problem</em></strong> that a specific part of the software solves, for example, Managing Clients. </p>&#xA;&#xA;<p>The problem comes when we read some definitions, like the following from <strong><a href=""https://en.wikipedia.org/wiki/Monolithic_application"" rel=""nofollow noreferrer"">Wikipedia</a></strong>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In software engineering, a monolithic application describes a&#xA;  single-tiered software application in which the user interface and&#xA;  data access code are combined into a single program from a single&#xA;  platform.</p>&#xA;</blockquote>&#xA;&#xA;<p>Based on that definition, <em>my application is not monolithic</em>, because it is perfectly separated in layers, but it is not found in a micro-services architecture either, which is confusing to me since in the web everything is about <strong>Monolithic vs. Microservices</strong>.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/EIfHO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EIfHO.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>So, should the microservices architecture be designed based on the business problem it solves?</strong> </p>&#xA;&#xA;<p><strong>Should the microservices architecture be designed based on to the way in which the application is organized in layers?</strong></p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
51926575,Linking data in java microservices in a database per service implementation,<java><spring><spring-boot><microservices><cqrs>,3,47,4,1.0,1,"<p>I am building a java / spring microservices where each service has it own database . Let's say i have a user service that stores user information in one of the table and a orders service that stores only the username of the person who orders as described below :-</p>&#xA;&#xA;<pre><code>User Service (UserService Database - User Table )&#xA;id     firstName    lastName     username     age &#xA;1       Chris        Brown       c.brown      20&#xA;2       John         Doe         j.doe        25&#xA;</code></pre>&#xA;&#xA;<p>And orders service as below</p>&#xA;&#xA;<pre><code> Order Service (OrderService Database - Order Table )&#xA;    id     username    productName     productPrice     OrderDate &#xA;    1      c.brown       Sony Mic       100$            20-08-2018&#xA;    2       j.doe       Television      j.doe           11-07-2018&#xA;</code></pre>&#xA;&#xA;<p>Question is what is the best approach to get firstName and lastName from user service while listing the orders . I am aware that microservices should communicate via Rest API , but if i have 1000 users with orders , i will have to loop 1000 times to get the firstName and lastName or take usernames as array , activity which might be expensive . </p>&#xA;&#xA;<p>I have read on using CQRS and event sourcing , but not sure how to best apply it in this scenario . </p>&#xA;"
43617787,What is the difference between workflow and dataflow?,<spring><workflow><microservices><dataflow><spring-cloud-dataflow>,1,586,0,0.0,1,"<p>I'm looking at Spring Cloud Date Flow, before that I watched Activiti and Camunda(this is workflow engine). And I can't understand what is the difference between these concepts as workflow and dataflow? and сan we call Spring Cloud Data Flow the workflow engine?</p>&#xA;&#xA;<p>Sorry, I'm newer in this topic.</p>&#xA;&#xA;<p>I will be glad to any answer!</p>&#xA;"
43584079,How to split an existing webApi project?,<.net><asp.net-web-api><architecture><microservices>,1,68,4,0.0,1,"<p>I have an existing legacy .Net webApi project with ~20 controllers and ~10 methods each.&#xA;The traffic is 15 requests per sec.&#xA;I'm wondering if it's a smart thing to do to take microServices approach and split it into few hosted projects.</p>&#xA;&#xA;<p>Since i don't have access to the clients (android, ios, WebSite and third parties) i will have to keep the existing API URL working (<a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a>).</p>&#xA;&#xA;<p>My quick and dirty architecture is:&#xA;1) Build new hosted API process <a href=""http://domainName/API1"" rel=""nofollow noreferrer"">http://domainName/API1</a>, <a href=""http://domainName/API2"" rel=""nofollow noreferrer"">http://domainName/API2</a>, <a href=""http://domainName/API3"" rel=""nofollow noreferrer"">http://domainName/API3</a>...&#xA;2) Ask kindly from the clients to use the new URLs&#xA;3) <a href=""http://domainName/API"" rel=""nofollow noreferrer"">http://domainName/API</a> will act as router to the new processes for background competitively </p>&#xA;&#xA;<p>Ideas ? Is there any existing pattern for that?  </p>&#xA;"
42918707,What are the disadvantages of using Kerberos authentication for secure micro-service to micro-service communication?,<kerberos><microservices>,1,404,4,0.0,1,"<p>Sam Newman's ""Building Microservices"" book has described several methods that can be used to perform secure service to service communication. Such as</p>&#xA;&#xA;<ol>&#xA;<li>HTTPS Basic Authentication</li>&#xA;<li>Client Certificates</li>&#xA;<li>HMAC API Keys</li>&#xA;</ol>&#xA;&#xA;<p>I think Kerberos protocol can also be used for service to service authentication. But I found less references of using Kerberos protocol. Are there any disadvantages of using kerberos protocol in microservice architecture than other methods? </p>&#xA;"
49985156,Aggregates in Event Sourcing Pattern,<java><aggregate><microservices><event-sourcing>,1,128,4,0.0,1,"<p>I am dipping my feet into event sourcing pattern and trying to make sense of aggregates.I have read a few blogs and now I am more confused than ever before.</p>&#xA;&#xA;<p>From what I inferred aggregates should somehow enable user to run different queries on the event store to retrieve different stream of events.</p>&#xA;&#xA;<p>Use case :</p>&#xA;&#xA;<ol>&#xA;<li><p>I want to <strong>replay</strong> events on an invoice where the I want to see all actions done by  a specific employee on the balance.</p></li>&#xA;<li><p>I want to <strong>replay all</strong> events on an invoice </p></li>&#xA;</ol>&#xA;&#xA;<p>I hope these are valid use cases.</p>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | EmployeeId | Event            | Payload |&#xA;|----------|------------|------------|------------------|---------|&#xA;| 1        | 12345      | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | 45567      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | 77341      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | 98421      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status of invoice&#xA;Status is(Review,Billed,Paid)</p>&#xA;&#xA;<p>So from my understanding there needs to be 5 components . </p>&#xA;&#xA;<ol>&#xA;<li>Event- A specific event.</li>&#xA;<li>Event Source - The service that calls repo to get related events</li>&#xA;<li>Event Stream - A list of events</li>&#xA;<li>Command - A request operation on invoice</li>&#xA;<li>Aggregate -  An api to decide on inputs to load events </li>&#xA;</ol>&#xA;&#xA;<p>I understand how other things play but having a hard time wrapping my head around Aggregate. What is it ?</p>&#xA;&#xA;<p>Will I have two aggregate classes </p>&#xA;&#xA;<ul>&#xA;<li>AggregateEventsByInvoice</li>&#xA;<li>AggregateEventsByInvoiceEmployee</li>&#xA;</ul>&#xA;&#xA;<p>I really am having a hard time figuring out the need and use of aggregate . All the examples I have seen use UUID which does not make sense to me at all? Any help will be greatly appreciated.</p>&#xA;"
50041559,How to share common Data over several Microservices,<domain-driven-design><microservices>,2,87,5,1.0,1,"<p>I'm writing a Bachelors-Thesis about Microservices.</p>&#xA;&#xA;<p>I'm trying to split a monolith into Microservices and now I ran into a problem that there are some tables in a Database, that are relevant for more than one Microservice.&#xA;There is no chance to split this data into domain specific views.</p>&#xA;&#xA;<p>My approach is that I will create a new Database Schema with that specific tables and let all Microservices read from it.&#xA;That would be a shared kernel approach which is not recommended by the experts of Microservices.</p>&#xA;&#xA;<p>Do you have any experience or recommendations about this problem?</p>&#xA;&#xA;<p>Do you have any recommendations about books which are about similar problems?</p>&#xA;"
40840470,MYSQL primary key strategy for microservices architecture,<mysql><microservices>,2,169,5,0.0,1,"<p>We are currently using auto-generated primary keys and we would like to switch to an approach which is more suitable for microservices-based applications: either we are going to use business defined primary key (a tax code for persons) or global unique identifiers.</p>&#xA;&#xA;<ul>&#xA;<li>In the past, MySQL had performance issues when using alphanumeric primary keys instead of autoincrement, is it still the case? </li>&#xA;<li>Is it possible, if we go for the UUID approach, to use a strong uuid generator which will guarantee the uuid will be unique even across different servers?</li>&#xA;</ul>&#xA;"
46668418,Microservice return response first and then process the request,<spring-boot><java-8><microservices>,2,582,5,1.0,1,<p>I am working on a solution for which i am trying to create a microservice which returns response immediately and then processes the request.</p>&#xA;&#xA;<p>I am trying to use Java 8 and Spring for this.</p>&#xA;
45390260,What things should I consider to split my Monolithic nodeJs app to Microservice architecture?,<node.js><microservices>,1,461,3,1.0,1,"<p>I'm trying to build Restful API's using NodeJs for a e-commerce application with a minimal functionality like User Accounts, Products, Inventory System, Cart/ Orders, Payments, Wallet/Credit, Delivery Management, Notifications etc.</p>&#xA;&#xA;<p>I wanted to implement this using a microservice architecture.</p>&#xA;&#xA;<p>I do not want to use a any framework, I want to explore and learn myself. </p>&#xA;&#xA;<p>How should I start?</p>&#xA;&#xA;<p>1) On what parameters should I choose a microservice architecture.</p>&#xA;&#xA;<p>2) How should I use the common ""terms"" like user model, or (products, inventory and orders).</p>&#xA;&#xA;<p>3) Should I build full monolithic App first and then take out the heavy parts out of it, one by one?</p>&#xA;&#xA;<p>A basic guideline that can put me in direction will be very helpful. I'll really appreciate and thank for helping on this subject.</p>&#xA;"
45486658,Is it bad practice to produce and consume messages from the same topic?,<apache-kafka><activemq><messaging><microservices><tibco-ems>,1,363,4,1.0,1,"<p>Say you have a micro-service architecture where multiple services produce and consume <em>unit</em> statusses. </p>&#xA;&#xA;<p>There are multiple ways to design this, which one would you recommend?</p>&#xA;&#xA;<p>These are some options that come to mind:</p>&#xA;&#xA;<ol>&#xA;<li>Create a generic topic <code>unit-status</code> and make services consume and produce messages on this topic. This has the consequence that you consume your own messages and have to filter them. I would consider this a dirty solution, but easy for new new consumers to get all unit status events.</li>&#xA;<li>Create a specific topic for each status, for example <code>unit-status-created</code>, <code>unit-status-packaged</code>, <code>unit-status-loaded</code>, <code>unit-status-deleted</code>, etc. Each service produces only on it's own topic, but can consume from a list of topics, excluding it's own. For example the loading service would consume from list(<code>unit-status-created</code>, <code>unit-status-deleted</code>, <code>unit-status-packaged</code>). This allows services to show interest in only specific events, but it requires a code or config change in potentially all service when a new status topic is added. </li>&#xA;<li>Give each status it's own partition and consume from all partitions except the one you produce in. This design makes things more complicated (bookkeeping which partition contains a specific status), does not auto balance when partitions are added, adding partitions while live makes things a bit more risky, therefore does not have my preference. </li>&#xA;</ol>&#xA;"
47162798,Decomposition into microservices,<design><architecture><microservices><bounded-contexts>,3,86,0,2.0,1,"<p>I have a question regarding decomposition into microservices. Suppose we have 2 microservices: <strong>User</strong> and <strong>Product</strong>. Suppose we now have a requirement to add categories to the system. More specifically, a product has one or more categories (e.g the product red miniature ferrari belongs to categories toys and cars) and a user can have categories which she likes (e.g. toys and shoes). Now when we retrieve the full list of products we want them to be sorted such that the products that fall in the preferred user categories are at the top. </p>&#xA;&#xA;<p>Basically be have a concept that is shared between microservices (in this case category). How to best model this in a microarchitecture environment? I see two solutions:</p>&#xA;&#xA;<p><strong>Solution 1:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Make a separate “categories"" microservice which manages CRUD of categories</li>&#xA;<li>In the product service have an API call to link category ids to a product</li>&#xA;<li>In the user service have an API call to link category ids to a user</li>&#xA;<li>In the product service we have an API call to fetch products ordered on preference. To make this work the product service needs to call the user service to get the user categories (or listen to events emitted by user services)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solution 2:</strong> </p>&#xA;&#xA;<ul>&#xA;<li><p>Make a separate “categories” microservice which manages CRUD of categories</p></li>&#xA;<li><p>The categories service also has an API call to link product ids to categories</p></li>&#xA;<li><p>The categories service also has an API call to link user ids to categories</p></li>&#xA;<li><p>In the product service we have an API call to fetch products ordered on preference (to make this work product service needs to call the categories service to get user and product categories (or listen to events)</p></li>&#xA;</ul>&#xA;&#xA;<p>What are the advantages/disadvantage to both solutions? </p>&#xA;"
47265946,Microservice Project Structure Using Spring boot and Spring Cloud,<spring-boot><microservices>,3,1693,0,1.0,1,"<p>I am trying to convert a normal monolithic web application into microservices structure using spring boot and spring cloud. I am actually trying to create Angular 2 front-end application and calls these my developed microservices in the cloud. And I am already started to break the modules into independent process's structure for microservice architecture.</p>&#xA;&#xA;<ul>&#xA;<li>Here my doubt is that , When designing the flow of control and microservice structure architecture, Can I use only one single spring boot project using different controller for this entire web application back end process.? Somewhere I found that when I am reading develop all microservices using 2 different spring boot project. Actually I am new to spring and spring cloud. I have lot of confusions in my task. Can any one help to clarify that is possible to create all services in single project by using different modules ???</li>&#xA;</ul>&#xA;"
47184194,common POM based plugins across multiple microservice projects,<maven><pom.xml><maven-plugin><microservices>,1,42,3,0.0,1,"<p>I am trying to figure out a way to import a set of common Maven plugins, across multiple microservice projects?</p>&#xA;&#xA;<p>Idea is to maintain a single place to manage all the common plugins - like jacoco, javadocs etc.</p>&#xA;&#xA;<p>We totally want to avoid the parent POM way of handling it.</p>&#xA;"
47309649,MicroService path /api/v1/ or /v1/api/,<java><microservices><grizzly>,1,51,4,0.0,1,"<p>I'm building a MicroSerive and I was planning to publish services using this URI naming convention:</p>&#xA;&#xA;<pre><code>https://host:port/api/v1/service1&#xA;https://host:port/api/v1/service2&#xA;https://host:port/api/v2/service1&#xA;https://host:port/api/v2/service2&#xA;</code></pre>&#xA;&#xA;<p>But I've also seen URIs named like this (ie vx and api 'swapped'):</p>&#xA;&#xA;<pre><code>https://host:port/v1/api/service1&#xA;https://host:port/v1/api/service2&#xA;https://host:port/v2/api/service1&#xA;https://host:port/v2/api/service2&#xA;</code></pre>&#xA;&#xA;<p>In my opinion, the first approach is better. Are there any reasons to go for the second approach?</p>&#xA;"
47860278,Best practice to share domain model between two microservices,<microservices>,1,376,3,0.0,1,"<p>Are there any best practices or guidelines on how to share the domain model between two micro-services?</p>&#xA;&#xA;<p>I have a micro-service (1) which provides end points to interact with a resource (e.g, Order) all CRUD and the other micro-service (2) which performs a specific non CRUD task on the resource (Order). The micro-service (2) almost needs all the order attributes to perform its operation. In this case, does it make sense to create a common shared lib of the domain model and share between the two services? I could technically combine 1 and 2 together but the micro-service (2) needs to support scalability as it is quite memory and CPU intensive.</p>&#xA;"
49606124,Neo4J In Microservices Architecture,<java><spring><neo4j><microservices><spring-data-neo4j-5>,4,176,0,0.0,1,"<p>To keep in line with DDD and Bounded Contexts, its well known that when you create your microservices you should keep separation of concerns.</p>&#xA;&#xA;<p>One of the main benefits of Neo4J is keeping your ""connected"" data in Neo4J so relationships between them are efficiently queried.</p>&#xA;&#xA;<p>These two opposing forces seem to make an microservice architecture decision difficult when choosing to use Neo4J.</p>&#xA;&#xA;<p>Do you have multiple microservices connect to Neo4J db and persist their own domain accordingly?</p>&#xA;&#xA;<p>OR</p>&#xA;&#xA;<p>Do you have one microservice with a db connection to Neo4J that controls persistance and querying?</p>&#xA;&#xA;<p>Both dont seem quite right...</p>&#xA;"
49637598,"Getting an error ""Cause: AMQ119031: Unable to validate user"" in Spring-Boot app",<spring-boot><microservices><spring-jms><jboss-eap-7><activemq-artemis>,1,167,3,0.0,1,"<p>I'm getting the following error when trying to connect to ActiveMQ Artemis Queue deployed on JBoss EAP 7.1. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: DefaultMessageListenerContainer: Could not refresh JMS&#xA;  Connection for destination 'jms/queue/QueueA' - retrying using&#xA;  FixedBackOff{interval=5000, currentAttempts=139,&#xA;  maxAttempts=unlimited}. Cause: AMQ119031: Unable to validate user</p>&#xA;</blockquote>&#xA;&#xA;<p>Here is the code I'm using:</p>&#xA;&#xA;<pre><code>@Bean public DefaultMessageListenerContainer myFactory() throws NamingException { &#xA;   DefaultMessageListenerContainer listenerContainer = new DefaultMessageListenerContainer();&#xA;   listenerContainer.setConnectionFactory(getConnectionFactory());&#xA;   listenerContainer.setDestinationName(""jms/queue/QueueA"");&#xA;   listenerContainer.setMessageListener(new MessageReceiver());&#xA;   return listenerContainer; &#xA;}&#xA;&#xA;private ConnectionFactory getConnectionFactory() throws NamingException { &#xA;   final Properties env = new Properties();&#xA;   env.put(Context.INITIAL_CONTEXT_FACTORY, org.wildfly.naming.client.WildFlyInitialContextFactory); &#xA;   env.put(Context.PROVIDER_URL, ""http-remoting://localhost:8080""); &#xA;   env.put(Context.SECURITY_PRINCIPAL, ""Username""); &#xA;   env.put(Context.SECURITY_CREDENTIALS, ""Password""); &#xA;   InitialContext ic = new InitialContext(env); &#xA;   return (ConnectionFactory) ic.lookup(""jms/RemoteConnectionFactory"");&#xA;}&#xA;</code></pre>&#xA;"
51520654,Distributed transactions in microservices,<microservices><distributed-transactions><saga>,3,55,0,0.0,1,"<p>I have 2 microservices <code>S1</code> and <code>S2</code>. <code>S1</code> invokes <code>S2</code> to update a data and then <code>S1</code> inserts another data,But let's consider <code>S1</code> fails,Then we need to rollback the data updated by <code>S2</code> or else we'll be in inconsistent state.</p>&#xA;&#xA;<p>I also gone through Saga patterns.will it satisfy this inconsistency</p>&#xA;&#xA;<p>Can anyone suggest any better solutions for this?</p>&#xA;"
51993175,org.springframework.web.client.ResourceAccessException: I/O error on GET request for in Microservices,<spring><spring-boot><microservices>,2,49,5,1.0,1,"<p>I am developing microservices code from the link : <a href=""https://github.com/sivaprasadreddy/spring-boot-microservices-series"" rel=""nofollow noreferrer"">https://github.com/sivaprasadreddy/spring-boot-microservices-series</a>. In this code base, I was successfully able to start the services like <code>""config-service""</code>, <code>""service-registry""</code>, <code>""shoppingcart-ui""</code>, <code>""zipkin-server""</code> etc, but when I tried to start the <code>""inventory-service""</code>, I got the below error. </p>&#xA;&#xA;<p><strong>Error below for reference:-</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8200/v1/secret/inventory-service"": Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8200 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:732) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:680) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:332) ~[spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.lambda$doRead$1(VaultTemplate.java:320) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doWithSession(VaultTemplate.java:307) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.doRead(VaultTemplate.java:317) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.VaultTemplate.read(VaultTemplate.java:212) ~[spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.doGetSecrets(SecretLeaseContainer.java:545) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.start(SecretLeaseContainer.java:357) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.lease.SecretLeaseContainer.addRequestedSecret(SecretLeaseContainer.java:316) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.loadProperties(LeaseAwareVaultPropertySource.java:147) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.vault.core.env.LeaseAwareVaultPropertySource.&lt;init&gt;(LeaseAwareVaultPropertySource.java:133) [spring-vault-core-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:151) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.LeasingVaultPropertySourceLocator.createVaultPropertySource(LeasingVaultPropertySourceLocator.java:88) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.doCreatePropertySources(VaultPropertySourceLocatorSupport.java:170) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.createCompositePropertySource(VaultPropertySourceLocatorSupport.java:145) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.vault.config.VaultPropertySourceLocatorSupport.locate(VaultPropertySourceLocatorSupport.java:116) [spring-cloud-vault-config-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:94) [spring-cloud-context-2.0.1.RELEASE.jar:2.0.1.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:636) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:376) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:328) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246) [spring-boot-2.0.4.RELEASE.jar:2.0.4.RELEASE]&#xA;    at com.sivalabs.inventoryservice.InventoryServiceApplication.main(InventoryServiceApplication.java:12) [classes/:na]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_162]&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;    at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_162]&#xA;</code></pre>&#xA;&#xA;<p><strong>I updated parent pom version to 2.0.4.RELEASE.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N574F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N574F.png"" alt=""enter image description here""></a></p>&#xA;"
48743223,Sharing domain model classes (Aggregates) across two microservices,<domain-driven-design><microservices>,1,138,3,0.0,1,"<p>Based on my limited knowledge, microservice can be designed at bounded context level or Aggregate level.</p>&#xA;&#xA;<p>If microservices are created at aggregate level, they might need to refer to an aggregate created in other microservices (as they share the same bounded context).</p>&#xA;&#xA;<p>Should we create the same aggregate multiple times in each microservice (if required)? Or there can never be a case, where we need to use one aggregate into other?</p>&#xA;"
48792602,Persistence layer as microservices?,<spring-boot><microservices><netflix-eureka>,3,251,3,0.0,1,"<p>I'm a beginner in microservice architecture and I have read in a lot of blog that in a microservice architecture, it is mandatory that each micro service has its own database. In my case it may cost very expensive. </p>&#xA;&#xA;<p>My question is, is it possible to make the persistence layer as micro service in itself ? Which would have the function of allowing other microservices to have read/write access to the database.&#xA;Thanks</p>&#xA;"
37897876,Vert.x how to pass/get messages from REST to message bus?,<java><rest><microservices><vert.x>,2,1175,0,0.0,1,"<p>I want to pass messages to bus via REST, and get it back. But I cant correctly setup the message bus receiver, it throws <code>java.lang.IllegalStateException</code>: Response has already been written. In real life message bus should receive messages from different sources and pass a message to another target. Therefore we just need to publish the message to the bus. But how to correctly read messages and handle all of them? For example from a REST interface: read that messages!&#xA;My simple app start:</p>&#xA;&#xA;<pre><code> public static void main(String[] args) {&#xA;        Vertx vertx = Vertx.vertx();&#xA;        vertx.deployVerticle(new RESTVerticle());&#xA;        vertx.deployVerticle(new Receiver());&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.registerDefaultCodec(MessageDTO.class, new CustomMessageCodec());&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>REST part</p>&#xA;&#xA;<pre><code>public class RESTVerticle extends AbstractVerticle {&#xA;&#xA;    private EventBus eventBus = null;&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        Router router = Router.router(vertx);&#xA;        eventBus = vertx.eventBus();&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.post(""/api/message"").handler(this::publishToEventBus);&#xA;       // router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9999);&#xA;        System.out.println(""Service running at 0.0.0.0:9999"");&#xA;&#xA;    }&#xA;&#xA;private void publishToEventBus(RoutingContext routingContext) {&#xA;        System.out.println(""routingContext.getBodyAsString() "" + routingContext.getBodyAsString());&#xA;        final MessageDTO message = Json.decodeValue(routingContext.getBodyAsString(),&#xA;                MessageDTO.class);&#xA;&#xA;        HttpServerResponse response = routingContext.response();&#xA;        response.setStatusCode(201)&#xA;                .putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                .end(Json.encodePrettily(message));&#xA;&#xA;        eventBus.publish(""messagesBus"", message);&#xA;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>And the Receiver: I move it to a different class, but it does not help</p>&#xA;&#xA;<pre><code>public class Receiver extends AbstractVerticle {&#xA;&#xA;    @Override&#xA;    public void start() throws Exception {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        Router router = Router.router(vertx);&#xA;&#xA;        router.route().handler(BodyHandler.create());&#xA;        router.route().handler(CorsHandler.create(""*"")&#xA;                .allowedMethod(HttpMethod.GET)&#xA;                .allowedHeader(""Content-Type""));&#xA;&#xA;        router.get(""/api/messagelist"").handler(this::getMessagesFromBus);&#xA;        router.route(""/*"").handler(StaticHandler.create());&#xA;&#xA;        vertx.createHttpServer().requestHandler(router::accept).listen(9998);&#xA;        System.out.println(""Service Receiver running at 0.0.0.0:9998"");&#xA;&#xA;private void getMessagesFromBus(RoutingContext routingContext) {&#xA;        EventBus eventBus = vertx.eventBus();&#xA;        eventBus.consumer(""messagesBus"", message -&gt; {&#xA;            MessageDTO customMessage = (MessageDTO) message.body();&#xA;            HttpServerResponse response = routingContext.response();&#xA;            System.out.println(""Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "" + customMessage);&#xA;            if (customMessage != null) {&#xA;                response.putHeader(""content-type"", ""application/json; charset=utf-8"")&#xA;                        .end(Json.encodePrettily(customMessage));&#xA;            }&#xA;            response.closed();&#xA;&#xA;        });&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So if i post message to REST and handler publish it to the bus, when I am runtime get <a href=""http://localhost:9998/api/messagelist"" rel=""nofollow"">http://localhost:9998/api/messagelist</a>  it is return json, but second time it trow exception</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Response has already been written&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.checkWritten(HttpServerResponseImpl.java:561)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:154)&#xA;    at io.vertx.core.http.impl.HttpServerResponseImpl.putHeader(HttpServerResponseImpl.java:52)&#xA;    at com.project.backend.Receiver.lambda$getMessagesFromBus$0(Receiver.java:55)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handleMessage(HandlerRegistration.java:207)&#xA;    at io.vertx.core.eventbus.impl.HandlerRegistration.handle(HandlerRegistration.java:201)&#xA;    at io.vertx.core.eventbus.impl.EventBusImpl.lambda$deliverToHandler$127(EventBusImpl.java:498)&#xA;    at io.vertx.core.impl.ContextImpl.lambda$wrapTask$18(ContextImpl.java:335)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:358)&#xA;    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)&#xA;    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112)&#xA;    at java.lang.Thread.run(Thread.java:745)&#xA;&#xA;Receiver -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Message{username=Aaaewfewf2d, message=41414wefwef2d2}&#xA;</code></pre>&#xA;&#xA;<p>How to correctly get all messages from the receiver? Or if the bus received messages, should I immediately store them to the db? Can a message bus keep messages and not lost them?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
37801454,Is there a way to implement SSO in front of the microservices?,<go><single-sign-on><cas><microservices><beego>,1,1127,5,1.0,1,"<p>Recently I have a project to implement <a href=""https://en.wikipedia.org/wiki/Single_sign-on"" rel=""nofollow noreferrer"">SSO(Single-Sign-On)</a> for multiple web applications based on <a href=""http://beego.me/"" rel=""nofollow noreferrer"">Beego Framework</a>. The most popular SSO project is <a href=""https://en.wikipedia.org/wiki/Central_Authentication_Service"" rel=""nofollow noreferrer"">CAS</a>, which needs a CAS Server in the center, and a CAS Client before each web application. Unfortunately, it seems that there's not any offical CAS clients written in Golang, except <a href=""https://github.com/go-cas/cas"" rel=""nofollow noreferrer"">go-cas/cas</a>, and <a href=""https://github.com/adanteng/cas"" rel=""nofollow noreferrer"">adanteng/cas</a>, which supports Beego.</p>&#xA;&#xA;<p>But the workflow of CAS is a little bit complicated: too many redirections, too many tickets transmitted among the CAS, web apps, and the user browser. I can't figure out why people deploy the Authentication Services in the center of all the web apps, rather than the front, like the following diagram:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/aqOmDm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aqOmDm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In this diagram, all the requests are forced to be processed in the Authenticate Service first, if authenticated successfully, then generate a session ID, saved in the cookies and Redis which is shared by other microservices. There's not any redirections or tickets at all, only requests transmittion.</p>&#xA;&#xA;<p>So is this diagram possible, or some critical problems I ignored?</p>&#xA;&#xA;<h1>Update 0</h1>&#xA;&#xA;<p>The session-sharing way is indeed not scalable and modular as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> counsels. How about transmitting user information, like name, email, etc., in the headers of requests between the auth service and downstream services, like the creative work of Heipei at <a href=""https://heipei.github.io/2015/09/23/nginx-sso-Simple-offline-SSO-for-nginx/"" rel=""nofollow noreferrer"">nginx-sso</a>? Is it possible to make it work as an SSO Gateway as Sam Newman sharing in the book <a href=""http://samnewman.io/books/building_microservices/"" rel=""nofollow noreferrer"">Building Microservices</a>?</p>&#xA;&#xA;<h1>Update 1</h1>&#xA;&#xA;<p>A more detailed diagram is shown as follows, in order to describe my childish idea a little bit clearly, hoping that there is not much misunderstanding from Heipei and Sam Newman. </p>&#xA;&#xA;<p>Rather than handling so many redirections and handshakes, all the requests are processed in the authentication service firstly, which writes user info from MySQL, into the Redis as the session provider, and the HTTP header to transmit to the downstream services, if the request is authenticated successfully.</p>&#xA;&#xA;<p>In this way, the user info is transmitted via HTTP header instead of the above shared-Redis as <a href=""https://stackoverflow.com/users/1357978/nadh"">Nadh</a> warning, and Redis can be depolyed with the auth service, or shared among auth instances only.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BeMFF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BeMFF.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<h1>Update 2</h1>&#xA;&#xA;<p>It seems that Cookie and Session are old-school techs. The cross-domain problem of cookie, and the sharing problem of session are the primary barrier to the scalability and flexibility of the modern web applications. Fortunately, JSON Web Token comes to be the best Single Sign-on solution for multiple lightweight services nowadays, by moving the user info(maybe id is enough) storage from the server side to the client side, and transmitted only if necessary.</p>&#xA;"
40737349,Right place to do the service composition in API world?,<microservices><aws-api-gateway><apigee><kong>,3,515,0,0.0,1,"<p>I am working in an environment where API is becoming a by default standard and we have a lot of micro services available... but still not able to meet the requirement of my customers...</p>&#xA;&#xA;<p>My customer demands a mix and match of data which I need to offer by writing new compositions and further host them as services.... </p>&#xA;&#xA;<p>1) What is the right platform to do this composition, gateways or host them on a dedicated paas instances?</p>&#xA;&#xA;<p>2) The moment I start going for composition, I end up paying for http overhead compared to get data directly from database</p>&#xA;&#xA;<p>Any help will be helpful</p>&#xA;"
42539505,How to get sorted data from one service to another over http,<microservices><api-design>,2,313,6,1.0,1,"<p>I have service oriented architecture with couple services.</p>&#xA;&#xA;<ul>&#xA;<li><p>Product  - store list of products</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   price: number&#xA;}</code></p></li>&#xA;<li><p>Categories   - store category information + the list of product ids</p>&#xA;&#xA;<p><code>{&#xA;   id: number,&#xA;   parentCategory: number,&#xA;   productIds: number[]&#xA; }</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Lets assume that I have such category instance</p>&#xA;&#xA;<pre><code>{&#xA;   id: 1,&#xA;   parentCategory: null,&#xA;   productIds: [1, 3, 4, 5, ....]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I need to get 10 products from the category above sorted by product price. </p>&#xA;&#xA;<p>Category service processes that request and because it doesn't know anything about the price it has to make the request to Product service like that: </p>&#xA;&#xA;<pre><code>/api/products?&#xA;   ids=&lt;list of all product ids&gt;&#xA;   limit=10&#xA;   sortBy=price&#xA;</code></pre>&#xA;&#xA;<p>which won't work well when the category has a lot of products.</p>&#xA;&#xA;<p>What is the recipe in such case? &#xA;Thanks.</p>&#xA;"
45661006,What is the difference between Monolith and n Layer?,<architecture><microservices>,1,972,0,1.0,1,"<p>i have a few questions regarding <strong>monolith</strong> and <strong>n layer architecture</strong>.</p>&#xA;&#xA;<p>First, whats the difference between Monolith and n Layer architecture?</p>&#xA;&#xA;<p>Second, let's say I have a single Visual Studio solutions that consist of multiple projects such as:</p>&#xA;&#xA;<ol>&#xA;<li>Presentation Layer</li>&#xA;<li>Service Layer</li>&#xA;<li>Business Layer</li>&#xA;<li>Cross Layer</li>&#xA;<li>Data Layer</li>&#xA;<li>Unit Test</li>&#xA;</ol>&#xA;&#xA;<p>Is that considered as Monolith or n layer architecture?</p>&#xA;&#xA;<p>If I have microservices that consist (let's say) 3 Web API and I build each service in single separate Visual Studio solutions, <strong><em>it is ok</em></strong> to implement my previous project structure (service layer, business layer, data layer, etc)?</p>&#xA;&#xA;<p>Thank you very much and sorry for my bad english.</p>&#xA;"
45642575,microservices or SOA: how to respond one specific request,<architecture><soa><microservices>,2,137,5,0.0,1,"<p>I am interested in microservices and SOA. I read some tutorials. This is my understanding SOA. The API gateway receives lots of requests (requestA, requestB, ...) and put requests in messaging queues. Micro-services will consume the events in the messaging queues and do some processing. My question is after processing, how the response can be returned to requests (responseA to requestA, responseB to requestB).</p>&#xA;&#xA;<p>I am not sure whether my understanding is right or wrong and whether messaging is used in every architecture. </p>&#xA;&#xA;<p>Anyone can give me more details/examples how to decouple/connect the API gateways and the microservices. How to respond to requests? should the connection between API gateways and clients kept alive?</p>&#xA;&#xA;<p>Sorry if my question is not clear. I am confused and have no idea how to understand each concept.</p>&#xA;&#xA;<p>Any comment welcomed. Thanks</p>&#xA;"
50889657,Microservice synchronous communication - service to service or message broker,<spring><spring-boot><apache-kafka><microservices>,2,53,0,2.0,1,"<p>I am developing a series of microservices using Spring Boot and Kafka. For asynchronous communication, I am using Kafka which is working well. </p>&#xA;&#xA;<p>I have a use case where I require synchronous communication between two microservices (a user registers a profile via the user profile service which needs to create an auth account in the auth microservice). </p>&#xA;&#xA;<p>Should I just call the auth service directly (service to service communication) or should I use Kafka?</p>&#xA;&#xA;<p>Any examples or best practise advice would be appreciated. </p>&#xA;"
50849415,What is the best way to do microservice REST API versioning?,<spring><rest><microservices><aws-api-gateway><api-versioning>,1,233,3,0.0,1,"<p>I'm developing this project using Spring and hosting in AWS EC2 instances. As few new requirements coming up, I have to change  my API contracts. But I don't want to break the current clients. So, I'm trying to implement some REST APIs with versioning. So that whenever I update the endpoints the consumer applications won't crash. But I'm confused on how to do the API versioning. I thought of two ways. </p>&#xA;&#xA;<ol>&#xA;<li><p>Create a next version endpoint in the same server,(in spring using RequestMaping(""/v1/api1""),RequestMaping(""/v2/api1"") something like this.)</p></li>&#xA;<li><p>Other wise completely run the v2 APIs in new server instance but keep the same API endpoint footprint and use AWS APIGateway as a proxy and configure the versioning there, then route to old server and new server depending on the version number in the request.</p></li>&#xA;</ol>&#xA;&#xA;<p>But the first approach will lead to lot of code duplication and code management messy I believe. Because we are keeping the same functionality with variations.</p>&#xA;&#xA;<p>In the second approach I have to keep two set of instances for bot versions if me Version increases then It's hard to manage those instances, specially, when I will have around 15 micro-service instances. And it'll not be cost effective also. Because my company is a startup , so I need to consider this fact also.</p>&#xA;&#xA;<p>Is there any best practices regarding API versioning and managing multiple version of endpoints? I'm open for any suggestions and guidelines. If multiple server is the solution also, I'm open to reconsider the cost limitations. I need the best solution for this problem. </p>&#xA;"
28114758,Microservices with spring integration and spring boot,<spring-boot><spring-integration><microservices>,2,2113,0,1.0,2,<p>I'm a bit new with microservices (and SI) and want to make a POC following a microservices architecture style. I've seen that I can use Spring Boot for deployment and SI for the development but found little docs about how to combine them (just an example in Spring Boot home page). Do you know about best practices or recommendations on how to combine this two technologies? </p>&#xA;
30449278,Automation of releases of microservices-based application,<git><automation><release-management><salt-stack><microservices>,4,894,0,0.0,2,"<p>We are working on the application that consists of many standalone services. It has advantages over the single monolithic application, but not when we do releases.</p>&#xA;&#xA;<p>We do weekly release cycles. Each service/component located in the separate git repository. 'A release' - is several features that we put into wild. Usually only several components should be updated. We manage servers using saltstack. To make a release salt scripts update component's versions using git.latest state. The problem is to specify right versions.</p>&#xA;&#xA;<p>This is where the manual work that I'd like to automate. To update versions I have to manually check each component's repository, merge development branch into master and tag according to symantec versioning rules. Then I write new version in salt scripts. We have over 10 components so this is rather boring and error prone process.</p>&#xA;&#xA;<p>Probably we doing it wrong, I'll be glad to hear any advices how to do it better, thanks.</p>&#xA;"
31525237,how to get scope associated with access token in Spring OAuth while building microservices?,<spring><spring-security><oauth-2.0><microservices>,1,733,0,0.0,2,"<p>I am in the process of spinning up a <code>microservices</code> system with a central <code>Authorization Server</code> that grants <code>tokens</code> with different scopes for accessing individual micro-service.</p>&#xA;&#xA;<p>Here is the picture explaining the various service calls.&#xA;The numbers marked are requests made in the chronological order.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/8R9CP.png"" alt=""enter image description here""></p>&#xA;&#xA;<p><strong>1)</strong> In a nut-shell, I want the auth Server to return <code>access-token</code> with a User identifer (id) and scope when controller makes a login call. just like the following example taken from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/#_sso_with_oauth2_angular_js_and_spring_security_part_v"" rel=""nofollow noreferrer"">spring tutorial</a> (but this is missing id). how can I have the id retured with the token returned?. I prefer not to make another REST call as proposed in the tutorial.</p>&#xA;&#xA;<pre><code>$ curl acme:acmesecret@localhost:9999/uaa/oauth/token  \&#xA;-d grant_type=authorization_code -d client_id=acme     \&#xA;-d redirect_uri=http://example.com -d code=jYWioI&#xA;{""access_token"":""2219199c-966e-4466-8b7e-12bb9038c9bb"",""token_type"":""bearer"",""refresh_token"":""d193caf4-5643-4988-9a4a-1c03c9d657aa"",""expires_in"":43199,""scope"":""openid""}&#xA;</code></pre>&#xA;&#xA;<p><strong>2)</strong> How does the photo Service which receives the access token in the ""Authorization bearer"" header checks with Auth Server to see the token is valid and it has the scope required to access the photo. (for example, if Auth Server responds back with list of scopes this token is eligible for, Post service can check among the list of scopes, if it can provide access).</p>&#xA;&#xA;<p><strong>3)</strong> on a side note, I see the <code>-d code=jYWioI</code> is passed in above the request, but not sure why it is passed and whats the purpose of it?</p>&#xA;"
30732982,What's the correct way to embed a remote AngularJS application into a webpage?,<javascript><php><angularjs><html5><microservices>,1,695,2,0.0,2,"<p>I'm trying to work out the correct way to embed an AngularJS application into another web page (served by another app). I have two apps, running on different servers:</p>&#xA;&#xA;<p>App 1 - PHP app</p>&#xA;&#xA;<p>App 2 - AngularJS app (calendar widget of sorts)</p>&#xA;&#xA;<p>The PHP app is the primary app, into which I want to embed the calendar, which is served from a remote server. I have full access to both servers, and to both apps. The idea is that I want to be able to re-use the Angular app elsewhere, so it needs to be as loosely coupled as possible to the PHP app, preferably embedded in a single line of code. </p>&#xA;&#xA;<p>I am currently using a HTML5  tag, which seems to work well, but I was wondering if there's anything wrong with this approach, or if there's a better means of doing what I'm after.</p>&#xA;&#xA;<p>I should mention that I'm happy to use a HTML5-only solution, I'm no worried about backwards compatibility with older browsers.</p>&#xA;&#xA;<p>No iFrame solutions, unless there's a REALLY valid solution. My ultimate goal is to head towards a microservice-style architecture.</p>&#xA;&#xA;<p>Thanks in advance for your help.</p>&#xA;"
44305351,Send data in Request body using HttpURLConnection,<java><web-services><httpurlconnection><microservices><spark-java>,2,6350,0,1.0,2,"<p>I am using <code>HttpURLConnection</code> to make a POST request to a local service deployed in my local created using JAVA Spark.<strong>I want to send some data in request body when I make the POST call using the HttpURLConnection but every time the request body in JAVA Spark is null</strong>. Below is the code I am using for this</p>&#xA;&#xA;<h3>Java Spark POST Service Handler</h3>&#xA;&#xA;<p><code>post(""/"", (req, res) -&gt; {&#xA;        System.out.println(""Request Body: "" + req.body());&#xA;        return ""Hello!!!!"";&#xA;  });</code></p>&#xA;&#xA;<h3>HTTPClass Making the post call</h3>&#xA;&#xA;<pre><code>`public class HTTPClassExample{&#xA;   public static void main(String[] args) {&#xA;        try{&#xA;            URL url = new URL(""http://localhost:4567/"");&#xA;            HttpURLConnection httpCon = (HttpURLConnection) url.openConnection();&#xA;            httpCon.setDoOutput(true);&#xA;            httpCon.setRequestMethod(""POST"");&#xA;            httpCon.connect();&#xA;            OutputStream os = httpCon.getOutputStream();&#xA;            OutputStreamWriter osw = new OutputStreamWriter(os, ""UTF-8"");    &#xA;            osw.write(""Just Some Text"");&#xA;            System.out.println(httpCon.getResponseCode());&#xA;            System.out.println(httpCon.getResponseMessage());&#xA;            osw.flush();&#xA;            osw.close();  &#xA;        }catch(Exception ex){&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}`&#xA;</code></pre>&#xA;"
36582126,How Lagom services consume other services?,<microservices><service-discovery><lagom>,1,1048,2,1.0,2,"<p>I cant think in three cases.</p>&#xA;&#xA;<ol>&#xA;<li>Lagom service consumes another Lagom service in the same cluster</li>&#xA;<li>Lagom service consumes another Lagom service in a different cluster</li>&#xA;<li>Lagom service consumes an external non-Lagom service</li>&#xA;<li>An external non-Lagom service consumes a Lagom service</li>&#xA;</ol>&#xA;&#xA;<p><strong>1. Lagom service consumes another Lagom service in the same cluster</strong></p>&#xA;&#xA;<p>For this case the approach is that ServiceAImpl depends on the ServiceB API, wich is binded to a concrete implementation that will be injected to ServiceAImpl.</p>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Binding-a-service-client"" rel=""nofollow"">ServiceB binding:</a></p>&#xA;&#xA;<pre><code>import com.google.inject.AbstractModule;&#xA;import com.lightbend.lagom.javadsl.server.ServiceGuiceSupport;&#xA;import docs.services.HelloService;&#xA;&#xA;public class Module extends AbstractModule implements ServiceGuiceSupport {&#xA;&#xA;    protected void configure() {&#xA;        bindClient(HelloService.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Using-a-service-client"" rel=""nofollow"">ServiceA implementation:</a></p>&#xA;&#xA;<pre><code>public class MyServiceImpl implements MyService {&#xA;  private final HelloService helloService;&#xA;&#xA;  @Inject&#xA;  public MyServiceImpl(HelloService helloService) {&#xA;    this.helloService = helloService;&#xA;  }&#xA;&#xA;  @Override&#xA;  public ServiceCall&lt;NotUsed, NotUsed, String&gt; sayHelloLagom() {&#xA;    return (id, msg) -&gt; {&#xA;      CompletionStage&lt;String&gt; response = helloService.sayHello().invoke(""Lagom"");&#xA;      return response.thenApply(answer -&gt;&#xA;          ""Hello service said: "" + answer&#xA;      );&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I understand it correctly, in order to consume the service API in this way, both clients must be in the same cluster.&#xA;However Lagom <a href=""http://www.lagomframework.com/documentation/1.0.x/Cluster.html#Cluster-composition"" rel=""nofollow"">says</a> that</p>&#xA;&#xA;<blockquote>&#xA;  <p>A cluster should only span nodes that are running the same service.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this case we have two different types of services. </p>&#xA;&#xA;<ul>&#xA;<li>""The same service"" means a top level service whose API is exposed to external services?</li>&#xA;<li>In Lagom 1 Microservice = 1 service with external API + n internal services?</li>&#xA;</ul>&#xA;&#xA;<p><strong>2. Lagom service consumes another Lagom service in a different cluster</strong></p>&#xA;&#xA;<p>The documentation <a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceLocator.html#Integrating-with-external-Lagom-projects"" rel=""nofollow"">says</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Note that if the service you want to communicate with is actually a Lagom service, you may want to read the documentation for <a href=""http://www.lagomframework.com/documentation/1.0.x/MultipleBuilds.html"" rel=""nofollow"">integrating with an external Lagom projects</a>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Why is only configured the dependency to the service API and not the IP and port of the external Lagom service also?</p>&#xA;&#xA;<p><strong>3. Lagom service consumes an external non-Lagom service</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>The first thing you will have to do is to register each external&#xA;  service in the Service Locator. Assume we want to register an external&#xA;  service named weather that is running on <a href=""http://localhost:3333"" rel=""nofollow"">http://localhost:3333</a>, here&#xA;  is what we would add to the build:</p>&#xA;&#xA;<pre><code> lagomUnmanagedServices in ThisBuild := Map(""weather"" -&gt; ""http://localhost:3333"")&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>What is the contract with that IP? What should be behind it?</p>&#xA;&#xA;<p><strong>4. An external non-Lagom service consumes a Lagom service</strong></p>&#xA;&#xA;<p>I have to use the <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow"">Third-Party Registration Pattern</a> until Lagom support the <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow"">self registration pattern</a>?</p>&#xA;"
48961000,Why shared libraries between microservices are bad?,<interface><architecture><shared-libraries><microservices><distributed-computing>,1,967,0,0.0,2,"<p>Sam Newman states in his book <em>Building Microservices</em></p>&#xA;&#xA;<blockquote>&#xA;  <p>The evils of too much coupling between services are far worse than the problems caused by code duplication</p>&#xA;</blockquote>&#xA;&#xA;<p>I just don't understand how the shared code between the services is evil. Does the author mean the <em>service boundaries themselves</em> are poorly designed if a need for a shared library emerges, or does he really mean I should duplicate the code in the case of common business logic dependency? I don't see what that solves.</p>&#xA;&#xA;<p>Let's say I have a shared library of entities common to two services. The common domain objects for two services may smell, but another service is the GUI to tweak the state of those entities, another is an interface for other services to poll the state for their purpose. Same domain, different function.</p>&#xA;&#xA;<p>Now, if the shared knowledge changes, I would have to rebuild and deploy both services regardless of the common code being an external dependency or duplicated across the services. Generally, same concerns all the cases for two services depending of the same article of the business logic. In this case, I see only harm of duplication of the code, reducing the cohesion of the system.</p>&#xA;&#xA;<p>Of course, <em>diverging</em> from the shared knowledge may cause headaches in the case of shared library, but even this could be solved with inheritance, composition and clever use of abstractions.</p>&#xA;&#xA;<p>So, what does Sam mean by saying code duplication is better than too much coupling via shared libraries? </p>&#xA;"
28387907,Push Data onto Queue vs Pull Data by Workers,<message-queue><soa><microservices>,2,801,0,0.0,2,"<p>I am building a web site backend that involves a client submitting a request to perform some expensive (in time) operation. The expensive operation also involves gathering some set of information for it to complete.</p>&#xA;&#xA;<p>The work that the client submits can be fully described by a <code>uuid</code>. I am hoping to use a service oriented architecture (SOA) (i.e. multiple micro-services).</p>&#xA;&#xA;<p>The client communicates with the backend using RESTful communication over HTTP. I plan to use a queue that the workers performing the expensive operation can poll for work. The queue has persistence and offers decent reliability semantics.</p>&#xA;&#xA;<p>One consideration is whether I gather all of the data needed for the expensive operation upstream and then enqueue all of that data or whether I just enqueue the <code>uuid</code> and let the worker fetch the data.</p>&#xA;&#xA;<p>Here are diagrams of the two architectures under consideration:</p>&#xA;&#xA;<p><strong>Push-based (i.e. gather data upstream):</strong>&#xA;<img src=""https://i.stack.imgur.com/rxZQe.png"" alt=""Push-based (i.e. gather data upstream)""></p>&#xA;&#xA;<p><strong>Pull-based (i.e. worker gathers the data):</strong>&#xA;<img src=""https://i.stack.imgur.com/R9aJN.png"" alt=""Pull-based (i.e. worker gathers the data)""></p>&#xA;&#xA;<p>Some things that I have thought of:</p>&#xA;&#xA;<ol>&#xA;<li>In the push-based case, I would be likely be blocking while I gathered the needed data so the client's HTTP request would not be responded to until the data is gathered and then enqueued. From a UI standpoint, the request would be pending until the response comes back.</li>&#xA;<li>In the pull based scenario, only the worker needs to know what data is required for the work. That means I can have multiple types of clients talking to various backends. If the data needs change I update just the workers and not each of the upstream services.</li>&#xA;</ol>&#xA;&#xA;<p>Any thing else that I am missing here?</p>&#xA;"
27839789,How do I change these producer-consumer microservices to allow parallel processing?,<ruby-on-rails><ruby><multithreading><parallel-processing><microservices>,3,429,2,0.0,2,"<p>I've got a couple microservices (implemented in ruby, although I doubt that is important for my question). One of them provides items, and the other one processes them, and then marks them as processed (via a DELETE call)</p>&#xA;&#xA;<p>The provider has an <code>/items</code> endpoint which lists a bunch of items identified with an id, in JSON format. It also has a <code>DELETE /items/id</code> endpoint which removes one item from the list (presumably because it is processed)</p>&#xA;&#xA;<p>The code (very simplified) in the ""processor"" looks like this:</p>&#xA;&#xA;<pre><code>items = &lt;GET provider/items&gt;&#xA;items.each do |item|&#xA;  process item&#xA;  &lt;DELETE provider/items/#{item.id}&gt;&#xA;end&#xA;</code></pre>&#xA;&#xA;<p>This has several problems, but the one I would like to solve is that it is not thread-safe, and thus I can't run it in parallel. If two workers start processing items simultaneously, they will ""step onto each other's toes"": they will get the same list of items, and then (try to) process and delete each item twice.</p>&#xA;&#xA;<p>What is the simplest way I can change this setup to allow for parallel processing?</p>&#xA;&#xA;<p>You can assume that I have ruby available. I would prefer keeping changes to a minimum, and would rather not install other gems if possible. <a href=""http://sidekiq.org/"" rel=""nofollow"">Sidekiq</a> is available as a queuing system on the consumer.</p>&#xA;"
32887039,How to implement HATEOAS in a Spring-Boot microservices project,<java><spring><rest><microservices><spring-hateoas>,1,488,5,0.0,2,"<p>Lately I've been experimenting with building <strong>microservices</strong> using the Java <strong>Spring Boot</strong> framework. I currently have a working Microservices systeem with several resources (which all have its own independent service), e.g.: A Book service and a Review service.&#xA;Each service has its own <strong>RestController</strong> and uses a <strong>MongoRepository</strong> to interact with its database.</p>&#xA;&#xA;<p>The end-users of the application (web-clients) will not communicate with these independent services itself but with an API above them.</p>&#xA;&#xA;<p>This API calls the book and review services, merges the data and returns it back to the client. Note that all the communication is using <code>ResponseEntity&lt;T&gt;</code> (<code>T</code> can be <code>Book</code>, <code>Review</code>, <code>Iterable&lt;Book&gt;</code>, etc, ..)</p>&#xA;&#xA;<p>But after reading a while I learnt about <strong>HATEOAS</strong> and I would like to use it in my microservices set-up. Now my question is, what is the best way to implement this?</p>&#xA;&#xA;<p>Some examples I've found extend the entity classes (which in my case would be the Book entity or the Review entity with Spring's <code>ResourceSupport</code> class). But this causes errors since my entity's have an ID parameter and the <code>getId()</code> method clashes with the <code>getId()</code> method of the ResourceSupport class. </p>&#xA;&#xA;<p>Other examples contain a <code>MongoRepository</code> annotated with <code>@RestResource</code> instead of using a <strong>Controller</strong>.</p>&#xA;&#xA;<p>So my question is, what would in this case be the best way to implement HATEOAS? And e.g. when the Book service adds links (the HATEOAS way), how can the API above change these links? Since the end-users will only do calls to this API and the API just processes these requests and delegates it to the necesarry sub-services.</p>&#xA;"
38964840,Text search for microservice architectures,<elasticsearch><architecture><microservices>,1,1133,0,1.0,2,"<p>I am investigating into implementing text search on a microservice based system. We will have to search for data that span across more than one microservice. </p>&#xA;&#xA;<p>E.g. say we have two services for managing Organisations and managing Contacts. We should be able to search for organisations by contact details in one search operation.</p>&#xA;&#xA;<p>Our preferred search solution is Elasticsearch. We already have a working solution based on embedded objects (and/or parent-child) where when a parent domain is updated the indexing payload is enriched with the dependent object data, which is held in a cache (we avoid making calls to the service managing child directly for this purpose). </p>&#xA;&#xA;<p>I am wondering if there is a better solution. Is there a microservice pattern applicable to such scenarios?</p>&#xA;"
39134238,Client authentication in microservices using JWT and OpenID Connect,<api><authentication><jwt><microservices>,1,994,0,1.0,2,"<p>I've some questions regarding authentication in a microservices architecture. I've right now a monolithic application and my goal is to split the application in small microservices.</p>&#xA;&#xA;<p>My bigest problem is for authentication (for now). After reading a LOT a documentation, It seems that the best solution is to use OpenID Connect to authenticate an user to retrieve a JWT that can by passed with the request to the microservices. </p>&#xA;&#xA;<p>Also, to avoid having multiple endpoints, you can deploy and API Gateway to have only one endpoint for the end user. Ok, so now I've two questions with this architecture.</p>&#xA;&#xA;<p>The standard flow for authentication will be :</p>&#xA;&#xA;<p>An user contact my identity server in OpenID Connect with the implicit flow and get the id_token (JWT) and also the access_token. The user can now contact my API with this access_token. The API Gateway will valide the access_token with the identity server and also retrieve the JWT to add it to the sub request to the microservice API. </p>&#xA;&#xA;<p>1/ How the API Gateway can get the JWT from the access_token? From what I red from the documentation (<a href=""http://openid.net/specs/openid-connect-core-1_0.html"" rel=""nofollow"">http://openid.net/specs/openid-connect-core-1_0.html</a>), It can contact the ""/userinfo"" endpoint but It will get just the JSON format not the JWT...</p>&#xA;&#xA;<p>2/ I want to allow authenticated calls between my microservices. So each microservice needs to be able to generate a JWT to contact other microservices directly. My first thought was to contact the identity server. But with the OAuth2 Client Credentials flow, I don't retrieve a id_token or a JWT. Just a classic OAuth2 access token without JWT. My second thought was that the microservice can directly sign its own JWT with a certificate issued by the same PKI as the one used by the identity server. That mean that a JWT can be sign by several certificats but from the same private PKI. When a microservice receives a JWT, It needs to be able to identify witch certificat was used to sign the JWT. I don't find anything on the RFC regarding this problem. I can add my own private claim in the token to have the certificate but after several days of browsing the web without seeing this kind of solution, I'm wondering if I'm not on the wrong path... To sum up, how can i perfom ""User to service"" authentication AND alors ""service to service"" authentication in JWT?</p>&#xA;&#xA;<p>Thank you very much!</p>&#xA;"
35632607,Is the HTTP method PURGE idempotent in Varnish?,<rabbitmq><varnish><microservices><http-method><purge>,2,614,0,0.0,2,<p>Is the HTTP verb PURGE idempotent? &#xA;If I send the same PURGE request twice will I receive 200 the second time?</p>&#xA;&#xA;<p>I have a microservice that invalidates a Varnish cache before publishing a message into a rabbit queue. In case of purge failure our need is to just log and continue the execution.</p>&#xA;&#xA;<p>The queue consumer has to get the latest status of the resource from the Varnish cache.&#xA;Will a new purge request (before actually requesting the resource from varnish) from the second microservice return success in case the first purge from the first microservice succeeded?</p>&#xA;
39388560,OpenID Connect ID Token: What's the purpose of audience [aud] field validation,<security><microservices><openid-connect>,1,573,0,0.0,2,"<p>I'm trying to implement <a href=""http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth"" rel=""nofollow"">OpenID Connect Implicit Flow</a>. The frontend Single Page App passes the ID Token down to the backend server (using Authorization header) where I need to validate it.</p>&#xA;&#xA;<p>The documentation requires me <a href=""http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation"" rel=""nofollow"">to check</a> that I trust the audience of the token (aud &amp; azp fields). I'm struggling to understand the significance of this validation step and what are the security implications of not doing so. Why should I distrust the token if I'm not the intended recipient?</p>&#xA;&#xA;<p>My reasoning is that if I trust the issuer it doesn't matter who was the token issued for. I would expect the claims to be the same for any clientId (is this wrong?). Ideally when I pass the ID Token around my microservices all they should know is what issuers to trust (and use <a href=""https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig"" rel=""nofollow"">discovery protocol</a> for figuring out the keys).</p>&#xA;&#xA;<p>What is the attack vector if I skip this validation step?</p>&#xA;"
29434226,Generating JPA entities in microservices design,<java-ee><jpa><microservices>,1,343,5,0.0,2,"<p>I am thinking of design and bit confused with generating entities in a microservices architecture (though I am new to microservices design, but I am fascinated with multiple lean war's). I have DB and multiple war's in mind. Should I generate the entities from DB and place them in a jar, and include the jar in every war i create, OR there is another option. Secondly where I place persistence.xml. And if i plan to use cache later to cache entity instances, will above approach pose any issues. Thanks</p>&#xA;"
45111662,Microservices with common users table,<architecture><soa><microservices>,3,244,0,1.0,2,<p>Is it possible to design a microservice based  architecture on which each microservice have separate independent database and a common users table?</p>&#xA;
45007694,Microservices - Database compatibility in between old and new versions,<database><rest><architecture><microservices>,1,175,3,1.0,2,"<p>I am trying to dive into Microservice architecture to start coding some of small pieces of logic for my company.</p>&#xA;&#xA;<p>I know one of microservices concerns is about the database handling (each microservice must have its separated db schmema). So I am looking for pieces of advice or experiences about to move out from an old to new microservice version.</p>&#xA;&#xA;<p>So lets say I have a REST API endpoint <code>ms/v1/whatEver</code> which is running today on prod. After a week we decide to go live with the next version of it. So that we create a <code>ms/v2/whatEver</code> which has some new columns and data types in the entities envolved in this service. Thus in order to not force all clients to migrate immediately we want to keep both versions up and running till users move in progressively to <code>v2</code>.</p>&#xA;&#xA;<p>A couple of scenarios come up in to my mind if we have both version up and running (which actually is my main doubt and the reason of this post):</p>&#xA;&#xA;<ol>&#xA;<li><p>Should they read/write in the same DB instance, hence <code>v1</code> implementation must be adapted to match with the new schema structure of <code>v2</code>?</p></li>&#xA;<li><p>Should they read/write in a separate DB instance. So in any manner both DBs have to be synchronised till the day we decide to turn off <code>v1</code> to guarantee we do not miss any data (eventual consistency)? So my question here is how to accomplish that (throughout framework, queue messaging, or something..)</p></li>&#xA;<li><p>Or, code forwarding every <code>v1</code> request (inside of it) to <code>v2</code> which is going to be the owner of the already migrated new schema (unique DB instance)?</p></li>&#xA;</ol>&#xA;&#xA;<p>I have been reading a couple of books like <a href=""https://developers.redhat.com/promotions/migrating-to-microservice-databases/"" rel=""nofollow noreferrer"">Migrating to Microservices Databases - Red Hat</a> but they are written in concept terms but nothing specific with technologies or best things to do whit this. So that my post. </p>&#xA;&#xA;<p>I really appreciate your opinions.&#xA;Thanks</p>&#xA;"
38049334,Manage multiple dependencies between microservices using Maven,<maven><dependencies><release><microservices>,1,760,0,0.0,2,<p>We are using Maven to define and manage our dependencies between our microservices. Here is an example:</p>&#xA;&#xA;<p><strong>Microservice 1</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-1&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.04-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>Microservice 2</strong></p>&#xA;&#xA;<pre><code>&lt;artifactId&gt;ms-2&lt;/artifactId&gt;&#xA;&lt;version&gt;0.25.00-SNAPSHOT&lt;/version&gt;&#xA;&lt;dependencies&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;artifactId&gt;ms-3&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.28.00-SNAPSHOT&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;&lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>The problem is that the release phase is taking a lot of time and is fully manual:</p>&#xA;&#xA;<ol>&#xA;<li>perform <code>mvn:release</code> for the first microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>change the version in <code>pom.xml</code> of the dependency</li>&#xA;<li>perform <code>mvn:release</code> for the second microservice (removes <code>-SNAPSHOT</code>)</li>&#xA;<li>and so on (actually on 15 microservices...)</li>&#xA;</ol>&#xA;&#xA;<p>I'm wondering if there is any automatized way to perform this release (in cascade)? </p>&#xA;&#xA;<p>Thanks</p>&#xA;
34790550,Threading configuration for microservices written in java/jersey/grizzly,<java><multithreading><jersey><grizzly><microservices>,1,574,7,1.0,2,"<p>I am designing a micro-services based system. Most of the services are deployed as standalone Jersey processes with an embedded Grizzly web server.</p>&#xA;&#xA;<p>Assuming that many of those services will execute on the same machine, shall I change any threading configuration in Grizzly to prevent a situation of too many threads machine-wide?</p>&#xA;&#xA;<p>What is the default threading model for Grizzly? Is there a limit for number of threads that a single web server can create?</p>&#xA;"
39561186,Best practice for loading multiple dynamic services and them dependencies services,<c#><multithreading><reflection><microservices>,2,58,5,0.0,2,"<p>I want to devlop a custom system for my self.</p>&#xA;&#xA;<p>I want to loading custom services by configuratin with dependency services - for example:</p>&#xA;&#xA;<pre><code>&lt;Services&gt;&#xA;    &lt;Service name=""ServiceA"" args="""" type=""CommonLib.IServiceA"" dependencies=""""/&gt;&#xA;    &lt;Service name=""ServiceB"" args="""" type=""CommonLib.IServiceB"" dependencies=""ServiceA""/&gt;&#xA;    &lt;Service name=""ServiceC"" args="""" type=""CommonLib.IServiceC"" dependencies=""ServiceA,ServiceB""/&gt;&#xA;    &lt;Service name=""ServiceD"" args="""" type=""CommonLib.IServiceD"" dependencies=""ServiceA,ServiceB,ServiceC""/&gt;&#xA;    &lt;Service name=""ServiceE"" args="""" type=""CommonLib.IServiceE"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD""/&gt;&#xA;    &lt;Service name=""ServiceF"" args="""" type=""CommonLib.IServiceF"" dependencies=""ServiceA,ServiceB,ServiceC,ServiceD,ServiceE""/&gt;&#xA;&lt;/Services&gt;&#xA;</code></pre>&#xA;&#xA;<p>All those services are implement custom interface:</p>&#xA;&#xA;<pre><code>public interface IService&#xA;{&#xA;    bool Start();&#xA;    bool Stop();&#xA;    bool IsReady {get;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>What the best practice for loading dynamic services toghether but depends on those dependencies?</p>&#xA;&#xA;<p>Loop every service and postpone till those dependencies are loaded and ready?</p>&#xA;&#xA;<p>Have any tutorial for that?</p>&#xA;"
39888480,Where to get the vertx dashboard monitor?,<java><microservices><vert.x>,1,553,0,0.0,2,"<p>I have seen a couple of times on vertx website a vertx dashboard monitor, that looks like:    </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FrR9F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FrR9F.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>How to setup the dashboard or how to get it?  </p>&#xA;"
40081965,Where lookup tables should be placed in a microservices architecture?,<microservices><lookup-tables>,1,268,3,1.0,2,"<p>In a microservices architecture, each microservice has its own database and tables should not be duplicated in different databases.&#xA;But there are tables, like lookup tables (called also reference tables), that are needed by multiple microservices.&#xA;Should we put lookup tables in each microservice database, or is it better to create a new microservice with a database holding all the lookup tables ?</p>&#xA;"
40296598,Micro-services approach: Isolation and decoupling,<design><architecture><microservices>,1,163,3,0.0,2,"<p>I've to add a service to my Micro-services architecture and&#xA;my new services needs to compute data he's responsable of. These computations occurs at a relatively high frequency.</p>&#xA;&#xA;<p>In order to compute things, my new service needs to retrieve additional infos from another service (lets say from the same bounded context)</p>&#xA;&#xA;<p>The issue here is that all these calls on every computation might cause some performance issues.</p>&#xA;&#xA;<p>What do you think is the best approach to take here?&#xA;Is it a good idea to let my new service save a kind of snapshot of the additional infos it needs (asynchronous synchronisation with the other service) so that it doesn't have to perform all those calls every time it needs to compute. </p>&#xA;"
43664192,Do we create difference projects when implementing micro services architecture in spring,<java><spring><spring-mvc><spring-boot><microservices>,1,99,5,0.0,2,"<p>I am confused with microservice architecture. I am not able to understand how to implement the microservice architecture in spring. In spring we use <code>@RestController</code> for Rest API. Let's say we have two rest controller like below</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/user"")&#xA;public class UserService {&#xA;// this class will hanlder operations related to user&#xA;}&#xA;&#xA;@RestController&#xA;@RequestMapping(""/role"")&#xA;public class RoleService {&#xA;// this class will hanlder operations related to role&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Both rest controllers belong to one single project. Can we say our above structure is microservices? Or we have to create two projects one is <code>UserServiceProject</code> and another one is <code>RoleServiceProject</code>. In <code>UserServiceProject</code> we create Rest Controller for rest API of User operations. In <code>RoleServiceProject</code> we create Rest Controller for rest API of Role Operations. </p>&#xA;&#xA;<p>As microservices architecture says each service should be independently deployable. From this definition can we say that if we have 2 services we need to create two projects so that both projects can be independently deployable. </p>&#xA;&#xA;<p>Please also note both services share the same database and also there is a relationship between User and Role.</p>&#xA;"
43633659,What to use for microservices inter-communications .NET,<.net><design-patterns><microservices>,1,875,11,0.0,2,"<p>Doing some research on splitting our monolith into micro-services and trying to understand/determine the best way for communications between services, or if I should even be communicating between services?</p>&#xA;&#xA;<p>Should each micro-service be a web service that only serves Http or should I be using a service bus to pass work requests around?</p>&#xA;"
47380189,Microservices governance vs SOA,<architecture><domain-driven-design><microservices><soa>,2,475,5,2.0,2,"<p>I was working in SOA goverened projects for the last 10 years and now we switch to a Microservices architecture ones.</p>&#xA;&#xA;<p>The good thing in SOA was that we had a Canonical Data Model where which was built with some effort indeed but at the end all systems ended up speaking the same 'language' and communication was centralized via a Service Bus.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QNcwq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QNcwq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>In a Microservice architecture teams are independent and as there is no service bus wonder how all this intergration points will work.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/37mGm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/37mGm.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>1) Is there a way to enfore some contracts like there is WSDL in SOA (for SOAP) ?</p>&#xA;&#xA;<p>2) If team developing service B is autonoumous and deploys a new service it has to keep the old version as well no ? In SOA this problem was solved that on the service bus we kept v1 and a we did a transformation to v2.It was trasparent for consumers that service B has a new version.</p>&#xA;&#xA;<p>3) What type of govenrnance you would put in place in case the number of microservices is quite high like in the below picture knowing the teams have to be as much as possible autonoumous ('agile')?</p>&#xA;&#xA;<p>I am not looking fot the best answer , I am interested in different opinions as there is no magic solution here.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/k2mB3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k2mB3.png"" alt=""enter image description here""></a></p>&#xA;"
49944789,Handle Status Update In Even Sourcing Pattern,<java><microservices><event-sourcing>,1,61,9,0.0,2,"<p>I was looking at an auditing pattern to save history of my entity and I came across Event Sourcing Pattern. It is an interesting pattern and most of it makes sense to me but I had one question on how to implement a certain use case scenario?</p>&#xA;&#xA;<p>Use Case:</p>&#xA;&#xA;<ol>&#xA;<li>There is an invoice generated with amount of $100 and status as in review.</li>&#xA;<li>Then the invoice status is updated to billed</li>&#xA;<li>Then a payment of $50 is adjustment of $20 is made and status is updated to paid</li>&#xA;<li>We later realized that the amounts were incorrect. So we want to rollback previous transaction and revert bill status to billed again</li>&#xA;<li>We then post a payment of $70 and adjustment of $20 and update invoice status to complete.</li>&#xA;</ol>&#xA;&#xA;<p>From my understanding of event store. It should only contain the actions that were applied on the entity.So the event always has the updated transaction amounts(payment and adjustment) and status.</p>&#xA;&#xA;<p><strong>Database:</strong></p>&#xA;&#xA;<p>Invoice:</p>&#xA;&#xA;<pre><code>| id    | balance | payment | adjustment | status   |&#xA;|-------|---------|---------|------------|----------|&#xA;| 12345 | 10      | 70      | 20         | Paid     |&#xA;</code></pre>&#xA;&#xA;<p>Event Store:</p>&#xA;&#xA;<pre><code>| event_id | invoice_id | Event            | Payload |&#xA;|----------|------------|------------------|---------|&#xA;| 1        | 12345      | Invoice_InReview | JSON    |&#xA;| 2        | 12345      | Invoice_Billed   | JSON    |&#xA;| 3        | 12345      | Invoice_Paid     | JSON    |&#xA;| 4        | 12345      | Invoice_Reversed | JSON    |&#xA;| 5        | 12345      | Invoice_Paid     | JSON    |&#xA;</code></pre>&#xA;&#xA;<p>JSON contains info about changes to payment,adjustment and status</p>&#xA;&#xA;<p>So here are my questions</p>&#xA;&#xA;<ol>&#xA;<li>I get how balances can be reversed but I do not see how we can accomplish the same effect for status</li>&#xA;<li>Also how will I handle if api calls(commands) come out of  order for the above events. i.e &#xA;&#xA;<ul>&#xA;<li>Step 3 calls service</li>&#xA;<li>then step 5 </li>&#xA;<li>then step 4.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>from what I understand the balances will be fine but the invoice status will be incorrect.</p>&#xA;&#xA;<p>Please advise me on how to best handle this on event sourcing pattern.</p>&#xA;"
40880443,Can micro services be applied to the front-end with JS?,<javascript><angularjs><reactjs><frontend><microservices>,1,524,3,0.0,2,"<p>I have a project which requires various developers to build components / modules for an app at any given time.</p>&#xA;&#xA;<p>However, each component can be written in a different framework or library e.g. <code>URI/app1</code> is a search component written in React, and <code>URI/app2</code> is a results component written in AngularJS. </p>&#xA;&#xA;<p>I'm trying to find a way so that given a <code>URI</code> if <code>URI/subdomain</code> is served I can serve a module which is fully encapsulated (technology wise) from other sub paths &amp; the URI.</p>&#xA;&#xA;<p>Does something along these lines exist? Is there a methodology or approach which will allow an app to holistically serve sub-modules (not fragments of a single page, but rather full pages under a unique path) and remain isolated to other front-end code, but still allow data to be passed across the technologies used, so that a developer could essentially come in and create a component / page / module under a subpath using the technology of their choice and have it be accepted cohesively across the existing app written in potentially varying technologies?</p>&#xA;"
46581254,Microservices and service granularity,<domain-driven-design><microservices>,3,110,4,1.0,2,"<p>I have never worked with microservices architecture before and there is something important that it is still not clear in what I am reading.</p>&#xA;&#xA;<p>In a microservice architecture a service is a single endpoint or a single module with several endpoints?</p>&#xA;&#xA;<p>Are the endpoints that are fine grained or the granularity is at a higher level? I thought at the beginning that the endpoints were fine grained and this is why there was the risk of making the API too chatty. </p>&#xA;&#xA;<p>I am now finding articles that say that in microservices architecture a service is associated to ""bounded context"". It seems to me that a bounded context needs more than a single endpoint in an API.</p>&#xA;"
46585082,Async communication between spring boot micro services,<asynchronous><spring-boot><microservices><spring-rabbitmq>,1,662,4,1.0,2,"<p>I am new to spring boot and created 2 micro services.&#xA;They need to communicate with one other in synchronous and asynchronous way.&#xA;For synchronous communication, I can use the RestTemplate.&#xA;But how to do for asynchronous calling ?&#xA;my requirement for Asynchonous is:&#xA;lets say I am querying for something from one micro service. To fetch the queried data it will take sometime because of queried for large sum of data. &#xA;In this case, I need to save the request into some transaction table and return the response with transactionId and callBackAPI. After sometime if I call the callBackAPI with transactionId. Then I should be able to get the previously queried data.</p>&#xA;&#xA;<p>Please help me with this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
45544777,"NodeJS Microservices, combining data",<javascript><node.js><redis><microservices>,1,147,13,1.0,2,"<p>I'm building a NodeJS platform that consist of several core 'parts' (users, messages and trading signals).</p>&#xA;&#xA;<p>So my idea is to create microservices for each of them, and it works pretty well.. But I can't get my head around how to 'join' data between the microservices (I'm a frontender originally.....)</p>&#xA;&#xA;<p>For example, I have 3 microservices.. Each with its own MongoDB, on its own machine complete isolated.. Imagine the common situation where the messages is retrieved from a single microservice, the message has a 'user_id' and I need to get the username and profilePicture to be combined in the retrieved message object..?</p>&#xA;&#xA;<p>I read a lot about using Redis, but it seems like a 'messaging' service to me, not much of a 'combine' service.. Can anyone help me through the darkness??</p>&#xA;&#xA;<p>Thanks!!</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jQphv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jQphv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I know its a very general question... But I just can't get a grip of what the 'best practice' is when combining data of multiple micro services..</p>&#xA;"
47145930,Microservices versioning best practices,<architecture><versioning><microservices>,2,885,0,1.0,2,"<p>I read the Susan Fowler's book ""production ready microservices"" and in two places (until now) I found </p>&#xA;&#xA;<ul>&#xA;<li>(page 26) ""Avoid Versioning Microservices and Endpoints"", </li>&#xA;<li>""versioning microservices can easily become an organizational nightmare"" (page 27),</li>&#xA;<li>In microservice ecosystems, the versioning of microservices is discouraged(page 58)</li>&#xA;</ul>&#xA;&#xA;<p>Anyway, I used all types of versioning for all kind of different projects: git tag, deb package versioning, python packages versioning, http api versions and I never had very big problems to manage the project's versions. Beside of this I knew exactly to what version to roll out in case of some failures or bugs from customers.</p>&#xA;&#xA;<p>Anybody have any clue why in this book the microservice versioning is so blamed and what advises would you have regarding the topic?</p>&#xA;"
47017657,How to have lombok to create constructor for non null fields since @RequiredArgsConstructor seems not to work?,<java><spring><microservices><lombok>,1,665,2,1.0,2,"<p>I am playing with the <strong>Lombok</strong> and already went through many link but none of them worked for me.</p>&#xA;&#xA;<p><strong>Person.java</strong></p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>PersonController.java</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/people"")&#xA;public class PersonController {&#xA;    @Autowired&#xA;    private PersonRepository personRepository;&#xA;&#xA;    @RequestMapping(value = """", method = RequestMethod.POST)&#xA;    @ResponseStatus(HttpStatus.CREATED)&#xA;    public void createPerson(@RequestBody Person person) {&#xA;        personRepository.save(new Person(person.getFirstName(), person.getLastName()));  //line-34&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But its not allowing me to create the two argument constructor</p>&#xA;&#xA;<pre><code>Multiple markers at this line&#xA;    - The constructor Person(String, String) is undefined&#xA;    - The method save(S) in the type CrudRepository&lt;Person,Long&gt; is not applicable for the arguments &#xA;     (Person)&#xA;</code></pre>&#xA;&#xA;<p><strong>On line No-34 its breaking...</strong></p>&#xA;&#xA;<p><strong>EDIT-1:</strong></p>&#xA;&#xA;<pre><code> @RequestMapping(value = ""/{id}"", method = RequestMethod.PUT)&#xA;    @ResponseStatus(HttpStatus.NO_CONTENT)&#xA;    public void updatePerson(@PathVariable(""id"") Long id, @RequestBody Person person) {&#xA;        Person existingPerson = personRepository.findOne(id);&#xA;        existingPerson.setFirstName(person.getFirstName());&#xA;        existingPerson.setLastName(person.getLastName());&#xA;        personRepository.save(existingPerson);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Here is the error</p>&#xA;&#xA;<pre><code>The method setFirstName(String) is undefined for the type Person&#xA;</code></pre>&#xA;&#xA;<p>The changes I made</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;//@NoArgsConstructor&#xA;@RequiredArgsConstructor()&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private final String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private final String lastName;&#xA;} &#xA;</code></pre>&#xA;&#xA;<p>-===================</p>&#xA;&#xA;<p><strong>Edit-2</strong></p>&#xA;&#xA;<p>Here is the final result:</p>&#xA;&#xA;<pre><code>@Setter @Getter&#xA;@ToString&#xA;@AllArgsConstructor&#xA;@RequiredArgsConstructor&#xA;@Entity&#xA;public class Person {&#xA;    @Id&#xA;    @GeneratedValue&#xA;    private Long id;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 20)&#xA;    private String firstName;&#xA;&#xA;    @NotNull&#xA;    @Size(min = 1, max = 50)&#xA;    private String lastName;&#xA;&#xA;    public Person(String firstName, String lastName){&#xA;        this.firstName = firstName;&#xA;        this.lastName = lastName;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
38377156,How to stop a spring boot service from command line?,<java><windows><spring><spring-boot><microservices>,1,4534,0,0.0,2,"<p>I’m a spring-boot newbie, so please go easy on me.</p>&#xA;&#xA;<p>I need to offer a way for an administrator to start and stop my spring-boot microservice from a job scheduler. If I can create <code>start.bat</code> and <code>stop.bat</code> files for the service, then the scheduler could call them.</p>&#xA;&#xA;<p>How do I stop a spring-boot microservice from command line without killing the process? I'd like a graceful exit, if possible.</p>&#xA;&#xA;<p>The host will be a Windows server.</p>&#xA;"
38453830,How defensive to be when interacting with another internal microservice?,<microservices><defensive-programming>,2,54,3,0.0,2,"<p>In this scenario there are two HTTP microservices:</p>&#xA;&#xA;<ol>&#xA;<li>The public service that provides the client with data</li>&#xA;<li>The internal microservice that authenticates calls to the public service</li>&#xA;</ol>&#xA;&#xA;<p>Service 1 makes a call to Service 2 to ask it to authenticate the token provided to it by the client.</p>&#xA;&#xA;<p>The agreement (""contract"") is that Service 2 should reply with <code>200 OK</code> and JSON content about the authenticated user.</p>&#xA;&#xA;<p>In Service 1, if it receives the response <code>200 OK</code>, is it worth going any further to validate the response further?</p>&#xA;&#xA;<p>For example, the JSON body of the response is parsed into an object. Is there value in checking if that object was correctly instantiated instead of being set to null? Or alternatively should that be left to integration tests?</p>&#xA;"
51149979,Microservicess with Serverless (Lambda or Function),<azure><lambda><microservices><azure-functions>,2,61,0,2.0,2,"<p>I have some concern on getting an idea of migrating current microservices system into serverless.</p>&#xA;&#xA;<p>Right now, between services are communicating with HTTP or API based.&#xA;Serverless like lambda or function can talk to each other with function call or lambda call. This way can be done by changing all HTTP code into lambda call within all services.</p>&#xA;&#xA;<p>Another way is still using HTTP request to call another service that on lambda through API Gateway. This method of calling is not good because the service request gone to Internet and go back again into API Gateway then neighbor service get the request. Too long and does not make sense for me.</p>&#xA;&#xA;<p>I will be glad if lambda app call another lambda app with local network HTTP request, this is still on my research on how to do it.</p>&#xA;&#xA;<p>I would like to know from all of you about your experience on migrating microservices based on HTTP communication between services into serverless like Lambda or Functions ?</p>&#xA;&#xA;<p>Do you change all your code into specific lambda function call ?&#xA;Do you use HTTP over internet and API Gateway again to call neighbor service ?&#xA;Have you guys figured it out on Local / Private network lambda call ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;"
51189616,How can I proceed a delete operation in Lagom Framework?,<java><scala><akka><microservices><lagom>,2,79,4,0.0,2,"<p>I am a little newbie on the Lagom framework and I need to know what the right way to do a delete operation in this framework. I develop with Java and I tested two approaches:</p>&#xA;&#xA;<ol>&#xA;<li>when I handle the delete event I set the state to Optional.empty () but it returns nullPointerException crashes and the line in my readSide (Cassandra DataBase) is not deleted</li>&#xA;<li>I add a Status field to my entity and when I handle the delete event I pass it to -1. When I refer to my entity I test on State.present and status! = -1 to make sure the entity and deleted. For the readSide, the line is deleted properly</li>&#xA;</ol>&#xA;&#xA;<p>In terms of logic, I think the second approach is the most logical but I want to know if there is a good practice that the Lagom framework offers developers to do delete operations</p>&#xA;&#xA;<p><strong>EDIT 1</strong>&#xA;This is my ReadSideHandler code, how can I proceed to handle properly the empty option</p>&#xA;&#xA;<pre><code>@Override&#xA;public ReadSideHandler&lt;AuthenticationEvent&gt; buildHandler() {&#xA;    return readSide.&lt;AuthenticationEvent&gt;builder(""authenticationEventOffset"")&#xA;            .setGlobalPrepare(this::createTables)&#xA;            .setPrepare(tag -&gt; prepareStatements())&#xA;            .setEventHandler(AuthenticationLoginEvent.class,&#xA;                    e -&gt; insertAuthentication(e.getAuthentication()))&#xA;            .setEventHandler(AuthenticationLogoutEvent.class, e -&gt; deleteAuthentication(e.getAccessToken()))&#xA;            .build();&#xA;}&#xA;</code></pre>&#xA;"
51227737,How to implement OpenID Connect authentication with 3rd party IDPs in a microservices architecture,<oauth-2.0><jwt><microservices><openid-connect>,3,192,4,0.0,2,"<p>For the past 10+ days I've read an watched ALL the content I could find on understanding OAuth2 and OpenID Connect, only to find that many people disagree on the implementation, which really confuses me.</p>&#xA;&#xA;<p>To my understanding, all the articles and examples I found assume you want access to eg. google calendar, profile info or emails if you eg. login with google, but I do NOT need to access other than my own API's - I only want to use Google, Facebook etc for logging in, and getting an id which I can link to my user in my own database - nothing more than that.</p>&#xA;&#xA;<p>I'll try illustrate my use case and use that as an example.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/H4VwP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H4VwP.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>A note on the diagram: the Authentication service could probably be built into the API Gateway - not that i matters for this example, since this is not about ""where to do it"", but ""how to do it the best way"" possible, for an architecture such as mine, where it's used for my own API's / Microservices, and not accessing Google, Facebook etc. external API's</em></p>&#xA;&#xA;<p>If you can understand what I'm trying to illustrate with this diagram above, please tell me if I've misunderstood this.</p>&#xA;&#xA;<p>The most basic requirements for this architecture you see here are:</p>&#xA;&#xA;<ul>&#xA;<li>Users can login with Google, Facebook, etc.</li>&#xA;<li>The same login will be used for all micro-services</li>&#xA;<li>OpenId user will have a linked account in the database</li>&#xA;<li>User access is defined in my own db, based on groups, roles and permissions</li>&#xA;</ul>&#xA;&#xA;<p>I do not intend to use external API's after the user is authenticated and logged in. No need for ever accessing a users calendar, email etc. so I really just need the authentication part and nothing else (proof of successful login). All user access is defined in my own database.</p>&#xA;&#xA;<p>So a few fundamental questions comes to mind.</p>&#xA;&#xA;<ul>&#xA;<li>First of all, is OpenID Connect even the right tool for the job for authentication only (I'll have no use for authorization, since I will not need read/write access to google / facebook API's other than getting the ID from authenticating)?</li>&#xA;<li>People generally do not agree on whether to use the ID or Access token for accessing your own API's. As far as I understand the ID token is for the client (user-agent) only, and the access token is for eg. accessing google calendar, emails etc.... External API's of the OpenID Provider... but since I'll only be accessing my own API's, do I event need the access token or the ID token - what is the correct way to protect your own API's?</li>&#xA;</ul>&#xA;&#xA;<p>If the ID token is really just for the client, so it can show eg. currently logged in user, without going to the DB, I have 0 use for it, since I'll probably query the user from from the db and store it in redux for my react frontend app.</p>&#xA;&#xA;<p><strong>Dilemma: To store user details, groups, roles and permission inside JWT or not for API authorization?</strong></p>&#xA;&#xA;<ul>&#xA;<li>By only storing the user identifier in the token, it means that I always allow authenticated users that has a valid token, to call endpoints BEFORE authorization and first then determine access based on the db query result and the permissions in my own database.</li>&#xA;<li>By storing more data about the user inside the JWT, it means that in some cases, I'd be able to do the authorization / access (group, role, permission) check before hitting the API - only possible with user info, groups, roles and permission stored inside a JWT issued upon login. In some cases it would not be possible due to eg. the CMS content access permissions being on a per-node level. But still it would mean a little better performance. </li>&#xA;</ul>&#xA;&#xA;<p>As you can see on the diagram I'm sending all API requests through the gateway, which will (in itself or with an authentication service) translate the opaque access token into some JWT with an identifier, so I can identify the user in the graph database - and then verify if the user has the required groups, roles and permissions - not from an external API, but from my own database like you see on the diagram.</p>&#xA;&#xA;<p>This seems like a lot of work on every request, even if the services can share the JWT in case multiple services should need to cross call each other.</p>&#xA;&#xA;<p>The advantage of always looking up the user, and his permissions in the db, is naturally that the moment the user access levels change, he is denied/granted access immediately and it will always be in sync. If I store the user details, groups, roles and permission inside a JWT and persist that in the client localstorage, I guess it could pose a security issue right, and it would be pretty hard to update the user info, groups, roles and permissions inside that JWT?</p>&#xA;&#xA;<p>One big advantage of storing user access levels and info inside the JWT is of course that in many cases I'd be able to block the user from calling certain API's, instead of having to determine access after a db lookup.</p>&#xA;&#xA;<p>So the whole token translation thing means increased security at the cost of performance, but is is generally recommended and worth it? Or is it safe enough to store user info and groups, roles, permissions inside the JWT? </p>&#xA;&#xA;<p>If yes, do I store all that information from my own DB in the ID Token, Access token or a 3rd token - what token is sent to the API and determines if the user should be granted access to a given resource based on his permissions in the db? Do I really need an access token if I don't need to interact with the ID providers API? Or do I store and append all my groups, roles, permissions inside the ID token (that doesn't seem clean to me) issued by OpenID connect, and call the API and authorize my own API endpoints using that, even if some say you should never use the ID token to access an API? Or do I create a new JWT to store all the info fetched from my database, which is to be used for deciding if the user can access a given resource / API endpoint?</p>&#xA;&#xA;<p>Please do not just link to general specs or general info, since I've already read it all - I just failed to understand how to apply all that info to my actual use case (the diagram above). Try to please be as concrete as possible.</p>&#xA;&#xA;<p>Made another attempt to try and simply the flow:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/1d1Tn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1d1Tn.png"" alt=""enter image description here""></a></p>&#xA;"
48209566,What to do when the queue is down?,<architecture><queue><message-queue><microservices><amazon-sqs>,5,142,2,0.0,2,"<p>I have 2 microservices, <code>A</code> and <code>B</code>. When <code>A</code> receives a request from a user, it gets processed (store some things in the database) and a message is sent to a queue that is read by <code>B</code>.</p>&#xA;&#xA;<p>If the queue is down, my initial thought is to make the entire request fall over, rollback, and show an error to the user asking to try again later. Is it a bad practice?</p>&#xA;&#xA;<p>Would it be a better practice to store the messages in <code>A</code>'s database marked as <code>NOT_SENT</code> and have a job to send it later when the queue is up again? Or is it over-engineering?</p>&#xA;&#xA;<p>EDIT: the request to <code>A</code> needs to be synchronous, so the user knows its outcome, but they <strong>don't</strong> need to know yet the results of <code>B</code> processing the message, so it can be asynchronous.</p>&#xA;"
44886715,Should the Auth Server be combined with the User Service in a microservices architecture?,<spring><authentication><oauth-2.0><microservices>,2,592,0,0.0,2,"<p>I am currently building a microservices based application in spring boot with the following services</p>&#xA;&#xA;<ul>&#xA;<li>Auth server (Distributes access tokens)</li>&#xA;<li>User service (User info like username, password, email, etc.)</li>&#xA;<li>Various other unrelated services</li>&#xA;</ul>&#xA;&#xA;<p>When a user sends their credentials to the auth server, the auth server should verify that they are correct and then return an access token. </p>&#xA;&#xA;<p>My question is, should I combine the auth server with the user service so looking up credentials is a simple database call, or should I keep them as separate applications and have them both point to the same shared database? Is there a better alternative?</p>&#xA;"
43212533,Eventual Consistency in microservice-based architecture temporarily limits functionality,<microservices><application-design><eventual-consistency><event-based-programming>,1,629,3,0.0,2,"<p>I'll illustrate my question with Twitter. For example, Twitter has microservice-based architecture which means that different processes are in different servers and have different databases.</p>&#xA;&#xA;<p>A new tweet appears, server A stored in its own database some data, generated new events and fired them. Server B and C didn't get these events at this point and didn't store anything in their databases nor processed anything.</p>&#xA;&#xA;<p>The user that created the tweet wants to edit that tweet. To achieve that, all three services A, B, C should have processed all events and stored to db all required data, but service B and C aren't consistent yet. <strong>That means that we are not able to provide edit functionality</strong> at the moment.</p>&#xA;&#xA;<p>As I can see, a possible workaround could be in switching to immediate consistency, but that will take away all microservice-based architecture benefits and probably could cause problems with tight coupling.    </p>&#xA;&#xA;<p>Another workaround is to restrict user's actions for some time till data aren't consistent across all necessary services. Probably a solution, depends on customer and his business requirements.    </p>&#xA;&#xA;<p>And another workaround is to add additional logic or probably service D that will store edits as user's actions and apply them to data only when they will be consistent. Drawback is very increased complexity of the system.</p>&#xA;&#xA;<p>And there are two-phase commits, but that's 1) not really reliable 2) slow.<br>&#xA;I think slowness is a huge drawback in case of such loads as Twitter has. But probably it could be solved, whereas lack of reliability cannot, again, without increased complexity of a solution.</p>&#xA;&#xA;<p>So, the questions are: </p>&#xA;&#xA;<ol>&#xA;<li>Are there any nice solutions to the illustrated situation or only things that I mentioned as workarounds? Maybe some programming platforms or databases?</li>&#xA;<li>Do I misunderstood something and some of workarounds aren't correct?</li>&#xA;<li>Is there any other approach except Eventual Consistency that will guarantee that all data will be stored and all necessary actions will be executed by other services?</li>&#xA;</ol>&#xA;&#xA;<p><em>Why Eventual Consistency has been picked for this use case</em>? As I can see, right now it is the only way to guarantee that some data will be stored or some action will be performed if we are talking about event-driven approach when some of services will start their work when some event is fired, and following my example, that event would be “tweet is created”. So, in case if services B and C go down, I need to be able to perform action successfully when they will be up again.</p>&#xA;&#xA;<p>Things I would like to achieve are: reliability, ability to bear high loads, adequate complexity of solution. Any links on any related subjects will be very much appreciated.</p>&#xA;&#xA;<p>If there are natural limitations of this approach and what I want cannot be achieved using this paradigm, it is okay too. I just need to know that this problem really isn't solved yet.</p>&#xA;"
48505946,Single Database backed Micro-server architecture?,<architecture><microservices>,2,121,3,0.0,2,"<p>In an application I am planning to build, I am trying to decide an architecture for our server. One idea I had was to spawn multiple servers at different addresses like <code>orders.example.com</code>, <code>settings.example.com</code> etc, i.e. , one server process per component of the system, which will be backed by a single database cluster.</p>&#xA;&#xA;<p>I am wondering if this is a good idea, and what are the caveats of it, if anyone has ever used it ?</p>&#xA;"
48531937,AWS ALB per ECS Service vs. multiple services per ALB for a microservices architecture,<amazon-web-services><microservices><amazon-elb><amazon-route53><amazon-alb>,1,272,4,0.0,2,"<p>Initially I thought that multiple services per ALB listener with different path patterns to distribute API calls appropriately was the obvious choice. In terms of health checks though (if one of those services goes down), I don't know of a smart way to divert traffic for just that service to a different region. </p>&#xA;&#xA;<p>If I have an active active setup with weighted route 53 records that will failover on a health check, I don't see any other solution than to either cut off that entire ALBs traffic and divert to another region, or ignore the 1 down service and continue to send traffic to the partially failing ALB.</p>&#xA;&#xA;<p>Having a one to one mapping of ALBs to services fixes this solution, but it adds additional overhead in terms of cost and complexity.</p>&#xA;&#xA;<p>What is the recommended pattern to follow for an active active microservices architecture?</p>&#xA;"
48753245,How to expose APIs endpoints from private AWS ALB,<amazon-web-services><microservices><amazon-vpc><aws-ecs>,3,240,0,0.0,2,"<p>We are having several microservices on AWS ECS. We have single ALB which has different target group for different microservices. We want to expose some endpoints externally while some endpoints just for internal communication. </p>&#xA;&#xA;<p>The problem is that if we put our load balancer in public VPC than it means that we are exposing all register endpoints externally. If we move load balancer to private VPC, we have to use some sort of proxy in public VPC, which required additional infra/cost and custom implementation of all security concerns like D-DOS etc.</p>&#xA;&#xA;<p>What possible approaches we can have or does AWS provide some sort of out of the box solution for this ?</p>&#xA;"
48809275,SpringBoot microservice How to set properties in application context using java configuration,<java><spring><spring-boot><microservices><applicationcontext>,2,455,4,0.0,2,"<p>I have a spring-boot microservice with Java based config. Now there is an auth token container, which I need to call to get the access token. That auth token library has a class like this. Notice that the class <code>AuthServletContextListener</code> comes from a third party  <code>jar</code> file which I can not modify.</p>&#xA;&#xA;<pre><code>public class AuthServletContextListener implements ServletContextListener {&#xA;    public void contextInitialized(ServletContextEvent arg0) {&#xA;        try {&#xA;            ServletContext e = arg0.getServletContext();&#xA;            Properties config = new Properties();&#xA;            this.addProp(config, e, ""auth.token.url"", ""Token Service URL"");&#xA;            this.addProp(config, e, ""auth.system.username"", ""System Username"");&#xA;            this.addProp(config, e, ""cauth.system.password"", ""System Password"");&#xA;            TokenContainer.init(config);&#xA;        } catch (IOException arg3) {&#xA;            arg3.printStackTrace();&#xA;        }&#xA;&#xA;    }&#xA;&#xA;&#xA;    private void addProp(Properties config, ServletContext context, String propName, String descrip) {&#xA;        String propVal = (String) context.getAttribute(propName);&#xA;        if (StringUtils.isEmpty(propVal)) {&#xA;            propVal = context.getInitParameter(propName);&#xA;        }&#xA;&#xA;        if (StringUtils.isNotEmpty(propVal)) {&#xA;            config.put(propName, propVal);&#xA;        } else {&#xA;            throw new RuntimeException(""error: "");&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The AuthContextListener has an annotation that automatically looks for an application startup event. This automatically starts the container correct settings if the above context params are included. I can then grab the token through that container like this:</p>&#xA;&#xA;<pre><code>TokenContainer.getSystemToken() &#xA;</code></pre>&#xA;&#xA;<p>This will initialize successfully if the above context params are included in the web.xml like so:</p>&#xA;&#xA;<pre><code>&lt;context-param&gt;&#xA;   &lt;param-name&gt;auth.system.username&lt;/param-name&gt;&#xA;   &lt;param-value&gt;UserName&lt;/param-value&gt;&#xA;&lt;/context-param&gt; &#xA;</code></pre>&#xA;&#xA;<p>The same Application context configuration as above can be performed by creating a Spring bean with the following information:</p>&#xA;&#xA;<pre><code>&lt;bean&gt;&#xA;    &lt;property name=""attributes""&gt;&#xA;        &lt;map&gt;&#xA;            &lt;entry key=""auth.token.url"" value=""${auth.token.url}""/&gt;&#xA;            &lt;entry key=""auth.system.username"" value=""${auth.system.username}""/&gt;&#xA;            &lt;entry key=""auth.system.password"" value=""${auth.system.password}""/&gt;&#xA;        &lt;/map&gt;&#xA;    &lt;/property&gt;&#xA;&lt;/bean&gt;&#xA;</code></pre>&#xA;&#xA;<p>My question is how can I achieve the same using Java based configuration in a latest spring boot application. All I have is <code>application.yml</code> file with the auth endpoint, username and password values. I tried using <code>@Configuration</code> bean but no luck. How can I set those three props in application context and make that listener start automatically for me.</p>&#xA;"
48762736,What is the best way to send password from app server to authentication micro service?,<node.js><microservices>,1,53,7,0.0,2,"<p>I am currently in a process to develop micro service architecture in one of my projects. I have one public layer of App Servers which actually routes the user requests to relevant micro services and replies back to client. My mirco services are in private layer.</p>&#xA;&#xA;<p>Currently i am using REST API to send data back and forth. However, I was wondering, what is the best way to send username and password from app server to micro service? Should I use plain text format as micro service is in private layer? Please suggest best way.</p>&#xA;"
50455134,Can Software Architects predict of how microservice architectures will mature over time?,<architecture><microservices><soa><software-design>,1,81,4,1.0,2,"<p>In March 2014 ( just over four years ago at the time of this question ), James Lewis and Martin Fowler wrote: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Many people believe that [decay of modularity over time] is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can't truly assess how microservice architectures mature.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now that many MSAs have been built by a variety of businesses, do we have a general understanding of the maturation of these architectures? What do we know about what works as time goes forward? What do we know about what does not work?</p>&#xA;"
40691082,Splitting and naming Microservices,<soa><microservices>,1,1036,0,1.0,2,"<p>I recently started a side-project. It was supposed to be a virtual recipe-book with the capabilities to store and retrieve recipes (CRUD), rate them and search through them. This is nothing new, but i wanted to build it as a desktop application to learn more about databases, unit testing, UIs and so on. Now that the core domain is pretty much done (i use a DDD approach) and i implemented most of the CRUD Repositories, i want to make this a bit more extensible by hosting the core functionality online, so i am able to write multiple backends (desktop application, web application, web api, etc).</p>&#xA;&#xA;<p>Service Oriented Architecture (or Microservices) sound like a good approach to me to do that. The problem i am facing is how to decide, which parts of my project belong into a separate service and how to name them.</p>&#xA;&#xA;<p>Take the following parts of the project:</p>&#xA;&#xA;<ul>&#xA;<li>Core domain (Aggregates, Entities, Value Objects, Logic) -> <em>Java</em></li>&#xA;<li>Persistence (DAOs, Repositories, multiple Database backend implementations) -> <em>Java</em></li>&#xA;<li>Search (Search Services which use SQL queries on the persistence DB for searching) -> <em>Java</em></li>&#xA;<li>Desktop Application -> <em>JS (Electron) or JavaFX</em></li>&#xA;<li>Web Application -> <em>Flask or Rails</em></li>&#xA;<li>Web API (Manage, Rate, Search for recipes using REST) -> <em>?</em></li>&#xA;</ul>&#xA;&#xA;<p>My initial approach would be to put the core domain, the persistence, the search and the web api into a single sub-project and host that whole stack on Heroku or something similar. That way my clients could consume the web interface. The Desktop and Web apps would be different projects on their own. The Dektop app could share the core domain if they are both written in Java.</p>&#xA;&#xA;<p>Is this a valid approach, or should i split the first service into smaller parts? How do you name these services?</p>&#xA;"
43498534,"In a NodeJs microservices Architecture, should I use a package.json per service?",<node.js><microservices>,1,297,2,2.0,2,"<p>I'm currently developing a microservices architecture in NodeJs. My first approach, was a <code>package.json</code> per service. Although, it can be very tricky when accessing to a common area (with logging or database utils), for all microservices. For instance:</p>&#xA;&#xA;<pre><code>common-area &gt;&#xA;    logger.js&#xA;    package.json - install module typeorm&#xA;&#xA;service1 &gt;&#xA;    app.js - use logger.js&#xA;    package.json - also install module typeorm&#xA;</code></pre>&#xA;&#xA;<p>When running <code>node app.js</code> (Service 1) we end up with 2 typeorm modules loaded, once we made two different installations, one in common area (used by logger) and another in service1.</p>&#xA;&#xA;<p>Should I use only one <code>package.json</code>, for all micro-services, resulting in only one <code>node_modules</code> folder?</p>&#xA;"
42490380,Handling JWT and Refresh token flow,<security><jwt><microservices>,1,1223,0,1.0,2,<p>I am building a front end built in react that accesses multiple microservice apis that I am also building. For auth I have built a jwt login system but was wondering what is the process of handling refresh tokens. </p>&#xA;&#xA;<ol>&#xA;<li><p>Is the refresh token inside the jwt with the user info or is it in its own token with a different encryption for extra protection?</p></li>&#xA;<li><p>If it is in its own token what should the other micro services respond with to the react app if the jwt is invalid and needs to be refreshed. Is there a common http status code used?</p></li>&#xA;<li><p>I have read that a refresh token should be more secure then your jwt cause it can be used to issue jwts and will have a longer active time. Is there any extra security past encryption that can be done server side or client side that isnt already done for jwts?</p></li>&#xA;<li><p>When should you refresh the refresh token with a new token and timestamp that it becomes invalid?</p></li>&#xA;</ol>&#xA;
38629740,How to implement security for my Microservices with Spring?,<spring-security><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,221,0,2.0,2,"<p>We have one monolithic application having more than 10 services like user management, fleet booking, feedback and etc developed on spring rest.</p>&#xA;&#xA;<p>We want to migrate to Microservices(Spring Boot + Cloud + Netflix OSS).</p>&#xA;&#xA;<p>Below are my questions :&#xA;How can we implement security for all our rest services (with own user database)?&#xA;How to implement api gateway from security stand point ?</p>&#xA;"
38629237,How to create a Transaction 'Wrapper' for multiple Services?,<c#><web-services><wcf><transactions><microservices>,2,434,3,0.0,2,"<p>Currently, I'm working on a project that using MicroServices as the main concept.</p>&#xA;&#xA;<p>For a clearer picture, I'll give you the example:</p>&#xA;&#xA;<p>I got <em>Service A</em> that has its own model and controller. </p>&#xA;&#xA;<p>Basically, Service A only contains basic CRUD operations for <em>Database A</em>. </p>&#xA;&#xA;<p>Second, I got <em>Service B</em>, same like Service A but different database (<em>Database B</em>). </p>&#xA;&#xA;<p>Now, I created 1 Services to consume both Service A and Service B. Currently I'm using TransactionScope for 'wrap' the transaction, but it didn't work.</p>&#xA;&#xA;<p>Here's the code :</p>&#xA;&#xA;<pre><code>//This is the service to call Service A and Service B&#xA;using (TransactionScope ts = new TransactionScope())&#xA;{&#xA;     callServiceAMethod(); // works good&#xA;     callServiceBMethod(); // something happened, and failed&#xA;&#xA;     //from here I don't know what should I do&#xA;     //What I'm expecting is : if one of the service i just called didn't work as expected, &#xA;     //the transaction will be rolled back else will committed     &#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Any help will be appreciated :)</p>&#xA;"
44115310,SessionId lost when I make a request between backend of microservices,<java><spring><rest><security><microservices>,3,271,2,1.0,2,"<p>I am trying to make request between microservices in order to retrieve a list of users with the same roles. For this, first I make a request between FrontEnd and Backend inside the microservice 1. Following, I call an endpoint in the microservice 2 from Microservice 1 backend, but the session Id is lost in it, and I can retrieve the context. &#xA;I am using spring security and Redis for the session Control. &#xA;Manually, I retrieve the session Id from the microservice 1 and I add it as an attribute of the header of the second call, to the microservice 2. But it does not work.</p>&#xA;&#xA;<pre><code>String sessionID= RequestContextHolder.currentRequestAttributes().getSessionId();&#xA;RestTemplate rest = new RestTemplate();&#xA;HttpHeaders headers= new HttpHeaders();            &#xA;headers.set(""Session"",sessionID);&#xA;HttpEntity&lt;ResponseData&gt; entity = new HttpEntity&lt;ResponseData&gt;(headers);&#xA;ResponseEntity&lt;ResponseData&gt; responseEntity =rest.exchange(targetApi,  HttpMethod.GET, entity,ResponseData.class);&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qFEXf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qFEXf.jpg"" alt=""enter image description here""></a></p>&#xA;"
31510697,Automating microservices load balancing / scaling,<docker><load-balancing><coreos><microservices><akka-cluster>,1,381,0,1.0,3,"<p>Reading up on micro services for a few days now I was wondering how do people go about automating the load balancing and scaling these things?</p>&#xA;&#xA;<p>I have a specific scenario in mind what I would like to achieve but not sure if it's possible or maybe I'm thinking about it wrong. So here it goes...</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Let's say I have a cluster of 3 CoreOS machines named A,B and C.</p>&#xA;&#xA;<p>First thing I want is transparent deployment for which I can probably use fleet. </p>&#xA;&#xA;<p>Then I would like to detect, when one of the services is under huge load and deploy another instance of it and have that one and the first one deployed, automatically load balanced in a way that would not disrupt other services that are using it (traffic goes through load balancer from now on).</p>&#xA;&#xA;<p>Another way could be that I manually deploy another version of the services which then gets load balanced automatically and traffic router to the load balancer.</p>&#xA;&#xA;<p>Then the last question, how is this all different to something like Akka cluster and how does development of those differ from micro services?</p>&#xA;"
50700178,Should API gateway be responsible for authorisation?,<authentication><architecture><authorization><microservices><api-gateway>,1,100,0,1.0,3,"<p>Currently I have a monolith application with Java/Spring Boot the following endpoints:</p>&#xA;&#xA;<ul>&#xA;<li><code>/login</code></li>&#xA;<li><code>/logout</code></li>&#xA;<li><code>/some-resource</code></li>&#xA;</ul>&#xA;&#xA;<p>To access <code>some-resource</code>, the flow is following:</p>&#xA;&#xA;<ol>&#xA;<li>The user makes a <code>POST</code> request to <code>/login</code> endpoint. If the credentials are correct, a JWT token is returned in header, otherwise a 401.</li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<p>Now I want to split the monolith into 2 services: ""AuthServer"" and ""SomeResourceServer"". There will be an API gateway on the top. I am thinking about 2 possible ways to handle authorisation</p>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 1</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway calls the ""AuthServer"" to validate the JWT token. If the token is valid, the API gateway calls ""SomeResourceServer"" and returns the results. Otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<h2>Option 2</h2>&#xA;&#xA;<ol>&#xA;<li>The user makes request to <code>/login</code> endpoint. The API gateway forwards it to the ""AuthServer"". If the credentials are correct, a JWT token is returned in header, otherwise a 401. <strong>- This step is the same</strong></li>&#xA;<li>The users sends the JWT token along with the request to <code>/some-resource</code>. The API gateway simply forwards the request to ""SomeResourceServer"". Then ""SomeResourceServer"" calls ""AuthServer"" to validate the JWT token. If the token is valid, the resource is returned, otherwise 403.</li>&#xA;</ol>&#xA;&#xA;<hr>&#xA;&#xA;<p>In Option 1 the API gateway is responsible to handle authorisation (communicate with ""AuthServer""), in option 2 the communication is done between the servers. So which option is more correct? Are there any good/bad practices? Or maybe another way/option?</p>&#xA;"
32604241,Best Protocol for a App to Use a Service on the Same Server?,<php><api><http><service><microservices>,1,53,0,0.0,3,"<p>I have a PHP app that needs to talk to a service which has a API that produces XML responses to HTTP requests. If this service was on a separate server I would normally use a HTTP client like Guzzle to create and consume, requests and responses.</p>&#xA;&#xA;<p>But my service will be (for the time being) on the same server. In this scenario is making HTTP requests in this fashion still my best option? Will all my requests to the API leave the server which will add latency which could be avoided?</p>&#xA;"
32574103,Microservices - how to solve security and user authentication?,<authentication><java-ee><microservices>,2,1504,1,2.0,3,"<p>There is a lot of discussion about microservice architecture. What I am missing - or maybe what I did not yet understand is, how to solve the issue of security and user authentication?</p>&#xA;&#xA;<p>For example: I develop a microservice which provides a Rest Service interface to a workflow engine. The engine is based on JEE and runs on application servers like GlassFish or Wildfly. &#xA;One of the core concepts of the workflow engine is, that each call is user centric. This means depending of the role and access level of the current user, the workflow engine produces individual results (e.g. a user-centric tasklist or processing an open task which depends on the users role in the process).</p>&#xA;&#xA;<p>In my eyes, thus a service is not accessible from everywhere. For example if someone plans to implement a modern Ajax based JavaScript application which should use the workflow microservice there are two problems:</p>&#xA;&#xA;<p>1) to avoid the cross-scripting problem from JavaScript/Ajax the JavaScript Web application needs to be deployed under the same domain as the microservice runs</p>&#xA;&#xA;<p>2) if the microservice forces a user authentication (which is the case in my scenario) the application need to provide a transparent authentication mechanism. </p>&#xA;&#xA;<p>The situation becomes more complex if the client need to access more than one user-centric microservices forcing user authentication.&#xA;I always end up with an architecture where all services and the client application running on the same application server under the same domain.</p>&#xA;&#xA;<p>How can these problems be solved? What is the best practice for such an architecture?</p>&#xA;"
44420585,Microservices: how to effectively deal with data dependencies between microservices,<node.js><mean-stack><microservices>,2,125,0,1.0,3,"<p>I am developing an application utilizing the microservices development approach with the mean stack.  I am running into a situation where data needs to be shared between multiple microservices.  For example, let's say I have user, video, message(sending/receiving,inbox, etc.) services.  Now the video and message records belong to an account record.  As users create video and send /receive message there is a foreign key(userId) that has to be associated with the video and message records they create. I have scenarios where I need to display the first, middle and last name associated with each video for example.  Let's now say on the front end a user is scrolling through a list of videos uploaded to the system, 50 at a time.  In the worst case scenario, I could see a situation where a pull of 50 occurs where each video is tied to a unique user.</p>&#xA;&#xA;<p>There seems to be two approaches to this issue:</p>&#xA;&#xA;<p>One, I make an api call to the user service and get each user tied to each video in the list.  This seems inefficient as it could get really chatty if I am making one call per video.  In the second of the api call scenario, I would get the list of video and send a distinct list of user foreign keys to query to get each user tied to each video.  This seems more efficient but still seems like I am losing performance putting everything back together to send out for display or however it needs to be manipulated.</p>&#xA;&#xA;<p>Two, whenever a new user is created, the account service sends a message with the user information each other service needs to a fanout queue and then it is the responsibility of the individual services to add the new user to a table in it's own database thus maintaining loose coupling.  The extreme downside here would be the data duplication and having to have the fanout queue to handle when updates needs to be made to ensure eventual consistency.  Though, in the long run, this approach seems like it would be the most efficient from a performance perspective.  </p>&#xA;&#xA;<p>I am torn between these two approaches, as they both have their share of tradeoffs.  Which approach makes the most sense to implement and why?</p>&#xA;"
36642718,Two microservices for read and write to one database table,<architecture><microservices>,2,1649,0,1.0,3,"<p>I'm a little bit confused about the microservice best practice approach. </p>&#xA;&#xA;<p>Following scenario:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Massive incoming messages from mqtt devices. A rest api where customers could read the messages (mostly only a part of them).</p>&#xA;</blockquote>&#xA;&#xA;<p>My idea was, to create one microservice for storing the messages in a database table. And a second microservice with a rest api to read this messages.&#xA;I want to do this, because of scaling issues. (The incoming storing part needs much more power, than the reading rest api)</p>&#xA;&#xA;<p>I read that the ""perfect"" microservice should be the only one, who accesses his data in a database. So other microservices should ask for this data, via its API and not on database level.&#xA;So my approach would be not the perfect one. I see a few options to handle this:</p>&#xA;&#xA;<ul>&#xA;<li>only one mircroservice, for storing and reading</li>&#xA;<li>making an api in the storing microservice, where the rest microservice could fetch the data.</li>&#xA;</ul>&#xA;&#xA;<p>But all of them, doesn't look good for me. </p>&#xA;&#xA;<p>Whats your opinion?</p>&#xA;&#xA;<p>Regards,&#xA;Markus</p>&#xA;"
36615117,microservice messaging db-assigned identifiers,<microservices><spring-cloud-stream>,2,154,0,2.0,3,"<p>The company I work for is investigating moving from our current monolithic API to microservices. Our current API is heavily dependent on spring and we use SQL server for most persistence. Our microservice investigation is leaning toward spring-cloud, spring-cloud-stream, kafka, and polyglot persistence (isolated database per microservice). </p>&#xA;&#xA;<p>I have a question about how messaging via kafka is typically done in a microservice architecture. We're planning to have a coordination layer between the set of microservices and our client applications, which will coordinate activities across different microservices and isolate clients from changes to microservice APIs. Most of the stuff we've read about using spring-cloud-stream and kafka indicate that we should use streams at the coordination layer (source) for resource change operations (inserts, updates, deletes), with the microservice being one consumer of the messages. </p>&#xA;&#xA;<p>Where I've been having trouble with this is inserts. We make heavy use of database-assigned identifiers (identity columns/auto-increment columns/sequences/surrogate keys), and they're usually assigned as part of a post request and returned to the caller. The coordination layer may be saving multiple things using different microservices and often needs the assigned identifier from one insert before it can move on to the next operation. Using messaging between the coordination layer and microservices for inserts makes it so the coordination layer can't get a response from the insert operation, so it can't get the assigned identifier that it needs. Additionally, other consumers on the stream (i.e. consumers that publish the data to a data warehouse) really need the message to contain the assigned identifier.</p>&#xA;&#xA;<p>How are people dealing with this problem? Are database-assigned identifiers an anti-pattern in microservices? Should we expose separate microservice endpoints that return database-assigned identifiers so that the coordination layer can make a synchronous call to get an identifier before calling the asynchronous insert? We could use UUIDs but our DBAs hate those as primary keys, and they couldn't be used as an order number or other user-facing generated ids.</p>&#xA;"
35314963,What is best practice to communicate between React components and services?,<rest><reactjs><redux><flux><microservices>,2,6713,0,3.0,3,"<p>Instead of using flux/redux architecture, how react components should communicate with services?</p>&#xA;&#xA;<p><strong>For example:</strong>&#xA;There is a container having few representational (react) components:</p>&#xA;&#xA;<ol>&#xA;<li>ChatBox - enables to read/write messages</li>&#xA;<li>AvatarBox with password changer - which enables to change user's password</li>&#xA;<li>News stream - lists news and apply filter to them</li>&#xA;</ol>&#xA;&#xA;<p>Thinking of them as resources representation, I want each of them to access Microservice API by itself (getting or updating data). Is this correct?&#xA;It will provide clean responsibility managing models, but it gives performance doubts using http requests to load each component's content</p>&#xA;&#xA;<p>This question also reffers to: <a href=""https://stackoverflow.com/questions/35286730/how-to-execute-efficient-communication-for-multiple-microservices"">How to execute efficient communication for multiple (micro)services?</a></p>&#xA;"
35348080,How to handle shared datasources using microservices architecture,<java><architecture><redis><microservices><bigdata>,1,622,0,1.0,3,"<p>I have couple of services in my microservice architecture.</p>&#xA;&#xA;<p>Two of the service(Service A, Service B) got different api's and provide different domain logic. However they do share some logic that should be returned - user-state from Redis.</p>&#xA;&#xA;<ul>&#xA;<li>When user state is changed Iam publishing from a 3rd service to all the my micro-services</li>&#xA;</ul>&#xA;&#xA;<p>solutions:</p>&#xA;&#xA;<ol>&#xA;<li><p>I could create another service which would be responsible for ""user-state"" and will hold all user data on Redis.&#xA;Disadvantages: &#xA;My clients going to have additional call on every api requests(to get the user-state).</p></li>&#xA;<li><p>Duplicate the user-state datasource for each microservices(holding more than one redis instance) and return it independently for each request.&#xA;Disadvantages: &#xA;I am going to duplicate my data and duplicate Redis instances(each microservice will access it's own)</p></li>&#xA;<li><p>have one redis datasource while all services going to use it. &#xA;Disadvantages: &#xA;Duplicating redis-logic(in order to retrieve the data) among the services and break microservices principle by using one shared datasource</p></li>&#xA;</ol>&#xA;&#xA;<p>What would you suggest doing?</p>&#xA;"
35223505,Spring Boot project setup design decisions,<java><spring><spring-boot><microservices>,1,252,1,1.0,3,"<p>We will be using Spring Boot to create services. Our initial idea would be that each service (not necessarily microservice) would be self-contained, and deployed as a .jar file. Maven for build.</p>&#xA;&#xA;<p>I'm wondering what would be a good Spring Boot project structure, as each service would be self-contained, but I'm guessing services will still have some code/entities that can or should be reused between services</p>&#xA;&#xA;<p>Options:</p>&#xA;&#xA;<ol>&#xA;<li><p>Each service is a standalone Spring Boot project. Implements only the entities, controllers, and utils that the actual service requires.</p>&#xA;&#xA;<p>Good: each service is fully self-contained</p>&#xA;&#xA;<p>Bad: what about custom utility classes that need to be re-used between services? What about domain objects that services may need to share?</p></li>&#xA;<li><p>All services are created in the same codebase. All services can re-use utilities, controllers, etc. from all other services&#xA;Good: easy re-use&#xA;Bad: A JVM is now able to serve all service calls? service boundaries are now handled by load balancers?</p></li>&#xA;</ol>&#xA;&#xA;<p>Thanks for any help!  </p>&#xA;"
39044130,Java EE Microprofile,<java><microservices>,2,1358,0,0.0,3,<p>I know it could be a pretty vague topic but please can someone explain it in plain English. I've read some articles regarding the trending topic java EE's 'microprofile' but was not able to clearly understand its purpose.</p>&#xA;&#xA;<p>My understanding in this emerging concept is that java community finds way to reshape the Java EE model to become a microservices friendly framework or platform. </p>&#xA;&#xA;<p>If we can already create a distributed microservice application in few minutes using spring boot or other API / library then why do we need microprofile?</p>&#xA;
39088230,How to ensure thrift objects are backward compatible?,<java><thrift><microservices>,1,643,0,0.0,3,"<p>We're currently using <strong>thrift</strong> for developing our micro-services.&#xA;When I recently came across this below issue.</p>&#xA;&#xA;<p>Assume below is the thrift contract for Summary Object and there is an API which gets and updates summary using the summary object passed.</p>&#xA;&#xA;<p><strong>Version - 1.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<p>Now let's say there are 5 services which are using this <strong>1.0</strong> contract of Summary.<br/>&#xA;In the next release we add another Object called a <strong>list of summaryvalues</strong>.</p>&#xA;&#xA;<p>So the new contract would look like</p>&#xA;&#xA;<p><strong>Version - 2.0</strong></p>&#xA;&#xA;<pre><code>struct Summary {&#xA;    1: required string summaryId,&#xA;    2: required i32 summaryCost,&#xA;    3: optional list&lt;i32&gt; summaryValues&#xA;}&#xA;&#xA;Summary getSummary(1: string summaryId);&#xA;&#xA;void updateSummary(1: Summary summary);&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>So when this below list is populated, we save the list of values <code>summaryValues</code> aganist that <code>summaryId</code>.</li>&#xA;<li>And when the client sends this list as <code>null</code> we remove the existing values saved for that 'summaryId`.</li>&#xA;</ol>&#xA;&#xA;<p>Now the <strong>problem</strong> occurs when other services which are using <strong>OLDER</strong> version of the thrift contract (<strong>Version 1.0</strong>) try to call getSummary and updateSummary.<br/>&#xA;The intention of the Older Client by calling updateSummary was to set another value for <code>summaryCost</code>. However since this client doesn't contain the object <code>summaryValues</code> it sends the Summary object with <code>summaryValues</code> as null to Server.<br/></p>&#xA;&#xA;<p><strong>This is resulting in the Server removing all existing values of <code>summaryValues</code> for that <code>summaryId</code>.</strong></p>&#xA;&#xA;<p>Is there a way to handle this in thrift? The isSet() Methods don't work here, as they try to perform a simple null check.<br/>&#xA;Every time we release a newer client with modification to existing objects, we're having to forcefully upgrade client versions of other servers even though the change is not related to them.</p>&#xA;"
49875284,Logback to Elasticsearch through yaml or properties,<spring><elasticsearch><logging><microservices><logback>,1,187,3,0.0,3,"<p>I have many spring based microservice project where I used Logback to Elasticsearch for saving all logs to Elastic search index. I have configured using xml based on some tutorials I got. The configuration is based on xml like as shown below. Instead of xml how can we configure Logback to Elasticsearch using yaml or key value property files.</p>&#xA;&#xA;<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;configuration&gt;&#xA;    &lt;springProperty scope=""context"" name=""microserviceName""&#xA;        source=""spring.application.name"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""profile""&#xA;        source=""spring.profiles.active"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESHost""&#xA;        source=""logging.esHost"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESPort""&#xA;        source=""logging.esPort"" /&gt;&#xA;    &lt;springProperty scope=""context"" name=""myESLoggingLevel""&#xA;        source=""logging.esLoggingLevel"" /&gt;  &#xA;    &lt;springProperty scope=""context"" name=""consoleLoggingLevel""&#xA;        source=""logging.consoleLoggingLevel"" /&gt; &#xA;&#xA;    &lt;appender name=""ELASTIC"" class=""com.internetitem.logback.elasticsearch.ElasticsearchAppender""&gt;&#xA;        &lt;url&gt;http://${myESHost}:${myESPort}/_bulk&lt;/url&gt;&#xA;        &lt;index&gt;logs-%date{yyyy-MM-dd}&lt;/index&gt;&#xA;        &lt;type&gt;tester&lt;/type&gt;&#xA;        &lt;loggerName&gt;es-logger&lt;/loggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;errorLoggerName&gt;es-error-logger&lt;/errorLoggerName&gt; &lt;!-- optional --&gt;&#xA;        &lt;connectTimeout&gt;30000&lt;/connectTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;errorsToStderr&gt;false&lt;/errorsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeCallerData&gt;false&lt;/includeCallerData&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;logsToStderr&gt;false&lt;/logsToStderr&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxQueueSize&gt;104857600&lt;/maxQueueSize&gt; &lt;!-- optional (default 104857600) --&gt;&#xA;        &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;!-- optional (default 3) --&gt;&#xA;        &lt;readTimeout&gt;30000&lt;/readTimeout&gt; &lt;!-- optional (in ms, default 30000) --&gt;&#xA;        &lt;sleepTime&gt;250&lt;/sleepTime&gt; &lt;!-- optional (in ms, default 250) --&gt;&#xA;        &lt;rawJsonMessage&gt;false&lt;/rawJsonMessage&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;includeMdc&gt;false&lt;/includeMdc&gt; &lt;!-- optional (default false) --&gt;&#xA;        &lt;maxMessageSize&gt;100&lt;/maxMessageSize&gt; &lt;!-- optional (default -1 --&gt;&#xA;        &lt;authentication class=""com.internetitem.logback.elasticsearch.config.BasicAuthentication"" /&gt; &lt;!-- optional --&gt;&#xA;        &lt;properties&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;host&lt;/name&gt;&#xA;                &lt;value&gt;${HOSTNAME}&lt;/value&gt;&#xA;                &lt;allowEmpty&gt;false&lt;/allowEmpty&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;severity&lt;/name&gt;&#xA;                &lt;value&gt;%level&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;thread&lt;/name&gt;&#xA;                &lt;value&gt;%thread&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;stacktrace&lt;/name&gt;&#xA;                &lt;value&gt;%ex&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;            &lt;property&gt;&#xA;                &lt;name&gt;logger&lt;/name&gt;&#xA;                &lt;value&gt;%logger&lt;/value&gt;&#xA;            &lt;/property&gt;&#xA;        &lt;/properties&gt;&#xA;        &lt;headers&gt;&#xA;            &lt;header&gt;&#xA;                &lt;name&gt;Content-Type&lt;/name&gt;&#xA;                &lt;value&gt;text/plain&lt;/value&gt;&#xA;            &lt;/header&gt;&#xA;        &lt;/headers&gt;&#xA;    &lt;/appender&gt;&#xA;&#xA;    &lt;root level=""info""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;        &lt;appender-ref ref=""ELASTIC"" /&gt;&#xA;    &lt;/root&gt;&#xA;&#xA;    &lt;logger name=""es-error-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender-ref ref=""FILELOGGER"" /&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;    &lt;logger name=""es-logger"" level=""INFO"" additivity=""false""&gt;&#xA;        &lt;appender name=""ES_FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;&#xA;            &lt;!-- ... --&gt;&#xA;            &lt;encoder&gt;&#xA;                &lt;pattern&gt;%msg&lt;/pattern&gt; &lt;!-- This pattern is important, otherwise it won't be the raw Elasticsearch format anyomre --&gt;&#xA;            &lt;/encoder&gt;&#xA;        &lt;/appender&gt;&#xA;    &lt;/logger&gt;&#xA;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;"
49836268,How to deal with authentication in a micro-services architecture,<microservices><grpc>,2,172,4,3.0,3,"<p>I am currently reading a lot about microservices but still, I don't understand some parts. I made the following draw:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/GkgRC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GkgRC.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Each microservice has 2 accesses:</p>&#xA;&#xA;<ul>&#xA;<li>REST: For http uses</li>&#xA;<li>gRPC: For intra/background communication/exchanges</li>&#xA;</ul>&#xA;&#xA;<p>If I want to login I can just send an Http Request to my Authentication service. But what about if I want to access the Stuff service that needs you to be already connected?</p>&#xA;&#xA;<p>Let say that the user wants to display the stuff available in the database STUFF, the service Stuff will first check if the ""token"" of the connected user is right, by exchanging with the Authentication service, and then return the stuff or a ""login requires request"".</p>&#xA;&#xA;<p>So the thing I don't understand is, if each services that needs a client already connected needs to exchange with Authentication, then it will create a huge internet traffic in order to check each user request.. So I though about make one Authentication service per service, but since I should have only one Database, then it's the database that will slow the traffic?</p>&#xA;&#xA;<p>Also, if I understand, each micro service should be on separate servers, not the same one?</p>&#xA;&#xA;<p>I hope I am clear, don't hesitate to ask for more details !</p>&#xA;&#xA;<p>Thanks in advance :)</p>&#xA;&#xA;<p>Max</p>&#xA;&#xA;<h1>Edit 1</h1>&#xA;&#xA;<p><strong>Based on @notionquest's answer:</strong></p>&#xA;&#xA;<p>So it should more looks like that right?</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pdOdR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pdOdR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Also, based on Peter's comment, each service can implement its own middleware (JWT as mentioned) so the API Gateway is only a ""pass-through"". However, I don't feel like it could be a nice for me since each service make a token check for each internal exchange, doesn't it?</p>&#xA;&#xA;<p>For the stuff, it's easy since it checks only 1 time the token. Now, let's say that, after the user got the stuff, he choose one and wanna buy it. Then the ""Buying service"" will call the stuff service in order the verify the price of the item, but... It will have to check the user token since the stuff is a ""on authenticated access"", so it means that ""Buying"" service and ""Stuff"" service both check the token, which add an extra check.</p>&#xA;&#xA;<p>I though about an internal guaranteed access between services but is it worth it?</p>&#xA;&#xA;<p>Also, maybe you said to implement the middleware for each service since they have a REST access, but the API Gateway would just destroy the idea of having REST access</p>&#xA;"
39672919,How to design a sails.js project with microservices architecture?,<node.js><architecture><sails.js><microservices>,2,1195,0,3.0,3,"<p>I learned about microservices from <a href=""http://microservices.io/"" rel=""nofollow"">here</a></p>&#xA;&#xA;<p>Now, I want to use microservices architecture in my next sails.js project.</p>&#xA;&#xA;<p><strong>One way I could think of is:</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>Breaking my one sails.js application into multiple small sails.js sub-projects/repositories. </p></li>&#xA;<li><p>Having one controller-model in one sub-project. For example, If we consider simple eCommerce app with entities say User, Products, Orders, etc. then there will be separate sails.js repositories for each of them with respective sails.js model-controller.  Then this single sub-repository will from my one microservice.</p></li>&#xA;<li><p>Each sub-repository then will obviously have its own configs.</p></li>&#xA;<li><p>These microservices will them communicate with each other using some HTTP node module.</p></li>&#xA;<li><p>Then writing my own <a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow"">API gateway</a> for routing in node.js, which will be responsible for invoking methods/web-services from these sub-repositories depending on the request from clients.</p></li>&#xA;</ol>&#xA;&#xA;<p>Is this the best way OR is there alternative way to design your project using microservices architecture?</p>&#xA;&#xA;<p>What will be the best way to implement inter-service communication, API gateway with sail.js? If one microservice designed with above mentioned approach get bigger, and if I have to split it up in 2, how sails.js model should be changed?</p>&#xA;"
35743527,Microservice with own UI with Spring and Thymleaf,<spring><thymeleaf><microservices><ssi>,2,590,7,0.0,3,"<p>I have three web application microservices and one gateway that include the UI. So, what i want to do is to change the app's that every microservice has his own UI and the gateway should make server side includes. Im using Thymeleaf as template engine and do the includes like this: </p>&#xA;&#xA;<p><code>&lt;div th:replace=""http://localhost:8080/#/organizations""&gt;&lt;/div&gt;</code></p>&#xA;&#xA;<p>My Problem is that the CSS and JS files are not Included from the original localhost:8080 server rather from the server with includes the content localhost:9090.</p>&#xA;&#xA;<p>This is how i include the JS and CSS files at *:8080:</p>&#xA;&#xA;<p><code>&lt;script th:src=""@{webjars/jquery/$jquery.version$/jquery.min.js}""&lt;/script&gt;</code></p>&#xA;&#xA;<p>Hope you understand my problem and someone can help...</p>&#xA;"
51602270,spring-data-rest and micro-services: Entity with @OneToOne relationship with Entity in another spring-data-rest service,<java><spring-boot><microservices><spring-data-rest>,1,56,0,0.0,3,"<p>In my spring-data-rest application I have the following entities</p>&#xA;&#xA;<pre><code>@Entity&#xA;public class com.foo.client.Foo {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    @OneToOne&#xA;    public Bar bar;        &#xA;}&#xA;&#xA;@Entity&#xA;public class Bar {&#xA;    @Id&#xA;    @Column(name = ""id"", nullable = false, length = 48)&#xA;    public String id = UUID.randomUUID().toString();&#xA;&#xA;    public String name;        &#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have JpaRepository for each entity class:</p>&#xA;&#xA;<pre><code>@RepositoryRestResource(collectionResourceRel = ""foos"", path = ""foos"")&#xA;public interface FooRepository extends JpaRepository&lt;Foo, String&gt; {&#xA;}&#xA;&#xA;&#xA;@RepositoryRestResource(collectionResourceRel = ""bars"", path = ""bars"")&#xA;public interface BarRepository extends JpaRepository&lt;Bar, String&gt; {&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8000/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8000/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>When the two entities are defined in the same spring-data-rest service endpoint then all is well and I can get the bar instance associated with the foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X GET -H ""Content-Type:application/json"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>Question: Looking at the postgresdb where entities are stored I see an association table FOO_BAR where there are two columns holding the id of each entity. However, I do not see where the URL for bar is stored and would like to understand where it is stored.</p>&#xA;&#xA;<p>Now if I split my app into two separate spring-data-rest services one foo-service for Foo and another bar-service for bar at separate ports, and also split the Repository classes between two project, then creating the association does not work and I get a 404. See modified code below:</p>&#xA;&#xA;<p>I create an instance for both Foo and Bar using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:foo:test:0""}' http://localhost:8000/foos&#xA;&#xA;&#xA;curl -i -X PUT -H ""Content-Type:application/json""&#xA;  -d '{""id"": ""urn:bar:test:0"", ""name"" : ""0""}' http://localhost:8001/bars&#xA;</code></pre>&#xA;&#xA;<p>I then associate the Bar instance to the Foo instance using:</p>&#xA;&#xA;<pre><code>curl -i -X PUT -d ""http://localhost:8001/bars/urn:bar:test:0\n""&#xA;  -H ""Content-Type:text/uri-list"" ""http://localhost:8000/foos/urn:foo:test:0/bar""&#xA;</code></pre>&#xA;&#xA;<p>This last request above gives me a 404 when Foo and Bar are managed by different spring-data-rest services.</p>&#xA;&#xA;<p>How can I get the second case to work?</p>&#xA;&#xA;<p>Note I used <a href=""http://www.baeldung.com/spring-data-rest-relationships"" rel=""nofollow noreferrer"">this</a> excellent resource for my example.</p>&#xA;"
31764926,Microservices API calls and dependency design,<design><dependencies><microservices>,2,359,0,2.0,3,"<p>Are there any best practice on designing microservices service regarding API dependency (APIs that the service is calling to)?</p>&#xA;&#xA;<p>For example if I have a ""Order Management"" (OM) service, obviously it will need to call ""User Management"" (UM) service since it will need to query user info (shipping address, email, etc) many times. If I let my OM calls UM all the time when it needs user info this will create lots of dependency on UM service. </p>&#xA;&#xA;<p>As far as I understand services are supposed to be autonomous and as decoupled as possible - but now I got a OM service that will go down everytime UM service go down.</p>&#xA;&#xA;<p>Upon searching on Google I found 3 alternatives:</p>&#xA;&#xA;<ol>&#xA;<li>Use the event-based programming to replciate user data as soon as user data is created in UM module so it is always replicated into a table inside OM</li>&#xA;<li>Use database's replciation mechanism to replicate data from UM onto OM database</li>&#xA;<li>Copy user data into order object as nested json to eliminate dependency for order query and update (but I suppose initial order creation will still need to call UM)</li>&#xA;</ol>&#xA;&#xA;<p>Are there any best practices on the challenge here or are there any rules of thumb of deciding which design approach to take?</p>&#xA;"
39268365,Nested GraphQL servers / microservices,<microservices><graphql><apollo-server>,1,291,1,1.0,3,<p>I would like to replace all my REST APIs with GraphQL (apollo-server preferred). It's clear to me how to use GraphQL in monolithic apps but it's not clear how to do it for microservices.</p>&#xA;&#xA;<p>The main API server consists of multiple microservices where each microservice exposes its own REST API through which the central API server communicates with it. I would like to replace all these REST APIs with GraphQL thus I would get microservices as nested GraphQL servers communicating with each other through GraphQL instead of REST.</p>&#xA;&#xA;<p>The problem that I'm facing is how to easily build a GraphQL query string for microservices based on the received attributes in the resolver of the main GraphQL server. There is no way to tell GraphQL to return all the fields for microservice. The best way would be to simple forward just a part of a the main query further to a microservice. </p>&#xA;&#xA;<p>Any ideas? Do you think that REST is still more appropriate for microservices then GraphQL?</p>&#xA;
46404449,Micro service architecture for Angular2,<angular><design-patterns><architecture><microservices>,1,657,4,2.0,3,"<p>If we take an enterprise  angular 2 web app it has several modules(screens) such as Customer management, Reservations, Booking management, Reporting and etc....</p>&#xA;&#xA;<p>What we normally do is we create common components in a component library and use them on main angular application. The main angular app contains all the modules(screens) with REST API integrations(assuming backed is REST). When app is getting bigger &amp; bigger compile time and rendering consuming more time &amp; resources. Also if one particular area is having a issue we cannot have a release since all are bundle to one app.</p>&#xA;&#xA;<p>As you all know <strong>Micro service architecture</strong> is a method of developing software systems that has grown in popularity. So, my question is can we apply same architecture for these type of enterprise angular 2 apps?. </p>&#xA;&#xA;<p>It is like this. We have a customer management as a separate angular app. Again Booking management is another angular app. Reporting is another app. These apps are going to be separate war files when deploying to the web server. </p>&#xA;&#xA;<p>Once we have developed such loosely coupled apps this will reduce the over head of project size, compile time &amp; resources. Also this will make unit testing more easier. Particular set of developers are only considering the only one unit of the module.</p>&#xA;&#xA;<p>Kindly share your expert thoughts about this</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
46471625,Multiple microservice symfony application share vendor folder,<php><symfony><composer-php><share><microservices>,2,314,5,1.0,3,"<p>We are working on a new web project, with a microservice architecture.</p>&#xA;&#xA;<p>We will need around 5 Front Web project, and about 5 API microservice orchestrate with an API manager.</p>&#xA;&#xA;<p>We plan to use Symfony2 Framework, but I think it will be too Heavy. I mean because by the instance of the composer that will download all around the same library from symfony component, core... and same library used for each project (phpmailer for example).</p>&#xA;&#xA;<p>Actually, I was asking myself about a great sharing strategy for the vendor folder assuming that each SF2 project would use a share vendor folder and compute all library in a unique folder.&#xA;We need all the same version for each library in each project.</p>&#xA;&#xA;<p>Does somebody have some experiment on this kind of sharing? Best practices? Is it preferable to have one vendor folder per project? </p>&#xA;&#xA;<p>Open discution !</p>&#xA;&#xA;<p>Cheers.</p>&#xA;"
34020234,Communication between Node.js microservices,<json><node.js><express><architecture><microservices>,1,1519,2,0.0,3,"<p>I'm creating an application with Node.js using microservices architecture. I'm trying to find the best way of communication between nodes. I have a Java background so the best option I can imagine is something like SOAP, where you create a proxy object and by calling it's method a request to a remote node would be made via http.</p>&#xA;&#xA;<p>Currently I only see an option of direct calls like </p>&#xA;&#xA;<pre><code>http.get(""remote-node/api/method1"", function(res) {&#xA;}).on('error', function(e) {&#xA;  console.log(""Got error: "" + e.message);&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However I don't think it's convenient. Are there better approaches?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
38070572,How to architecture Microservice & OpenID connect?,<microservices><openid-connect><oauth2>,1,1235,0,1.0,3,"<p>We have three microservices: microA, microB &amp; microC.</p>&#xA;&#xA;<ul>&#xA;<li>microA &amp; microB are powering product 1.</li>&#xA;<li>microA &amp; microC are powering product 2.</li>&#xA;</ul>&#xA;&#xA;<p>Obviously, we would need a security layer, in our case implementing an ""OpenID Connect"" provider fits well with the business needs. We add to the stack the OpenID provider.</p>&#xA;&#xA;<p>The user/rights management is quite easy &amp; natural: we associate the OpenId identifier of the user on each microservices to a subset of rights:</p>&#xA;&#xA;<p>For example on the service microA, we store that the user OpenID XXX can do this and that. it's isolated on the microservice level. Respect the boundaries of our context. Fine.</p>&#xA;&#xA;<p>When the user login with OpenID on product1, we grant an access token to the user + an Id token.</p>&#xA;&#xA;<p>The situation becomes more complex when product1 expose an API that third-party use.</p>&#xA;&#xA;<p>Now, let say that my user comes to the third-party webapp and is prompted to login &amp; allow the third-party to get some rights on product1 API.</p>&#xA;&#xA;<p>If I understand correctly OpenID connect, it's all about authentication over OAuth2, but how do we handle classic OAuth2 scope management then?</p>&#xA;&#xA;<p>The best scenario I have found is:</p>&#xA;&#xA;<ol>&#xA;<li><p>make the whole OpenID connect to have the authentication info </p></li>&#xA;<li><p>and then make another full OAuth2 process to another Authorization server to ask the user to grant some scopes to the third party?</p></li>&#xA;</ol>&#xA;&#xA;<p>which means that on the third-party:</p>&#xA;&#xA;<ul>&#xA;<li>the user will be prompted to login on the OpenID Provider </li>&#xA;<li>then redirected and prompted to accept the scope requested</li>&#xA;</ul>&#xA;&#xA;<p>Is that correct? If yes, OAuth2 server flow is like 4 HTTP requests to the end user, so performing it twice is like executing eight requests to get the Authentication + Authorization flow done. Seems too massive.</p>&#xA;"
45167593,Authorization of actions across microservices,<web-services><rest><authorization><microservices><event-sourcing>,2,108,1,1.0,3,"<p>A modern multi-user web application imposes a lot of restrictions on the actions that users can perform. In other words, the actions require authority. For example, a user can only change its own personal data, and only members of a group can post content to that group. In a classic monolith application, such restrictions are easily enforced by joining several database tables and acting according to the results of queries. However, with microservices, it becomes much less clear where and how such limitations should be handled.</p>&#xA;&#xA;<p>For the sake of argument, consider a Facebook clone. The whole application consists of several parts:</p>&#xA;&#xA;<ul>&#xA;<li>A front-end, written in JS and other web technologies</li>&#xA;<li>A backend consisting of a number of microservices</li>&#xA;<li>An API for retrieving and submitting data to the backend, i.e. a gateway</li>&#xA;</ul>&#xA;&#xA;<p>As for the business logic, there are (among others) two well-known entities:</p>&#xA;&#xA;<ul>&#xA;<li>Events (as in concerts, birthday parties etc.)</li>&#xA;<li>Posts (text entries existing on walls, pages, events etc.)</li>&#xA;</ul>&#xA;&#xA;<p>Suppose that these two entities are managed by separate services, EventService and PostService. Then consider the following constraint:</p>&#xA;&#xA;<blockquote>&#xA;  <p>A post to an event can be deleted by two kinds of users: the author of the post, and the host(s) of the event.</p>&#xA;</blockquote>&#xA;&#xA;<p>In a monolith, this constraint would've been conceptually very easy to deal with. Upon receiving a request to delete a post, supplying the post id and user id,</p>&#xA;&#xA;<ol>&#xA;<li>Fetch the event which the post belongs to.</li>&#xA;<li>Check if the user is the author of the post.</li>&#xA;<li>If yes, delete the post. If not, fetch the hosts of the event.</li>&#xA;<li>Check if the user is among the hosts.</li>&#xA;<li>If yes, delete the post.</li>&#xA;</ol>&#xA;&#xA;<p>However, with a microservice strategy, I have a hard time figuring out how to divide the responsibilities of an operation like this across the services.</p>&#xA;&#xA;<h2>Alternative 1</h2>&#xA;&#xA;<p>An easy way around it would be to put logic like this in the gateway. That way, the same procedure as described above could essentially be performed, but with calls to the services instead of directly to the database. Rough sketch:</p>&#xA;&#xA;<pre class=""lang-js prettyprint-override""><code>// Given postId and userId&#xA;// Synchronous solution for presentational purposes&#xA;&#xA;const post = postClient('GET', `/posts/${postId}`);&#xA;const hosts = eventClient('GET', `/events/${post.parentId}/hosts`);&#xA;const isHost = hosts.find(host =&gt; host.id == userId);&#xA;&#xA;if (isHost) {&#xA;    postClient('DELETE', `/posts/${postId}`);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, I'm not happy with this solution. Once I start putting logic like this in the gateway, it'll become very tempting to <em>always</em> do it, as it's a quick and simple way to get things done. All business logic would eventually amass in the gateway, and the services would become ""stupid"" CRUD endpoints. This would defeat the purpose of having separate services with well-defined areas of responsibility.  Furthermore, it could be slow as it could give rise to a high number of calls to the services when operations are getting more complex.</p>&#xA;&#xA;<p>I would essentially be reinventing the monolith, replacing database queries with slow and limited network calls.</p>&#xA;&#xA;<h2>Alternative 2</h2>&#xA;&#xA;<p>Another option would be to allow unlimited communication <em>between</em> services, allowing PostService to simply ask EventService whether the user is a host of the event in question before performing the delete. However, I'm afraid that having a potentially large number of microservices communicating with each other could introduce a lot of coupling in the longer run. Experts seem to generally advise against direct inter-service communication.</p>&#xA;&#xA;<h2>Alternative 3</h2>&#xA;&#xA;<p>With a solid system for publishing and subscribing to events, the services could stay updated about what happens in other services. For example, every time a user is promoted to host in EventService, an event would be posted (e.g. <code>events.participant-status-changed, {userId: 14323, eventId: 12321, status: 'host'}</code>). PostService could subscribe to the event and remembering this fact when a request to delete a post is received.</p>&#xA;&#xA;<p>However, I'm not quite happy with this one either. It'd create a very intricate and error-prone system, where an unhandled (but potentially rare) event could make services go out of sync. Also, there's a risk that logic would end up in the wrong place. For example, the constraint in this question would be handled by PostService even though conceptually it's a property of the event entity.</p>&#xA;&#xA;<p>I should stress though that I'm very optimistic about the usefulness of events when implementing applications using microservices. I'm just not sure they are the answer to this category of problems.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>How would you tackle this hypothetical, but quite realistic difficulty?</p>&#xA;"
45351222,Is it possible to proxy a POJO in microservices application?,<java><spring-boot><microservices>,1,140,2,0.0,3,"<p>I would like to avoid duplicating my POJOs in a microservices application, so I am wondering if there is a way to do that (like proxying)?</p>&#xA;&#xA;<p>I mean, is there a way for a <code>Service A</code> to access POJOs (or other classes/interfaces) defined inside a <code>Service B</code> without physically creating these POJOs classe files in <code>Service A</code>? </p>&#xA;&#xA;<p>The big big challenge in a microservice architecture is that point and I didn't find a way to solve it.</p>&#xA;"
39591223,Can SOA and Microservices co-exist?,<design><architecture><soa><microservices>,3,379,0,0.0,3,<p>It is often documented to build a microservice based architecture from a monolith. Is it also possible to have microservices in SOA based architecture?</p>&#xA;
39540366,Go-kit real world example with inter microservice data transfers,<go><microservices>,1,947,0,4.0,3,"<p>I try to work with go-kit (gokit.io) and to build real-work application with it.&#xA;I look through examples. These examples are great. But I do not understand how to do services to service communications / data transfers in go-kit framework. </p>&#xA;&#xA;<p>I can see ""real-world"" shipping app, but I do not understand how it could be ""real world"" micro-services. I can see in sources that, for example, they build the booking service just passing foreign repositories into service</p>&#xA;&#xA;<pre><code>type service struct {&#xA;    cargoRepository         cargo.Repository&#xA;    locationRepository      location.Repository&#xA;    routingService          routing.Service&#xA;    handlingEventRepository cargo.HandlingEventRepository&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and later they get data from repositories (this repository belongs to foreign micro-service) just calling the method:</p>&#xA;&#xA;<p><code>locationRepository.Find(...)</code></p>&#xA;&#xA;<p>Could someone please explain me:</p>&#xA;&#xA;<ul>&#xA;<li>how to build micro-service to micro-service communications in go-kit framework? Just show me the way / pattern, please. I do not understand it at all.</li>&#xA;</ul>&#xA;&#xA;<p>I see it as they just share direct access to data. But in real world micro-services, I expected that micro-services will communicate to each other to get needed data. And I do not understand how to do it in go-kit framework.</p>&#xA;"
39601492,how monolith spring 3 application will communicate with microservice?,<spring><spring-boot><microservices><netflix-ribbon>,1,238,2,0.0,3,<p>I have one monolith spring web application developed using spring 3.1 and spring-security 3.1 with Java 7 and it is deployed on tomcat 7. </p>&#xA;&#xA;<p>Now I have a new requirement where I have to create a micro-service for a new module using spring boot with java 8. This micro-service will be deployed separately on different EC2 instance. </p>&#xA;&#xA;<p>I am looking for suggestion/idea to access new microservice from my existing spring web application. </p>&#xA;&#xA;<p>How to perform <em>inter process communication</em> within these two spring application?</p>&#xA;&#xA;<p>Can someone provide me any help/pointer?</p>&#xA;
39967784,Microservice vs SOA differs,<soa><microservices>,5,712,0,1.0,3,"<p>I was looking for differences b/w SOA and Microservices architecture style&#xA;and found a good link <a href=""https://www.infoq.com/articles/boot-microservices"" rel=""nofollow noreferrer"">https://www.infoq.com/articles/boot-microservices</a></p>&#xA;&#xA;<p>It Says:<br>&#xA;As a successor to ""Service Oriented Architecture"" (SOA), microservices can be categorized in the same family of ""distributed systems"", and carry forward many of the same concepts and practices of SOA. Where they differ, however, is in terms of the scope of responsibility given to an individual service. In SOA, a service may be responsible for handling a wide range of functionality and data domains, while a general guideline for a microservice is that it is responsible for managing a <strong>single data domain</strong> and the corresponding functions around that domain.</p>&#xA;&#xA;<p>Please help me to understand :<br>&#xA;The meaning of single data domain (recommended for microservice).&#xA;is it saying that a separate Microservice has to be build to manage a single domain/entity (and associated/composite domain/entities with this single domain/entity). Becasue if this case, then there will be many(~20 to ~50) microservices even to implement a basic functionality (enterprise) application</p>&#xA;&#xA;<p>Edit:&#xA;I have gone through the link <a href=""https://stackoverflow.com/questions/25501098/difference-between-microservices-architecture-and-soa"">Difference between Microservices Architecture and SOA</a>, but it explains, that it is same on the first two tenets, and different on 3rd point (in SOA, Services share schema and contract, not class), but that is SOAP contracts, but then what is the difference b/w SOA (with REST) vs Microservices (which is mostly with REST)</p>&#xA;"
41914911,microservice based event store,<microservices><cqrs><event-store><eventsource>,1,244,0,0.0,3,"<p>Unfamiliar with all the details of domain driven design, would it make sense  in a microservice architecture to think of each service as it's own domain and in turn build an event store per service?</p>&#xA;&#xA;<p>Not totally sure what the trade-offs might be from a single monolithic event store for the entire system. For example, more difficulty replaying conditions in the system or debugging cross service dependencies.</p>&#xA;"
41036330,Store private key in microservices,<microservices><private-key><public-key>,1,140,0,1.0,3,"<p>There are some microservice which communicating with each other with rsa encrypted messages. The private keys are in files currently, what is the best practice to store the private and public keys in the containers? The current solution is in the /etc/ssl, but this is a little bit hard to manage and not to safety.</p>&#xA;"
50134195,Authorization between micro services and users,<architecture><microservices>,1,127,0,1.0,3,"<p>What would be best way to handle access and authorization between microservices and users?</p>&#xA;&#xA;<p>I'm building an application on microservice architecture. Services speak to each other through REST. there are endpoints that should be accessed only by other microservices and not directly by users, some endpoints are public and some would require users to register or have admin privileges. On top of that Users will have roles like admins and regular users.</p>&#xA;&#xA;<p>I'm trying to figure out if Oauth2 and scopes is the best approach for what I'm trying to achieve. e.g. each microservice will have ""user"" that have permission on certain scopes like ""service1-place-order"". </p>&#xA;"
51889526,Why would we go for micro-services if there is requirement for lower latency code?,<java><microservices>,1,63,8,1.0,3,"<p>In a monolith, we just need to either make a function call or method invocation as opposed to inter process communication. Can someone familiar with micro-services architecture help to understand reasons how you can use micro services for developing low latency applications?</p>&#xA;&#xA;<p>I think Chronicle framework claims that you can develop micro-services based products and use chronicle queues to communicate without incurring network hop latency. </p>&#xA;"
42949138,Rails: Microservice architecture with dedicated authorization service and app services using Knock (JWT),<ruby-on-rails><ruby><jwt><microservices>,1,461,0,0.0,3,"<p>I'm now trying to separate monolithic application into microservices (dedicated rails app's) and wanted to know - is there a solution to move authorization service from each service?</p>&#xA;&#xA;<p>For example, I have 6 different Rails API services with 'knock' gem that have user model for authentication purpose.&#xA;All those services sharing one user database.</p>&#xA;&#xA;<p>I want to implement dedicated service with user model, but how other services will verify users with given tokens?</p>&#xA;&#xA;<p>Also I want to able to control what services user can and can't use. So there should be AccessRole service?</p>&#xA;&#xA;<p>Draft case:</p>&#xA;&#xA;<ol>&#xA;<li>User go to 'articles' (frontend UI client)</li>&#xA;<li>auth_service is validating token from client</li>&#xA;<li>access_service got message from auth_service somehow and validating user's role to access 'articles' resource.</li>&#xA;<li>articles_service send response to client with json data.</li>&#xA;</ol>&#xA;&#xA;<p>Here some more questions:</p>&#xA;&#xA;<ol>&#xA;<li>How access_service will communicate with auth_service? Should they use one user database to verify user's credentials and role?</li>&#xA;<li>articles_service and so on - should they become private services without access to public and act as black boxes to user?</li>&#xA;</ol>&#xA;"
49443206,Difference between OSGI and microservices,<osgi><microservices><osgi-bundle>,2,1173,1,0.0,3,<p>When would you like to choose for OSGI modules than micro services and is there anything i can do with micro services that i can not do with OSGI modules?</p>&#xA;
40932850,Mongodb IsoDate and the issue with if-modified-since on microservices,<java><mongodb><microservices>,1,170,2,1.0,3,"<p>When I insert a document on my MongoDB using spring data, I do the following:</p>&#xA;&#xA;<pre><code>Update update = new Update();&#xA;update.currentDate(""lastModified"");&#xA;mongoTemplate.upsert(query, update, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>I'm using the currentDate of MongoDB, because I want to save the date that MyDocument was last modified with the date where my MongoDB database is located. </p>&#xA;&#xA;<p>Based on the <a href=""https://www.ietf.org/rfc/rfc2616.txt"" rel=""nofollow noreferrer"">spec</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>The If-Modified-Since request-header field is used with a method to&#xA;     make it conditional: if the requested variant has not been modified&#xA;     since the time specified in this field, an entity will not be&#xA;     returned from the server; instead, a 304 (not modified) response will&#xA;     be returned without any message-body.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, the purpose of saving this date is to verify if MyDocument was modified or not based on the received date.</p>&#xA;&#xA;<p>So, when I execute the update, the following IsoDate is created on the database:</p>&#xA;&#xA;<pre><code>ISODate(""2016-12-02T12:11:33.083Z"")&#xA;</code></pre>&#xA;&#xA;<p>So, when a client wants to know if the document has changed, they send me back this date, and I query on the database:</p>&#xA;&#xA;<pre><code>    Query query = new Query(where(""id"").is(filter.getId()));&#xA;    Criteria criteria = Criteria.where(""lastModified"").gt(filter.getLastModified());&#xA;    query.addCriteria(criteria);&#xA;    return mongoTemplate.findOne(query, MyDocument.class);&#xA;</code></pre>&#xA;&#xA;<p>This works perfectly, except for one problem: The spec says that the header if-modified-since has the following format:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT</p>&#xA;</blockquote>&#xA;&#xA;<p>Which means that the milliseconds is not passed on the if-modified-since header. However, MongoDB IsoDate saves the current date with milliseconds. So, when two dates are exactly the same, the query will not return 304 Not Modified, but it will return the entire resource, because the query will be the following:</p>&#xA;&#xA;<pre><code>{ ""id"" : 123, ""lastModified"" : { ""$gt"" : { $java : 2016-12-02T12:11:39.000Z } } }&#xA;</code></pre>&#xA;&#xA;<p>Since the client does not send the milliseconds, the java put the milliseconds as zeros ( 2016-12-02T12:11:39.<strong>000</strong>Z), which means that &#xA;the date on my database is greater than the date sended by my client:</p>&#xA;&#xA;<p>2016-12-02T12:11:33.083Z > 2016-12-02T12:11:39.000Z </p>&#xA;&#xA;<p>Because of the 83 milliseconds. </p>&#xA;&#xA;<p><strong>The final question is</strong>: What it is the correct way to solve this problem, and work correctly as the specs for if-modified-since suggests?</p>&#xA;"
47007159,Looking for JWT Auth microservice example,<node.js><authorization><jwt><microservices>,1,982,0,1.0,3,"<p>I am wanting to build a authentication/authorization service using NodeJS, Mongo, and JWT.  This service would be a micro-service that handles requests not only from my API Gateway before allowing requests, but from other services that might want to check auth and roles. I am assuming that all other services will use this Auth Service to validate the JWT as well as roles, etc.</p>&#xA;&#xA;<p>Hopefully this diagram better explains what I am looking for.&#xA;<a href=""https://i.stack.imgur.com/NDuCY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NDuCY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Can anyone point me to a resource that might help me learn how to do this with NodeJS?</p>&#xA;"
48279479,How to query in a Event Driven Microservice architecture?,<microservices><cqrs><event-driven>,3,308,0,1.0,3,"<p>Let suppose the following simple UC based on a CQRS architecture:</p>&#xA;&#xA;<p>We have a backend managing a Business Object, let says a Movie.</p>&#xA;&#xA;<ul>&#xA;<li>This backend is composed of 2 Microservices: a CommandManager (Create/Update/Delete Movie) and a QueryManager (Query Movie)</li>&#xA;<li>We have a frontend that offer a web page for creating a new Movie and this action lead automatically to another web page describing the Movie. </li>&#xA;</ul>&#xA;&#xA;<p>A simple way to do that is:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend make a POST request to the CommandManager</li>&#xA;<li>The CommandManager write the new movies to the datastore and return the movie key</li>&#xA;<li>The frontend make a GET using this key to the QueryManager</li>&#xA;<li>The QueryManager looks for the Movie in the Datastore using the key and return it.</li>&#xA;<li>The frontend deliver the page with the Movie Information.</li>&#xA;</ul>&#xA;&#xA;<p>Ok, now I want to transform this UC in a more Event Driven way. Here is the new flow:</p>&#xA;&#xA;<ul>&#xA;<li>A web page collect movie information using a form and send them to the frontend.</li>&#xA;<li>The frontend write a Message in the BUS with the new movie information</li>&#xA;<li>The CommandManager listen the BUS and create the new movies in the datastore. Eventually, it publish a new message in the BUS specifying that a new Movie has been created.</li>&#xA;</ul>&#xA;&#xA;<p>At this point, the frontend is no more waiting for a response due to the fact that this kind of flow is asynchronous. How could we complete this flow in order to forward the user to the Movie Information Web page? We should wait that the creation process is done before querying the QueryManager. </p>&#xA;&#xA;<p>In a more general term, in a asynchronous architecture based on bus/event, how to execute Query used to provide information in a web page?</p>&#xA;"
51542197,Async Flows Design in Lagom or Microservices,<domain-driven-design><microservices><lagom>,1,67,7,5.0,3,"<p>How to design asyn flows in Lagom ? </p>&#xA;&#xA;<p>Problem faced: In our product we have a Lead Aggregate which has a User Id (represents the owner of the lead), Now User has a limitation which says one user can have max of 10 Lead associated with this. We designed this by creating a separate Service ResourceManagement and when a User asks for Picking a Lead, we send a Command to LeadAggregate which generates a Event LeadPickRequested. On ProcessManager Listen to the event and asks for the Resource From ResourceManagement, on Success send Command to LeadAggregate - MarkAsPicked and on this send Push notification to the User that Lead is Picked but from building the UI perspective its very difficult and same cannot be done for exposing our API to third party. </p>&#xA;&#xA;<p>One Sol. we have done is when request is received on Service save a RequestID Vs Request Future . in Command Add the request Id and when the LeadAggregate finally change into Picked State or Picked Failure a PM listen to the event , checks if a RequestFuture is there for the request Id , then complete the future with correct response. This way it works as Sync API for the end User. </p>&#xA;&#xA;<p>Any Better Sol. for this</p>&#xA;"
45853546,"Two processes reside in different AP servers and refer to a same boolean flag. (Spring, Java)",<java><spring><microservices><consistency>,4,41,0,0.0,3,"<p>I am using Spring Framework to develop a web application. I have two services which are going to store some processed results into one table T in Database. The logic now is:</p>&#xA;&#xA;<p><strong>Service A</strong></p>&#xA;&#xA;<pre><code>for all items:&#xA;    result = func(item)&#xA;    store result to Table T (with status = new)&#xA;is_running = False&#xA;</code></pre>&#xA;&#xA;<p><strong>Service B</strong></p>&#xA;&#xA;<pre><code>for some items:&#xA;    if is_running == False:&#xA;        result = func(item)&#xA;        store result to Table T (with status = new)&#xA;    else:&#xA;        store result to Table T (with status = inprogress)&#xA;</code></pre>&#xA;&#xA;<p>The boolean flag <code>is_running</code> will be a field in Service A.</p>&#xA;&#xA;<p>Since we have MicroService Architechture for the domain server, Service A and Service B may reside in different AP servers. How can I ensure Servie A and Service B refer to the same <code>is_running</code>?</p>&#xA;&#xA;<p>Is it possible to use <a href=""https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html#beans-factory-scopes"" rel=""nofollow noreferrer"">Spring's bean scope</a> to achieve this?</p>&#xA;"
46002727,What is the difference between an API-Gateway and an Edge Service?,<microservices>,1,935,0,0.0,3,"<p>I understand the concept behind an API gateway as described by Richardson:</p>&#xA;&#xA;<p><a href=""http://microservices.io/patterns/apigateway.html"" rel=""nofollow noreferrer"">http://microservices.io/patterns/apigateway.html</a></p>&#xA;&#xA;<p>But what is the difference to an Edge service. Is this a concrete implementation of the API gateway pattern?</p>&#xA;"
48458627,How to filter and sort data from multiple microservices?,<architecture><microservices>,1,362,0,3.0,3,"<p>We have microservices which work with different, but related data. For example, ads and their stats. We want to be able to filter, sort and aggregate this related data for UI(and not only for it). For example, we want to show to a user ads which have 'car' in their text and which have more than 100 clicks.</p>&#xA;&#xA;<p><strong>Challenges:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There could be a lot of data. Some users have millions of rows after filtration</li>&#xA;<li>Services doesn't have all the data. For example, for statistics service ad without stats == non existent ad. It doesn't know anything about such ads. But sorting and filtration should work anyway(ad without stats should be considered as ad without zero clicks)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Requirements:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Eventual consistency within couple of seconds is OK</li>&#xA;<li>Data loss is not acceptable</li>&#xA;<li>5 to 10 seconds filtration and sorting for big clients with millions of rows is OK</li>&#xA;</ul>&#xA;&#xA;<p><strong>Solutions we could think of:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Load all data required by query from all services and filter and sort it in memory.</li>&#xA;<li>Push updates from services to Elasticsearch(or something like this). Elastic handles query and returns ids of desired entities which then loaded from services.</li>&#xA;<li>One big database for all services which has everything</li>&#xA;</ul>&#xA;&#xA;<p>What should we pay attention to? Are there other ways to solve our problem?</p>&#xA;"
40702179,micro service web app with AWS,<amazon-web-services><amazon-s3><amazon-ec2><microservices>,1,601,0,2.0,3,"<p>I am developing a web application for image upload and retrieval with AWS cloud services using a micro service architecture.&#xA;I am new to AWS and micro service architecture, please help me map the components of the architecture to AWS components.</p>&#xA;&#xA;<p>Do i consider each micro service to run on one EC2 instance with auto scaling and load balancing?&#xA;Or do I run each micro service on one EC2 cluster?</p>&#xA;&#xA;<p>If i put my static html files in an S3, how can i call database methods to load the html pages with content? &#xA;Is it by calling am API gateway from the client?</p>&#xA;&#xA;<p>I have searched the web, but was unable to find a tutorial which implements multiple services as micro services using AWS EC2 / ECS.</p>&#xA;&#xA;<p>Please help me figure out how to map my requirements and if there are any tutorials on implementing a similar app, will be very helpful.</p>&#xA;&#xA;<p>Thank you in advance! :)</p>&#xA;"
43396744,Microservices UI Frontend with Java and ReactJS Server Side Rendering,<java><reactjs><microservices><serverside-rendering>,2,3077,9,3.0,3,"<p>My current design is to have clients connect to my (Java) Web API Gateway using a browser, the Web API Gateway will call each (Java) microservice to get their JSON data and return it to the UI component that made the request on the client. </p>&#xA;&#xA;<p>The only client side rendering will be from each ReactJS UI component for recurring requests to the gateway. </p>&#xA;&#xA;<p>On the server side the full HTML view will be rendered prior to being sent back to the client. </p>&#xA;&#xA;<pre><code>Client browser&#xA;&#xA;     ▼ (Request Dashboard View)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Request microservice JSON data)&#xA;&#xA;Microservice A JSON Data&#xA;Microservice B JSON Data&#xA;Microservice C JSON Data&#xA;Microservice D JSON Data&#xA;&#xA;     ▼ (Return JSON Data to gateway)&#xA;&#xA;Web API Gateway&#xA;&#xA;     ▼ (Render HTML and return to Client)&#xA;&#xA;Client browser&#xA;&#xA;     ▼ (ReactJS UI Components request data from API Gateway)&#xA;</code></pre>&#xA;&#xA;<p>This is where it gets unclear, would it be best to have each UI component communicate with the Web API Gateway or the parent Microservice it came from to get data? </p>&#xA;&#xA;<p>Considerations</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components talk to the Web API Gateway seems reasonable but will couple the microservices to the gateway, meaning to expose a new API on the microservice the gateway will also need to be updated. </li>&#xA;<li>Having the UI components talk directly to its Microservice for data removes the need to also update the Web API Gateway, keeping them less coupled. But this then exposes the Microservice to external calls from the client browser. </li>&#xA;</ul>&#xA;&#xA;<p>Design Decisions</p>&#xA;&#xA;<ul>&#xA;<li>Having the UI components within the API gateways creates a UI monolith as opposed to having each microservice responsible for its own UI component. Using the monolithic approach simplifies the solution and also avoids the complexities of having to aggregate each microservices UI component when the client requests a particular view. </li>&#xA;</ul>&#xA;&#xA;<p>Tools:</p>&#xA;&#xA;<ul>&#xA;<li>Java</li>&#xA;<li>Nashorn</li>&#xA;<li>Dropwizard </li>&#xA;<li>ReactJS</li>&#xA;<li>Gradle</li>&#xA;<li>Webpack</li>&#xA;<li>NodeJS</li>&#xA;<li>NPM </li>&#xA;</ul>&#xA;&#xA;<p><strong>How do I aggregate multiple microservice ui components on the Web API Gateway using Java and ReactJS then serve this pre-rendered HTML data along with the JavaScript application to the client?</strong></p>&#xA;&#xA;<p><strong>Helpful References:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Server side rendering with Java 8 and Nashhorn <a href=""http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/"" rel=""nofollow noreferrer"">http://winterbe.com/posts/2015/02/16/isomorphic-react-webapps-on-the-jvm/</a></li>&#xA;</ul>&#xA;"
42562820,DDD. Shared kernel? Or pure event-driven microservices?,<domain-driven-design><microservices><bounded-contexts>,3,1670,1,1.0,3,"<p>I'm breaking my system into (at least) two bounded-contexts: study-design and survey-planning.</p>&#xA;&#xA;<p>There's a concept named ""subject"" (potential subject for interviewing) in the study-design context. We also maintain associations between subjects and populations in that domain.</p>&#xA;&#xA;<p>Now, in the survey-planning, we also need (some) information about the subject (for example: for planning a visit, or even for anticipated selection of questionnaire, in case the population the subject belongs to is known beforehand).</p>&#xA;&#xA;<p>So, I need that ""subject"" in both contexts. </p>&#xA;&#xA;<p>What approach should I pick? Having a shared kernel, as explained in Eric Evans DDD book? I don't mind (at least for now) having the two contexts sharing the same database.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/FKtJ9.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FKtJ9.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Or... should I go pure microservice? Meaning: those two can't / shouldn't share database..., and in that case I might have to go the mirroring / duplicating route through event passing: <a href=""https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts"" rel=""nofollow noreferrer"">https://www.infoq.com/news/2014/11/sharing-data-bounded-contexts</a></p>&#xA;&#xA;<p>Any thoughts on which one is better, for the above situation?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
42404800,How to build front end for Microservices,<user-interface><architecture><microservices>,1,477,1,0.0,3,"<p>Let's say I have a dozen microservices. I am wondering where should the front end go. Let's say front end is HTML, Javascript, CSS. One way is to make it a separate service handled by a UI team. So it can form the API gateway where the request from browser comes in first. But this seems against the idea of independent self contained services.<br>&#xA;browser ------> API Gateway ------> Microservices&#xA;<br>&#xA;In <a href=""https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/"" rel=""nofollow noreferrer"">this</a> link, they say that Javascript and CSS should be served by microservices. API gateway should serve only the HTML page. THere is a nice diagram showing this >>&#xA;<a href=""https://i.stack.imgur.com/1suda.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1suda.png"" alt=""microservices with UI""></a>&#xA;I have two questions<br>&#xA;1. How will this be implemented? How will API gateway serve the JS and CSS files in microservices, and maybe HTML fragments too. How will initial page load happen and from where.<br>&#xA;2. Now we are mingling HTML into microservices. But what if I want to serve Android and iOS apps too? THanks.</p>&#xA;"
31717615,Databases in a microservices pattern/architecture,<web-services><rest><design-patterns><microservices>,2,453,0,3.0,4,"<p>I'm trying to understand the layout of the microservices pattern. Given that each microservice would run on its on VM (for sake of example) how does the database fit into this architecture? </p>&#xA;&#xA;<p>Would each service, in turn, connect to the consolidated database to read/write data? </p>&#xA;&#xA;<p>Thanks for any insight</p>&#xA;"
26529567,What are the strategies available for doing pagination or filtering data using microservices architecture?,<filter><pagination><filtering><paging><microservices>,1,743,0,1.0,4,<p>Usually when you have a monolithic application or data model then you can create a SQL joining different tables and apply filters to them. Then once you get resultset back you can page that data as well. But if you are using microservice architecture the data model might be disparate. I heard netflix actually takes it to an extreme where they have every table  exposed as a microservice. How can you handle paging and filtering in this case?</p>&#xA;&#xA;<p>I know they use API Gateway pattern which  could act as aggregation layer (probably this is where RxJava like projects come in). It would be great to have ideas from people using microservices or tackle this problem.</p>&#xA;
30288968,Micro Services and noSQL - Best practice to enrich data in micro service architecture,<microservices>,4,2100,0,5.0,4,"<p>I want to plan a solution that manages enriched data in my architecture.<br>&#xA;To be more clear, I have dozens of micro services.<br>&#xA;let's say - Country, Building, Floor, Worker.<br>&#xA;All running over a separate NoSql data store.  </p>&#xA;&#xA;<p>When I get the data from the worker service I want to present also the floor name (the worker is working on), the building name and country name.</p>&#xA;&#xA;<p><strong>Solution1.</strong><br>&#xA;Client will query all microservices.<br>&#xA;Problem - multiple requests and making the client be aware of the structure.<br>&#xA;I know multiple requests shouldn't bother me but I believe that returning a json describing the entity in one single call is better.</p>&#xA;&#xA;<p><strong>Solution 2.</strong><br>&#xA;Create an orchestration that retrieves the data from multiple services.<br>&#xA;Problem - if the data (entity names, for example) is not stored in the same document in the DB it is very hard to sort and filter by these fields.</p>&#xA;&#xA;<p><strong>Solution 3.</strong><br>&#xA;Before saving the entity, e.g. worker, call all the other services and fill the relative data (Building Name, Country name).<br>&#xA;Problem - when the building name is changed, it doesn't reflect in the worker service. </p>&#xA;&#xA;<p><strong>solution 4.</strong><br>&#xA;(This is the best one I can come up with).<br>&#xA;Create a process that subscribes to a broker and receives all entities change.<br>&#xA;For each entity it updates all the relavent entities.<br>&#xA;When an entity changes, let's say building name changes, it updates all the documents that hold the building name.<br>&#xA;Problem:&#xA;Each service has to know what can be updated.&#xA;When a trailing update happens it shouldnt update the broker again (recursive update),  so this can complicate to the microservices.</p>&#xA;&#xA;<p><strong>solution 5.</strong><br>&#xA;Keeping everything normalized. Fileter and sort in ElasticSearch.&#xA;Problem: keeping normalized data in ES is too expensive performance-wise</p>&#xA;"
36571963,Python Development in multiple repositories,<python><git><pip><setuptools><microservices>,2,594,4,0.0,4,"<p>We are trying to find the best way to approach that problem.&#xA;Say I work in a Python environment, with pip &amp; setuptools.&#xA;I work in a normal git flow, or so I hope.&#xA;So:</p>&#xA;&#xA;<ol>&#xA;<li>Move to feature branch in some app, make changes.</li>&#xA;<li>Move to feature branch in a dependent lib - Develop thing. </li>&#xA;<li>Point the app, using ""-e git+ssh"" to the feature branch of the dependent lib.</li>&#xA;<li>Create a Pull Request.</li>&#xA;</ol>&#xA;&#xA;<p>When this is all done, I want to merge stuff to master, but I can't without making yet another final change to have the app (step 3 above) requirements.txt now point to the main branch of the feature.</p>&#xA;&#xA;<p>Is there any good workflow for ""micro services"" or multiple dependent source codes in python that we are missing?</p>&#xA;"
41445442,How to sync the database with the microservices (and the new one)?,<mysql><database><message-queue><microservices><nsq>,1,888,12,0.0,4,"<p>I'm developing a website with the microservice architecture, and each of the service owns a database. The database stores the data which the microservice needs.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><code>Post</code>, <code>Video</code> services need the user information, so both of the services subscribed to the <code>NEW_USER_EVENT</code>. </p>&#xA;&#xA;<p>The <code>NEW_USER_EVENT</code> will be triggered when there's a new user registered.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0SY8a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0SY8a.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Once the services received the <code>NEW_USER_EVENT</code>, they put the incoming user information to each of their own database. So they can do things without asking the <code>User</code> service.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NR8Xk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NR8Xk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>So far so good. But here comes the question:</p>&#xA;&#xA;<ul>&#xA;<li>What if I'm going to create a new service? How do I get the registered user informations and put them in the new service?</li>&#xA;</ul>&#xA;&#xA;<p>Maybe I can get the informations from the existing services. But the events are pushed by the messaging queue (<code>NSQ</code>). </p>&#xA;&#xA;<p>If I'm going to copy the data from one of the microservices, how do I make sure which service has the latest user informations? (<em>Because some services haven't received the latest event</em>) </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/vJoGv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vJoGv.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<hr>&#xA;&#xA;<p><em>Read More:</em></p>&#xA;&#xA;<p><a href=""http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/"" rel=""nofollow noreferrer"">The Hardest Part About Microservices: Your Data</a></p>&#xA;&#xA;<p><a href=""https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/"" rel=""nofollow noreferrer"">Intro to Microservices, Part 4: Dependencies and Data Sharing</a></p>&#xA;"
31206417,SOA by microservices - how to normalize/transform messages,<architecture><soa><transformation><microservices>,3,555,0,1.0,4,"<p>We are developing solution which adapts Messages Pattern and Microservices to define and run business flows.</p>&#xA;&#xA;<p>It should have such components:</p>&#xA;&#xA;<ul>&#xA;<li>Gateways to initiate transaction, with given flow id,</li>&#xA;<li>BPM to store rules (which services should be called for given flow)</li>&#xA;<li>Service selector - kind of processor, it takes request from gateway, get flow definition and then call appropriate services one by one,</li>&#xA;<li>Functional Services.</li>&#xA;</ul>&#xA;&#xA;<p>We should be able to define multiple flows where each step is to call different service.</p>&#xA;&#xA;<p>Output of one service may be input for another one. Problem is that they can have different schema so it should be transformed/normalized somehow.</p>&#xA;&#xA;<p>But which part should be responsible to do such transformation? It should be configurable, because we want to add new flows without redeployment.</p>&#xA;&#xA;<p>First idea is to store responses from each services, and then each step will use XSLT transformation to produce input xml out of previous responses. But it may be configuration hell, cause creating and testing such XSLT won't be easy</p>&#xA;&#xA;<p>Do you have any suggestions how to solve this properly?</p>&#xA;"
31190685,Microservices explained,<php><microservices>,4,1266,0,1.0,4,<p>I'm trying to understand micro services. Can someone please explain to me how it works? I've looked at several tutorials and still confused.</p>&#xA;&#xA;<p>Let's say you have a shopping application. What are the different microservices entailed for such an application?</p>&#xA;&#xA;<p>I will need to do the following</p>&#xA;&#xA;<ul>&#xA;<li>Account creation</li>&#xA;<li>Charge the customer</li>&#xA;<li>Get a list of items for sale&#xA;etc</li>&#xA;</ul>&#xA;
38734740,How to config SpringBoot logback setting in application.yml?,<spring-boot><yaml><logback><microservices>,2,2551,1,0.0,4,"<p>I want to specify my logback.xml file in my project, and in my SpringBoot application I was using the application.yml, I just add</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: logback.xml&#xA;</code></pre>&#xA;&#xA;<p>but it doesn't work for me, the error is :</p>&#xA;&#xA;<pre><code> Logging system failed to initialize using configuration from 'logback.xml'&#xA;java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Exception in thread ""main"" java.lang.IllegalStateException: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:289)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:255)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:224)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:200)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)&#xA;    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)&#xA;    at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)&#xA;    at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180)&#xA;    at com.hansight.saas.statistic.Application.main(Application.java:16)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;    at java.lang.reflect.Method.invoke(Method.java:498)&#xA;    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)&#xA;Caused by: java.io.FileNotFoundException: /Users/liufenglin/workspace/java/cruncher/statistic/logback.xml (No such file or directory)&#xA;    at java.io.FileInputStream.open0(Native Method)&#xA;    at java.io.FileInputStream.open(FileInputStream.java:195)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)&#xA;    at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)&#xA;    at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)&#xA;    at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)&#xA;    at java.net.URL.openStream(URL.java:1045)&#xA;    at org.springframework.boot.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:281)&#xA;    ... 19 more&#xA;</code></pre>&#xA;&#xA;<p>And if I use</p>&#xA;&#xA;<pre><code>logging:&#xA;    config: ./logback.xml&#xA;</code></pre>&#xA;&#xA;<p>to specify the config location, it appears the same error.&#xA;What should I do ?</p>&#xA;"
35465175,"microservice architecture questions about code resue, security and database sharing",<microservices>,1,117,0,1.0,4,<p>I have the following questions about micro service architecture</p>&#xA;&#xA;<ol>&#xA;<li><p>How common code/utility-libs are being reused between different micro services? Where this common code is also being developed</p></li>&#xA;<li><p>In my micro-service some services are for clients and some can be internal ( for other micro services to use). What is the best option to make internal services secure?</p></li>&#xA;<li><p>What if two micro-services has to use the same database? Say they do totally different operations but using the same database table?</p></li>&#xA;<li><p>Micro services are mostly about the back end but the GUI is going to be the same. In that case each micro service deployment requires website update as well. Is that consider as a disadvantage?</p></li>&#xA;</ol>&#xA;
39228311,Best practices for storing content in secure area,<node.js><microservices>,1,44,1,0.0,4,<p>In our project we have separate login page and several SPAs which user can access only after proper authentication.&#xA;All static content is placed in public CDN. But html files of SPAs are stored in DB and delivered to user by index service.&#xA;We don't want to store html files in DB because it is inconvenient for us.</p>&#xA;&#xA;<p>What is the best way to store html files in secure area?</p>&#xA;
37289634,How to Set Request Headers Using a Feign Client?,<spring-mvc><spring-cloud><microservices><netflix-feign><spring-cloud-netflix>,1,6976,0,3.0,4,"<p>We are developing a suite of Microservices using Spring Cloud framework and one of the the things that we need to do is to set request headers. I know I can pass a parameter <code>@RequestHeader</code> to a Feign method but the value needs to come from another bean. I don't know if SPEL can be used for a Feign param value.&#xA;I was thinking that this is a common enough use case for most clients so there'd be some examples, but so far I've not found any. Of course I can dig through the Spring course code and try to override the default Feign configuration but it kinda defeats the purpose of a declarative client if I've to write a lot of code to achieve this.&#xA;Any thoughts?</p>&#xA;"
34909182,Microservice solution structure in .NET applications,<visual-studio><microservices>,1,1384,2,1.0,4,"<p>I'm developing an application using the microservices approach, and I'm having a hard time defining how those microservices will look like on a visual studio project.</p>&#xA;&#xA;<p>My initial approach is to create one visual studio solution for every microservice. Every solution will have the following projects:</p>&#xA;&#xA;<ul>&#xA;<li>Host</li>&#xA;<li>Business API</li>&#xA;<li>Data Access Layer</li>&#xA;<li>Model</li>&#xA;<li>Interfaces (for DI) </li>&#xA;<li>Data Access Mock</li>&#xA;<li>Tests for Business API</li>&#xA;</ul>&#xA;&#xA;<p>So there are 7 projects per microservice. Somehow it feels a lot of projects being reimplemented for every solution.</p>&#xA;&#xA;<p>Is this approach correct? Has anybody built microservices with .net? How does your projects configuration look like?</p>&#xA;"
42788267,"Can I use Oauth2 Authorization Code flow for a SPA (React app), if I have a server-side proxy?",<oauth-2.0><single-sign-on><microservices><openid-connect><identityserver4>,1,1407,1,1.0,4,"<p>After watching an obscene amount of tutorials on OAuth2, there is one best practice that everyone repeatedly states - if you have a React app (or Angular, or Ember) - you <strong>must</strong> use <em>Implicit flow</em> with it.</p>&#xA;&#xA;<p>I understand that storing client credentials in publicly visible javascript would not work. However, my scenario is a bit different:</p>&#xA;&#xA;<ol>&#xA;<li>I'm only using Oauth2 for single sign on and token generation for microservices. I chose it instead of simply generating tokens, since well-supported third party libraries are built around the Oauth2 idea.</li>&#xA;<li>My idea is to have a React app, and a ASP.NET MVC app which serves the javascript and acts as a proxy for API requests. The user authenticates for the server-side app (by using Oauth2 authorization code flow).</li>&#xA;<li>Then if I need to retrieve data from an API, I call my ASP.NET MVC app from React (by sending a simple cookie). The MVC app holds the token without ever exposing it to the user's browser.</li>&#xA;<li>Obviously, when called, my MVC app then redirects the request to the necessary API, providing the bearer token.</li>&#xA;</ol>&#xA;&#xA;<p>To better understand why this is what I came up with, here are some requirements I've received that might be unusual:</p>&#xA;&#xA;<ol>&#xA;<li>I really don't want the access token to be shared - even if it's relatively short lived.</li>&#xA;<li>I also want to be able to limit each user account to 3 concurrent user sessions. Easy to do using cookies and server-side sessions.</li>&#xA;</ol>&#xA;&#xA;<p>I can't wrap my head around why this idea would be that bad. Is there any technical problem that might prevent this from working? Or maybe a security risk?</p>&#xA;"
40234243,OAuth 2.0 service to service authentication and best practices,<authentication><oauth><microservices>,1,519,0,0.0,4,"<p>I have to deal with such type of auth flows:</p>&#xA;&#xA;<ol>&#xA;<li>Create auth flows for Web users;</li>&#xA;<li>In the same way deal with service to service authentication</li>&#xA;</ol>&#xA;&#xA;<p>Briefly following diagram can depict main components that we'll have:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/NzDM7.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/NzDM7.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>For users Authentication we'd like to use OAuth2 (the Implicit Flow) and in general it looks more or less clear.</p>&#xA;&#xA;<p>The question about service to service authorization can it be OAuth2 Authorization Code Flow used?</p>&#xA;&#xA;<p>The main problem there that inside of datacenter1 it will be plenty of backend services that's why it will be good as services will work on the similar permission model as a users (at least some some functionality might be retracted ).</p>&#xA;&#xA;<p>And additional question: what is the general recommendation for this use case if Authorization Server is inside of Datacenter1 or outside?</p>&#xA;"
41837637,Microservices vs multi-layered architecture,<asp.net-web-api><architecture><microservices><multi-layer>,1,2806,0,1.0,4,"<p>My project has one backend service (Web API) and one frontend SPA application. Backend service has presentation, application services, domain and infrastructure layers located in different .net assemblies. Domain layer has business domain objects, infrastructure – communication with external data and other stuff, application services – set of services used by presentation layer, presentation – Web API controllers. I think it’s very common layered architecture.</p>&#xA;&#xA;<p>Our new architect announced we are going to move backend to microservices architecture braking down our layers and dividing domain, application service and infrastructure layers to a few services and convert presentation layer to backend for frontend layer (as <a href=""http://samnewman.io/patterns/architectural/bff/"" rel=""nofollow noreferrer"">here</a> described). In feature, we are going to have mobile application. Sql Server database is going to leave as is for now.</p>&#xA;&#xA;<p>I don’t have experience with microservice architecture, so my questions are: &#xA;Is multi-layered architecture out of fashion already? What benefits and problems can bring such architecture design for my application?</p>&#xA;"
41824300,.NET Core API Gateway,<c#><api><.net-core><microservices><gateway>,2,6347,9,3.0,4,"<p>I've got some work to do for school around Microservices. </p>&#xA;&#xA;<p>I've got the architectural concept, but need an implementation to show off. I'll be using angular2 as a client, would like to use a .NET core API gateway to dispatch my requests to different services. </p>&#xA;&#xA;<p>What's the best approach for this? I red something about using Rx.Net, but no definitive example or implementation that I can follow.</p>&#xA;&#xA;<p>So what should I do to implement an API gateway in .NET Core?</p>&#xA;"
43609390,User as a microservice,<architecture><microservices>,1,506,1,1.0,4,"<p>I'm working on PAAS solution as a product. we have divided business processes in several microservices. One core part of the processes is closely connected to nearly all microservices.</p>&#xA;&#xA;<p>Is this a good practice to create a separate service to manage data such as user management? After the implementation, only this service will have access to users and other related DB tables. All other services will have to call this new user microservice for user related tasks.</p>&#xA;&#xA;<p>This approach will enforced us to refactor DB schema by adding denormalization. We would not get underlying tables that is served among multiple microservices. If serveral services needs data, it would be shared via a microservice.</p>&#xA;"
46605663,Best practices sharing types across multiple Haskell packages/microservices,<haskell><architecture><microservices>,1,131,3,1.0,4,"<p>I am working in a Haskell project that is composed of multiple microservices. There are certain types that are needed by multiple services at the same time and therefore are defined in separate libraries that are imported by whichever needs them (each type is versioned). But there are things about it that make me uncomfortable and I was wondering which are the best practises regarding that topic. In particular:</p>&#xA;&#xA;<ul>&#xA;<li>I don't know how to handle instances of shared types. In order to avoid orphans the instances must be defined in the type's module for each of the types. But then there are instances that are not needed by all the microservices that import the package and have to be included regardless, potentially adding redundant dependencies to the microservice. An example would be a datatype <strong>T</strong> that is shared by a frontend and a backend. It has an instance of <strong>Store</strong> in order to be stored in a database that is not needed by the frontend, but still makes the frontend depend of the store package.</li>&#xA;<li>In order to avoid the previous issue I could introduce a wrapper every time the type has to ""leave"" a microservice to represent that type going through the wire. In the previous example I would have a <strong>Storable T</strong> which would have an instance for <strong>Store</strong>. This adds quite a lot of overhead to the overall development process though.</li>&#xA;<li>Is it even a good idea to share the types or should each microservice define its own representation of each type, so nothing has to be shared? So for a type <strong>T</strong> a microservice <strong>MA</strong> would have a representation <strong>A.T</strong> and an instance to serialise it in order to send the data to a microservice <strong>B</strong> which would decode that data into a representation <strong>MB.T</strong>.</li>&#xA;</ul>&#xA;&#xA;<p>And finally, regarding the logistical side of the matter,</p>&#xA;&#xA;<ul>&#xA;<li>What's the most convenient way to structure the project? Would a monorepo be a better choice than having separate repos/submodules?</li>&#xA;<li>Maybe related to the previous one, is there any way to find out automatically which microservices should be redeployed when one of the shared libraries is modified because the changes in the library affect a piece of code that is being used by the microservice?</li>&#xA;</ul>&#xA;"
52031350,How ACID works in a restful micro-service architecture,<java><rest><microservices><acid>,1,59,2,1.0,4,"<p>I'm pretty new at implementing microservice architecture and this question is breaking my mind</p>&#xA;&#xA;<p>How a microservice architecture address transactional mechanism between different end-points calls.</p>&#xA;&#xA;<p>An example is banking services based on a microservice architecture&#xA;basically, the banking operation is for different calls to different services to complete a transaction, if one of them fails, then there is no way to eliminate the partial process, I do not know if there is any mechanism to solve this problem</p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>create a payment</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /payments/customer/10/payment/100/ </p>&#xA;  &#xA;  <p><strong>debit money from the account</strong></p>&#xA;  &#xA;  <p><strong>PUT</strong> /customers/10/accounts/20</p>&#xA;  &#xA;  <p><strong>Send a customer notification</strong></p>&#xA;  &#xA;  <p><strong>POST</strong> /alerts/customers/10</p>&#xA;</blockquote>&#xA;"
44355294,How to offer multiple versions of an API with different database schemas?,<database><versioning><microservices>,1,387,2,2.0,5,"<p>In Kevin Goldsmith's 2015 talk about <a href=""https://youtu.be/7LGPeBgNFuU?t=925"" rel=""noreferrer"">microservices at Spotify</a> (from 15:25 - 17:43), he mentions that when they create a new version of an API they just create a new server, and keep the old server running with the old version for as long as there are still clients calling it (in this case, a smart lamp with Spotify embedded on it).</p>&#xA;&#xA;<p>I am confused about how they would be able to maintain and offer older versions for potentially years, when surely there would be database schema changes during that timeframe?</p>&#xA;&#xA;<p>I can see a few possible solutions, but none of them seem very reasonable:</p>&#xA;&#xA;<ol>&#xA;<li>Using the same database across all versions, only ever add new tables, and new nullable fields. Never delete fields, nor rename fields, nor set fields to non-nullable, nor delete tables, nor rename tables.</li>&#xA;<li>Using a different database per version, keep each version's data separate.</li>&#xA;<li>Using a different database per version, keep each version's data separate, but write a way to migrate and pass the requests from one version to another, so that each version receives the request with the valid parameters for that version.</li>&#xA;</ol>&#xA;&#xA;<p>Solution 1 sounds like it would induce way too much code smell, with legacy code everywhere (which Kevin, in my opinion, seems to suggest they certainly do not do).</p>&#xA;&#xA;<p>Solution 2 sounds like a nightmare to pull data out of for other services, or for reporting. What if the information about an entity that you want is in another version's database than the one you request?</p>&#xA;&#xA;<p>Solution 3 sounds like more of a nightmare as you would have to write code to migrate a request for your version, to the versions above and below yours. This would mean that you can't just leave the existing (the one currently in production) version as-is when creating a new version, as you would need to add migrations to move the request both forward and backward so that all versions received the correct parameters for the request.</p>&#xA;&#xA;<p>Hopefully I am just missing something simple here, and there is a magic solution to make this problem easier, but I really cannot see how they could accomplish this?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
36627628,setting up Elasticsearch server for processing data from microservices,<ruby-on-rails><elasticsearch><architecture><microservices>,1,880,0,3.0,5,"<p>I am very new to elasticsearch and its scaling, and I've got a question I don't even know how to approach. </p>&#xA;&#xA;<p>Here's the situation:</p>&#xA;&#xA;<p>There're several servers with Rails microservice applications. Each of them is getting each its own pretty big piece of data (more specifically, aggregating posts from different social networks - so the indexable search fields are the same in all databases).</p>&#xA;&#xA;<p>I need to find a solution that would allow to keep the data where it currently is and setting up an elasticsearch server dedicated exclusively to searching through multiple databases without the respective Rails apps turning on this search server. It potentially means setting up ES on each of the other servers, defining the search patterns there but making the multiple-model search on a totally different server.</p>&#xA;&#xA;<p>The final goal of these manipulations should be sending the entire ActiveRecord objects / or all the related attributes to the main application.</p>&#xA;&#xA;<p>Is it even possible to achieve? Maybe anyone has had a similar problem? </p>&#xA;&#xA;<p>I am a little lost about how to get started with it.</p>&#xA;"
36680157,Communication between REST Microservices: Latency,<http><connection-pooling><microservices><http2>,3,2688,2,2.0,5,"<p>The problem I'm trying to solve is latency between Microservice communication on the backend. Scenario. Client makes a request to service A, which then calls service B that calls service C before returning a response to B which goes to A and back to the client.</p>&#xA;&#xA;<pre><code>Request: Client -&gt; A -&gt; B -&gt; C&#xA;Response: C -&gt; B -&gt; A -&gt; Client&#xA;</code></pre>&#xA;&#xA;<p>The microservices expose a REST interface that is accessed using HTTP. Where each new HTTP connection between services to submit requests is an additional overhead. I'm looking for ways to reduce this overhead without bringing in another transport mechanism into the mix (i.e. stick to HTTP and REST as much as possible). Some answers suggest using <a href=""https://stackoverflow.com/questions/35673254/communication-between-microservices"">Apache Thrift</a> but I'd like to avoid that. Other possible solutions are using Messaging Queues which I'd also like to avoid. (To keep operational complexity down).</p>&#xA;&#xA;<p>Has anyone experience in microservices communication using HTTP Connection pooling or HTTP/2? The system is deployed on AWS where service groups are fronted by a ELB. </p>&#xA;"
41433856,emailing in microservice architecture,<rest><email><microservices><restful-architecture><email-integration>,1,1709,0,3.0,5,"<p>Sorry about my english - if some thing is not clear please ask me in comments - i will clarify this.</p>&#xA;&#xA;<p>I build system in microservice architecture. I have one service with user information, one service for ""offers"", and one service for ""ideas"". Services ""offers"" and ""ideas"" comunicate (by Restful API) with ""User"" service on login and other operations. And i wonder - how to deal with emails? Each service have it separate frontend and send emails after some actions (eg. when some third person open link with some offer the user who create this offer will get email, or when some user create idea the manager will get email). Moreover, on each service frontend, manager can create ""periodic"" mailing with season statistical data or just some other information. Each service email looks differently and have different content.</p>&#xA;&#xA;<p>I have many choices and don't know which will be better. This are some propositions:</p>&#xA;&#xA;<ol>&#xA;<li>Each service has his own separate emailing system and send all kinds&#xA;of email (after action, and periodic) independent. </li>&#xA;<li>The ""user service"" have ""engine"" to send action and periodic emails and other services give the task. Inside task there is link to service who give task and that link will generate email content (for example witch statistical data in periodic email). This solution is complicated...</li>&#xA;<li>The ""user service"" has only engine to periodic emails (tasks have link to generate email body...) but email after actions are send from each microservice indepenndent</li>&#xA;<li>Create new microservice only for sending email (periodic and ""after action"") with proper API. Ofcourse each service like ""offers"" should send also link (to themself) in mailing task - this link will be call when the periodic email will be send and the response of this link will be generated body of email....</li>&#xA;</ol>&#xA;&#xA;<p>Which one will be better? Or may be there is some better alternative? </p>&#xA;"
27865814,Does my concept follow a Microservice architecture?,<php><magento><soa><single-page-application><microservices>,2,5151,0,3.0,5,"<p>I read <a href=""http://martinfowler.com/articles/microservices.html"" rel=""noreferrer"">the article on Microservices</a> on Martin Fowler's page and find it quite interesting. Now I plan structuring an E-Commerce Web Application as proof-of-concept and am wondering if my concept is considered being a Microservice architecture.</p>&#xA;&#xA;<p>The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li>a javascript based single page application, which sends AJAX requests to</li>&#xA;<li>a server with a REST API which feeds JSON data received by calling other services (I think you call this behaviour API Gateway)</li>&#xA;<li>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento (PHP) Shopsystem. In future I plan to then swap the providers with other systems.</p>&#xA;&#xA;<p>So my questions are:</p>&#xA;&#xA;<ul>&#xA;<li><p>MS are considered to be 'independently deployable'. I understand that in the world of JAVA we are talking about one JAR- or WAR-file, but how is a PHP service 'independently deployable'?</p></li>&#xA;<li><p>Does my concept NOT follow the principles of a MS architecture, because the providers are all part of one big (Magento) system?</p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading. I'm happy for any suggestions.</p>&#xA;"
46453981,How an authorization service implements ownership checks in a role-based microservice architecture,<design><architecture><authorization><microservices><soa>,2,162,0,2.0,5,"<p>Let's say I have three types of users on a blogging app</p>&#xA;&#xA;<ol>&#xA;<li><strong>Author</strong> (is able to modify their own posts but not others)</li>&#xA;<li><strong>Administrator</strong> (is able to modify all posts)</li>&#xA;<li><strong>Reader</strong> (can not modify any posts)</li>&#xA;</ol>&#xA;&#xA;<p>To manage this system I want to have three main services: </p>&#xA;&#xA;<ul>&#xA;<li>An <strong>API Gateway</strong> that exposes all the APIs clients will consume, composing services as needed. </li>&#xA;<li>A <strong>Post Management Service</strong> which provides the CRUD operations for blog posts (including the data of who owns what posts)</li>&#xA;<li>An <strong>Authorization Service</strong> which stores roles and permissions, exposing an API which takes in an array of roles (the roles a requesting user has) and an array of permissions (the permissions needed to access an API) and determines if those inputted roles cover all the permissions inputted. </li>&#xA;</ul>&#xA;&#xA;<p>Now what I am struggling with is ownership of a resource (and where ownership should be checked).</p>&#xA;&#xA;<p>Without communicating with other services how would an authorization service determine if a user should be able to access something they own without knowing how to determine if a user owns a given resource. </p>&#xA;&#xA;<p>I've come up with a few different solutions to this problem, although I'm not quite happy with any of them. </p>&#xA;&#xA;<ol>&#xA;<li>The API Gateway would query a different service that manages the posts to determine if a requesting user owns the post they are trying to access, this would mean there is authorization logic that happens outside of the authorization service.</li>&#xA;<li>The service managing blog posts would handle authorization based on ownership, this would also mean authorization logic is happening outside the authorization service as well as the fact that unauthorized requests are being marked as authorized initially (since they will still pass through the authorization service)</li>&#xA;<li>The Authorization service could be given the knowledge of how to check ownership, the API would have to be able to be told whether or not it should check for ownership along with the permissions. This would add complexity to the authorization service and increase the cross-service communication which I'd like to relegate as much as possible to the API gateway since it should be the primary service composer. </li>&#xA;</ol>&#xA;&#xA;<p>Looking for ideas on alternative methods or insight into what the best solution to this problem might be.</p>&#xA;"
46311488,Confused about ESBs as a solution to point-to-point integration,<architecture><microservices><esb>,4,675,0,0.0,5,"<p>Still very new to studying application architecture and having trouble stomaching some ideas in a book about microservices. In my readings, I have come across the older idea of the ESBs(Enterprise Service Bus) and its role in coordinating messages between new services and legacy applications. ESBs are touted as a solution to problems poised by point-to-point integration. Microservices seem to be the approach taken by newer companies as the de facto standard to creating an agile, scalable, and resilient app. But aren't microservices using point-to-point integration? Each node in an application built from microservices is communicating directly with other nodes, right? I feel I am connecting some dots that shouldn't be connected. Any help much appreciated, thanks in advance.</p>&#xA;"
39485459,Microservice Versioning,<architecture><versioning><soa><microservices>,4,834,0,1.0,5,"<p>What is the best practice to adapt for versioning in a Microservice Based Architecture, in terms of supporting multiple versioned deployment of the same service during runtime and how the consumers would be able to use different versions?&#xA;1) If we use Routing based Versioning as one of the approaches mentioned <a href=""http://niels.nu/blog/2016/microservice-versioning.html"" rel=""nofollow noreferrer"">here</a>&#xA;then I guess we would have the following drawbacks </p>&#xA;&#xA;<ol>&#xA;<li>Internal Services have to go through Reverse Proxy for consumption.</li>&#xA;<li>Consumers always have to be aware of the required versioning.</li>&#xA;</ol>&#xA;&#xA;<p>Is it a best practice to expose the version information to consumers?  </p>&#xA;&#xA;<p>In any case, as I feel, the following always applies:</p>&#xA;&#xA;<ol>&#xA;<li>For MAJOR version change, the consumers have to be changed.</li>&#xA;<li>For MINOR version change (backwards compatible), only the consumer(s) that requires the added functionality needs to change.</li>&#xA;<li>For PATCH version change, it's optional and would probably be seamless for any consumers to make use of it.</li>&#xA;</ol>&#xA;&#xA;<p>What kind of Microservice versioning strategy can help us in enabling the above?</p>&#xA;&#xA;<p>NOTE - Please feel free to let me know if this needs to be split in multiple questions.</p>&#xA;"
47527983,Designing java project for monoliths and microservices at same time,<java><scope><package><domain-driven-design><microservices>,3,268,2,0.0,5,"<p>I would like to know how you divide project modules in java for monolith with possibility of transforming modules to micro-services later?<br>&#xA;My personal naming looks like this:</p>&#xA;&#xA;<pre><code>com.company.shopapp.product&#xA;...product.domain (ddd, services, repositories, entities, aggregates, command handlers - everything with package scope)&#xA;...product.api (everything with public scope)&#xA;...product.controller (CQRS endpoints for commands in web perspective - (package scope))&#xA;...product.query(CQRS - package scope)&#xA;&#xA;com.company.shopapp.sales&#xA;- domain&#xA;- api &#xA;- controller&#xA;- query &#xA;</code></pre>&#xA;&#xA;<p>What we have here is basically product management context and sales context as packages. </p>&#xA;&#xA;<p>Modules communicate each other using public interfaces (api package) only. In my project I use ""..api.ProductFacade"" to centralize communication points.</p>&#xA;&#xA;<p>When my ""sales"" module grow i will turn it into microservice by implementing ""..api.ProductFacade"" interface as a ""rest"" or ""soap"" client and on the other side I will create Endpoint/RestController based on ProductFacade interface.&#xA;Package ""com.company.shopapp.product.api"" will be transformed into extended library and added to both projects. </p>&#xA;&#xA;<p>Edit: &#xA;I can achive this out of the box using @Feign library.&#xA;<a href=""https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance"" rel=""nofollow noreferrer"">https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html#spring-cloud-feign-inheritance</a></p>&#xA;&#xA;<p>The whole idea feels nice, but maybe you have better way to design project and ensure that breaking it into micro-services will not break whole application. </p>&#xA;"
47544877,Websockets in microservices architecture,<web-applications><websocket><microservices><api-gateway>,1,1872,5,0.0,5,"<p>Let's say we have a notification service which read an event from message queue and notify all web clients in real time. I know how web socket work but i am puzzled when there is an API gateway in between then how web socket connection is maintained between client, API gateway and notification service.</p>&#xA;&#xA;<p>Please help! Thanks</p>&#xA;&#xA;<p><strong>Edit:</strong>&#xA;Architecture:&#xA;<a href=""https://i.stack.imgur.com/wEeu3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wEeu3.jpg"" alt=""enter image description here""></a></p>&#xA;"
34295221,Microservices: decomposing a graph db based application,<graph-databases><microservices>,1,583,0,0.0,5,"<p>I'm planning to decompose an application I started to build as a monolith with a graph database into microservices. But the dilema i'm facing is trying to find a proper solution to split the different services and not loosing the benefits provided by the graph database. </p>&#xA;&#xA;<p>The idea I've considered initially is to split each different entity into it's own microservice, using a document store to persist the data on each service. And then define a higher level service to manage the relationships. </p>&#xA;&#xA;<p>For example with a relationship (A)-->(B), would produce 3 microservices, a service for entities of type A, another for the entities of type B, and a third higher level with a graph database, storing nodes of type A and B, containing only the ID's and the relationships between those. </p>&#xA;&#xA;<p><strong>Question 1</strong>: Is there anything wrong with this approach in terms of coupling, fault tolerance, or anything else that I can't think of right now?</p>&#xA;&#xA;<p><strong>Question 2</strong>: When you toss a third entity into the game, for example (A)-->(B), (A)-->(C) and (C)-->(B), which one would be the best approach in this scenario? </p>&#xA;&#xA;<ul>&#xA;<li>Do I stick to the strategy of just one higher level service to maintain all the relationships? </li>&#xA;<li>Do I generate several higher level services to maintain each type of relationship?</li>&#xA;</ul>&#xA;&#xA;<p><strong>Question 3</strong>: In the case of relationships between entities of the same type, for example (Person)--isFriendOf-->(Person), having in mind the concept of separation of concerns, is it appropiate to separate the management of the relationships into a different service?</p>&#xA;&#xA;<p>Any input, feedback and ideas are very welcome.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>I've been doing some research on the subject, and for the sake of clarity, I'll propose a more concrete scenario, so it will be easier to discuss about it. &#xA;The graph model would be something like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/87MOt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/87MOt.png"" alt=""Graph relationships""></a></p>&#xA;&#xA;<p>The goal here would be to implement a song playlist recommendation service, trying to find the songs that a given user haven't listened yet, based on genres and artists from the songs that the user already listened, and also from other songs listened by other users, followed by the current user.</p>&#xA;"
46236744,Swagger for Event?,<events><swagger><microservices><event-driven>,4,327,1,0.0,5,"<p>The <a href=""https://github.com/OAI/OpenAPI-Specification"" rel=""nofollow noreferrer"">Swagger / OpenAPI specification</a> is useful to document and run automated tests against HTTP APIs. However, I run an event-driven microservices architecture and it is important to document the event payload passed among different services, even when they are not accessed via HTTP paths. Since eerything I've seen is API-based via HTTP paths, I'm wondering if Swagger handle this or, if not, is there anything similar for events?</p>&#xA;"
47050984,Enabling session in lumen framework,<laravel><microservices><lumen>,3,2894,12,1.0,5,"<p>I have two (but let's image more) micro-services (API) which need to be aware of authenticated user. Ideally I would simple like to resume their sessions.</p>&#xA;&#xA;<p>All micro-services are using same storage for sessions: redis.</p>&#xA;&#xA;<p>All API calls will have Cookie header, so all services will be able to resume sessions based on that cookie. I have successfully implemented this via PHP $_SESSIONs.</p>&#xA;&#xA;<p>Now the question: how would you go about implementing this with Laravel/Lumen?</p>&#xA;"
47647560,How to share entity between REST service between two microservices?,<java><rest><microservices>,3,643,2,2.0,5,<p>I have created two micro-services using java. I need to make a REST api call from service A to service B. The data sent will be in JSON format. Using jax-rs I need to create entity class in both the service.</p>&#xA;&#xA;<p>Since both the entity class be same in both the projects. Do i </p>&#xA;&#xA;<ul>&#xA;<li>Create an common jar and use is for all my entity/domain objects? Does this make my microservice more tightly coupled?</li>&#xA;<li>Do i create the same class in both the microservice projects? This will just mean repeating the work in both the projects?</li>&#xA;</ul>&#xA;&#xA;<p>Is there a better way to communicate between the sevices?</p>&#xA;
42486386,Does CQRS With OLTP and OLAP Databases Make Sense?,<api><olap><microservices><cqrs><oltp>,1,219,2,1.0,5,"<p>I have several OLTP databases with API's talking to them. I also have ETL jobs pushing data to an OLAP database every few hours.</p>&#xA;&#xA;<p>I've been tasked with building a custom dashboard showing hight level data from the OLAP database. I want to build several API's pointing to the OLAP database. Should I:</p>&#xA;&#xA;<ol>&#xA;<li>Add to my existing API's and call the OLAP database and use a CQRS type pattern, so reads come from OLAP, while writes come from OLTP. My concern here is that there could be a mismatch in the data between reads and writes. How mismatched the data is depends on how often you run the ETL jobs (Hours in my case).</li>&#xA;<li>Add to my existing API's and call the OLAP databases then ask the client to choose whether they want OLAP or OLTP data where API's overlap. My concern here is that the client should not need to know about the implementation detail of where the data is coming from.</li>&#xA;<li>Write new API's that only point to the OLAP database. This is a lot of extra work.</li>&#xA;</ol>&#xA;"
45622414,Should there be authentication/authorization between microservices?,<soa><microservices>,3,1038,0,0.0,5,"<p>I know this may be not a good question.</p>&#xA;&#xA;<p>I was asked a question: do we really need authentication among microservices. And I have no idea the answer. I did read some tutorials on SOA, microservices, and how to add authentication among the services. But I did not have too many ideas <strong>why we need authentication/authorization between microservices? Any use cases where they are required? Any use cases where they are not required?</strong> Any potential risk without authentication/authorization? </p>&#xA;&#xA;<p>Any comments welcomed. It is better to give some practical examples. Thanks</p>&#xA;"
45655728,What is the real difference between an API and an microservice?,<api><microservices>,5,11680,0,2.0,5,"<p>I am learning about microservices and I don't understand what the real difference between creating a REST API and creating microservices is. I’m working in Go, but my question applies over all languages.</p>&#xA;"
38863827,How to handle REST API paths when related resources belong to different microservices?,<rest><microservices>,2,309,0,1.0,6,"<p>I have two microservices:</p>&#xA;&#xA;<ul>&#xA;<li>UserService, which defines paths such as /users, /users/:id;</li>&#xA;<li>MessageService, which defines paths such as /messages, /messages/:id.</li>&#xA;</ul>&#xA;&#xA;<p>Also, each message in MessageService has an attribute user_id which references a user in UserService.</p>&#xA;&#xA;<p>Now, lets say I want to list all messages of a given user. Right now I can think of the following approaches:</p>&#xA;&#xA;<ol>&#xA;<li>A path such as <strong>/users/:id/messages</strong> seems like the best approach if I want to follow the best REST API practices. However, it seems to me that I couldn't define such path inside MessageService because I would be tight-coupling it to UserService. I believe paths starting with /users should belong to UserService only.</li>&#xA;<li><strong>/messages?user_id=:id</strong> so I could use the existing /messages path and add a filter by attribute (user_id). Not sure if a good practice.</li>&#xA;<li>Put an API gateway in front of the microservices and create a proxy from <strong>/users/:id/messages</strong> to <strong>/messages?user_id=:id</strong>. This allows clients to use the most REST-friendly path while keeping the microservices loosely coupled.</li>&#xA;</ol>&#xA;&#xA;<p>Which of these approaches would be the most appropriate?</p>&#xA;"
42140285,How to implement a microservice Event Driven architecture with Spring Cloud Stream Kafka and Database per service,<apache-kafka><spring-cloud><microservices><spring-cloud-stream><spring-kafka>,2,2318,0,5.0,6,"<p>I am trying to implement an event driven architecture to handle distributed transactions. Each service has its own database and uses Kafka to send messages to inform other microservices about the operations.</p>&#xA;&#xA;<p>An example:</p>&#xA;&#xA;<pre><code> Order service -------&gt; | Kafka |-------&gt;Payment Service&#xA;       |                                       |&#xA;Orders MariaDB DB                   Payment MariaDB Database&#xA;</code></pre>&#xA;&#xA;<p>Order receives an order request. It has to store the new Order in its DB and publish a message so that Payment Service realizes it has to charge for the item:</p>&#xA;&#xA;<p>private OrderBusiness orderBusiness;    </p>&#xA;&#xA;<pre><code>@PostMapping&#xA;public Order createOrder(@RequestBody Order order){&#xA;    logger.debug(""createOrder()"");&#xA;    //a.- Save the order in the DB&#xA;    orderBusiness.createOrder(order);&#xA;    //b. Publish in the topic so that Payment Service charges for the item.&#xA;    try{&#xA;        orderSource.output().send(MessageBuilder.withPayload(order).build());&#xA;    }catch(Exception e){&#xA;        logger.error(""{}"", e);&#xA;    }&#xA;    return order;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>These are my doubts:</p>&#xA;&#xA;<ol>&#xA;<li>Steps a.- (save in Order DB) and b.- (publish the message) should be performed in a transaction, atomically. How can I achieve that?</li>&#xA;<li>This is related to the previous one: I send the message with: orderSource.output().send(MessageBuilder.withPayload(order).build()); This operations is asynchronous and ALWAYS returns true, no matter if the Kafka broker is down. How can I know that the message has reached the Kafka broker?</li>&#xA;</ol>&#xA;"
35882330,how to get my configuration values in yml - using dropwizard (microservice) Jersey D.I @Injection?,<java><jersey><dropwizard><inject><microservices>,1,4347,0,2.0,6,"<p>here's my code snippets.</p>&#xA;&#xA;<p>here's my yml file:</p>&#xA;&#xA;<pre><code>productionServer:&#xA;  host: production-server.amazonaws.com&#xA;  publicIp: xx.xx.xx.xx&#xA;  privateIp: xx.xx.xx.xx&#xA;  userName: xx.xx.xx.xx&#xA;  password: xx.xx.xx.xx&#xA;  remoteFilePath: fake/path/&#xA;  fileName: test.txt&#xA;  privateKey: private-public-key.ppk&#xA;&#xA;server:&#xA;  applicationConnectors:&#xA;    - type: http&#xA;      port: 8080&#xA;    - type: https&#xA;      port: 8443&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;  adminConnectors:&#xA;    - type: http&#xA;      port: 8081&#xA;    - type: https&#xA;      port: 8444&#xA;      keyStorePath: key.keystore&#xA;      keyStorePassword: password&#xA;      validateCerts: false&#xA;</code></pre>&#xA;&#xA;<p>MyConfiguration class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Configuration;&#xA;&#xA;public class MyConfiguration extends Configuration{&#xA;&#xA;    @NotNull&#xA;    @JsonProperty&#xA;    private ProductionServer productionServer;&#xA;&#xA;    // getters&#xA;&#xA;public class ProdctionServer{&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private host;&#xA;&#xA;      @NotEmpty&#xA;      @JsonProperty&#xA;      private publicIp;&#xA;&#xA;      // getters&#xA;</code></pre>&#xA;&#xA;<p>Application class:</p>&#xA;&#xA;<pre><code>import io.dropwizard.Application;&#xA;&#xA;public class MyApplication extends Application&lt;MyConfiguration&gt; {&#xA;&#xA;    public static void main(String[] args) throws Exception{&#xA;        new MysApplication().run(args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public String getName(){ return ""micro-service""; }&#xA;&#xA;    @Override&#xA;    public void initialize(Bootstrap&lt;MyConfiguration&gt; bootstrap){}&#xA;&#xA;    @Override&#xA;    public void run(MyConfiguration conf, Environment environment ){&#xA;        final MyResource myResource = new MyResource();&#xA;        // health check&#xA;&#xA;        // environment.healthChecks().register(""template"",healthCheck);&#xA;&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println( ""==&gt; "" + conf.getProductionServer() );&#xA;&#xA;        // register&#xA;        environment.jersey().register( MyResource );&#xA;</code></pre>&#xA;&#xA;<p>and when running this app:</p>&#xA;&#xA;<p>i received a logged as follows:</p>&#xA;&#xA;<pre><code>==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@623e088f, io.dropwizard.jetty.HttpsConnectorFactory@39fcbef6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34f22f9d, io.dropwizard.jetty.HttpsConnectorFactory@77d67cf3], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@663411de]}}&#xA;==&gt; com.mycompany.myproject.model.ProductionServer@5b04476e&#xA;</code></pre>&#xA;&#xA;<p>meaning it is successfully gets the value of my yaml.&#xA;but my problem is during the D.I or dependency injection of MyConfiguration class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service. </p>&#xA;&#xA;<p>here's my code snippet of dependency binding the MyService.class and the MyConfiguration.class </p>&#xA;&#xA;<p>DependencyBinder.class</p>&#xA;&#xA;<p>import org.glassfish.hk2.utilities.binding.AbstractBinder;</p>&#xA;&#xA;<p>public class DependencyBinder extends AbstractBinder {</p>&#xA;&#xA;<pre><code>@Override&#xA;protected void configure() {&#xA;    bind(MyConfiguration.class).to(MyConfiguration.class);&#xA;    bind(MyService.class).to(MyService.class);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>public class MyService {&#xA;&#xA;    @Inject&#xA;    MyConfiguration conf;&#xA;&#xA;    public void invoke(){&#xA;        System.out.println( ""=============================== "" );&#xA;        System.out.println( ""==&gt; "" + conf );&#xA;        System.out.println(""==&gt; "" + conf.getProductionServer() );&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>and during the invoking of the method invoke()...&#xA;i got a logged as follows:</p>&#xA;&#xA;<pre><code>=============================== &#xA;==&gt; MyConfiguration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@34e82c4d], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@19b70fbd], adminMaxThreads=64, adminMinThreads=1, applicationContextPath=/, adminContextPath=/}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@543f81c9]}}&#xA;==&gt; null&#xA;</code></pre>&#xA;&#xA;<p>now my problem is during the D.I or dependency injection of MyConfiguration class in MyService.class. i cannot get the value of my ProductionServer though the Object MyConfiguration seems not null in my Service.&#xA;please give me some resolution? thnx.</p>&#xA;"
34023438,microservices: How to model related domain objects?,<soa><microservices>,1,353,0,1.0,6,"<p>I have 2 domain objects: Project and Contract. A project can have many contracts so in the database it is modeled as a classic one-to-many relationship. Our question is this: How do you model the above in the context of microservices? Do you (a) have 2 microservices ProjectService and ContractService? or (b) Do you have one ProjectService which encompasses both Projects and Contracts?</p>&#xA;&#xA;<p>We are thinking that answer (a) (i.e. 2 microservices ProjectService and ContractService) implies that one would have to call 2 services to retrieve and save the complete Project object hierarchy. On the other hand, answer (a) completely decouples Projects from Contracts which may be a good thing in theory, but practically useless since a Contract cannot logically exist without a Project.</p>&#xA;&#xA;<p>What is the correct approach here? Is answer (a) an example of the nano service anti pattern?</p>&#xA;"
33952306,"Microservice, amqp and service registry / discovery",<rest><architecture><amqp><microservices><service-discovery>,1,767,1,1.0,6,"<p>I m studying Microservices architecture and I m actually wondering something.</p>&#xA;&#xA;<p>I m quite okay with the fact of using (back) service discovery to make request able on REST based microservices. I need to know where's the service (or at least the front of the server cluster) to make requests. So it make sense to be able to discover an ip:port in that case.</p>&#xA;&#xA;<p>But I was wondering what could be the aim of using service registry / discovery when dealing with AMQP (based only, without HTTP possible calls) ?</p>&#xA;&#xA;<p>I mean, using AMQP is just like ""I need that, and I expect somebody to answer me"", I dont have to know who's the server that sent me back the response.</p>&#xA;&#xA;<p>So what is the aim of using service registry / discovery with AMQP based microservice ?</p>&#xA;&#xA;<p>Thanks for your help</p>&#xA;"
34794630,Micro service security,<c#><microservices>,2,1298,7,2.0,6,"<p>Over the last few days I've been playing with the micro service pattern and all is going well but security seems to baffle me.</p>&#xA;&#xA;<p><strike>&#xA;So If I may ask a question:&#xA;How do I handle user authentication on an individual service? At the moment I pass a request to the <code>Gateway API</code> which in turns connects to the service.&#xA;</strike></p>&#xA;&#xA;<p><strong>Question Edited Please See Below</strong></p>&#xA;&#xA;<p>Bearing in mind that the individual services should not know about each other. The <code>Gateway</code> is the aggregator as such. </p>&#xA;&#xA;<p><strong>Current architecture.</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/60tiY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60tiY.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>A little code to simulate the request:</p>&#xA;&#xA;<p><strong>Frontend - Client App</strong></p>&#xA;&#xA;<pre><code>public class EntityRepository&lt;T&gt;&#xA;{&#xA;    private IGateway _gateway = null;&#xA;    public EntityRepository(IGateway gateway)&#xA;    {&#xA;        this._gateway = gateway;&#xA;    }&#xA;    public IEnumerable&lt;T&gt; FindAll()&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;IEnumerable&lt;T&gt;&gt;().Result;&#xA;    }&#xA;    public T FindById(int id)&#xA;    {&#xA;        return this._gateway.Get(typeof(T)).Content.ReadAsAsync&lt;T&gt;().Result;&#xA;    }&#xA;    public void Add(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Update(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;    public void Save(T obj)&#xA;    {&#xA;        this._gateway.Post(typeof(T), obj);&#xA;    }&#xA;}&#xA;&#xA;&#xA;   //Logic lives elsewhere&#xA;   public HttpResponseMessage Get(Type type)&#xA;   {&#xA;      return Connect().GetAsync(Path(type)).Result;&#xA;   }&#xA;   public HttpResponseMessage Post(Type type, dynamic obj)&#xA;   {&#xA;      return Connect().PostAsync(Path(type), obj);&#xA;   }&#xA;    private string Path(Type type)&#xA;    {&#xA;        var className = type.Name;&#xA;        return ""api/service/"" + Application.Key + ""/"" + className;&#xA;    }&#xA;    private HttpClient Connect()&#xA;    {&#xA;        var client = new HttpClient();&#xA;        client.BaseAddress = new Uri(""X"");&#xA;&#xA;        // Add an Accept header for JSON format.&#xA;         client.DefaultRequestHeaders.Accept.Add(&#xA;         new MediaTypeWithQualityHeaderValue(""application/json""));&#xA;&#xA;        return client;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>I use generics to determine where it needs to fire once it hit's the gateway.&#xA;So if the <code>Type</code> is <strong>Category</strong> it will fire the <strong>Category</strong> service thus calling:</p>&#xA;&#xA;<pre><code>public IEnumerable&lt;dynamic&gt; FindAll(string appKey, string cls)&#xA;{&#xA;    var response = ConnectTo.Service(appKey, cls);&#xA;    return (appKey == Application.Key) ? (response.IsSuccessStatusCode) ? response.Content.ReadAsAsync&lt;IEnumerable&lt;dynamic&gt;&gt;().Result : null : null;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The Gateway does not contain the physical files/Class's of the types.</p>&#xA;&#xA;<p>After a little code, I was hoping someone could give me a little demonstration or the best approach to handle security/user authentication with the current architecture.</p>&#xA;&#xA;<p><strong>Case Scenario 1</strong>&#xA;User hits the web app and logs in, at that point the users encrypted email and password is sent to the <code>Gateway API</code> which is then passed to the <code>User Service</code> and decides whether the user is authenticated - all well and good but now I want to fetch all Messages from the <code>Message Service</code> that the user has received. I cannot really say in the Gateway if the user is authenticated, fetch the messages because that does not solve the issue of calling the <code>Message Service</code> outside of the <code>Gateway API</code></p>&#xA;&#xA;<p>I also cannot add authentication to each individual service because that would require all respective services talking to the <code>User Service</code> and that defeats the purpose of the pattern.</p>&#xA;&#xA;<p><strong>Fixes:</strong>&#xA;Only allow the Gateway to call the Services. Requests to services outside of the Gateway should be blocked.</p>&#xA;&#xA;<p>I know security is a broad topic but within the current context, I'm hoping someone could direct me with the best course of action to resolve the issue.</p>&#xA;&#xA;<p>Currently I have Hardcoded a <code>Guid</code> in all off the applications, which in turn fetches data if the app is equal.</p>&#xA;"
39920488,What is the role of falcor in a microservice architecture?,<microservices><falcor>,2,1336,0,4.0,6,"<p>Say we have following taxi-hailing application that is composed of loosely coupled microservices:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QgctP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QgctP.png"" alt=""https://www.nginx.com/blog/introduction-to-microservices/""></a></p>&#xA;&#xA;<p><em>The example is taken from <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/introduction-to-microservices/</a></em></p>&#xA;&#xA;<p>Each services has its own rest api and all services are combined in a single api gateway. The client does not talk to a single service but to the gateway. The gateway requests information from several services and combines them to a single response. For the client it looks like it is talking to a monolithic application.</p>&#xA;&#xA;<p><strong>I am trying to understand: where could we incorporate falcor into this application?</strong></p>&#xA;&#xA;<p><strong>One Model Everywhere</strong> from <a href=""http://netflix.github.io/falcor/"" rel=""nofollow noreferrer"">http://netflix.github.io/falcor/</a> </p>&#xA;&#xA;<blockquote>&#xA;  <p>Falcor lets you represent all your remote data sources as a single&#xA;  domain model via a virtual JSON graph. You code the same way no matter&#xA;  where the data is, whether in memory on the client or over the network&#xA;  on the server.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this taxi-hailing application each microservice represents a single domain model already. Can you think of any benefit we could thrive by wrapping each microservice with falcor? I cannot.</p>&#xA;&#xA;<p>However I think it is very convenient to incorporate falcor into the api gateway because we can abstract away the different domain models created by the microservices into one single or at least a few models.</p>&#xA;&#xA;<p>What is your opinion?</p>&#xA;"
34442192,Api gateway or No Api Gateway,<microservices>,1,1401,1,0.0,6,"<p>I am developing an application based on the <code>microservice architecture</code>. Here, each <code>service</code> is an independently deployable <code>play-scala application</code> exposing <code>rest apis</code>. I want to implement an <code>Api gateway</code> on top of these services for mapping incoming requests.I am following the architecture discussed here :<a href=""http://%20https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""nofollow noreferrer"">Building Microservices</a></p>&#xA;&#xA;<p>There are very few projects with substantial maturity that are based on the microservice architecture. One of them is <a href=""https://github.com/theiterators/reactive-microservices#master"" rel=""nofollow noreferrer"">Reactive Microservices</a>.But this project is not using the <code>api gateway pattern</code> and seems to be following the <a href=""http://www.infoq.com/articles/seven-uservices-antipatterns"" rel=""nofollow noreferrer"">Anti Pattern</a> There is an <a href=""https://github.com/theiterators/reactive-microservices/issues/10"" rel=""nofollow noreferrer"">issue</a> opened for this project regarding the missing Api Gateway here .The contributors here claim that they did not follow the <code>api gateway pattern</code> because it has the risk of <code>single-point of failure</code>. </p>&#xA;&#xA;<p>This varying opinion is very confusing to me. So,I am looking for the suggestions on whether I should be using Api Gateway or not. <code>What is the right practice here ?</code> </p>&#xA;"
45453061,What is the difference between microservices and webservices?,<web-services><microservices>,3,3866,1,1.0,6,"<p>The closest I got to finding the actual difference is this <a href=""http://www.tatvasoft.com/blog/the-difference-between-micro-services-and-web-services/"" rel=""nofollow noreferrer"">article</a>.</p>&#xA;&#xA;<p>But I didn't understand what would make me choose one over the other and if microservices can also use a REST API and communicate via http.</p>&#xA;&#xA;<p>I mainly didn't understand what a microservice is and if it can come instead of a webservice, other than the purpose of </p>&#xA;&#xA;<blockquote>&#xA;  <p>breaking large software applications into loosely coupled modules</p>&#xA;</blockquote>&#xA;"
43290480,Using celery to build microservices,<python-2.7><celery><microservices><celerybeat>,1,1023,0,3.0,6,"<p>I am going break down a project into small microservices.</p>&#xA;&#xA;<p>All microservices are cron-based. I am thinking of celery as a task distribution as well a mechanism to run periodic tasks (celerybeat).</p>&#xA;&#xA;<p>I don't want to build multiple celery app per microserverice as that will increase overhead of having multiple brokers and multiple flower system to use for monitoring.</p>&#xA;&#xA;<p>I tried with single app on multiple servers but I failed. My needs with celery are :</p>&#xA;&#xA;<ol>&#xA;<li>I need to have independent servers for each microservice </li>&#xA;<li>Task belonging to certain microservice should execute only on their servers; no sharing of task among other servers</li>&#xA;<li>In case microservice is down i don't want celerybeat to clog the broker with thousands of pending tasks, resulting in halting service at other microservices. </li>&#xA;<li>In do not have any need of communication between microservices.</li>&#xA;</ol>&#xA;&#xA;<p>I tried separating queues per worker which doesn't seem to be possible&#xA;I tried one worker per server but i need more than one worker on per microservices</p>&#xA;"
37830008,Handling multiple event dependency in event-driven architecture,<publish-subscribe><microservices><event-driven>,2,348,0,2.0,6,<p>What would be best practice if you have an event-driven architecture and a service subscribing to events has to wait for multiple event (of the same kind) before proceeding with creating the next event in the chain?</p>&#xA;&#xA;<p>An example would be a book order handling service that has to wait for each book in the order to have been handled by the warehouse before creating the event that the order has been picked so that the shipping service (or something similar) picks up the order and starts preparing for shipping.</p>&#xA;
44065208,Data integrity across the databases of different Microservices,<database><foreign-keys><relational-database><rdbms><microservices>,1,801,4,0.0,6,"<p>Let's say I am using relational databases for my microservices. I have <code>CustomersMService</code> which has its own database with table <code>Customer</code>, then I have <code>OrdersMService</code> which also has its own database but with table <code>Order</code> and that table has column <code>CustomerId</code>. My question is how can I ensure data integrity between databases, that <code>Orders</code> table won't point to non-existent Customers?</p>&#xA;"
29636899,Do microservices break the bounded context?,<domain-driven-design><microservices>,2,3461,3,3.0,7,"<p>I am a bit confused. I am working in a young banking company and we decided to implement a DDD architecture to break complexity.</p>&#xA;&#xA;<p>So, here is my question (it follows a design suggestion made by someone in the team). Let's say we have 3 different domains. D1, D2, D3, that expose domain (web)services. Each domain manipulates strongly typed business entities, that rely on the same tables. In front of these domains, we want a microservice to garantee that data persisted in tables is consistent, in a centralized manner. D1, D2 and D3 ask the microservice to persist data conforming to specific rules. We want the microservice to act as a CRUD proxy to the tables. The microservice provides specific DTOs to D1, D2 and D3 domains, obfuscating the tables to D1, D2, D3.</p>&#xA;&#xA;<p>Does this approach sound good ? Would you consider using microservices in a DDD architecture to manage CRUD and data consistency for 1+ domains ? Does ""CRUDing"" and validating data with a microservice break the bounded context ? What are the best practices with dealing with microservices in a DDD architecture, if any ?</p>&#xA;&#xA;<p>Many thanks for your contribution,</p>&#xA;&#xA;<p>[EDIT]</p>&#xA;&#xA;<p>The following article helped me to refine my thoughts : <a href=""http://martinfowler.com/bliki/MicroservicePremium.html"" rel=""noreferrer"">http://martinfowler.com/bliki/MicroservicePremium.html</a></p>&#xA;&#xA;<p>Microservices are useful on complex situations where monolithic systems failed at being maintainable. They are not good candidates for upfront design implementations. On the other hand, DDD tries to tackle complexity at the very beginning of the projects. Successful DDD should not meet microservices implementations.</p>&#xA;"
29704842,Integration testing Spring Boot based Microservices,<junit><spring-boot><microservices>,2,3024,4,1.0,7,"<p>I have read many of the guides about working with Spring Boot and RESTful services, and many of them contain information about running unit tests, most notably ""Building an Application with Spring Boot"".  However, I haven't seen anything that gives an example on how to unit test a Spring Boot application that consumes/depends on other Spring Boot applications, as is common in cloud micro-services architecture. So, for example, we have the following Spring Boot services:</p>&#xA;&#xA;<p>ServiceMediator,&#xA;Adapter1,&#xA;Adapter2</p>&#xA;&#xA;<p>ServiceMediator calls Adapter1 or Adapter2, depending on the input.</p>&#xA;&#xA;<p>Is there a way to start up the Spring Boot services Adapter1 and Adapter2  before starting and testing the ServiceMediator in a Spring JUnit test?</p>&#xA;"
40205675,Microservices Authentication best practices and security (OAuth 2.0 and OpenIdConnect),<security><oauth><oauth-2.0><microservices><openid-connect>,2,1694,2,3.0,7,"<p>There are several ways to build authentication in micro-services. However very popular is using JWT tokens and OAuth protocol together with OpenID Connect identity layer.</p>&#xA;&#xA;<p>In <a href=""http://nordicapis.com/api-security-oauth-openid-connect-depth/"" rel=""nofollow"">this tutorial</a> explaining how it can be achieved there is one tip:  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Pass by reference when tokens have to leave your network, and then convert them to by-value tokens as they enters your space. Do this conversion in your API gateway.</p>&#xA;</blockquote>&#xA;&#xA;<p>However it's not clear to me what's reason behind it. I suspect it might be due to some security benefits (not to give client possibility to read any specific info). Because in the JWT token itself it might be info about roles/permission. But for this purpose token can also be encrypted.</p>&#xA;&#xA;<p>Another reason might be that JWT token is too big and in order to don't carry this token every time such approach might be used. (or if JWT token is stored in cookie it has size limits).</p>&#xA;&#xA;<p>I haven't seen any info that JWT token authentication is compromised and it's a bad practice to keep it on client (in browser).</p>&#xA;&#xA;<p>On the other hand I see that Ping Identity is also using <strong>pass by reference</strong> approach. Can you help me understand the reasoning behind it?</p>&#xA;"
41903352,How do I register a microservice (or its methods) to Task in Netflix Conductor?,<microservices><netflix><amazon-swf><axon><netflix-conductor>,2,1341,1,0.0,7,"<p>I was looking for a more sophisticated workflow than Saga from AxonFramework  -- which we are currently using -- and I found one in Netflix Conductor. &#xA;Sadly, I have searched the Internet for a decent example but to no avail.</p>&#xA;&#xA;<p>My question is, in Netflix Conductor, how might one define and create Task or WorkflowTask and most importantly, link a microservice to it? Here is a Netflix Conductor code from github:</p>&#xA;&#xA;<pre><code>    WorkflowDef def = new WorkflowDef();&#xA;    def.setName(""test"");&#xA;    WorkflowTask t0 = new WorkflowTask();&#xA;    t0.setName(""t0"");&#xA;    t0.setType(Type.SIMPLE);&#xA;    t0.setTaskReferenceName(""t0"");&#xA;&#xA;    WorkflowTask t1 = new WorkflowTask();&#xA;    t1.setName(""t1"");&#xA;    t1.setType(Type.SIMPLE);&#xA;    t1.setTaskReferenceName(""t1"");&#xA;&#xA;    def.getTasks().add(t0);&#xA;    def.getTasks().add(t1);&#xA;</code></pre>&#xA;&#xA;<p>Pardon my confusion as I am new to Netflix Conductor.</p>&#xA;"
28930710,How to avoid concurrency issues when scaling writes horizontally?,<azure><scalability><sharding><microservices><horizontal-scaling>,5,639,2,3.0,8,"<p>Assume there is a worker service that receives messages from a queue, reads the product with the specified Id from a document database, applies some manipulation logic based on the message, and finally writes the updated product back to the database (a).</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/RZYlA.png"" alt=""horizontally scaling writes""></p>&#xA;&#xA;<p>This work can be safely done in parallel when dealing with different products, so we can scale horizontally (b). However, if more than one service instance works on the same product, we might end up with concurrency issues, or concurrency exceptions from the database, in which case we should apply some retry logic (and still the retry might fail again and so on). </p>&#xA;&#xA;<p><strong>Question</strong>: How do we avoid this? Is there a way I can ensure two instances are not working on the same product?</p>&#xA;&#xA;<p><strong>Example/Use case</strong>: An online store has a great sale on productA, productB and productC that ends in an hour and hundreds of customers are buying. For each purchase, a message is enqueued (productId, numberOfItems, price).  <strong>Goal</strong>: How can we run three instances of our worker service and make sure that all messages for productA will end up in instanceA, productB to instanceB and productC to instanceC (resulting in no concurrency issues)?</p>&#xA;&#xA;<p><strong>Notes</strong>: My service is written in C#, hosted on Azure as a Worker Role, I use Azure Queues for messaging, and I'm thinking to use Mongo for storage. Also, the Entity IDs are <code>GUID</code>.</p>&#xA;&#xA;<p>It's more about the technique/design, so if you use different tools to solve the problem I'm still interested.</p>&#xA;"
30648096,centralized API documentation for microservices,<api><documentation><microservices>,3,3386,5,2.0,8,"<p>My team and I are currently building multiple services in parallel. We have the benefit of building all the services from scratch. I would like the ability to automatically display all API endpoints, from all services, in one page/site.  This would be helpful because (among other things):</p>&#xA;&#xA;<ol>&#xA;<li><p>I don't have to go to multiple documentation sites to see what are the available endpoints in my entire ""system"". </p></li>&#xA;<li><p>It'll be a good first step to determine if any of the services should be split, combined or simply refactored.  </p></li>&#xA;</ol>&#xA;&#xA;<p>Some of our services are in Django and the <a href=""http://swagger.io/"" rel=""noreferrer"">rest-swagger</a> module is a great help. But I don't see how I can combine rest-swagger documentation from multiple services into a single documentation page/site.</p>&#xA;&#xA;<p>I'm currently looking through <a href=""http://microservices.io/index.html"" rel=""noreferrer"">this site</a> and anything related to the <a href=""http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/"" rel=""noreferrer"">Netflix experience</a> but could not find a solution to my problem. Maybe centralized documentation isn't a big deal with 600+ services at Netflix, but that's hard to believe.</p>&#xA;&#xA;<p>Can anyone suggest a tool or method to have a combined API documentation for all services in a microservice architecture? </p>&#xA;&#xA;<p>My ideal scenario of what happens when a service is changed: </p>&#xA;&#xA;<ol>&#xA;<li>I click on the link to see the list of endpoints in my system.</li>&#xA;<li>A teammate updates a service and also it's documentation.</li>&#xA;<li>I refresh the page I am currently and I see that change made from step #2.</li>&#xA;</ol>&#xA;"
36083504,Database connection pool strategy for micro services,<database><postgresql><jdbc><connection-pooling><microservices>,1,1749,2,0.0,8,"<p>We are trying to convert our monolithic application to a micro services based architecture. We use Postgresql as one of our database in the monolithic application with BoneCP for connection pooling. </p>&#xA;&#xA;<p>When this monolith is split to a number of independent micro-services with each of them running in a different JVM, I can think about two options for connection pooling</p>&#xA;&#xA;<ol>&#xA;<li>BoneCP or any decent connection pool for each microservice - My initial research shows that this is the primary choice. It is possible to have a fine grained control of connection requirements for each service.But, down side is that as the number of services increase, number of connection pool also increases and eventually there will be too many idle connections assuming that minimum connections in each pool is greater than 0.</li>&#xA;<li>Rely on database specific extensions like PGBouncer - This approach has the advantage that connection pool is managed by a central source rather than a pool for each micro service and hence number of idle connections can be brought down. It is also language/technology agnostic. Down side is that these extensions are database specific and some of the functionalities in JDBC may not work. For eg: Prepared statments may not work with PGBouncer in Transaction_Pooling mode. </li>&#xA;</ol>&#xA;&#xA;<p>In our case most of the micro-services(at least 50) will be connecting to the same Postgres server even though the database can be different. So, if we go with option 1, there is a higher chance of creating too many idle connections.The traffic to most of our services are very moderate and the rationale behind moving to micro-service is for easier deployment, scaling etc.</p>&#xA;&#xA;<p>Has anyone faced a similar problem while adopting micro-services architecture? Is there a better way of solving this problem in micro-service world?</p>&#xA;"
31317470,How should you deal with auth and sharing Users info across microservices?,<node.js><mongodb><nginx><microservices>,1,1189,3,6.0,8,"<p><strong>TLTR:</strong> What is a good way to communicate across services for Auth and User Info regardless of location of server or technology used</p>&#xA;&#xA;<p>I'm trying to learn about microservices and I'm a little bit unclear as to how I should approach accessing user information and control access with multiple services. Please let me know if I am approaching this completely wrong.</p>&#xA;&#xA;<p>For example I have a basic service for Blog CRUD operations and a Service for uploading and storing images and videos. I haven't done anything with Authorization or Users yet (except I am accounting for UserIds eventually being present in my Models (e.g. in my blog model ObjectID's for author, commenters, etc).</p>&#xA;&#xA;<p>I want to keep this as separated as possible (for learning purposes more then anything) and while at the moment I am building it all in Node.js I hope to be able to swap in and out different technologies such as nginx, a java/go/python service or a different storage (currently mongo, but would like to be able to switch to sql as an option )</p>&#xA;&#xA;<p>How I currently have these structured is I have both services built as Express.js apps and currently I am using node-http-proxy to proxy to the express services (this is just to save with setting up nginx for now but I don't want to be dependent on nginx either).</p>&#xA;&#xA;<p><em>How should I approach:</em></p>&#xA;&#xA;<ul>&#xA;<li><p>Authenticated user or some of the routes (e.g. when creating a new post or updating/deleting) and Not when getting the post to Read (eventually I would like to incorporate roles too)</p></li>&#xA;<li><p>populating the User information e.g. from the user's ID stored in the blog author and replacing it with the user information (in a single app I could just use mongoose populate</p></li>&#xA;</ul>&#xA;&#xA;<p>The main aim is I would like to keep the Auth and Users in separate services that could be called in any other service and stored in another DB for example if they were located on different physical servers.</p>&#xA;&#xA;<p>someone had suggested to me I could do this using HTTP/S but is there a better way to do this and can anyone point me to any implementation examples, Node.js would be preferable but not essential</p>&#xA;&#xA;<p>This likely requires some service registry but I am a bit lost as to how this would be implemented</p>&#xA;"
43426699,DB design for microservice architecture,<database><design><microservices>,2,7671,0,4.0,8,"<p>I am planning to use the Microservices architecture for the implementation of our website. I wanted to know if it is right to share databases between services or if it is preferable to have a separate database for each service. In this regard, can I consider having one common database for all services or does it violate the very essence of Microservice architecture ?</p>&#xA;"
35289988,Authorization and user microservices design,<microservices>,2,856,2,4.0,10,"<p>I'm trying to design microservice from an existing application with a quite standard user management: has authentication and authorization, and stores user data.</p>&#xA;&#xA;<p>I'm developping an <em>Authorization server</em> to manage user <strong>authentication</strong> and <strong>authorization</strong> using <code>OAuth2</code> as authorization. On other side I have to store user's information/profile.</p>&#xA;&#xA;<p><strong>Question:</strong> Should <em>Authorization server</em> manage:</p>&#xA;&#xA;<ul>&#xA;<li><strong>both authorization and user API?</strong> Thus other microservices can contact <em>Authorization server</em> on <code>/me</code> to get current user but also <code>/users</code> to get full list of users.</li>&#xA;<li><strong>Or only authorization and I have to create <em>User microservices</em>?</strong> Thus <em>Authorization server</em> only exposes <code>/me</code> API related to user and <em>User microservices</em> will expose <code>/users</code>?</li>&#xA;</ul>&#xA;&#xA;<p>The first solution is a bit simpler but the <em>Authorization server</em> will become less generic (less reusable) because user application data model will be part of it (database data model of <code>User</code> table).</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>The other requirement is <strong><em>Authorization server</em> should check if a user exists before authorizing it</strong>. </p>&#xA;&#xA;<p>There is no user auto-creation, users must be invited by <em>administrator</em> to get access.&#xA;With this requirement, the first solution is simple because <em>Authorization server</em> has access to user database but the second solution <em>Authorization server</em> implies:</p>&#xA;&#xA;<ol>&#xA;<li>Share database with <em>User service</em> (hum don't like that)</li>&#xA;<li>Call <em>User service</em> before authorization using REST API (for example) </li>&#xA;<li><em>Authorization server</em> should maintain minimal <code>User</code> table (can be renamed <code>Account</code>) and administrator will not create user on <em>User service</em> but only user account on <em>Authorization server</em></li>&#xA;</ol>&#xA;&#xA;<p>I think <strong>1.</strong> solution is out but any advices about <strong>2.</strong> and <strong>3.</strong>?</p>&#xA;&#xA;<p><strong>3.</strong> in first place seems the best, but if I want to switch to another <em>Authorization server</em>, for example a public one (OAuth2) like Google, Github, Facebook, etc... Security can be compromise because we can't control user account creation.</p>&#xA;&#xA;<p>Any feedback?</p>&#xA;"
28607400,Sessions in a Microservice architecture for an E-Commerce system,<php><magento><soa><single-page-application><microservices>,4,1282,2,5.0,10,"<p>I plan on developing a microservice E-Commerce system as proof of concept. The architecture consists of 3 components:</p>&#xA;&#xA;<ul>&#xA;<li><p>a javascript based single page application, which sends AJAX requests to</p></li>&#xA;<li><p>a server (API Gateway) with a REST API which feeds JSON data received by calling other services</p></li>&#xA;<li><p>3 services: CatalogProvider, CustomersProvider, CheckoutProvider</p></li>&#xA;</ul>&#xA;&#xA;<p>For now the services all are API endpoints of a Magento Shopsystem. </p>&#xA;&#xA;<p>When I try to log in a user into they Magento system by sending a request to the REST Api obviously the server doesn't remember the session when sending the next request.</p>&#xA;&#xA;<p>Also I handle the shopping cart on the server side with Magento and add/update/remove items by REST Api calls. Here, also the added items get lost when sending the next request as the session got lost.</p>&#xA;&#xA;<p>So my question is:</p>&#xA;&#xA;<p>What are possible approaches to solve issues regarding session handling in a microservice architecture?</p>&#xA;"
32741333,Session Management in microservices,<java><session><cookies><weblogic><microservices>,1,9293,3,5.0,10,"<p>We have the following setup.</p>&#xA;&#xA;<ol>&#xA;<li>STM (Stingrey Traffic Manager) does load balancing + session stickiness</li>&#xA;<li>Weblogic 'cluster'</li>&#xA;<li>Auth handled by a third party tool</li>&#xA;</ol>&#xA;&#xA;<p>Therefore I do not have to worry about session with regards to horizontal scaling/ running multiple instances of the application. STM/ Weblogic cluster makes sure that the subsequent request come to same managed server.</p>&#xA;&#xA;<p>What we currently have is a monolithic application and we are trying to move to microservices. Also we do not wan't to move out of current infrastructure (i.e. STM/ Weblogic cluster/ Auth tool). What we have planned is:</p>&#xA;&#xA;<ol>&#xA;<li>A Gateway WAR which routes requests to other microservices</li>&#xA;<li>N x Microservices (WAR) for each functional sub-domain</li>&#xA;<li>Only the API Gateway receives user requests and other microservices are not accessible from outside</li>&#xA;</ol>&#xA;&#xA;<p>So my question is</p>&#xA;&#xA;<ol>&#xA;<li>Should API Gateway be state-full while other microsevices are stateless?</li>&#xA;<li>If so, how should the user session data be shared between API Gateway and microservices?</li>&#xA;</ol>&#xA;&#xA;<p>Please suggest any better alternatives and resources/links as well.  Thanks.</p>&#xA;"
38786207,Netflix Feign - Propagate Status and Exception through Microservices,<java><spring><spring-boot><microservices><netflix-feign>,4,13177,0,1.0,10,"<p>I'm using <a href=""https://github.com/OpenFeign/feign/blob/master/okhttp/src/main/java/feign/okhttp/OkHttpClient.java"" rel=""noreferrer"">Netflix Feign</a> to call to one operation of a Microservice A to other other operation of a Microservice B which validates a code using Spring Boot. </p>&#xA;&#xA;<p>The operation of Microservice B throws an exception in case of the validation has been bad. Then I handled in the Microservices and return a <code>HttpStatus.UNPROCESSABLE_ENTITY</code> (422) like next:</p>&#xA;&#xA;<pre><code>@ExceptionHandler({&#xA;       ValidateException.class&#xA;    })&#xA;    @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY)&#xA;    @ResponseBody&#xA;    public Object validationException(final HttpServletRequest request, final validateException exception) {&#xA;        log.error(exception.getMessage(), exception);&#xA;        error.setErrorMessage(exception.getMessage());&#xA;        error.setErrorCode(exception.getCode().toString());&#xA;        return error;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>So, when Microservice A calls to B in a interface as next:</p>&#xA;&#xA;<pre><code>@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /other"")&#xA;void otherOperation(@Param(""other"")  String other );&#xA;&#xA;@Headers(""Content-Type: "" + MediaType.APPLICATION_JSON_UTF8_VALUE)&#xA;@RequestLine(""GET /code/validate"")&#xA;Boolean validate(@Param(""prefix"") String prefix);&#xA;&#xA;static PromotionClient connect() {&#xA;&#xA;    return Feign.builder()&#xA;        .encoder(new GsonEncoder())&#xA;        .decoder(new GsonDecoder())&#xA;        .target(PromotionClient.class, Urls.SERVICE_URL.toString());&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>and the validations fails It returns a internal error 500 with next message:</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": ""2016-08-05T09:17:49.939+0000"",&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""feign.FeignException"",&#xA;  ""message"": ""status 422 reading Client#validate(String); content:\n{\r\n  \""errorCode\"" : \""VALIDATION_EXISTS\"",\r\n  \""errorMessage\"" : \""Code already exists.\""\r\n}"",&#xA;  ""path"": ""/code/validate""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I need to return the same as the Microservice operation B.</p>&#xA;&#xA;<p>Wich would be the best ways or techniques to propagate Status and Exceptions through microservices using Netflix Feign?</p>&#xA;"
43612866,Microservices with shared database? using multiple ORM's?,<database><orm><microservices>,2,7791,3,3.0,10,"<p>I'm learning about microservices and I'm gonna build a project with a microservices architecture.</p>&#xA;&#xA;<p>The thing is, one of my team mates want to use one database for all services, sharing all tables so ""data doesn't get repeated"", each service would be built with different frameworks and languages like django and rails which use very different ORM standards.</p>&#xA;&#xA;<p>What would be the correct approach? Since I think working with one database would involve a lot of ""hacking"" the ORMs in order to make them work correctly.</p>&#xA;"
36415988,Is there some crashreporting library for java applications?,<java><monitoring><microservices><reliability>,1,56,3,0.0,-2,"<p>I wan't to be able to perform Asserts in production runtime, and send out crash reports (with CRITICAL or WARNING messages) through different channels. Emails being one of them.</p>&#xA;&#xA;<p>As you can see, I wan't this library to be performing collection of most commonly required stats - like Stacktrace, Host details, configurations etc. </p>&#xA;"
43593778,Microservices design,<java><spring><microservices>,1,122,9,1.0,-2,"<p>I am new to microservices and I am getting a hardtime in understanding what they exactly are. I would take an example situation, if you can break it down to how microservices should be written for this scenario then it woud be really great. </p>&#xA;&#xA;<p>Scenario: I have to work with two content management systems: Documentum and IBM FileNet.</p>&#xA;&#xA;<p>For each content management system I want to write an implementation to - </p>&#xA;&#xA;<ol>&#xA;<li>Create a new file or a folder.</li>&#xA;<li>Update a fileor a folder. </li>&#xA;<li>Delete a fileor a folder.</li>&#xA;<li>Update fileor folder metadata.</li>&#xA;<li>Search a file.</li>&#xA;<li>Get content of a file.</li>&#xA;<li>Create and Update permission sets applied on file or folder.&#xA;etc. </li>&#xA;</ol>&#xA;&#xA;<p>How should I break this down to microservices? &#xA;Should I write implementation for each content management systems in a seperate microservice? </p>&#xA;&#xA;<p>Please help.</p>&#xA;&#xA;<p>Thanks </p>&#xA;"
40884616,REST based message queue for microservices,<java><activemq><message-queue><microservices>,1,660,3,0.0,-2,"<p>I'm given a task to implement Message queue to publish and consume message over queue but my requirement is, i'm gonna need to interact with queue using REST API (eg: ActiveMQ having REST API but problem with ActiveMq is when implementing consumer  we don't have way to keep waiting for message queue to fetch,we cant listen to the queue using REST client ).&#xA;So  i'm leaving my problem to you guys to give me better alternative for this &#xA;NOTE - solution should use only open source product only </p>&#xA;"
50891382,Unit test does not cover locally imported packages,<go><microservices><go-gin><go-toolchain>,1,55,4,0.0,-2,"<p>I am new to golang and trying to understand how i can make this scenario work?</p>&#xA;&#xA;<p>Here is my structure&#xA;GOPATH set to /Users/xyz/project</p>&#xA;&#xA;<pre><code>/Users/xyz/project/src/main.go // import calculator and call SUM with two integeres&#xA;/Users/xyz/project/src/main_test.go // test function&#xA;/Users/xyz/project/src/calculator/sum.go // SUM function (add two integers)&#xA;</code></pre>&#xA;&#xA;<p>i have a main go file that imports ""calculator"" which is a local packages. When i run </p>&#xA;&#xA;<pre><code>go test -cover&#xA;</code></pre>&#xA;&#xA;<p>it only gives the coverage of main but not for the package ""calculator"" imported by main. i know i can write a test inside calculator and that would do the trick but is there any way possible to get the coverage of locally imported package from main?</p>&#xA;&#xA;<p>Bigger Context - The reason i want to do this is because i have a micro service written in go using gin framework and i want to spin it up as a service and make http calls and further see how the coverage looks like (like component test). I can easily spin it up by writing a main_test go file which starts the service but i am not getting the coverage of the imported packages.</p>&#xA;"
36026454,SFTP ChannelSftp.put stop it's execution process but successfully being uploaded or copy the source file,<java><sftp><dropwizard><jsch><microservices>,1,571,5,1.0,-1,"<p>details:</p>&#xA;&#xA;<p>in my API i have struggle on debugging why is that the ChannelSftp.put method hangs up or stop it's execution process but when checking it's output it is successfully being uploaded. </p>&#xA;&#xA;<p>here's my code snippet:</p>&#xA;&#xA;<p>MyService.class</p>&#xA;&#xA;<pre><code>@Inject&#xA;MyConfiguration conf;&#xA;&#xA;public String copyAndMove( String fileName ){&#xA;    try{&#xA;        MyServer origin = conf.getOriginServer().setFileName( fileName );&#xA;        MyServer destination = conf.getDestinationServer().setFileName( fileName );&#xA;&#xA;        SFTPServer originSftpServer = new SFTPServer( origin ).build();&#xA;        SFTPServer destinationSftpServer = new SFTPServer( destination ).build();&#xA;&#xA;        // originSftpServer.copyTo(destinationSftpServer);&#xA;        originSftpServer.copyTo(originSftpServer);&#xA;&#xA;        return ""Successfully copied file."";&#xA;        }catch( Exception ex ){&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>SFTPServer.class</p>&#xA;&#xA;<pre><code>public class SFTPServer {&#xA;&#xA;    private MyServer server;&#xA;    private static SFTPServer instance;&#xA;&#xA;    private Session session = null;&#xA;    private Channel channel = null;&#xA;    private ChannelSftp channelSftp = null;&#xA;&#xA;    // getters and setters&#xA;&#xA;    public SFTPServer(){}&#xA;&#xA;    public SFTPServer(MyServer server) throws  Exception{&#xA;        if(CommonUtil.isNull( server )){&#xA;            throw new Exception(""MyServer cannot be null!"");&#xA;        }&#xA;&#xA;        this.server = server;&#xA;    }&#xA;&#xA;    public SFTPServer build(){&#xA;        try{&#xA;            this.session = SFTPUtil.constructSession(getServer());&#xA;            this.channel = SFTPUtil.constructChannel(getSession());&#xA;            this.channelSftp = (ChannelSftp) channel;&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }&#xA;    }&#xA;&#xA;    public SFTPServer copyTo( SFTPServer destination ) {&#xA;        InputStream is = null;&#xA;        try{&#xA;            ChannelSftp channel = destination.getChannelSftp();&#xA;            String originSourceFile = String.format(""%s/%s"", getServer().getSourceFilePath(), getServer().getFileName());&#xA;            String destinationProcessedFile = String.format(""%s/%s"", destination.getServer().getProcessedFilePath(), destination.getServer().getFileName());&#xA;&#xA;            is = getChannelSftp().get(originSourceFile);&#xA;            channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);&#xA;&#xA;            return this;&#xA;        } catch (Exception ex) {&#xA;            throw new IllegalStateException(ex.getMessage(), ex);&#xA;        }finally{&#xA;            CommonUtil.closeQuitely(is); // close input stream&#xA;            destination.destroy(); // disconnect session, channel, channelSftp&#xA;        }&#xA;    }&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The problem is this. it's seems that it cannot proceed until the program done for it's execution. when i debug on it it stop and it's execution for this code: <strong>channel.put(is, destinationProcessedFile, ChannelSftp.OVERWRITE);</strong> but on the sftp server it is successfully being copied from source to destination file path. please help me with this problem because it cannot return the <strong>Successfully copied file.</strong> on the service part. thanx. </p>&#xA;"
42105805,Microservices Communication Design,<python><api><microservices>,2,629,0,0.0,-1,<p>I would like to know how to create a communication for each services. I am using API Gateway for the outside of the system to communicate with the services within. Is it necessary for a service to call another service through API Gateway or just directly into the service itself ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;
35838016,Which microservice library is best or mostly used?,<microservices>,1,472,3,0.0,-1,<p>I am split my business logic into micro services. Which micro services library is good or mostly used? what about apache karaf? </p>&#xA;
41749456,How to integrate Machine learning into a ruby on rails application,<python><ruby-on-rails><r><ruby><microservices>,1,1288,0,1.0,-1,"<p>Given Python and R have huge machine learning libraries that make it easy to train a machine learning model, and given rails provides a very fast way of building a web app, is there a 'best practice' for integrating a machine learning model (written in python or R) into a rails application? </p>&#xA;&#xA;<p>If so what tools can we use? What are pros and cons of each?</p>&#xA;"
49922136,Nuget package restore ERROR,<.net><.net-core><nuget><microservices><nuget-package>,1,47,6,0.0,-1,<p>We created one rest client application and pushed it to nuget with version 1.0.0 and used it in one of our Micro Services and then recently we updated our Rest client application with new version 1.1.0 and tried to update it in our Micro services using nuget package restore. </p>&#xA;&#xA;<p>Now we got the latest version of our RestClient application dll ie Project.json file got updated with my latest version 1.1.0. But now when i try to build the application i am getting error for namespace not found for restclient</p>&#xA;&#xA;<p>When i checked project.json its already updated with my new version 1.1.0</p>&#xA;&#xA;<p>NOTE: I am using .net core</p>&#xA;&#xA;<p>Why i am not getting reference to my latest RestClient dll (1.1.0) in my MicroServices? </p>&#xA;&#xA;<p>Is there any work around for it?</p>&#xA;&#xA;<p>One work around i did is i deleted Project.json.lock files and i tried to restore again. But no luck</p>&#xA;
38403001,How to listen two micro services on same port in Node.js,<node.js><microservices>,1,760,9,1.0,-1,"<p>I am new to micro service. I want to create one application with two micro services. But i don't know how to listen both (or more) micro services on a same port to make it as one application. &#xA;Is there any good tutorial pages available in online ? Please suggest me any blogpost or tutorial pages or help me to create a application with two micro services.</p>&#xA;&#xA;<p>I am trying to create a Bus booking application which has two services, </p>&#xA;&#xA;<ol>&#xA;<li>Bus Service (which gives bus names &amp; availability)</li>&#xA;<li>User Service (which gives &amp; connect user details with bus).</li>&#xA;</ol>&#xA;&#xA;<p>I created two this as two nodejs application. Now i need to know how to combine this two as one application (with microservice).for that i can't listen this to one port.</p>&#xA;"
51454764,View injection container for angular,<angular><dependency-injection><microservices><view-injection><micro-frontend>,1,49,3,1.0,-1,"<p>I'm trying to have an angular module for each backend microservice. So to keep each module independent and clean while they use each other's components when available and a default ""service-is-not-available"" component, when the component is not found in the container.</p>&#xA;&#xA;<p><strong>Example Scenario:</strong> Let's say there are a sales and accounting module.&#xA;The sales module needs a component with selector: 'total-price'.&#xA;Sales module and Accounting module are both used by the main module, but the sales doesn't know about accounting.&#xA;When I call the 'total-price' tag in sales I want the main module to find it in the accounting and display it in the sales.</p>&#xA;&#xA;<p>Here the 'total-price' tag selector works like an abstraction (OO interface) which it's implementation is placed at accounting module, and the main module should have an IOC to search and find the implementation an inject it to the sales, and return a not found view if the view is unavailable (kind of like null object pattern). This may also help with handling authorization and returning a proper view whenever the user is not permitted to see some component.</p>&#xA;&#xA;<p><strong>Code Sample:</strong>&#xA;<a href=""https://stackblitz.com/edit/angular-vxstyk?file=src%2Fapp%2Fsales%2Fsales%2Fsales.component.html"" rel=""nofollow noreferrer"">This</a> is a sample code for the scenario but it doesn't compile, because as my question states I'm looking for a way of orchestrating, and composing the UI and injecting the <code>&lt;total-price&gt;</code> component to sales without referencing the accounting module directly.</p>&#xA;"
