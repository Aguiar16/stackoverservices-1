Id,Title,CreationDate,Tags,AnswerCount,ViewCount,CommentCount,FavoriteCount,Score,Body
22513893,Microservices and SOA using messaging,2014-03-19 17:39:26,<architecture><messaging><soa><microservices>,5,5075,0,8.0,21,"<p>I've been very interested in trying out microservices/SOA as an architecture and am having a hard time conceptualizing how the integration between services would actually be done.</p>&#xA;&#xA;<p>I like the idea of using messaging to decouple the clients from the services, but don't understand how a system could utilize it exclusively. The typical async operations and pub/sub stuff obviously makes sense - scenarios like creating a new order, broadcasting data for reporting, etc. What I don't understand is whether people typically try to use messaging for common request/reply scenarios - for example, a user hits their ""profile"" page and part of the data that needs to get rendered on the page is from a user service.</p>&#xA;&#xA;<p>I know common messaging implementations provide REST-like reply/request functionality but is that often used for simple data requests? It seems more likely that microservices would both expose REST endpoints and also register with a message broker for different types of communication it will participate in, but all these presentations I watch of SOA and microservice architecture seem to suggest they only use one or the other..</p>&#xA;&#xA;<p>Thanks for any elaboration/experiences!</p>&#xA;"
28942614,Should I use forever/pm2 within a (Docker) container?,2015-03-09 13:00:16,<node.js><docker><coreos><microservices>,2,10713,0,13.0,37,"<p>I am refactoring a couple of node.js services. All of them used to start with <code>forever</code> on virtual servers, if the process crashed they just relaunch.</p>&#xA;&#xA;<p>Now, moving to containerised and state-less application structures, I think the process should exit and the container should be restarted on a failure.</p>&#xA;&#xA;<p>Is that correct? Are there benefits or disadvantages?</p>&#xA;"
25600580,Sharing code and schema between microservices,2014-09-01 07:13:19,<architecture><microservices>,4,8717,1,9.0,40,"<p>If you go for a <strong>microservices architecture</strong> in your organization, they can share configuration via <a href=""http://zookeeper.apache.org/"">zookeeper</a> or its equivalent. However, how should the various services share a common db schema? common constants? and common utilities?</p>&#xA;&#xA;<p>One way would be to place all the microservices in the same code repository, but that would contradict the decoupling that comes with microservices...</p>&#xA;&#xA;<p>Another way would be to have each microservice be completely independent, however that would cause code duplication and data duplication in the separate databases each microservice would have to hold.</p>&#xA;&#xA;<p>Yet another way would be to implement functional microservices with no context\state, but that's usually not realistic and would push the architecture to having a central hub that maintains the context\state and a lot of traffic from\to it.</p>&#xA;&#xA;<p><strong>What would be a scalable, efficient practical and hopefully beautiful way to share code and schema between microservices?</strong> </p>&#xA;"
26331854,Micro services and .NET,2014-10-13 01:45:35,<.net><microservices>,5,43797,1,7.0,25,"<p>How to build micro service oriented application in .NET world? Are there any platforms where we can write micro service oriented apps in .NET world? How to envision architecture that includes Micro services, Event store and some of NoSQL databases?&#xA;Thanks.</p>&#xA;"
30422184,Where does Elixir/erlang fit into the microservices approach?,2015-05-24 09:54:33,<architecture><erlang><docker><elixir><microservices>,1,8742,7,26.0,88,"<p>Lately I've been doing some experiments with docker compose in order to deploy multiple collaborating microservices. I can see the many benefits that microservices provide, and now that there is a good toolset for managing them, I think that it's not extremely hard to jump into the microservices wagon.</p>&#xA;&#xA;<p>But, I have been experimenting with Elixir too, and I am quite fond of the benefits that provides by itself. Given that it encourages packing your code into multiple decoupled applications, and supports hot code upgrades, how would you mix docker with elixir (or erlang, for that matter)?</p>&#xA;&#xA;<p>For example, if I want to use docker because it provides dev-prod parity, how does elixir fit in that? Given that docker containers are immutable, I lose the ability to do hot-code upgrades, right? What about blue/green deployments or canary releases?</p>&#xA;&#xA;<p>I mean, I could just write microservices with Elixir and use them as if they were written in any other language, polyglotism is one of the benefits of microservices anyway, but then I'm not getting the full benefits of using the OTP platform, I guess that pure collaborative erlang applications are way more optimal that using intermediate queues to communicate between microservices written in different (or not) languages.</p>&#xA;"
31342583,How to manage/balance semi persistent jobs over service instances,2015-07-10 13:54:10,<php><load-balancing><apache-zookeeper><microservices>,3,261,0,4.0,17,"<p>I see a common pattern for services that we try to develop and I wonder if there are tools / libraries out there that would help here. While the default jobs as discussed in microservice literature is from the REQUEST -> RESPONSE nature, our jobs are more or less assignments of semi permanent tasks.</p>&#xA;&#xA;<p>Examples of such tasks</p>&#xA;&#xA;<ul>&#xA;<li>Listen on the message queue for data from source X and Y, correlate the data that comes in and store it in Z.</li>&#xA;<li>Keep an in-memory buffer that calculates a running average of the past 15 mins of data everytime a new data entry comes in.</li>&#xA;</ul>&#xA;&#xA;<p>Currently our services are written in PHP. Due to the perceived overhead of PHP processes and connections to the message queue we'd like a single service process to handle multiple of those jobs simultanously.</p>&#xA;&#xA;<p>A chart that hopefully illustrated the setup that we have in our head:&#xA;<img src=""https://i.stack.imgur.com/HHDls.png"" alt=""services_setup""></p>&#xA;&#xA;<ul>&#xA;<li>Service Workers are currently deamonized PHP scripts</li>&#xA;<li>For the Service Registry we are looking at Zookeeper</li>&#xA;</ul>&#xA;&#xA;<p>While Zookeeper (and Curator) do loadbalancing, I did not find anything around distributing permanent jobs (that are updatable, removable, and must be reassigned when a worker dies)</p>&#xA;&#xA;<p>Proposed responsibilities of a Job Manager</p>&#xA;&#xA;<ul>&#xA;<li>Knows about jobs</li>&#xA;<li>Knows about services that can do these jobs</li>&#xA;<li>Can assign jobs to services</li>&#xA;<li>Can send job updates to services</li>&#xA;<li>Can reassign jobs if a worker dies</li>&#xA;</ul>&#xA;&#xA;<p>Are there any libraries / tools that can tackle such problems, and can thus function as the Job Manager? Or is this all one big anti pattern and should we do it some other way?</p>&#xA;"
31313170,How to route in between microservices using Spring Cloud & Netflix OSS,2015-07-09 09:17:06,<spring-cloud><microservices><netflix-eureka><netflix-zuul><blue-green-deployment>,1,2730,2,16.0,17,"<p>During our development of microservices using Spring Cloud, we started out using Zuul as a proxy for any connection from the outside to microservices, and for any microservice needing to contact another microservice.</p>&#xA;&#xA;<p>After some time we made the conclusion that Zuul was designed to be an edge service (only proxying traffic from the outside to the microservices), and shouldn't be used for intermicroservices communication. Especially the way Spring Cloud recommends the use of eureka to make a direct (potentially load balanced) connection to another service made us go against having Zuul in between everything.</p>&#xA;&#xA;<p>Of course everything works nicely as expected (as it always does with Spring Cloud), but we are clueless on how to perform a certain use case with this setup.</p>&#xA;&#xA;<p>When deploying a new version of a microservice, we'd like to have a <a href=""http://martinfowler.com/bliki/BlueGreenDeployment.html"" rel=""noreferrer"">blue/green deployment</a> with the old and the new version.&#xA;However, having no Zuul in between the microservices, the communication between two separate services will continue to go to the old version until it is removed from eureka.</p>&#xA;&#xA;<p>We are thinking of how we can achieve this. In the picture below I have drawn what I think might be an option.</p>&#xA;&#xA;<p>In the first part of the picture, Zuul calls eureka to get the registry to create the routes. Also service 1 is calling eureka to get the registry to route to service 2. Since service 2 is in the eureka registry, the routing is done successfully.</p>&#xA;&#xA;<p>In the second part of the picture, an update of service 2 (service 2.1) is deployed. It registers with eureka as well, which makes service 1 now route to both service 2 and service 2.1. This is not wanted with the blue/green deployment.</p>&#xA;&#xA;<p>In the third part a potential solution to this issue is showcased with another instance of eureka being deployed just for this purpose. This instance isn't peer aware and won't sync with the first eureka instance. As opposed to the first instance, this one's only purpose is to facilitate the blue/green deployment. Service 2.1 registers with the second eureka instance, and service 1 his configuration is changed to fetch its registry not from the first but from the second eureka instance.</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/V9lpR.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>The main question we are facing is whether this is a viable solution. Having the flexibility of Zuul to route is a big plus which we don't have in this scenario. Should we move back to routing every service-to-service call through Zuul or is there another solution (maybe ribbon configuration of some sort) more appropriate? Or is the second eureka instance the best solution for this type of deployments?</p>&#xA;&#xA;<p>Any feedback would be greatly appreciated.</p>&#xA;&#xA;<p>Kind regards,&#xA;Andreas</p>&#xA;"
29591967,"Microservice architecture, what is a service in this case",2015-04-12 16:52:49,<java><web-services><rest><microservices>,6,4110,1,3.0,9,"<p>I'm reading some documentation about the micro-services architecture (through  <a href=""http://microservices.io/patterns/microservices.html"" rel=""noreferrer"">this link for example</a>) and I was wondering what is exactly a service in this case.</p>&#xA;&#xA;<p>In IT, everything could be called a service:&#xA;- a SPRING REST application launched through the java command like:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java -jar build/libs/gs-rest-service-0.1.0.jar</p>&#xA;</blockquote>&#xA;&#xA;<ul>&#xA;<li>It could also be a classes corresponding to the business layer in a DDD </li>&#xA;<li>It could be simply something related to the domain studied, like providing something to somebody</li>&#xA;<li>and many others... (android background running services etc...)</li>&#xA;</ul>&#xA;&#xA;<p>But in microservices, what does it mean? And what kind of technologies / tools are used to create a ""service running by himself"" in the Java EE stack for example? It's only related to webservices?</p>&#xA;"
33465577,How to manage secrets in a Microservice / Container / Cloud environment?,2015-11-01 18:21:40,<git><docker><microservices><secret-key>,1,2735,4,8.0,16,"<p>Microservices and Cloud is a thing. Everyone is talking and writing about. Personally i am thinking a lot about this topics: How this can be used to benefit from? What are possible challenges? How can this speedup the daily development? And how to manage all things?&#xA;One question that bothers me since a few days is ""How to manage secrets in a Microservice / Cloud environment?"".</p>&#xA;&#xA;<p>Imagine a company with 150 software engineers and various teams with various products. Every team is creating a software and every service needs various amounts of secrets (API-Keys, Passwords, SSH-Keys, whatever).&#xA;The ""old fashion"" way was to create a few configuration files in a ini / yaml / txt format and read it from. 12Factor apps say: Do it per env vars.</p>&#xA;&#xA;<p>Env vars can be set per machine and the config files can be placed there as well.&#xA;This works if you got a hand full of machines and the deployment is done by a few system admins.&#xA;One of the general rules say: ""Don`t store secrets in a Git repo."".</p>&#xA;&#xA;<p>Now the new world comes in.&#xA;Ever team is responsible for the application they produce itself.&#xA;They should be deployed and run by the team.&#xA;So our company is moving to a container and self-service way (e.g. Mesos and Marathon or Kubernetes).</p>&#xA;&#xA;<p>Of course, Dockerfiles can set env vars as well. And yes, you can ADD your config file into the Docker container during build.&#xA;But with this everyone can access the secrets (e.g. from other teams). And no one knows who uses this secrets and do something dangerous.</p>&#xA;&#xA;<p>You want to versionize your Dockerfiles as well. And applications you want to run on Marathon should be versionized (Git or whatever) as well (and applied by REST API). So where to store and manage all the secrets for this containers / apps?&#xA;Because with scheduler frameworks like Swarm and Machine (for Docker), Mesos and Marathon (usable for Docker as well) or Kubernetes you don`t know where your app will be running. This will be scheduled over several machines.&#xA;And most of this tools have no authentification (by default, of course this can be added by a Nginx proxy or something).</p>&#xA;&#xA;<p>One idea to manage secrets is using a tool like <a href=""https://vaultproject.io/"">Vault</a>. But i never saw ""native"" support in an app. The same applies for <a href=""https://github.com/StackExchange/blackbox"">Blackbox</a>. And i don`t know how configuration management can solve this. I know that Chef supports encrypted databags, but afaik it is not possible to use Chef to setup/build Docker containers.</p>&#xA;&#xA;<p>How do you manage secrets in a multi team env with several engineers in a Microservice / Container / Cloud environment?</p>&#xA;"
28767707,How to deal with shared state in a micro-service architecture?,2015-02-27 14:44:20,<deployment><architecture><integration-testing><microservices><test-environments>,3,4043,8,13.0,17,"<p>In our company we are transitioning from a huge monolithic application to a micro-service architecture. The main technical drivers for this decision were the need to be able to scale services independently and the scalability of development - we've got ten scrum teams working in different projects (or 'micro-services').</p>&#xA;&#xA;<p>The transition process is being smooth and we've already started to benefit from the advantages of this new technical and organizational structures. Now, on the other hand, <strong>there is a main point of pain that we are struggling with: how to manage the 'state' of the dependencies between these micro-services</strong>. </p>&#xA;&#xA;<p>Let's put an example: one of the micro-services deals with users and registrations. This service (let's call it X) is responsible for maintaining identity information and thus is the main provider for user 'ids'. The rest of the micro-services have a strong dependency on this one. For example, there are some services responsible for user profile information (A), user permissions (B), user groups (C), etc. that rely on those user ids and thus there is a need for maintaining some data sync between these services (i.e. service A should not have info for a userId not registered in service X). We currently maintain this sync by notifying changes of state (new registrations, for example) using RabbitMQ. </p>&#xA;&#xA;<p>As you can imagine, there are <em>many</em> Xs: many 'main' services and many more complicated dependencies between them.</p>&#xA;&#xA;<p>The main issue comes when managing the different dev/testing environments. Every team (and thus, every service) needs to go through several environments in order to put some code live: continuous integration, team integration, acceptance test and live environments. </p>&#xA;&#xA;<p>Obviously we need all services working in all these environments to check that the system is working as a whole. Now, this means that in order to test dependent services (A, B, C, ...) we must not only rely on service X, but also on its state. <strong>Thus, we need somehow to maintain system integrity and store a global &amp; coherent state</strong>.</p>&#xA;&#xA;<p>Our current approach for this is getting snapshots of all DBs from the live environment, making some transformations to shrink and protect data privacy and propagating it to all environments before testing in a particular environment. This is obviously a tremendous overhead, both organizationally and in computational resources: we have ten continuous integration environments, ten integration environments and one acceptance test environment that all need to be 'refreshed' with this shared data from live and the latest version of the code frequently. </p>&#xA;&#xA;<p>We are struggling to find a better way to ease this pain. Currently we are evaluating two options: </p>&#xA;&#xA;<ol>&#xA;<li>using docker-like containers for all these services </li>&#xA;<li>having two versions of each service (one intended for development of that service and one another as a sandbox to be used by the rest of the teams in their development &amp; integration testing)</li>&#xA;</ol>&#xA;&#xA;<p><strong>None of these solutions ease the pain of shared data between services</strong>. We'd like to know how some other companies/developers are addressing this problem, as we think this must be common in a micro services architecture. </p>&#xA;&#xA;<p>How are you guys doing it? Do you also have this problem? Any recommendation?</p>&#xA;&#xA;<p>Sorry for the long explanation and thanks a lot!</p>&#xA;"
30027545,Vert.x 3 and Microservices,2015-05-04 10:10:47,<architecture><vert.x><microservices>,3,2637,0,4.0,20,"<p>Microservices are gaining traction as an software architecture style that will better support continuous delivery, provide a model for rapid deployment and separation of concerns.</p>&#xA;&#xA;<p>Vert.x 3 and Vert.x-Apex provide an interesting model for building a microservices. As one of the examples shows, a simple verticle can expose an HTTP service, so a REST service is available. The verticle binds its own tcp port.</p>&#xA;&#xA;<p>When scaling up to multiple micro-services to support a full application you end up with a number of choices. Any thoughts on what style could eventually support continuous delivery, and minimizing downtime on upgrades?</p>&#xA;&#xA;<h2>Options</h2>&#xA;&#xA;<ol>&#xA;<li>Run multiple verticles could be a solution, all containing there own routing, so http handling is contained in the verticle. A request/response can be handled completely by the verticle. This could mean that every verticle runs on it's own tcp port. </li>&#xA;<li>Using a router you can expose all paths on a single port, and handle them accordingly. Data will be handled by the verticle that contains the router, possible passing it on to other verticles. This then starts to look like a more monolithic approach.</li>&#xA;<li>Run separate instances of vert.x containing the service (possible cluster them). This could make it easier use continuous delivery, because the whole thing is self-contained.</li>&#xA;<li>Other possible options?</li>&#xA;</ol>&#xA;&#xA;<h2>Deployment</h2>&#xA;&#xA;<p>On the deployment side rapid deployment of new services would be desirable, without bringing the whole application down. </p>&#xA;&#xA;<ul>&#xA;<li>Option 3. could provide a way for this, but can also cause overhead, especially when there is a DB verticle running in every verticle. </li>&#xA;<li>Option 1. could be easier, but what about reloading the new and updated verticles.</li>&#xA;</ul>&#xA;&#xA;<p>Separate micro-services offer an interesting way of development, but offers some challenges in orchestration and deployment.</p>&#xA;&#xA;<p>Any thoughts?</p>&#xA;"
29117570,Orchestrating microservices,2015-03-18 08:52:57,<http><orchestration><hypermedia><microservices>,7,41902,0,115.0,132,"<p>What is the standard pattern of orchestrating microservices?</p>&#xA;&#xA;<p>If a microservice only knows about its own domain, but there is a flow of data that requires that multiple services interact in some manner, what's the way to go about it?</p>&#xA;&#xA;<p>Let's say we have something like this:</p>&#xA;&#xA;<ul>&#xA;<li>Invoicing</li>&#xA;<li>Shipment</li>&#xA;</ul>&#xA;&#xA;<p>And for the sake of the argument, let's say that once an an order has been shipped, the invoice should be created. </p>&#xA;&#xA;<p>Somewhere, someone presses a button in a GUI, ""I'm done, let's do this!""&#xA;In a classic monolith service architecture, I'd say that there is either an ESB handling this, or the Shipment service has knowledge of the invoice service and just calls that.</p>&#xA;&#xA;<p>But what is the way people deal with this in this brave new world of microservices?</p>&#xA;&#xA;<p>I do get that this could be considered highly opinion-based. but there is a concrete side to it, as microservices are not supposed to do the above.&#xA;So there has to be a ""what should it by definition do instead"", which is not opinion-based.</p>&#xA;&#xA;<p>Shoot.</p>&#xA;"
35065875,How to bring a gRPC defined API to the web browser,2016-01-28 15:44:56,<javascript><node.js><protocol-buffers><microservices><grpc>,7,21905,0,25.0,49,"<p>We want to build a Javascript/HTML gui for our gRPC-microservices. Since gRPC is not supported on the browser side, we thought of using web-sockets to connect to a node.js server, which calls the target service via grpc. &#xA;We struggle to find an elegant solution to do this. Especially, since we use gRPC streams to push events between our micro-services.&#xA;It seems that we need a second RPC system, just to communicate between the front end and the node.js server. This seems to be a lot of overhead and additional code that must be maintained.</p>&#xA;&#xA;<p>Does anyone have experience doing something like this or has an idea how this could be solved?</p>&#xA;"
35113957,Running multiple projects using docker which each runs with docker-compose,2016-01-31 12:42:12,<docker><development-environment><docker-compose><microservices>,3,6126,0,5.0,12,"<p>We are using microservices approach to build our product. We are using some projects which each uses docker-compose to run. The problem is that in development environment, if we want to change codes in multiple projects and test developed codes, we must run projects separately and link them together manually.</p>&#xA;&#xA;<p>Now we want to create a development kit which clones projects and runs them together and handles links. Can docker-compose handle multiple docker-compose file? If not is there any sufficient tool to do that for us? Or is there any recommended approach for our goal?</p>&#xA;&#xA;<p>EDIT: For example we have two projects: PROJECT_A and PROJECT_B. Each one has its own docker-compose.yml and each one needs postgresql to run. We have docker-compose.yml in PROJECT_A like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_a:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>And we have docker-compose.yml in PROJECT_B like this:</p>&#xA;&#xA;<pre><code>db:&#xA;    image: postgres:9.4&#xA;    ports:&#xA;      - ""5432""&#xA;&#xA;project_b:&#xA;    build: .&#xA;    command: python2.7 main.py&#xA;    links:&#xA;        - db&#xA;</code></pre>&#xA;&#xA;<p>Each project can run separately and works fine. But if we want to change the api between PROJECT_A and PROJECT_B we need to run both projects and link them together to test our code. Now we want to write a development kit project which can run both projects and link them if needed. What is the best approach to do this?</p>&#xA;"
33041733,Microservices vs Monolithic Architecture,2015-10-09 15:11:34,<microservices>,3,26144,2,37.0,60,"<p>I did some reading about microservices, and I'm little bit intrigued.Seems like it is interesting concept. But I wonder, what are advantages and disadvantages using microservices over monolithic architecture, and vice versa.</p>&#xA;&#xA;<p>When microservices suitable better, and where better to go with monolithic architecture.</p>&#xA;"
33125508,Service discovery vs load balancing,2015-10-14 12:36:39,<web-services><amazon-web-services><cloud><distributed-computing><microservices>,3,5816,1,3.0,21,"<p>I am trying to understand in which scenario I should pick a service registry over a load balancer.</p>&#xA;&#xA;<p>From my understanding both solutions are covering the same functionality.</p>&#xA;&#xA;<p>For instance if we consider <strong>consul.io</strong> as a feature list we have:</p>&#xA;&#xA;<ul>&#xA;<li>Service Discovery</li>&#xA;<li>Health Checking</li>&#xA;<li>Key/Value Store</li>&#xA;<li>Multi Datacenter</li>&#xA;</ul>&#xA;&#xA;<p>Where a load balancer like <strong>Amazon ELB</strong> for instance has:</p>&#xA;&#xA;<ul>&#xA;<li>configurable to accept traffic only from your load balancer</li>&#xA;<li>accept traffic using the following protocols: HTTP, HTTPS (secure HTTP), TCP, and SSL (secure TCP)</li>&#xA;<li>distribute requests to EC2 instances in multiple Availability Zones</li>&#xA;<li>The number of connections scales with the number of concurrent requests that the load balancer receives</li>&#xA;<li>configure the health checks that Elastic Load Balancing uses to monitor the health of the EC2 instances registered with the load balancer so that it can send requests only to the healthy instances</li>&#xA;<li>You can use end-to-end traffic encryption on those networks that use secure (HTTPS/SSL) connections</li>&#xA;<li>[EC2-VPC] You can create an Internet-facing load balancer, which takes requests from clients over the Internet and routes them to your EC2 instances, or an internal-facing load balancer, which takes requests from clients in your VPC and routes them to EC2 instances in your private subnets. Load balancers in EC2-Classic are always Internet-facing.</li>&#xA;<li>[EC2-Classic] Load balancers for EC2-Classic support both IPv4 and IPv6 addresses. Load balancers for a VPC do not support IPv6 addresses.</li>&#xA;<li>You can monitor your load balancer using CloudWatch metrics, access logs, and AWS CloudTrail.</li>&#xA;<li>You can associate your Internet-facing load balancer with your domain name. </li>&#xA;<li>etc.</li>&#xA;</ul>&#xA;&#xA;<p>So in this scenario I am failing to understand why I would pick something like <code>consul.io</code> or <code>netflix eureka</code> over <code>Amazon ELB</code> for service discovery.</p>&#xA;&#xA;<p>I have a hunch that this might be due to implementing <strong>client side service discovery</strong> vs <strong>server side service discovery</strong>, but I am not quite sure.</p>&#xA;"
33202053,Product Versioning Microservices,2015-10-18 19:08:57,<architecture><docker><domain-driven-design><soa><microservices>,2,6086,2,6.0,15,"<p>I go into microservices architecture based on docker and I have 3 microservices, which together create one product for example ""CRM system"".</p>&#xA;&#xA;<p>Now I want my client to be able to upgrade his product, whenever he wants to. &#xA;I have 3 different versions of my microservices, which one should client see? &#xA;I guess product version should be independent of microservices, because copying one of the microservices version would make me go into more trouble than having no version at all. </p>&#xA;&#xA;<p>So is there any pattern, idea to handle such situation? </p>&#xA;&#xA;<p>The only thing that comes to my mind is to have another repository which will be versioned whenever one of the microservices will produce production ready package. However, I now have a version, which none of my Product Owners (PO) would ever know about.</p>&#xA;"
34640611,How do I use an API Gateway in conjunction with microservices and JWTs?,2016-01-06 18:54:39,<api><security><jwt><microservices><kong>,1,2748,0,7.0,16,"<p>Afternoon y'all,</p>&#xA;&#xA;<p>Just looking for someone to double check my work. Is the below an effective way to secure microservices?</p>&#xA;&#xA;<h2>Premise</h2>&#xA;&#xA;<p>Breaking up our monolithic application and monolithic Partner API into microservices oriented around specific business functions. They'll most likely be small expressjs applications running in a docker container, on elastic beanstalk, who knows. They'll live somewhere :)</p>&#xA;&#xA;<p>I'm looking into either standing up <a href=""https://getkong.org"">Kong</a> as my API Gateway or using AWS API Gateway to encapsulate the details of my microservices. Also, it just feels good. </p>&#xA;&#xA;<p>The <a href=""https://getkong.org/plugins/jwt/"">JWT plugin</a> for Kong will verify the signature of the JWT and then pass the <code>customer_id</code> along in the header to the microservice. I should also mention that we have 3rd party developers that will be partaking in the integration fun as well. Here's a basic sketch of what I see happening:</p>&#xA;&#xA;<h2>Implementation</h2>&#xA;&#xA;<ol>&#xA;<li>Generate ""consumers"" for each platform and 3rd party developer we have. (Web app, mobile app, and the current integration partners we have. Note: I'm not looking to create consumers for every user that logs in. While certainly more secure, this adds a lot of work. Also, if you figure out how to get the secret out of my API Gateway I clearly have other issues)</li>&#xA;<li>Let Kong verify the request for me. Kind of like a bouncer at the door, there's no authorization, just authentication. </li>&#xA;<li>I don't need to know that the token is valid once it gets to the microservice, I can just use some middleware to decode it and use custom logic to decide if this user <em>really</em> should be doing whatever is they're trying to do. </li>&#xA;</ol>&#xA;&#xA;<h2>Extra Stuff</h2>&#xA;&#xA;<ul>&#xA;<li><p>There's a nice access control plugin for Kong. Our application and mobile app would run with ""God"" privileges, but I could definitely lock down the developers to specific routes and methods. </p></li>&#xA;<li><p>Revoking 3rd party access will be easy, revoking end users access won't be so simple unless I'm willing to invalidate all JWTs at once by generating a new secret. Perhaps I can limit token time to 10 minutes or so and make our applications check if they're expired, get a new token, and then get on with the original request. This way I can ""flag"" them in the database or something and not let the JWT be generated. </p></li>&#xA;<li><p>SSL used everywhere, JWT is stored in an SSL only cookie in the web browser and there's no sensitive information stored in any of the claims. </p></li>&#xA;</ul>&#xA;&#xA;<p>Thanks guys. </p>&#xA;"
31031865,How do you manage per-environment data in Docker-based microservices?,2015-06-24 16:20:31,<deployment><configuration><architecture><docker><microservices>,1,6770,1,17.0,21,"<p>In a microservice architecture, I'm having a hard time grasping how one can manage environment-specific config (e.g. IP address and credentials for database or message broker).</p>&#xA;&#xA;<p>Let's say you have three microservices (""A"", ""B"", and ""C""), each owned and maintained by a different team.  Each team is going to need a team integration environment... where they work with the latest snapshot of their microservice, along with stable versions of all dependency microservices.  Of course, you'll also need QA/staging/production environments as well.  A simplified view of the big picture would look like this:</p>&#xA;&#xA;<p><strong>""Microservice A"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice B"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (<strong>SNAPSHOT</strong>)</li>&#xA;<li>Microservice C (STABLE)</li>&#xA;</ul>&#xA;&#xA;<p><strong>""Microservice C"" Team Environment</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE)</li>&#xA;<li>Microservice B (STABLE)</li>&#xA;<li>Microservice C (<strong>SNAPSHOT</strong>)</li>&#xA;</ul>&#xA;&#xA;<p><strong>QA / Staging / Production</strong></p>&#xA;&#xA;<ul>&#xA;<li>Microservice A (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice B (STABLE, RELEASE, etc)</li>&#xA;<li>Microservice C (STABLE, RELEASE, etc)</li>&#xA;</ul>&#xA;&#xA;<p>That's a lot of deployments, but that problem can be solved by a continuous integration server and perhaps something like Chef/Puppet/etc.  The <strong><em>really</em></strong> hard part is that each microservice would need some environment data particular to each place in which it's deployed.  </p>&#xA;&#xA;<p>For example, in the ""A"" Team Environment, ""A"" needs one address and set of credentials to interact with ""B"".  However, over in the ""B"" Team Environment, <em>that</em> deployment of ""A"" needs a different address and credentials to interact with <em>that</em> deployment of ""B"".</p>&#xA;&#xA;<p>Also, as you get closer to production, environmental config info like this probably needs security restrictions (i.e. only certain people are able to modify or even view it).</p>&#xA;&#xA;<p>So, with a microservice architecture, how to you maintain environment-specific config info and make it available to the apps?  A few approaches come to mind, although they all seem problematic:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Have the build server bake them into the application at build-time</strong> - I suppose you could create a repo of per-environment properties files or scripts, and have the build process for each microservice reach out and pull in the appropriate script (you could also have a separate, limited-access repo for the production stuff).  You would need a <em>ton</em> of scripts, though.  Basically a separate one for every microservice in every place that microservice can be deployed.</li>&#xA;<li><strong>Bake them into base Docker images for each environment</strong> - If the build server is putting your microservice applications into Docker containers as the last step of the build process, then you could create custom base images for each environment.  The base image would contain a shell script that sets all of the environment variables you need.  Your Dockerfile would be set to invoke this script prior to starting your application.  This has similar challenges to the previous bullet-point, in that now you're managing a ton of Docker images.</li>&#xA;<li><strong>Pull in the environment info at runtime from some sort of registry</strong> - Lastly, you could store your per-environment config inside something like Apache ZooKeeper (or even just a plain ol' database), and have your application code pull it in at runtime when it starts up.  Each microservice application would need a way of telling which environment it's in (e.g. a startup parameter), so that it knows which set of variable to grab from the registry.  The advantage of this approach is that now you can use the <em>exact</em> same build artifact (i.e. application or Docker container) all the way from the team environment up to production.  On the other hand, you would now have another runtime dependency, and you'd still have to manage all of that data in your registry anyway.</li>&#xA;</ul>&#xA;&#xA;<p>How do people commonly address this issue in a microservice architecture?  It seems like this would be a common thing to hear about.</p>&#xA;"
30296587,Using Amazon SQS with multiple consumers,2015-05-18 06:40:40,<amazon-web-services><amazon-sqs><microservices><event-based-programming>,1,10770,0,5.0,17,"<p>I have a service-based application that uses Amazon SQS with multiple queues and multiple consumers. I am doing this so that I can implement an event-based architecture and decouple all the services, where the different services react to changes in state of other systems. For example:</p>&#xA;&#xA;<ul>&#xA;<li><strong>Registration Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'registration-new' when a new user registers.</li>&#xA;</ul></li>&#xA;<li><strong>User Service</strong>: &#xA;<ul>&#xA;<li>Emits event 'user-updated' when user is updated.</li>&#xA;</ul></li>&#xA;<li><strong>Search Service</strong>: &#xA;<ul>&#xA;<li>Reads from queue 'registration-new' and indexes user in search.</li>&#xA;<li>Reads from queue 'user-updated' and updates user in search.</li>&#xA;</ul></li>&#xA;<li><strong>Metrics Service</strong>:&#xA;<ul>&#xA;<li>Reads from 'registration-new' queue and sends to Mixpanel.</li>&#xA;<li>Reads from queue 'user-updated' and sends to Mixpanel.</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I'm having a number of issues:</p>&#xA;&#xA;<ul>&#xA;<li>A message can be received multiple times when doing polling. I can design a lot of the systems to be idempotent, but for some services (such as the metrics service) that would be much more difficult.</li>&#xA;<li>A message needs to be manually deleted from the queue in SQS. I have thought of implementing a ""message-handling-service"" that handles the deletion of messages when all the services have received them (each service would emit a 'message-acknowledged' event after handling a message).</li>&#xA;</ul>&#xA;&#xA;<p>I guess my question is this: what patterns should I use to ensure that I can have multiple consumers for a single queue in SQS, while ensuring that the messages also get delivered and deleted reliably. Thank you for your help.</p>&#xA;"
30213456,Transactions across REST microservices?,2015-05-13 11:27:25,<rest><architecture><transactions><microservices>,10,43100,6,79.0,120,"<p>Let's say we have a User, Wallet REST microservices and an API gateway that glues things together. When Bob registers on our website, our API gateway needs to create a user through the User microservice and a wallet through the Wallet microservice. </p>&#xA;&#xA;<p>Now here are a few scenarios where things could go wrong:</p>&#xA;&#xA;<ul>&#xA;<li><p>User Bob creation fails: that's OK, we just return an error message to the Bob. We're using SQL transactions so no one ever saw Bob in the system. Everything's good :)</p></li>&#xA;<li><p>User Bob is created but before our Wallet can be created, our API gateway hard crashes. We now have a User with no wallet (inconsistent data).</p></li>&#xA;<li><p>User Bob is created and as we are creating the Wallet, the HTTP connection drops. The wallet creation might have succeeded or it might have not.</p></li>&#xA;</ul>&#xA;&#xA;<p>What solutions are available to prevent this kind of data inconsistency from happening? Are there patterns that allow transactions to span multiple REST requests? I've read the Wikipedia page on <a href=""http://en.wikipedia.org/wiki/Two-phase_commit_protocol"">Two-phase commit</a> which seems to touch on this issue but I'm not sure how to apply it in practice. This <a href=""http://ws-rest.org/2014/sites/default/files/wsrest2014_submission_7.pdf"">Atomic Distributed Transactions: a RESTful design</a> paper also seems interesting although I haven't read it yet.</p>&#xA;&#xA;<p>Alternatively, I know REST might just not be suited for this use case. Would perhaps the correct way to handle this situation to drop REST entirely and use a different communication protocol like a message queue system? Or should I enforce consistency in my application code (for example, by having a background job that detects inconsistencies and fixes them or by having a ""state"" attribute on my User model with ""creating"", ""created"" values, etc.)?</p>&#xA;"
33726653,Service Fabric Reliable Services Pipeline design,2015-11-16 00:03:44,<c#><azure><pipeline><microservices><azure-service-fabric>,1,2574,0,10.0,14,"<p>I need to implement pipeline if Service Fabric's Reliable Services, and I need some guidelines about what of these approaches is preferable from the viewpoint of reliability simplicity and simple good design:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/pWFql.png""><img src=""https://i.stack.imgur.com/pWFql.png"" alt=""enter image description here""></a></p>&#xA;"
31786040,Spring Cloud: Canary Deployments with Zuul,2015-08-03 11:27:35,<spring-cloud><microservices><netflix-eureka><netflix-zuul><canary-deployment>,1,2173,0,8.0,15,"<p>I am getting started with Spring Cloud using Eureka and Zuul and had some questions around structuring blue/green and Canary deployments. So far, I have the basics worked out and have Eureka, Zuul, and a config server working as expected. What I am trying to accomplish is set up a service that has two versions, say 1.0 and a 1.1. For a subset of specific users, I want to route them to the 1.1 version and everyone else should go to the 1.0 version. </p>&#xA;&#xA;<p>The Zuul filter API is a little light on documentation and I'm struggling a bit to grok some of the concepts, so I thought I'd ask a few questions here. I have also have some basic filters running, which don't do a whole lot a the moment other than getting the identity of the principal and the service they are requesting. Where I am hitting a wall is understanding how to expose two different versions of the same service to Eureka and Zuul. A few things I'm curious about:</p>&#xA;&#xA;<ul>&#xA;<li>Between documentation, posts, and other stack overflow, the term ""service"" and ""cluster"" seem to be used interchangeably. Is this correct?</li>&#xA;<li>With that said if I have a service named <code>/simpleservice</code> do I expose two different serviceIDs (i.e. <code>simpleservice</code> and <code>simpleservice-1.1</code> )? And If I do that, when one of the targeted users requests <code>/simpleservice</code>, I'm having Zuul send them to <code>/simpleservice-1.1</code></li>&#xA;<li>Or, do you add another node to the existing service ID and add additional metadata to each node so that Zuul and distinguish versions 1.0 and 1.1?</li>&#xA;<li>Is the correct answer ""all of the above?"" :)</li>&#xA;</ul>&#xA;"
42648060,Unauthorized in spring boot admin,2017-03-07 12:15:20,<spring><spring-boot><microservices><netflix-eureka><spring-boot-admin>,2,11214,0,3.0,11,"<p>I wanted to control the microservices that are running in the Eureka server. I used spring-boot-admin for this, but I am getting the error on accessing the information about the Trace,Log etc...</p>&#xA;&#xA;<p>The error I am getting is </p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: {""timestamp"":1489052472862,""status"":401,""error"":""Unauthorized"",""message"":""Full authentication is required to access this resource."",""path"":""/metrics""}</p>&#xA;</blockquote>&#xA;&#xA;<p>My dependencies are</p>&#xA;&#xA;<pre><code>&lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;scope&gt;test&lt;/scope&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;    &lt;dependency&gt;&#xA;        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.4.3&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>and none of the below properties worked</p>&#xA;&#xA;<pre><code>endpoints.info.id=information&#xA;endpoints.info.sensitive=false&#xA;endpoints.info.enabled=true&#xA;information.app.name=Actuator Example&#xA;information.app.description=Actuator Example&#xA;information.app.version=1.0.0&#xA;</code></pre>&#xA;&#xA;<p>and the same thing is happening with all the end points like mappings, env and all accept health</p>&#xA;"
36701111,Communication between two microservices,2016-04-18 17:58:51,<java><spring><spring-boot><jhipster><microservices>,4,13403,5,9.0,29,"<p>I am creating a project with microservices architecture. And I created two microservices.</p>&#xA;&#xA;<p>One of them is for product entity, the other is for bill entity. They have their own endpoints and they are connected together with the gateway (i am using jhipster microservices architecture). </p>&#xA;&#xA;<p>The bill-ms should access to list of products. I'm wondering how I can communicate between those two ms. I have three approaches in my mind:</p>&#xA;&#xA;<ol>&#xA;<li><p>Send a request from bill-ms to queue - like rabbitMQ, to get these products with these ids from product-ms (I don't know what is bottleneck of this)</p></li>&#xA;<li><p>Send a request to gateway for product service and get the product from there (I'm worried about the latency because of the data size between them and in this way I'm not touching the database directly so I always depend on the gateway)</p></li>&#xA;<li><p>I can duplicate the repositories, services and entities in bill-ms (it's an ugly way, and I think it breaks the rule of ms-architecture and the maintenance is very difficult)</p></li>&#xA;</ol>&#xA;&#xA;<p>If you have any other approaches, I appreciate you to share it with me.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<ol>&#xA;<li>Now I know what the bottleneck is: say that there are 3 instance of bill-ms and how does rabbitMQ decide which instance to respond? or how should I say to ribbon ""<strong>give me the free instance of bill-ms to subscribe to the request from rabbitMQ</strong>"" for load balancing.</li>&#xA;</ol>&#xA;"
44870461,Microservices: how to handle foreign key relationships,2017-07-02 11:45:53,<database><microservices>,2,6194,0,11.0,26,"<p>Microservices architecture suggest that each service should handle it's own data. Hence any service (Service A) dependent on data owned by other service (service B) should access such data not by making direct DB calls but through the api provided by the second service (service B).</p>&#xA;&#xA;<p><strong>So what does microservices best practices suggest on checking foreign key constrains.</strong> </p>&#xA;&#xA;<p>Example: I am developing a delivery feature (microservice 1) for products and certain products are deliverable to only certain locations as mentioned in the products table accessible to only products micro service (mircoservice 2).</p>&#xA;&#xA;<p>How do I make sure that microservice 1 (i.e delivery feature) does not take an order to a unserviced location. I have this question because delivery feature can not directly access products database, so there is no constraints applicable at DB level when a delivery order is place in to delivery data base (no check is possible to see if a foreign key match exists in products database or table).</p>&#xA;"
35756663,API gateway vs. reverse proxy,2016-03-02 19:44:32,<nginx><reverse-proxy><microservices><aws-api-gateway><tyk>,2,17931,0,23.0,47,"<p>In order to deal with the microservice architecture, it's often used alongside a Reverse Proxy (such as nginx or apache httpd) and for cross cutting concerns implementation  <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">API gateway pattern is used</a>. Sometimes Reverse proxy does the work of API gateway. <br>&#xA;It will be good to see clear differences between these two approaches.&#xA;It looks like the potential benefit of API gateway usage is invoking multiple microservices and aggregating the results. All other <a href=""https://auth0.com/blog/2015/09/13/an-introduction-to-microservices-part-2-API-gateway/"" rel=""noreferrer"">responsibilities</a> of API gateway can be implemented using Reverse Proxy.Such as:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication (It can be done using nginx LUA scripts);</li>&#xA;<li>Transport security. It itself Reverse Proxy task;</li>&#xA;<li>Load balancing</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>So based on this there are several questions:</p>&#xA;&#xA;<ol>&#xA;<li>Does it make sense to use API gateway and Reverse proxy simultaniously (as example request->Api gateway-> reverse proxy(nginx)-> concrete mictoservice)? In what cases ?</li>&#xA;<li>What the other differences that can be implemented using API gateway and can't be implemented by Reverse proxy and vice versa ?</li>&#xA;</ol>&#xA;"
43950808,Data Consistency Across Microservices,2017-05-13 08:13:05,<design-patterns><akka><microservices><data-consistency>,5,3656,0,9.0,12,"<p>While each microservice generally will have its own data - certain entities are required to be consistent across multiple services. </p>&#xA;&#xA;<p>For such data consistency requirement in a highly distributed landscape such as microservices architecture, what are the choices for design? Of course, I do not want shared database architecture, where a single DB manages the state across all the services. That violates isolation and shared-nothing principles. </p>&#xA;&#xA;<p>I do understand that, a microservice can publish an event when an entity is created, updated or deleted. All other microservices which are interested in this event can accordingly update the linked entities in their respective databases. </p>&#xA;&#xA;<p>This is workable, however it leads to a lot of careful and coordinated programming effort across the services.</p>&#xA;&#xA;<p>Can Akka or any other framework solve this use case? How?</p>&#xA;&#xA;<p><strong>EDIT1:</strong><br/>&#xA;Adding the below diagram for clarity. &#xA;<br/>Basically, I am trying to understand, if there are available frameworks today that can solve this data consistency problem. </p>&#xA;&#xA;<p>For the queue I can use any AMQP software such as RabbitMQ or Qpid etc. &#xA;For the data consistency framework, I am not sure if presently Akka or any other software can help. Or is this scenario so uncommon, and such an anti-pattern that no framework should be ever needed?<br>&#xA;<a href=""https://i.stack.imgur.com/9hIo9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9hIo9.png"" alt=""enter image description here""></a></p>&#xA;"
37180375,Using Zuul as an authentication gateway,2016-05-12 07:42:05,<spring-boot><spring-cloud><microservices><gateway><netflix-zuul>,3,14024,3,14.0,18,"<p><strong>Background</strong></p>&#xA;&#xA;<p>I want to implement the design presented in this <a href=""http://nordicapis.com/how-to-control-user-identity-within-microservices/"" rel=""noreferrer"">article</a>.</p>&#xA;&#xA;<p>It can be summarised by the diagram below:&#xA;<a href=""https://i.stack.imgur.com/viaL4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viaL4.png"" alt=""Security Architecture""></a></p>&#xA;&#xA;<ol>&#xA;<li>The client first authenticate with the IDP (OpenID Connect/OAuth2)</li>&#xA;<li>The IDP returns an access token (opaque token with no user info)</li>&#xA;<li>The client makes a call through the API gateway use the access token in the Authorization header</li>&#xA;<li>The API gateway makes a request to the IDP with the Access Token</li>&#xA;<li>The IDP verifies that the Access Token is valid and returns user information in JSON format</li>&#xA;<li>The API Gateway store the user information in a JWT and sign it with a private key. The JWT is then passed to the downstream service which verifies the JWT using the public key</li>&#xA;<li>If a service must call another service to fulfil the request it passes the JWT along which serves as authentication and authorisation for the request</li>&#xA;</ol>&#xA;&#xA;<p><strong>What I have so far</strong></p>&#xA;&#xA;<p>I have most of that done using:</p>&#xA;&#xA;<ul>&#xA;<li>Spring cloud as a global framework</li>&#xA;<li>Spring boot to launch individual services</li>&#xA;<li>Netflix Zuul as the API gateway</li>&#xA;</ul>&#xA;&#xA;<p>I have also written a Zuul PRE filter that checks for an Access Token, contacts the IDP and create a JWT. The JWT is then added to the header for the request forwarded to the downstream service.</p>&#xA;&#xA;<p><strong>Problem</strong></p>&#xA;&#xA;<p>Now my question is quite specific to Zuul and its filters. If authentication fails in the API gateway for any reason, how can I can stop the routing and respond directly with a 401 without continuing the filter chain and forwarding the call?</p>&#xA;&#xA;<p>At the moment if authentication fails the filter won't add the JWT to the header and the 401 will come from the downstream service. I was hoping my gateway could prevent this unnecessary call.</p>&#xA;&#xA;<p>I tried to see how I could use <code>com.netflix.zuul.context.RequestContext</code>to do this but the documentation is quite poor and I couldn't find a way. </p>&#xA;"
45869766,How to get docker toolbox to work with .net core 2.0 project,2017-08-24 19:46:40,<c#><docker><asp.net-core><visual-studio-2017><microservices>,2,4412,3,14.0,20,"<p>I'm getting an error trying to use the Docker functionality with my .NET core 2.0 project. I've been getting an error message saying </p>&#xA;&#xA;<blockquote>&#xA;  <p>Visual Studio Container Tools requires Docker to be running before&#xA;  building, debugging or running a containerized project. For more info,&#xA;  please see: <a href=""http://aka.ms/DockerToolsTroubleshooting"" rel=""noreferrer"">http://aka.ms/DockerToolsTroubleshooting</a></p>&#xA;</blockquote>&#xA;&#xA;<p>I followed the link, and upon realizing I have Windows 10 Home x64, and had to install Docker Toolbox, instead of Docker For Windows. Now it installed this executable called </p>&#xA;&#xA;<blockquote>&#xA;  <p>Docker Quickstart Terminal</p>&#xA;</blockquote>&#xA;&#xA;<p>Is this the way one is supposed to start up that docker services? I have tried running this executable, and it seems to be working. My containers are running, but the error for Visual Studio Container Tools still persists. </p>&#xA;&#xA;<p>What am I missing? Is having a version of windows higher than Home required in order to use the Docker Container Support within Visual Studio 2017?</p>&#xA;&#xA;<p>UPDATE:</p>&#xA;&#xA;<p>I tried to follow Quetzcoatl's suggestion, and I am still getting the same error within visual studio about those tools. Here is what I ran in the Docker Quick Start Terminal. I tried building the project after Visual Studio successfully opened the project, and was still getting the aforementioned error regarding the container tools.</p>&#xA;&#xA;<p>My devenv.exe file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\devenv.exe</p>&#xA;</blockquote>&#xA;&#xA;<p>and my solution file is located at </p>&#xA;&#xA;<blockquote>&#xA;  <p>D:\Development\Visual Studio\Musify2\Musify2\Musify2.sln</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/epqfT.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/epqfT.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>UPDATE 2:</strong></p>&#xA;&#xA;<p>I ran some of the suggested commands to try in the docker quickstart terminal and here were the results of those commands quetz<a href=""https://i.stack.imgur.com/nowpc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/nowpc.png"" alt=""enter image description here""></a></p>&#xA;"
40448015,Microservices Architecture in NodeJS,2016-11-06 09:54:11,<node.js><microservices>,2,3310,3,8.0,12,"<p>I was working on a side project and i deiced to redesign my Skelton project to be as Microservices, so far i didn't find any opensource project that follow this pattern. After a lot of reading and searching i conclude to this design but i still have some questions and thought.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/N265s.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N265s.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Here are my questions and thoughts:</p>&#xA;&#xA;<ul>&#xA;<li>How to make the API gateway smart enough to load balnce the request if i have 2 node from the same microservice?</li>&#xA;<li>if one of the microservice is down how the discovery should know?</li>&#xA;<li>is there any similar implementation? is my design is right?</li>&#xA;<li>should i use Eureka or similar things?</li>&#xA;</ul>&#xA;"
29669180,"Microservice, service registry, API gateway and data sharing",2015-04-16 08:22:16,<java><web-services><rest><microservices>,1,3736,1,9.0,14,"<p>I m actually reading tones of articles concerning microservices architecture, but, it seems that they are dealing the things the easiest way possible, without going deeper in explanations.</p>&#xA;&#xA;<p>To explain you my questions, I will show you my actual little architecture :</p>&#xA;&#xA;<p><img src=""https://i.stack.imgur.com/0hqf5.png"" alt=""enter image description here""></p>&#xA;&#xA;<p>So, here's what I want to use. Before making anything technically, I need more theorical informations.</p>&#xA;&#xA;<p><strong>Description of my domain</strong></p>&#xA;&#xA;<p>I have some mobile and browser based customers, able to connect themselves on an application, getting their user informations and able to consult billing informations about what they bought. </p>&#xA;&#xA;<p>On a monolithic application, I would use this architecture :&#xA;- Presentation layer with Mobile / Angular-Ember&#xA;- Business layer with a REST API with NGINX in front of that&#xA;- DAL with a standard MySQL database&#xA;- Scalability would be applied only on X-axis</p>&#xA;&#xA;<p>I want to use a microservice architecture in this case, because it's ""domain scalable"" and really flexible (and to learn a bit more about it of course).</p>&#xA;&#xA;<p>On the schema, in each service, there is the only HTTP URL exposed by the API concerned.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<p><strong>a/</strong> In the (1) flux, ""mobile"" send an http request on <a href=""http://myDomain.or/auth"" rel=""noreferrer"">http://myDomain.or/auth</a>.</p>&#xA;&#xA;<p>In my mind, the APIGateway is able to ask a standard Service Registry (Eureka, ZooKeeper, or something else) is able to find if a AuthSrv is accessible and can retrieve his network adress. Then the ApiGateway can request the AuthSrv and respond to the server</p>&#xA;&#xA;<p>Is that a good way to make it work ? Isn't there a latency problem when dealing with X machines to access a data ?</p>&#xA;&#xA;<p><strong>b/</strong> The flux (2) consults the service registry. How can the service registry understand that every requests on /auth, even on children url like /auth/other (if it was exposed) are related to this service on this address ip:port ?</p>&#xA;&#xA;<p><strong>c/</strong> The flux (3) is showing that the service registry has an available AuthSrv. The (3 bis) show the other : no AuthSrv is available. In a little application, we can admit that we lose sometime of disponibility, but in a big system, where hundred of services are linked, how can we handle service defficience ?</p>&#xA;&#xA;<p><strong>d/</strong> In an other post, I was asking how to store a billing information because it's related to a user, from another service, and another database.</p>&#xA;&#xA;<p>In a standard architecture I would have : </p>&#xA;&#xA;<pre><code>{&#xA;   billingInformations:{...},&#xA;   billingUser:ObjectId(""userId"")&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In a microservice architecture, somebody recommended to use :</p>&#xA;&#xA;<pre><code>{&#xA;    billingInformations:{...},&#xA;    billingUser:""/user/12365"" // URL corresponding the the user Ressource in the other service&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Is this the best way to handle ""service data sharing"" and not couple the services ?</p>&#xA;&#xA;<p><strong>e/</strong> When should I prefer using AMQP protocol instead of HTTP protocol in this specific case ?</p>&#xA;&#xA;<p>Thanks for advance</p>&#xA;"
41731704,Use docker-compose with multiple repositories,2017-01-19 00:16:29,<docker><docker-compose><microservices>,1,3197,0,1.0,11,"<p>I'm currently struggling with the deployment of my services and I wanted to ask, what's the proper way when you have to deal with multiple repositories. The repositories are independent, but to run in production, everything needs to be launched.</p>&#xA;&#xA;<p>My Setup:</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Backend:&#xA;&#xA;<ul>&#xA;<li>Backend Project Rails</li>&#xA;<li>docker-compose: backend(expose 3000), db and redis</li>&#xA;</ul></li>&#xA;<li>Git Repository Frontend&#xA;&#xA;<ul>&#xA;<li>Express.js server</li>&#xA;<li>docker-compose: (expose 4200)</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>Both can be run independently and test can be executed by CI</p>&#xA;&#xA;<ul>&#xA;<li>Git Repository Nginx for Production&#xA;&#xA;<ul>&#xA;<li>Needs to connect to the other two services (same docker network)</li>&#xA;<li>forwards requests to the right service</li>&#xA;</ul></li>&#xA;</ul>&#xA;&#xA;<p>I have already tried to include the two services as submodules into the Nginx repository and use the docker-compose of the nginx repo, but I'm not really happy with it.  </p>&#xA;"
41795612,How to deploy microservices on Heroku,2017-01-22 20:09:47,<heroku><architecture><jhipster><microservices>,1,3183,1,4.0,11,"<p>I have read a lot about microservices, and would like to build my app with that approach. What I know so far is that I nead some services like:</p>&#xA;&#xA;<ul>&#xA;<li><strong>load balancer</strong> - to deal with every request, and push it forward to another services</li>&#xA;<li><strong>authorization service</strong> - to authorize my users</li>&#xA;<li><strong>database</strong> - for my microservices. I would like to use one instance of DB with different schemas for every service.</li>&#xA;<li><strong>service A</strong> - for functionality A</li>&#xA;<li><p><strong>service B</strong> - for functionality B</p></li>&#xA;<li><p>etc. etc. etc.</p></li>&#xA;</ul>&#xA;&#xA;<p>I found out, that Heroku is interesting place to deploy applications. My problem is that I completely don't understand they ideology. What I have done so far, is creation/registration of few ""apps"":</p>&#xA;&#xA;<ul>&#xA;<li>my-app-auth</li>&#xA;<li>my-app-load-balancer</li>&#xA;<li>etc. etc.</li>&#xA;</ul>&#xA;&#xA;<p>I see, that Heroku gives me some public hostname for every of that app, and this is where my concerns starts. Should I deploy my internal services with public hostnames? I don't think so. And here my question comes:</p>&#xA;&#xA;<p>Can anyone provide me some guidelines, how to deal with microservices on Heroku? How should i deploy them? How should I define my load balancer, and hook internal services to it? What is JHipster? Do I need it? How can I use it? Should I use Heroku tools (for example CLI) or can I stay with my gitlab repo? I can't find any point of grasp on the Internet, about that.</p>&#xA;"
50986816,How to handle HTTP requests in a Microservice / Event Driven Architecture?,2018-06-22 11:20:06,<node.js><rest><websocket><apache-kafka><microservices>,6,455,1,8.0,16,"<p><strong>Background:</strong></p>&#xA;&#xA;<p>I am building an application and the proposed architecture is Event/Message Driven on a microservice architecture. </p>&#xA;&#xA;<p>The monolithic way of doing thing is that I've a <code>User/HTTP request</code> and that actions some commands that have a direct <code>synchronous response</code>. Thus, to respond to the same User/HTTP request is 'hassle free'.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rP5nf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rP5nf.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>The problem:</strong></p>&#xA;&#xA;<p>The user sends an <code>HTTP request</code> to the <strong>UI Service</strong> (there are multiple UI Services) that fires some events to a queue (Kafka/RabbitMQ/any). a N of services picks up that Event/Message do some magic along the way and <strong>then at some point that same UI Service should pick that up a response and give that back to the user that originated HTTP request.</strong> Request processing is <code>ASYNC</code> but the <code>User/HTTP REQUEST-&gt;RESPONSE</code> is <code>SYNC</code> as per your typical HTTP interaction.</p>&#xA;&#xA;<p><strong>Question:</strong>&#xA;How do I send a response to the same UI Service that originated the action (The service thats interacting with the user over HTTP) in this Agnostic/Event driven world?</p>&#xA;&#xA;<p><strong>My research so far</strong> &#xA;I've been looking around and it seems that some people are solving that problem using WebSockets.</p>&#xA;&#xA;<p>But the layer of complexity is that there needs to be some table that maps <code>(RequestId-&gt;Websocket(Client-Server))</code> which is used to ‘discover’ which node in the gateway has the websocket connection for some particular response. But even if I understand the problem and complexity I'm stuck that I can't find any articles that would give me info on how to solve this problem at the implementation layer. <strong>AND</strong> this still is not a viable option because of 3rd party integrations such as payments providers(WorldPay) that expect <code>REQUEST-&gt;RESPONSE</code> - specially on the 3DS validation.</p>&#xA;&#xA;<p>So I am somehow reluctant to think that WebSockets is an option. But even if WebSockets are ok for Webfacing apps, for API that connects to external systems is not a great architecture.</p>&#xA;&#xA;<p>** ** ** <strong>Update:</strong> ** ** ** </p>&#xA;&#xA;<p>Even if long polling is an possible solution for a WebService API with a <code>202 Accepted</code> a <code>Location header</code> and a <code>retry-after header</code> it wouldn't be performant for a high concurrency &amp; high ability website. &#xA;Imagine a huge number of people trying to get the transaction status update on EVERY request they make and you have to invalidate CDN cache (go and play with that problem now! ha).</p>&#xA;&#xA;<p>But most important and relatable to my case I've 3rd party APIs such as payment systems where the 3DS systems have automatic redirects that are handled by the payment provider system and they expect a typical <code>REQUEST/RESPONSE flow</code>, thus this model would not work for me nor the sockets model would work. </p>&#xA;&#xA;<p>Because of this use-case the <code>HTTP REQUEST/RESPONSE</code> should be handled in the typical fashion where i have a dumb client that expect that the complexity of the precessing is handled in back-end.</p>&#xA;&#xA;<p><strong>So i am looking for a solution where externally I have a typical <code>Request-&gt;Response</code>(SYNC) and the complexity of the status(ASYNCrony of the system) is handled internally</strong> </p>&#xA;&#xA;<p>An example of the long polling, but this model wouldn't work for 3rd party API such as payments provider on <code>3DS Redirects</code> that are not within my control.</p>&#xA;&#xA;<pre><code> POST /user&#xA;    Payload {userdata}&#xA;    RETURNs: &#xA;        HTTP/1.1 202 Accepted&#xA;        Content-Type: application/json; charset=utf-8&#xA;        Date: Mon, 27 Nov 2018 17:25:55 GMT&#xA;        Location: https://mydomain/user/transaction/status/:transaction_id&#xA;        Retry-After: 10&#xA;&#xA;GET &#xA;   https://mydomain/user/transaction/status/:transaction_id&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/rznNC.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rznNC.png"" alt=""enter image description here""></a></p>&#xA;"
42487685,How to inject module from different app in Node.js,2017-02-27 14:02:36,<javascript><node.js><express><amd><microservices>,4,434,3,4.0,9,"<p>I've two node apps/services that are running together, &#xA;1. main app&#xA;2. second app</p>&#xA;&#xA;<p>The main app is responsible to show all the data from diffrent apps at the end. Now I put some code of the second app in the main app and now its working, but I want it to be decoupled. I mean that the code of the secnod app will not be in the main app (by somehow to inject it on runtime )</p>&#xA;&#xA;<p>like the second service is registered to the main app in inject the code of it.&#xA;the code of it is just two modules ,is it possible to do it in nodejs ?</p>&#xA;&#xA;<pre><code>const Socket = require('socket.io-client');&#xA;const client = require(""./config.json"");&#xA;&#xA;module.exports =  (serviceRegistry, wsSocket) =&gt;{&#xA;    var ws = null;&#xA;    var consumer = () =&gt; {&#xA;        var registration = serviceRegistry.get(""tweets"");&#xA;        console.log(""Service: "" + registration);&#xA;        //Check if service is online&#xA;        if (registration === null) {&#xA;            if (ws != null) {&#xA;                ws.close();&#xA;                ws = null;&#xA;                console.log(""Closed websocket"");&#xA;            }&#xA;            return&#xA;        }&#xA;        var clientName = `ws://localhost:${registration.port}/`&#xA;        if (client.hosted) {&#xA;            clientName = `ws://${client.client}/`;&#xA;        }&#xA;        //Create a websocket to communicate with the client&#xA;        if (ws == null) {&#xA;            console.log(""Created"");&#xA;            ws = Socket(clientName, {&#xA;                reconnect: false&#xA;            });&#xA;            ws.on('connect', () =&gt; {&#xA;                console.log(""second service is connected"");&#xA;            });&#xA;            ws.on('tweet', function (data) {&#xA;                wsSocket.emit('tweet', data);&#xA;            });&#xA;            ws.on('disconnect', () =&gt; {&#xA;                console.log(""Disconnected from blog-twitter"")&#xA;            });&#xA;            ws.on('error', (err) =&gt; {&#xA;                console.log(""Error connecting socket: "" + err);&#xA;            });&#xA;        }&#xA;    }&#xA;    //Check service availability&#xA;    setInterval(consumer, 20 * 1000);&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>In the main module I put this code and I want to decouple it by inject it somehow on runtime ? example will be very helpful ... </p>&#xA;"
37915326,How to keep DB in sync when using microservices architecture?,2016-06-20 05:47:00,<architecture><microservices>,3,3503,0,3.0,9,"<p>Im about to learn how microservices architecture work. So far i unserstood that each microservice need its own database, which make sense. </p>&#xA;&#xA;<p>So lets say we have a customer microservice which is responsible for creating a customer and returning a list of customers. The service will ofcource have it own customer DB. </p>&#xA;&#xA;<p>Lets say we have very high load on this ervice, so we chooce to scale out 20x. </p>&#xA;&#xA;<p>Så we have 20 microservices and each have its own DB, and all the services is behind a load balancer. </p>&#xA;&#xA;<p>Now a client wants to create a customer, load balancer sends client request to service 9/20, and the customer is created. </p>&#xA;&#xA;<p>On the next request the same client wants to be sure that customer is created and want to view the list of the customers, on the request LB sends him to service 11/20. </p>&#xA;&#xA;<p>Now how do i make sure that service 9/20 synced the newly created customer to the db of service 11/20?</p>&#xA;&#xA;<p>In MSSQL there are functionality to keep DB in sync by before alowing the initial commit, to save the data in all the other databases first, but this approach will give problems in the long run, because the more services there are the longer time it will take to make a commit?</p>&#xA;"
45208766,Microservices Why Use RabbitMQ?,2017-07-20 07:57:56,<rabbitmq><microservices>,2,5165,1,3.0,9,<p>I haven't found an existing post asking this but apologize if I missed it. </p>&#xA;&#xA;<p>I'm trying to get my head round microservices and have come across articles where RabbitMQ is used. I'm confused why RabbitMQ is needed. Is the intention that the services will use a web api to communicate with the outside world and RabbitMQ to communicate with each other?</p>&#xA;
45625886,REST vs gRPC: when should I choose one over the other?,2017-08-11 02:09:34,<rest><kubernetes><microservices><docker-swarm><grpc>,3,3474,1,3.0,14,"<p>I see more and more software organizations using gRPC in their service-oriented architectures, but people are also still using REST. In what use cases does it make sense to use gRPC, and when does it make sense to use REST for inter-service communication?</p>&#xA;&#xA;<p>Interestingly, I've come across open source projects that use both REST and gRPC. For instance, Kubernetes and Docker Swarm all employ gRPC to some extent for cluster coordination, but also expose REST APIs for interfacing with master/leader nodes. Why not use gRPC up and down?</p>&#xA;"
33431076,Environment variables inheritance with microservices (Laravel & Lumen),2015-10-30 07:52:01,<php><laravel><inheritance><environment-variables><microservices>,1,399,6,0.0,0,"<p>Recently I ran into a problem while deploying a <strong>Lumen</strong> microservice next to a <strong>Laravel</strong> app. On the same machine I have a Laravel app and a Lumen app both with different <code>.env</code> file and the default environment variables (<code>APP_ENV</code>, <code>DB_HOST</code>, <code>DB_DATABASE</code>, etc).</p>&#xA;&#xA;<p>My <strong>Laravel</strong> app needs to make a request the the <strong>Lumen</strong> app to get some data. That's when the problem occures. When the <strong>Lumen</strong> app receives the request it also inherits the <strong>Laravel</strong>'s environment variables, making it impossible to do it's job (to connect to the database or other services that have the environment variables set in the <code>.env</code> file because all the variables are inherited from the parent request).</p>&#xA;&#xA;<p>Has anyone encountered this problem before? Am I using the microservices architecture the right way?</p>&#xA;&#xA;<p><strong>Update</strong> with code.</p>&#xA;&#xA;<p><em>Laravel app - UsersController.php</em> </p>&#xA;&#xA;<pre><code>/**&#xA; * Makes a request to the Core API and fills properties with the response data&#xA; *&#xA; * @param $method&#xA; * @param $uri&#xA; * @param array|null $data&#xA; */&#xA;public function request($method, $uri, array $data = null)&#xA;{&#xA;    $this-&gt;api = new Client(['base_uri' =&gt; 'http://127.0.0.1/']);&#xA;&#xA;    if (property_exists($this, 'uriPrefix')) $uri = $this-&gt;uriPrefix . $uri;&#xA;    $requestOptions = [&#xA;        'http_errors'   =&gt; false,&#xA;        'headers' =&gt; ['Accept' =&gt; 'application/json']&#xA;    ];&#xA;    if (session('api_cookie')) $requestOptions['headers']['Cookie'] = implode(';', session('api_cookie'));&#xA;    if ($data) {&#xA;        if ($method == 'GET') $requestOptions['query'] = $data;&#xA;        else if (($method == 'POST') || ($method == 'PUT')) $requestOptions['form_params'] = $data;&#xA;    }&#xA;&#xA;    $response = $this-&gt;api-&gt;request($method, $uri, $requestOptions);&#xA;&#xA;    session(['api_cookie' =&gt; $response-&gt;getHeader('Set-Cookie')]);&#xA;&#xA;    $this-&gt;responseCode = $response-&gt;getStatusCode();&#xA;    $this-&gt;responseReasonPhrase = $response-&gt;getReasonPhrase();&#xA;    $this-&gt;responseData = $response-&gt;getBody();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>When I make this request the <strong>Lumen</strong> app can't connect to the database because it inherits the <code>DB_</code> environment variables from the parent <strong>Laravel</strong> app.</p>&#xA;"
35179495,Spring Boot Microservices Deployment,2016-02-03 14:16:51,<spring-boot><microservices>,3,542,0,0.0,0,"<p>Has anyone deployed multiple instances of the same microservice? If so, how are you managing such deployments?</p>&#xA;"
33194778,Keyword Search in microservices based architecture,2015-10-18 05:51:39,<search><solr><microservices>,1,1009,0,2.0,0,<p>I need some advice as to how a search needs to be implemented to search keywords within relational databases owned by microservices.&#xA;I have some microservices with their own relational DB. These microservices are likely to be deployed in a docker container.&#xA;What would be the best way to use a search engine like Apache SOLR so that each of the microservices' database can be indexed and we can achieve keyword search</p>&#xA;&#xA;<p>Thanks in advance</p>&#xA;
36988921,What is a good event store/stream middleware for service-oriented/ microservice-architectures,2016-05-02 18:14:06,<events><soa><microservices><event-driven><event-stream>,2,196,4,0.0,0,"<p>I am building a microservice-architecture and I am looking for a good way to stream events.</p>&#xA;&#xA;<p>Currently I have a service that publishes an event that three other services need to react to in a certain way, however the reaction to this event shall happen only once. </p>&#xA;&#xA;<p>At the moment I am using RabbitMQ and my service publishes three messages in seperate queues, and each subscribing service listens to one queue. So, only one service instance can actually take the message and react to it. </p>&#xA;&#xA;<p>However, I do not like this approach, because if I want to add a new subscriber I have to add a new queue for the publishing service.</p>&#xA;&#xA;<p>I am basically looking for some kind of middleware on an event stream, that lets multiple services listen to one event, but makes sure that only one instance of each service actually reacts to the event.</p>&#xA;&#xA;<p>I haven't found anything yet, so I would appreciate suggestions.</p>&#xA;"
40216362,Microservices and Messaging: Message Content,2016-10-24 10:39:10,<java><spring><rabbitmq><microservices>,3,112,0,0.0,0,"<p>I'm building an application that consists out of several microservices. One of the microservices, which is called Hera, manages users. Another microservice manages authorization and authentication. This microservice is called Zeus and is an implementation of Spring OAuth 2.0. </p>&#xA;&#xA;<p>When a user is created, updated or deleted in Hera, I'd like to replicate certain information to Zeus via RabbitMQ. This information includes the username, the user type (an enum) and a flag to indicate whether the user is enabled. </p>&#xA;&#xA;<p>I've already set up RabbitMQ and everything is working properly. The only thing I'm not certain about is the message body content. How should this information be packaged in the message? For instance, should I create a maven project containing the POJO with the required properties which will be marshalled and send via RabbitMQ and add dependency to this project in both Hera and Zeus? Or should I just add this information as a list of plain properties? </p>&#xA;&#xA;<p>I could not find any best practices or guidelines on this subject, so I'm asking you.</p>&#xA;&#xA;<p>Thank you in advance!</p>&#xA;"
40170212,how to add content-length to response headers when i use spring cloud to build my micro service,2016-10-21 06:56:58,<spring-boot><spring-cloud><microservices><netflix-zuul>,1,965,0,0.0,0,"<p>I have used spring cloud to build a multiple microservice,and i use a API-Gateway implemented using Spring Cloud Netfix's Zuul Server to route the requests to our micro services ,the gateway config like this:</p>&#xA;&#xA;<p>application.yml:</p>&#xA;&#xA;<pre><code>server:&#xA;port: 8021&#xA;&#xA;ribbon:&#xA;ConnectTimeout: 3000&#xA;ReadTimeout: 60000&#xA;&#xA;zuul:&#xA;ignoredServices: ""*""&#xA;add-proxy-headers: true&#xA;#prefix: /v1&#xA;&#xA;routes:&#xA;m_test:&#xA;path: /api/testService/**&#xA;sensitiveHeaders: ""*""&#xA;url: http://127.0.0.1:4008/testService/  &#xA;&#xA;eureka:&#xA;instance:&#xA;hostname: gateway&#xA;client:&#xA; registerWithEureka: true&#xA; fetchRegistry: true&#xA;serviceUrl:&#xA;  defaultZone: http://127.0.0.1:8761/eureka/&#xA;</code></pre>&#xA;&#xA;<p>CorsFilter.java:</p>&#xA;&#xA;<pre><code>@Component&#xA;@Order(Ordered.HIGHEST_PRECEDENCE)&#xA;public class CorsFilter implements Filter {&#xA;public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {&#xA;&#xA;    HttpServletResponse response = (HttpServletResponse) res;&#xA;    HttpServletRequest request = (HttpServletRequest) req;&#xA;    response.setHeader(""Access-Control-Allow-Origin"", ""*"");&#xA;    response.setHeader(""Access-Control-Allow-Methods"", ""POST, PUT, GET, OPTIONS, DELETE"");&#xA;    response.setHeader(""Access-Control-Allow-Headers"", ""Origin, X-Requested-With, Content-Type, Accept, Authorization,Content-length"");&#xA;    response.setHeader(""Access-Control-Max-Age"", ""1800"");&#xA;    Map&lt;String, String&gt; map = getHeadersInfo(request);&#xA;&#xA;    if (request.getMethod().equalsIgnoreCase(""OPTIONS"")) {&#xA;        response.setStatus(HttpServletResponse.SC_OK);&#xA;    } else {&#xA;        chain.doFilter(request, response);&#xA;    }&#xA;}&#xA;&#xA;public void init(FilterConfig filterConfig) {&#xA;}&#xA;&#xA;public void destroy() {&#xA;}&#xA;&#xA;private Map&lt;String, String&gt; getHeadersInfo(HttpServletRequest request) {&#xA;    Map&lt;String, String&gt; map = new HashMap&lt;&gt;();&#xA;    Enumeration headerNames = request.getHeaderNames();&#xA;    while (headerNames.hasMoreElements()) {&#xA;        String key = (String) headerNames.nextElement();&#xA;        String value = request.getHeader(key);&#xA;        map.put(key, value);&#xA;    }&#xA;&#xA;    return map;&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>GatewaySystemApplication.java:</p>&#xA;&#xA;<pre><code>@SpringBootApplication&#xA;@EnableZuulProxy&#xA;@EnableEurekaClient&#xA;public class GatewaySystemApplication {&#xA;&#xA;public static void main(String[] args) throws Exception {&#xA;    //SpringApplication.run(GatewaySystemApplication.class, args);&#xA;    new SpringApplicationBuilder(GatewaySystemApplication.class).web(true).run(args);&#xA;}&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>The browser response headers are like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jeFDo.png"" rel=""nofollow noreferrer"">passing through gateway layer response headers</a></p>&#xA;&#xA;<p>and the response header of my request miss the content-length,&#xA;but it has the content-length when i directly invoke backend service.<a href=""https://i.stack.imgur.com/2IYfM.png"" rel=""nofollow noreferrer"">directly response headers</a></p>&#xA;"
32398245,Node.js + RabbitMQ + Socket.io,2015-09-04 12:35:57,<javascript><node.js><socket.io><rabbitmq><microservices>,1,728,3,1.0,0,"<p>We're in a project with a few microservices.<br>&#xA;We've got a microservice (A) that get's and saves data and publishes a message to RabbitMQ, stating new data has come in (with the CouchDB _id), so that another microservice(b) can process it.</p>&#xA;&#xA;<p>The problem lies in a third service where we've got a frontend that needs to be updated in 'real-time'.<br>&#xA;We're using Socket.io for the client updates, but the node.js instance get's the updates from A as well.</p>&#xA;&#xA;<p>The later is as followed:  </p>&#xA;&#xA;<pre><code>- RabbitMQ message comes in&#xA;- Order is being retrieved from A (HTTP Request)&#xA;- Data is processed (remapping for user interface, bla bla bla)&#xA;- Data is sent through Socket.io to the client.&#xA;</code></pre>&#xA;&#xA;<p>My problem is, how do I do this cleanly in node?</p>&#xA;&#xA;<p>I want to split the files (ofcourse), make each their own module and create a handler which 'knows' RabbitMQ and Socket.io, so it can process the data and send a message back up the queue when the client has done something with the data that needs to be processed and the other way around.</p>&#xA;&#xA;<p>If more info is needed, please tell me.</p>&#xA;"
32364506,Monolithic (vs) Micro-services ==> Threads (vs) Process,2015-09-02 22:58:59,<multithreading><process><docker><microservices>,1,1584,4,0.0,0,"<p>I have a monolithic application with single process having 5 threads. Each thread accomplishes certain specific task. Thinking to move this application to microservices using dockers. If I look at the architecture, each worker thread would become a docker process. So, in some way Monolithic vs Microservices becomes more like Thread vs Process discussion in my case. </p>&#xA;&#xA;<p>The original thinking of having the monolithic was to have threads for performance and share the same memory. Now with microservices arch, I am pushed to a process model that may not suit from performance point of view.</p>&#xA;&#xA;<p>I am kind of stuck on how to approach this problem.</p>&#xA;"
35600997,ejabberd in a microservice network,2016-02-24 11:31:54,<xmpp><ejabberd><microservices><mongoose-im>,2,287,6,0.0,0,<p>I'm willing to use ejabberd / mongooseIm in a microservice network. XMPP should be our chat protocol aside from a REST API network. I want to send messages incoming at the xmpp server downstream to worker services. Has anybody done this or could lead me into the right direction? </p>&#xA;&#xA;<p>My first thoughts are using RabbitMQ for sending the new incoming messages to the workers.</p>&#xA;
39338259,Dropwizard: Microservice Architecture,2016-09-05 22:15:30,<dropwizard><microservices>,1,235,7,0.0,0,"<p>This is similar to <a href=""https://stackoverflow.com/questions/6994054/how-to-deserialize-from-a-file-to-different-class"">How to deserialize from a file to different class</a>. But, I'm developing micro-services using Dropwizard. </p>&#xA;&#xA;<p>I have two services, service A and service B. I have a message queue (RabbitMQ) setup between the two services. </p>&#xA;&#xA;<p>I am trying to send an object of type Class A (defined in service A) from service A to service B. I have not imported class A in service B. However in service B i have Class B defined which is exactly same as Class A. </p>&#xA;&#xA;<p>I am getting a ClassNotFoundException: Class A in service B when service B tries to deserialize and typecast the object to Class B.  </p>&#xA;&#xA;<p>I want the two jars to be as independent as possible. &#xA;Is there a way to do this. </p>&#xA;"
49849813,Node js microservice,2018-04-16 04:49:43,<node.js><spring><microservices>,1,53,3,0.0,0,<p>Can anyone please tell how to consume a node js based microservice from spring based web application?can restful API be the best choice to be used by the application to message the microservices based on nodejs ?</p>&#xA;
49823345,What is the best way to host a MicroService .net core web api in Docker?,2018-04-13 18:41:49,<docker><asp.net-core><microservices>,1,384,3,0.0,0,<p>I have several micro services that I would like to dockerized them. Is it better to build them in a self-hosted console application or build asp.net web application?</p>&#xA;&#xA;<p>Which one is faster?</p>&#xA;&#xA;<p>My MicroServices are only simple Web Api.</p>&#xA;
49777963,How to best handle shared services using docker-compose for local development in microservice architecture?,2018-04-11 14:38:16,<docker><docker-compose><microservices>,1,110,4,0.0,0,"<p>Trying to set up an effective pattern that allows communication between all of my services and allows for local development on multiple services simultaneously. I am currently setting up local development for my application using docker compose. The basic idea of my <code>docker-compose.yml</code> looks something like this. </p>&#xA;&#xA;<pre><code>version: '3'&#xA;services:&#xA;  web: &#xA;    &lt;web_config&gt;&#xA;  worker:&#xA;    &lt;worker_config&gt;&#xA;  service-a:&#xA;</code></pre>&#xA;&#xA;<p>I'm questioning how to handle <code>service-a</code>. </p>&#xA;&#xA;<p><code>service-a</code> is required by any local applications I am running. So if I am running this application and another at the same time, they will both need to communicate with <code>service-a</code>. </p>&#xA;&#xA;<p>Should <code>service-a</code> be running in its own compose instance? If so, are <code>networks</code> the best way for all my apps to communicate with <code>service-a</code>? From my understanding, this used to be the job of <code>links</code>, but <code>networks</code> are now preferred. I have already tried running with <code>network_mode</code> host, but am running into issues, as I am using Docker for Mac. </p>&#xA;&#xA;<p>I've seen a lot of opinions and solutions out there, but I'm honestly unsure which of these approaches is best. Some of the solutions I've seen include:</p>&#xA;&#xA;<ul>&#xA;<li>creating a shared <code>network</code> for all my services and run them separately in their own docker composes</li>&#xA;<li>using <code>network_mode: 'host'</code> and run everything on my host (Sadly I couldn't get this working)</li>&#xA;<li>running a separate compose of all my shared services that all other services depend on</li>&#xA;</ul>&#xA;&#xA;<p>Let me know if you've run into this and have any advice to share, thanks!</p>&#xA;"
44265295,Caching layer for different microservices,2017-05-30 14:40:03,<caching><design><varnish><microservices><vert.x>,1,447,3,0.0,0,"<p>We have different microservices which makes duplicate calls to internal and external services. We need to cache these calls between services to improve latency. We are thinking of introducing an API gateway whose major aim would be caching the data between services. &#xA;Some other objectives are -</p>&#xA;&#xA;<p>i) Would be calling different micro-services to aggregate their response.</p>&#xA;&#xA;<p>ii) Would also be avoiding multiple calls to external services across micro services.</p>&#xA;&#xA;<p>iii) Would be taking care of cache miss &amp; hit for external API calls.</p>&#xA;&#xA;<p>iv) High throughput, performance and low latency.</p>&#xA;&#xA;<p>We have vert.x based tech stack.&#xA;What would be the best way to implement such a system. I had following questions -</p>&#xA;&#xA;<p>1) Implement it as a library or a service ?</p>&#xA;&#xA;<p>2) Which data store to be used ( we are considering Redis/Hazelcast) ?</p>&#xA;&#xA;<p>3) Can libraries such as Varnish/Squid/Nginx help here ?</p>&#xA;&#xA;<p>4) How to handle cache invalidation ?</p>&#xA;"
36573857,Consistency with partitioned Service Fabric stateful service,2016-04-12 12:51:14,<architecture><microservices><consistency><azure-service-fabric>,4,319,0,0.0,0,"<p>Let's take a simple example. I have a stateful service that manages users. It has a reliable dictionary that maps UserID to some data, including User Name.</p>&#xA;&#xA;<p>In this service's RegisterUser method, we want to check that the user name has not already been used. This is quite straightforward when the service is a singleton, but when it's partitioned we end up with several problems:</p>&#xA;&#xA;<ol>&#xA;<li>We have to ask all partitions if the user already exists. We could possibly introduce another singleton service that maps user name to user id to overcome this problem.</li>&#xA;<li>There's a race condition. Two users could try to register the name user name at the same time. It's possible that both users could succeed.</li>&#xA;</ol>&#xA;&#xA;<p>I'm looking for general advice for possible ways to deal with situations such as this. I can imagine that this sort of problem would occur regularly with partitioned data.</p>&#xA;"
36569703,how to set local path in yaml configuration file in microservice,2016-04-12 09:51:32,<config><microservices><netflix-eureka>,1,1374,0,0.0,0,"<p>Here all the properties file are in github location,so that I am able to read using uri path ,how I will read if It's in my local system.Can anybody please guide ?</p>&#xA;&#xA;<pre><code>server:&#xA;  port: 8888&#xA;&#xA;eureka:&#xA;  instance:&#xA;    hostname: configserver&#xA;  client:&#xA;    registerWithEureka: true&#xA;    fetchRegistry: true&#xA;    serviceUrl:&#xA;      defaultZone: http://discovery:8761/eureka/&#xA;&#xA;spring:&#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: https://github.com/****/******&#xA;</code></pre>&#xA;"
33659658,Service Fabric Reliable Services: proccessing parallel request with CPU-bound methods,2015-11-11 20:56:00,<c#><azure><microservices><azure-service-fabric>,2,1663,0,0.0,0,"<p>Azure <strong>Service Fabric</strong>'s Reliable Actors turn-based concurrency is described in official documentation.As If I get it right, <strong>Reliable Services</strong>, can serve multiple requests simultaneously.&#xA;Lets say I have a Reliable Service with single CPU-bounded method.&#xA;Method is async as expected, so Service can handle multiple requests.&#xA;My local cluster is hosted on 2-core machine, when I call Service from 2 different console-app clients, CPU 100% utilized as expected. So there is no reason to handle more than 2 request simultaneously. How can I limit this?&#xA;And if I move to real cluster, I don't know anything about machine Service hosted on, what should I do then?</p>&#xA;&#xA;<pre><code>public async Task&lt;bool&gt; CpuBoundAsync(int value)&#xA;&#xA;    {&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK IN PROGRESS"");&#xA;        int z;&#xA;        await Task.Run(() =&gt;&#xA;        {&#xA;            for (int i = 0; i &lt; int.MaxValue; i++)&#xA;            {&#xA;                z++;&#xA;                z--;&#xA;            }&#xA;        });&#xA;&#xA;        ServiceEventSource.Current.ServiceMessage(this,&#xA;            ""CPU-BOUND WORK COMPLETED"");&#xA;        return true;&#xA;    }&#xA;</code></pre>&#xA;"
33706599,Where to store configuration retrieved from etcd in nodejs,2015-11-14 08:34:03,<node.js><soa><microservices><etcd>,1,245,3,0.0,0,"<p>I'm getting config from http call. </p>&#xA;&#xA;<p>Where I can store that config, Serialize to <strong>filesystem or attach to GLOBAL</strong> or any other</p>&#xA;&#xA;<p>I'm implementing service discovery with nodejs. <a href=""http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/"" rel=""nofollow"">http://lukebond.ghost.io/service-discovery-with-etcd-and-node-js/</a></p>&#xA;&#xA;<p>I'm getting the service registry. I want to store it for using application wide.</p>&#xA;"
34889229,Recreating Docker images instead of reusing - for microservices,2016-01-20 00:02:48,<docker><microservices>,2,102,3,0.0,0,"<p>One microservice stays in one docker container. Now, let's say that I want to upgrade the microservice - for example, some configuration is changed, and I need to re-run it.</p>&#xA;&#xA;<p>I have two options:</p>&#xA;&#xA;<ol>&#xA;<li><p>I can try to re-use existing image, by having a script that runs on containers startup and that updates the microservice by reading new config (if there is) from some shared volume. After the update, script runs the microservice. </p></li>&#xA;<li><p>I can simply drop the existing image and container and create the new image (with new name) and new container with updated configuration/code.</p></li>&#xA;</ol>&#xA;&#xA;<p>Solution #2 seems more robust to me. There is no 'update' procedure, just single container creation.</p>&#xA;&#xA;<p>However, what bothers me is if this re-creation of the image has some bad side-effects? Like a lot of dangling images or something similar. Imagine that this may happens very often during the time user plays with the app - for example, if developer is trying out something, he wants to play with different configurations of microservice, and he will re-start it often. But once it is configured, this will not change. Also, when I say <em>configuration</em> I dont mean just config files, but also user code etc.</p>&#xA;"
51697673,"Microservice design with Kubernetes - API gateway, communication, service discovery and db issues",2018-08-05 19:42:13,<node.js><database><rest><kubernetes><microservices>,1,69,1,2.0,0,"<p>Recently I have been researching about microservices and kubernetes. All the tutorial and article I read online talks about general staff. I have several specific questions about building a microservices app on kubernetes.</p>&#xA;&#xA;<ol>&#xA;<li><strong>API gateway:</strong> Is API gateway a microservice I built for my app that can automatically scale? Or is it already a built-in function of kubernetes? The reason I ask is because a lot of the articles are saying that load-balancing is part of the API gateway which confuse me since in kubernetes, load-balancing is handled by <code>service</code>. Also, is this the same as the API gateway on AWS, why don't people use the AWS API gateway instead?</li>&#xA;<li><strong>Communication within services:</strong> from what I read only, there are <em>Rest/RPC</em> way and <em>Message queue</em> way. But why do people say that the <em>Rest</em> way is for sync operation? Can we build the services and have them communicate with rest api with <code>Nodejs async/await</code> functions? </li>&#xA;<li><strong>Service Discovery:</strong> Is this a problem with kubernetes at all? Does kubernetes automatically figure out this for you?</li>&#xA;<li><strong>Databases:</strong> What is the best practice to deploy a database? Deploy as a microservice on one of the node? Also, some articles say that each service should talk to a different db. So just separate the tables of one db to several dbs?</li>&#xA;</ol>&#xA;"
51679363,multi-module Maven project on Dockers,2018-08-03 19:57:38,<java><maven><docker><pom.xml><microservices>,1,43,3,0.0,0,"<p>I have a multi-module maven project where the single modules are all runnable microservice applications containing their own Dockerfile, so in production every module will be a containerized application.</p>&#xA;&#xA;<p>The parent project, which contains the child-modules only contains the parent pom.xml and the docker-compose.yml</p>&#xA;&#xA;<p>I have tried to use the following Dockerfile (on sub-module level):</p>&#xA;&#xA;<pre><code>FROM sgrio/java-oracle&#xA;&#xA;RUN apt-get update&#xA;&#xA;RUN apt-get install -y maven&#xA;&#xA;COPY ../pom.xml /usr/local/service/Oogaday/pom.xml&#xA;&#xA;COPY pom.xml /usr/local/service/Oogaday/OogadayApi/pom.xml&#xA;&#xA;COPY src /usr/local/service/Oogaday/OogadayApi/src&#xA;&#xA;WORKDIR /usr/local/service/Oogaday/OogadayApi/&#xA;&#xA;RUN mvn package -DskipTests&#xA;&#xA;CMD [""java"",""-jar"",""org.oogaday.api-1.0-SNAPSHOT-jar-with-dependencies.jar""]&#xA;</code></pre>&#xA;&#xA;<p>But I am getting a security error because I am  trying to copy the parent pom.xml file (which is not placed in the directory from which I am running the build).</p>&#xA;&#xA;<p>So is there a way to build a maven based sub-module with parent pom?</p>&#xA;"
36318795,Example of Sidecar Application for Microservices,2016-03-30 20:12:22,<spring><spring-boot><spring-cloud><microservices>,1,1501,1,0.0,0,<p>Is Spring cloud config server an example of sidecar application for microservices?</p>&#xA;
50647694,Why using Eureka?,2018-06-01 16:33:00,<kubernetes><microservices><spring-cloud><netflix-eureka>,2,138,0,3.0,0,"<p>I was setting up microservices based on <a href=""https://github.com/Netflix/eureka"" rel=""nofollow noreferrer"">Netflix Eureka</a> and experimenting on top of <a href=""https://cloud.spring.io/spring-cloud-netflix/"" rel=""nofollow noreferrer"">spring-cloud</a> and after weeks of research and development the question rose! </p>&#xA;&#xA;<p>Why do I need the Eureka and spring-cloud?</p>&#xA;&#xA;<p>Why not developing your independent containers and deploy them on <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> as pods and maintain everything from there?</p>&#xA;&#xA;<p>You can support load balancing, service registery, monitoring, containerization, etc. from <a href=""https://kubernetes.io"" rel=""nofollow noreferrer"">Kubernetes</a> too.</p>&#xA;&#xA;<p>Here are some points that I can think of:</p>&#xA;&#xA;<ul>&#xA;<li>developer friendly</li>&#xA;<li>lower server costs for the complete stack</li>&#xA;<li>less OPS dependent</li>&#xA;<li>more resources on developer communities and tutorials</li>&#xA;<li>gradual learning curve</li>&#xA;</ul>&#xA;"
50506101,Spring Boot - how to communicate between microservices?,2018-05-24 09:45:18,<spring-boot><microservices>,2,721,1,0.0,0,"<p>I'm currently working on a Spring Boot microservices project. I have created services and each service is running separately. With this, I need some services to communicate with other services. How can i achieve that?</p>&#xA;&#xA;<p>I saw some blogs about this which use Netflix, Eureka cloud servers to achieve this. Is there any way I can achieve this in my local environment without using cloud servers?</p>&#xA;"
47017875,Scheduler in a java spring boot microservice,2017-10-30 14:34:41,<java><spring-boot><scheduler><microservices>,1,601,3,0.0,0,"<p>We have a microservice written using Spring boot which has its own NoSQL datastore. We are working on functionality whereby we want to delete some old data (in magnitude of 0.5 million documents) and want to do it on a regular basis(once a day) based on presence of records of particular type in data store. </p>&#xA;&#xA;<p>Is having a scheduler which runs once everyday and does the deletion, a correct approach for it ? Also since its a microservice and several instances of it will be running, how do we control that this scheduler runs on only 1 instance ?</p>&#xA;"
47061556,Microservice Setup,2017-11-01 18:39:46,<node.js><docker-compose><microservices>,3,55,4,0.0,0,"<p>I have a several git repo that I want to manage via docker-compose. I also want the project where the docker-compose resides to be a git repo. So I have the following organization:</p>&#xA;&#xA;<p><code>&#xA;UI-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Server-Repo&#xA;  --&gt; .git&#xA;  --&gt; Dockerfile&#xA;</code></p>&#xA;&#xA;<p><code>&#xA;Local-Development-Repo&#xA;  --&gt; .git&#xA;  --&gt; docker-compose.yml&#xA;</code></p>&#xA;&#xA;<p>Unfortunately, I cannot seem to access the UI-Repo and Server-Repo dockerfiles due to limitations in Docker. Having a sym link for the UI-Repo and Server-Repo inside the Local-Development-Repo does not work either. So I can think of two options.</p>&#xA;&#xA;<ol>&#xA;<li><p>Git Submodules</p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I will need to copy package.json and perform a <code>npm install</code> inside my dockerfiles since <code>node_modules</code> is on my .gitignore. I want this purely for development and ideally, should just use volumes instead of installing dependencies inside the docker container. </li>&#xA;</ul></li>&#xA;<li><p>House UI-Repo and Server-Repo inside a parent directory, which contains the docker-compose.yml file. </p>&#xA;&#xA;<ul>&#xA;<li>The downside to this approach is that I want this parent to be tracked via Git as well. I do not think having .git in the parent directory that houses two more git repo will work. </li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>What is the suggested practice to set up microservices architecture having several independent git repos and manage these projects for local development using docker-compose?</p>&#xA;"
38178208,Can CakePhp 2.x or 3.x be used to develop web app based on micro service architecture,2016-07-04 06:35:33,<rest><cakephp><cakephp-3.0><microservices><cakephp-2.8>,1,447,5,0.0,0,<p>I was evaluating PHP based frameworks for development of highly available and scalable applications based on micro service architecture. </p>&#xA;&#xA;<p>I have not seen any documentation for using CakePhp 2.x or 3.0 for design and development of micro services. Where as Laravel ( which is another PHP MVC framework based on Symphony) seems to have these capabilities based on its Lumen modules or components.</p>&#xA;&#xA;<p>It appears that CakePhp frameworks are only suited for design and development of big gigantic monolithic app. </p>&#xA;&#xA;<p>Can anyone point me to a documentation or example about how to use CakePhp 2.x or 3.x for designing web apps based on Micro service architecture ? </p>&#xA;
42642688,Spring Cloud Zuul as API gateway,2017-03-07 07:35:12,<spring><spring-security><microservices><spring-cloud><netflix-zuul>,1,929,2,0.0,0,"<p>I'm new to Spring Cloud and about to kick start a new project in micro-service fashion using Spring Cloud stack i.e. Eureka, Zuul, Ribbon and Hystrix.</p>&#xA;&#xA;<p>The application will have a dumb UI which will interact with back-end services to get job done, the back-end services are rest in nature and will use token based authentication (using JWT) backed by Spring security, so following will be the flow of application </p>&#xA;&#xA;<ol>&#xA;<li><strong>Authentication service</strong>:- Authentication service will take care of authenticating user and validating access token.</li>&#xA;<li><strong>Rest services</strong>: Other services will have their own authorization mechanism, i.e. whether given user (identified from JWT token) has access to requested resource or not.</li>&#xA;</ol>&#xA;&#xA;<p>I've used JWT and Spring security filters to achieve same but not able to map how Zuul will fit into this picture, while going through documentation I encountered ZuulFilters, which can be used to achieve this but using this I need to have my authentication/authorization mechanism at same place i.e. Zuul, but I want my authentication piece at Zuul and have distributed authorization this will save me from configuring every rest resource to role mapping in DB and have that loaded/read at zuul for every request.</p>&#xA;&#xA;<p>I've gone through some blogs/example but most of them talk about SSO stuff, Can someone please enlighten me with a blog post or example, any help is appreciated. </p>&#xA;"
42711116,Service Fabric - DeleteServiceAsync timing out,2017-03-10 05:45:34,<azure><microservices><azure-service-fabric><service-fabric-stateful>,1,62,3,0.0,0,"<p>I am spawning several ASF microservices to run some process. Once the process is done, I am deleting those services using <code>DeleteServiceAsync</code> by using following code. Almost 98% of the time, everything works fine. However, 2% of the time, I run into timeout issue and the microservices stucks in deleting state with Idle Secondary replica. Thanks in advance for any suggestions to resolve this issue.</p>&#xA;&#xA;<pre><code>using (FabricClient fc = new FabricClient())&#xA;{&#xA;    fc.ServiceManager.DeleteServiceAsync(deleteServiceDescription, TimeSpan.FromMinutes(5), cancellationToken);&#xA;}&#xA;</code></pre>&#xA;"
39941660,Which could be the best way for communication of Micro-services without any HARD-CODE,2016-10-09 08:43:40,<spring-boot><microservices><netflix-eureka>,2,153,0,2.0,0,"<p>I having a bunch of microservices which communicates with each other using <code>RestTemplate</code>. All the communication of microservices is from API gateway.</p>&#xA;&#xA;<p>I am doing as following,</p>&#xA;&#xA;<pre><code>    public List&lt;ServiceInstance&gt; serviceInstancesByApplicationName(String applicationName) {&#xA;            return this.discoveryClient.getInstances(applicationName);&#xA;        }&#xA;&#xA;    //some Other logic &#xA;&#xA;    List&lt;ServiceInstance&gt; apigatewaymsInstanceList = discoveryClient.getInstances(apigatewaymsName);&#xA;            ServiceInstance apigatewaymsInstance = apigatewaymsInstanceList.get(0);&#xA;&#xA;    //and&#xA;&#xA;    restTemplate.exchange(apigatewaymsInstance.getUri().toString() + plmpayloadprocessmsResource, HttpMethod.POST,&#xA;                                entity, String.class);&#xA;</code></pre>&#xA;&#xA;<p>But here it appears like a hard code. Is there some another approach I am missing? What could be the best way ?</p>&#xA;&#xA;<p>Likewise, I am asking is there any method available so that I can pass the name of application and eureka return me its full URI no need to do <code>applicationgetInstaceId(0);</code></p>&#xA;"
40082248,Handle message dependency when using evening environment(MessageMQ),2016-10-17 09:00:38,<spring-boot><rabbitmq><message><microservices>,1,28,3,0.0,0,"<p>I am developing a micro service platform using Spring technologies. I am facing some problem when consuming message from Rabbit MQ.</p>&#xA;&#xA;<p>Scenario:</p>&#xA;&#xA;<p>I have two message queue, <strong>student</strong> and <strong>enrollment</strong>. In my one microservice I put the student and enrollment creation request to message queue. </p>&#xA;&#xA;<p>But, since the message queue order not guaranteed, enrollment message comes <strong>before</strong> the students come. &#xA;On that time my relation database fail. </p>&#xA;&#xA;<p>What is the best way to handle this kind of scenario(message ordring) when using message mq in microservice platform? </p>&#xA;"
38872460,How to share a host directory between multiple docker container?,2016-08-10 11:41:31,<node.js><docker><dockerfile><microservices>,3,294,1,0.0,0,"<p>This is my directory structure <a href=""http://i.stack.imgur.com/yaANi.png"" rel=""nofollow"">for docker microservices </a>. What I need to do  is to share certain files from my lib folder which is on my host machine to containers. These are lib files which are required to run the application in both of the containers.This is the content from one of my docker file inside one of the container propinfo-finder</p>&#xA;&#xA;<pre><code>FROM alpine:3.3&#xA;&#xA;RUN apk add --update nodejs&#xA;&#xA;RUN mkdir -p /usr/src/app&#xA;WORKDIR /usr/src/app&#xA;&#xA;COPY . /usr/src/app&#xA;RUN npm install&#xA;&#xA;EXPOSE 3000&#xA;&#xA;WORKDIR /usr/src/app&#xA;CMD node index.js&#xA;</code></pre>&#xA;&#xA;<p>I build the docker images using this command <code>docker build -t nodeapp/premcal .</code> The build process is successful . Then i use this command to map/mount the directory <code>bin</code> to the container to make it run&#xA;from the parent directory where bin folder is located </p>&#xA;&#xA;<p><code>docker run -v $PWD/lib:/usr/src/app -p 3010:3000 -i nodeapp/premcal&#xA;</code>&#xA;after running it I am getting this error </p>&#xA;&#xA;<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">&#xD;&#xA;<div class=""snippet-code"">&#xD;&#xA;<pre class=""snippet-code-html lang-html prettyprint-override""><code>module.js:328&#xD;&#xA;    throw err;&#xD;&#xA;    ^&#xD;&#xA;&#xD;&#xA;Error: Cannot find module '/usr/src/app/index.js'&#xD;&#xA;    at Function.Module._resolveFilename (module.js:326:15)&#xD;&#xA;    at Function.Module._load (module.js:277:25)&#xD;&#xA;    at Function.Module.runMain (module.js:442:10)&#xD;&#xA;    at startup (node.js:136:18)&#xD;&#xA;    at node.js:966:3</code></pre>&#xD;&#xA;</div>&#xD;&#xA;</div>&#xD;&#xA;</p>&#xA;&#xA;<p>The host is a physical Ubuntu machine . </p>&#xA;&#xA;<p>can anybody please tell me how to make this go away . All I have is 2 hrs of experience with node.js and docker environment . &#xA;Thank you .</p>&#xA;"
38764797,Get AccessToken from spring cloud zuul API Gateway,2016-08-04 10:26:02,<wso2is><spring-cloud><microservices><oauth2><netflix-zuul>,1,301,4,0.0,0,<p>We are using zuul as API gateway in spring cloud. Now we want to extract access token from zuul for further implementation.Please provide suggestion how we want to implement. Thank you</p>&#xA;
51300620,Strange error with a JHipster app in a microservices architecture and Docker up,2018-07-12 08:22:11,<docker><docker-compose><microservices><jhipster>,2,66,4,0.0,0,"<p>I have generated an app with JHipster 5.0.1 version. The app has 4 components:</p>&#xA;&#xA;<ul>&#xA;<li>UAA app for user accounting and authorizing</li>&#xA;<li>JHipster Registry app</li>&#xA;<li>A gateway app </li>&#xA;<li>A simple microservice</li>&#xA;</ul>&#xA;&#xA;<p>I have followed all the steps in the documentation, including the steps to create docker compose file. But, then when I want to run docker-compose up I get some errors with pull permisions with my custom components.</p>&#xA;&#xA;<p>Here are the logs</p>&#xA;&#xA;<blockquote>&#xA;  <p>compose.cli.verbose_proxy.proxy_callable: docker inspect_image &lt;- ('chipagames')&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""GET /v1.22/images/chipagames/json HTTP/1.1"" 404 60&#xA;  compose.service.pull: Pulling chipagames-app (chipagames:)...&#xA;  compose.cli.verbose_proxy.proxy_callable: docker pull &lt;- ('chipagames', tag='latest', stream=True, platform=None)&#xA;  docker.auth.get_config_header: Looking for auth config&#xA;  docker.auth.resolve_authconfig: Using credentials store ""osxkeychain""&#xA;  docker.auth._resolve_authconfig_credstore: Looking for auth entry for '<a href=""https://index.docker.io/v1/"" rel=""nofollow noreferrer"">https://index.docker.io/v1/</a>'&#xA;  docker.auth.get_config_header: Found auth config&#xA;  urllib3.connectionpool._make_request: <a href=""http://localhost:None"" rel=""nofollow noreferrer"">http://localhost:None</a> ""POST /v1.22/images/create?tag=latest&amp;fromImage=chipagames HTTP/1.1"" 404 91</p>&#xA;</blockquote>&#xA;&#xA;<p>I have docker service running, I have created a repository in docker hub too, but I don't understand the error.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Here is my docker-compose.yml</p>&#xA;&#xA;<pre><code>version: '2'&#xA;services:&#xA;    appuaa-app:&#xA;        image: appuaa&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATA_MONGODB_URI=mongodb://appuaa-mongodb:27017&#xA;            - SPRING_DATA_MONGODB_DATABASE=appuaa&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=appuaa-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    appuaa-mongodb:&#xA;        image: mongo:3.6.3&#xA;    appuaa-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    chipagames-app:&#xA;        image: chipagames&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://chipagames-postgresql:5432/chipagames&#xA;            - JHIPSTER_SLEEP=30&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;        ports:&#xA;            - 8080:8080&#xA;    chipagames-postgresql:&#xA;        image: postgres:9.6.5&#xA;        environment:&#xA;            - POSTGRES_USER=chipagames&#xA;            - POSTGRES_PASSWORD=&#xA;&#xA;    users-app:&#xA;        image: users&#xA;        environment:&#xA;            - SPRING_PROFILES_ACTIVE=prod,swagger&#xA;            - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/eureka&#xA;            - SPRING_CLOUD_CONFIG_URI=http://admin:$${jhipster.registry.password}@jhipster-registry:8761/config&#xA;            - SPRING_DATASOURCE_URL=jdbc:postgresql://users-postgresql:5432/users&#xA;            - JHIPSTER_SLEEP=30&#xA;            - SPRING_DATA_ELASTICSEARCH_CLUSTER_NODES=users-elasticsearch:9300&#xA;            - JHIPSTER_REGISTRY_PASSWORD=;nddeanb&#xA;    users-postgresql:&#xA;        image: postgres:10.4&#xA;        environment:&#xA;            - POSTGRES_USER=users&#xA;            - POSTGRES_PASSWORD=&#xA;    users-elasticsearch:&#xA;        image: elasticsearch:5.6.5&#xA;        command: -Enetwork.host=0.0.0.0 -Ediscovery.type=single-node&#xA;&#xA;    jhipster-registry:&#xA;        extends:&#xA;            file: jhipster-registry.yml&#xA;            service: jhipster-registry&#xA;&#xA;    jhipster-elasticsearch:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-elasticsearch&#xA;    jhipster-logstash:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-logstash&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-console:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-console&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-import-dashboards:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-import-dashboards&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;    jhipster-zipkin:&#xA;        extends:&#xA;            file: jhipster-console.yml&#xA;            service: jhipster-zipkin&#xA;        depends_on:&#xA;            - jhipster-elasticsearch&#xA;</code></pre>&#xA;"
49284804,Understanding Microservice Architecture,2018-03-14 18:02:37,<spring><mongodb><docker><jar><microservices>,3,74,0,0.0,0,"<p>Since I am trying hard to understand the microservice architecture pattern for some work, I came across the following question:</p>&#xA;&#xA;<p>It's always said that a microservice usually has its own database. But does this mean that it always has to be on the same server or container (for example having <strong>one</strong> docker container that runs a MongoDB and my JAR)? Or can this also mean that on one server my JAR is running while my MongoDB is located somewhere else (so <strong>two</strong> containers for example)?</p>&#xA;&#xA;<p>If the first one is correct (JAR <strong>and</strong> database within <strong>one</strong> container), how can I prevent that after some changes regarding my application and after a new deployment of my JAR my data of the MongoDB is resetted (since a whole new container is now running)?</p>&#xA;&#xA;<p>Thanks a lot already :-)</p>&#xA;"
49390064,Is it possible to create an exposed kubernetes service based on a new deployment in one command?,2018-03-20 16:57:44,<kubernetes><containers><cluster-computing><microservices>,1,23,5,0.0,0,<p>I feel this must be possible but haven't managed to find docs on how to do this.</p>&#xA;&#xA;<p>I would ideally like to add service exposure details in a deployment yaml file and the service would come up with a host name and port upon the issuing of a create command with the deployment yaml. </p>&#xA;
46813736,Microservices are compatible with existing SQL database?,2017-10-18 15:21:30,<sql><database-design><architecture><rabbitmq><microservices>,3,260,0,0.0,0,"<p>I'm creating a microservice architecture with Core, rabbitMQ, strangler pattern ... but I have to use an existing SQL database (Transaction requeriment).</p>&#xA;&#xA;<p>Doing a research I don't found a lot of information about how implement SQL database, but I think it's impossible to do a transactional operation on different services at the same time.</p>&#xA;&#xA;<p>1- Every service must have access to entirely database?</p>&#xA;&#xA;<p>2- Is a good idea do a service exclusive to do transactionals operations?</p>&#xA;&#xA;<p>3- SQL with microservices it's maybe too much slow?</p>&#xA;&#xA;<p>I don't know if exist a standard for this.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
45058457,How to Auto Scale Microservices in Local server without cloud using JAVA,2017-07-12 13:03:10,<spring-boot><microservices><spring-boot-maven-plugin>,1,1697,0,0.0,0,"<p>Hi I am new to the microservices. I have created spring boot(maven) microservices (2 services, 1 gateway and service registry). How can I scale (auto scaling) 2 services without cloud technology. Is it possible in the local configuration? </p>&#xA;"
44977364,How does Microservices in practice work?,2017-07-07 18:20:26,<web><architecture><microservices>,2,165,2,2.0,0,"<p>In theory I understand how Microservices work and why they can be helpful in various cases but I still don´t get how it works in practice.</p>&#xA;&#xA;<p>Let´s say there´s an online shop based on a CMS as a monolith application.</p>&#xA;&#xA;<p>And there´s now the need to run the online shop in a MIcroservices architecture. </p>&#xA;&#xA;<p>How would this Microservices architecture differ technically from the current, monolith, architecture?</p>&#xA;&#xA;<p>For example, I pick out the productsearch.php. If i want to scale this function, normally I had to set up a new server and copy the whole CMS ressources folder to it for loadbalancing. </p>&#xA;&#xA;<p>And with Microservices, productsearch.php would be a single Microservice I guess, and I would have to just copy this php file to scale without the need to copy other ressources?</p>&#xA;"
45031529,Create service instances with parameters in Service Fabric,2017-07-11 10:09:01,<c#><azure><microservices><azure-service-fabric><azure-iot-hub>,1,171,3,0.0,0,"<p>I'm using Service Fabric on Azure for a project at work where, put simply, I have a service whose function is to read data from IoT Hub.</p>&#xA;&#xA;<p>As it stands, that service is reading data from 32 partitions at the same time (multiple threads), but I'm trying to refactor it into one service intance per partition. The problem is I can't find a way to create 32 instances of a service and inform each instance of the Hub partition it should read (paramethers perhaps?).</p>&#xA;&#xA;<p>I can provide code samples if needed, but I feel the problem is pretty self-explanatory.</p>&#xA;"
45023334,How to efficiently handle spring boot microservices?,2017-07-10 23:55:58,<java><spring><spring-boot><dns><microservices>,2,192,4,0.0,0,"<p>I have bunch of spring boot microservices running in unique ports. How do we handle these microservices in production ?</p>&#xA;&#xA;<p>In production, we only need the DNS, how do we handle the DNS mapping.</p>&#xA;&#xA;<p>For ex:&#xA;<em>example-microservice-1 (port: 8001)<br>&#xA;example-microservice-2 (port: 8002)<br>&#xA;example-microservice-3(port: 8003)<br>&#xA;example-microservice-4 (port: 8004)<br>&#xA;example-microservice-5 (port: 8005)</em>  </p>&#xA;&#xA;<p>I would want something like below,<br>&#xA;<em>myprod.com/example-microservice-1<br>&#xA;myprod.com/example-microservice-2</em>   ...</p>&#xA;&#xA;<p>Instead of,<br>&#xA;<em>myprod:8001/example-microservice-1<br>&#xA;myprod:8002/example-microservice-2</em>  </p>&#xA;&#xA;<p>(removed ""https/http"" above due to less reputation) </p>&#xA;&#xA;<p>All the microservices exists in a different codebase and when build will create individual runnable jars.</p>&#xA;"
44484346,bash command to wait until TCP port is opened,2017-06-11 13:24:50,<java><linux><bash><microservices>,1,981,7,0.0,0,"<p>I want my micro services to open in a new command line and run it from there one after the other. below is my bash script</p>&#xA;&#xA;<pre class=""lang-bash prettyprint-override""><code>################ first SERVER #####################&#xA;gnome-terminal -x sh -c 'java -jar server/target/first-server.jar; exec bash'&#xA;&#xA;################ second SERVER #####################&#xA;export service_port=8771&#xA;export host_name=firstdomain&#xA;gnome-terminal -x sh -c 'java -Dservice.port=""${service_port}"" -Dhost.name=""${host_name}"" -jar eureka/target/second-server.jar; exec bash'&#xA;</code></pre>&#xA;&#xA;<p>The problem is it that i want to start my <strong>""second-server.jar""</strong> after successfully started the <strong>""first-server.jar""</strong>. I can detect that by checking if the service is listening to network port. Is there any way to archive this? <strong>sleep</strong> bash command is not a option for me.</p>&#xA;"
37684678,"Integration Tests with Microservices (NodeJS), Jenkins and Docker",2016-06-07 16:31:18,<node.js><git><jenkins><docker><microservices>,1,599,0,0.0,0,"<p>How would you typically configure Jenkins to build microservices (multiple NodeJS services, Rabbit, Mongo, etc), then test those services all together ?</p>&#xA;&#xA;<p>Let's say I've the following services:</p>&#xA;&#xA;<ul>&#xA;<li>RabbitMQ</li>&#xA;<li>Mongo</li>&#xA;<li>NodeJS Service 1</li>&#xA;<li>NodeJS Service 2</li>&#xA;</ul>&#xA;&#xA;<p>Each of them has their own tests (unit and integration) and their Dockerfile.</p>&#xA;&#xA;<p>I want to configure Jenkins in a way that it would enable me to clone all theses services, run them all at the same time in different containers with Rabbit and Mongo containers along them. It would then run the tests for each of those services (they do generate TAP and coverage reports). Then take those reports for the TAP/Coverage Jenkins plugins. If it works out, commit the image and push it to the docker registry.</p>&#xA;&#xA;<p>I've been lying around Stack and Google and I don't really see an easy way to get there that would not imply tons of bash.</p>&#xA;&#xA;<p>Maybe I see it in the wrong way, any input is more than welcome!</p>&#xA;"
44692442,Https config dosn't work in zuul routing,2017-06-22 07:07:19,<https><routing><microservices><spring-cloud><netflix-zuul>,2,943,4,0.0,0,"<p>I have a router application with zuul and many services that are run in the backend and requests from client are routed to their services by zuul.</p>&#xA;&#xA;<p>Everything is working well over http but when I configure the router and all services to https the following error is raised:</p>&#xA;&#xA;<pre><code>javax.net.ssl.SSLPeerUnverifiedException: Certificate for &lt;127.0.0.1&gt; doesn't match any of the subject alternative names: []&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:467) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.createLayeredSocket(SSLConnectionSocketFactory.java:397) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:355) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;</code></pre>&#xA;&#xA;<p>The zuul yml file :</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredPatterns: /reza,/we&#xA;  routes:&#xA;    trp:&#xA;      path: /micro1/**&#xA;      sensitiveHeaders:&#xA;      url: https://127.0.0.1:8080/micro1&#xA;server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 80&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234  &#xA;</code></pre>&#xA;&#xA;<p>And the yml file of one of those services:</p>&#xA;&#xA;<pre><code>server:&#xA;    compression:&#xA;        enabled: true&#xA;    port: 8080&#xA;    ssl:&#xA;        key-store: classpath:keystore.jks&#xA;        key-store-password: password&#xA;        key-password: matin1234&#xA;</code></pre>&#xA;&#xA;<p>First I want to know that the concept of https over zuul works properly and secondly I want to know how I fix my problem.</p>&#xA;&#xA;<p>Note: I don't have Eureka server registration.</p>&#xA;"
48296421,Docker Microservice Architecture - Communication between different containers,2018-01-17 08:16:40,<azure><docker><microservices><docker-container>,1,130,1,2.0,0,"<p>I've just started working with docker and I'm currently trying to work out how to setup a project using microservice architecture.</p>&#xA;&#xA;<p>My goal is to move out different services from the api and instead have each one in their own container.</p>&#xA;&#xA;<p><strong>Current architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ewRMg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ewRMg.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Desired architecture</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/mCKD7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mCKD7.png"" alt=""To""></a></p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ol>&#xA;<li>How does the API gateway communicate with the internal services? Should all microservices have their own API which only accept communication from the API gateway? Any other means of communications?</li>&#xA;<li>What would be the ideal authentication between the gateway and the microservices? JWT token? Basic Auth?</li>&#xA;<li>Do you see any problems with this architecture if hosted in Azure?</li>&#xA;<li>Is integration testing even possible in the desired architecture? For example, I use EF SQlite inmemory for integration testing and its easily accessible within the api, but I don't see this working if the database is located in it's own container.</li>&#xA;<li>Anything important here that i've missed?</li>&#xA;</ol>&#xA;"
37457765,Access microservice using Spring Boot,2016-05-26 10:09:12,<java><spring><spring-boot><microservices>,1,614,10,0.0,0,"<p>I have to implement my project as microservice arch. For that I am doing one sample app using Spring Boot of adding two no. I have three services. Here is my registration-server.yml.Similarly I have <code>account-server.yml</code> and <code>user-service.yml</code>. I want to call <code>add()</code> using <code>UserService.java</code> without RMI concept, since I am using Spring Boot. Also I don't want REST call since it will be costly for my project. How can I manually write code for <code>lookup()</code> in <code>UserService</code> so that it can call Adder?</p>&#xA;&#xA;<pre><code>@EnableAutoConfiguration&#xA;@EnableDiscoveryClient&#xA;public class AddService {&#xA;&#xA;public static int add(int x,int y){&#xA;    int z=x+y;&#xA;    System.out.println(""The sum of no. is ""+z);&#xA;    return z;&#xA;}&#xA;&#xA;public static void main(String[] args) {&#xA;    System.setProperty(""spring.config.name"", ""add-service"");&#xA;    SpringApplication.run(AddService.class, args);&#xA;}&#xA;&#xA;@SpringBootApplication&#xA;@EnableEurekaServer&#xA;public class RegistrationService {&#xA;&#xA;public static void main(String[] args) {&#xA;    // Tell server to look for registration.properties or registration.yml&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(RegistrationService.class, args);&#xA;}&#xA;&#xA;&#xA;@SpringBootApplication&#xA;@EnableDiscoveryClient&#xA;public class UserService {&#xA;public static void main(String[] args) {&#xA;&#xA;    System.setProperty(""spring.config.name"", ""registration-service"");&#xA;&#xA;    SpringApplication.run(UserService.class, args);&#xA;}&#xA;&#xA;&#xA;&#xA;&#xA;    eureka:&#xA;   instance:&#xA;    hostname: localhost&#xA;    client:  # Not a client, don't register with yourself&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;  server:&#xA;  port: 1111   # HTTP (Tomcat) port&#xA;</code></pre>&#xA;"
44129347,Microservices for job/cron tasks,2017-05-23 08:14:47,<cron><scalability><microservices>,2,989,0,0.0,0,"<p>For example I want to have a microservice to send notifications(email, sms, push notification). Everything is ok for few users. After some time our application have a lot of users, so, this microservice doe not manage, and email a sent after 1 hour. </p>&#xA;&#xA;<p>So, how to handle this situation? Deploy another instance of microservice, but how to handle that only one microservice process one email and user don't receive multiple emails?</p>&#xA;"
44084744,Microservice architecture Flaws,2017-05-20 10:25:34,<architecture><microservices><restful-architecture>,1,189,3,1.0,0,"<p>We are facing performance related issues with microservice architecture.</p>&#xA;&#xA;<p>Let's say there is microservice for user and account management. which have api's like </p>&#xA;&#xA;<pre><code>GET /users/{id} &#xA;GET /users       (arrount 6 million users)&#xA;&#xA;GET /accounts/{accountId}&#xA;GET /accounts &#xA;and Other Operations on user and account&#xA;</code></pre>&#xA;&#xA;<p>We have other microservice which track's user activities and list all the activities done by the user in his last login.</p>&#xA;&#xA;<pre><code>GET /user/activity/{userId}  (on an average 1000 to 10000 records)&#xA;</code></pre>&#xA;&#xA;<p>We have protal for sales and marketing team to show individual user activities and  user info and account info based on search criteria,</p>&#xA;&#xA;<pre><code>let's say search criteria is like : get all user activies who are located in colombia&#xA;Algorithm : &#xA;&#xA;1)Get /users ? location = colombia&#xA;2)then for individual user Get /user/activity/{userId}&#xA;</code></pre>&#xA;&#xA;<p>it is like joining two tables from different databases.</p>&#xA;&#xA;<p>it is very slow and creating lot of performance issues.</p>&#xA;&#xA;<p>what i though of is replicating user table in other microservice by a job which makes sure it is up to date and using only one api like</p>&#xA;&#xA;<pre><code>GET /user/activities?location=colombia.&#xA;</code></pre>&#xA;&#xA;<p>but replicating a table(user) is breaking the micro-service architecture main fundamentals</p>&#xA;&#xA;<p>is there any other way to do it or support this type of filter criteria which join's tables from different micro-services.</p>&#xA;"
44198061,Decision path for Azure Service Fabric Programming Models,2017-05-26 09:25:59,<azure><microservices><azure-service-fabric>,1,225,4,1.0,0,"<p><strong>Background</strong></p>&#xA;&#xA;<p>We are looking at porting a 'monolithic' 3 tier Web app to a microservices architecture. The web app displays listings to a consumer (think Craiglist).</p>&#xA;&#xA;<p>The backend consists of a REST API that calls into a SQL DB and returns JSON for a SPA app to build a UI (there's also a mobile app). Data is written to the SQL DB via background services (ftp + worker roles). There's also some pages that allow writes by the user.</p>&#xA;&#xA;<p><strong>Information required:</strong></p>&#xA;&#xA;<p>I'm trying to figure out how (if at all), Azure Service Fabric would be a good fit for a microservices architecture in my scenario. I know the pros/cons of microservices vs monolith, but i'm trying to figure out the <em>application</em> of various microservice programming models to our current architecture.</p>&#xA;&#xA;<p><strong>Questions</strong></p>&#xA;&#xA;<ul>&#xA;<li>Is Azure Service Fabric a good fit for this? If not, other recommendations? Currently i'm leaning towards a bunch of OWIN-based .NET web sites, split up by area/service, each hosted on their own machine and tied together by an API gateway.</li>&#xA;<li>Which Service Fabric programming model would i go for? Stateless services with their own backing DB? I can't see how Stateful or Actor model would help here.</li>&#xA;<li>If i went with Stateful services/Actor, how would i go about updating data as part of a maintenance/ad-hoc admin request? Traditionally we would simply login to the DB and update the data, and the API would return the new data - but if it's persisted in-memory/across nodes in a cluster, how would we update it? Would i have to expose this all via methods on the service? Similarly, how would I import my existing SQL data into a stateful service? </li>&#xA;<li>For Stateful services/actor model, how can I 'see' the data visually, with an object Explorer/UI. Our data is our Gold, and I'm concerned of the lack of control/visibility of it in the reliable services models</li>&#xA;</ul>&#xA;&#xA;<p>Basically, is there some documentation on the <em>decision path</em> towards which programming model to go for? I could model a ""listing"" as an Actor, and have millions of those - sure, but i could also have a Stateful service that stores the listing locally, and i could also have a Stateless service that fetches it from the DB. How does one decide as to which is the best approach, for a given use case?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
35890054,Test automation for microservices architecture,2016-03-09 11:16:13,<automated-tests><microservices>,3,609,2,0.0,0,"<p>I am in charge of implementing QA processes and test automation for a project using microservices architecture.</p>&#xA;&#xA;<p>Project has one public api that makes some data available. So I will automate API tests. Tests will live in one repository. This part is clear to me, I did this before in other monolith projects. I had one repo for API tests. And possibly another repo for selenium tests.</p>&#xA;&#xA;<p>But then here the whole poduct consists of many microservices that communicate via restful apis and/or rabbit queues. How would I go about automating tests for each of these individual servicess? Would tests for each individual service be in a separate repo? Note: services are written in Java or PHP. I will automate tests with Python. It seems to me that I will end up with a lot of repos for tests/stubs/mocks.</p>&#xA;&#xA;<p>What suggestions or good resources can community offer? :)</p>&#xA;"
40807126,Run powershell script as microservice,2016-11-25 14:25:28,<windows><powershell><automation><microservices>,1,343,6,0.0,0,"<p>Is it possible to make my powershell script, run as a microservice?</p>&#xA;&#xA;<pre><code>Param(&#xA;    $a,&#xA;    $b&#xA;)&#xA;&#xA;$x = [int]$a + [int]$b&#xA;&#xA;echo $x&#xA;</code></pre>&#xA;"
52057828,How to Create a MicroService in .Net Core / Visual Studio,2018-08-28 12:23:28,<asp.net-core><.net-core><microservices>,3,38,1,0.0,0,"<blockquote>&#xA;  <p>This buzzword is making me pull my hair... I have been asked to create&#xA;  a <strong>microservice</strong> using <strong>.net core</strong>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Googled a lot, different definitions and samples, but still, I don't know what makes a vs project a microservice / how can I create a microservice in VS. For example, I have asked to create a microservice where a user will input two latitude and longitude values and they will get the distance between them.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Cool, I can do this as a web project in no time. But here I need this as a microservice where the rest of the projects in our firm can use it.&#xA;What really makes a VS project into a Microservice or can I convert a project into a micro service? Microservice experts are welcome ...!!! I looking for that step by process in which a microservice is created in .net core. </p>&#xA;"
52098392,Consuming RESTful services orchestrated by Kubernetes,2018-08-30 13:33:31,<rest><kubernetes><microservices>,1,26,3,0.0,0,"<p>How do you consume a service that is being orchestrated by Kubernetes?&#xA;What does the calling statement look like.&#xA;When consuming a normal RESTful web service, you might use RestTemplate (for Java) and specify the URL.&#xA;How does this differ when Kubernetes creates and destroys occurrences of the service?</p>&#xA;"
43142821,"Kubernetes: single POD with many container, or many Pod with single container",2017-03-31 14:11:28,<kubernetes><microservices>,5,420,0,0.0,0,"<p>I've rather a teoretical question which I can't answer  with the reousrces found online. The question is: <strong>what's the rule to decide how to compose containers in POD?</strong> . Let me explain with an example.</p>&#xA;&#xA;<p>I've these microservices:</p>&#xA;&#xA;<ul>&#xA;<li>Authentication </li>&#xA;<li>Authorization </li>&#xA;<li>Serving content</li>&#xA;<li>(plus) OpenResty to forward the calls form one to the other and orhcestarate the flow. (is there a possibility to do so natively in K8?, it seems to have services base on nginx+lua, but not sure how it works)</li>&#xA;</ul>&#xA;&#xA;<p><em>For the sake of the example I avoid Databases and co, I assume they are external and not managed by kubernetes</em></p>&#xA;&#xA;<p>Now, what's the correct way here <em>LEFT</em> or <em>RIGHT</em> of the image?&#xA;<a href=""https://i.stack.imgur.com/b0VwE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b0VwE.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><em>LEFT</em> : this seems easier to make it working, everything works on ""localhost"" , the downside is that it looses a bit the benefit of the microservices. For example, if the auth become slows and it would need more instances, I've to duplicate the whole pod and not just that service.</p>&#xA;&#xA;<p><em>RIGHT</em> seems a bit more complex, need services to expose each POD to the other PODs. Yet, here, I could duplicate auth as I need without duplicating the other containers. On the other hand I'll have a lot of pods since each pod is basically a container.</p>&#xA;"
37213471,Best Practices when Migrating to Microservices,2016-05-13 15:05:28,<refactoring><microservices>,3,145,0,0.0,0,"<p>To anyone with real world experience breaking a monolith into separate modules and services.</p>&#xA;&#xA;<p>I am asking this question having already read the <a href=""http://martinfowler.com/bliki/MonolithFirst.html"" rel=""nofollow"">MonolithFirst</a> blog entry by Martin Fowler. When taking a monolith and breaking it into microservices the ""size"" element of the equation is the one that I ponder over the most.  Specifically, how to approach breaking a monolith application (we're talking 2001: A Space Oddessy; as in it is that old and that large) into micro services without getting overly fine grained or staying too monolithic.  The end goal is creating separate modules that can be upgraded indepenently and scaled independently.</p>&#xA;&#xA;<p>What are some recommended best practices based on personal experience of breaking a monolith into microservices?</p>&#xA;"
43326844,swagger2 for springboot microservice do no produce response on ui,2017-04-10 15:11:06,<spring-boot><microservices><swagger-ui>,1,75,5,0.0,0,"<p>I created one micro service with spring boot, I don't have resource folder and i wanted to add swagger support. So I followed as per <a href=""http://www.baeldung.com/swagger-2-documentation-for-spring-rest-api"" rel=""nofollow noreferrer"">document</a></p>&#xA;&#xA;<p>So </p>&#xA;&#xA;<ol>&#xA;<li>Added swagger dependency.</li>&#xA;<li>Added docker class as it is </li>&#xA;<li>Added swagger's ui dependency</li>&#xA;</ol>&#xA;&#xA;<p>Results</p>&#xA;&#xA;<ol>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><a href=""http://localhost:port/myservice/v2/api-docs"" rel=""nofollow noreferrer"">http://localhost:port/myservice/v2/api-docs</a> ->&#xA; Response is as per expectation.</li>&#xA;<li><p>But &#xA;<a href=""http://localhost:port/myservice/swagger-ui.html"" rel=""nofollow noreferrer"">http://localhost:port/myservice/swagger-ui.html</a> ->&#xA;Not expected response, on browser console i am getting error</p>&#xA;&#xA;<p>GET <a href=""http://localhost:port/myservice/configuration/ui"" rel=""nofollow noreferrer"">http://localhost:port/myservice/configuration/ui</a> 404 (Not Found)</p></li>&#xA;</ol>&#xA;&#xA;<p>As its microservice, I don't have <code>@EnableWebMvc</code> class. </p>&#xA;&#xA;<p>What Am I missing ? </p>&#xA;"
43460615,How to execute docker commands after a process has started,2017-04-17 22:25:10,<docker><docker-compose><dockerfile><microservices><consul>,2,112,5,0.0,0,"<p>I wrote a Dockerfile for a service (I have a CMD pointing to a script that starts the process) but I cannot run any other commands after the process has started? I tried using '&amp;' to run the process in the background so that the other commands would run after the process has started but it's not working? Any idea on how to achieve this?</p>&#xA;&#xA;<p>For example, consider I started a database server and wanted to run some scripts only after the database process has started, how do I do that?</p>&#xA;&#xA;<p><strong>Edit 1:</strong></p>&#xA;&#xA;<p>My specific use case is I am running a Rabbitmq server as a service and I want to create a new user, make him administrator and delete the default guest user once the service starts in a container. I can do it manually by logging into the docker container but I wanted to automate it by appending these to the shell script that starts the rabbitmq service but that's not working.</p>&#xA;&#xA;<p>Any help is appreciated!</p>&#xA;&#xA;<p>Regards</p>&#xA;"
48062134,Connection refused with two microservices in Docker,2018-01-02 13:44:21,<java><docker><spring-boot><microservices>,1,1008,2,0.0,0,"<p>I have two microservices and I want that one consumes of the other but I'm obtaining this mistake: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path&#xA;  [] threw exception [Request processing failed; nested exception is&#xA;  org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  GET request for ""<a href=""http://localhost:8080/testMicroservicio"" rel=""nofollow noreferrer"">http://localhost:8080/testMicroservicio</a>"": Connection&#xA;  refused (Connection refused); nested exception is&#xA;  java.net.ConnectException: Connection refused (Connection refused)]&#xA;  with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused (Connection refused)</p>&#xA;</blockquote>&#xA;&#xA;<p>However if I execute the url in the browser, it works perfectly but if a microservice wants to access to the other microservice, I have this mistake.</p>&#xA;&#xA;<p>Does someone kown why?</p>&#xA;&#xA;<p>I'm consuming with: RestTemplate</p>&#xA;&#xA;<p>I put some of code:</p>&#xA;&#xA;<pre><code>@RestController&#xA;public class MicroServiceController {&#xA;&#xA;&#xA;    private final AddressService service;&#xA;&#xA;    private static final String URL_API_INFO = ""http://localhost:8080/testMicroservicio"";&#xA;&#xA;    private RestTemplate restTemplate = new RestTemplate();&#xA;&#xA;    private final static Logger log = Logger.getLogger(""com.bernanetwork.web.controller.MicroServiceController"");&#xA;&#xA;    @Autowired&#xA;    public MicroServiceController(AddressService service) {&#xA;        this.service = service;&#xA;    }&#xA;&#xA;    @RequestMapping(value = ""/micro-service-test"")&#xA;    public String consumidor() throws Exception {&#xA;&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;        log.info(""-------------------------Iniciando método consumidor------------------------------------"");&#xA;        log.info(""----------------------------------------------------------------------------------------"");&#xA;&#xA;        ResponseEntity &lt;PruebasMicroservicio[]&gt; response = restTemplate.getForObject(URL_API_INFO, PruebasMicroservicio[].class);&#xA;&#xA;        Arrays.asList(response.getBody()).forEach(info -&gt; log.info(""---""+info));&#xA;&#xA;        return ""ok"";&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>These microservices are running in Docker</p>&#xA;&#xA;<p>Thanks so much.</p>&#xA;"
48153334,Microservices Monitoring Using Status Code,2018-01-08 15:30:31,<amazon-web-services><microservices>,1,34,3,0.0,0,"<p>We are using Amazon ECS for micro-services based architecture. We are right now using ALB service monitoring with target-group associated with each service in an ECS cluster. </p>&#xA;&#xA;<p>Right now, We are facing difficulty to monitor the microservices as they are hosted under route 53 private hosted zone. </p>&#xA;&#xA;<p>We have tried to monitor Route 53 health monitoring but route 53 doesn't allow to monitor the health of the endpoints with a simple routing policy. </p>&#xA;&#xA;<blockquote>&#xA;  <p>Ref:&#xA;  <a href=""https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html</a></p>&#xA;</blockquote>&#xA;&#xA;<p>We need to monitor the status code of each microservice at any interval of time. </p>&#xA;&#xA;<p>We have also setup health-check for each microservice. Example: service-a.domain/ping. We need a status-page which represent the health of all available service we add using the status code we add. Also, any way if we can monitor them from application load balancer target group).</p>&#xA;&#xA;<p>What will be the best way to monitor every microservice. ?</p>&#xA;"
48030343,Microservice deployment --- simple jars vs docker containers,2017-12-30 02:14:56,<java><docker><war><microservices><continuous-deployment>,1,470,3,0.0,0,"<p>I am about to deploy a set of JAVA based microservices.&#xA;I am confused as to whether:</p>&#xA;&#xA;<ol>&#xA;<li>Run them as simple jars via ""java -jar [JAR_NAME]""</li>&#xA;<li>Run them in a JAVA based docker container.</li>&#xA;<li>Run them as a war.</li>&#xA;</ol>&#xA;&#xA;<p>Please offer me pros and cons of each implementation as this will save me a lot of headache if I use the suggested best approach :)</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
48095718,No service dependencies found in Jaeger UI,2018-01-04 12:50:20,<spring-boot><kubernetes><microservices><minikube><jaeger>,1,218,3,0.0,0,"<p>I am new to jaeger and I am facing issues with finding the services list in the jaeger UI.</p>&#xA;&#xA;<p>Below are the .yaml configurations I prepared to run jaeger with my spring boot app on Kubernetes using minikube locally.</p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/production-elasticsearch/elasticsearch.yml --namespace=kube-system</code></p>&#xA;&#xA;<p><code>kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/jaeger-production-template.yml --namespace=kube-system</code></p>&#xA;&#xA;<p>Created deployment for my spring boot app and jaeger agent to run on the same container</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;    name: tax-app-deployment&#xA;spec:&#xA;    template:&#xA;      metadata:&#xA;        labels:&#xA;          app: tax-app&#xA;          version: latest&#xA;      spec:&#xA;        containers:&#xA;        - image: tax-app&#xA;          name: tax-app&#xA;          imagePullPolicy: IfNotPresent&#xA;          ports:&#xA;          - containerPort: 8080&#xA;        - image: jaegertracing/jaeger-agent&#xA;          imagePullPolicy: IfNotPresent&#xA;          name: jaeger-agent&#xA;          ports:&#xA;          - containerPort: 5775&#xA;            protocol: UDP&#xA;          - containerPort: 5778&#xA;          - containerPort: 6831&#xA;            protocol: UDP&#xA;          - containerPort: 6832&#xA;            protocol: UDP&#xA;          command:&#xA;          - ""/go/bin/agent-linux""&#xA;          - ""--collector.host-port=jaeger-collector.jaeger-infra.svc:14267""&#xA;</code></pre>&#xA;&#xA;<p>And the spring boot app service yaml</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: tax&#xA;  labels:&#xA;    app: tax-app&#xA;    jaeger-infra: tax-service&#xA;spec:&#xA;  ports:&#xA;  - name: tax-port&#xA;    port: 8080&#xA;    protocol: TCP&#xA;    targetPort: 8080&#xA;  clusterIP: None&#xA;  selector:&#xA;    jaeger-infra: jaeger-tax&#xA;</code></pre>&#xA;&#xA;<p>I am getting </p>&#xA;&#xA;<blockquote>&#xA;  <p>No service dependencies found</p>&#xA;</blockquote>&#xA;"
42332938,What is the difference between Service Fabric Applications and Services,2017-02-19 21:12:26,<azure><microservices><azure-service-fabric>,3,387,2,0.0,0,<p>What is the reasoning behind Applications concept in Service Fabric? What is the recommended relation between Applications and Services? In which scenarios do Applications prove useful?</p>&#xA;
48440783,Is it possible to have 2 different services with the same application name?,2018-01-25 10:35:36,<spring><microservices><netflix-eureka><netflix-zuul>,1,40,3,0.0,0,"<p>Let's say I have a service named ""FooService"" running in a docker container and a second service named ""BarService"" running in a second docker container. Both services register with Eureka (running in another docker container). Is it possible to have the same application name for both services? E.g. <a href=""http://localhost/myservice/foo"" rel=""nofollow noreferrer"">http://localhost/myservice/foo</a> should call the FooService and <a href=""http://localhost/myservice/bar"" rel=""nofollow noreferrer"">http://localhost/myservice/bar</a> should call the BarService. Development environment is Spring Boot and the services are implemented as Spring RestControllers. Just put ""spring.application.name=myservice"" in both bootstrap.properties files and then put @RequestMapping(""${spring.application.name}"") in the RestController will not work, of course. But is it somehow possible to register the services with a unique identifier and still call them with a common URL path?</p>&#xA;"
48493849,Should API and message consumer be in the same microservice?,2018-01-29 03:11:48,<apache-kafka><microservices><distributed-system>,1,96,4,1.0,0,"<p>My team is torn with how we should architect our microservices with using a message bus.</p>&#xA;&#xA;<p>We currently have an API Gateway with many microservices behind it all communicating over http.</p>&#xA;&#xA;<p>After looking into implementing Message Buses (Kafka) the team is torn on whether the consumer and API should live in the same service or if they should be two separate services.</p>&#xA;&#xA;<p>Some think they should be separate as they have different scaling concerns, while others think they should be in the same service since they are communicating with the same database and have the same domain concerns. IE) Not duplicating code between two services.</p>&#xA;&#xA;<p>What are your thoughts?</p>&#xA;"
46131443,"java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing with microservices",2017-09-09 13:55:44,<java><microservices>,4,4903,0,0.0,0,"<p>I am new to the microservices + Spring Boot combinations and getting the below error while running the code from the link: <a href=""https://github.com/sqshq/PiggyMetrics"" rel=""nofollow noreferrer"">https://github.com/sqshq/PiggyMetrics</a> . Please guide me what is the nissue ?</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89) ~[spring-cloud-context-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1191) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1180) [spring-boot-1.3.5.RELEASE.jar:1.3.5.RELEASE]&#xA;    at com.piggymetrics.statistics.StatisticsApplication.main(StatisticsApplication.java:34) [classes/:na]&#xA;Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://config:8888/statistics-service/default"": config; nested exception is java.net.UnknownHostException: config&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    ... 7 common frames omitted&#xA;Caused by: java.net.UnknownHostException: config&#xA;    at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.PlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.SocksSocketImpl.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.NetworkClient.doConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.openServer(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.&lt;init&gt;(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.http.HttpClient.New(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(Unknown Source) ~[na:1.8.0_144]&#xA;    at sun.net.www.protocol.http.HttpURLConnection.connect(Unknown Source) ~[na:1.8.0_144]&#xA;    at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:80) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:93) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$BasicAuthorizationInterceptor.intercept(ConfigServicePropertySourceLocator.java:179) ~[spring-cloud-config-client-1.1.0.RELEASE.jar:1.1.0.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:85) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:69) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:596) ~[spring-web-4.2.6.RELEASE.jar:4.2.6.RELEASE]&#xA;    ... 11 common frames omitted&#xA;&#xA;2017-09-09 19:19:34.861  INFO 4968 --- [           main] .b.l.ClasspathLoggingApplicationListener : Application failed to start with classpath: [file:/C:/Learnings/micro-services/PiggyMetrics/statistics-service/target/classes/, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-security/1.3.5.RELEASE/spring-boot-starter-security-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter/1.3.5.RELEASE/spring-boot-starter-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot/1.3.5.RELEASE/spring-boot-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.3.5.RELEASE/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-aop/4.2.6.RELEASE/spring-aop-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-config/4.0.4.RELEASE/spring-security-config-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-web/4.0.4.RELEASE/spring-security-web-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-expression/4.2.6.RELEASE/spring-expression-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-config/1.1.0.RELEASE/spring-cloud-starter-config-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter/1.1.0.RELEASE/spring-cloud-starter-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-context/1.1.0.RELEASE/spring-cloud-context-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-rsa/1.0.1.RELEASE/spring-security-rsa-1.0.1.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.47/bcpkix-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.47/bcprov-jdk15on-1.47.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-config-client/1.1.0.RELEASE/spring-cloud-config-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.6/jackson-annotations-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.6/jackson-databind-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.6/jackson-core-2.6.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/oauth/spring-security-oauth2/2.0.9.RELEASE/spring-security-oauth2-2.0.9.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-beans/4.2.6.RELEASE/spring-beans-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-core/4.2.6.RELEASE/spring-core-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-context/4.2.6.RELEASE/spring-context-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-webmvc/4.2.6.RELEASE/spring-webmvc-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-core/4.0.4.RELEASE/spring-security-core-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.3.5.RELEASE/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.3.5.RELEASE/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.0.33/tomcat-embed-core-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.0.33/tomcat-embed-el-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-logging-juli/8.0.33/tomcat-embed-logging-juli-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.0.33/tomcat-embed-websocket-8.0.33.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-validation/1.3.5.RELEASE/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/hibernate/hibernate-validator/5.2.4.Final/hibernate-validator-5.2.4.Final.jar, file:/C:/Users/pashtikar/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/org/jboss/logging/jboss-logging/3.3.0.Final/jboss-logging-3.3.0.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/fasterxml/classmate/1.1.0/classmate-1.1.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-web/4.2.6.RELEASE/spring-web-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-feign/1.1.0.RELEASE/spring-cloud-starter-feign-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-core/1.1.0.RELEASE/spring-cloud-netflix-core-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-commons/1.1.0.RELEASE/spring-cloud-commons-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/security/spring-security-crypto/4.0.4.RELEASE/spring-security-crypto-4.0.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-core/8.16.2/feign-core-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/jvnet/animal-sniffer-annotation/1.0/animal-sniffer-annotation-1.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-slf4j/8.16.2/feign-slf4j-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/feign/feign-hystrix/8.16.2/feign-hystrix-8.16.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-ribbon/1.1.0.RELEASE/spring-cloud-starter-ribbon-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon/2.1.5/ribbon-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-transport/2.1.5/ribbon-transport-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-contexts/0.4.9/rxnetty-contexts-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty-servo/0.4.9/rxnetty-servo-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxnetty/0.4.9/rxnetty-0.4.9.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec-http/4.0.27.Final/netty-codec-http-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-codec/4.0.27.Final/netty-codec-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-handler/4.0.27.Final/netty-handler-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport-native-epoll/4.0.27.Final/netty-transport-native-epoll-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-common/4.0.27.Final/netty-common-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-buffer/4.0.27.Final/netty-buffer-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/io/netty/netty-transport/4.0.27.Final/netty-transport-4.0.27.Final.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-core/2.1.5/ribbon-core-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-httpclient/2.1.5/ribbon-httpclient-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-commons-util/0.1.1/netflix-commons-util-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-loadbalancer/2.1.5/ribbon-loadbalancer-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-statistics/0.1.1/netflix-statistics-0.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/io/reactivex/rxjava/1.1.5/rxjava-1.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-archaius/1.1.0.RELEASE/spring-cloud-starter-archaius-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/archaius/archaius-core/0.7.4/archaius-core-0.7.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/commons-configuration/commons-configuration/1.8/commons-configuration-1.8.jar, file:/C:/Users/pashtikar/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-eureka/1.1.0.RELEASE/spring-cloud-starter-eureka-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-eureka-client/1.1.0.RELEASE/spring-cloud-netflix-eureka-client-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-client/1.4.6/eureka-client-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/jettison/jettison/1.3.7/jettison-1.3.7.jar, file:/C:/Users/pashtikar/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/netflix-commons/netflix-eventbus/0.3.0/netflix-eventbus-0.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-core/0.10.1/servo-core-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/servo/servo-internal/0.10.1/servo-internal-0.10.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-core/1.19.1/jersey-core-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/jersey-client/1.19.1/jersey-client-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/com/sun/jersey/contribs/jersey-apache-client4/1.19.1/jersey-apache-client4-1.19.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-api/1.12.10/governator-api-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/eureka/eureka-core/1.4.6/eureka-core-1.4.6.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-core/1.10.30/aws-java-sdk-core-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-ec2/1.10.30/aws-java-sdk-ec2-1.10.30.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-autoscaling/1.9.3/aws-java-sdk-autoscaling-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-sts/1.9.3/aws-java-sdk-sts-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/amazonaws/aws-java-sdk-route53/1.9.3/aws-java-sdk-route53-1.9.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator/1.12.10/governator-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/governator/governator-core/1.12.10/governator-core-1.12.10.jar, file:/C:/Users/pashtikar/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/woodstox-core-asl/4.4.1/woodstox-core-asl-4.4.1.jar, file:/C:/Users/pashtikar/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar, file:/C:/Users/pashtikar/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/ribbon/ribbon-eureka/2.1.5/ribbon-eureka-2.1.5.jar, file:/C:/Users/pashtikar/.m2/repository/com/thoughtworks/xstream/xstream/1.4.2/xstream-1.4.2.jar, file:/C:/Users/pashtikar/.m2/repository/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar, file:/C:/Users/pashtikar/.m2/repository/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-data-mongodb/1.3.5.RELEASE/spring-boot-starter-data-mongodb-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/mongodb/mongo-java-driver/2.13.3/mongo-java-driver-2.13.3.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-mongodb/1.8.4.RELEASE/spring-data-mongodb-1.8.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tx/4.2.6.RELEASE/spring-tx-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/data/spring-data-commons/1.11.4.RELEASE/spring-data-commons-1.11.4.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.21/jcl-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/1.3.5.RELEASE/spring-boot-starter-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-actuator/1.3.5.RELEASE/spring-boot-actuator-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-bus-amqp/1.1.0.RELEASE/spring-cloud-starter-bus-amqp-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-starter-stream-rabbit/1.0.0.RELEASE/spring-cloud-starter-stream-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-binder-rabbit/1.0.0.RELEASE/spring-cloud-stream-binder-rabbit-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream-codec/1.0.0.RELEASE/spring-cloud-stream-codec-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-amqp/1.3.5.RELEASE/spring-boot-starter-amqp-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-rabbit/1.5.6.RELEASE/spring-rabbit-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/amqp/spring-amqp/1.5.6.RELEASE/spring-amqp-1.5.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/http-client/1.0.0.RELEASE/http-client-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/rabbitmq/amqp-client/3.5.7/amqp-client-3.5.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-amqp/4.2.5.RELEASE/spring-integration-amqp-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-jmx/4.2.5.RELEASE/spring-integration-jmx-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-bus/1.1.0.RELEASE/spring-cloud-bus-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-core/4.2.5.RELEASE/spring-integration-core-4.2.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-netflix-hystrix-stream/1.1.0.RELEASE/spring-cloud-netflix-hystrix-stream-1.1.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.3.5.RELEASE/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-classic/1.1.7/logback-classic-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/ch/qos/logback/logback-core/1.1.7/logback-core-1.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/jul-to-slf4j/1.7.21/jul-to-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.21/log4j-over-slf4j-1.7.21.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/cloud/spring-cloud-stream/1.0.0.RELEASE/spring-cloud-stream-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-messaging/4.2.6.RELEASE/spring-messaging-4.2.6.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/spring-tuple/1.0.0.RELEASE/spring-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar, file:/C:/Users/pashtikar/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/integration/spring-integration-tuple/1.0.0.RELEASE/spring-integration-tuple-1.0.0.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/org/springframework/retry/spring-retry/1.1.2.RELEASE/spring-retry-1.1.2.RELEASE.jar, file:/C:/Users/pashtikar/.m2/repository/com/netflix/hystrix/hystrix-core/1.5.2/hystrix-core-1.5.2.jar, file:/C:/Users/pashtikar/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.7/HdrHistogram-2.1.7.jar, file:/C:/Users/pashtikar/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/C:/Users/pashtikar/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/C:/Users/pashtikar/.m2/repository/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar]&#xA;</code></pre>&#xA;"
48699742,How to handle user authentication with microservices in AWS?,2018-02-09 06:10:16,<node.js><amazon-web-services><authentication><microservices>,3,374,0,0.0,0,"<p>I'm reading a tutorial provided by AWS explaining how to break up a monolithic NodeJS application into a microservice architectured one.</p>&#xA;&#xA;<p><a href=""https://aws.amazon.com/getting-started/container-microservices-tutorial/"" rel=""nofollow noreferrer"">Here is a link to it.</a></p>&#xA;&#xA;<p>One important piece is missing from <a href=""https://github.com/awslabs/amazon-ecs-nodejs-microservices/tree/master/3-microservices"" rel=""nofollow noreferrer"">the simple application example they've provided</a> and that is <strong>user authentication</strong>.</p>&#xA;&#xA;<p>My question is, where does authentication fit into all this? &#xA;How do you allow users to authenticate to all these services separately? </p>&#xA;&#xA;<p>I am specifically looking for an answer that <strong>does not</strong> involve AWS Cogntio. I would like to have my own service perform user authentication/management.</p>&#xA;"
48810786,is putting sqs-consumer to detect receiveMessage event in sqs scalable,2018-02-15 15:30:43,<microservices><amazon-sqs>,1,78,3,0.0,0,"<p>I am using aws sqs as message queue. After <code>sqs.sendMessage</code> sends the data , I want to detect <code>sqs.receiveMessage</code> via either infinite loop or event triggering in scalable way. Then I came accross <a href=""https://www.npmjs.com/package/sqs-consumer"" rel=""nofollow noreferrer"">sqs-consumer</a> &#xA;to handle <code>sqs.receiveMessage</code> events, the moment it receives the messages. But I was wondering , is it the most suitable way to handle message passing between microservices or is there any other better way to handle this thing?</p>&#xA;"
41188108,How to enable automatic routing in Netflix/Zuul and Netflix/Ribbon with discovery information from Netflix/Eureka Service?,2016-12-16 15:58:41,<java><spring-boot><microservices><netflix-zuul><netflix-eureka>,2,847,0,0.0,0,"<p>I'm quite new in things with the netflix cloud Microservice architecture.</p>&#xA;&#xA;<p>There are three Microservices running in my Network:</p>&#xA;&#xA;<ul>&#xA;<li><p>Zuul/Ribbon Service: localhost:8765</p>&#xA;&#xA;<p><code>Application.yml:&#xA;  ===============&#xA;  eureka:&#xA;   client:&#xA;    serviceUrl:&#xA;     defaultZone: http://localhost:8761/eureka/</code></p></li>&#xA;<li><p>Eureka Service: localhost:8761</p></li>&#xA;<li>RentCarService: localhost:8888</li>&#xA;</ul>&#xA;&#xA;<p>Now, my request is: <strong>localhost:8765/RentCarService/getAllAvailableCars</strong></p>&#xA;&#xA;<p>This request should automatically routed forward to the right Microservice (RentCarService with Port 8888) like <strong>localhost:8888/getAllAvailableCars</strong></p>&#xA;&#xA;<p>I have seen much tutorials and the most of them are forwarding the requests programmatically like in this tutorial:</p>&#xA;&#xA;<p><a href=""http://www.disasterarea.co.uk/blog/microservice-discovery-with-spring-boot-and-eureka/"" rel=""nofollow noreferrer"">Microservice discovery with spring boot and eureka</a></p>&#xA;&#xA;<p><a href=""https://github.com/callistaenterprise/blog-microservices/blob/B1/microservices/composite/product-composite-service/src/main/java/se/callista/microservices/composite/product/service/Util.java"" rel=""nofollow noreferrer"">Or here by a method called getServiceURL</a></p>&#xA;&#xA;<p>Do i have to code the forwarding by my own or is <strong>this possible automatically by Ribbon</strong>?</p>&#xA;&#xA;<p>Beste regards&#xA;lars</p>&#xA;"
41027573,Ansible playbook to find particular java process and kill,2016-12-07 21:20:12,<java><jar><find><ansible><microservices>,1,1195,0,0.0,0,"<p>I'm working on deploying microservices with ansible-playbook right now. And all of the microservices uses <code>java -jar</code> command to deploy. Right now I'm trying to write an ansible playbook to find and kill dependent java -jar process before deploying other one.</p>&#xA;&#xA;<p>I'm running out of ideas here. I was thinking of creating a script in init.d for java deamon. But, if i do that and stop service, it would stop all the java processes which i wouldn't want. </p>&#xA;&#xA;<p><strong>Output for</strong> <code>ps -ef | grep java</code></p>&#xA;&#xA;<blockquote>&#xA;  <p><strong>root</strong>     28330     1  1 13:52 ?        00:00:56 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config /opt/app/microservices/deploy/dal-core/enrollment-vehicle-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29143     1  2 14:22 ?        00:00:49 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-vehicle-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     29879     1  2 14:23 ?        00:00:48 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/dal-core/config  /opt/app/microservices/deploy/dal-core/enrollment-account-dal-core-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p><strong>root</strong>     31093     1  3 14:28 ?        00:01:04 <em>java -jar -DCONFIG_FOLDER=/opt/app/microservices/deploy/listener/config  /opt/app/microservices/deploy/listener/enrollment-account-listener-0.0.1-SNAPSHOT.jar</em></p>&#xA;  &#xA;  <p>asadmin  31208 18879  0 14:57 pts/1    00:00:00 grep --color=auto java</p>&#xA;</blockquote>&#xA;&#xA;<p>In the above scenario, If i happen do deploy enrollment-account-dal-core again, I should 1st kill enrollment-account-listener (pid:31093) and then enrollment-account-dal-core (pid:29879).</p>&#xA;&#xA;<p>I have one playbook for all of the microservices so I won't be able to hard code it either.</p>&#xA;"
41123857,How to publish an event in the microservice world?,2016-12-13 14:44:03,<amazon-web-services><events><microservices><grpc>,1,149,3,0.0,0,"<p>There are many books and blogs detailing how event-based communication between microservices is easier to maintain than services calling eachother directly. </p>&#xA;&#xA;<p>However how would this be implemented in the AWS world? I was considering Topics, but it is far from ideal.</p>&#xA;&#xA;<p>How is this patter usually implemented to give guarantees on latency, durability, guaranteed delivery, idempotency etc.</p>&#xA;"
45855433,Microservices Config and eureka service which one to start first?,2017-08-24 07:27:40,<spring-boot><intellij-idea><microservices><netflix-eureka><netflix>,1,577,4,0.0,0,"<p>I am creating a simple project in microservices using spring boot and netflix OSS to get my hands dirty. I have created two services</p>&#xA;&#xA;<ol>&#xA;<li>config service which has to register itself in discovery(eureka)&#xA;service. </li>&#xA;<li>discovery service which requires config service to be running to get its configuration.</li>&#xA;</ol>&#xA;&#xA;<p>Now when I am starting these services, both services fails due to inter dependency. What are the best practices resolve this issue and which one to start first.</p>&#xA;&#xA;<p>PS:- I know I am creating circular dependency, But what is the way to deal with situation like this where I want to keep eureka configuration also with the config server</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
45996858,Self-contained microservices with Docker,2017-09-01 09:14:22,<docker><docker-compose><microservices>,1,92,5,0.0,0,"<p>I'm trying to setup a project built up of several microservices orchestrated with Docker. Here is the simplified schema of my project:</p>&#xA;&#xA;<pre><code>- Main-project&#xA;  - Dockerfile&#xA;  - docker-compose.yml (bundles Microservice1 and Microservice2)&#xA;&#xA;- Microservice1&#xA;  - Dockerfile&#xA;&#xA;- Microservice2&#xA;  - Dockerfile&#xA;</code></pre>&#xA;&#xA;<p>Now, each component has many dependencies such as RabbitMQ managed by the docker-compose.yml file. I manage to make the whole project run on Docker by using the compose file.</p>&#xA;&#xA;<p>However, I'm having problems in running the individual components by itself. The problem is that Microservice1 depends on rabbitMQ but it does not have a compose file to manage this dependency, and the same goes for all other components. So when I try to run any individual component by itself (for unit-tests, for instances) I have a problem of missing dependencies.</p>&#xA;&#xA;<p>Should I add all the dependencies also on the Dockerfile of each component? &#xA;Should I have one docker-compose file per component?&#xA;What are the best practices to setup a system like this?</p>&#xA;&#xA;<p>Thanks a lot!</p>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>As an important note, I forgot to mention that each microservice has its own repo.</p>&#xA;"
40436389,using entity in other jhipster microservice,2016-11-05 08:53:23,<jhipster><microservices>,2,673,0,0.0,0,"<p>I have problem to use entities between Microservices ,I have microservice1 has Team entity I need to use Team entity in microservice2 ,I mean I need to import TeamRepository.java in microservice2,How can do that with jhipster?</p>&#xA;"
41783283,RabbitMQ embedded broker is not starting from spring boot application,2017-01-21 19:02:28,<java><spring-boot><microservices><spring-rabbitmq><embedded-server>,1,1037,0,0.0,0,"<p>I am unable to send message in ""CustomerQ"" queue of rabbitmq broker. I have configured rabbitmq broker as embedded server through spring boot.</p>&#xA;&#xA;<pre><code> package com.testlab.chapter2;&#xA;&#xA;  import org.springframework.amqp.core.Queue;&#xA;  import org.springframework.amqp.rabbit.core.RabbitMessagingTemplate;&#xA;  import org.springframework.beans.factory.annotation.Autowired;&#xA;  import org.springframework.context.annotation.Bean;&#xA;  import org.springframework.context.annotation.Lazy;&#xA;  import org.springframework.stereotype.Component;&#xA;&#xA;&#xA;&#xA;  @Component &#xA;  @Lazy&#xA; class Sender {&#xA;&#xA;  RabbitMessagingTemplate template;&#xA;&#xA;  @Autowired&#xA;  Sender(RabbitMessagingTemplate template){&#xA;    this.template = template;&#xA;  }&#xA;&#xA;  @Bean&#xA;  Queue queue() {&#xA;    return new Queue(""CustomerQ"", false);&#xA;   }&#xA;&#xA;   public void send(String message){&#xA;    System.out.println(template.getRabbitTemplate().getConnectionFactory());&#xA;&#xA;    template.convertAndSend(""CustomerQ"", message);&#xA;    }&#xA;  }&#xA;&#xA; **application.properties file configuration:**&#xA;&#xA;  spring.rabbitmq.host=localhost&#xA;  spring.rabbitmq.port=5672&#xA;  spring.rabbitmq.username=guest&#xA;  spring.rabbitmq.password=guest&#xA;</code></pre>&#xA;&#xA;<p>I am getting below error when code is trying to connect/put any message in queue&#xA;<strong>Error:</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.messaging.MessagingException: java.net.ConnectException: Connection refused: connect; nested exception is org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused: connect] with root cause</p>&#xA;  &#xA;  <p>java.net.ConnectException: Connection refused: connect&#xA;      at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_25]&#xA;      at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:345) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_25]&#xA;      at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_25]&#xA;      at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_25]&#xA;      at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_25]&#xA;      at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_25]</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate your help on this.</p>&#xA;"
41783704,How can we route a request to every pod under a kubernetes service on Openshift?,2017-01-21 19:42:36,<kubernetes><microservices><restful-architecture><application-design><openshift-enterprise>,1,307,3,0.0,0,"<p>We are building a Jboss BRMS application with <em>two microservices in spring-boot</em>, one for <strong>rule generation (SRV1)</strong> and one for <strong>rule execution (SRV2)</strong>.&#xA;The idea is to <strong><em>generate the rules</em></strong> using the generation microservice (SRV1) and <strong><em>persist them in the database with versioning</em></strong>. The next part of the process is having the execution microservice <strong><em>load these persisted rules into each pods memory</em></strong> by querying the information from the shared database.</p>&#xA;&#xA;<p>There are two following scenarios when this should happen :</p>&#xA;&#xA;<blockquote>&#xA;  <ul>&#xA;  <li><p>When the rule execution service pod/pods <strong>starts up</strong>, it queries the db for the lastest version and every pod running the execution application loads those rules from the shared db.</p></li>&#xA;  <li><p>The second senario is we <strong>manually</strong> want to trigger the loading of a <strong>specific version</strong> of rules on every pod running the execution application preferably via a rest call.</p></li>&#xA;  </ul>&#xA;</blockquote>&#xA;&#xA;<p><strong><em>Which is where the problem lies!</em></strong> </p>&#xA;&#xA;<p>Whenever we try and issue a rest request to the api, since it is load balanced under a kubernetes service, the request hits only one of the pods and the rest of them do not load the specific rules.</p>&#xA;&#xA;<p>Is there a programatic or design change that may help us achieve that or is there any other way we construct our application to achieve a capability to load a certain version of rules on all pods serving the execution microservice.</p>&#xA;"
42395345,Service fabric reliable collections data loss after service upgrade,2017-02-22 15:13:29,<.net><azure><microservices><azure-service-fabric><service-fabric-stateful>,1,395,0,2.0,0,"<p>Why reliable collections is empty after micro-service upgrade and not invoking event OnDataLossAsync to restore state from external backup?</p>&#xA;&#xA;<p>We have large scale system based on stateful services</p>&#xA;&#xA;<pre><code>&lt;StatefulServiceType ServiceTypeName=""UserServiceType"" HasPersistedState=""true"" /&gt;&#xA;</code></pre>&#xA;&#xA;<p>HasPersistedState is set as true, and data replicated across replicas, in case of VM failure data still valid and recovering with OnDataLossAsync but after upgrade collections is empty.</p>&#xA;&#xA;<p>I have tried all upgrade options (remove, keep, auto ugrade) application, result the same - collections is empty.</p>&#xA;&#xA;<p>For now we decided to replicate data to blob storage and recover it after service update which is not perfect solution, data recovery takes a few minutes and it makes some service unavailable/inconsistent for that time.</p>&#xA;&#xA;<p>So we are looking for solution that allows to save data after upgrade.</p>&#xA;"
42458964,logback settings and spring config-server,2017-02-25 17:03:42,<java><spring><spring-boot><cloud><microservices>,1,1272,0,0.0,0,"<p>There are many of microservices, all of them should write logs to  the same graylog server. In every of microservices is used a GelfLogbackAppender which has several settings like host, post and etc. These setting are the same for all of services and i want to store them in one place like a spring config-server. How can i do that? How can i get and use GELF_ADDRESS from config-server?</p>&#xA;&#xA;<pre><code>&lt;appender name=""gelf"" class=""biz.paluch.logging.gelf.logback.GelfLogbackAppender""&gt;&#xA;    &lt;host&gt;udp:${GELF_ADDRESS}&lt;/host&gt;&#xA;    &lt;port&gt;${GELF_PORT}&lt;/port&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>UPDATE</strong> I've decided to show simple example what i want to, let's imagine i want to change log level for all microservices through config-server. i make next things:</p>&#xA;&#xA;<p><strong>logback-spring.xml</strong></p>&#xA;&#xA;<pre><code>&lt;configuration&gt;&#xA;    &lt;property name=""LEVEL"" value=""${log_level}""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/defaults.xml""/&gt;&#xA;    &lt;include resource=""org/springframework/boot/logging/logback/console-appender.xml""/&gt;&#xA;    &lt;root level=""${LEVEL}""&gt;&#xA;         &lt;appender-ref ref=""CONSOLE""/&gt;&#xA;    &lt;/root&gt;&#xA;&lt;/configuration&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>application.yml</strong> is being in config-server</p>&#xA;&#xA;<pre><code>eureka:&#xA;  client:....&#xA;feign:&#xA;  hystrix:....&#xA;log_level: info&#xA;</code></pre>&#xA;&#xA;<p>it doesn't work, i always see DEBUG level, if i write</p>&#xA;&#xA;<pre><code>&lt;property name=""LEVEL"" value=""info""/&gt; &#xA;</code></pre>&#xA;&#xA;<p>manualy into  logback-spring.xml, the level will be changed, but i want to do that through central config-serverer</p>&#xA;"
42611968,"I have multiple flask microservices that all communicate with each other, how would I configure docker?",2017-03-05 18:02:18,<python><docker><flask><dockerfile><microservices>,1,480,6,0.0,0,<p>I have multiple flask microservices (this is obviously obfuscated to protect IP)</p>&#xA;&#xA;<pre><code>├── README.md&#xA;├── api_starter.py&#xA;├── app_api.py&#xA;├── service1&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service1.py&#xA;├── service2&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   ├── service2.py&#xA;├── dags&#xA;│   ├── airflow_pipeline_runner.py&#xA;├── service3&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   ├── service3.py&#xA;├── service4&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service4.py&#xA;├── service5&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service5.py&#xA;├── service6&#xA;│   ├── __init__.py&#xA;│   ├── api.py&#xA;│   └── service6.py&#xA;├── requirements.txt&#xA;└── service7&#xA;    ├── __init__.py&#xA;    ├── api.py&#xA;    └── service7.py&#xA;</code></pre>&#xA;&#xA;<p>Each one of these microservices are being run by the api_starter. Each of these microservices communicate with each other. What's the best way to dockerize this application? Do I give each microservice a docker file and then have a docker-compose.yml in the root of the directory? Each of these microservices communicate with each other. Any and all </p>&#xA;
39622142,resilient microservices design pattern,2016-09-21 16:42:31,<reactive-programming><microservices><resiliency>,2,154,0,2.0,0,"<p>in reactive programming Resilience is achieved by replication, containment, isolation and delegation.</p>&#xA;&#xA;<p>two of the famous design patterns are Bulkheads with supervisor and circuit breaks. are these only for reaching isolation and containment?</p>&#xA;&#xA;<p>what are the most famous design patterns for microservices and specially the ones give resiliency?  </p>&#xA;"
47178056,Spring boot Kubernetes Service Discovery,2017-11-08 11:04:17,<spring><spring-boot><kubernetes><microservices>,1,844,3,1.0,0,"<p>I am running into issues with Kubernetes Service Discovery on Spring Boot applications. </p>&#xA;&#xA;<p>I should be able to discover the services whether my spring boot application is running within or out of Kubernetes cluster. Our local development won't be on k8s cluster.</p>&#xA;&#xA;<p>I am using Service Discovery via DNS. I tried using <a href=""https://github.com/spring-cloud-incubator/spring-cloud-kubernetes"" rel=""nofollow noreferrer"">spring-cloud-starter-kubernetes</a></p>&#xA;&#xA;<pre><code>    &lt;dependency&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-kubernetes&lt;/artifactId&gt;&#xA;        &lt;version&gt;0.2.0.RELEASE&lt;/version&gt;&#xA;    &lt;/dependency&gt;&#xA;</code></pre>&#xA;&#xA;<p>As per documentation you should be able to autowire DiscoveryClient and good to go</p>&#xA;&#xA;<pre><code>@Autowire&#xA;private DiscoveryClient discoveryClient;&#xA;</code></pre>&#xA;&#xA;<p>DiscoveryClient is part of spring-cloud-commons. spring-cloud-starter-kuberenetes doesn't have it. </p>&#xA;&#xA;<p>Anyone solved similar problem using the same library or a different one? Please share the solution</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
37864255,Security between microservices,2016-06-16 16:07:44,<spring-security><microservices><spring-cloud-feign><spring-cloud-security>,2,1835,3,0.0,0,"<p>I have two microservices, for example, A and B. The microservice B has the rest enpoint that must be accessible only from the microservice A.&#xA;How can I limit access between microservices? What is the best practice if at all possible?</p>&#xA;&#xA;<p>I'm using spring cloud security (oauth2, jwt).</p>&#xA;"
50270206,Linking Microservices to test/dev/prod environments with ingress,2018-05-10 09:55:58,<kubernetes><microservices><kubernetes-ingress>,1,47,3,0.0,0,"<p>Let's consider we have three environments:</p>&#xA;&#xA;<ul>&#xA;<li><code>test.website.com</code></li>&#xA;<li><code>dev.website.com</code></li>&#xA;<li><code>prod.website.com</code></li>&#xA;</ul>&#xA;&#xA;<p>Each of the environment consists of the following microservices: webapp, service1, service2. I want to be able to easily call all the services from JS frontend without having to deal with domains. It would be great if I could just call <code>/services/service1/</code> and the fact I am on the same domain would keep me in the same environment.</p>&#xA;&#xA;<p>So let's consider dev environment:</p>&#xA;&#xA;<ul>&#xA;<li><code>dev.website.com/</code> -> goes to webapp</li>&#xA;<li><code>dev.website.com/services/service1/</code> -> goes to service1</li>&#xA;<li><code>dev.website.com/services/service1/</code> ...</li>&#xA;</ul>&#xA;&#xA;<p>To be able to do that, I configured ingress as follows:</p>&#xA;&#xA;<pre><code>    - path: /services/service1/*&#xA;      backend:&#xA;        serviceName: service1&#xA;        servicePort: 8080&#xA;    - path: /services/service2/*&#xA;      backend:&#xA;        serviceName: service2&#xA;        servicePort: 8080&#xA;    - path: /*&#xA;      backend:&#xA;        serviceName: webapp&#xA;        servicePort: 8080&#xA;</code></pre>&#xA;&#xA;<p>This would work great, but it doesn't.</p>&#xA;&#xA;<ol>&#xA;<li>First issue is that the <code>service1</code> receives full path (<code>/services/service1</code>) instead of just <code>/</code> when being called. For that I found this: <code>ingress.kubernetes.io/rewrite-target: /</code> - But I also foudn that this feature is not implemented, which is contradictory and doesn't make much sense.</li>&#xA;<li>Second problem is that, the order of the services is not followed and call on <code>/services/service1/</code> ends up in <code>webapp</code>.</li>&#xA;</ol>&#xA;&#xA;<p>Is this even a good approach? What is the best practice to do this?</p>&#xA;&#xA;<p><strong>Edit</strong>:</p>&#xA;&#xA;<p>According to suggestions I removed <code>*</code> from the path, which helped, but also removed necessary functionality. I need to be able to use:</p>&#xA;&#xA;<ul>&#xA;<li><code>/en/</code> -> <code>webapp</code></li>&#xA;<li><code>/services/service1/method1</code> -> <code>service1</code></li>&#xA;</ul>&#xA;&#xA;<p>This doesn't work without the <code>*</code> in path.</p>&#xA;"
43700905,Microservices - how to find DNS IP?,2017-04-29 22:05:26,<dns><microservices><service-discovery>,4,266,0,0.0,0,<p>In the world of microservices endpoints should not (must not) be hardcoded. One of the best ways to do this is to have a DNS and let each microservice register while starting. By doing this whenever microservice A wants to communicate with microservice B it just asks DNS for endpoints where B currently listens.</p>&#xA;&#xA;<p>What I do not understand is: <strong>How microservices know where the DNS lives?</strong></p>&#xA;&#xA;<p>Basically DNS is just a 'special' service and I can have one or multiple instances of it right? So I should not hardcode it's endpoint too or should I? And let's say I do - what if DNS instnace is moved to different location? Do I have to manually change it's location in configuration?</p>&#xA;&#xA;<p>Does anyone happen to know how to design this? (or can anyone just point me to any document where this is explained since although there are many information about microservices and dns I can not find this particular information anywhere - maybe it's just too trivial and I am the only one who does not get it)</p>&#xA;
43567411,PACT: java-maven,2017-04-23 04:32:40,<maven><microservices><pact><pact-java>,1,785,0,1.0,0,"<p>I need few answer for my doubt:</p>&#xA;&#xA;<ol>&#xA;<li>Pact-mock-service Vs pact-jvm-server, is both are same? Pls describe this.</li>&#xA;<li>Am implementing the PACT in java-maven</li>&#xA;</ol>&#xA;&#xA;<p>I can able to run this:</p>&#xA;&#xA;<p><a href=""https://github.com/anha1/microservices-pact-maven"" rel=""nofollow noreferrer"">https://github.com/anha1/microservices-pact-maven</a></p>&#xA;&#xA;<p><a href=""https://github.com/warmuuh/pactbroker-maven-plugin"" rel=""nofollow noreferrer"">https://github.com/warmuuh/pactbroker-maven-plugin</a></p>&#xA;&#xA;<p>Help me to understand this with pact-mock-service and pact-jvm-server</p>&#xA;"
43753039,Openshift Container Platform V3.X vs. Fabric8,2017-05-03 06:49:48,<containers><openshift><kubernetes><microservices><fabric8>,1,660,0,0.0,0,"<p>I took a look at Fabric8 Microservices Platform and searched for some alternatives for comprehension. I found Red Hats Openshift Container Platform, which seems to be the same as Fabric8, but not Open-Source. &#xA;I tried to figure out what are the major benefits of Red Hats solution.&#xA;I am already on the Openstack. </p>&#xA;"
43607751,How to create SPARK/Flink Stream Data Processing as a Microservice (REST API),2017-04-25 10:11:30,<apache-spark><playframework-2.0><microservices><apache-flink><lagom>,1,224,0,2.0,0,"<p>I am creating streaming analytics application using Spark, Flink &amp; Kafka. Each analytics/functionality will implement as a Microservice so that this analytics can able to use in the different project later.</p>&#xA;&#xA;<p>I run my Spark/Flink job perfectly in Simple Scala application and submit this job over Spark &amp; Flink cluster respectively. But I have to start/run this job when REST POST startJob() request invoke to my web service.</p>&#xA;&#xA;<p>How can I integrate my Spark &amp; Flink data processing functionality in a web service oriented application? </p>&#xA;&#xA;<p>Till now I tried <a href=""http://www.lagomframework.com/"" rel=""nofollow noreferrer"">Lagom Microservice</a> but i found so many issues you can check </p>&#xA;&#xA;<ol>&#xA;<li><a href=""https://stackoverflow.com/questions/43255302/best-approach-to-ingest-streaming-data-in-lagom-microservice"">Best approach to ingest Streaming Data in Lagom Microservice&#xA;</a></li>&#xA;<li><a href=""https://stackoverflow.com/questions/43570899/java-io-notserializableexception-using-apache-flink-with-lagom"">java.io.NotSerializableException using Apache Flink with&#xA;Lagom</a></li>&#xA;</ol>&#xA;&#xA;<p>I think i am not taking the right direction for Stream Processing Microservice Application. Looking for right direction to implement this analytics over REST Service.</p>&#xA;"
43689879,How does one pass user context between an API and a microservice?,2017-04-28 22:50:00,<rest><microservices><azure-service-fabric>,2,412,3,1.0,0,"<p>I am trying to setup audit logging and we were wanting the log event to happen as close to the action as possible, while also knowing which user performed the action. This means we need to pipe in the user info.  What are best practices for this?</p>&#xA;"
45579511,A/B testing. Routing Clients in a gateway API,2017-08-08 23:34:40,<microservices><ab-testing><api-gateway><canary-deployment>,3,760,0,0.0,0,"<p>I am working on a new project that will be based on microservices. It's an internal app and only about 10 microservices. We will be using a gateway API for authentication and possibly some microservice aggregation. (Probably Netflix zuul with Spring Boot)</p>&#xA;&#xA;<p>What I'm not clear on is how we do the routing for A/B testing and Canary testing. Lets assume I have 100 clients and we want to A/B test a new version of a microservice. The client app needs no changes, it's just internal changes to the function that the microservice provides.</p>&#xA;&#xA;<p>I understand we would stand up a new microservice which is (say) v2. What I'm puzzled on is how do I direct (say) clients 1-10 to the new version. We need to be able to configure this centrally and not change anything on the client.</p>&#xA;&#xA;<p>We know their mac addresses (as well as other identifying attributes) and can insert any kind of header we want to identify their messages.</p>&#xA;&#xA;<p>So how would I direct these to v2 of the API for the A/B test or Canary deployment?</p>&#xA;"
45325062,Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams?,2017-07-26 11:03:53,<jvm><microservices><datacontract><pact>,3,117,1,1.0,0,<p>Is Contract testing necessary when both consumer and provider are developed by the same company in different scrum teams ?</p>&#xA;
51855075,Django microservices within Docker,2018-08-15 08:08:19,<django><docker><nginx><docker-compose><microservices>,3,44,0,0.0,0,"<p>I have the following <code>docker-compose.yml</code>:</p>&#xA;&#xA;<pre><code>version: '3.6'&#xA;&#xA;services:&#xA;  db:&#xA;    image: postgres:10.4&#xA;    volumes:&#xA;      - postgres_data:/var/lib/postgresql/data/&#xA;  cache:&#xA;    image: redis:4.0.10&#xA;    volumes:&#xA;      - redis_data:/data&#xA;  web:&#xA;    build: .&#xA;    image: dockerdjangoexample&#xA;    command: bash -c ""gunicorn demosite.wsgi:application -b 0.0.0.0:8000""&#xA;    volumes:&#xA;      - .:/code&#xA;    depends_on:&#xA;      - db&#xA;      - cache&#xA;  nginx:&#xA;    image: nginx:1.15.2-alpine&#xA;    ports:&#xA;      - ""8000:8000""&#xA;    volumes:&#xA;      - ./docker-config/nginx:/etc/nginx/conf.d&#xA;    depends_on:&#xA;      - web&#xA;&#xA;volumes:&#xA;  postgres_data:&#xA;  redis_data:&#xA;</code></pre>&#xA;&#xA;<p>The <code>Dockerfile</code> is:</p>&#xA;&#xA;<pre><code>FROM python:3.6.5&#xA;&#xA;ENV PYTHONDONTWRITEBYTECODE 1&#xA;ENV PYTHONUNBUFFERED 1&#xA;&#xA;WORKDIR /code&#xA;COPY . /code/&#xA;&#xA;RUN pip install --upgrade pip&#xA;RUN pip install pipenv&#xA;RUN pipenv install --deploy --system --skip-lock --dev&#xA;</code></pre>&#xA;&#xA;<p>The <code>Nginx</code> config file is:</p>&#xA;&#xA;<pre><code>upstream web {&#xA;  ip_hash;&#xA;  server web:8000;&#xA;}&#xA;&#xA;server {&#xA;  location / {&#xA;         proxy_pass http://web/;&#xA;  }&#xA;  listen 8000;&#xA;  server_name localhost;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>This all works perfectly. What im trying to figure out now is how I can add a second <code>Django</code> app into the mix so I can create a microservice environment.</p>&#xA;&#xA;<p>For example, the existing web app from above would be an API that handles user registration / sign in etc. I would like to add another <code>Django</code> API into the mix that would do something else and would also use its own database.</p>&#xA;&#xA;<p>If this were to theoretically ever be put into a production environment, then the first API would be used through urls starting with <code>www.demosite.com/api/users</code> and the second API could be used through urls starting with <code>www.demosite.com/api/widgets</code>.</p>&#xA;&#xA;<p>Im not sure how to accomplish this from a <code>Docker</code> and <code>Nginx</code> perspective.</p>&#xA;&#xA;<p>Also, if im doing anything completely wrong so far, please correct me as I am new to this.</p>&#xA;"
51781316,Unable to login through gateway jhipster 4.9.0 microservice architechture,2018-08-10 07:33:01,<java><microservices><jhipster><jhipster-registry>,1,33,4,0.0,0,"<p>I've generated microservice application through jHipster 4.9.0.&#xA;My UAA server is running on port 9999 and gateway on 8080 these microservices are connected through jHipster registry. When I try to log in through the gateway <strong>it's giving me 404 for /auth/login</strong> although gateway has this endpoint in AuthResource.java file.&#xA;I have just generated these microservices and trying to log in but unfortunately, I'm unable to log in. Please guide me if there is something wrong I do not want to use the latest version of jHipster. JHipster registry version is 3.3. war download from github. It would be great if you can help me in any way. Thanks in advance. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/LzYgn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LzYgn.png"" alt=""enter image description here""></a></p>&#xA;"
51911797,How to manage microservices that are live,2018-08-18 19:12:13,<java><spring><spring-boot><microservices>,3,68,5,0.0,0,"<p>I have been testing out microservices lately using springboot to create microservice projects. The more i understand about the setup the more questions i am confronted with. </p>&#xA;&#xA;<ol>&#xA;<li>How are all the microservices that are running, managed? How do developers manage, deploy or update microservices via a central location?</li>&#xA;<li>When deploying multiple instances of a microservice, do you leave the port to be decided during runtime, or should it be predefined?</li>&#xA;</ol>&#xA;&#xA;<p>I am sure there will be much more questions popping up later.&#xA;Links used:</p>&#xA;&#xA;<ul>&#xA;<li><a href=""http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started"" rel=""nofollow noreferrer"">http://www.springboottutorial.com/creating-microservices-with-spring-boot-part-1-getting-started</a></li>&#xA;<li><a href=""https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/"" rel=""nofollow noreferrer"">https://fernandoabcampos.wordpress.com/2016/02/04/microservice-architecture-step-by-step-tutorial/</a></li>&#xA;</ul>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
40733857,Using Nginx as micro service API gateway,2016-11-22 04:37:08,<node.js><nginx><docker><kubernetes><microservices>,2,674,7,0.0,0,"<p>We are splitting our monolith API into micro services.</p>&#xA;&#xA;<p>We do not need rate-limiting, auth, caching or any other gateway like abilities. </p>&#xA;&#xA;<p>Would it be a valid approach to use very simple stateless Nginx containers that route to the underlying services?</p>&#xA;"
46660853,How to run micro services using docker,2017-10-10 07:25:37,<docker><spring-boot><cassandra><docker-compose><microservices>,3,216,1,1.0,0,"<p>Am newbie to Spring boot. I need to create micro services and need to run by docker. I have attached my project structure here. Problem which is every time i need to up the micro services manually. For example am having 4 micro services and i just up this services manually. But all micro services should be started itself when deploying into docker. How to achieve this. <a href=""https://i.stack.imgur.com/QZFMw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QZFMw.png"" alt=""Project Structure""></a></p>&#xA;&#xA;<p>Also am using Cassandra database.</p>&#xA;"
27489124,Connecting two Node/Express apps with streaming JSON,2014-12-15 16:58:01,<node.js><rest><stream><microservices>,1,311,1,2.0,1,"<p>I currently have two apps running...</p>&#xA;&#xA;<p>One is my REST API layer that provides a number of services to the frontend. &#xA;The other is a 'translation app', it can be fed a JSON object (over http POST call) , perform some data translation and mappings on that object and return it to the REST layer </p>&#xA;&#xA;<p>My situation is I want to do this for a large number of objects. The flow i want is: </p>&#xA;&#xA;<p><strong><em>User requests 100,000 objects in a specific format -> REST layer retrieves that from the database -> passes each JSON data object to&#xA;translation service to perform formatting -> pass each one back to the&#xA; REST layer -> REST layer returns new objects to the user.</em></strong></p>&#xA;&#xA;<p>What I don't want to do is call tranlate.example.com/translate on 100,000 different calls, or pass megabytes of data through 1 single huge POST request. </p>&#xA;&#xA;<p>So the obvious answer is streaming data to the translate app, and then streaming data back. </p>&#xA;&#xA;<p>There seems to be a lot of solutions to stream data across apps: open a websocket (socket.io) , open a raw TCP connection between the two, or since the HTTP request and response data of Node is actually a stream I could utilize that then emit a JSON object when its successfully translated</p>&#xA;&#xA;<p>My question is Is there a best practice here to stream data between two apps? It seems I should use http(req, res) stream and keep a long-lived connection open to preserve the 'REST' model. Any samples that could be provided would be great. </p>&#xA;"
27470721,How can I avoid duplication of business logic when batch processing?,2014-12-14 15:19:48,<java><batch-processing><spring-batch><microservices>,2,626,0,0.0,1,"<p>I have a web application dedicated to batch processing (batch service here on out, api driven) and I have the main web application that is dedicated to everything else. I've been struggling with making a decision on what the best way is to avoid duplication of business logic in the batch service. Both applications are clustered. The separation for batch processing has been okay for simple jobs, but I have more complex jobs where it would just cause chaos if the business logic were duplicated. Here's my use case for the purposes of this question.</p>&#xA;&#xA;<ol>&#xA;<li>Customer schedules a cron job for user updates.</li>&#xA;<li>Batch service is given a CSV file with 20,000 user records.</li>&#xA;<li>The batch service rips through the file performing validation on the records, basically a dry run.</li>&#xA;<li>The batch service will check the allowable change and error thresholds (percentages are counts)</li>&#xA;<li>If validation thresholds pass, the batch service will begin creating/updating users.</li>&#xA;<li>When users are created or updated, there are a number of modules/features that need to know about these events.</li>&#xA;<li>Job progress is tracked and customer can view progress, logs, and status of job.</li>&#xA;</ol>&#xA;&#xA;<p>Here are a few solutions I have been thinking about:</p>&#xA;&#xA;<ul>&#xA;<li>Jar up the business logic and share it across the two applications. This wouldn't necessarily be easy because the main application is a Grails application and it's got GORM littered throughout.</li>&#xA;<li>Have the batch service hit APIs on the main application for the create and updates and possibly the more complex validation scenarios. Worried about the toll this would take on tomcat, but calls would be going through the load balancer so they would be distributed.</li>&#xA;<li>Have the batch service hit APIs on the main application for validation, then queue create/update requests and let the main application retrieve them. Same as above, queue would help reduce http calls. Also would need a queue to report status back to batch service.</li>&#xA;<li>Duplicate some logic by having batch service do it's own validation and inserts/updates, but then fire a user created event or user updated event so modules/features in the main app can deal with the changes.</li>&#xA;<li>Embed the batch processing service into the main application</li>&#xA;</ul>&#xA;&#xA;<p>Other details:</p>&#xA;&#xA;<ul>&#xA;<li>The batch service and web application are both clustered</li>&#xA;<li>Both are running on AWS, so I have tools like SQS and SNS easily accessible</li>&#xA;<li>Java 1.7 applications</li>&#xA;<li>Tomcat containers</li>&#xA;<li>Main application is Grails</li>&#xA;<li>Batch service uses Spring Batch and Quartz at it's core</li>&#xA;</ul>&#xA;&#xA;<p>So my question is what are accepted ways to avoid duplication of business logic based on the details above? Can/Should the architecture be changed to better accommodate this?</p>&#xA;&#xA;<p>Another idea to consider is what would this look like and a ""microservices"" architecture. That word has been tossed around a number of times in the office and we have been considering the idea of breaking up the main web application into services. So for example, we may end up with a service for user management.</p>&#xA;"
34180115,How to register service in Consul without address declaration,2015-12-09 13:33:02,<java><microservices><service-discovery><consul>,1,1620,2,0.0,1,"<p>Using Consul, I want a service to register itself with the Consul Agent, using the HTTP endpoint <code>/v1/agent/service/register</code>. The only problem is that the service may bind to different IP addresses (1st instance 10.0.0.1, 2nd 10.0.0.2, etc) and I want Consul to set the address automatically basing on the IP address of the request.</p>&#xA;&#xA;<p>For example,</p>&#xA;&#xA;<p>""Service instance 1 (10.0.0.1)"" sends <code>{name:'svs', id:'svs-01'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-01', Address: 10.0.0.1}</code></p>&#xA;&#xA;<p>""Service instance 2 (10.0.0.2)"" sends <code>{name:'svs', id:'svs-02'}</code> to <code>/v1/agent/service/register</code> and Consul registers it as <code>{name:'svs', id:'svs-02', Address: 10.0.0.2}</code></p>&#xA;&#xA;<p>According to <a href=""https://consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow"" title=""Consul Agent Service Documentation"">Consul Agent Service Documentation</a> if the Address field is missing in service register query, the Address will default to that of the agent if not provided. But it is not what I need.</p>&#xA;&#xA;<p>I've tried to detect service's ip address at runtime but it may have several network interfaces and it's hard to distinguish them.</p>&#xA;"
31404820,Service locator - why not use DNS?,2015-07-14 11:04:07,<dns><soa><microservices>,3,144,1,0.0,1,"<p>There are a lot of applications that can take role of Service Locator in distributed environment AKA SOA. For example, Zookeeper and Consul. Why not use DNS instead?</p>&#xA;&#xA;<ul>&#xA;<li>Standard, well-known, stable</li>&#xA;<li>Distributed, fault-tolerant</li>&#xA;<li>Can assign multiple IPs to the same name for load balancing in homogeneous clusters</li>&#xA;<li>Can serve additional metadata</li>&#xA;</ul>&#xA;&#xA;<p>So... why not?</p>&#xA;"
32945623,Load balancing in distributed system,2015-10-05 09:49:56,<soa><distributed><distributed-computing><microservices>,1,116,5,0.0,1,"<p>Given:</p>&#xA;&#xA;<ul>&#xA;<li>n producers and m consumers, n >> m</li>&#xA;<li>consumers make requests to producers for data</li>&#xA;<li>any producer can be used by only one consumer at a time i.e. consumer can work with multiple producers but producer must work with single consumer</li>&#xA;</ul>&#xA;&#xA;<p>Needed:</p>&#xA;&#xA;<ul>&#xA;<li>Consumers need to coordinate so every consumer can own subset of producers.</li>&#xA;<li>If consumer goes down, other consumers should take his producers.</li>&#xA;<li>Consumers should exchange producers to ensure equal load on consumers.</li>&#xA;</ul>&#xA;&#xA;<p>Question:</p>&#xA;&#xA;<p>Are there papers/algorithms/libraries for that case or should I invent another wheel?</p>&#xA;"
30915043,Setting up rabbitMQ on docker with python,2015-06-18 12:13:32,<python><docker><localhost><rabbitmq><microservices>,1,1325,0,1.0,1,"<p>I am fairly new to docker and I am learning about rabbitMQ. So far I have been able to run rabbitMQ, in the form of the python libary pika, on my ubuntu vm. This worked with no problems at all but I have now put it onto a small app in docker and does not work.</p>&#xA;&#xA;<p>The problem seems to be in the set up and it all ways fails this line of code:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>The Variables being imported:</p>&#xA;&#xA;<pre><code>USER = ""test""&#xA;PASS = ""testpass1""&#xA;HOST = ""dockerhost""&#xA;</code></pre>&#xA;&#xA;<p>The file:</p>&#xA;&#xA;<pre><code>import pika&#xA;from settings import USER, PASS, HOST&#xA;&#xA;def send(message):&#xA;&#xA;    message = str(message)&#xA;    print 'trying: credentials = pika.PlainCredentials(username=USER, password=PASS)'&#xA;    try:&#xA;        credentials = pika.PlainCredentials(username=USER, password=PASS)&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: credentials = pika.PlainCredentials(username=USER, password=PASS) \n' + str(Exception.message)&#xA;&#xA;    print 'trying: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials))'&#xA;    try:&#xA;        connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;            host=HOST, port=80, credentials=credentials))&#xA;    except Exception:&#xA;        print 'Failed'&#xA;        print str(Exception)&#xA;        return 'Failed on: connection = pika.BlockingConnection(pika.ConnectionParameters(host=HOST, port=80, credentials=credentials)) \n' + str(Exception.message)&#xA;&#xA;    channel = connection.channel()&#xA;&#xA;    channel.queue_declare(queue='hello')&#xA;&#xA;    channel.basic_publish(exchange='',&#xA;                      routing_key='hello',&#xA;                      body=message)&#xA;    connection.close()&#xA;&#xA;    return ""Message Sent""&#xA;</code></pre>&#xA;&#xA;<p>Within this code it always fails on the line:</p>&#xA;&#xA;<pre><code>connection = pika.BlockingConnection(pika.ConnectionParameters(&#xA;        host=HOST, port=80, credentials=credentials))&#xA;</code></pre>&#xA;&#xA;<p>And finally the Dockerfile:</p>&#xA;&#xA;<pre><code>FROM ubuntu&#xA;MAINTAINER Will Mayger&#xA;RUN echo ""deb http://archive.ubuntu.com/ubuntu/ $(lsb_release -sc) main universe"" &gt;&gt; /etc/apt/sources.list&#xA;RUN apt-get update&#xA;RUN apt-get install -y tar git curl nano wget dialog net-tools build-essential&#xA;RUN apt-get install -y python python-dev python-distribute python-pip&#xA;RUN git clone https://github.com/CanopyCloud/microservice-python&#xA;RUN pip install -r /microservice-python/requirements.txt&#xA;EXPOSE 80&#xA;WORKDIR /microservice-python/&#xA;CMD sudo rabbitmqctl add_user test testpass1&#xA;CMD sudo rabbitmqctl add_vhost myvhost&#xA;CMD sudo rabbitmqctl set_permissions -p myvhost test "".*"" "".*"" "".*""&#xA;CMD sudo rabbitmq-server&#xA;&#xA;CMD python /microservice-python/server.py&#xA;</code></pre>&#xA;&#xA;<p>For any additional information all the files are located on:&#xA;<a href=""https://github.com/CanopyCloud/microservice-python"" rel=""nofollow"">https://github.com/CanopyCloud/microservice-python</a></p>&#xA;"
33287495,Netflix OSS/ Spring cloud on Weblogic,2015-10-22 17:55:36,<oracle><weblogic><spring-cloud><microservices><netflix>,1,1177,3,0.0,1,"<p>We do currently have an infrastructure with Weblogic 11g, Java 6, Apache WL plugin and ZXTM. Our traffic flows as follows:</p>&#xA;&#xA;<pre><code>ZXTM &gt;&gt; Apache httpd (WL plugin) &gt;&gt; WL cluster &gt;&gt; Oracle DB (RAC)&#xA;</code></pre>&#xA;&#xA;<p>We want to start microservices and evaluating Netflix OSS/ Spring cloud. Are there any complexities having spring netflix cloud on Weblogic with the infrastructure explained above? Following are our findings.</p>&#xA;&#xA;<ol>&#xA;<li>Turbine needs Java 8, so we have to upgrade to Java 8.</li>&#xA;<li>WL 11g does not support Java 8, so WL needs be upgraded to 12.1.3.</li>&#xA;</ol>&#xA;&#xA;<p>And we are fine with above upgardes.</p>&#xA;&#xA;<ol>&#xA;<li>Along with WL upgrade, is orcale DB (currently 11g) upgrade required?</li>&#xA;<li>Any issues/ complexities with running Netflix cloud on Weblogic 12c?</li>&#xA;<li>Does WL 12c supports JDBC 4.1 and 4.2 and any dependency for Netflix OSS products on these JDBC versions?</li>&#xA;<li>How can Eureka and Ribbon be used along with WL cluster load balancing?</li>&#xA;<li>Is Apache WL plugin required anymore? at-least for session stikiness?</li>&#xA;</ol>&#xA;&#xA;<p>Appreciate if you could share your experience, thoughts.&#xA;(Doesn't matter if you do not answer all the queries above, please share what you know of :) )</p>&#xA;"
49176544,Hystrix and Turbine does not work with Spring boot 2 and Spring cloud Finchley.M8,2018-03-08 15:18:49,<spring-boot><microservices><spring-cloud><hystrix><turbine>,2,684,0,1.0,1,"<p>I tried turbine + hystrix  dashboard with Spring boot 2 and latest versions of Spring cloud, seems exist some problem and turbine could not get stream from reactive service. I just uploaded simple microservices to github</p>&#xA;&#xA;<p><a href=""https://github.com/armdev/reactive-spring-cloud"" rel=""nofollow noreferrer"">https://github.com/armdev/reactive-spring-cloud</a></p>&#xA;&#xA;<p>Exception like this:</p>&#xA;&#xA;<pre><code>com.netflix.turbine.monitor.instance.InstanceMonitor$MisconfiguredHostException: [{""timestamp"":""2018-03-08T17:22:05.809+0000"",""status"":404,""error"":""Not Found"",""message"":""No message available"",""path"":""/hystrix.stream""}]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.init(InstanceMonitor.java:318) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor.access$100(InstanceMonitor.java:103) ~[turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:235) [turbine-core-1.0.0.jar:na]&#xA;    at com.netflix.turbine.monitor.instance.InstanceMonitor$2.call(InstanceMonitor.java:229) [turbine-core-1.0.0.jar:na]&#xA;    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_101]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_101]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]&#xA;</code></pre>&#xA;&#xA;<p>Or broken PIPE.</p>&#xA;&#xA;<p>Any one tried full spring cloud stack with Spring webflux? Any suggestions?</p>&#xA;"
36948775,Managing data-store concurrency as microservices scale,2016-04-29 23:04:45,<concurrency><scalability><microservices><data-consistency>,1,979,2,0.0,1,"<p>I am still trying to find my way around micro-services. I have a fundamental question.</p>&#xA;&#xA;<p>In an enterprise scenario, micro-services would probably have to write to a persistent data-store - be it a RDBMS or some kind of NoSQL. In most cases the  persistent data-store is enterprise grade, but a single entity (ofcourse replicated and backed up).</p>&#xA;&#xA;<p>Now, let's consider the case of a single micro-service deployed to private/public cloud environment having it's own persistent data-store (say enterprise grade RDBMS). As I scale my micro-service, there will be multiple instances of the micro-service trying to read/write from the same data-store. A traditional data-store can probably be tuned to handle ~50-200 concurrent connections. How do I handle a situation when my microservices has to be scaled much beyond that?</p>&#xA;&#xA;<p>What are the best practices in such a scenario? Any patterns that can be used?</p>&#xA;"
36954140,How to create JAX-RS Sub Resources with WSO2 MSf4J,2016-04-30 11:13:24,<java><wso2><jax-rs><microservices><msf4j>,1,195,4,0.0,1,"<p>I have create a sample micro service using WSO2 MSF4J. But i can't access the sub resources (services). Following are my service classes. </p>&#xA;&#xA;<p>Message Resource - </p>&#xA;&#xA;<pre><code>@Path(""/messages"")&#xA;@Consumes(MediaType.APPLICATION_JSON) &#xA;@Produces(MediaType.APPLICATION_JSON) &#xA;public class MessageResource {&#xA;&#xA;    @Path(""/{messageId}/comments"")&#xA;    public CommentResource getCommentResource(){&#xA;&#xA;        System.out.println(""inside the getCommentResource method"");&#xA;        return new CommentResource();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Comment Resource - </p>&#xA;&#xA;<pre><code>@Path(""/"") &#xA;public class CommentResource {&#xA;&#xA;    @GET&#xA;    @Path(""/{commentId}"")&#xA;    public String test2(@PathParam(""messageId"") long messageId, @PathParam(""commentId"") long commentId){&#xA;&#xA;        System.out.println(""method to return comment Id : "" + commentId + "" for message : "" + messageId);&#xA;        return ""method to return comment Id : "" + commentId + "" for message : "" + messageId;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have used following URI to access this service.</p>&#xA;&#xA;<p>GET : <a href=""http://localhost:8080/messages/1/comments/5"" rel=""nofollow"">http://localhost:8080/messages/1/comments/5</a></p>&#xA;&#xA;<p>But i got following result to my REST client.</p>&#xA;&#xA;<pre><code>404 Not Found&#xA;&#xA;Problem accessing: /messages/1/comments/5. Reason: Not Found&#xA;</code></pre>&#xA;&#xA;<p>Please help to resolve this. </p>&#xA;"
40201069,Not able to connect mongodb with Rails container using Docker compose,2016-10-23 08:38:33,<ruby-on-rails><mongodb><docker><docker-compose><microservices>,1,984,3,1.0,1,"<p>Getting this error when inserting values in Model through rails console .</p>&#xA;&#xA;<blockquote>&#xA;  <p>""Mongo::Error::NoServerAvailable: No server is available matching&#xA;  preference: # using server_selection_timeout=30 and local_threshold=&#xA;  0.015 ""</p>&#xA;</blockquote>&#xA;&#xA;<p>Both containers are running fine, but Rails not able to connect mongodb .&#xA;I have only one Dockerfile.</p>&#xA;&#xA;<p>My docker-compose.yml file contents are:</p>&#xA;&#xA;<pre><code> version: '2'&#xA;&#xA;services:&#xA;  mongo:&#xA;    image: mongo:3.0&#xA;    command: mongod --smallfiles --quiet&#xA;    environment:&#xA;      - RAILS_ENV=production&#xA;      - RACK_ENV=production&#xA;    ports:&#xA;      - ""27017:27017""&#xA;&#xA;  app:&#xA;    depends_on:&#xA;      - 'mongo'&#xA;      # - 'redis'&#xA;    build: .&#xA;    ports:&#xA;      - '3000:3000'&#xA;    volumes:&#xA;      - '.:/app'&#xA;    command: rails s -b '0.0.0.0'&#xA;    env_file:&#xA;      - '.env'&#xA;&#xA;volumes:&#xA;  mongo:&#xA;</code></pre>&#xA;&#xA;<p>My Dockerfile :</p>&#xA;&#xA;<pre><code>FROM ruby:2.3.0&#xA;RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs&#xA;&#xA;ENV APP_HOME /app&#xA;&#xA;RUN mkdir $APP_HOME  &#xA;WORKDIR $APP_HOME&#xA;&#xA;&#xA;ADD Gemfile* $APP_HOME/ &#xA;RUN bundle install&#xA;&#xA;&#xA;ADD . $APP_HOME&#xA;</code></pre>&#xA;"
38989659,"Getting error using mvn spring-boot:run ""A child container fail to start""",2016-08-17 06:37:27,<spring-boot><microservices>,3,5088,2,0.0,1,"<p>If I am run using my spring tool suites, then it's working fine, but while running using command prompt <strong>mvn spring-boot:run</strong> I am getting these error:</p>&#xA;&#xA;<pre><code>8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) [na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_71]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;Caused by: java.lang.SecurityException: class ""javax.servlet.http.HttpSessionIdListener""'s signer information does not match signer information of other classes in the sa&#xA;ackage&#xA;        at java.lang.ClassLoader.checkCerts(ClassLoader.java:895) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.preDefineClass(ClassLoader.java:665) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.defineClass(ClassLoader.java:758) ~[na:1.8.0_71]&#xA;        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.access$100(URLClassLoader.java:73) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:368) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader$1.run(URLClassLoader.java:362) ~[na:1.8.0_71]&#xA;        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_71]&#xA;        at java.net.URLClassLoader.findClass(URLClassLoader.java:361) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_71]&#xA;        at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4752) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: ERROR ContainerBase - A child container failed during start&#xA;java.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_71]&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:916) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) [spring-boot-1.2.8.RELEASE.j&#xA;.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) [spring-boot-1.2.8.RELEASE.jar:1&#xA;.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) [spring-boot-1.2&#xA;ELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) [spring-boot-1.2.8.RELEASE.jar:1.2.8.&#xA;ASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) [spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RE&#xA;E]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_71]&#xA;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_71]&#xA;        ... 1 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:871) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 6 common frames omitted&#xA;8564: WARN  AnnotationConfigEmbeddedWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.&#xA;icationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to st&#xA;embedded Tomcat&#xA;8564: ERROR SpringApplication - Application startup failed&#xA;org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServlet&#xA;ainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.R&#xA;SE]&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23) [classes/:na]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_71]&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_71]&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_71]&#xA;        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_71]&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478) [spring-boot-maven-plugin-1.3.3.RELEASE.jar:1.3.3.RELEASE]&#xA;        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76) ~[spring-boot-1.2.8.RELEASE.jar:&#xA;8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159) ~[spring-boot-1.&#xA;RELEASE.jar:1.2.8.RELEASE]&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8&#xA;EASE]&#xA;        ... 13 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89) ~[spring-boot-1.2.8.RELEASE.&#xA;1.2.8.RELEASE]&#xA;        ... 18 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 20 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 22 common frames omitted&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;        ... 24 common frames omitted&#xA;[WARNING]&#xA;java.lang.reflect.InvocationTargetException&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;        at java.lang.reflect.Method.invoke(Method.java:497)&#xA;        at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;        at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.Embe&#xA;ServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:133)&#xA;        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:474)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118)&#xA;        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:970)&#xA;        at org.springframework.boot.SpringApplication.run(SpringApplication.java:959)&#xA;        at com.hm.msp.event.EventHubServer.main(EventHubServer.java:23)&#xA;        ... 6 more&#xA;Caused by: org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:99)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.&lt;init&gt;(TomcatEmbeddedServletContainer.java:76)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getTomcatEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.&#xA;:384)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainerFactory.getEmbeddedServletContainer(TomcatEmbeddedServletContainerFactory.java:1&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:159)&#xA;        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:130)&#xA;        ... 13 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardServer[-1]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.startup.Tomcat.start(Tomcat.java:344)&#xA;        at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.initialize(TomcatEmbeddedServletContainer.java:89)&#xA;        ... 18 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardService[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:769)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 20 more&#xA;Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat]]&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)&#xA;        at org.apache.catalina.core.StandardService.startInternal(StandardService.java:441)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 22 more&#xA;Caused by: org.apache.catalina.LifecycleException: A child container failed during start&#xA;        at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:924)&#xA;        at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262)&#xA;        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;        ... 24 more&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] BUILD FAILURE&#xA;[INFO] ------------------------------------------------------------------------&#xA;[INFO] Total time: 10.858 s&#xA;[INFO] Finished at: 2016-08-16T16:33:40+05:30&#xA;[INFO] Final Memory: 50M/521M&#xA;[INFO] ------------------------------------------------------------------------&#xA;[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project core.eventhub: An exception occurred while run&#xA;. null: InvocationTargetException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Un&#xA; to start embedded Tomcat: Failed to start component [StandardServer[-1]]: Failed to start component [StandardService[Tomcat]]: Failed to start component [StandardEngine[&#xA;at]]: A child container failed during start -&gt; [Help 1]&#xA;[ERROR]&#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR]&#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>This is the pom.xml I am using ,</p>&#xA;&#xA;<pre><code>&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;    &lt;groupId&gt;com.hm.msp.services&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;sample.springboot&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0.0&lt;/version&gt;&#xA;    &lt;packaging&gt;jar&lt;/packaging&gt;&#xA;    &lt;name&gt;sample-server&lt;/name&gt;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-cloud-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;Angel.SR6&lt;/version&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;start-class&gt;com.hm.msp.event.Main&lt;/start-class&gt;&#xA;        &lt;mstack.version&gt;2.0.1&lt;/mstack.version&gt;&#xA;        &lt;json-lib.version&gt;2.4&lt;/json-lib.version&gt;&#xA;        &lt;msp.blp.version&gt;0.2.0&lt;/msp.blp.version&gt;&#xA;        &lt;msp.collection.version&gt;2.0.1&lt;/msp.collection.version&gt;&#xA;        &lt;msp.bundle.version&gt;0.2.0&lt;/msp.bundle.version&gt;&#xA;        &lt;camel.version&gt;2.17.0&lt;/camel.version&gt;&#xA;        &lt;xbean-spring-version&gt;4.5&lt;/xbean-spring-version&gt;&#xA;        &lt;!--following activemq version has dependencies. If you upgrade activemq &#xA;            libs make sure to pick up the right version --&gt;&#xA;        &lt;activemq-version&gt;5.11.1&lt;/activemq-version&gt;&#xA;        &lt;activemq-pool-version&gt;5.7.0&lt;/activemq-pool-version&gt;&#xA;        &lt;logback-version&gt;1.1.3&lt;/logback-version&gt;&#xA;        &lt;storm.version&gt;0.10.0&lt;/storm.version&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;&#xA;            &lt;!-- &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt; --&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-context&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&#xA;            &lt;version&gt;2.5&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;commons-logging&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.2&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Testing starter --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;!-- Setup Spring Data JPA Repository support --&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;&#xA;        &lt;!-- Spring Cloud starter --&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;mysql&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&#xA;            &lt;version&gt;5.1.38&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;!-- Swagger dependency for mIDAS webservice --&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;io.swagger&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;swagger-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;1.5.8&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;storm-core&lt;/artifactId&gt;&#xA;            &lt;version&gt;${storm.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-spring-boot-starter&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;camel-kafka&lt;/artifactId&gt;&#xA;            &lt;version&gt;${camel.version}&lt;/version&gt;&#xA;            &lt;exclusions&gt;&#xA;                &lt;exclusion&gt;&#xA;                    &lt;artifactId&gt;netty&lt;/artifactId&gt;&#xA;                    &lt;groupId&gt;io.netty&lt;/groupId&gt;&#xA;                &lt;/exclusion&gt;&#xA;            &lt;/exclusions&gt;&#xA;        &lt;/dependency&#xA;    &lt;/dependencies&gt;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;finalName&gt;${project.name}&lt;/finalName&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;    &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;"
41431506,Zuul routing : One endpoint with multiple microservices,2017-01-02 18:14:51,<java><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1829,2,0.0,1,"<p>I would like to setup zuul and the underlying microservices in a way that all services will be under the '/gateway' context.</p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>Microservice 1 has : <a href=""http://localhost:8081/api/hello"" rel=""nofollow noreferrer"">http://localhost:8081/api/hello</a></p>&#xA;&#xA;<p>Microservice 2 has : <a href=""http://localhost:8082/api/bye"" rel=""nofollow noreferrer"">http://localhost:8082/api/bye</a></p>&#xA;&#xA;<p>I would want to be able to access the microservices via zuul as follows:</p>&#xA;&#xA;<p>Microservice 1 : <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice1/api/hello</p>&#xA;&#xA;<p>Microservice 2: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a><strong>gateway</strong>/microservice2/api/bye</p>&#xA;&#xA;<p>I have tried to set this up, although it seems the requests are not getting routed correctly.</p>&#xA;&#xA;<p>The reason I would like the front end to route all client side REST calls to server that begin with '/gateway' is that it provides simpler maintenance to the front end.</p>&#xA;&#xA;<p>My application.yml:</p>&#xA;&#xA;<pre><code>zuul:&#xA; prefix: /gateway&#xA;   routes:&#xA;     microservice1:&#xA;        path: /microservice1/**&#xA;        serviceId: microservice1&#xA;        strip-prefix: true&#xA;     microservice2:&#xA;        path: /microservice2/**&#xA;        serviceId: microservice2&#xA;        strip-prefix: true&#xA;</code></pre>&#xA;&#xA;<p>Thank you </p>&#xA;"
36129008,How to Send a Response Using Seneca and Express,2016-03-21 10:48:12,<node.js><express><microservices>,2,1982,0,1.0,1,"<p>I'm using Seneca to route API calls and express to serve my files.&#xA;The problem is I can't seem to find a way to send a response back to the client after getting my data from the API.&#xA;With express, I would just use <code>res.send</code>, but since I'm in the Seneca context I can't. Haven't found any reference to this issue in the documentation.</p>&#xA;&#xA;<pre><code>""use strict""; &#xA;const bodyParser  = require('body-parser');&#xA;const express = require('express');&#xA;const jsonp = require('jsonp-express');&#xA;const Promise = require('bluebird');&#xA;const path = require('path');&#xA;const seneca = require('seneca')();&#xA;const app = express();&#xA;&#xA;module.exports = (function server( options ) {   &#xA;&#xA;    seneca.add('role:api,cmd:getData', getData);&#xA;&#xA;    seneca.act('role:web',{use:{&#xA;        prefix: '/api',&#xA;        pin: {role:'api',cmd:'*'},&#xA;        map:{&#xA;            getData: {GET:true}          // explicitly accepting GETs&#xA;        }&#xA;     }});&#xA;&#xA;     app.use( seneca.export('web') )&#xA;&#xA;     app.use(express.static(path.join(__dirname, '../../dist/js')))&#xA;     app.use(express.static(path.join(__dirname, '../../dist/public')))&#xA;&#xA;     app.listen(3002, function () {&#xA;         console.log('listening on port 3002');&#xA;     });&#xA;&#xA;    function getData(arg, done){&#xA;        //Getting data from somewhere....&#xA;&#xA;        //Here I would like to send back a response to the client.            &#xA;     }&#xA; }())    &#xA;</code></pre>&#xA;"
35501600,How to config spring cloud oauth2 in docker container,2016-02-19 09:20:34,<spring><docker><spring-cloud><microservices><oauth2>,1,841,0,0.0,1,"<p>I met some problems with micro-spring-docker , i think maybe the sso token-url is not correct.</p>&#xA;&#xA;<p>The demo https://github.com/keryhu/micro-oauth2-docker</p>&#xA;&#xA;<p>In local computer , sso service and auth-service works fine .</p>&#xA;&#xA;<p>But not  in docker container , </p>&#xA;&#xA;<blockquote>&#xA;  <p>the problem is that redirecting to auth-server Timeout .</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>SSO(pc-gateway service) application.yml:</strong></p>&#xA;&#xA;<pre><code>security:&#xA;  user:&#xA;    password: none&#xA;  oauth2:&#xA;    client:&#xA;      accessTokenUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/token&#xA;      userAuthorizationUri: http://${AUTHSERVER_PORT_9999_TCP_ADDR:localhost}:9999/uaa/oauth/authorize&#xA;</code></pre>&#xA;&#xA;<p><strong>docker-compose.yml</strong></p>&#xA;&#xA;<pre><code>eureka:&#xA;  image: eureka:0.0.1-SNAPSHOT&#xA;  container_name: eureka&#xA;  hostname: eureka&#xA;  ports:&#xA;   - ""8761:8761""&#xA;&#xA;configserver:&#xA;  image: config-server:0.0.1-SNAPSHOT&#xA;  container_name: configserver&#xA;  hostname: configserver&#xA;  links:&#xA;    - eureka&#xA;  ports:&#xA;    - ""8888:8888""&#xA;&#xA;authserver:&#xA;  image: auth-server:0.0.1-SNAPSHOT&#xA;  container_name: authserver&#xA;  hostname: authserver&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;  ports:&#xA;    - ""9999:9999""&#xA;&#xA;pcgateway:&#xA;  image: pc-gateway:0.0.1-SNAPSHOT&#xA;  container_name: pcgateway&#xA;  hostname: pcgateway&#xA;  links:&#xA;    - eureka&#xA;    - configserver&#xA;    - authserver&#xA;  ports:&#xA;    - ""8080:8080""&#xA;</code></pre>&#xA;&#xA;<p>After starting in docker container :         </p>&#xA;&#xA;<p><a href=""http://192.168.99.100:8761/"" rel=""nofollow"">http://192.168.99.100:8761/</a> showing :</p>&#xA;&#xA;<pre><code>Instances currently registered with Eureka&#xA;Application   AMIs     Availability Zones   Status&#xA;AUTHSERVER   n/a(1)           (1)           UP (1) - authserver:authserver:9999&#xA;CONFIGSERVER n/a(1)           (1)           UP (1) - configserver:configserver:8888&#xA;PCGATEWAY    n/a(1)           (1)           UP (1) - pcgateway:pcgateway:8080&#xA;</code></pre>&#xA;&#xA;<p>But when open the auth page: <a href=""http://192.168.99.100:8080"" rel=""nofollow"">http://192.168.99.100:8080</a> </p>&#xA;&#xA;<p>It should be redirected to  auth-server login page , but it opened Timeout ， the Address Bar is: </p>&#xA;&#xA;<pre><code>http://172.17.0.4:9999/uaa/oauth/authorize?client_id=clientapp&amp;redirect_uri=http://192.168.99.100:8080/login&amp;response_type=code&amp;state=cdXhfg&#xA;</code></pre>&#xA;&#xA;<p>I don't know why , maybe the above sso tokenurl is not correct . How to resolve ?</p>&#xA;"
34637868,Mobile App with microservices (on Microsoft Azure service fabric),2016-01-06 16:25:43,<microservices><azure-service-fabric><azure-api-apps><azure-api-management><azure-mobile-services>,1,720,0,1.0,1,"<p>I am planning to build an enterprise grade mobile application that requires full offline capability. It would be used worldwide. For the backend application, I intend to realise it as microservices using Azure Service fabric. The backend application would be leveraged by both a web admin UI as well as by the above mobile app. For the mobile app, I intend to use Azure App service's the new mobile app service. This would provide me the capability to do offline data sync and also carry out the functions when network reachability is there.</p>&#xA;&#xA;<p>MobileApp --> Azure MobileApp service --> Azure API app service --> Azure Service Fabric (cluster of nodes hosting microservices). </p>&#xA;&#xA;<p>Following are some questions &amp; observations on which I require advice:</p>&#xA;&#xA;<ol>&#xA;<li><p>The reason I am putting in Azure API service in the middle is because I intend to do API management (I understand Azure has a separate API management offering - any pointers on how I can do true API management in the above architecture would be very helpful. Would API management replace API app service ? )</p></li>&#xA;<li><p>I intend to use Swagger generated code out of API app service, so that both the web admin UI layer and the Azure Mobile App service layer can leverage. Your thoughts ?</p></li>&#xA;<li><p>Here I am using 2 paradigms - App Service (for mobile &amp; API) and App Service fabric. I believe this is the only option given the fact that I have a mobile app requiring heavy duty offline feature.</p></li>&#xA;<li><p>Data Sync from mobile: How do you think I can sync data between Mobile App service and the microservice specific data stores ? Do I need to go via the APIs or I can easily do a data sync with the data stores of individual microservices. Your thoughts please ? </p></li>&#xA;</ol>&#xA;"
31141688,Deployment methods for docker based micro services architecture on AWS,2015-06-30 14:53:50,<amazon-web-services><docker><elastic-beanstalk><microservices><ec2-container-service>,1,371,1,2.0,1,"<p>I am working on a project using a microservices architecture.&#xA;Each service lives in its own docker container and has a separate git repository in order to ensure loose coupling.</p>&#xA;&#xA;<p>It is my understanding that AWS recently announced support for <a href=""http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_v2config.html"" rel=""nofollow"">Multi-Container Docker environments in ElasticBeanstalk</a>. This is great for development because I can launch all services with a single command and test everything locally on my laptop. Just like Docker Compose.</p>&#xA;&#xA;<p>However, it seems I only have the option to also deploy all services at once which I am afraid defies the initial purpose of having a micro services architecture.</p>&#xA;&#xA;<p>I would like to be able to deploy/version each service independently to AWS. What would be the best way to achieve that while keeping infrastructure management to a minimum?</p>&#xA;"
31161436,How to use Apache ZooKeeper with Spring Cloud service discovery and load balancing?,2015-07-01 12:32:33,<java><apache-zookeeper><spring-cloud><service-discovery><microservices>,1,969,2,2.0,1,"<p>I'm new to Apache ZooKeeper concept to implement the service discovery and load balancing with netflix ribbon client. I seen some examples in github (<a href=""https://github.com/spring-cloud/spring-cloud-zookeeper"" rel=""nofollow"">https://github.com/spring-cloud/spring-cloud-zookeeper</a> ). Could anyone help me to know how to set-up the ZooKeeper and service discovery implementation on app service instances. I'm very curious to know about this concept.</p>&#xA;&#xA;<p>Thanks in advance..,</p>&#xA;"
31088764,Design strategy for Microservices in .NET,2015-06-27 12:28:35,<microservices>,3,591,3,0.0,1,<p>What would be a good way for Microservices .NET to communicate with each other? Would a peer to peer communication be better (for performance) using NETMQ (port of ZeroMQ) or would it be better via a Bus (NServiceBus or  RhinoBus)?&#xA;Also would you break up your data access layer into microservices too?</p>&#xA;&#xA;<p>-Indu</p>&#xA;
44416904,Use KONG as API Gateway to GraphQL/REST services,2017-06-07 15:27:36,<microservices><graphql><kong>,2,1594,0,0.0,1,<p>I'm trying to understand if it's possible to use KONG as API Gateway to microservices implementing REST and/or GraphQL interfaces</p>&#xA;&#xA;<p>As API Gateway will expose a GraphQL API and will request to our microservices currently implemented in REST/GraphQL and grpc coming soon.</p>&#xA;
44301997,"Spring netflix eureka, zuul vs Spring cloud data flow",2017-06-01 08:10:23,<spring><microservices><spring-cloud-netflix><spring-cloud-stream>,2,1527,0,2.0,1,"<p>I am new to the microservice world. Would like to know when to use Spring eureka, zuul vs spring data flow. </p>&#xA;&#xA;<p>I am building a service which in turns will consume multiple granular services(aka micro service), aggregate all the data and returns aggregated data to the consumer. All the services will run in local intranet within company infrastructure. Also, I would like to load balance individual microservices.</p>&#xA;&#xA;<p>What should be the choice of technology for microservices deployment?</p>&#xA;&#xA;<p>I am using Spring 4.3, Spring boot, Rest, Spring data.</p>&#xA;"
44313956,Microservices: model sharing between bounded contexts,2017-06-01 17:42:16,<mean-stack><microservices><bounded-contexts>,2,217,4,2.0,1,"<p>I am currently building a microservices-based application developed with the mean stack and am running into several situations where I need to share models between bounded contexts.  </p>&#xA;&#xA;<p>As an example, I have a User service that handles the registration process as well as login(generate jwt), logout, etc.  I also have an File service which handles the uploading of profile pics and other images the user happens to upload.  Additionally, I have an Friends service that keeps track of the associations between members.  </p>&#xA;&#xA;<p>Currently, I am adding the guid of the user from the user table used by the User service as well as the first, middle and last name fields to the File table and the Friend table.  This way I can query for these fields whenever I need them in the other services(Friend and File) without needing to make any rest calls to get the information every time it is queried.  </p>&#xA;&#xA;<p>Here is the caveat: </p>&#xA;&#xA;<p>The downside seems to be that I have to, I chose seneca with rabbitmq, notify the File and Friend tables whenever a user updates their information from the User table.  </p>&#xA;&#xA;<p>1) Should I be worried about the services getting too chatty?</p>&#xA;&#xA;<p>2) Could this lead to any performance issues, if alot of updates take place over an hour, let's say?</p>&#xA;&#xA;<p>3) in trying to isolate boundaries, I just am not seeing another way of pulling this off.  What is the recommended approach to solving this issue and am I on the right track?</p>&#xA;"
33780962,Versioning services,2015-11-18 13:09:31,<microservices><azure-service-fabric>,1,308,0,2.0,1,"<p>We are trying to do Microservices with MS' ServiceFabric.</p>&#xA;&#xA;<p>The scenario:&#xA;We have a Service1 running version1 and getting ready to upgrade to v2.</p>&#xA;&#xA;<p>Three other services depend on the interface of Service1. We want to be able to release v2 of Service1, but keep v1 running until we have upgraded and tested the three services against v2.</p>&#xA;&#xA;<p>All the examples I have found, v2 replaces v1 immediately. Can this be configured? And is there a method to tell the service discovery mechanism that I rely on a specific version of a given service?</p>&#xA;"
41548676,Running Lagom in Production,2017-01-09 13:00:59,<java><akka><actor><microservices><lagom>,1,1214,0,1.0,1,"<p>I am working on setting up a Lagom application in production. I have tried contacting Lightbend for ConductR license but haven't heard back in ages. So, now I am looking for an alternative approach. I have multiple questions.</p>&#xA;&#xA;<p>Since the scale of the application is pretty small right now, I think using a static service locator works for me right now (open to other alternatives). Also, I am using MySQL as my event store instead of the default configuration of Cassandra (Reasons not relevant to this thread).</p>&#xA;&#xA;<p>To suppress Cassandra and Lagom's Service Locator, I have added the following lines to my build.sbt:</p>&#xA;&#xA;<pre><code>lagomCassandraEnabled in ThisBuild := false&#xA;</code></pre>&#xA;&#xA;<p>I have also added the following piece to my application.conf with service1-impl module.</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>For the dev environment, I have been able to successfully run my application using <code>sbt runAll</code> in a tmux session. With this configuration, there is no service locator running on the default 8000 port but I can individually hit service1 on 8080 port. (Not sure if this is the expected behaviour. Comments?)</p>&#xA;&#xA;<p>I ran <code>sbt dist</code> to create a zip file and then unzipped it and ran the executable in there. Interestingly, the zip was created within the service1-impl folder. So, if I have multiple modules (services?), will sbt dist create individual zip files for each of the service?</p>&#xA;&#xA;<p>When I run the executable created via <code>sbt dist</code>, it tries to connect to Cassandra and also launches a service locator and ignores the static service locator configuration that I added. Basically, looks like it ignores the lines I added to build.sbt. Anyone who can explain this?</p>&#xA;&#xA;<p>Lastly, if I were to have 2 services, service1 and service2, and 2 nodes in the cluster with node 1 running service1 and node 2 running both the services, how would my static service locator look like in the application.conf and since each of the service would have its own application.conf, would I have to copy the same configuration w.r.t. static service locator in all the application.confs?</p>&#xA;&#xA;<p>Would it be something like this?</p>&#xA;&#xA;<pre><code>lagom.services {&#xA;    service1 = ""http://0.0.0.0:8080""&#xA;    service1 = ""http://1.2.3.4:8080""&#xA;    service2 = ""http://1.2.3.4:8081""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Since each specific actor would be spawned on one of the nodes, how would it work with this service locator configuration?</p>&#xA;&#xA;<p>Also, I don't want to run this in a tmux session in production. What would be the best way to finally run this code in production?</p>&#xA;"
47077380,Spring Cloud Services - Eureka,2017-11-02 14:10:53,<angular><spring-boot><microservices><spring-cloud>,1,630,1,0.0,1,"<p>I am trying to learn microservices using spring and spring boot , and learning to deploy into cloud platform. I am planning to create a angular 2 front-end application which communicates with my deployed microservice. Now I just going through spring cloud services eureka, Zuul , circuit breakers etc. </p>&#xA;&#xA;<ol>&#xA;<li>When I reading I found that Eureka is using for service registry for finding services each other. Here My doubt is that , When I am communicating from my angular 2 http request, I need to use these service registering?? What cloud configuration I need to follow to make a ReST API to microservice?? I am totally getting confusing what i need to push my sample microservice to cloud,Since I am a beginner. Can anyone help me to clarify these doubts??</li>&#xA;</ol>&#xA;"
42002512,Running multiple instance microservice using spring cloud config,2017-02-02 12:39:10,<spring><spring-boot><microservices><spring-cloud-config>,2,1485,2,0.0,1,"<p>I am developing a <strong>microservice, using <a href=""https://projects.spring.io/spring-boot/"" rel=""nofollow noreferrer"">Spring Boot</a></strong>, that exposes REST Endpoint. </p>&#xA;&#xA;<p>To meet the scalability constrains, <strong>multiple instance of the [same] service</strong> will be deployed (basically scale up when needed and scale down when not needed). </p>&#xA;&#xA;<p>I am using the <strong><a href=""https://cloud.spring.io/spring-cloud-config/spring-cloud-config.html"" rel=""nofollow noreferrer"">Spring Cloud Config Server</a></strong> to supply the configuration (such as port to bound, and other configurations) to this service. </p>&#xA;&#xA;<p><strong>Since the service exposing REST api, How can configure the config server to supply a unique port to each instance of the microservice?</strong></p>&#xA;&#xA;<p>One possible solution could be, running the service in individual machine/VM or create a docker container and deploy the service. This could be my solution if there is no way to supply random port to the service from cloud config server.</p>&#xA;"
42653725,In which microservice should I store a liaison table,2017-03-07 16:45:01,<relational-database><relationship><microservices>,2,117,3,0.0,1,"<p>I'm splitting my zoo-management application into micro-services.&#xA;I have the following domain : animals, caretakers, cages </p>&#xA;&#xA;<p>I thinking about where I should store the relationships. </p>&#xA;&#xA;<p>For exemple a cage contain several animals :&#xA;Should I store the cage_animals table into the cages services database or into the animals database ?</p>&#xA;&#xA;<p>And several caretakers are attributed to several animals :&#xA;Should I store the caretakers_animals table into the caretakers service's database or into the animals service's database ?</p>&#xA;"
38460678,Architecture Microservices Jhipster,2016-07-19 13:57:51,<java><jwt><jhipster><microservices>,1,1781,0,0.0,1,"<p>I want to start an architecture with microservices of Jhipster but I have doubts.&#xA;I have 4 pieces.</p>&#xA;&#xA;<ul>&#xA;<li>""HR"" &lt;- front and backend application</li>&#xA;<li>""SELECTION"" &lt;- front and backend application</li>&#xA;<li>Validation &lt;- Only one database for all front</li>&#xA;<li>Customers &lt;- is shared between ""HR"" and ""SELECT"" back in front in microservice and ""HR"" and ""SELECT"".</li>&#xA;</ul>&#xA;&#xA;<p>Both applications must be validated against the same database (JWT).&#xA;Both applications must share a microservicio ""CUSTOMER"" which will have the backend, but the front will be in each of the two applications.</p>&#xA;&#xA;<ul>&#xA;<li>1 - ""HR"" It would be a gateway?</li>&#xA;<li>2 - ""SELECTION"" It would be a gateway?</li>&#xA;<li>3 - How to implement security that is both against the same database (JWT) validated</li>&#xA;<li>4 - ""CUSTOMER"" It would be a microservicio?</li>&#xA;</ul>&#xA;&#xA;<p>Sorry for my English.</p>&#xA;"
40010594,Consul deregister 'failing' services,2016-10-13 00:51:04,<microservices><mesos><mesosphere><consul><consul-template>,2,836,0,0.0,1,<p>I have consul running on Consul v0.5.2 version &amp; services running in Mesos. Services keep moving from 1 server to another.</p>&#xA;&#xA;<p>Is there way to deregister services in consul that are in 'failing' state? I am able to get the list of services in failing state using this curl</p>&#xA;&#xA;<pre><code>curl http://localhost:8500/v1/health/state/critical&#xA;</code></pre>&#xA;&#xA;<p>Issue that we are seeing is over a period of time in consul UI we have stale data &amp; making the whole UI unusable</p>&#xA;
39998701,throw new TypeError('app.use() requires middleware functions');,2016-10-12 12:31:23,<javascript><node.js><express><microservices><seneca>,1,302,5,0.0,1,"<p>I'm just trying to run sample codes from Developing Microservices with Node js, and it says:</p>&#xA;&#xA;<pre><code>var express = require('express')&#xA;var bodyParser = require('body-parser')&#xA;var cookieParser = require('cookie-parser')&#xA;var methodOverride = require('method-override')&#xA;var seneca = require('seneca')()&#xA;var argv = require('optimist').argv&#xA;var app = express()&#xA;var cors = require('cors')&#xA;var routes = require('./../routes/index')&#xA;let path = require('path')&#xA;var webpack = require('webpack')&#xA;var webpackMiddleware = require('webpack-dev-middleware')&#xA;var config = require('./../webpack.config.js')&#xA;&#xA;var compiler = webpack(config)&#xA;&#xA;var conf = {&#xA;   port: argv.p || 7770&#xA;}&#xA;&#xA;app.engine('jsx', require('express-react-views').createEngine())&#xA;app.set('port', conf.port)&#xA;app.use(cors())&#xA;app.use('/public', express.static(path.join(__dirname,'./../public')))&#xA;app.use('/views', express.static(path.join(__dirname, './../views')))&#xA;app.use(webpackMiddleware(compiler));&#xA;app.use(cookieParser())&#xA;app.use(express.query())&#xA;app.use(bodyParser.urlencoded({extended: true}))&#xA;app.use(methodOverride())&#xA;app.use(bodyParser.json())&#xA;app.use(express.static('public'))&#xA;app.use(seneca.export('web'))  // Error line&#xA;&#xA;seneca.use('./../lib/registerAPI')&#xA;&#xA;app.use('/', routes)&#xA;&#xA;module.exports = app&#xA;</code></pre>&#xA;&#xA;<p>but Im getting an error that says:</p>&#xA;&#xA;<pre><code>/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177&#xA;     throw new TypeError('app.use() requires middleware functions');&#xA;     ^&#xA;TypeError: app.use() requires middleware functions &#xA;     at EventEmitter.use (/home/quocdinh/workspace/ECommerce/ass-ECommerce/node_modules/express/lib/application.js:177:11)&#xA;     at Object.&lt;anonymous&gt; (/home/quocdinh/workspace/ECommerce/ass-ECommerce/src/app.js:33:5) // --&gt; line: app.use(seneca.export('web'))&#xA;</code></pre>&#xA;&#xA;<p>I have tried to find solutions but ineffective.</p>&#xA;&#xA;<p>I tried adding</p>&#xA;&#xA;<pre><code> app.use(require('seneca-web'))&#xA;</code></pre>&#xA;&#xA;<p>but still not be</p>&#xA;&#xA;<p>I tried to lower the version of the node version that I have to 4.0 from 6.0, but still got the same error</p>&#xA;"
49659871,Java circuit breaker running in request thread,2018-04-04 20:28:50,<java><microservices><hystrix><circuit-breaker>,1,110,7,1.0,1,"<p>I have been considering Netflix OSS circuit breaker solution - Hystrix.</p>&#xA;&#xA;<p>Everything sounds good but I think that having the command run in a different thread does not make sense in my use case scenario. </p>&#xA;&#xA;<p>That is because the work done by my request handler requires very little computation before calling the remote service. Also, there is nothing I can do while waiting for the response.</p>&#xA;&#xA;<p>Example in Pseudo code:</p>&#xA;&#xA;<p>@post(""/token"")&#xA;token(@body authResult){&#xA;  Validate authResult&#xA;  Get id from authResult &#xA;  Call a remote service to get authz token&#xA;  Return authz token&#xA;}</p>&#xA;&#xA;<p>I would like to do the remote call using hystrix but I do not think it makes sense to execute the command in a separate thread since I would be blocked anyway. </p>&#xA;&#xA;<p>Any suggestions? Is it possible to run hystrix command in the same thread as the caller?</p>&#xA;"
38889466,How to run multiple Spring Boot application sharing same context?,2016-08-11 07:04:23,<spring><spring-security><spring-boot><microservices>,2,1676,0,1.0,1,"<p>I want to run multiple micro-services app sharing same context so that I can run my custom security filter for multiple spring boot(micro-services) app.</p>&#xA;&#xA;<p>Example: </p>&#xA;&#xA;<p>User services : <a href=""https://ip:port/myapp/user"">https://ip:port/myapp/user</a></p>&#xA;&#xA;<p>Product services : <a href=""https://ip:port/myapp/product"">https://ip:port/myapp/product</a></p>&#xA;&#xA;<p>Comment services : <a href=""https://ip:port/myapp/comment"">https://ip:port/myapp/comment</a></p>&#xA;&#xA;<p>And I should run  a common filter(Custom Security Filter) for all micro-services.</p>&#xA;"
38711908,How many database in a Microservices Event Driven architecture?,2016-08-02 04:42:50,<cqrs><microservices><event-sourcing><eventsource>,3,1161,4,1.0,1,"<p>I've read tons of documentation, blog posts and examples about CQRS with EventSource as a useful architecture in a Microservice system.</p>&#xA;&#xA;<p>A popular example is the banking transfer app:&#xA;<a href=""https://i.stack.imgur.com/zmxrc.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zmxrc.jpg"" alt=""banking transfer app""></a></p>&#xA;&#xA;<p>It's clear there are four microservices, but I don't understand becouse the ""command side"" microservices don't have their own database.</p>&#xA;&#xA;<p>By this image all Microservices are using the same eventStore database, that's should be against the microservice pattern?</p>&#xA;&#xA;<p>And how should be the EventStore db? Single table? One table for each service&#xA;?</p>&#xA;"
51282761,Microservices Scalable Deployment,2018-07-11 10:09:21,<spring-boot><google-cloud-platform><microservices><google-kubernetes-engine>,1,49,3,0.0,1,"<p>I have recently developed REST API. My project is developed with microservices using SpringBoot. I have used Zuul API Gateway and Eureka Discovery server in the project. I deployed it on a google kubernetes cluster. When I do a load test for the Rest API calls it shows me, it can handle only a few requests per second. &#xA;What I need to know is, how to autoscale the kubernetes pods for my services. What parameter should I look into? Ram usage or CPU usage or any other ???</p>&#xA;"
49302010,What are the benefits of splitting a big monolithic application into 2 applications?,2018-03-15 14:24:18,<java><web-services><java-ee><weblogic><microservices>,3,113,3,1.0,1,<p>We currently have a big monolithic J2EE application (weblogic / DB2).  It is a typical OLTP application.  We are considering to split this application into 2 applications where each application has its own database which is not directly accessible by the other application.  This also means that each application need to expose an interface for the functionality that is needed by the other application.</p>&#xA;&#xA;<p>So what are potentially the major benefits of splitting such an existing application into 2 applications ?</p>&#xA;
45095183,Low Level Protocol for Microservice Orchestration,2017-07-14 05:18:57,<rest><redis><network-programming><apache-zookeeper><microservices>,1,109,3,2.0,1,"<p>Recently I started working with Microservices, I wrote a library for service discovery using Redis to store every service's url and port number, along with a TTL value for the entry. It turned out to be an expensive approach since for every cross service call to any other service required one call to Redis. Caching didn't seem to be a good idea, since the services won't be up all the times, there can be possible downtimes as well.</p>&#xA;&#xA;<p>So I wanted to write a separate microservice which could take care of the orchestration part. For this I need to figure out a really low level network protocol to take care of the exchange of heartbeats(which would help me figure out if any of the service instance goes unavailable). How do applications like zookeeperClient, redisClient take care of heartbeats?</p>&#xA;&#xA;<p>Moreover what is the industry's preferred protocol for cross service calls? &#xA;I have been calling REST Api's over HTTP and eliminated every possibility of Joins across different collections.</p>&#xA;&#xA;<p>Is there a better way to do this?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
48942153,Do we really need Event Sourcing and CQRS in microservices?,2018-02-23 06:11:21,<microservices><cqrs><event-sourcing>,3,1173,0,1.0,1,"<p>In my understanding when database transactions span across microservices ,we can solve this problem with using message-broker(kafka,RabbitMQ etc) by publishing events so that Subscriber Microservices can update their database by listening to these events.</p>&#xA;&#xA;<p>In case of exception we can send event for failure ,so that Subscriber services can update their state.</p>&#xA;&#xA;<p>Is this not sufficient? What is the problem with this approach?</p>&#xA;&#xA;<p>why and when we need event sourcing?</p>&#xA;&#xA;<p>Do we need really event sourcing ?</p>&#xA;"
36715395,Clustering Microservices Components,2016-04-19 10:15:07,<cluster-computing><microservices>,1,10957,1,1.0,1,"<p>I have a Microservice that is realised as a Play framework based HTTP service. We now want to add fault tolerance to this service by having another instance that picks up the requests when one instance goes down. Now I understand that Microservices are not designed from the ground up to be clustered as they are purely stateless, self sustaining components that are meant to simply run.</p>&#xA;&#xA;<p>Are there ways wherein I could add failover support? I'm thinking of some external component that checks for the status of the service and reacts upon failures by starting another instance on some other host. Any suggestions?</p>&#xA;"
44642751,AWS Kinesis for Microservice Choreography,2017-06-20 02:15:51,<amazon-web-services><domain-driven-design><microservices><cqrs><event-sourcing>,1,614,0,0.0,1,"<p>I am trying to develop microservices for online shop using CQRS, DDD, and Event sourcing concept. I looked to AWS Kinesis as event stream. I think it would be good for choreographed microservices. I have 2 services, service for customer data and service for ordering system. I want to see total number of unpaid orders and the total amount of orders for each customer. So, I should send orderCreated event and orderPaid event to the service for customer data and recalculate the total unpaid orders and total amount of orders for related customer.</p>&#xA;&#xA;<p>Could I put the ordering system events to AWS Kinesis and listen it in command-side service for customer? Should I persist the events (orderCreated and orderPaid event) from AWS Kinesis to database in customer command-side service? Or is it ok to just update the customer query-side service only? Should I use AWS Lambda as event processor? Could you give me some best practices for this model?</p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
44554638,How do I guarantee that the interface between two microservices is not broken?,2017-06-14 20:58:56,<java><microservices>,3,160,2,0.0,1,"<p>Imagine we have two microservices: client and server. One of the most fundamental features of microservice architecture is an ability to have a separated pipelines for each microservice meaning that we have to be able to deploy them to production independently. </p>&#xA;&#xA;<p>This implies that different microservices may be developed by different teams and some of the features are developed faster on one microservice than on the another. This quite often ends up with the contract (interface) being broken between client and server, so the JSON that the client sends to the server is no more valid.</p>&#xA;&#xA;<p><strong>The question is how to prevent cases where communication between two microservices is broken due to a broken contract between them? What is the best strategy to handle such issues?</strong></p>&#xA;"
37711051,Example open source microservices applications,2016-06-08 19:16:46,<microservices>,3,729,1,1.0,1,"<p>I'm looking for open source applications that demonstrate the <a href=""http://martinfowler.com/articles/microservices.html"" rel=""nofollow"">microservices</a> pattern. In particular, I'd like to find one or more applications that can be spun up on real cloud environment up (but with fake data and requests) to demonstrate real-world deployment mechanics.</p>&#xA;&#xA;<p>Unfortunately, I haven't found any good options yet. I'll note that <a href=""https://www.discourse.org/"" rel=""nofollow"">Discourse</a> is a modern 3-tier application, using Rails API, Ember.js, Postgres, and Redis, but it still is much closer to a monolith than an example of microservices. The closest I've found so far is <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">https://github.com/kbastani/spring-cloud-microservice-example</a> but that is more of a framework than an actual application that delivers data.</p>&#xA;"
37679132,Load Balancing in Spring Cloud / Netflix OSS,2016-06-07 12:15:56,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-ribbon>,2,767,1,0.0,1,"<p>I am looking  at Spring Boot / Cloud and Netflix FWs (Eureka, Ribbon). I am working through this example:</p>&#xA;&#xA;<p><a href=""https://spring.io/blog/2015/07/14/microservices-with-spring"" rel=""nofollow"">https://spring.io/blog/2015/07/14/microservices-with-spring</a>&#xA;Basically it is about some small Spring Boot microservices that use the Eureka Service Registry. </p>&#xA;&#xA;<p>I now want to start several instances of the same service (in this example the AccountService, on different ports). Everything I read (above article, <a href=""http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/"" rel=""nofollow"">http://callistaenterprise.se/blogg/teknik/2015/04/10/building-microservices-with-spring-cloud-and-netflix-oss-part-1/</a> etc) suggests that if I do this, all instances get registered with Eureka redundantly and when I call the service, client-side load balancing is applied and the service to call is dynamically chosen.</p>&#xA;&#xA;<p>However, this is NOT what happens. When I start the first service instance, it gets registered and shows up in the Eureka Dashboard. When I start the same service on a different port, it also registers, but it seems to REPLACE the previous service instance: The Eureka Dashboard still only shows one instance with Availability Zones = 1 (should be 2?) and ALL calls to this service are handled by the second instance. When I query the registry, only this instance is applied.</p>&#xA;&#xA;<p>When I stop the second instance, after some time Eureka switches back to the first one and it still works. So it seems to keep all instances, but only ever uses the instance that was registered latest.</p>&#xA;&#xA;<p>Do I miss anything important? I thought all instances should be used simultaneously?</p>&#xA;&#xA;<p>==========&#xA;Application Properties are (those are practically unchanged to the example from the Spring Site):</p>&#xA;&#xA;<p><strong>EurekaServer</strong>  </p>&#xA;&#xA;<pre><code>eureka:  &#xA;  instance:  &#xA;    hostname: localhost  &#xA;  client:    &#xA;    registerWithEureka: false  &#xA;    fetchRegistry: false  &#xA;&#xA;server:  &#xA;  port: 1111     &#xA;&#xA;spring:  &#xA;  thymeleaf:  &#xA;    enabled: false  &#xA;</code></pre>&#xA;&#xA;<p><strong>AccountsServer</strong>  </p>&#xA;&#xA;<pre><code>spring:  &#xA;  application:  &#xA;    name: accounts-service  &#xA;  freemarker:  &#xA;    enabled: false           &#xA;  thymeleaf:  &#xA;    cache: false             &#xA;    prefix: classpath:/accounts-server/templates/      &#xA;&#xA;eureka:  &#xA;  client:  &#xA;    serviceUrl:  &#xA;      defaultZone: http://localhost:1111/eureka/  &#xA;&#xA;server:  &#xA;  port: 4444   # HTTP (Tomcat) port, for the second instance this is changed to a different port&#xA;</code></pre>&#xA;"
37427976,How do micro services in Cloud Foundry communicate?,2016-05-25 04:41:47,<rest><communication><cloudfoundry><microservices><predix>,2,1076,0,0.0,1,"<p>I'm a newbie in Cloud Foundry. In following the reference application provided by Predix (<a href=""https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600"" rel=""nofollow"">https://www.predix.io/resources/tutorials/tutorial-details.html?tutorial_id=1473&amp;tag=1610&amp;journey=Connect%20devices%20using%20the%20Reference%20App&amp;resources=1592,1473,1600</a>), the application consisted of several modules and each module is implemented as micro service.</p>&#xA;&#xA;<p>My question is, how do these micro services talk to each other? I understand they must be using some sort of REST calls but the problem is:</p>&#xA;&#xA;<ol>&#xA;<li><p>service registry: Say I have services A, B, C. How do these components 'discover' the REST URLs of other components? As the component URL is only known after the service is pushed to cloud foundry.</p></li>&#xA;<li><p>How does cloud foundry controls the components dependency during service startup and service shutdown? Say A cannot start until B is started. B needs to be shutdown if A is shutdown.</p></li>&#xA;</ol>&#xA;"
37528335,Splitting monolith into microservices,2016-05-30 14:39:57,<spring><rest><spring-boot><microservices>,1,691,1,1.0,1,"<p>I have an existing web service that supports ordering and it has multiple operations (approximately 20). This is a single webservice that support the ordering function. It interacts with multiple other services to provide ordering capability. </p>&#xA;&#xA;<p>Since there is a lot of business functionality within this app and it is supported by a 10 member team , I believe it is a monolith (though I assume there is no hard and fast rule to define what a monolith is). </p>&#xA;&#xA;<p>We are planning to get the application deployed in cloud foundry environment and we are planning to split the app into 2-3 microservices , primarily to enable them scale independently. </p>&#xA;&#xA;<p>The first few apis which enable searching for a product typically have more number of hits whereas the api that support actual order submission receives less that 5% of the hits. So the product search api should have significantly larger number of instances as compared to order submission api. </p>&#xA;&#xA;<p>Though I am not sure if we could split is based on sub-domains (which I have read should be the basis) , we are thinking of splitting them based on the call sequence as explained earlier. </p>&#xA;&#xA;<p>I have also read that microservices should be choreographed and not orchestrated. However in order to ensure our existing consumers are not impacted , I believe we should expose a api layer which would orchestrate the calls to these microservices. Is providing an api gateway , the normal approach that is followed to ensure consumers do not end up calling multiple microservices and also provides a layer of abstraction? </p>&#xA;&#xA;<p>This seems to be orchestration more than choreography - though I am not hung up on the theoretical aspects , I would like to understand the different solutions that are pursued for this problem statement in an enterprise world.</p>&#xA;"
44060464,Managing table which is frequently updated and queried,2017-05-19 02:27:17,<mysql><sql><scalability><microservices><bigdata>,5,44,0,0.0,1,"<p>So far, I and my friend have made a small system which is for collecting weather data from sensors placed around our area.&#xA;Here is one of table in our database:</p>&#xA;&#xA;<pre><code>CREATE TABLE `Measurement` (&#xA;  `Id` varchar(255) COLLATE utf8_unicode_ci NOT NULL DEFAULT '',&#xA;  `SensorId` varchar(16) COLLATE utf8_unicode_ci NOT NULL,&#xA;  `Time` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',&#xA;  `Battery` double DEFAULT NULL,&#xA;  `Rain` double DEFAULT NULL,&#xA;  `Humidity` double DEFAULT NULL,&#xA;  PRIMARY KEY (`Id`,`Time`)&#xA;) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;&#xA;</code></pre>&#xA;&#xA;<p><strong>Environment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>ASP.Net Framework 4.6.</li>&#xA;<li>Web API 2.</li>&#xA;<li>MySQL Community edition.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Deployment:</strong></p>&#xA;&#xA;<ul>&#xA;<li>There is one database for storing user information, weather measurement and sensor information deployed onto a single server.</li>&#xA;<li>There is one WEB API to help client app to connect to and obtain data.</li>&#xA;</ul>&#xA;&#xA;<p>Our situation is:</p>&#xA;&#xA;<p>This table is for storing climate element measurements each 10 second from 60 sensors.&#xA;For now, we are facing a problem that data is increasing drammatically, just do the simple calculation:</p>&#xA;&#xA;<p><strong>1</strong> (record each 10 second) * <strong>6</strong> (records in one hour) * <strong>24</strong> (hours a day) * <strong>365</strong> (days a year) = <strong>52 560</strong> (records a year)</p>&#xA;&#xA;<p><strong>52 560</strong> (records a year) * <strong>60</strong> (sensors) = <strong>3 153 000</strong> (records)</p>&#xA;&#xA;<p>So, after a year of collecting data from <strong>60</strong> sensors, we have <strong>3 153 000</strong> records. That is too many records to store into one table (in my opinion).&#xA;That's why I'm thinking about a solution that:&#xA;- Divide measurement data of sensors into many database and deploy onto many servers. Each sensor will have one small PC to store its information (by using API)&#xA;- When user want to query database to search for their needed information, base on the information of sensor that they provide, Web server will make calls to different API endpoint to obtain data and summarize information then display them to UI.</p>&#xA;&#xA;<p>My question is:</p>&#xA;&#xA;<ul>&#xA;<li>Exclude the cost of PC we use to deploy our database and micro service of whether measurement. Is this deployment an efficient practise ?</li>&#xA;<li>Are there any way to manage this kind of Measurement table ? (Data is increasing each 10 second and can be queried many times) ?</li>&#xA;<li>If there is a way to optimize my table, please let me know ?</li>&#xA;<li>Should I deploy sensor measurement collecting function as micro services to increase performance and scalability ?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you,</p>&#xA;"
44114755,How to do 2 phase commit between two micro-services(Spring-boot)?,2017-05-22 13:55:56,<spring-boot><microservices><distributed-transactions><2phase-commit>,2,892,0,0.0,1,"<p>I Have two mico-serives A and B where they connect to seperate database, From Mico-serives A i need to persist(save) objects of both A and B in same transtation how to achive this.</p>&#xA;&#xA;<p>I am using Spring micro-servies with netflix-oss.Please give suggestions on best way to do achive 2 phase commit.</p>&#xA;"
44000812,consul - connect client to server,2017-05-16 11:56:48,<service><microservices><consul><service-discovery>,1,663,0,0.0,1,"<p>I'm new at consul and I try to setup a server-client environment. I have started my server with the following command and configuration:</p>&#xA;&#xA;<pre><code>consul.exe agent -ui -config-dir=P:\Consule\config&#xA;</code></pre>&#xA;&#xA;<p>The config file looks the following (""P:\Consule\config\server.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""bootstrap"": false,&#xA;    ""server"": true,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""P:\\Consule\\data"",&#xA;    ""log_level"": ""INFO""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Output when I start consul from commandline with above command:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Consul agent running!&#xA;       Version: 'v0.8.3'&#xA;       Node ID: '1a244456-e725-44be-0549-33603ea7087d'&#xA;       Node name: 'MYCOMPUTERNAMEA'&#xA;       Datacenter: 'myservices'&#xA;       Server: true (bootstrap: false)&#xA;       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600)&#xA;       Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)&#xA;       Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false&#xA;       Atlas: &lt;disabled&gt;&#xA;</code></pre>&#xA;&#xA;<p>Now, at another computer in my domain I try to run an consul client with follwoing commandline and config-file:</p>&#xA;&#xA;<pre><code>consul.exe agent -config-dir C:\Consul -bind=127.0.0.1&#xA;</code></pre>&#xA;&#xA;<p>Config file (""C:\Consul\client.json"")</p>&#xA;&#xA;<pre><code>{&#xA;    ""server"": false,&#xA;    ""datacenter"": ""MyServices"",&#xA;    ""data_dir"": ""C:\\TEMP"",&#xA;    ""log_level"": ""INFO"",&#xA;    ""start_join"": [""MYCOMPUTERNAMEA""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But I always get follwing output/error message:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Joining cluster...&#xA;==&gt; 1 error(s) occurred:&#xA;&#xA;* Failed to join &lt;IP_OF_MYCOMPUTERNAMEA&gt;: dial tcp &lt;IP_OF_MYCOMPUTERNAMEA&gt;:8301: connectex: No connection could be made because the target machine actively refused it.&#xA;</code></pre>&#xA;&#xA;<p>Does anyone know what I'm doing wrong?</p>&#xA;&#xA;<p>Thanks and best regards</p>&#xA;"
44169046,How to manage microservice failure?,2017-05-24 21:49:57,<microservices>,4,227,1,0.0,1,"<p>Let's say, I have several micro-services (REST API), the problem is, if one service is not accessible (let's call service ""A"" ) the data which was sending to service ""A"" will be saved in temporary database. And after service worked, the data will be sent again. &#xA;Question:&#xA;1. Should I create the service which pings to service ""A"" in every 10 seconds to know service works or not? Or is it possible to do it by task queue? Any suggestions? </p>&#xA;"
44063886,How to achieve orchestration with spring boot micro service?,2017-05-19 07:21:59,<spring-boot><microservices><orchestration>,1,1793,2,0.0,1,<p>what is best way to orchestrate micro services in spring boot.</p>&#xA;
46283367,What are Hystrix benefits over normal exception handling?,2017-09-18 15:45:14,<microservices><hystrix>,4,600,0,0.0,1,"<p>I'm really new to Hystrix topic and concept of resilient services. I was going through some course and this question came into my mind. In Hystrix I need to define fallback method for a gracefull degradation. This method is then called when circuit is broken. But I can imagine to just wrap code with try and catch and when particular exceptions appear (for timeout for instance) and then call fallback method in catch clause. When called service is up then normal code would be called. Of course with Hystrix I can additionally monitor this, but what else it gives me ?. I'm pretty sure that I don't understand whole concept. </p>&#xA;"
46432262,How to achieve Statefullness in Microservices,2017-09-26 17:12:03,<microservices><stateful>,2,644,4,1.0,1,"<p>I have two microservices 1) Product Microservices 2) Checkout Microservices both are spring boot projects. In Checkout Microservice , i should get all the products that i have shopped, means my microservices should be STATEFUL to know what happend previously. Please suggest examples on how to achieve the statefulness it can be like Asyncronous with event source with Kafka/RabbitMQ. But please suggest architecture, code, example in detail how to get product details in checkout service.</p>&#xA;"
43870576,Batch - Get Requests from different Microservices,2017-05-09 13:01:35,<rest><get><microservices>,2,368,3,0.0,1,"<p>I am dividing a monolithic service to a microservice architecture. What I have done is separate the services and now the REST call is distributed but the problem is if I call a <code>service A</code> which returns 10000 instances and it is dependent on some other <code>service B</code>, so call comes to <code>service A</code> and for each instance, call goes to <code>service B</code> to get its data, so converting a single call to 10000 additional calls so now the call takes alot of time. </p>&#xA;&#xA;<p>I want to make multiple Get Requests in a single request. </p>&#xA;&#xA;<p>What I have searched is to use batch requests to POST different instances, but this is recommended on Creating &amp; Updating multiple instances together. Can this be done for getting information as well? </p>&#xA;&#xA;<p>And is there any other way to do it?</p>&#xA;&#xA;<p>Edit: A similar use case as to mine e.g. There are two services one service gets the details of students and the other gets the details of teachers. In teachers table there is student's ID that it teaches not as a foreign key but a simple key, Now in the UI for the teacher, it shows the teacher details and the student ID and student names and class it belongs to, so for getting the student name and class details, I would have to call the student's service with the student's ID.</p>&#xA;"
49992237,"If there are multiple microservices, how should I integration test them?",2018-04-24 01:42:04,<docker><go><microservices>,3,110,0,0.0,1,"<p>I am learning microservice architecture, but now there is some confusion.</p>&#xA;&#xA;<h3>situation</h3>&#xA;&#xA;<ul>&#xA;<li>there are 4 projects written in <code>golang</code>&#xA;&#xA;<ol>&#xA;<li><strong>orderService</strong></li>&#xA;<li><strong>userService</strong></li>&#xA;<li><strong>tools</strong></li>&#xA;<li><strong>web</strong> ( forward <code>HTTP</code> request )</li>&#xA;</ol></li>&#xA;<li><code>orderService</code> , <code>userService</code>, <code>web</code> communicate via <code>grpc</code></li>&#xA;<li>all api requests through <code>web</code> forwarding to <code>orderService</code> or <code>userService</code></li>&#xA;<li><code>orderService</code> and <code>userService</code> have their own independent database</li>&#xA;<li>they are all in <code>docker</code> containers</li>&#xA;</ul>&#xA;&#xA;<h3>confusion</h3>&#xA;&#xA;<p>when I want to test a request, I have to do the following steps:</p>&#xA;&#xA;<pre><code>cd orderService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd userService&#xA;govender update +vendor&#xA;go build&#xA;&#xA;cd web&#xA;govender update +vendor&#xA;go build&#xA;&#xA;docker-compose build&#xA;docker-compose up&#xA;</code></pre>&#xA;&#xA;<p>when I changed some code, I have to do this steps again.<br>&#xA;I think this is unscientific and abnormal.  I want to know whether all of these steps are necessary to integration test four microservices in docker.</p>&#xA;"
47343439,microservice not able to locate zipkin service using discovery-server,2017-11-17 04:44:23,<spring-boot><microservices><spring-cloud><zipkin><eureka>,1,770,2,0.0,1,"<p>I have mircroservice environment based on spring-boot, where i am using zipkin server and discovery-server(eureka) and config-server. Now i have a rest-microservice which sends logs to zipkin server and this microservice is required to resolve where is zipkin server using discovery-server.</p>&#xA;&#xA;<p>following is zipkin configuration i have in my rest-microservice's application.properties(pulled from config-server).</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://MTD-ZIPKIN-SERVER/&#xA;spring.zipkin.locator.discovery.enabled=true&#xA;spring.zipkin.enabled=true&#xA;...&#xA;</code></pre>&#xA;&#xA;<p>here MTD-ZIPKIN-SERVER is zipkin-server name in discovery-server.</p>&#xA;&#xA;<p>discovery-server dashboard.&#xA;<a href=""https://i.stack.imgur.com/SNliR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SNliR.png"" alt=""enter image description here""></a>&#xA;but it does not try to resolve zipkin from discovery-server, instead it tries to connect directly using spring.zipkin.baseUrl, and i get below exception.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Dropped 1 spans due to ResourceAccessException(I/O error on POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER)</p>&#xA;  &#xA;  <p>org.springframework.web.client.ResourceAccessException: I/O error on&#xA;  POST request for ""<a href=""http://MTD-ZIPKIN-SERVER/api/v1/spans"" rel=""nofollow noreferrer"">http://MTD-ZIPKIN-SERVER/api/v1/spans</a>"":&#xA;  MTD-ZIPKIN-SERVER; nested exception is java.net.UnknownHostException:&#xA;  MTD-ZIPKIN-SERVER     at&#xA;  org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:666)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.execute(RestTemplate.java:628)&#xA;    at&#xA;  org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:590)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.post(RestTemplateSender.java:73)&#xA;    at&#xA;  org.springframework.cloud.sleuth.zipkin.RestTemplateSender.sendSpans(RestTemplateSender.java:46)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$BoundedAsyncReporter.flush(AsyncReporter.java:245)&#xA;    at&#xA;  zipkin.reporter.AsyncReporter$Builder.lambda$build$0(AsyncReporter.java:166)&#xA;    at zipkin.reporter.AsyncReporter$Builder$$Lambda$1.run(Unknown&#xA;  Source)   at java.lang.Thread.run(Thread.java:745) Caused by:&#xA;  java.net.UnknownHostException: MTD-ZIPKIN-SERVER  at&#xA;  java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)&#xA;    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</p>&#xA;</blockquote>&#xA;&#xA;<p>if i provide exact zipkin url in property spring.zipkin.baseUrl like below</p>&#xA;&#xA;<pre><code>spring.zipkin.baseUrl=http://localhost:5555/&#xA;</code></pre>&#xA;&#xA;<p>then my rest-microservice is able to connect to zipkin-server.</p>&#xA;&#xA;<p>My goal here is to read zipkin-server location from discovery-srever. What am i doing wrong? Do i need to add some zipkin enabling annotation on my spring-boot rest-microservice?</p>&#xA;"
52092546,Create Pub/Sub service WITHOUT third parties tool,2018-08-30 08:34:30,<c#><asp.net><microservices><publish-subscribe>,1,38,11,0.0,1,"<p>I would like to find a solution to create a pub/sub medium for 2 microservices to talk to each other,&#xA;I am aware i can use some third parties E.g Redis, RabbitMQ&#xA;<a href=""https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/multi-container-microservice-net-applications/integration-event-based-microservice-communications"" rel=""nofollow noreferrer"">Implementing event-based communication between microservices (integration events)</a></p>&#xA;&#xA;<p>The challenge lies on the client is unable to allow install any third parties tool due to security reason. &#xA;The messageQueue server in Windows won't be allowed to use too. &#xA;I can only use the applications that is only existed in the server.</p>&#xA;&#xA;<p>Therefore i am asking if there is anyway that i can create one simple app using windows service.&#xA;It is a one-to-many relationship. I have one service that will be dealing with data, once if there is any update, it will publish to those services that is subsribed to it.</p>&#xA;&#xA;<p>It seems my problem could be similar with </p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/9919804/net-scalable-pub-sub-service-implementation"">.NET Scalable Pub/Sub service implementation</a></p>&#xA;&#xA;<p><a href=""https://stackoverflow.com/questions/391296/wcf-pub-sub-with-subscriber-caching"">WCF Pub/Sub with subscriber caching</a>(link is dead on the WCF pub-sub)</p>&#xA;&#xA;<p>but i dont see any critical solutions. </p>&#xA;&#xA;<p>I was thinking to use data notifications that MSSQL offers as last alternatives, but seems like it could cause a bottle neck when the applications get scale up. &#xA;The internet is so much flooded with articles using third parties tool. </p>&#xA;&#xA;<p>Thanks </p>&#xA;"
43243883,"distributed transactions in microservice architecture, how to handle timeouts and failed commits",2017-04-06 00:49:46,<rest><rabbitmq><microservices><distributed-transactions>,1,787,2,0.0,1,"<p>Lets say you have a service <code>A</code> that is part of large microservice architecture, where those services communicate between each other either via REST APIs or via messaging where some broker is involved (RabbitMQ). Service <code>A</code> expose REST endpoint that needs to communicate with some 3rd party service (so with service that is not in our architecture) and to create some stuff there, when service <code>A</code> receives a response from 3rd party that everything went good there, it should persist some data from that response in its own database. </p>&#xA;&#xA;<p>What would be the best way of covering following issues, having in mind that 3rd party does not provide any idempotence mechanism.</p>&#xA;&#xA;<ol>&#xA;<li><p>Creation on 3rd party side went good, but DB write failed in service <code>A</code>. This would lead to inconsistent state, you created something on 3rd party side, but you don't have needed data about it in your own database.</p></li>&#xA;<li><p>You received timeout from 3rd party, so you can't just repeat the call, cause they are not providing any idempotence mechanism. If you repeat the call, potentially you can end with two (or more) created resources instead of one.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem number 1. could be solved having whatever retry mechanism that could retry DB call for whatever number of times. Problem with that approach is that, if service <code>A</code> instance that is repeating the DB call goes down suddenly. </p>&#xA;&#xA;<p>Presumably, better approach would be that service after successful creation on 3rd party side, publish a RabbitMQ message about successful creation. This service would listen to that message and it could do DB call when it receive the message. Having nice retry mechanism and taking benefit of ACKing messages, one could solve the issue about, <code>What if service instance goes down suddenly</code>. <strong>So in this solution service is publisher and consumer of its own message(s).</strong> Any better idea? This solution will also introduce <strong>eventual-consistency</strong>, because API caller (guy who is calling service <code>A</code> endpoint) will receive response <strong>right after</strong> successful creation on 3rd party side, <strong>but before</strong> anything is persisted in service database (what API client need actually)</p>&#xA;&#xA;<p>What about timeout problem? <strong>How one would handle timeouts from 3rd party in this case?</strong>. I don't see anything better than issuing GET calls to check do they created something. Still again that GET call can fail, but it can be repeated until it succeed. Here also marginal use case is what if service goes down in time of issuing GET calls.</p>&#xA;"
37176069,Docker container A dies after excuting query(insert/update) in cassandra running as another docker service B,2016-05-12 02:05:36,<python><docker><cassandra><microservices>,1,149,0,3.0,1,"<p>I am new to docker,Cassandra . &#xA;well I'm facing a weird issue, any help as how I could debug this issue would be great. I am using </p>&#xA;&#xA;<pre><code> Cassandra 3.3.0, &#xA;native Cassandra-driver for python- 3.3.0 &#xA;Docker 1.11.1&#xA;</code></pre>&#xA;&#xA;<p>I have two containers one is hosting cassandra service say container A and from the other container say B i'm performing an insert query to cassandra container.&#xA;here once B executes the query to A just after this container B which is my service container dies . </p>&#xA;&#xA;<p><strong>Logs that i see in container B</strong></p>&#xA;&#xA;<pre><code>[start] application exit with code 0, killing container&#xA;</code></pre>&#xA;&#xA;<p>i dont see any other relevant logs to debug further as what is the reason so that i am container dies right after insert.</p>&#xA;&#xA;<p>Just to make sure i am not missing  any exception i am catching all exceptions&#xA;i.e BaseException . i have added few loggers their to track my issue however even container dies it never comes to this except block.</p>&#xA;&#xA;<p><strong>What i suspect</strong>  </p>&#xA;&#xA;<p>it seems docker has error in memory and the moment it will write , it dies or something else.</p>&#xA;&#xA;<p><strong>what  i tried also</strong></p>&#xA;&#xA;<p>i tried to run my code without docker container to see offending lines  if any. here without docker it works and no exceptions  comes. I also make sure  to shutdown the cassandra session. </p>&#xA;&#xA;<p>Please advise .. </p>&#xA;"
43350278,SemVer and Microservices,2017-04-11 15:29:38,<architecture><microservices><semantic-versioning>,2,289,3,0.0,1,"<p>Are there any best practices/patterns for applying SemVer in a microservice'd product? Should there be SemVer for each microservice, and SemVer for the overall product?</p>&#xA;&#xA;<p>Example- I have a product called <code>SuperDatabase</code> with 3 microservices called <code>SuperDatabaseCore</code>, <code>SuperDatabaseReports</code>, and <code>SuperDatabaseSearch</code>.</p>&#xA;&#xA;<p>Initial Release:&#xA;<code>SuperDatabase v1.0.0</code>&#xA;<code>SuperDatabaseCore v1.0.0</code>&#xA;<code>SuperDatabaseReports v1.0.0</code>&#xA;<code>SuperDatabaseSearch v1.0.0</code></p>&#xA;&#xA;<p>Minor Update to Report:&#xA;<code>SuperDatabaseReport v1.1.0</code></p>&#xA;&#xA;<p>Should the product be <code>SuperDatabase v1.1.0</code> now?</p>&#xA;&#xA;<p>What if later there is a patch to Search:&#xA;<code>SuperDatabaseSearch v1.0.1</code></p>&#xA;&#xA;<p>Should the product versioning be changed again? Should the product version be completely independent of the microservice? Should it use SemVer at all? Or should it not have any versioning?</p>&#xA;"
43424176,How to send various command type by MassTransit and RabbitMQ?,2017-04-15 09:01:03,<c#><rabbitmq><microservices><masstransit>,1,1238,4,0.0,1,"<p>I’m a beginner in using message brokers.<br/>&#xA;We have a ticketing service which has multiple sub service. A supervisor service gets requests with help of a web API and sends them to sub services.<br/>&#xA;Any request has a header which is used to detect command type (such as Reserve, Refund, Availability or etc.). We use json for serializing objects.<br/>&#xA;Now, How to send various message types(different objects) by MassTransit from a publisher such as our supervisor system, in a way that consumer can use it easily?<br/>&#xA;In general, is it possible to send various message type in MassTransit and rabbitMQ?<br/>&#xA;Every consumer has only one queue for processing received messages.</p>&#xA;&#xA;<p>Thanks</p>&#xA;&#xA;<blockquote>&#xA;  <h1>Update</h1>&#xA;</blockquote>&#xA;&#xA;<p><code>https://dotnetcodr.com/2016/08/02/messaging-with-rabbitmq-and-net-review-part-1-foundations-and-terminology/</code> <br/></p>&#xA;&#xA;<p>I read This posts suit to start in messaging with MassTransit and didn't see any example to using various message types on these and another resources:</p>&#xA;&#xA;<p>I have multiple commands and need various message types to send with them, but in examples only use a message type such as below:</p>&#xA;&#xA;<p><strong>Sender</strong></p>&#xA;&#xA;<pre><code>    private static void RunMassTransitPublisherWithRabbit()&#xA;    {&#xA;        string rabbitMqAddress = ""rabbitmq://localhost:5672/Ticket"";&#xA;        string rabbitMqQueue = ""mycompany.domains.queues"";&#xA;        Uri rabbitMqRootUri = new Uri(rabbitMqAddress);&#xA;&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            rabbit.Host(rabbitMqRootUri, settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;        });&#xA;&#xA;        Task&lt;ISendEndpoint&gt; sendEndpointTask = rabbitBusControl.GetSendEndpoint(new Uri(string.Concat(rabbitMqAddress, ""/"", rabbitMqQueue)));&#xA;        ISendEndpoint sendEndpoint = sendEndpointTask.Result;&#xA;&#xA;        Task sendTask = sendEndpoint.Send&lt;IRegisterCustomer&gt;(new&#xA;        {&#xA;            Address = ""New Street"",&#xA;            Id = Guid.NewGuid(),&#xA;            Preferred = true,&#xA;            RegisteredUtc = DateTime.UtcNow,&#xA;            Name = ""Nice people LTD"",&#xA;            Type = 1,&#xA;            DefaultDiscount = 0&#xA;        });&#xA;        Console.ReadKey();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><strong>Receiver</strong></p>&#xA;&#xA;<pre><code>        private static void RunMassTransitReceiverWithRabbit()&#xA;    {&#xA;        IBusControl rabbitBusControl = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;&#xA;        {&#xA;            IRabbitMqHost rabbitMqHost = rabbit.Host(new Uri(""rabbitmq://localhost:5672/Ticket""), settings =&gt;&#xA;            {&#xA;                settings.Password(""Kalcho^Milano"");&#xA;                settings.Username(""ticketadmin"");&#xA;            });&#xA;&#xA;            rabbit.ReceiveEndpoint(rabbitMqHost, ""mycompany.domains.queues"", conf =&gt;&#xA;            {&#xA;                conf.Consumer&lt;RegisterCustomerConsumer&gt;();&#xA;            });&#xA;        });&#xA;&#xA;        rabbitBusControl.Start();&#xA;        Console.ReadKey();&#xA;&#xA;        rabbitBusControl.Stop();&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p><code>IRegisterCustomer</code> is an interface and I can only get message content in  <code>rabbit.ReceiveEndpoint</code> and convert to usable object.</p>&#xA;&#xA;<p>Now, How to use various message types such as <code>IReserveTicket</code>, <code>IRefundTicket</code> and <code>IGetAvailability</code> to sending and receiving messages?</p>&#xA;&#xA;<p>Thanks again</p>&#xA;"
48043523,PACT provider verification against public APIs,2017-12-31 15:06:54,<microservices><pact><pact-jvm>,1,114,3,0.0,1,"<p>am trying to do test for consumer driver contract testing using pact jvm and able to generate consumer side contract file.During provider side verification, how to provide public API's instead of localhost most of the examples uses only localhost as provider, any help pls</p>&#xA;&#xA;<pre><code>@RunWith(PactRunner.class) // Say JUnit to run tests with custom Runner&#xA;@Provider(""WeatherProvider"") // Set up name of tested provider&#xA;@PactFolder(""D:\Workspace\pactConsumer\pactConsumer_v2\pacts"") // Point where to find pacts (See also section Pacts source in documentation)&#xA;@VerificationReports(value = {""markdown"",""json""}, reportDir = ""D:\Workspace\pactConsumer\pactConsumer_v2\target"")&#xA;&#xA;public class ProviderVerifyer {&#xA;@State(""Weather information is available for Chennai"") // Method will be run before testing interactions that require ""with-data"" state&#xA;public void getWeather() {&#xA;System.out.println(""Weather information is available for Chennai"" );&#xA;}&#xA;@TestTarget // Annotation denotes Target that will be used for tests&#xA;public final Target target = new HttpTarget(8114); // Out-of-the-box implementation of Target (for more information take a look at Test Target section)&#xA;&#xA;}&#xA;</code></pre>&#xA;"
42379365,How to see the output of a service in a docker stack?,2017-02-21 22:40:31,<docker><docker-compose><microservices><docker-swarm>,1,1050,0,0.0,1,"<p>With Docker Compose, when we run <code>docker-compose up</code> we see the output of all services being presented on the console, even with different colors to make it easier to distinguish them. Even if we have multiple instances of a service, the output of all of them appears there.</p>&#xA;&#xA;<p>Now, today I've tried deploying a stack to a swarm with Docker Compose v3 for the first time.</p>&#xA;&#xA;<p>After I do</p>&#xA;&#xA;<pre><code>docker deploy stack --compose-file=docker-compose.yml the_stack&#xA;</code></pre>&#xA;&#xA;<p>I can see the services running by using </p>&#xA;&#xA;<pre><code>docker service ls&#xA;</code></pre>&#xA;&#xA;<p>However, I'd like to see the output of the services as in Docker Compose.</p>&#xA;&#xA;<p>For instance, if I have a service <code>background_worker</code> with 3 replicas running in one node, I'd like to be able to see in that node the output of these replicas as I do with Docker Compose.</p>&#xA;&#xA;<p>How can I see the output of a replicated service deployed in a Docker Stack with Docker Swarm?</p>&#xA;&#xA;<p><strong>Edit</strong>: As answered, I need to enable experimental options on your docker daemon, however, I'm running this inside a docker-machine created with the hyperv driver, since it is not yet possible to run a multi-node swarm with Docker for Windows. How can I enable this inside the docker machine?</p>&#xA;"
42311050,How to register spring boot microservices on spring cloud Netflix eureka?,2017-02-18 04:28:10,<spring-boot><microservices><netflix-eureka><spring-cloud-netflix>,2,1029,1,0.0,1,"<p>We were planning to use spring cloud Netflix oss components. So I was doing a small sample project.&#xA;I developed 2 spring microservices and those services runs well on &#xA;<a href=""http://localhost:9000/microsvc-one"" rel=""nofollow noreferrer"">http://localhost:9000/microsvc-one</a> <a href=""http://localhost:9001/microsvc-two"" rel=""nofollow noreferrer"">http://localhost:9001/microsvc-two</a> </p>&#xA;&#xA;<p>And also wrote a sample spring cloud etflix eureka maven project which runs well on&#xA;<a href=""http://localhost:8761"" rel=""nofollow noreferrer"">http://localhost:8761</a></p>&#xA;&#xA;<p>I used annotations @EurekaDiscoveryClient and @SpringBootApplication on both the spring boot microservices main class</p>&#xA;&#xA;<p>I used annotation @EnableEurekaServer and @SpringBootApplication</p>&#xA;&#xA;<p>Now I am facing a problem in registering those services in eureka server. I referred some samples. I am not understanding those.&#xA; I did some changes in  application.yml files of microsvc-one and microsvc-two and also application.yml file of eureka server.&#xA;But still it shows empty. </p>&#xA;&#xA;<p>What all changes are required or missing or correct configuration to be done so that my services are being registered on eureka.</p>&#xA;&#xA;<p>I also have other question like do i need to create a separate project which has @EnableConfigServer and @SpringBootApplication Annotations other than the above 2 microservices and eureka server project module to register the services on eureka.&#xA;I see those in most of the examples.</p>&#xA;&#xA;<p>If yes..how do we link between all these?</p>&#xA;"
48438747,Jhipster microservices : How to create dynamic instances on microservices in production?,2018-01-25 08:40:53,<java><jhipster><microservices><production-environment>,2,210,5,0.0,1,"<p>I am using JHipster with 3 microservices (microservice1, microservice2, microservice3) applications, 1 JHipster registry application, and the API gateway. All applications are working as needed. I can  run my 5 applications in production without problem in mode one instance by application :</p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One instance</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>I want to have the following instance dynamically or with some automation : </p>&#xA;&#xA;<ul>&#xA;<li><p>microservice1 => One instance</p></li>&#xA;<li><p><strong>microservice2 => One, two or more instances</strong></p></li>&#xA;<li><p>microservice3 => One instance</p></li>&#xA;<li><p>jhipster registry=> One instance</p></li>&#xA;<li><p>API Gateway=> One instance</p></li>&#xA;</ul>&#xA;&#xA;<p>But I wonder how to instance dynamically or manually more instance of microservice2. If I want to create a new instance of service what is the best practices? :&#xA; - In Jhipster configuration are set in application-prod.yml. The port is set are the creation of the application. I just avec one server.  So if I cannot create a new instance on the same server!  There is be a conflict IP/port because the port is configured in the application-prod.yml. How to solve it? I think it's not a good idea to create multiple configuration files with different ports in case I have to run others instances of my microservices.</p>&#xA;&#xA;<ul>&#xA;<li>Is there another way to solve my problem?</li>&#xA;</ul>&#xA;&#xA;<p>Thank you for reading and for your ideas.</p>&#xA;"
48763985,Feasibility of Choosing EC2 + Docker As a Production Deployment Option,2018-02-13 09:59:48,<docker><amazon-ec2><microservices>,3,139,1,1.0,1,"<p>I am trying to deploy my microservice in EC2 machine. I already launched my Ec2 machine with Ubuntu 16.04 LTS AMI. And also I found that we can install docker and run containers through docker installation. Also I tried sample service deployment using docker in my ubuntu.I successfully run commands using -d option for running image in background also.</p>&#xA;&#xA;<ol>&#xA;<li>Here My confusion is that Can I choose this EC2 + Docker for deployment of my microservice for actual production environment? , Then I can deploy all my spring boot microservice in these option.</li>&#xA;</ol>&#xA;&#xA;<p>I know that ECS is another option for me.To be frank trying to avoid ECR, ECS optimized AMI and its burdens, Looking for machine with full control that only belongs to me. &#xA;                              But still I need to know about the feasibility of choosing EC2 + Docker through my Ubuntu machine.Also I am planning to deploy my angular 2. I don't need to install , deploy and manage any application server for both spring boot and angular.Since It will gives me about a serverless production environment to me.</p>&#xA;&#xA;<p>Can anyone help to clarify my doubts on choosing EC2 + Docker in production version for deploying my microservice? </p>&#xA;"
41880229,Send a message from one microservice to another in Azure Service Fabric (APIs),2017-01-26 18:16:09,<asp.net-web-api><architecture><microservices><azure-service-fabric><service-fabric-stateful>,2,651,0,3.0,1,"<p><a href=""https://i.stack.imgur.com/Og0vb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Og0vb.jpg"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>What is the best architecture, using Service Fabric, to guarantee that the message I need to send from Service 1 (mostly API) to Service 2 (mostly API) does not get ever lost (black arrow)?</p>&#xA;&#xA;<p>Ideas:</p>&#xA;&#xA;<h1>1</h1>&#xA;&#xA;<p>1.a. Make service 1 and 2 stateful services. Is it a bad call to have a stateful Web API?</p>&#xA;&#xA;<p>1.b. Use Reliable Collections to send the message from API code to Service 2.</p>&#xA;&#xA;<h1>2</h1>&#xA;&#xA;<p>2.a. Make Service 1 and 2 stateless services</p>&#xA;&#xA;<p>2.b. Add a third service</p>&#xA;&#xA;<p>2.c. Send the message over a queuing system (i.e.: Service Bus) from service 1</p>&#xA;&#xA;<p>2.d. To be picked up by the third service. Notice: this third service would also have access to the DB that service 2 (API) has access to. Not an ideal solution for a microservice architecture, right?</p>&#xA;&#xA;<h1>3</h1>&#xA;&#xA;<p>3.a. Any other ideas?</p>&#xA;&#xA;<p>Keep in mind that the goal is to never lose the message, not even when service 2 is completely down or temporary removed… so no direct calls.</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
41837933,Accessing Kubernetes Web UI (Dashboard),2017-01-24 20:02:38,<docker><kubernetes><microservices><kubectl><kube-dns>,1,2484,0,0.0,1,"<p>I have installed a Kubernetes with Kubeadm tool, and then followed the <a href=""https://kubernetes.io/docs/user-guide/ui/"" rel=""nofollow noreferrer"">documentation</a> to install the Web UI (Dashboard). Kubernetes is installed and running in one node instance which is a taint master node. </p>&#xA;&#xA;<p>However, I'm not able to access the Web UI at <code>https://&lt;kubernetes-master&gt;/ui</code>. Instead I can access it on <code>https://&lt;kubernetes-master&gt;:6443/ui</code>.</p>&#xA;&#xA;<p>How could I fix this?</p>&#xA;"
41832273,Kuberenets Web UI (Dashboard) missing graphs,2017-01-24 15:41:14,<docker><kubernetes><microservices>,1,607,2,0.0,1,<p>I have installed Docker v1.13 and Kubernetes with Kubeadm v1.6. Then I installed Web UI (Dashboard). I can access it but its missing CPU/Memory usage graphs... Why could this happen? </p>&#xA;
51040814,Micro services: shared library vs code duplication,2018-06-26 10:37:23,<.net><asp.net-core><architecture><microservices>,3,117,3,0.0,1,"<p>Similar questions were asked a few times, but as every use-case can be different I thought it worth to ask it again with the specific case I'm facing with.&#xA;So, we are developing micro-services using .netCore.  Let's call these services <strong>ServiceA</strong>, <strong>ServiceB</strong>, <strong>ServiceC</strong>.</p>&#xA;&#xA;<h2>Common entities</h2>&#xA;&#xA;<p>If <strong>ServiceA</strong> calls  <strong>ServiceC</strong>, then <strong>ServiceC</strong> responds with a JSON content which can be serialized into <strong>ResponseC</strong> object.</p>&#xA;&#xA;<p>This means, that both <strong>ServiceA</strong> and <strong>ServiceC</strong> should know <strong>ResponseC</strong> class.&#xA;At this point I see two possibilities. <strong>ResponseC</strong> class can be in a shared library and both <strong>ServiceA</strong> and <strong>ServiceC</strong> should have a reference to this shared library.&#xA;However I read statements like <strong>do not share libraries among micro-services</strong>. This leads to an other possible solution. Let's introduce <strong>ResponseC</strong> class in both micro-services, but then somehow I find this a bit against maintainability, because of code duplication.</p>&#xA;&#xA;<h2>Common logic</h2>&#xA;&#xA;<p>Both <strong>ServiceA</strong> and <strong>ServiceB</strong> communicates with <strong>ServiceC</strong>. When communicating with <strong>ServiceC</strong> we intend to have some policy regarding read and connection timeout and regarding the maximum number of retries. These values are configurable and there is also some common parts in the retry logic to be able to read the relevant values from the configuration file and to wrap the http calls. &#xA;The question is pretty much the same like in the previous case, because I either put these classes into a shared library or I basically introduce the same classes in both <strong>ServiceA</strong> and <strong>ServiceB</strong>. These classes are quite simple and generic, so at the moment I cannot imagine, that these classes will change frequently.</p>&#xA;&#xA;<p>So the question is, that what is better in these cases, duplicate code and having independent micro-services or introduce a shared library which makes these services dependent?</p>&#xA;"
42549749,"Micro-services, client-side discovery",2017-03-02 08:00:04,<microservices>,2,689,0,0.0,1,"<p>I am new to microservices, so while reading about it,I can't understand the below paragraph when talking about the load balancing, how the client will do something like this?</p>&#xA;&#xA;<p>""When using client‑side discovery, the client is responsible for determining the network locations of available service instances <strong>and load balancing requests across them.</strong>""</p>&#xA;"
42478361,How to login to Microservices ui app using jhipster,2017-02-27 05:24:39,<jhipster><microservices>,1,383,4,0.0,1,"<p>I am creating a <code>jhipster</code> application using microservices. I have created JHipster Registry, UAAserver, 2 microservices calling 2 Ui apps on 2 different url. Have added entities in 2 UI apps, using Mongodb for database. Have run all the above JHipster Registry, UAAserver, 2 microservices, 2 Uiapp's and i am able to see all running in Jhipster registry and tables being created in Mongodb but when i try to login to Uiapp1 or UiApp2 its throwing </p>&#xA;&#xA;<blockquote>&#xA;  <p>XMLHttpRequest cannot load <a href=""http://192.168.0.10:9999/login"" rel=""nofollow noreferrer"">http://192.168.0.10:9999/login</a>. No 'Access-Control-Allow-Origin' header is present on the requested resource. &#xA;  Origin '<a href=""http://192.168.0.10:8084"" rel=""nofollow noreferrer"">http://192.168.0.10:8084</a>' is therefore not allowed access.</p>&#xA;</blockquote>&#xA;"
37864491,"In a microservices architecture, how do you handle composite requests which must do minor data processing and call other services?",2016-06-16 16:19:04,<architecture><restful-architecture><microservices>,3,966,0,0.0,1,"<p>For example once the user gets to the payment step in our workflow a lot of different services need to be called (such as payment, email generation, content generation). Should the front-end handle that or should a service be designed to handle this type of request? If so, how should that service be designed so that it can handle doing composite requests without specifically hardcoding what those requests are composed of?</p>&#xA;"
37985551,Alternative to iframe for microservices ui composition,2016-06-23 08:01:54,<iframe><microservices>,2,1405,2,0.0,1,"<p>I'm currently integrating multiple microservices ui into a web portal. I have a navigation sidebar with link to microservices which will be loaded into an iframe in the central area.</p>&#xA;&#xA;<p>I have lot of issue with iframe (security with frame option header, window sizing, etc...)</p>&#xA;&#xA;<p>Do you know about a better alternative to an iframe?</p>&#xA;"
50217813,Disable Microservice initial exposed port after configuring it in a gateway,2018-05-07 15:35:30,<security><microservices><firewall><kong><api-gateway>,3,41,0,0.0,1,"<p>Hello I've been searching everywhere and did not found a solution to my problem, which is how can I access my API through the gateway configured endpoint only, currently I can access to my api using localhost:9000, and localhost:8000 which is the Kong gateway port, that I secured and configured, but what's the point of using this gateway if the initial port is still accessible.&#xA;Thus I am wondering is there a way to disable the 9000 port and only access to my API with KONG.</p>&#xA;"
50248560,spring-boot:run for multi module maven project,2018-05-09 08:14:42,<java><maven><spring-boot><microservices><netflix-eureka>,1,239,3,0.0,1,<p>I have a micro services setup of Eureka Server and multiple spring-boot applications as Eureka Clients. This is setup as maven multi module project at the parent (root) level. Below is the hierarchy:</p>&#xA;&#xA;<pre><code>parent (multi-module parent pom.xml)&#xA;  |_ eureka-server-spring-boot-app (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-1 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-2 (individual pom.xml)&#xA;  |_ eureka-client-spring-boot-app-3 (individual pom.xml)&#xA;  .&#xA;  .&#xA;</code></pre>&#xA;&#xA;<p>I was trying to run all the modules in the order defined in parent pom.xml. But when I run <code>mvn spring-boot:run</code> at parent level it only runs the first module (Eureka Server). Other modules are not deployed. I tried reading through SO but no relevant answers found.</p>&#xA;&#xA;<p>I want maven to run all the modules in order from parent directory. Is there any way this can be achieved?</p>&#xA;
43665011,Microservice registration with Eureka replicas in docker swarm cluster,2017-04-27 18:05:23,<docker><microservices><netflix-eureka>,1,988,0,0.0,1,"<p>If I have a microservice for Eureka service discovery and I have 5 replicas for it in docker-compose.yml then, these 5 eureka containers would be spread across multiple swarm nodes available in swarm cluster.</p>&#xA;&#xA;<p>My question is, when a microservice wants to register itself with eureka,</p>&#xA;&#xA;<ol>&#xA;<li><p>Would it specify the ip address of the master node in the swarm cluster in its config for eureka server ?</p></li>&#xA;<li><p>When a microservice registers itself with eureka whichever way, does this registry get replicated across all the eureka containers in swarm cluster as who know which eureka node in swarm cluster would service a particular microservice.</p></li>&#xA;</ol>&#xA;"
45489456,connect docker container on local and other containers remotely,2017-08-03 16:07:48,<docker><docker-compose><microservices><docker-machine>,2,70,0,2.0,1,"<p>For our development debugging easiness and few issues over deployment we planned to containerize the services we have. For example.</p>&#xA;&#xA;<p>I have services such as <code>A</code>, <code>B</code>, <code>C</code> and <code>D</code>. where <code>A</code> is my development code(which changes frequently) , and B,C and D are the dependent services. </p>&#xA;&#xA;<p>Currently the <code>B</code>,<code>C</code> and <code>D</code> are planned to deploy remotely because they are just a dependency (Docker Container)&#xA;I would want a way  to debug/deploy so that </p>&#xA;&#xA;<ul>&#xA;<li><p>My service <code>A</code> could be on local and it could easily connect with the remote Docker Service <code>B</code>,<code>C</code>,<code>D</code></p></li>&#xA;<li><p>Or <code>A</code> could be somehow deployed to the remote cluster and it could be tested.</p></li>&#xA;</ul>&#xA;&#xA;<p>I thought of going with the push to registry but each developer with his own snapshot being pushed could not co-relate others images.</p>&#xA;&#xA;<p><strong>Note:</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>I do not want Swarm kind of thing but want to keep it simple.</p></li>&#xA;<li><p>The Cluster is managed via Docker Machine. Can it be replaced?</p></li>&#xA;<li><p>The services are woven by Docker Compose.</p></li>&#xA;</ul>&#xA;&#xA;<p>Any suggestions on how I could drive this? Also preferred way is via Docker.</p>&#xA;"
45363163,what is the difference between netflix zuul server and netflix eureka server?,2017-07-28 00:46:18,<spring-boot><microservices><spring-cloud><spring-cloud-netflix>,2,2209,0,0.0,1,<p>i have created two java spring-boot micro services they are &#xA;1) producer &#xA;2) consumer &#xA;and i have used spring eureka server for service registration and discovery . it worked fine . then what is the use of Netflix Zuul.</p>&#xA;
45567201,User docker-compose to pull images from private repository,2017-08-08 11:32:44,<docker><docker-compose><microservices>,1,4064,6,0.0,1,<p>I'm using docker-compose command to run multiple containers. The problem is my docker-compose has to pull some images from the public repository and some from a private repository. What I'm planning to do is push all required images to the private repository but how can I make docker-compose pull the images from the private repository.</p>&#xA;&#xA;<p>In short -> How to point to a private repository when the images are only available there</p>&#xA;
51863731,Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository,2018-08-15 17:38:33,<spring><microservices><spring-cloud>,1,87,3,1.0,1,"<p>I am developing <code>Microservices with Spring Boot 2.0, Eureka and Spring Cloud</code> taking a ref from : <a href=""https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/"" rel=""nofollow noreferrer"">https://piotrminkowski.wordpress.com/2018/04/26/quick-guide-to-microservices-with-spring-boot-2-0-eureka-and-spring-cloud/</a>. In this example, I am developing <code>config-service</code> with <code>spring-boot-starter-parent</code> version <code>2.0.4.RELEASE</code>. </p>&#xA;&#xA;<p>When I simply run this code I got the below error. No where steps mentioned to setup the local git or use remote git. Could anyone please guide me on this?</p>&#xA;&#xA;<p><strong>Error:</strong></p>&#xA;&#xA;<pre><code>Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.&#xA;23:04:07.774 [main] ERROR o.s.boot.SpringApplication - Application run failed&#xA;org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155)&#xA;    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:544)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)&#xA;    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762)&#xA;    at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:398)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:330)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1258)&#xA;    at org.springframework.boot.SpringApplication.run(SpringApplication.java:1246)&#xA;    at com.prateek.ConfigServiceApplication.main(ConfigServiceApplication.java:12)&#xA;Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:126)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:413)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:174)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152)&#xA;    ... 8 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'servletEndpointRegistrar' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:226)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:214)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:91)&#xA;    at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:80)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:250)&#xA;    at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:237)&#xA;    at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:54)&#xA;    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)&#xA;    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1421)&#xA;    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1411)&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)&#xA;    at java.lang.Thread.run(Unknown Source)&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method 'servletEndpointRegistrar' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 23 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:590)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1089)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBean(EndpointDiscoverer.java:143)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.createEndpointBeans(EndpointDiscoverer.java:132)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.discoverEndpoints(EndpointDiscoverer.java:122)&#xA;    at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.getEndpoints(EndpointDiscoverer.java:116)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.servletEndpointRegistrar(ServletEndpointManagementContextConfiguration.java:75)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.CGLIB$servletEndpointRegistrar$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c$$FastClassBySpringCGLIB$$5ed0fb30.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration$$EnhancerBySpringCGLIB$$1185663c.servletEndpointRegistrar(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 24 common frames omitted&#xA;Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthEndpoint]: Factory method 'healthEndpoint' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:582)&#xA;    ... 48 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'configServerHealthIndicator' defined in class path resource [org/springframework/cloud/config/server/config/EnvironmentRepositoryConfiguration.class]: Unsatisfied dependency expressed through method 'configServerHealthIndicator' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:732)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:474)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:514)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:502)&#xA;    at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1198)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthIndicatorBeansComposite.get(HealthIndicatorBeansComposite.java:46)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration.healthEndpoint(HealthEndpointConfiguration.java:38)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.CGLIB$healthEndpoint$0(&lt;generated&gt;)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444$$FastClassBySpringCGLIB$$c5cb8397.invoke(&lt;generated&gt;)&#xA;    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)&#xA;    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:361)&#xA;    at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration$$EnhancerBySpringCGLIB$$77f1c444.healthEndpoint(&lt;generated&gt;)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;    at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&#xA;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&#xA;    at java.lang.reflect.Method.invoke(Unknown Source)&#xA;    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)&#xA;    ... 49 common frames omitted&#xA;Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.cloud.config.server.config.CompositeConfiguration': Unsatisfied dependency expressed through method 'setEnvironmentRepos' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:666)&#xA;    at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:91)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1341)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:572)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:372)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1247)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:818)&#xA;    at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:724)&#xA;    ... 73 common frames omitted&#xA;Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'defaultEnvironmentRepository' defined in class path resource [org/springframework/cloud/config/server/config/DefaultRepositoryConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1699)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:573)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)&#xA;    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)&#xA;    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)&#xA;    at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1322)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1288)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1190)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1093)&#xA;    at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062)&#xA;    at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:658)&#xA;    ... 96 common frames omitted&#xA;Caused by: java.lang.IllegalStateException: You need to configure a uri for the git repository&#xA;    at org.springframework.util.Assert.state(Assert.java:73)&#xA;    at org.springframework.cloud.config.server.environment.JGitEnvironmentRepository.afterPropertiesSet(JGitEnvironmentRepository.java:245)&#xA;    at org.springframework.cloud.config.server.environment.MultipleJGitEnvironmentRepository.afterPropertiesSet(MultipleJGitEnvironmentRepository.java:69)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1758)&#xA;    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1695)&#xA;    ... 109 common frames omitted&#xA;</code></pre>&#xA;&#xA;<p><strong>pom.xml</strong></p>&#xA;&#xA;<pre><code>&lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;</code></pre>&#xA;"
40564595,Docker - run two processes in single container,2016-11-12 15:48:29,<ruby-on-rails><nginx><docker><docker-compose><microservices>,1,612,0,0.0,1,"<p>I've created Ruby on Rails project with Nginx. Rails app and Nginx runs in separate and linked containers. This configuration works fine. However...</p>&#xA;&#xA;<p><strong>1) Is it possible to run both together (Rails / Puma server + Nginx) in a single container?</strong> </p>&#xA;&#xA;<p><strong>2) How should the CMD command in Dockerfile look like?</strong></p>&#xA;&#xA;<p><strong>3) What command should I use as the ""command:"" attribute in docker-compose.yml?</strong></p>&#xA;&#xA;<p>I think that configuration to run them in separate containers is better solution, but I would like to get to know all possibilites.</p>&#xA;&#xA;<p><em>I use Puma as a Rails' app server and to run it I use command: bundle exec puma -C config/puma.rb</em></p>&#xA;"
40564979,Host WepAPI on Service Fabric,2016-11-12 16:25:29,<c#><asp.net-web-api><microservices><azure-service-fabric><devops>,3,755,0,1.0,1,"<p>We just stood up an on-premise MS Service Fabric cluster.  I have some WebAPI's i'd like to host in it.  I'm looking for resources on how to take our standard 4.5 WebAPI's and host them in Service Fabric without have to create a Service Fabric project and migrate it; that just seems too complex.</p>&#xA;&#xA;<p>I looked at some of the Service Fabric sample projects, and it seems all the projects are tightly coupled with Service Fabric.  My goal is keep these apps unaware of Service Fabric.</p>&#xA;&#xA;<p>Any links of information is greatly appreciated, thanks!</p>&#xA;"
46615008,Microservices: Service discovery/ circuit breaker for Event-driven architecture,2017-10-06 22:58:45,<spring-boot><microservices><event-driven><event-driven-design><circuit-breaker>,4,274,0,1.0,1,"<p>I'm fairly new to Microservices...</p>&#xA;&#xA;<p>I've taken an interest in learning more about two main patterns like <em><a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">service discovery</a></em> and <em><a href=""https://martinfowler.com/bliki/CircuitBreaker.html"" rel=""nofollow noreferrer"">circuit breaker</a></em> and I have conducted research on how these could be implemented. </p>&#xA;&#xA;<p>As a Java Developer, I'm using Spring Boot. From what I understand, these patterns are useful if microservices communicate via HTTP.</p>&#xA;&#xA;<p>One of the topics I've recently seen is the importance of event-driven architecture, which makes use of an event message bus that services would use to send messages to for other services, which subscribe to the bus&#xA;and process the message.</p>&#xA;&#xA;<p>Given this event-driven nature, how can service-discovery and circuit breakers be achieved/implemented, given that these are commonly applicable for services communicating via HTTP?</p>&#xA;"
45661006,What is the difference between Monolith and n Layer?,2017-08-13 13:44:07,<architecture><microservices>,1,972,0,1.0,1,"<p>i have a few questions regarding <strong>monolith</strong> and <strong>n layer architecture</strong>.</p>&#xA;&#xA;<p>First, whats the difference between Monolith and n Layer architecture?</p>&#xA;&#xA;<p>Second, let's say I have a single Visual Studio solutions that consist of multiple projects such as:</p>&#xA;&#xA;<ol>&#xA;<li>Presentation Layer</li>&#xA;<li>Service Layer</li>&#xA;<li>Business Layer</li>&#xA;<li>Cross Layer</li>&#xA;<li>Data Layer</li>&#xA;<li>Unit Test</li>&#xA;</ol>&#xA;&#xA;<p>Is that considered as Monolith or n layer architecture?</p>&#xA;&#xA;<p>If I have microservices that consist (let's say) 3 Web API and I build each service in single separate Visual Studio solutions, <strong><em>it is ok</em></strong> to implement my previous project structure (service layer, business layer, data layer, etc)?</p>&#xA;&#xA;<p>Thank you very much and sorry for my bad english.</p>&#xA;"
45776238,Golang microservice project structure,2017-08-19 21:00:10,<go><microservices><directory-structure>,3,2271,0,2.0,1,"<p>I'm at an initial stage of creating a microservice application in Go, but due to the way that the import paths and directories are handled I'm not quite sure what's best way to structure the project files.</p>&#xA;&#xA;<p>Normally, the project would look something like this in Java:</p>&#xA;&#xA;<pre><code>|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>Now if I do it the same way in Go, the import paths become somewhat cumbersome:</p>&#xA;&#xA;<pre><code>import (&#xA;       ""fmt"" &#xA;       ""github.com/user/myproject/gateway_microservice/src/package1""&#xA;       ""github.com/user/myproject/gateway_microservice/src/package2""&#xA;)&#xA;</code></pre>&#xA;&#xA;<p>Additionally, I hear that the idiomatic way is to put all <code>main.go</code> files in a separate <code>cmd</code> directory, which adds to the confusion. Would it look something like this:</p>&#xA;&#xA;<pre><code>|-- cmd&#xA;   |-- gateway_microservice&#xA;      |-- main.go&#xA;   |-- config_microservice&#xA;      |-- main.go&#xA;   |-- recommendation_microservice&#xA;      |-- main.go&#xA;   |-- users_microservice&#xA;      |-- main.go&#xA;|-- gateway_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- config_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- recommendation_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;|-- users_microservice&#xA;   |-- src&#xA;   |-- docker&#xA;</code></pre>&#xA;&#xA;<p>What is the 'correct' or idiomatic way of structuring a project like this in Go?</p>&#xA;"
45791262,How to orchestrate multiple microservices on local env?,2017-08-21 07:14:59,<docker><development-environment><microservices><orchestration>,1,584,6,0.0,1,"<p>at the moment of speaking I have a bunch of services running each one on its own container&#xA;Every repo of code has its own Docker file and docker compose file in order to bring up the service on my local dev-machine</p>&#xA;&#xA;<p>Everything is fine and I'm able o access each service at</p>&#xA;&#xA;<p><a href=""http://localhost:[service"" rel=""nofollow noreferrer"">http://localhost:[service</a> mapped/exposed port]</p>&#xA;&#xA;<p>Problem is that services are augmenting and I'm thinking that could be a better idea to have everything in a local private network, where each service 's container has its own IP address.</p>&#xA;&#xA;<p>Is this a better approach to orchestrate containers locally?</p>&#xA;&#xA;<p>Where should I start from to make up my mind?</p>&#xA;"
50830715,REST-based services running as pods on Kubernetes in Azure with intermittent timeouts,2018-06-13 06:48:18,<azure><docker><kubernetes><microservices>,3,36,0,0.0,1,"<p>We have a number of different REST-based services running in Azure within a Kubernetes (version 1.9.6) cluster.  </p>&#xA;&#xA;<p>Two of the services, let's say A and B needs to communicate with each other using REST-calls.  Typically, something like the following:</p>&#xA;&#xA;<pre><code>Client calls A (original request)&#xA;A calls B (request 1)&#xA;B calls A (request 2)&#xA;A responds to B (request 2)&#xA;B responds to A (request 1)&#xA;A responds to the original request&#xA;</code></pre>&#xA;&#xA;<p>The above being a typical intertwined micro-services architecture.  Manually running the docker instances works perfectly on our local test servers.</p>&#xA;&#xA;<p>The moment we run this in Kubernetes on Azure we get intermittent timeouts (60+ seconds) on the micro-services calling each other through Kubernetes' networking services.  After a timeout, repeating the request would then often give correct responses in a few micro-seconds.</p>&#xA;&#xA;<p>I am stuck at this point as I have no idea what could be causing this.  Could it be the dynamic routing?  The virtualised network? Kubernetes configuration? </p>&#xA;&#xA;<p>Any ideas?</p>&#xA;"
50849415,What is the best way to do microservice REST API versioning?,2018-06-14 04:00:55,<spring><rest><microservices><aws-api-gateway><api-versioning>,1,233,3,0.0,1,"<p>I'm developing this project using Spring and hosting in AWS EC2 instances. As few new requirements coming up, I have to change  my API contracts. But I don't want to break the current clients. So, I'm trying to implement some REST APIs with versioning. So that whenever I update the endpoints the consumer applications won't crash. But I'm confused on how to do the API versioning. I thought of two ways. </p>&#xA;&#xA;<ol>&#xA;<li><p>Create a next version endpoint in the same server,(in spring using RequestMaping(""/v1/api1""),RequestMaping(""/v2/api1"") something like this.)</p></li>&#xA;<li><p>Other wise completely run the v2 APIs in new server instance but keep the same API endpoint footprint and use AWS APIGateway as a proxy and configure the versioning there, then route to old server and new server depending on the version number in the request.</p></li>&#xA;</ol>&#xA;&#xA;<p>But the first approach will lead to lot of code duplication and code management messy I believe. Because we are keeping the same functionality with variations.</p>&#xA;&#xA;<p>In the second approach I have to keep two set of instances for bot versions if me Version increases then It's hard to manage those instances, specially, when I will have around 15 micro-service instances. And it'll not be cost effective also. Because my company is a startup , so I need to consider this fact also.</p>&#xA;&#xA;<p>Is there any best practices regarding API versioning and managing multiple version of endpoints? I'm open for any suggestions and guidelines. If multiple server is the solution also, I'm open to reconsider the cost limitations. I need the best solution for this problem. </p>&#xA;"
25812816,How to shutdown dropwizard application?,2014-09-12 16:30:05,<java><dropwizard><microservices>,5,6562,2,0.0,2,"<p>I am trying to come up with a microservice using dropwizard. &#xA;The documentation tells how to start the application, but says nothing about terminating it gracefully. Fir example, apache tomcat has both startup <em>and</em> shutdown scripts. </p>&#xA;&#xA;<p>So does anyone know how to terminate a dropwizard application other than pressing <code>Ctrl+C</code> of <code>kill</code> ? </p>&#xA;"
31973473,Message Bus versus Quasar/HTTP for internal Microservice Calls,2015-08-12 19:08:08,<java><microservices><message-bus><backpressure><quasar>,1,981,0,0.0,2,"<p>I am looking to optimize a microservice architecture that currently uses HTTP/REST for internal node-to-node communication.</p>&#xA;&#xA;<p>One option is implementing backpressure capability into the services, (eg) by integrating something like Quasar into the stack.  This would no doubt improve things.  But I see a couple challenges.  One is, the async client threads are transient (in memory) and on client failure (crash), these retry threads will be lost.  The second, in theory, if a target server is down for some time, the client could eventually reach OOM attempting retry because threads are ultimately limited, even Quasar Fibers.</p>&#xA;&#xA;<p>I know it's a little paranoid, but I'm wondering if a queue-based alternative would be more advantageous at very large scale.</p>&#xA;&#xA;<p>It would still work asynchronously like Quasar/fibers, except a) the queue is centrally managed and off the client JVM, and b) the queue can be durable, so that in the event client and or target servers go down, no in flight messages are lost.</p>&#xA;&#xA;<p>The downside to queue of course is that there are more hops and it slows down the system.  But I'm thinking there is probably a sweet spot where Quasar ROI peaks and a centralized and durable queue becomes more critical to scale and HA.</p>&#xA;&#xA;<p><strong>My question is:</strong>  </p>&#xA;&#xA;<blockquote>&#xA;  <p>Has this tradeoff been discussed?  Are there any papers on using a&#xA;  centralized external queue / router approach for intraservice&#xA;  communication.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>TL;DR;</strong>  I just realized I could probably phrase this question as:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""When is it appropriate to use Message Bus based intraservice&#xA;  communication as opposed to direct HTTP within a microservice&#xA;  architecture.""</p>&#xA;</blockquote>&#xA;"
29387250,RESTful Microservice failover & load balancing,2015-04-01 09:30:10,<spring-boot><load-balancing><failover><microservices>,1,1748,0,2.0,2,<p>At the moment we have some monolithic Web Applications and try to transfer the projects to an microservices infrastructure. </p>&#xA;&#xA;<p>For the monolithic application is an HAProxy and Session Replication to have failover and load balancing. </p>&#xA;&#xA;<p>Now we build some RESTful microservices with spring boot but it's not clear for me what is the best way to build the production environment. &#xA;Of course we can run all applications as unix services and still have a reverse proxy for load balancing and failover. This solution seems very heavy for me and have a lot of configuration and maintenance. Resource Management and scaling up or down servers will be always a manually process. </p>&#xA;&#xA;<p>What are the best possibilities to setup production environment with 2-3 Servers and easy resource management? &#xA;Is there some solution the also support continuous deployment?</p>&#xA;
30000824,How to use kubernetes replication controllers to replicate message-based services,2015-05-02 09:50:02,<rabbitmq><kubernetes><microservices>,1,1121,0,0.0,2,"<p>We usually use message passing to send messages to decoupled services. This makes service discovery a non-issue, because (with AMQP in RabbitMQ for instance) you can use the broker's routing capability to dispatch messages to the right queues that feed the correct services. Load balancing is also handled by the message broker.</p>&#xA;&#xA;<p>Enter kubernetes.</p>&#xA;&#xA;<p>The use case that is usually laid out when talking about service replication and re-spawning failing services, is when your clients use some active protocol like http to contact a service, even if this service handles requests asynchronously. In this context, it is a natural fit to have replication controllers, that manage a group of services and a single entry point to load balance between them.</p>&#xA;&#xA;<p>I like kubernetes' intuitive concepts, like rolling deployments, but how to you control this beasts that don't have an http interface ?</p>&#xA;&#xA;<p><strong>UPDATE:</strong>&#xA;I am not trying to set up a cluster of message brokers. I am looking at message consumers as services. Service clients don't connect directly to the services, they send messages to the message broker. The message broker acts as a load balancer in a way, and dispatches the messages to the subscribed queue consumers. These consumers implement the service.</p>&#xA;&#xA;<p>My question gravitates around the fact that most usage patterns in demos handle services that are called via http, and kubernetes does a good job here to create a service proxy for these services, and a replication controller. Is it possible to create replication controllers for my kind of service, which does not have a http interface per se, and have all the benefits of rolling updates, and minimum instances?</p>&#xA;"
30739851,How can microservices be truly independent when using an ESB (i.e. MassTransit)?,2015-06-09 18:20:33,<c#><esb><servicebus><masstransit><microservices>,1,611,0,0.0,2,"<p>I'm doing some initial investigation into decomposing a current monolithic system by using MassTransit.  My main reason for going with a queue-based ESB is that the set of features I'm tackling first are using a shared database as, essentially, a queue.</p>&#xA;&#xA;<p>I've also been reading ""Building Microservices"" and while I haven't yet finished it, one of the core tenets appears to be that microservices should essentially be standalone.</p>&#xA;&#xA;<p>How can I reconcile using MassTransit which by necessity shares a message library (or at least contracts) and the fact that these services shouldn't have to ""know"" anything about each other?</p>&#xA;"
35140042,Django or Flask or Falcon for Microservices,2016-02-01 20:49:21,<django><flask><architecture><microservices><falconframework>,1,3874,2,1.0,2,"<p>Why is Microservice Architecture better than monolithic architecture? I know the answer will be because the microservice architecture is more scalable and each service is independent of each other etc.</p>&#xA;&#xA;<p>My following question is: should we build using Flask or Django REST Framework?</p>&#xA;&#xA;<p>I have also heard of a framework know as <a href=""http://falconframework.org"" rel=""nofollow"">Falcon</a> as per there documentation seems good enough.</p>&#xA;"
36876367,Cloud Service to Service Fabric authentication?,2016-04-26 21:47:08,<c#><azure><microservices><azure-service-fabric>,1,1084,0,1.0,2,<p>What's the recommended way to authorize service-to-service traffic in Service Fabric?</p>&#xA;&#xA;<p>I have a Classic Cloud Service that I'd like to have call a Web API endpoint in a service fabric service. Is there a way to open up specific ports to specific IPs in a service fabric cluster? Or is there a better way to make sure my service fabric endpoints can not be called from the outside internet?</p>&#xA;&#xA;<p>Thanks!</p>&#xA;
41400158,Bitnami and Docker,2016-12-30 17:26:04,<docker><cloud><microservices><bitnami>,1,1792,1,0.0,2,"<p>How Bitnami and Docker are different from each other when it comes to container based deployments.</p>&#xA;&#xA;<p>I have been learning about microservices recently. I used Docker images to run my apps as containers. And, I noticed that Bitnami does something similar when it creates a virtual image on a cloud form its launchpad.</p>&#xA;&#xA;<p>From whatever links I could see on Internet, I could not visualize how these two - Docker and Bitnami - are different from each other.</p>&#xA;"
41285879,Microservice and RabbitMQ,2016-12-22 14:53:49,<asp.net-web-api><architecture><rabbitmq><microservices><easynetq>,3,711,2,2.0,2,"<p>I am new to Microservices and have a question with RabbitMQ / EasyNetQ. &#xA;I am sending messages from one microservice to another microservice.</p>&#xA;&#xA;<p> Each Microservice are Web API's. I am using CQRS where my Command Handler would consume message off the Queue and do some business logic. In order to call the handler, it will need to make a request to the API method. </p>&#xA;&#xA;<p>I would like to know without having to explicit call the API endpoint to hit the code for consuming messages. Is there an automated way of doing it without having to call the API endpoint ? &#xA;<p> Suggestion could be creating a separate solution which would be a Console App that will execute the RabbitMQ in order to start listening. Create a while loop to read messages, then call the web api endpoint to handle business logic every time a new message is sent to the queue. </p>&#xA;&#xA;<p>My aim is to create a listener or a startup task where once messages are in the queue it will automatically pick it up from the Queue and continue with command handler but not sure how to do the ""Automatic"" way as i describe it. I was thinking to utilise Azure Webjob that will continuously be running and it will act as the Consumer.&#xA;<br>Looking for a good architectural way of doing it. &#xA;<p> Programming language being used is C#  </p>&#xA;&#xA;<p>Much Appreciated</p>&#xA;"
35617996,Eureka registration of Https micro services,2016-02-25 03:57:15,<spring-boot><microservices><netflix-eureka>,2,1894,0,0.0,2,<p>Eureka does not recognized HTTPS endpoints like '/info' and '/health' and always points to HTTP endpoints after enabling HTTPS. How to enable HTTPS micro-service url registration at Eureka ? </p>&#xA;
35441660,Micro services with JBOSS,2016-02-16 19:42:39,<jboss><microservices>,3,1732,0,0.0,2,"<p>I am new to Jboss, want to know if micro services architecture is a right choice on JBOSS. I cannot change the application server as it is decided by client architect and I have no choice.&#xA;Want to know whether we can develop micro services with underlying JBOSS application server.</p>&#xA;&#xA;<p>I understand Spring boot comes with embedded tomcat container, which makes it flexible to stop and start, deploy individual service with no impact to other services.&#xA;However will that architecture works with JBoss too.</p>&#xA;&#xA;<p>Please suggest.</p>&#xA;&#xA;<p>Thanks,</p>&#xA;"
39686227,Handling database schema creation and migrations when launching multiple instances of a containerized microservice,2016-09-25 11:18:52,<docker><kubernetes><database-migration><microservices>,2,814,0,0.0,2,"<p>I want to deploy my microservices in docker containers. I want these microservices to be as stateless as possible, only persisting state to a database.</p>&#xA;&#xA;<p>This means that there are these requirements:</p>&#xA;&#xA;<ul>&#xA;<li>These services are deployed as docker containers and orchestrated using kubernetes.</li>&#xA;<li>Each service can be deployed and scaled to multiple instances.</li>&#xA;<li>Each instance of a service will be identical. This means that they must all have the same environment variables and configurations passed to it.</li>&#xA;<li>Each instances should not care or know about another instance.</li>&#xA;<li>The instances should be stateless and should not elect a leader or have a quorum.</li>&#xA;</ul>&#xA;&#xA;<p>That leads to my problem with handling schema creation and migrations:</p>&#xA;&#xA;<ol>&#xA;<li><p>If I have a service that uses MySQL or Postgres as the data store, how do I create the tables/schemas on first launch? Should I just use <code>CREATE IF NOT EXIST</code> statements and let the instances ""fight it out"" during boot? I am not able to set an environment variable to ask for table/schema creation for just 1 of the instances.</p></li>&#xA;<li><p>How do I handle schema migrations with the above constraints? There are numerous actions like dropping/adding columns that cannot be encapsulated in a transaction.</p></li>&#xA;</ol>&#xA;"
34578641,Is there a real need to adopt ssl transport layer in a microservice architecture for internal lan-only Service to Service communication?,2016-01-03 16:13:29,<ssl><https><microservices>,1,1355,1,0.0,2,<p>In a scenario where there are thousands of webservices are there reasons to use also a signed cert for each microservice or it's just going to add overhead? Services communicate via VPC sitting behind a firewall while Public endpoints are behind a nginx public facing a valid CA cert.</p>&#xA;&#xA;<p>Services are on multiple servers on aws.</p>&#xA;
39224930,jhipster 3 Migrate from monolithic to microservices,2016-08-30 10:24:52,<migration><jhipster><microservices>,2,635,0,2.0,2,"<p>Currently I've a JHipster 3.3 monolithic application and I would like to migrate to microservices architecture. I've already created the registry, the gateway and the uaa service. Now I need to migrate the core business of my application into a microservice. Is there a facility to perform it? Can I make it automatically?</p>&#xA;"
39364466,How to dockerized java microservices efficiently,2016-09-07 08:06:47,<java><docker><jvm><microservices><application-server>,1,383,1,2.0,2,"<p>While a java application server will extend a unique JVM to run several (micro)services, a dockerized java microservices architecture will run a JVM for each dockerized microservice.&#xA;Considering 20+ java microservices and a limited number of host it seems that the amount of resources consumed by the JVMs on each host is huge.</p>&#xA;&#xA;<p>Is there an efficient way to manage this problem ? Is it possible to tune each JVM to limit resources consumption ?&#xA;The aim is to limit the overhead of using docker in a java microservices architecture.</p>&#xA;"
31095177,Data replication in Micro Services: restoring database backup,2015-06-28 01:07:07,<microservices>,1,1124,0,0.0,2,"<p>I am currently working with a legacy system that consists of several services which (among others) communicate through some kind of Enterprise Service Bus (ESB) to synchronize data.</p>&#xA;&#xA;<p>I would like to gradually work this system towards the direction of micro services architecture. I am planning to reduce the dependency on ESB and use more of message broker like RabbitMQ or Kafka. Due to some resource/existing technology limitation, I don't think I will be able to completely avoid data replication between services even though I should be able to clearly define a single service as the data owner.</p>&#xA;&#xA;<p>What I am wondering now, how can I safely do a database backup restore for a single service when necessary? Doing so will cause the service to be out of sync with other services that hold the replicated data. Any experience/suggestion regarding this?</p>&#xA;"
44392569,Will istio add support for docker swarm?,2017-06-06 14:19:18,<docker><microservices><docker-swarm>,2,650,0,1.0,2,"<p><a href=""https://github.com/istio/istio"" rel=""nofollow noreferrer"">istio</a> An open platform to connect, manage, and secure micro-services looks very interesting, but supports only Kubernetes. I couldn't find a roadmap or mention of future support for other container management platforms, specifically Docker Swarm</p>&#xA;"
44274982,Spring Boot Application - what is default timeout for any rest API endpoint or a easy config to control all endpoint timeout,2017-05-31 03:08:28,<java><spring><rest><spring-boot><microservices>,4,10949,2,1.0,2,"<p>I am using current Spring boot version (1.4.x) and wondering if it has any default timeout for api calls. I have tested it by putting breakpoints but it was keep waiting and didn't time-out. &#xA;I was also trying to configure default timeout for all my spring-boot apps by using some annotation or yml settings. </p>&#xA;&#xA;<p>I found couple of alternatives (one of them <a href=""https://stackoverflow.com/questions/34852236/spring-boot-rest-api-request-timeout"">here</a>) but using callable actually adding extra non-business logic code where setting something in xml bean is out of fashion in latest spring boot applications.</p>&#xA;"
36582126,How Lagom services consume other services?,2016-04-12 19:15:41,<microservices><service-discovery><lagom>,1,1048,2,1.0,2,"<p>I cant think in three cases.</p>&#xA;&#xA;<ol>&#xA;<li>Lagom service consumes another Lagom service in the same cluster</li>&#xA;<li>Lagom service consumes another Lagom service in a different cluster</li>&#xA;<li>Lagom service consumes an external non-Lagom service</li>&#xA;<li>An external non-Lagom service consumes a Lagom service</li>&#xA;</ol>&#xA;&#xA;<p><strong>1. Lagom service consumes another Lagom service in the same cluster</strong></p>&#xA;&#xA;<p>For this case the approach is that ServiceAImpl depends on the ServiceB API, wich is binded to a concrete implementation that will be injected to ServiceAImpl.</p>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Binding-a-service-client"" rel=""nofollow"">ServiceB binding:</a></p>&#xA;&#xA;<pre><code>import com.google.inject.AbstractModule;&#xA;import com.lightbend.lagom.javadsl.server.ServiceGuiceSupport;&#xA;import docs.services.HelloService;&#xA;&#xA;public class Module extends AbstractModule implements ServiceGuiceSupport {&#xA;&#xA;    protected void configure() {&#xA;        bindClient(HelloService.class);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p><a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceClients.html#Using-a-service-client"" rel=""nofollow"">ServiceA implementation:</a></p>&#xA;&#xA;<pre><code>public class MyServiceImpl implements MyService {&#xA;  private final HelloService helloService;&#xA;&#xA;  @Inject&#xA;  public MyServiceImpl(HelloService helloService) {&#xA;    this.helloService = helloService;&#xA;  }&#xA;&#xA;  @Override&#xA;  public ServiceCall&lt;NotUsed, NotUsed, String&gt; sayHelloLagom() {&#xA;    return (id, msg) -&gt; {&#xA;      CompletionStage&lt;String&gt; response = helloService.sayHello().invoke(""Lagom"");&#xA;      return response.thenApply(answer -&gt;&#xA;          ""Hello service said: "" + answer&#xA;      );&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>If I understand it correctly, in order to consume the service API in this way, both clients must be in the same cluster.&#xA;However Lagom <a href=""http://www.lagomframework.com/documentation/1.0.x/Cluster.html#Cluster-composition"" rel=""nofollow"">says</a> that</p>&#xA;&#xA;<blockquote>&#xA;  <p>A cluster should only span nodes that are running the same service.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this case we have two different types of services. </p>&#xA;&#xA;<ul>&#xA;<li>""The same service"" means a top level service whose API is exposed to external services?</li>&#xA;<li>In Lagom 1 Microservice = 1 service with external API + n internal services?</li>&#xA;</ul>&#xA;&#xA;<p><strong>2. Lagom service consumes another Lagom service in a different cluster</strong></p>&#xA;&#xA;<p>The documentation <a href=""http://www.lagomframework.com/documentation/1.0.x/ServiceLocator.html#Integrating-with-external-Lagom-projects"" rel=""nofollow"">says</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Note that if the service you want to communicate with is actually a Lagom service, you may want to read the documentation for <a href=""http://www.lagomframework.com/documentation/1.0.x/MultipleBuilds.html"" rel=""nofollow"">integrating with an external Lagom projects</a>.</p>&#xA;</blockquote>&#xA;&#xA;<p>Why is only configured the dependency to the service API and not the IP and port of the external Lagom service also?</p>&#xA;&#xA;<p><strong>3. Lagom service consumes an external non-Lagom service</strong></p>&#xA;&#xA;<blockquote>&#xA;  <p>The first thing you will have to do is to register each external&#xA;  service in the Service Locator. Assume we want to register an external&#xA;  service named weather that is running on <a href=""http://localhost:3333"" rel=""nofollow"">http://localhost:3333</a>, here&#xA;  is what we would add to the build:</p>&#xA;&#xA;<pre><code> lagomUnmanagedServices in ThisBuild := Map(""weather"" -&gt; ""http://localhost:3333"")&#xA;</code></pre>&#xA;</blockquote>&#xA;&#xA;<p>What is the contract with that IP? What should be behind it?</p>&#xA;&#xA;<p><strong>4. An external non-Lagom service consumes a Lagom service</strong></p>&#xA;&#xA;<p>I have to use the <a href=""http://microservices.io/patterns/3rd-party-registration.html"" rel=""nofollow"">Third-Party Registration Pattern</a> until Lagom support the <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow"">self registration pattern</a>?</p>&#xA;"
34841789,microservices & service discovery with random ports,2016-01-17 18:09:16,<docker><microservices><service-discovery><consul>,3,598,0,3.0,2,"<p>My question is related to microservices &amp; service discovery of a service which is spread between several hosts.</p>&#xA;&#xA;<p>The setup is as follows:</p>&#xA;&#xA;<ul>&#xA;<li>2 docker hosts (host A &amp; host B)</li>&#xA;<li>a Consul server (service discovery)</li>&#xA;</ul>&#xA;&#xA;<p>Let’s say that I have 2 services: </p>&#xA;&#xA;<ul>&#xA;<li>service A</li>&#xA;<li>service B</li>&#xA;</ul>&#xA;&#xA;<p>Service B is deployed 10 times (with random ports): 5 times on host A and 5 times on host B.</p>&#xA;&#xA;<p>When service A communicates with service B, for example,  it sends a request to serviceB.example.com (hard coded).</p>&#xA;&#xA;<p>In order to get an IP and a port, service A should query the Consul server for an SRV record.</p>&#xA;&#xA;<p>It will get 10 ip:port pairs, for which the client should apply some load-balancing logic.</p>&#xA;&#xA;<ul>&#xA;<li>Is there a simpler way to handle this without me developing a client resolver (+LB) library for that matter ? </li>&#xA;<li>Is there anything like that already implemented somewhere ?</li>&#xA;<li>Am I doing it all wrong ?</li>&#xA;</ul>&#xA;"
34973135,Service Fabric Service vs. Service Fabric Actors for user representation,2016-01-24 07:06:53,<c#><.net><microservices><azure-service-fabric>,1,1445,0,0.0,2,"<p>In my application users can post events on a map. The entry point of the application is a stateless web api service. For representing the users internally, I want to have an user service. When should I use Reliable Stateful Actors and when Reliable Stateful Services to store the profile data and the posted events of each user? </p>&#xA;&#xA;<p>When a client creates a new user at the frontend, the actor or service should create a new user internally. And every time the user is logged in, the web api service should forward all user interactions to the internally representation of the user (Actor or Service). E.g. the user post a new event, the web api service find the user and forward the posted event to him. Because the posted event is public, I also want to have an reliable stateful event service. After storing the posted event inside the user, the user service should forward the event to the event service. </p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<pre><code>Client/User --&gt; WebApiService --&gt; UserService/UserActor --&gt; EventService&#xA;</code></pre>&#xA;&#xA;<p>And when a user want to see all the public events on a map the should be something like this: </p>&#xA;&#xA;<pre><code>Client/User &lt;-- WebApiService &lt;-- EventService&#xA;</code></pre>&#xA;&#xA;<p>Because the events have a geo reference, I want to partition the EventService based on geocodes or something like that. </p>&#xA;&#xA;<p>Which programming model (actor and/or service) should I prefer for such an application and why?</p>&#xA;"
34774290,Implications of implementing a microservice architecture,2016-01-13 18:26:26,<amazon-web-services><architecture><spring-boot><licensing><microservices>,2,598,1,1.0,2,"<p>I'm starting out on the journey of learning/implementing microservice architecture for the first time and I have some questions related to the implications that has.</p>&#xA;&#xA;<p>For some background, the techstack I intend on using is in a very over-arching sense is dockerized spring-boot microservices running on AWS. </p>&#xA;&#xA;<p>So what I want to know is...</p>&#xA;&#xA;<p>Firstly, given that each microservice is supposed to be full stack including separate databases does this mean I need 3 separate instances of whatever database I choose runnning? I'm guessing the answer is yes. So, I guess my real question is, isn't this consuming a lot more hardware resources than a monolithic application with a single database? Databases are pretty memory hungry...</p>&#xA;&#xA;<p>Not only that but the full amount of ram required for running a single spring-boot application will be required 5 times over if I'm running 5 microservices right? It seems to me this would require far, far more ram than the monolithic application, correct?</p>&#xA;&#xA;<p>What about if you are using Oracle as a database? What implications does it have for licencing? Wouldn't it get crazy expensive if you need a separate database for each microservice?</p>&#xA;&#xA;<p>Are there any other licencing pitfalls to consider? Or any other pitfalls of MSA in general that one should consider/be aware of before starting out on this journey?</p>&#xA;&#xA;<p>Edit:&#xA;Also, given each microservice is full-stack, what if I want a consist looking front-end for each of them (where a microservice requires a front-end)? I haven't seen any good advice around this. Especially given (if they are so called '12 factor') the codebase is supposed to be in separate repository for each microservice. How is this best managed/achieved?</p>&#xA;"
50702676,How to solve two generals issue between event store and persistence layer?,2018-06-05 14:31:34,<microservices><distributed-system><event-store>,3,50,2,0.0,2,"<p><strong>Two General Problems - EventStore and persistence layer?</strong></p>&#xA;&#xA;<p>I would like to understand how industry is actually dealing with this problems! </p>&#xA;&#xA;<p>If a microservice 1 persists object X into Database A. In the same time, for micro-service 2 to feed on the data from micro-service 1, micro-service 1 writes the same object X to an event store B. </p>&#xA;&#xA;<p>Now, the question I have is, where do I write object X first? </p>&#xA;&#xA;<ol>&#xA;<li><p>Database A first and then to event store B, is it fair to roll back the thread at the app level if Database A is down? Also, what should be the ideal error handle if Database A is online and persisted object X but event store B is down?</p></li>&#xA;<li><p>What should be the error handle look like if we go vice-versa of point 1?</p></li>&#xA;</ol>&#xA;&#xA;<p>I do understand that in today's world of distributed high-available systems, systems going down is questionable thing. But, it can happen. I want to understand what needs to be done when either database or event store system/cluster is down?</p>&#xA;"
31845342,How does Spring Cloud Config download remote configurations for a service?,2015-08-06 01:24:32,<spring-boot><spring-cloud><microservices>,1,866,3,0.0,2,"<p>I have found this <a href=""https://github.com/kbastani/spring-cloud-microservice-example"" rel=""nofollow"">example</a> about spring-cloud on GitHub a few days ago.</p>&#xA;&#xA;<p>I am having some problems getting the config service example working. I don't know how to use <code>config-microservice</code> correctly.</p>&#xA;&#xA;<p><a href=""http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html?mkt_tok=3RkMMJWWfF9wsRonuqTMZKXonjHpfsX57ukoWaC0lMI%2F0ER3fOvrPUfGjI4ATcdqI%2BSLDwEYGJlv6SgFQ7LMMaZq1rgMXBk%3D"" rel=""nofollow"">in this blog</a>,it said configurations for your microservice applications should be stored in the environment and not in the project.</p>&#xA;&#xA;<p>But I'm not sure how to do this. I don't know how one of the microservices, for instance a <code>movie-microservice</code> Spring Boot application gets a config file from <code>config-service</code>.</p>&#xA;"
38049329,"DDD, Microservices and data direction",2016-06-27 08:39:06,<domain-driven-design><microservices>,2,170,3,1.0,2,"<p>Let's assume I have Identity Management bounded context and discussion bounded context. Each of those is a separate micro service.</p>&#xA;&#xA;<p>Identity has Users, Discussion has Moderators.</p>&#xA;&#xA;<p>If I update first and last name in the Identity bounded context, my plan is to publish a message to Amazon SQS, and have discussion bounded context to listen that queue for any changes, and update first and last name in discussion context via Anti-Corruption layer.</p>&#xA;&#xA;<p>My question is, what if I decide to change first name and last name in the Discussion BC? Should my Identity BS listen for that changes too, or having bi-directional communication is not considered a good practice, and I should always update that information inside Identity BC?</p>&#xA;"
38230495,Zuul spring security and adding Additional Params in Request,2016-07-06 17:48:01,<spring><spring-cloud><microservices><netflix-zuul><spring-cloud-netflix>,1,1545,7,0.0,2,"<p>I am building Microservices using Spring Microservices, I have 2 questions related to that.<br><br>1. I have spring security in the Api Gateway i.e <strong>Zuul server</strong>, now Zuul is not forwarding any request if I have already read the request from the stream once to Authenticate(to get username/pass from POST Request) <br>&#xA;<code>new ObjectMapper().readValue(request.getInputStream(), UserDto.class);</code> &#xA;<br><strong>How can I read the request and then again forward the same request to Downstream services?</strong><br><br>&#xA;2. Zuul is not forwarding <strong>request.setAttribute()</strong> to Downstream services, so a workaround is to use <strong>ctx.addZuulRequestHeader</strong>, which is making <code>Request Header</code> too huge, How can I acheive <strong>request.setAttribute</strong> and get in downstream services.</p>&#xA;&#xA;<pre><code> public Authentication getAuthentication(HttpServletRequest request) {&#xA;    final String token = request.getHeader(AUTH_HEADER_NAME);&#xA;    logger.info(""token=""+token);&#xA;    if (token != null) {&#xA;        logger.info(""Entering getAuthentication"");&#xA;        final UserToken userInfo = tokenHandler.validateToken(token);&#xA;        if (userInfo != null&#xA;                &amp;&amp; token.equals(String.valueOf(redisUtility.getValue(userInfo.getUsername()+""_""+userInfo.getUniqueId())))) {&#xA;            logger.info(""Validating token key=""+userInfo.getUsername()+""_""+userInfo.getUniqueId());&#xA;            User user=userDetailsService.loadUserByUsername(userInfo.getUsername());&#xA;            if(user!=null &amp;&amp; user.getUsername().equals(userInfo.getUsername())&#xA;                &amp;&amp; user.getLastPasswordResetTime()&lt;userInfo.getCreatedTime()){&#xA;                request.setAttribute(""username"",user.getUsername());//**Not able to fetch this in Downstream services**&#xA;                logger.info(""Token Authenticated for User ""+user.getUsername());&#xA;                return new UserAuthentication(user);&#xA;            }&#xA;        } &#xA;    }&#xA;    return null;&#xA;}&#xA;&#xA;&#xA;  public class SimpleFilter extends ZuulFilter {&#xA;&#xA;      private static Logger log = LoggerFactory.getLogger(SimpleFilter.class);&#xA;&#xA;      @Override&#xA;      public String filterType() {&#xA;        return ""pre"";&#xA;      }&#xA;&#xA;      @Override&#xA;      public int filterOrder() {&#xA;        return 1;&#xA;      }&#xA;&#xA;      @Override&#xA;      public boolean shouldFilter() {&#xA;        return true;&#xA;      }&#xA;&#xA;      @Override&#xA;      public Object run() {&#xA;        RequestContext ctx = RequestContext.getCurrentContext();&#xA;        HttpServletRequest request = ctx.getRequest();&#xA;        request.setAttribute(""test"", ""test"");// Not able to get this in services&#xA;        log.info(String.format(""%s request to %s"", request.getMethod(), request.getRequestURL().toString()));&#xA;&#xA;        return null;&#xA;      }&#xA;&#xA; @Bean&#xA;  public SimpleFilter simpleFilter() {&#xA;    return new SimpleFilter();&#xA;  }&#xA;&#xA;@RequestMapping(value = ""/test/avl"",method=RequestMethod.POST)&#xA;  public String test(HttpServletRequest request) {&#xA;    System.out.println(request.getAttribute(""test"")+"""");&#xA;    return ""Spring in Action"";&#xA;  }&#xA;</code></pre>&#xA;"
39891218,Setting up development environment in micro-services architecture,2016-10-06 08:30:12,<microservices><gateway>,1,365,4,0.0,2,<p>We are moving towards developing a web app in a micro-services architecture.<br>&#xA;We thought about running the services behind a API gateway that will handle authentication and will proxy the requests to the appropriate services.<br>&#xA;We have encountered a problem while setting up the development environment. How can we develop a service in a local machine (laptop) and test and run it in a way that is similar to the production (behind the gateway)?</p>&#xA;&#xA;<p>Consider the following requirements:</p>&#xA;&#xA;<ul>&#xA;<li>Inter process communication (B2B)</li>&#xA;<li>Manage and sync different versions</li>&#xA;<li>Access the service with authentication token (produced by the gateway)</li>&#xA;</ul>&#xA;
49531349,Request Caching with Circuit-Breaker(Opossum) in nodejs,2018-03-28 09:50:53,<javascript><node.js><microservices><hystrix><circuit-breaker>,1,149,3,0.0,2,"<p>Based on the Netflix Hystrix circuit-breaker design pattern i was trying to do the following:</p>&#xA;&#xA;<pre><code>const circuitBreaker = require('opossum');&#xA;import * as request from 'request-promise';&#xA;&#xA;const circuit = circuitBreaker(request.get);&#xA;&#xA;circuit.fallback(() =&gt; Promise.resolve({result:[]}));&#xA;</code></pre>&#xA;&#xA;<p>I have 3 node js services deployed . They use a circuit-breaker(opossum) to make REST Calls in between them. I have a fallback method which handles the scenario when a service goes down. I was wondering if something like request-caching can be used alongside the circuit breaker to return cached response  whenever the fallback is invoked. If yes, how can i achieve this ?</p>&#xA;&#xA;<p>P.S : <strong>request is my client to make REST calls</strong></p>&#xA;"
38922420,Microservices configuration server,2016-08-12 16:15:18,<microservices>,1,605,0,1.0,2,"<p>It's well understood that in a microservices architecture, configuration must be externalized. </p>&#xA;&#xA;<p>Tools like zookeeper, etcd or consul are excellent options to store that configuration. However a new layer on top of those services is required in order to provide new functionalities that are fundamental in a configuration server. Ex. versioning; change history; ""draft"" / published configuration, etc...</p>&#xA;&#xA;<p>I've found <a href=""https://github.com/spring-cloud/spring-cloud-config"" rel=""nofollow"">spring config server</a>, which is an interesting project and addresses all these concerns using git for handling the above mentioned requirements. However, I'd like avoid using git due to additional required setup. ex. replication, etc...</p>&#xA;&#xA;<p>Do you know any other options other then spring config server?</p>&#xA;"
51149979,Microservicess with Serverless (Lambda or Function),2018-07-03 08:30:31,<azure><lambda><microservices><azure-functions>,2,61,0,2.0,2,"<p>I have some concern on getting an idea of migrating current microservices system into serverless.</p>&#xA;&#xA;<p>Right now, between services are communicating with HTTP or API based.&#xA;Serverless like lambda or function can talk to each other with function call or lambda call. This way can be done by changing all HTTP code into lambda call within all services.</p>&#xA;&#xA;<p>Another way is still using HTTP request to call another service that on lambda through API Gateway. This method of calling is not good because the service request gone to Internet and go back again into API Gateway then neighbor service get the request. Too long and does not make sense for me.</p>&#xA;&#xA;<p>I will be glad if lambda app call another lambda app with local network HTTP request, this is still on my research on how to do it.</p>&#xA;&#xA;<p>I would like to know from all of you about your experience on migrating microservices based on HTTP communication between services into serverless like Lambda or Functions ?</p>&#xA;&#xA;<p>Do you change all your code into specific lambda function call ?&#xA;Do you use HTTP over internet and API Gateway again to call neighbor service ?&#xA;Have you guys figured it out on Local / Private network lambda call ?</p>&#xA;&#xA;<p>Thank You</p>&#xA;"
51189616,How can I proceed a delete operation in Lagom Framework?,2018-07-05 10:59:14,<java><scala><akka><microservices><lagom>,2,79,4,0.0,2,"<p>I am a little newbie on the Lagom framework and I need to know what the right way to do a delete operation in this framework. I develop with Java and I tested two approaches:</p>&#xA;&#xA;<ol>&#xA;<li>when I handle the delete event I set the state to Optional.empty () but it returns nullPointerException crashes and the line in my readSide (Cassandra DataBase) is not deleted</li>&#xA;<li>I add a Status field to my entity and when I handle the delete event I pass it to -1. When I refer to my entity I test on State.present and status! = -1 to make sure the entity and deleted. For the readSide, the line is deleted properly</li>&#xA;</ol>&#xA;&#xA;<p>In terms of logic, I think the second approach is the most logical but I want to know if there is a good practice that the Lagom framework offers developers to do delete operations</p>&#xA;&#xA;<p><strong>EDIT 1</strong>&#xA;This is my ReadSideHandler code, how can I proceed to handle properly the empty option</p>&#xA;&#xA;<pre><code>@Override&#xA;public ReadSideHandler&lt;AuthenticationEvent&gt; buildHandler() {&#xA;    return readSide.&lt;AuthenticationEvent&gt;builder(""authenticationEventOffset"")&#xA;            .setGlobalPrepare(this::createTables)&#xA;            .setPrepare(tag -&gt; prepareStatements())&#xA;            .setEventHandler(AuthenticationLoginEvent.class,&#xA;                    e -&gt; insertAuthentication(e.getAuthentication()))&#xA;            .setEventHandler(AuthenticationLogoutEvent.class, e -&gt; deleteAuthentication(e.getAccessToken()))&#xA;            .build();&#xA;}&#xA;</code></pre>&#xA;"
46807757,Service discovery on aws ECS with Application Load Balancer,2017-10-18 10:11:46,<amazon-web-services><microservices>,2,1616,0,1.0,2,"<p>I would like to ask you if you have an microservice architecture (based on Spring Boot) involving Amazon Elastic Container Service (ECS) with Application Load Balancer(ALB), service discovery is performed automatically by the platform, or do you need a special mechanism (such as Eureka or Consul)?</p>&#xA;&#xA;<p>From the documentation (ECS and ALB) is not clear you have this feature provided.</p>&#xA;"
38511443,AWS Pub/Sub Message Pattern,2016-07-21 18:09:32,<amazon-web-services><aws-lambda><amazon-sqs><microservices>,2,1848,0,0.0,2,"<p>Can someone explain to me the advantage or disadvantage of using SNS -> Lambda  vs. SNS -> SQS -> Lambda.</p>&#xA;&#xA;<p>I'm looking to setup an architecture for pub/sub micro-service messaging, but having a queue in front of every Lambda seems excessive.</p>&#xA;"
38629740,How to implement security for my Microservices with Spring?,2016-07-28 07:28:20,<spring-security><spring-boot><spring-cloud><microservices><spring-cloud-netflix>,1,221,0,2.0,2,"<p>We have one monolithic application having more than 10 services like user management, fleet booking, feedback and etc developed on spring rest.</p>&#xA;&#xA;<p>We want to migrate to Microservices(Spring Boot + Cloud + Netflix OSS).</p>&#xA;&#xA;<p>Below are my questions :&#xA;How can we implement security for all our rest services (with own user database)?&#xA;How to implement api gateway from security stand point ?</p>&#xA;"
38480000,Service Fabric Nested Applications,2016-07-20 11:26:37,<deployment><configuration><microservices><azure-service-fabric>,1,195,6,0.0,2,"<p>I am trying to re-architect our current monolithic web application into a more modular (micro-service) style design.</p>&#xA;&#xA;<p>I have a good idea of the boundaries and a plan on how to build it...</p>&#xA;&#xA;<p>Each part of the app will have it's own domain package, a backing rest api, and a web front-end for managing the data. Plus other stuff like unit tests and possibly a connection helper library, etc.</p>&#xA;&#xA;<p>For argument's sake, say my monolithic app has 3 main components (modules):</p>&#xA;&#xA;<ol>&#xA;<li>An accounts module for creating and managing users</li>&#xA;<li>A Products module for administering and managing the product&#xA;catalog</li>&#xA;<li>An Orders module for creating, viewing and amending orders.</li>&#xA;</ol>&#xA;&#xA;<p>In the monolithic app these are all part of the same application (and VS solution and project) and usually have distinct controllers configured using MVC / WebApi Etc:</p>&#xA;&#xA;<pre><code>// MyApp.Web Project (base url ~/)&#xA;myapp.com/...&#xA;myapp.com/accounts/...&#xA;myapp.com/products/...&#xA;myapp.com/orders/...&#xA;&#xA;// MyApp.Api Project (base url ~/api)&#xA;myapp.com/api/...&#xA;myapp.com/api/accounts/...&#xA;myapp.com/api/products/...&#xA;myapp.com/api/orders/...&#xA;</code></pre>&#xA;&#xA;<p>Currently we host this in IIS using nested applications and virtual folders but I want to replicate this sort of idea or structure using a service fabric cluster. But each isolated area (accounts, products, orders) will be developed and deployed independently of one another.</p>&#xA;&#xA;<p><strong>How do I configure service fabric cluster to enable this type of situation?</strong></p>&#xA;&#xA;<p>For instance if I have a cluster of 50 nodes and on those 50 nodes I have instances spread out of each service and the service's api. How do I say:</p>&#xA;&#xA;<pre><code>v2.myapp.com/accounts --&gt; any available accounts web UI instance?&#xA;v2.myapp.com/products --&gt; any available products web UI instance?&#xA;v2.myapp.com/api/products --&gt; any available products api instance?&#xA;</code></pre>&#xA;&#xA;<p>Should I have VM Scale Sets for web and api or one for each component too, like VM Scale Sets for just products api and another for orders web UI, etc?</p>&#xA;&#xA;<p>Also please note that our system is BIG so there are lots of components, hence the reason for splitting out the monolithic style, so I need a consistent structure to enable all this.</p>&#xA;&#xA;<p>We have major scaleability issues and very slow (manual) virtual server provisioning. Plus a single monolithic SQl Server database. The features of SF I want is modular design, easy provisioning and deployment and a drastic increase in response times and throughput of our system. And of course good failover.</p>&#xA;&#xA;<p>At the end of the day I want customers to see a consistent url structure but under the covers I want to be able to have it all separate and working together over many nodes.</p>&#xA;&#xA;<p>Thanks in advance.<br>&#xA;Any help on how to configure this is very much appreciated.</p>&#xA;&#xA;<p>G.</p>&#xA;"
44939302,"*** process.env.ENV is not defined, assuming 'prod' env",2017-07-06 03:28:00,<angularjs><environment-variables><jhipster><microservices><gateway>,1,632,0,0.0,2,"<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in <code>application-dev.yml</code>) and&#xA;Getting following exception in console</p>&#xA;&#xA;<pre><code>*** process.env.ENV is not defined, assuming 'prod' env&#xA;</code></pre>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is given by yarn) and giving exception like below in console.</p>&#xA;&#xA;<pre><code>process.env.ENV is not defined, assuming 'prod' env&#xA;chrome-extension://kbfnbcaeplbcioakkpcpgfkobkghlhen/src/js/bundle.js:4776 *** &#xA;</code></pre>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other microservices applications.</p>&#xA;&#xA;<p>Why am I getting the above exception?</p>&#xA;"
44540545,Microservices. What is difference between Service registry and service discovery,2017-06-14 09:18:44,<microservices><service-discovery>,1,2488,0,0.0,2,"<p>I am new to Microservice. I cam e across term  Service registry and service discovery. &#xA;What I understood is when a new service(or service instance comes up) then it will register itself with ""service registry"". It is also mentioned that client can contact service registry and get the list of IP-port where that service is available.  </p>&#xA;&#xA;<p>In that case what is the role of ""service discovery"". </p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>Accepted answer. Also more theoretical details were found <a href=""https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/</a></p>&#xA;"
44619634,What is the best way to run multiple services that use Socket.io,2017-06-18 21:19:51,<node.js><sockets><websocket><socket.io><microservices>,2,604,1,1.0,2,"<p>I am developing a website where I will use microservices.</p>&#xA;&#xA;<p>I will have a couple or more Node.js application that will use Socket.io.</p>&#xA;&#xA;<p>I was trying to figure out how I will architecture this.</p>&#xA;&#xA;<p>Can I use multiple Node.js with Socket.io connecting to a user or will I run into conflicts? I can use NGiNX as a proxy a an UUID to identify which microservice to send the request to. Does that make sens? Is there a better way?</p>&#xA;&#xA;<p>Or I was also thinking of using a Node.js has a proxy that receives all the Socket.io connection and then it creates a connection with the user. But this seems to be adding to the network load because I am adding a another microservice.</p>&#xA;&#xA;<p>Anyways, I would love your views on this.</p>&#xA;"
37684053,"Docker, connection refused for every other running services",2016-06-07 15:55:56,<ruby-on-rails><port><docker-compose><microservices>,1,615,0,0.0,2,"<p>My local installation of docker cannot access to other ports.</p>&#xA;&#xA;<p>This is my <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<pre><code>db:&#xA;  image: library/mysql:5.6&#xA;  environment:&#xA;    MYSQL_ALLOW_EMPTY_PASSWORD: ""yes""&#xA;  expose:&#xA;    - ""3306""&#xA;  ports:&#xA;    - ""3306:3306""&#xA;&#xA;mailcatcher:&#xA;  image: yappabe/mailcatcher&#xA;  ports:&#xA;    - ""1025:1025""&#xA;    - ""1080:1080""&#xA;&#xA;rails-app:&#xA;  build: .&#xA;  dockerfile: ""Dockerfile""&#xA;  environment:&#xA;    RAILS_ENV: development&#xA;  links:&#xA;    - mailcatcher&#xA;    - db&#xA;  command: bundle exec rails server -p 3005 -b '0.0.0.0'&#xA;  volumes:&#xA;    - "".:/home/app""&#xA;  volumes_from:&#xA;    - bundle&#xA;  expose:&#xA;    - ""3005""&#xA;  ports:&#xA;    - ""3005:3005""&#xA;</code></pre>&#xA;&#xA;<p>This is the config for mailcatcher <code>config/environments/development.rb</code>:</p>&#xA;&#xA;<pre><code>config.action_mailer.delivery_method = :smtp&#xA;config.action_mailer.smtp_settings = { address: ""localhost"", port: 1025 }&#xA;</code></pre>&#xA;&#xA;<p>This is how I run the rails app:</p>&#xA;&#xA;<pre><code>docker-compose run --service-ports rails-app&#xA;</code></pre>&#xA;&#xA;<p>This is what I see when running <code>docker ps</code>:</p>&#xA;&#xA;<pre><code>&gt; docker ps&#xA;CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                                            NAMES&#xA;1fa8ac2ad8fd        pmt_rails-app          ""bundle exec rails se""   5 seconds ago       Up 3 seconds        0.0.0.0:3005-&gt;3005/tcp                           pmt_rails-app_run_1&#xA;4f65bb2fc9ac        yappabe/mailcatcher    ""/run.sh""                About an hour ago   Up About an hour    0.0.0.0:1025-&gt;1025/tcp, 0.0.0.0:1080-&gt;1080/tcp   pmt_mailcatcher_1&#xA;cfb364ee569f        library/mysql:5.6      ""docker-entrypoint.sh""   About an hour ago   Up About an hour    0.0.0.0:3306-&gt;3306/tcp                           pmt_db_1&#xA;</code></pre>&#xA;&#xA;<p>This is what I get when rails app tries to send an email:</p>&#xA;&#xA;<pre><code>Errno::ECONNREFUSED: Connection refused - connect(2) for ""localhost"" port 1025&#xA;from /usr/local/lib/ruby/2.3.0/net/smtp.rb:542:in `initialize'&#xA;</code></pre>&#xA;&#xA;<p>I get the same error when I try to connect with another <code>rails server</code> that is running in another port.</p>&#xA;&#xA;<p>I am working with Docker-beta in a Mac OSX.</p>&#xA;"
44802594,Refused connection to RabbitMQ when using docker link,2017-06-28 12:34:43,<asp.net-core><rabbitmq><docker-compose><microservices>,1,800,6,0.0,2,"<p>I have a microservices application which has two services and a rabbit mq used as a message queue for communication between them. Now, I want to deploy them on docker. I have the following code in the <code>docker-compose.yml</code> file:</p>&#xA;&#xA;<p>version: ""3""&#xA;services:</p>&#xA;&#xA;<pre><code>  rabbitmq:&#xA;    build: ./Rabbit&#xA;    hostname: ""rabbitmq""&#xA;    container_name: ""rabbitmq""&#xA;    environment:&#xA;      RABBITMQ_ERLANG_COOKIE: ""cookie""&#xA;      RABBITMQ_DEFAULT_USER: ""user""&#xA;      RABBITMQ_DEFAULT_PASS: ""pass""&#xA;      RABBITMQ_DEFAULT_VHOST: ""/""&#xA;    ports:&#xA;      - ""15672:15672""&#xA;      - ""5672:5672""&#xA;    # labels:&#xA;    #   NAME: ""rabbit1""&#xA;    volumes:&#xA;    - ""/opt/rabbitmq:/var/lib/rabbitmq""&#xA;&#xA;  service1:&#xA;    build: ./service1&#xA;    deploy:&#xA;      replicas: 5&#xA;      restart_policy:&#xA;        condition: on-failure&#xA;      resources:&#xA;        limits:&#xA;          cpus: ""0.1""&#xA;          memory: 50M&#xA;    ports:&#xA;      - ""8181:80""&#xA;    depends_on:&#xA;      - rabbitmq&#xA;    links:&#xA;     - rabbitmq&#xA;    networks:&#xA;      - webnet&#xA;</code></pre>&#xA;&#xA;<p>So, here I build the RabbitMQ image in a container and then link this container to the container of <code>service1</code>. Since <code>service1</code> one is an ASP.NET Core Web API, I use the following setup to connect to the message queue:</p>&#xA;&#xA;<pre><code>//Establish the connection&#xA;            var factory = new ConnectionFactory&#xA;            {&#xA;                HostName = ""rabbitmq"",&#xA;                Port = 5672,&#xA;                UserName = ""user"",&#xA;                Password = ""pass"",&#xA;                VirtualHost = ""/"",&#xA;                AutomaticRecoveryEnabled = true,&#xA;                NetworkRecoveryInterval = TimeSpan.FromSeconds(15)&#xA;            };&#xA;</code></pre>&#xA;&#xA;<p>But when I try to run <code>docker-compose up</code>, I receive the following error message:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Unhandled Exception:&#xA;  RabbitMQ.Client.Exceptions.BrokerUnreachableException: None of the&#xA;  specified endpoints were reachable --->&#xA;  RabbitMQ.Client.Exceptions.ConnectFailureException: Connection failed&#xA;  ---> System.Net.Internals.SocketExceptionFactory+ExtendedSocketException:&#xA;  No such device or address</p>&#xA;</blockquote>&#xA;&#xA;<p>Maybe I have a mistake in the <code>HostName</code> but I am not sure how to correct it.</p>&#xA;"
48370641,Microservice internal communication,2018-01-21 19:09:30,<microservices>,4,347,3,1.0,2,"<p>I've been reading up on Microservice Architecture But I still can't understand the inter-microservices communication mechanism.<br>&#xA;In many articles they said that microservices are usually exposed over a RESTful API. But when you search the internet you always see implementations based on messaging and events for the backend communications.<br><br>&#xA;So I'm confused, Is REST API a standard for all the microservices or we can see microservices without a REST endpoints.</p>&#xA;"
44181863,Difference between Microservices and load balancer?,2017-05-25 13:30:39,<load-balancing><microservices>,2,636,2,0.0,2,"<p>I'm fairly new to the realm of microservices but know basics about load balancing. I recently read an article about the microservices: <a href=""https://aadrake.com/posts/2017-05-20-enough-with-the-microservices.html"" rel=""nofollow noreferrer"">Enough with the microservices</a>.    </p>&#xA;&#xA;<p>There it's mentioned that both the microservices and load balancers have clusters/different VM's for deploying many copies of application but in the case of microservices, we have a <strong>separate database</strong> in contrast to load balancers which backs a single database. Is it the only difference between them?</p>&#xA;&#xA;<p>Here's the quoted text:</p>&#xA;&#xA;<blockquote>&#xA;  <p>""multiple copies of the same microservice can be deployed in order to&#xA;  achieve a form of scalability. However, most companies that adopt&#xA;  microservices too early will use the same storage subsystem (most&#xA;  often a database) to back all of their microservices. What that means&#xA;  is that you don’t really have horizontal scalability for your&#xA;  application, only for your service. If this is the scalability method&#xA;  you plan to use, why not just deploy more copies of your monolith&#xA;  behind a load balancer? You’ll accomplish the same goal with less&#xA;  complexity.""</p>&#xA;</blockquote>&#xA;"
35751630,Spring-cloud Zuul retry when instance is down,2016-03-02 15:36:12,<spring><spring-cloud><microservices><netflix-eureka><netflix-zuul>,2,1841,10,2.0,2,"<p>Using Spring-cloud Angel.SR6:</p>&#xA;&#xA;<p>Here is the configuration of my Spring-boot app with @EnableZuulProxy:</p>&#xA;&#xA;<pre><code>server.port=8765&#xA;&#xA;ribbon.ConnectTimeout=500&#xA;ribbon.ReadTimeout=5000&#xA;ribbon.MaxAutoRetries=1&#xA;ribbon.MaxAutoRetriesNextServer=1&#xA;ribbon.OkToRetryOnAllOperations=true&#xA;&#xA;zuul.routes.service-id.retryable=true&#xA;</code></pre>&#xA;&#xA;<p>I have 2 instances of <code>service-id</code> running on random ports.  These instances, as well as the Zuul instance, successfully register with Eureka, and I can access RESTful endpoints on the 2 <code>service-id</code> instances by accessing <a href=""http://localhost:8765/service-id/"" rel=""nofollow"">http://localhost:8765/service-id/</a>.... and find that they are balanced in a round-robin manner.</p>&#xA;&#xA;<p>I would like to kill one of the <code>service-id</code> instances and, when that defunct instance is next in line for forwarding, have Zuul attempt to contact it, fail, and retry with the other instance.  </p>&#xA;&#xA;<p>Is this possible, or am I misreading the documentation?  When I try the above config, the request 'destined' for the defunct instance fails with a 500 Forwarding error.  From the Zuul stacktrace: </p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:140)&#xA;&#xA;....&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-idRibbonCommand timed-out and no fallback available&#xA;</code></pre>&#xA;&#xA;<p>The subsequent request succeeds as expected.  This behavior continues until the defunct instance is removed from Zuul's registry.</p>&#xA;&#xA;<p><strong>EDIT:</strong> Updated to Brixton.M5.  No change in behavior.  Here's the Hystrix exception in more detail:</p>&#xA;&#xA;<pre><code>Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: service-id timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$DeprecatedOnFallbackHookApplication$1.onError(AbstractCommand.java:1521) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$FallbackHookApplication$1.onError(AbstractCommand.java:1411) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:314) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:306) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:162) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable$2.call(Observable.java:154) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.Observable.unsafeSubscribe(Observable.java:7710) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:100) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$1.run(AbstractCommand.java:958) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$2.tick(AbstractCommand.java:978) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.util.HystrixTimer$1.run(HystrixTimer.java:100) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_66]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    ... 1 common frames omitted&#xA;&#xA;Caused by: java.util.concurrent.TimeoutException: null&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:601) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$9.call(AbstractCommand.java:581) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    ... 15 common frames omitted&#xA;</code></pre>&#xA;"
40960054,"Service Fabric, What Microservices is best intended for continuous polling from Service Bus",2016-12-04 15:12:29,<c#><azure><microservices><azureservicebus><azure-service-fabric>,3,1421,2,1.0,2,"<p>I am new to Service Fabric.</p>&#xA;&#xA;<p>We have a queue on Azure Service Bus. I want to continuously pull from the queue in my Service Fabric, process the message (execute some business logic) and save some data in the DB, then remove the message from the queue.</p>&#xA;&#xA;<p>The Microservice should check the queue every couple of seconds to monitor for a new message.</p>&#xA;&#xA;<p>My question is, <strong>What is the intended Microservice(s) that would pull data, process some business logic, then save to the DB. Is it A Stateless Service or a Reliable Actor</strong></p>&#xA;"
40807355,Scheduled messages with RabbitMQ,2016-11-25 14:39:26,<rabbitmq><message-queue><microservices>,2,2663,3,1.0,2,"<p>I'm looking for a solution to have scheduled messages with RabbitMQ, so not only delaying the messages as described in several sources but schedule it to have a message e.g. every day.</p>&#xA;&#xA;<p>If not RabbitMQ, any other solutions out there you can think of and you'd suggest for a microservices environment using a message-bus?&#xA;So it's really about combining the concept of a task-scheduler and a message bus ...</p>&#xA;&#xA;<p>Or is it better to use a job scheduler just to push messages to the message queue, e.g. using rundeck in combination with RabbitMQ?</p>&#xA;"
43927492,Microservices - Stubbing/Mocking,2017-05-12 00:15:48,<java><cloudfoundry><microservices>,5,926,2,0.0,2,"<p>I am developing a product using microservices and am running into a bit of an issue. In order to do any work, I need to have all 9 services running on my local development environment. I am using Cloud Foundry to run the applications, but when running locally I am just running the Spring Boot Jars themselves. Is there anyway to setup a more lightweight environment so that I don't need everything running? Ideally, I would only like to have the service I am currently working on to have to be real.</p>&#xA;"
43850359,Microservice Coupling,2017-05-08 14:32:40,<spring><architecture><cloud><microservices><coupling>,5,280,9,1.0,2,"<p>I'm building a new application with microservice concepts, but I don't know how to communicate with another microservice without coupling. Here is my scenario.</p>&#xA;&#xA;<p>I want to show a graphic bar about my sales but I have two microservices, the first one is the <strong>sales-service</strong> and the another one <strong>product-service</strong>. In this case I have to select the period I want to filter and then select the sales and after select the products from these sales, but I'm calling the product-service directly with REST and if my product-service going down fails every thing. What is the correct way to work in this scenario?</p>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/faHqp.jpg"" rel=""nofollow noreferrer"">Diagram of Architecture</a></p>&#xA;&#xA;<p>This is the architecture with some services. The problem is that sale-service has to communicate with others services to get some informations.</p>&#xA;&#xA;<p>We have a sales software in hundreds of client and this application recieves this data and we have a front-end that shows this informations. In this scenario, microservice is the best approatch?</p>&#xA;&#xA;<p>I'm using Spring Cloud.</p>&#xA;"
34439201,Java Spring will not talk to Consul when run as a Docker container,2015-12-23 15:46:51,<java><docker><spring-cloud><microservices><consul>,2,1970,1,1.0,2,"<p>I am trying to solve what I believe is a common use case for running micro services.  In this case I am testing consul with a spring cloud application. I am trying to test consul in two different ways.  The first of which is running in a docker container and the other is running on the docker host machine.  I am then attempting to start a spring cloud container that will talk with either consul example.</p>&#xA;&#xA;<p>I have been unable to make the spring cloud application talk to consul when the spring cloud application is run as a docker container.  When the spring cloud application is run with the host networking mode it works as it can resolve the localhost ports, but this is not an acceptable solution if I wish to run multiple instances of the image.  </p>&#xA;&#xA;<p>An example of my docker compose file when running both services as containers is shown below. Here I am attempting to set the consul uri in spring cloud through the environment variables, but have been unable to get it to work using a variety of configurations.  If anyone could point to an example of these functions working together that would be immensely helpful.</p>&#xA;&#xA;<pre><code> consul1:&#xA;  image: progrium/consul&#xA;  ports:&#xA;    - ""8400:8400""&#xA;    - ""8500:8500""&#xA;    - ""8600:53/udp""&#xA;    - ""8600:53/tcp""&#xA;  environment:&#xA;      GOMAXPROCS: 100&#xA;      entrypoint: ""/bin/consul""&#xA;      hostname: consul&#xA;      command: agent -log-level=debug -server -config-dir=/config -bootstrap -ui-dir /ui&#xA;&#xA;simpletest:&#xA;    build: simpletest&#xA;    hostname: simpletest&#xA;    environment:  &#xA;      JAVA_OPTS: ""-Xdebug -Xrunjdwp:server=y,transport=dt_socket,suspend=n -Dspring.cloud.consul.host=consul1""&#xA;    ports:&#xA;     - 39041:7051&#xA;     - 39052:7055&#xA;#     d2fdockerroot_consul1_1 consul&#xA;#    links:&#xA;#     - consul1&#xA;</code></pre>&#xA;"
52051459,"Jhipster - unable to Use a Gateway app when deploying everything on docker host except the Gateway itself, Mixed Docker and locally deployment",2018-08-28 06:30:31,<docker><microservices><jhipster><keycloak><gateway>,1,31,0,2.0,2,"<p>I have some JHipster Spring Microservice and gateway projects. I deployed all of them on a host using docker except the gateway. I started the gateway on another host.</p>&#xA;&#xA;<p>I use Keycloak for OAuth authentication.</p>&#xA;&#xA;<p>Everything works fine when i deploy all of the microservices and databases and Gateways as docker containers on a docker network using docker-compose.</p>&#xA;&#xA;<p>But it doesn't work when i just deploy everything on docker except the gateway.i mean if the gateway resides outside of docker-created network. the motivation for this action is that I just want my UI programmer to up and run the gateway on his own PC, and use microservices which are deployed on server host. Just for ease of UI development in need to up and run this sole gateway using <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>I used a technique to assign a separate IP to each container on my docker network. This technique is called Docker MacVLan networking. so that every container in the host have a separate IP address in physical network and each of these containers are visible on other hosts in the network.</p>&#xA;&#xA;<p>the problem is that in normal docker deployment (when gateway is deployed in a docker network in same host) everything works fine. but in my scenario after successful login, every microservice return <code>error 401</code>.</p>&#xA;&#xA;<p>in microservice it says this error:</p>&#xA;&#xA;<pre><code>o.s.s.oauth2.client.OAuth2RestTemplate   : Setting request Accept header to [application/json, application/x-jackson-smile, application/cbor, application/*+json]&#xA;o.s.s.oauth2.client.OAuth2RestTemplate   : GET request for ""http://keycloak:9080/auth/realms/jhipster/protocol/openid-connect/userinfo"" resulted in 401 (Unauthorized); invoking error handler&#xA;n.m.b.s.o.CachedUserInfoTokenServices    : Could not fetch user details: class org.springframework.security.oauth2.client.resource.OAuth2AccessDeniedException, Unable to obtain a new access token for resource 'null'. The provider manager is not configured to support it.&#xA;p.a.OAuth2AuthenticationProcessingFilter : Authentication request failed: error=""invalid_token"", error_description=""token string here""&#xA;</code></pre>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/C7MwY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/C7MwY.png"" alt=""SSO 401 is Happening""></a></p>&#xA;&#xA;<p>it says that your token is invalid. the same mechanism just works when everything is deployed in same host in docker. is it for the Keycloak that prevents the token to validate for external hosts? i personally doubt that , because it didn't prevent me from logging into gateway successfully. and i just checked keycloak. its up by the command <code>-b 0.0.0.0</code></p>&#xA;&#xA;<p>Please help me up and run a gateway just by <code>gradle bootRun -Pprod</code>.</p>&#xA;&#xA;<p>In summary I could rephrase my question to: <strong><em>i just want the UI Developer be able to test his angular/spring-gateway project in it's own PC while other services are deployed in powerful server using docker</em></strong> (authentication using <strong><em>Keycloak</em></strong>). and it is not possible to deploy those other services on UI developers own PC. how to do it in JHipster?</p>&#xA;"
43100199,zuul API Gateway Filter,2017-03-29 17:24:47,<spring><microservices><spring-cloud><netflix-zuul>,2,545,3,0.0,2,"<p>I am facing problem when i trying to access another REST API(registered in ZUUL route) from zuul pre-filter, the call is becoming recursive i.e its running my pre-filter code again and again. My Usecase is as follows-</p>&#xA;&#xA;<ol>&#xA;<li><p>In Zuul <code>PreFilter</code> <code>run()</code> method, I am validating the token passed in the header.</p></li>&#xA;<li><p>After validating the token, I am calling one rest service(User Location Service) to fetch the user details. My User Location Service is itself registered in ZUUL as below:</p>&#xA;&#xA;<pre><code>user-location-service:&#xA;  path: /userLocationService/**&#xA;  url: http://localhost:9002&#xA;</code></pre></li>&#xA;</ol>&#xA;&#xA;<p>The problem is that the JWT token validation code is running again and again, Can you please suggest some solution where I can apply the call Userlocation service so that the <code>PreFilter</code> code would not run again and again?</p>&#xA;"
37143689,JHipster Registry rejects gateways and microservices,2016-05-10 16:03:40,<jwt><jhipster><microservices><spring-cloud-config>,2,2306,0,1.0,2,"<p>I'm trying to use JHipster for a project using microservices, but the latest JHipster Registry won't let my gateway or microservices access the config server and rejects them.</p>&#xA;&#xA;<p>I installed the JHipster Vagrant DevBox, then used <code>docker run -p 8761:8761 jhipster/jhipster-registry</code> to run the JHipster registry.&#xA;Then, I generated a gateway and 2 microservices following <a href=""http://www.ipponusa.com/blog/jhipster-3-0-introducing-microservices/"" rel=""nofollow"">this</a>, and it worked.</p>&#xA;&#xA;<p>But then I wanted to use the JHipster Registry from GitHub, so I cloned it and runned it (apparently it had been updated to 2.0.0 in the meantime). Sadly, the gateway and the microservices weren't able to access this registry. They were still able to access the Docker image registry though (I suppose Docker didn't update it). But since it was fancier, and probably more up-to-date, I wanted to use the latest version of the registry, the same as the one from GitHub. So I tried to update the Docker image Jhipster Registry with <code>docker pull</code>. And now it won't work with either registry - Docker image or GitHub clone. </p>&#xA;&#xA;<p>When a registry is running and I run a gateway or microservice, I get 6 times this:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.511 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@86ba8f5 pairs: {GET /config/gateway/dev/master HTTP/1.1: null}{Accept: application/json, application/*+json}{User-Agent: Java/1.8.0_91}{Host: localhost:8761}{Connection: keep-alive}&#xA;2016-05-10 15:39:07.522 DEBUG 20706 --- [           main] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@43c7802510 pairs: {null: HTTP/1.1 401 Unauthorized}{Server: Apache-Coyote/1.1}{X-Content-Type-Options: nosniff}{X-XSS-Protection: 1; mode=block}{Cache-Control: no-cache, no-store, max-age=0, must-revalidate}{Pragma: no-cache}{Expires: 0}{Content-Type: application/json;charset=UTF-8}{Transfer-Encoding: chunked}{Date: Tue, 10 May 2016 15:39:07 GMT}&#xA;</code></pre>&#xA;&#xA;<p>Then I get an error:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:13.781 ERROR 20706 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Then I get Java exceptions:</p>&#xA;&#xA;<pre><code>java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 common frames omitted&#xA;&#xA;[WARNING] &#xA;java.lang.reflect.InvocationTargetException&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#xA;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;at java.lang.reflect.Method.invoke(Method.java:498)&#xA;at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run(AbstractRunMojo.java:478)&#xA;at java.lang.Thread.run(Thread.java:745)&#xA;Caused by: java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:110)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;)&#xA;at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)&#xA;at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:74)&#xA;at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)&#xA;at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:154)&#xA;at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:101)&#xA;at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:118)&#xA;at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)&#xA;at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$a0abff82.locate(&lt;generated&gt;)&#xA;at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:89)&#xA;at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:640)&#xA;at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:343)&#xA;at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)&#xA;at com.soprasteria.example.GatewayApp.main(GatewayApp.java:73)&#xA;... 6 more&#xA;Caused by: org.springframework.web.client.HttpClientErrorException: 401 Unauthorized&#xA;at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)&#xA;at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:641)&#xA;at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:597)&#xA;at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557)&#xA;at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:130)&#xA;at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:81)&#xA;... 23 more&#xA;</code></pre>&#xA;&#xA;<p>And finally a <code>BUILD FAILURE</code> and a Maven error:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.3.3.RELEASE:run (default-cli) on project gateway: An exception occurred while running. null: InvocationTargetException: Could not locate PropertySource and the fail fast property is set, failing: 401 Unauthorized -&gt; [Help 1]&#xA;[ERROR] &#xA;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;[ERROR] &#xA;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#xA;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;</code></pre>&#xA;&#xA;<p>In the registry's shell I get this line 6 times too:</p>&#xA;&#xA;<pre><code>2016-05-10 15:39:07.519 DEBUG 17958 --- [io-8761-exec-10] i.g.j.r.s.Http401UnauthorizedEntryPoint  : Pre-authenticated entry point called. Rejecting access&#xA;</code></pre>&#xA;&#xA;<p>I tried updating everything, and I am currently trying to downgrade things (since the doc says ""we recommend you use the same version tag as the one you use for your JHipster generator"", but I don't think it'll work since JHipster Registry's latest version is 2.0.0 and the JHipster generator introduced microservices with the 3.0 version), and I also tried copying directly the secret from the central-server-config to the config of the applications, but apparently to no avail.</p>&#xA;&#xA;<p>Could you help me with this ?</p>&#xA;&#xA;<p>Thank you very much in advance.</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>I tried updating JHipster to 3.2.1 using <code>npm install -g generator-jhipster</code>, which apparently worked, but when I run <code>yo jhipster</code>, Yeoman still uses JHipster 3.1.0. Actually, even if I uninstall JHipster with <code>npm uninstall -g generator-jhipster</code>, Yeoman can still use JHipster 3.1.0...</p>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>It works fine if I reinstall everything locally (in the directory where I use <code>yo jhipster</code>).&#xA;However, I still can't update JHipster globally in Yeoman. When I try using <code>npm install -g generator-jhipster</code>, it updates JHipster globally to 3.2.1 but Yeoman still uses 3.1.0. If I try to update JHipster using <code>yo</code>/""Update your generators""/generator-jhipster, I get an error:</p>&#xA;&#xA;<pre><code>npm WARN deprecated npmconf@2.1.2: this package has been reintegrated into npm and is now out of date with respect to npm&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules/generator-jhipster&#xA;npm WARN checkPermissions Missing write access to /usr/local/lib/node_modules&#xA;/usr/local/lib&#xA;└── generator-jhipster@3.2.1 &#xA;&#xA;npm ERR! Linux 3.13.0-85-generic&#xA;npm ERR! argv ""/usr/local/bin/node"" ""/usr/local/bin/npm"" ""install"" ""-g"" ""generator-jhipster""&#xA;npm ERR! node v4.4.4&#xA;npm ERR! npm  v3.8.9&#xA;npm ERR! path /usr/local/lib/node_modules/generator-jhipster&#xA;npm ERR! code EACCES&#xA;npm ERR! errno -13&#xA;npm ERR! syscall access&#xA;&#xA;npm ERR! Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster'&#xA;npm ERR!     at Error (native)&#xA;npm ERR!  { [Error: EACCES: permission denied, access '/usr/local/lib/node_modules/generator-jhipster']&#xA;npm ERR!   errno: -13,&#xA;npm ERR!   code: 'EACCES',&#xA;npm ERR!   syscall: 'access',&#xA;npm ERR!   path: '/usr/local/lib/node_modules/generator-jhipster' }&#xA;npm ERR! &#xA;npm ERR! Please try running this command again as root/Administrator.&#xA;&#xA;npm ERR! Please include the following file with any support request:&#xA;npm ERR!     /home/vagrant/npm-debug.log&#xA;&#xA;I've just updated your generators. Remember, you can update&#xA;a specific generator with npm by running:&#xA;&#xA;    npm install -g generator-_______&#xA;</code></pre>&#xA;&#xA;<p>Using <code>sudo</code> will do the same and <code>sudo su</code> give me this when I try to run <code>yo</code>:</p>&#xA;&#xA;<pre><code>/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:53&#xA;                throw err;&#xA;                ^&#xA;&#xA;Error: EACCES: permission denied, open '/root/.config/configstore/insight-yo.json'&#xA;You don't have access to this file.&#xA;&#xA;    at Error (native)&#xA;    at Object.fs.openSync (fs.js:549:18)&#xA;    at Object.fs.readFileSync (fs.js:397:15)&#xA;    at Object.create.all.get (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:34:26)&#xA;    at Object.Configstore (/usr/local/lib/node_modules/yo/node_modules/configstore/index.js:27:44)&#xA;    at new Insight (/usr/local/lib/node_modules/yo/node_modules/insight/lib/index.js:37:34)&#xA;    at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/yo/lib/cli.js:163:11)&#xA;    at Module._compile (module.js:409:26)&#xA;    at Object.Module._extensions..js (module.js:416:10)&#xA;    at Module.load (module.js:343:32)&#xA;</code></pre>&#xA;&#xA;<p>EDIT:</p>&#xA;&#xA;<p>Ok it does <strong>not</strong> work even with a local installation...&#xA;Well the gateway does access to the registry, but it displays a debug page when I try to access to localhost:8080.&#xA;Actually, during the generation, I get a <code>permission denied</code> again, and missing dependencies (<code>gulp-rev</code>).</p>&#xA;&#xA;<p>I just saw this: ""It is wise to use a tag to have a stable version: the JHipster DevBox tags are the same as the JHipster Generator tags, so using the DevBox v3.2.0 also means using the generator v3.2.0"" on the DevBox GitHub page, so maybe I'll just delete and download the DevBox again...</p>&#xA;"
43369008,Unable to connect with Azure Container Services - Kubernetes,2017-04-12 12:03:27,<azure><kubernetes><credentials><microservices><azure-container-service>,1,588,7,1.0,2,"<p>I am working on setting up environment for deploying microservices.</p>&#xA;&#xA;<p>I have gotten as far as building my code and deploying to a registry but having problem running it in Azure Container Services.</p>&#xA;&#xA;<p>I am following this guide to connect to ACS: <a href=""https://docs.microsoft.com/en-us/azure/container-service/container-service-connect"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/container-service/container-service-connect</a> </p>&#xA;&#xA;<p>But i fail on the step: Download Cluster Credentials&#xA;Using the given command</p>&#xA;&#xA;<pre><code>az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt;&#xA;</code></pre>&#xA;&#xA;<p>Ofc changing the reseource group and clustername to the correct names from my portal. I get an error:</p>&#xA;&#xA;<pre><code>[WinError 10049] The requested address is not valid in its context&#xA;</code></pre>&#xA;&#xA;<p>(if i change resource group or clustername to something else I get other errors so seems it can find those at least)</p>&#xA;&#xA;<p>When i try to search for the error it seems to be some IP adress problem but can't figure out what to do. Tried running same command from other network (from home) to make sure work firewall is not blocking something.. but I get the same error</p>&#xA;&#xA;<p>Any help appriciated!</p>&#xA;"
42204181,Spring Cloud Stream Kafka - How to implement idempotency to support distributed transaction management (eventual consistency),2017-02-13 12:34:23,<spring-cloud><microservices><distributed-transactions><spring-cloud-stream><spring-kafka>,2,1234,6,0.0,2,"<p>I have the following typical scenario: </p>&#xA;&#xA;<ul>&#xA;<li>An order service used to purchase products. Acts as the commander of the distributed transaction.</li>&#xA;<li>A product service with the list of products and its stock.</li>&#xA;<li><p>A payment service.</p>&#xA;&#xA;<pre><code>    Orders DB               Products DB&#xA;       |                       |&#xA;---------------         ----------------          ----------------&#xA;| OrderService  |       | ProductService |        | PaymentService |&#xA; ---------------         ----------------          ----------------&#xA;       |                       |                         |&#xA;       |                --------------------             |&#xA;       --------------- | Kafka orders topic |-------------&#xA;                       ---------------------&#xA;</code></pre></li>&#xA;</ul>&#xA;&#xA;<p>The normal flow would be:</p>&#xA;&#xA;<ol>&#xA;<li>The user orders a product.</li>&#xA;<li>Order service creates an order in DB and publishes a message in Kafka topic ""orders"" to reserve a product (PRODUCT_RESERVE_REQUEST).</li>&#xA;<li>Product service decreases the product stock one unit in its DB and publishes a message in ""orders"" saying PRODUCT_RESERVED</li>&#xA;<li>Order service gets the PRODUCT_RESERVED message and orders the payment publishing a message PAYMENT_REQUESTED</li>&#xA;<li>Payment service orders the payment and answers with a message PAYED</li>&#xA;<li>Order service reads the PAYED message and marks the order as COMPLETED, finishing the transaction.</li>&#xA;</ol>&#xA;&#xA;<p>I am having trouble to deal with error cases, e.g: let's assume this:</p>&#xA;&#xA;<ol start=""5"">&#xA;<li>Payment service fails to charge for the product, so it publishes a message PAYMENT_FAILED</li>&#xA;<li>Order service reacts publishing a message UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service increases the stock in the DB to cancel the reservation and publishes PRODUCT_UNRESERVATION_COMPLETED</li>&#xA;<li>Order service finishes the transaction saving the final state of the order as CANCELLED_PAYMENT_FAILED.</li>&#xA;</ol>&#xA;&#xA;<p>In this scenario imagine that for whatever reason, order service publishes a UNDO_PRODUCT_RESERVATION message but doesn't receive the PRODUCT_UNRESERVATION_COMPLETED message, so it retries publishing another UNDO_PRODUCT_RESERVATION message.</p>&#xA;&#xA;<p>Now, imagine that those two UNDO_PRODUCT_RESERVATION messages for the same order end up arriving to ProductService. If I process both of them I could end up setting an invalid stock for the product. </p>&#xA;&#xA;<p>In this scenario how can I implement idempotency? </p>&#xA;&#xA;<p><strong>UPDATE:</strong></p>&#xA;&#xA;<p>Following Artem's instructions I can now detect duplicated messages (by checking the message header) and ignore them but there may still be situations like the following where I shouldn't ignore the duplicated messages:</p>&#xA;&#xA;<ol>&#xA;<li>Order Service sends UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service gets the message and starts processing it but crashes before updating the stock.</li>&#xA;<li>Order Service doesn't get a response so it retries sending UNDO_PRODUCT_RESERVATION</li>&#xA;<li>Product service knows this is a duplicated message BUT, in this case it should repeat the processing again. </li>&#xA;</ol>&#xA;&#xA;<p>Can you help me come up with a way to support this scenario as well? How could I distinguish when I should discard the message or reprocess it?</p>&#xA;"
48531937,AWS ALB per ECS Service vs. multiple services per ALB for a microservices architecture,2018-01-30 23:05:32,<amazon-web-services><microservices><amazon-elb><amazon-route53><amazon-alb>,1,272,4,0.0,2,"<p>Initially I thought that multiple services per ALB listener with different path patterns to distribute API calls appropriately was the obvious choice. In terms of health checks though (if one of those services goes down), I don't know of a smart way to divert traffic for just that service to a different region. </p>&#xA;&#xA;<p>If I have an active active setup with weighted route 53 records that will failover on a health check, I don't see any other solution than to either cut off that entire ALBs traffic and divert to another region, or ignore the 1 down service and continue to send traffic to the partially failing ALB.</p>&#xA;&#xA;<p>Having a one to one mapping of ALBs to services fixes this solution, but it adds additional overhead in terms of cost and complexity.</p>&#xA;&#xA;<p>What is the recommended pattern to follow for an active active microservices architecture?</p>&#xA;"
48753245,How to expose APIs endpoints from private AWS ALB,2018-02-12 18:35:49,<amazon-web-services><microservices><amazon-vpc><aws-ecs>,3,240,0,0.0,2,"<p>We are having several microservices on AWS ECS. We have single ALB which has different target group for different microservices. We want to expose some endpoints externally while some endpoints just for internal communication. </p>&#xA;&#xA;<p>The problem is that if we put our load balancer in public VPC than it means that we are exposing all register endpoints externally. If we move load balancer to private VPC, we have to use some sort of proxy in public VPC, which required additional infra/cost and custom implementation of all security concerns like D-DOS etc.</p>&#xA;&#xA;<p>What possible approaches we can have or does AWS provide some sort of out of the box solution for this ?</p>&#xA;"
48805353,Can we call Zuul enabled server through RestTemplate,2018-02-15 10:47:22,<java><microservices><netflix-eureka><netflix-zuul>,3,431,2,0.0,2,"<p>I am trying to call a <code>zuul</code> enabled server through <code>RestTemplate</code> by directly giving the URL.&#xA;For example: restTemplate.getForObject(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>"", Employee[].class);</p>&#xA;&#xA;<p>But it is giving an error to me:</p>&#xA;&#xA;<blockquote>&#xA;  <p>java.lang.IllegalStateException: No instances available for localhost&#xA;      at org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.execute(RibbonLoadBalancerClient.java:90) ~[spring-cloud-netflix-core-1.2.3.RELEASE.jar:1.2.3.RELEASE]</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Question in detail</strong> :&#xA;I am having four projects (Github link (branch-master): <a href=""https://github.com/vickygupta0017/microservice-poc"" rel=""nofollow noreferrer"">https://github.com/vickygupta0017/microservice-poc</a>)</p>&#xA;&#xA;<ol>&#xA;<li>microservice-server (eureka-server) port:8080</li>&#xA;<li>microservice-producer (Rest-api)   port:8086</li>&#xA;<li>zuul-gatewayproxy (zuul-server)   port:8090</li>&#xA;<li><p>microservice-consumer (spring-mvc) port:8087</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/Gg1hF.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gg1hF.jpg"" alt=""Flow Image""></a></p></li>&#xA;</ol>&#xA;&#xA;<p>If I am calling <code>zuul server</code> directly from browser(""<a href=""http://localhost:8090/emp-api"" rel=""nofollow noreferrer"">http://localhost:8090/emp-api</a>), then it is redirecting the request to producer successfully.&#xA;But if I am calling this URL from the consumer through <code>RestTemplate</code> then it is giving me this error.</p>&#xA;&#xA;<p><strong>For Information :</strong> If I am not using zuul sever then I am able to call 'microservice-producer' from 'microservice-consumer' using <code>RestTemplate</code> successfully.</p>&#xA;"
41019199,Enabling CORS in Azure Service Fabric Web Api,2016-12-07 13:50:41,<angularjs><azure><asp.net-web-api><microservices><azure-service-fabric>,2,883,5,1.0,2,"<p>I have an angular app that sends an http request to my Service Fabric Web API (deployed on a Secure Service Fabric cluster) like so:</p>&#xA;&#xA;<pre><code>    $scope.request_headers = {&#xA;            ""Content-Type"": ""application/xml; charset=utf-8"",&#xA;            ""Access-Control-Allow-Origin"":""*""&#xA;        }&#xA;    $http({&#xA;                url: ""Service_Fabric_web_api_url"",&#xA;                method: ""GET"",&#xA;                headers:$scope.request_headers&#xA;            }).&#xA;            then(function (result) {&#xA;                console.log(result);&#xA;            });&#xA;</code></pre>&#xA;&#xA;<p>I've also enabled CORS globally in my web api startup class like so:</p>&#xA;&#xA;<pre><code>HttpConfiguration config = new HttpConfiguration();&#xA;var cors = new EnableCorsAttribute(""*"", ""*"", ""*"");&#xA;config.EnableCors(cors);&#xA;</code></pre>&#xA;&#xA;<p>When I run my angular app locally and try sending the http request, I still get this error:</p>&#xA;&#xA;<pre><code>XMLHttpRequest cannot load Service_Fabric_web_api_url. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:xxxxx' is therefore not allowed access. The response had HTTP status code 500.&#xA;</code></pre>&#xA;&#xA;<p>I'm able to access my service directly from my browser with the same url.</p>&#xA;&#xA;<p>Also, the same http request works when I tried deploying my Web Api on an unsecure Service Fabric Cluster with the same lines added to the startup class to enable CORS. </p>&#xA;&#xA;<p>Why is this happening even though I've enabled CORS globally in my Web API and particularly when its on a secure cluster?</p>&#xA;"
40377076,Access to Microservices via Eureka Server,2016-11-02 10:01:34,<spring><spring-boot><microservices><netflix-eureka>,2,1976,1,1.0,2,"<p>can I access to microservice with someting like this:&#xA;Eureka Server: <a href=""http://localhost:8761/"" rel=""nofollow noreferrer"">http://localhost:8761/</a>&#xA;Microservice url: <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a>&#xA;Call to Microservice to be something like: <a href=""http://localhost:8761/name-service/"" rel=""nofollow noreferrer"">http://localhost:8761/name-service/</a>&#xA;Is it posible?&#xA;When i open the eureka server the service is registered.</p>&#xA;&#xA;<p>eureka/application.properties:</p>&#xA;&#xA;<pre><code>server.port=8761&#xA;eureka.client.register-with-eureka=false&#xA;eureka.client.fetch-registry=false&#xA;logging.level.com.netflix.eureka=OFF&#xA;logging.level.com.netflix.discovery=OFF&#xA;</code></pre>&#xA;&#xA;<p>name-service/application.properties</p>&#xA;&#xA;<pre><code>spring.application.name=name-service&#xA;server.port=8080&#xA;</code></pre>&#xA;&#xA;<p>How can i achieve this?</p>&#xA;"
40485481,Front End Developer workflow for Service Fabric Web Apps,2016-11-08 11:15:26,<azure><microservices><azure-service-fabric>,1,396,7,2.0,2,"<p>I'm a front end developer about to join a project team working with Service Fabric to build a Web Front End to their microservice driven application.</p>&#xA;&#xA;<p>One of the problems I've been having in my own research is that when working with local Service Fabric Clusters, I have to redeploy my Application to test if something does or doesn't work in my Web App. This slows down developer velocity massively, as the process will only take longer and longer as other Back End services are added. I largely work with the Web App communicating to an API Gateway Service (GraphQL.NET). </p>&#xA;&#xA;<p>What I'd like to know is if there's a way to run a local Web Application out outside of a Service Fabric cluster, but still have it communicate to one. This would allow my front end developer tool chain to remain intact, and develop at a much faster pace with incremental building and live-reload tools.</p>&#xA;&#xA;<p>Of course, if anyone's come up with any better solution to the problem, I'd love to hear about it! ;)</p>&#xA;"
29825744,How to decide between using messaging (e.g. RabbitMQ) versus a web service for backend component interactions/communication?,2015-04-23 13:58:41,<web-services><rest><messaging><spring-rabbit><microservices>,2,1338,0,1.0,2,"<p>In developing backend components, I need to decide how these components will interact and communicate with each other. In particular, I need to decide whether it is better to use (RESTful, micro) web services versus a message broker (e.g. RabbitMQ).  Are there certain criteria to help decide between using web services for each component versus messaging?</p>&#xA;"
29775643,Microservice Event driven Design with multiple Instances,2015-04-21 14:49:06,<spring><jms><spring-jms><microservices><event-driven-design>,1,740,0,1.0,2,<p>At the Moment we design and plan to transform our system to a microservice architecture pattern. </p>&#xA;&#xA;<p>To loose coupling we think about an event driven design with an JMS Topic. This looks great. But i don't now how we can solve the problem with multiple instances of a microservice. &#xA;For failover and load balancing we have <em>n</em> instances of each service. If an event is published to the topic each instance will receive and process that event. </p>&#xA;&#xA;<p>It's possible to handle this with locks and processed states in the data storage. But this solution looks very expensive and every instance has the same work. This is not a load balaning for me. </p>&#xA;&#xA;<p>Is there some good Solution or best practice for this pattern?</p>&#xA;
41762928,How to do client side load balancing for discovered microservices in nodejs,2017-01-20 11:45:09,<node.js><microservices><netflix-ribbon>,2,1286,1,0.0,2,"<p>We are trying to build a microservice with nodejs in an environment with other microservices written in java/spring boot.</p>&#xA;&#xA;<p>The other microservices are using consul.io for service discovery and ribbon for client side load balancing. (that would be: spring-boot, spring-cloud-starter-consul-discovery, spring-cloud-starter-feign and spring-cloud-starter-ribbon projects)</p>&#xA;&#xA;<p>Now in this mix, we have a <a href=""https://www.npmjs.com/package/consul"" rel=""nofollow noreferrer"">consul node module</a> to register or discover services, but what of rest of the things? How do I do a discovery-aware rest call with a load balancing handled on the client, similar to that of ribbon.</p>&#xA;&#xA;<p>How can I achieve this in node's stack?</p>&#xA;"
41850142,Microservices centralized database model,2017-01-25 11:13:51,<mysql><database><go><microservices>,2,1030,3,1.0,2,"<p>Currently we have some <a href=""https://en.wikipedia.org/wiki/Microservices"" rel=""nofollow noreferrer"">microservice</a>, they have their own database model and migration what provided by GORM Golang package. We have a big old MySQL database which is against the microservices laws, but we can't replace it. Im afraid when the microservices numbers start to growing, we will be lost in the many database model. When I add a new column in a microservice I just type <code>service migrate</code> to the terminal (because there is a cli for run and migrate commands), and it is refresh the database.</p>&#xA;&#xA;<p>What is the best practice to manage it. For example I have 1000 microservice, noone will type the <code>service migrate</code> when someone refresh the models. I thinking about a centralized database service, where we just add a new column and it is store the all model with all migration. The only problem, how will the services get know about database model changes. This is how we store for example a user in a service:</p>&#xA;&#xA;<pre><code>type User struct {&#xA;    ID        uint           `gorm:""column:id;not null"" sql:""AUTO_INCREMENT""`&#xA;    Name      string         `gorm:""column:name;not null"" sql:""type:varchar(100)""`&#xA;    Username  sql.NullString `gorm:""column:username;not null"" sql:""type:varchar(255)""`&#xA;}&#xA;&#xA;func (u *User) TableName() string {&#xA;    return ""users""&#xA;}&#xA;</code></pre>&#xA;"
42435307,Spring Cloud Netflix vs Kubernetes,2017-02-24 09:42:37,<kubernetes><microservices><docker-swarm><netflix-zuul><spring-cloud-netflix>,1,2244,1,1.0,2,"<p>I am trying to finally choose between Spring Cloud Netflix, Kubernetes and Swarm for building our microservices environment. They are all very cool and do some choice is very hard. &#xA;I'll describe a little which kind of problems I want to solve.&#xA;I couldn't find any best way to design Api Gateway (not a simple load balancer) with Kubernetes or Swarm , that's why I want to use Zuul. But from other side Api Gateway must use service discovery which in case of Kubernetes or Swarm will be embedded inside the orchestra. With Kubernetes I can use it's spring cloud integration, but this way I will have server side discovery and client side discovery inside Kubernetes. Which is overkill I think. &#xA;I am wondering does anyone have some experience with them and any suggestions about that.&#xA;Thanks.</p>&#xA;"
47329630,How to host MassTransit and RabbitMq,2017-11-16 12:25:13,<rabbitmq><cloud><microservices><masstransit><queuing>,2,325,3,0.0,2,"<p>We are working towards an architecture like one below but we will have micro services on cloud and some on premises which will talk to each other using queue(s) and bus(es), </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/qfFOh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qfFOh.png"" alt=""RabbitMQ implementation of an event bus""></a></p>&#xA;&#xA;<p>Now I am confused with where we should host MassTransit and RabbitMq, also should it be a ASP.NET Core project on its own ? if yes what I will be doing in it ? starting a bus ? creating queues ? I am not able to move forward with this</p>&#xA;"
37793364,"AWS ECS: How do I get around ""too many containers"" with my microservice architecture API?",2016-06-13 15:13:57,<amazon-web-services><elastic-beanstalk><microservices><amazon-ecs>,2,916,6,0.0,2,"<p>I'm working on an API with microservice architecture. I deploy to ECS via Elastic Beanstalk. Each microservice is a long-running task (which, on ECS equates to a single container). I just passed up 10 tasks, and I can no longer deploy.</p>&#xA;&#xA;<blockquote>&#xA;  <p>ERROR: Service:AmazonECS, Code:ClientException, Message:Too many containers., Class:com.amazonaws.services.ecs.model.ClientException</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""http://docs.aws.amazon.com/AmazonECS/latest/developerguide/service_limits.html"" rel=""nofollow"">According to the documentation</a>, 10 task definition containers is a hard limit on ECS.</p>&#xA;&#xA;<p>Is there any way to get around this? How can I continue adding services to my API on ECS? This limitation suggests to me I am not using the service as intended. What is the best way to deploy a collection of microservices each as a separate Docker container on AWS?</p>&#xA;&#xA;<p><strong>EDIT:</strong> My understanding of the relationship between containers and tasks was completely wrong. Looks like the entire API is a single task and each container in my Dockerrun.aws.json is a container inside the API task. So, the limitation is a limit on containers inside a single task.</p>&#xA;"
37854185,Server to Server communication in microservices,2016-06-16 08:46:04,<java><spring><microservices><spring-cloud-netflix>,2,967,11,1.0,2,"<p>I am working on microservice architecture, but I am facing some challenges in that.</p>&#xA;&#xA;<p>First let me give you a brief about the architecture.</p>&#xA;&#xA;<ol>&#xA;<li><p>User logs in and get a signed token which will be used to call all REST APIS.</p></li>&#xA;<li><p>There will be lot of API server where APIs are secured using Spring security and Authorized as per the user roles.</p></li>&#xA;<li><p>Services have to interact with each other to get/update information.</p></li>&#xA;<li><p>Every service will have the power to validate a token issue by auth server.</p></li>&#xA;</ol>&#xA;&#xA;<p>Problem:-</p>&#xA;&#xA;<ol>&#xA;<li><p>Everything works fine if User logs in and the same token is used and passsed to every service which is validated across.So, services dont need to trust each other as the token is passed.</p></li>&#xA;<li><p>Now, the problem is there are some services which needs to be called from server itself without logging in. Lets say a server to server call. How will a service authenticate and authorize the call from other services.</p></li>&#xA;</ol>&#xA;&#xA;<p>I read about spring Microservices but Zuul is also not the saviour here as every API server has spring security embedded and not just the API gateway.</p>&#xA;&#xA;<p>One solution can be that every service has its own default user with certaing roles which is used to Login->Fetch a token->call other server api with token.</p>&#xA;&#xA;<p>Can you please give me some pointers in server to server calls where each server is authenticated and authorized using spring security.</p>&#xA;&#xA;<p>Thanks. </p>&#xA;"
43532494,Use ehcache for application deployed via docker against the stateless rule,2017-04-21 01:37:26,<docker><spring-boot><ehcache><microservices><stateless>,3,333,1,0.0,2,"<p>I have an spring-boot application which I would like to deploy it into multiple docker instances and there is a load balance before the instances.&#xA;However, the application uses ehcache to cache some data from a database. It makes the application stateful.&#xA;So without session sticky, a same customer might hit different docker instances and see different results.&#xA;My question is if I can't apply session sticky in load balance, what is the best practice to deploy an app with cache feature via docker style and still comply the rule of should-be-stateless?</p>&#xA;"
43538070,How to manage state in microservices?,2017-04-21 08:49:10,<kubernetes><microservices>,1,464,4,0.0,2,"<p>First of all, this is a question regarding my thesis for school. I have done some research about this, it seems like a problem that hasn't been tackled yet (might not be that common).</p>&#xA;&#xA;<p>Before jumping right into the problem, I'll give a brief example of my use case.</p>&#xA;&#xA;<p>I have multiple namespaces containing microservices depending on a state X. To manage this the microservices are put in a namespace named after the state. (so namespaces state_A, state_B, ...)</p>&#xA;&#xA;<p>Important to know is that each microservice needs this state at startup of the service. It will download necessary files, ... according to the state. When launching it with state A version 1, it is very likely that the state gets updated every month. When this happens, it is important to let all the microservices that depend on state A upgrade whatever necessary (databases, in-memory state, ...).</p>&#xA;&#xA;<p>My current approach for this problem is simply using events, the microservices that need updates when the state changes can subscribe on the event and migrate/upgrade accordingly. The only problem I'm facing is that while the service is upgrading, it should still work. So somehow I should duplicate the service first, let the duplicate upgrade and when the upgrade is successful, shut down the original. Because of this the used orchestration service would have to be able to create duplicates (including duplicating the state).</p>&#xA;&#xA;<p>My question is, are there already solutions for my problem (and if yes, which ones)? I have looked into Netflix Conductor (which seemed promising with its workflows and events), Amazon SWF, Marathon and Kubernetes, but none of them covers my problem.</p>&#xA;&#xA;<p>Best of all the existing solution should not be bound to a specific platform (Azure, GCE, ...).</p>&#xA;"
47566338,Not able to read configuration from Consul in spring-boot application,2017-11-30 05:13:58,<spring-boot><microservices><spring-cloud><consul><spring-cloud-consul>,1,806,3,2.0,2,"<p>I am creating a <code>Spring Boot</code> application, which will read configuration like DB properties from <code>Consul</code>. But I am not able to read the key value from Consul using my application. Following is, what I am trying to do.</p>&#xA;&#xA;<pre><code>**pom.xml**&#xA;&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&#xA;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0""&#xA;         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&#xA;         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;&#xA;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&#xA;&#xA;    &lt;groupId&gt;com.tuturself&lt;/groupId&gt;&#xA;    &lt;artifactId&gt;spring-boot-consul&lt;/artifactId&gt;&#xA;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&#xA;&#xA;    &lt;parent&gt;&#xA;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&#xA;        &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;&#xA;        &lt;relativePath/&gt;&#xA;    &lt;/parent&gt;&#xA;&#xA;    &lt;properties&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;spring.retry.version&gt;1.2.1.RELEASE&lt;/spring.retry.version&gt;&#xA;        &lt;consul.version&gt;1.1.2.RELEASE&lt;/consul.version&gt;&#xA;        &lt;consul.discovery.version&gt;1.1.2.RELEASE&lt;/consul.discovery.version&gt;&#xA;        &lt;jackson.version&gt;2.8.1&lt;/jackson.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-consul-all&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-consul-discovery&lt;/artifactId&gt;&#xA;            &lt;version&gt;${consul.discovery.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&#xA;            &lt;version&gt;${spring.retry.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&#xA;            &lt;version&gt;${jackson.version}&lt;/version&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;&#xA;    &lt;build&gt;&#xA;        &lt;plugins&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&#xA;                &lt;version&gt;3.5.1&lt;/version&gt;&#xA;                &lt;configuration&gt;&#xA;                    &lt;source&gt;1.8&lt;/source&gt;&#xA;                    &lt;target&gt;1.8&lt;/target&gt;&#xA;                &lt;/configuration&gt;&#xA;            &lt;/plugin&gt;&#xA;            &lt;plugin&gt;&#xA;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&#xA;                &lt;executions&gt;&#xA;                    &lt;execution&gt;&#xA;                        &lt;goals&gt;&#xA;                            &lt;goal&gt;repackage&lt;/goal&gt;&#xA;                        &lt;/goals&gt;&#xA;                    &lt;/execution&gt;&#xA;                &lt;/executions&gt;&#xA;            &lt;/plugin&gt;&#xA;        &lt;/plugins&gt;&#xA;    &lt;/build&gt;&#xA;&#xA;    &lt;dependencyManagement&gt;&#xA;        &lt;dependencies&gt;&#xA;            &lt;dependency&gt;&#xA;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;                &lt;artifactId&gt;spring-cloud-consul-dependencies&lt;/artifactId&gt;&#xA;                &lt;version&gt;1.2.1.RELEASE&lt;/version&gt;&#xA;                &lt;type&gt;pom&lt;/type&gt;&#xA;                &lt;scope&gt;import&lt;/scope&gt;&#xA;            &lt;/dependency&gt;&#xA;        &lt;/dependencies&gt;&#xA;    &lt;/dependencyManagement&gt;&#xA;&#xA;&lt;/project&gt;&#xA;</code></pre>&#xA;&#xA;<p><strong>And Following is my Main class:</strong></p>&#xA;&#xA;<pre><code>@EnableRetry&#xA;@RefreshScope&#xA;@EnableDiscoveryClient&#xA;@SpringBootApplication&#xA;@ComponentScan(""com.test.*"")&#xA;public class SpringBootConsulApplication {&#xA;&#xA;    private static ConsulConfiguration consulConfiguration;&#xA;&#xA;    public static void main(String[] args) {&#xA;        try {&#xA;            String consulHost = System.getProperty(""spring.cloud.consul.host"");&#xA;            System.out.println(""consulHost ::"" + consulHost);&#xA;            String consulPort = System.getProperty(""spring.cloud.consul.port"");&#xA;            System.out.println(""consulPort ::"" + consulPort);&#xA;            String consulPrefix = System.getProperty(""spring.cloud.consul.config.prefix"");&#xA;            System.out.println(""consulPrefix ::"" + consulPrefix);&#xA;            new SpringApplicationBuilder(SpringBootConsulApplication.class).web(true).run(args);&#xA;        } catch (Exception ex) {&#xA;            ex.printStackTrace();&#xA;        }&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>And I am reading the consul properties using the <code>@Value</code> annotation:</p>&#xA;&#xA;<pre><code>@Configuration&#xA;@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)&#xA;public class ConsulConfiguration {&#xA;&#xA;    @Value(""${cassandra.host}"")&#xA;    private String cassandraHost;&#xA;&#xA;    @Value(""${cassandra.user}"")&#xA;    private String userName;&#xA;&#xA;    @Value(""${cassandra.password}"")&#xA;    private String password;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>I have my <code>bootstrap.yml</code> in resources folder:</p>&#xA;&#xA;<pre><code>spring:&#xA;  cloud:&#xA;    consul:&#xA;      host: localhost&#xA;      port: 8500&#xA;      enabled: true&#xA;      config:&#xA;        enabled: true&#xA;        prefix: config/application&#xA;        defaultContext: apps&#xA;        profileSeparator: '::'&#xA;  application:&#xA;    name: spring-boot-consul&#xA;</code></pre>&#xA;&#xA;<p>Consul is up and running in my local system on <code>localhost:8500</code> where I have the file <code>config/application/spring-boot-consul.yml</code> file;</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: spring-boot-consul&#xA;cassandra:&#xA;  host: 127.0.0.1:9042,127.0.0.2:9042&#xA;  user: my_user&#xA;  password: my_pass&#xA;  pooling:&#xA;    maxThread: 10&#xA;    timeout: 50&#xA;  keyspace:&#xA;    name: test_keyspace&#xA;    readConsistency: ONE&#xA;    writeConsistency: ONE&#xA;</code></pre>&#xA;&#xA;<p>When I am strating the application, it is showing not able to bind <code>cassandra.host</code> in my <code>ConsulConfiguration</code>  class. Thus stopping the application. Any hints , What I am doing wrong here?</p>&#xA;"
45400096,Migrating multi-module project to microservices?,2017-07-30 13:00:55,<java><microservices>,5,473,1,0.0,2,"<p>I have multi module application. To be more explicit these are maven modules where high level modules depends on low level modules. &#xA;Below are the some of the modules :-</p>&#xA;&#xA;<pre><code>    user-management&#xA;    common-services&#xA;    utils&#xA;    emails&#xA;</code></pre>&#xA;&#xA;<p>For example :- If <code>user management</code> module wants to use any services from <code>utils</code> module, it can call its services as dependency of utils is already injected under user-management.&#xA;To convert/call my project truly following microserives architecture, I believe i need to convert each module as  independently deployable services where each module is a war module&#xA;and provides its services over http(mainly as resful web services) . Is that correct or anything else need to be taken care of as well ? </p>&#xA;&#xA;<p>Probably each modules now has to be secured and authentication layer as well ?</p>&#xA;&#xA;<p>If that's the crux of microservices I really do not understand when someone ask whether you have worked on microservices as to me Its not tool/platform/framework but a simple &#xA;concept to divide you monolithic application in to smaller set of deployable modules whose services is available through HTTP. Is n't it ? May be its another buzz word.</p>&#xA;&#xA;<p><strong>Update:-</strong>&#xA;Obviously there are adavantages going micro services way like independent unit testablemodule, scalable as it can be deployed on separate machine, loose coupling etc but I see I need to handle two complex concerns also </p>&#xA;&#xA;<ol>&#xA;<li>Authentication:- For each module I need to ensure it authenticates the request which is not the case right now</li>&#xA;<li>Transaction:- I can not maintain the transaction atomicity across different services which I could do very easily at present</li>&#xA;</ol>&#xA;"
45547556,Blue Green deployment with multiple Micro Services with internal calls,2017-08-07 13:00:57,<java><amazon-web-services><spring-boot><microservices><blue-green-deployment>,4,693,4,0.0,2,"<p>I have a 8 spring boot micro services which internally call each other. The calling dns's of other micro services, define in the application.properties file of each service.</p>&#xA;&#xA;<p>Suppose,  micro service A represent by A -> a.mydns.com and B-> b.mydns.com etc</p>&#xA;&#xA;<p>So basically each micro service consist of a ELB and two HA Proxies (distribute &#xA; in two zones) and 4 App servers (distribute in two zones).</p>&#xA;&#xA;<p>Currently I am creating the new Green servers (app servers only) and switch the live traffic from HA Proxy level. In this case, while the new version of the micro services are testing, it expose to the live customers also.</p>&#xA;&#xA;<p>Ideally, the approach should be, <strong>creating the entire server structure including ELB's and HA Proxies for each micro service right?</strong></p>&#xA;&#xA;<p>But then how come I face the challenge of testing it with a test dns. I can map the ELB to a test dns. <strong>But then how about the external micro service dns's which hard coded in side the application.properties file?</strong></p>&#xA;&#xA;<p>What would be the approach I should take in such scenario?</p>&#xA;"
45146319,Spring - Make microservice only accessible internally,2017-07-17 14:00:20,<spring><spring-security><microservices>,2,221,3,0.0,2,"<p>How can I setup a microservice which can only be called by other internal services. The microservice should not be accessible in public, because it has access to databases with secret information. I already tried to secure the microservice with spring security but in this case I got problems with the FeignClient concerning authorization.</p>&#xA;"
40734086,Implementing API Gateway for ASP.NET API Microservices,2016-11-22 05:01:43,<.net><asp.net-web-api><asp.net-core><microservices><api-gateway>,2,3920,0,0.0,2,"<p>I have developed my micro services using ASP.NET Core WEB API. I am still planning and investigating at this step to add an API Gateway that can acts just as proxy and routes client requests to the designated service (just to isolate and prevent clients from calling the services directly). The gateway will also perform logging and security checks.</p>&#xA;&#xA;<p>I don't need any Discovery Mechanisms for the time being (but if there is a platform I could leverage that would be great).</p>&#xA;&#xA;<p>For constraint purposes let's say that my micro services are hosted on static IPs.</p>&#xA;&#xA;<p>As far as creating my own AP-Gateway, what things do I need to do?&#xA;How would such gateway be implemented?&#xA;How should I host it?  How many?&#xA;I need some patterns that I can translate into an generic implementation.</p>&#xA;&#xA;<p>I was thinking about a simply structured DB that maps every api requested to a micro service API at the other end, then using HttpWebRequest to construct the request and return back the response. Then I can create a message handler that can log all the requests.</p>&#xA;"
40586946,gofabric8> Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip,2016-11-14 10:49:35,<maven><openshift><kubernetes><microservices><fabric8>,4,180,0,0.0,2,<p>I'm trying to set up environment for microservices. I'm using fabric8 to do that.</p>&#xA;&#xA;<p>I'm using <code>mvn fabric8:cluster-start -Dfabric8.cluster.kind=openshift</code> command. while executing i'm getting following error...</p>&#xA;&#xA;<pre><code>  [INFO] gofabric8&gt; Downloading https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-mac.zip...&#xA;    [INFO] gofabric8&gt; **Unable to unzip /Users/apple/.fabric8/bin/oc.zip zip: not a valid zip fileUnable to download client zip: not a valid zip file**&#xA;    [INFO] gofabric8&gt; using the executable /Users/apple/.fabric8/bin/minishift&#xA;    [INFO] gofabric8&gt; running: /Users/apple/.fabric8/bin/minishift start --vm-driver=xhyve --memory=4096 --cpus=1&#xA;    [INFO] gofabric8&gt; Starting local OpenShift cluster...&#xA;    [INFO] gofabric8&gt; Downloading ISO&#xA;    [INFO] gofabric8&gt; &#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] BUILD FAILURE&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [INFO] Total time: 18:50 min&#xA;    [INFO] Finished at: 2016-11-14T16:05:32+05:30&#xA;    [INFO] Final Memory: 21M/224M&#xA;    [INFO] ------------------------------------------------------------------------&#xA;    [ERROR] Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = ''' -&gt; [Help 1]&#xA;    org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal io.fabric8:fabric8-maven-plugin:3.1.49:cluster-start (default-cli) on project demo: Failed to execute gofabric8 start --batch --minishift --console. java.io.IOException: Failed to execute process stdin for gofabric8 start --batch --minishift --console: java.util.UnknownFormatConversionException: Conversion = '''&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)&#xA;        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)&#xA;        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)&#xA;        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)&#xA;</code></pre>&#xA;&#xA;<p>Any Idea?</p>&#xA;
40574379,SNS + CloudFormation,2016-11-13 13:31:34,<microservices><amazon-sns><amazon-cloudformation>,3,327,3,1.0,2,"<p>I'm using <em>AWS CloudFormation</em> to build a stack for a microservice. My <em>AWS CloudFormation</em> template creates resources like: a Lambda function, an SNS topic and API Gateway.</p>&#xA;&#xA;<p>This microservice does some work and publishes messages to the SNS topic. Other microservices subscribe to this topic.</p>&#xA;&#xA;<p>The problem I'm facing is that when I upgrade my microservice's <em>CloudFormation</em> template (sometimes I need to redeploy it, and recreate all resources), the SNS topic changes its <code>ARN</code>. Hence, all microservices that use this topic need to change as well.</p>&#xA;&#xA;<p>I think I could create a separate <em>CloudFormation</em> template for the SNS topic (I have more than one per microservice).</p>&#xA;&#xA;<ul>&#xA;<li>Will this be a good approach? </li>&#xA;<li>If not, what's the recommended way?</li>&#xA;</ul>&#xA;"
33556707,Dynamic Scalable and adaptive architecture,2015-11-05 23:21:28,<docker><zeromq><microservices><consul>,2,434,0,1.0,3,"<p>I am a PhD student in Cloud Computing, I plan to use the microservices based architecture with consul and zeromq for my research project. I had few questions that I am finding hard to understand. Can someone help me out in sharing their experience.</p>&#xA;&#xA;<ol>&#xA;<li>We have microservices based on dockers, We have zeromq and we have consul. Can you mention how we could combine all the three together to have a dynamic adaptive environment? </li>&#xA;</ol>&#xA;&#xA;<p>Though I understand as to what zeromq, docker and consul is individually, I am still unable to get a clear picture of how all of them function as a whole.We have docker containers having microservices running inside them on a host. We use zeromq for transport (Pub-sub/pipeline) of messages between docker containers. The containers may be running on the same host/datacenter or on different hosts/datacenters. We then use consul for service discovery.Is my understanding correct here? </p>&#xA;&#xA;<ol start=""2"">&#xA;<li>How does the architecture dynamically scale up/down according to workload? </li>&#xA;</ol>&#xA;&#xA;<p>Say, I have a situation where I need more worker nodes for a particular computation for sometime. Who spins up more number of worker nodes. Which component determines/takes this decision? </p>&#xA;&#xA;<p>Is there a scheduling component? If so, can someone briefly explain how it happens or which component performs that function?</p>&#xA;&#xA;<ol start=""3"">&#xA;<li>So, what is the major role of consul? Is it used just for service discovery?Can it be used for configurations as well. If so, whats its limitation? </li>&#xA;</ol>&#xA;&#xA;<p>I see that even zeromq has service discovery mechanisms, so why do we require consul? </p>&#xA;&#xA;<ol start=""4"">&#xA;<li>How does a failure of a node information gets propagated in the architecture? Which component is responsible? Is it just consul ? Or zeroMq also?</li>&#xA;</ol>&#xA;&#xA;<p>Please advice.</p>&#xA;"
33478131,Centralised configuration of docker-compose services,2015-11-02 12:57:09,<database><docker><config><docker-compose><microservices>,1,87,6,2.0,3,"<p>Imagine a non-trivial <a href=""https://www.docker.com/docker-compose"" rel=""nofollow"">docker compose</a> app, with nginx in front of a webapp, and a few linked data stores:</p>&#xA;&#xA;<pre class=""lang-css prettyprint-override""><code>web:&#xA;  build: my-django-app&#xA;  volumes:&#xA;    - .:/code&#xA;  ports:&#xA;    - ""8000:8000""&#xA;  links:&#xA;    - redis&#xA;    - mysql&#xA;    - mongodb&#xA;nginx:&#xA;  image: nginx&#xA;  links:&#xA;    - web&#xA;redis:&#xA;  image: redis&#xA;  expose:&#xA;    - ""6379""&#xA;mysql:&#xA;  image: mysql&#xA;  volumes:&#xA;    - /var/lib/mysql&#xA;  environment:&#xA;    - MYSQL_ALLOW_EMPTY_PASSWORD=yes&#xA;    - MYSQL_DATABASE=myproject&#xA;mongodb:&#xA;  image: mongo&#xA;</code></pre>&#xA;&#xA;<p>The databases are pretty easy to configure (for now), the containers expose pretty nice environmental variables to control them (see the <code>mysql</code> container), but what of <code>nginx</code>? We'll need to template a vhost file for that, right?</p>&#xA;&#xA;<p>I don't want to roll my own image, that'll need rebuilding for each changed config, from different <strong>devs</strong>' setups, to <strong>test</strong>, through <strong>staging</strong> and <strong>production</strong>. And what if we want to, in a lightweight manner, do <strong>A/B testing</strong> by flipping a config option? </p>&#xA;&#xA;<p>Some <strong>centralised config management</strong> is needed here, maybe something controlled by docker-compose that can write out config files to a shared volume?</p>&#xA;&#xA;<p>This will only get more important as new services are added (imagine a microservice cloud, rather than, as in this example, a monolithic web app)</p>&#xA;&#xA;<p><strong>What is the correct way to manage configuration in a docker-compose project?</strong></p>&#xA;"
34020234,Communication between Node.js microservices,2015-12-01 12:15:03,<json><node.js><express><architecture><microservices>,1,1519,2,0.0,3,"<p>I'm creating an application with Node.js using microservices architecture. I'm trying to find the best way of communication between nodes. I have a Java background so the best option I can imagine is something like SOAP, where you create a proxy object and by calling it's method a request to a remote node would be made via http.</p>&#xA;&#xA;<p>Currently I only see an option of direct calls like </p>&#xA;&#xA;<pre><code>http.get(""remote-node/api/method1"", function(res) {&#xA;}).on('error', function(e) {&#xA;  console.log(""Got error: "" + e.message);&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>However I don't think it's convenient. Are there better approaches?</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
36844842,Patterns for knowing if a pub-sub message was successful,2016-04-25 15:26:16,<design-patterns><publish-subscribe><amazon-sqs><amazon-sns><microservices>,1,354,4,0.0,3,"<p>I'm developing microservices for a project and we're experimenting with pub-sub communication using AWS SNS+SQS. We're unsure how to signal to services whether or not other services have successfully completed tasks or not.<br>&#xA;For example, if service A emits an SNS Event and service D, E, and F all are listening to the subscribed SQS Queue, how does service A know if the activities kicked off by service A inside of service D, E, and F were successful?  </p>&#xA;&#xA;<p>I'll give a more concrete example:&#xA;A new user registers for a website.  This network call first reaches the <code>user service</code> in the backend.  If the user was successful, it sends off an event saying a new user was created.  That triggers the <code>email service</code> to send an email to for the user to confirm his registration. What happens if it fails to send an email? &#xA;Has the <code>user service</code>:</p>&#xA;&#xA;<p>1) Already responded to the frontend saying it was successful</p>&#xA;&#xA;<p>2) Or is it waiting for a confirmation?  What is a good pub-sub pattern for confirmations?  </p>&#xA;&#xA;<p>I know we could have just done a synchronous call, but this example is simplified for brevity's sake.  </p>&#xA;"
39044130,Java EE Microprofile,2016-08-19 16:47:42,<java><microservices>,2,1358,0,0.0,3,<p>I know it could be a pretty vague topic but please can someone explain it in plain English. I've read some articles regarding the trending topic java EE's 'microprofile' but was not able to clearly understand its purpose.</p>&#xA;&#xA;<p>My understanding in this emerging concept is that java community finds way to reshape the Java EE model to become a microservices friendly framework or platform. </p>&#xA;&#xA;<p>If we can already create a distributed microservice application in few minutes using spring boot or other API / library then why do we need microprofile?</p>&#xA;
39020065,Marathon: How to specify environment variables in args,2016-08-18 13:54:03,<microservices><mesos><marathon><consul>,1,2340,1,0.0,3,"<p>I am trying to run a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<p>With Marathon I have the following JSON script:</p>&#xA;&#xA;<pre><code>{&#xA;    ""id"": ""consul-agent"",&#xA;    ""instances"": 10,&#xA;    ""constraints"": [[""hostname"", ""UNIQUE""]],&#xA;    ""container"": {&#xA;        ""type"": ""DOCKER"",&#xA;        ""docker"": {&#xA;            ""image"": ""consul"",&#xA;            ""privileged"": true,&#xA;            ""network"": ""HOST""&#xA;        }&#xA;    },&#xA;    ""args"": [""agent"",""-bind"",""$MESOS_SLAVE_IP"",""-retry-join"",""$MESOS_MASTER_IP""]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>However, it seems that marathon treats the <code>args</code> as plain text.</p>&#xA;&#xA;<p>That's why I always got errors:</p>&#xA;&#xA;<pre><code>==&gt; Starting Consul agent...&#xA;==&gt; Error starting agent: Failed to start Consul client: Failed to start lan serf: Failed to create memberlist: Failed to parse advertise address!&#xA;</code></pre>&#xA;&#xA;<p>So I just wonder if there are any workaround so that I can start a Consul container on each of my Mesos slave node.</p>&#xA;&#xA;<hr>&#xA;&#xA;<p><strong>Update:</strong></p>&#xA;&#xA;<p>Thanks @janisz for the link.</p>&#xA;&#xA;<p>After taking a look at the following discussions:</p>&#xA;&#xA;<ul>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/3416"" rel=""nofollow"">#3416</a>: <em>args in marathon file does not resolve env variables</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/2679"" rel=""nofollow"">#2679</a>: <em>Ability to specify the value of the hostname an app task is running on</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1328"" rel=""nofollow"">#1328</a>: <em>Specify environment variables in the config to be used on each host through REST API</em></p></li>&#xA;<li><p><a href=""https://github.com/mesosphere/marathon/issues/1828"" rel=""nofollow"">#1828</a>: <em>Support for more variables and variable expansion in app definition</em></p></li>&#xA;</ul>&#xA;&#xA;<p>as well as the Marathon documentation on <a href=""https://mesosphere.github.io/marathon/docs/task-environment-vars.html"" rel=""nofollow"">Task Environment Variables</a>.</p>&#xA;&#xA;<p>My understanding is that:</p>&#xA;&#xA;<ul>&#xA;<li>Currently it is not possible to pass environment variables in args</li>&#xA;<li>Some post indicates that one could pass environment variables in <code>""cmd""</code>. But those environment variables are Task Environment Variables provided by Marathon, not the environment variables on your host machine.</li>&#xA;</ul>&#xA;&#xA;<p>Please correct if I was wrong.</p>&#xA;"
27857790,Best practice for redirecting between docker containers,2015-01-09 09:47:35,<redirect><docker><reverse-proxy><boot2docker><microservices>,1,964,4,0.0,3,"<p>Given I have multiple web applications running in docker containers, I want to be able to let the user be redirected from on service to another service in his browser. I wonder how to achieve this - especially if I want my applications to be portable from one docker host to a different host. </p>&#xA;&#xA;<p>Let's say we have a ServiceA which redirects the user to ServiceB. So we have a relationship </p>&#xA;&#xA;<p><code>ServiceA --&gt; ServiceB</code></p>&#xA;&#xA;<p>One approach would be to statically assign ports and hostnames and set them as environment vars to my web services - which I would not prefer because I don't want to care about which service runs on which port.</p>&#xA;&#xA;<p>A second approach would be to have a proxy like nginx and link the services and use the proxy host and port. But this would require to change the proxy configuration when moving a service to a different host.</p>&#xA;&#xA;<p>The third approach that comes to mind, is to use etcd and ambassadors to register and resolve services. So ServiceA would use a ServiceB-Ambassador which looks up ServiceB in etcd. This results in many docker containers just to connect between services.</p>&#xA;&#xA;<p>Which way would you prefer? Or are there different approaches?</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>The real problem is to inject the uri of ServiceB into ServiceA, so I can launch my ServiceA with an argument like <code>-DserviceB.uri=&lt;serviceUri&gt;</code>, so that serviceA can build the correct redirect header.</p>&#xA;"
31510697,Automating microservices load balancing / scaling,2015-07-20 07:16:00,<docker><load-balancing><coreos><microservices><akka-cluster>,1,381,0,1.0,3,"<p>Reading up on micro services for a few days now I was wondering how do people go about automating the load balancing and scaling these things?</p>&#xA;&#xA;<p>I have a specific scenario in mind what I would like to achieve but not sure if it's possible or maybe I'm thinking about it wrong. So here it goes...</p>&#xA;&#xA;<hr>&#xA;&#xA;<p>Let's say I have a cluster of 3 CoreOS machines named A,B and C.</p>&#xA;&#xA;<p>First thing I want is transparent deployment for which I can probably use fleet. </p>&#xA;&#xA;<p>Then I would like to detect, when one of the services is under huge load and deploy another instance of it and have that one and the first one deployed, automatically load balanced in a way that would not disrupt other services that are using it (traffic goes through load balancer from now on).</p>&#xA;&#xA;<p>Another way could be that I manually deploy another version of the services which then gets load balanced automatically and traffic router to the load balancer.</p>&#xA;&#xA;<p>Then the last question, how is this all different to something like Akka cluster and how does development of those differ from micro services?</p>&#xA;"
34526251,What is the difference between Kubernetes and Amazon ECS,2015-12-30 09:05:46,<docker><kubernetes><containers><microservices><amazon-ecs>,2,2207,2,0.0,3,<p>What is the difference between Amazon ECS and Kubernetes implementation architecture?</p>&#xA;&#xA;<p>I need to decide to pick a technology for container management in cloud.&#xA;What is the deciding factor while picking any of these technology?</p>&#xA;&#xA;<p>I am using Docker for container creation and execution.</p>&#xA;
34575783,Azure Service Fabric actor microservice,2016-01-03 11:03:07,<c#><microservices><azure-service-fabric>,2,1744,3,0.0,3,<p>Microsoft is offering a microservice solution for it's cloud platform Azure. There are two frameworks - reliable services and reliable actors. </p>&#xA;&#xA;<p>I was wondering if a reliable actor is an independently microservice? Or form multiple actors together a microservice?</p>&#xA;
39305118,Event publisher for ASP.NET Web Api,2016-09-03 08:57:40,<c#><asp.net><asp.net-web-api><domain-driven-design><microservices>,2,1891,3,2.0,3,"<p>I have started to work with micro-services and I need to create an event publishing mechanism.</p>&#xA;&#xA;<p>I plan to use Amazon SQS. </p>&#xA;&#xA;<p>The idea is quite simple. I store events in the database in the same transaction as aggregates.&#xA;If user would change his email, event <code>UserChangedEmail</code> will be stored in the database.</p>&#xA;&#xA;<p>I also have event handler, such as <code>UserChangedEmailHandler</code>, which will (in this case) be responsible to publish this event to SQS queue, so other services can know that user changed email.</p>&#xA;&#xA;<p>My question is, what is the practice to achieve this? Should I have some kind of background timed process which will scan events table and publish events to SQS?&#xA;Can this be process within WebApi application (preferable), or should this be a separate a process?</p>&#xA;&#xA;<p>One of the ideas was to use Hangfire, but it does not support cron jobs under a minute.</p>&#xA;&#xA;<p>Any suggestions?</p>&#xA;&#xA;<p><strong>EDIT:</strong> </p>&#xA;&#xA;<p>As suggested in the one of the answers, I've looked in to NServicebus. One of the examples on the <a href=""http://docs.particular.net/samples/step-by-step/"" rel=""nofollow"">NServiceBus page</a> shows core of my concern.</p>&#xA;&#xA;<p>In their example, they create a log that order has been placed. What if log or database entry is successfully commited, but publish breaks and event never gets published?</p>&#xA;&#xA;<p>Here's the code for the event handler:</p>&#xA;&#xA;<pre><code>public class PlaceOrderHandler :&#xA;    IHandleMessages&lt;PlaceOrder&gt;&#xA;{&#xA;    static ILog log = LogManager.GetLogger&lt;PlaceOrderHandler&gt;();&#xA;    IBus bus;&#xA;&#xA;    public PlaceOrderHandler(IBus bus)&#xA;    {&#xA;        this.bus = bus;&#xA;    }&#xA;&#xA;    public void Handle(PlaceOrder message)&#xA;    {&#xA;        log.Info($""Order for Product:{message.Product} placed with id: {message.Id}"");&#xA;        log.Info($""Publishing: OrderPlaced for Order Id: {message.Id}"");&#xA;&#xA;        var orderPlaced = new OrderPlaced&#xA;        {&#xA;            OrderId = message.Id&#xA;        };&#xA;        bus.Publish(orderPlaced); &lt;!-- my concern&#xA;    }&#xA;}&#xA;</code></pre>&#xA;"
44253950,Using soap services(.asmx) with Azure Service fabric,2017-05-30 05:16:14,<web-services><rest><soap><microservices><azure-service-fabric>,1,256,0,1.0,3,<p>I am migrating my existing services to Azure service fabric. My existing application support the soap service(asmx) for the legacy users. I want to use the same web service as part of my microservice. That web service test.asmx(say) can be called from Rest Apis as well(If soln is there). But I'm not finding any way to use the soap service as part of Azure service fabric microservice approach. Help me out of possible solutions for tackling the web service scenario. Thanks!</p>&#xA;
44331178,Testing same API for multiple response sets,2017-06-02 14:20:01,<javascript><node.js><rest><microservices><pact>,1,148,0,1.0,3,"<p>We've been trying to test an API exposed from a microservice (say GET /contacts) which is being consumed by another microservice.</p>&#xA;&#xA;<p>In order to avoid integration tests, we created consumer-driven contract tests where the consumer microservice created pacts and published them to a broker from where the producer would verify the pact separately.</p>&#xA;&#xA;<p>We've used <a href=""https://docs.pact.io/"" rel=""nofollow noreferrer"" title=""Pact IO"">Pact IO</a> to achieve this and it has been quite good so far.</p>&#xA;&#xA;<p>Now we are facing issues when trying to do exhaustive tests where we would want to see how an empty list is returned from GET /contacts.</p>&#xA;&#xA;<p>The problem is: while adding interactions, we could use Provider States but we couldn't find a way to differentiate between writing tests for getting a list of contacts from GET /contacts once and getting an empty list in another test.</p>&#xA;&#xA;<p>This is how we create pact tests in our consumer microservice:</p>&#xA;&#xA;<pre><code>mockServer.start()&#xA;        .then(() =&gt; {&#xA;          provider = pact({&#xA;            // config&#xA;          })&#xA;          return provider.addInteraction({&#xA;            state: 'Get all contacts',&#xA;            uponReceiving: 'Get all contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: //list of all contacts&#xA;            }&#xA;          })&#xA;        .then(() =&gt; {&#xA;          return provider.addInteraction({&#xA;            state: 'Get empty list of contacts',&#xA;            uponReceiving: 'Get empty list of contacts',&#xA;            withRequest: {&#xA;              method: 'GET',&#xA;              path: '/contacts',&#xA;              headers: {&#xA;                Accept: 'application/json; charset=utf-8'&#xA;              }&#xA;            },&#xA;            willRespondWith: {&#xA;              status: 200,&#xA;              body: [] // empty list&#xA;            }&#xA;          })&#xA;        })&#xA;</code></pre>&#xA;&#xA;<p>We cannot find a way to differentiate between these interations in our tests! :(</p>&#xA;&#xA;<p>Any help would be appreciated!</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
36586934,Carrying request context through the stack and across thrift service boundaries with Node.js,2016-04-13 01:26:35,<node.js><typescript><microservices><restify>,1,305,0,0.0,3,"<p>I'm trying to figure out an appropriate method to carry a request-id (x-request-id from a restify request header) through my stack; across thrift inter-service calls, and with rabbitmq queue messages. The goal is that anywhere, in any service, I can correlate an error or event back to an initiating http request. Is there a known practice for doing this with Node? I'd like to avoid passing a context around through virtually every function call.</p>&#xA;&#xA;<p>I've looked into the way New Relic handles instrumentation, and there's this blog: <a href=""https://opbeat.com/blog/posts/how-we-instrument-nodejs/"" rel=""nofollow"">https://opbeat.com/blog/posts/how-we-instrument-nodejs/</a>; but these types of instrumentation require hooking into tons of node core library calls, and don't really help with carrying the context across thrift calls.</p>&#xA;&#xA;<p>How can I take a restify header id such as ""x-request-id"" from a request, and have access to it deeper in my stack (even in async callbacks) without modifying every function to pass the values through? </p>&#xA;&#xA;<p>I'm also looking for a clean way to pass it through all thrift calls (getting it across service boundaries).</p>&#xA;&#xA;<p>This is with TypeScript and Node.js 5.x</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
33680497,What is a Java MicroService,2015-11-12 20:16:11,<java><microservices>,2,1730,3,3.0,3,"<p>I been searching on the web but im a little confused on what exactly is a java microservice. I mean i know what a web service is, and im told that a microservice is the following per wiki:</p>&#xA;&#xA;<blockquote>&#xA;  <p>In computing, microservices is a software architecture style in which complex applications are composed of small, independent processes communicating with each other using language-agnostic APIs.</p>&#xA;</blockquote>&#xA;&#xA;<p>and the properties of a microservice are:</p>&#xA;&#xA;<blockquote>&#xA;  <p>Properties of microservices architecture:</p>&#xA;  &#xA;  <p>It's a kind of architecture The services are easy to replace Services&#xA;  are organized around capabilities, e.g. user interface front-end,&#xA;  recommendation, logistics, billing, etc Services can be implemented&#xA;  using different programming languages, databases, hardware and&#xA;  software environment, depending on what fits best Architectures are&#xA;  symmetrical rather than hierarchical (producer - consumer)</p>&#xA;</blockquote>&#xA;&#xA;<p>but i need a concrete java example to understand how i can make a microservice.  Does anyone have a example you could provide ?</p>&#xA;"
41609091,Sharing files between microservices,2017-01-12 09:12:44,<node.js><microservices><seneca>,2,1858,1,1.0,3,"<p>I'm trying to move a project from its current monolithic state to microservices architecture. The project is in Node.js, so I've started looking into <a href=""http://senecajs.org/"" rel=""nofollow noreferrer"" title=""Seneca.js"">Seneca.js</a>, especially with its <a href=""https://github.com/senecajs/seneca-mesh"" rel=""nofollow noreferrer"" title=""seneca-mesh"">seneca-mesh</a> module. Moving image manipulation (crop, resize, etc.) into a microservice seemed the most sensible first step, since it drastically slows down my application now.</p>&#xA;&#xA;<p>When the application is monolithic, there is no problem in passing certain files into file-manipulation logic — just read it from local storage disk. With microsevices, however, if we keep in mind <em>scalability</em>, it becomes more difficult. Of course, I could build an image manipulation microservice, scale it up <em>within the same host machine</em>, and share directories I need between it, so they, too, can read from a local disk.</p>&#xA;&#xA;<p>What if I want a truly scalable microservice, that can be run and scaled on <em>different</em> machines with different IP-adresses that <em>don't share the same filesystem</em>? I thought that maybe I could take advantage of Node's streaming API and send these files back and forth via HTTP or TCP or sockets or you name it.</p>&#xA;&#xA;<p>As far as I've learned, Seneca.js cannot do it <em>the right way</em>. Of course, I could send a file from the main app to image manipulation service via Seneca.js like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('/files/hello.jpg')&#xA;  .on('data', function(data) {&#xA;    seneca.act({ role: 'file', cmd: 'chunk', data: data }, cb);&#xA;  })&#xA;  .on('end', function(err) {&#xA;    seneca.act({ role: 'file', cmd: 'end' });&#xA;  })&#xA;  .on('error', function(err) {&#xA;    seneca.act({ role: 'test', cmd: 'error' });&#xA;  });&#xA;</code></pre>&#xA;&#xA;<p>And receive it in chunks:</p>&#xA;&#xA;<pre><code>seneca.add({ role: 'file', cmd: 'chunk' }, writeToFileCb);&#xA;seneca.add({ role: 'file', cmd: 'end' }, endFileWriteCb);&#xA;</code></pre>&#xA;&#xA;<p>But this approach seems ugly and wheel-reinventive.</p>&#xA;&#xA;<p>Another way would be to come up with some HTTP server and send files as <code>multipart/form-data</code> or <code>application/octet-stream</code>, like so:</p>&#xA;&#xA;<pre><code>fs.createReadStream('file.json')&#xA;  .pipe(request.post('http://image-manipulator'))&#xA;</code></pre>&#xA;&#xA;<p>But this means reinventing the framework for microservice communication. All in all, I ask for advice on file sharing between distributed microservices and possible frameworks for this.</p>&#xA;"
41661858,Microservice Interaction,2017-01-15 13:52:12,<c#><.net><microservices><restful-architecture>,2,439,2,0.0,3,"<p>I would like to know what is the best practice on making one Microservice to interact with another Microservice?</p>&#xA;&#xA;<p> I am developing in C#. What I currently have done is, created a service bus which passes new events created from one Microservice. I then use task runner (WebJob) which consumes the messages off the bus and then I am using Http to Post to another Microservice endpoint. Each microservice is a web api. </p>&#xA;&#xA;<p>I would like to ask if I am doing it correctly, if not I am happy to hear the suggestions. </p>&#xA;"
46920685,How to do canary releases and dynamic routing with Netflix Zuul?,2017-10-24 21:55:19,<spring-boot><microservices><netflix-zuul><canary-deployment><dynamic-routing>,1,222,0,1.0,3,"<p>We faced with the problem that we need to do such thing as dynamic routing and canary releases. So, for example, we deploy microservice <code>microservice-1</code>. Then, when someone finished a big feature we want to deploy it as a microservice <code>microservice-1.1</code>.</p>&#xA;&#xA;<h3>Question</h3>&#xA;&#xA;<p>Is it possible to dynamically reroute requests using information, for example, from Headers, and route to the microservice version <code>microservice-1.1</code> instead on <code>microservice-1</code>?</p>&#xA;&#xA;<p>For example, someone needs this feature and he will modify/add specific Header and for all requests, he will use new <code>microservice-1.1</code>. And if that Header is missing then the current microservice-1 version should be used.</p>&#xA;&#xA;<p>For service discovery, I am using Eureka. Right now I am looking at <a href=""https://linkerd.io/"" rel=""nofollow noreferrer"">linkerd</a> but there is no support for Eureka and I am working on it right now. Of course, if it is possible to do it using Zuul that would be great. Please advise where to look at. </p>&#xA;"
38023093,Refer to another service/task running in same ECS cluster,2016-06-24 22:43:57,<docker><microservices><amazon-ecs>,1,237,0,1.0,3,"<p>I know how to refer to ""services"" from within the same task. But how can I refer to an essential task from within another task definition?&#xA;For example:</p>&#xA;&#xA;<ul>&#xA;<li>Service ""mesage-broker"" is running task rabbitmq.&#xA;&#xA;<ul>&#xA;<li>Service ""user-api"" is running task user-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;<li>Service ""order-api"" is running task order-api and needs to be configured to be able to connect to rabbitmq.</li>&#xA;</ul></li>&#xA;</ul>&#xA;"
38224152,How to maintain repositories into a single repository,2016-07-06 12:34:37,<git><docker><docker-compose><microservices>,1,65,1,1.0,3,"<p>I have a repository for each micro-services ('A', 'B', ..). The structure of a repository looks like :</p>&#xA;&#xA;<pre><code>A&#xA;|-dockerfile&#xA;|-src&#xA;  |-Java&#xA;  |-Groovy&#xA;</code></pre>&#xA;&#xA;<p>Since all of these repositories belongs to a project called 'WholeProject', I want to maintain a repository 'WholeProject' which looks like :</p>&#xA;&#xA;<pre><code>WholeProject&#xA;|-docker-compose.yml&#xA;|-µS&#xA;  |-A&#xA;  |-B&#xA;  |-..&#xA;</code></pre>&#xA;&#xA;<p>So I could easily maintain a docker-compose file and a repository that contains all the revelant things about my project.</p>&#xA;&#xA;<p>Is this a good idea ? How can I perform that ?</p>&#xA;"
42836979,Can same dyno run multiple different processes?,2017-03-16 14:31:27,<amazon-web-services><heroku><microservices>,3,373,0,0.0,3,"<p>I got a question regarding heroku architecture. I am creating small app running as microservices (not a lot of - about 4-6 microservices). The point is, that I would like to get this app available 24/7, so free dyno hours are not enough for me.</p>&#xA;&#xA;<p>I saw that if I will expand to <code>hobby</code> plan I would get something what heroku calls <code>10 Process Types</code>. Here my question comes: </p>&#xA;&#xA;<p>Can I run another microservice on each of that process (web), or heroku gives me ability only to install one web process per dyno, and given <code>10 process types</code> are for scaling my app? In other words, If i need 6 microservices running 24/7 should I buy 6 hobby dynos?</p>&#xA;"
40058568,Synchronous communication in a mostly asynchronous microservices architecture,2016-10-15 11:40:51,<architecture><publish-subscribe><microservices>,1,253,2,1.0,3,"<p>I'm trying to extract some services from my monolithic application pet project, mostly as a learning exercise. I'm using AMQP (RabbitMQ) for communication between services, which is working just fine. However, I'm having trouble separating the web frontend from the rest of the application. The web service takes care of views and UI logic, but needs to query the backend ""core"" service for the main data. AMQP doesn't seem like a good fit for this, as the frontend service needs to wait for the response, and response times are critical. My first thought was to implement a REST interface for just this line of communication, but the same service also uses AMQP to subscribe to communication of other services. </p>&#xA;&#xA;<p>This seems like it should be a pretty common occurrence, but I haven't been able to find any answers.</p>&#xA;&#xA;<p>I guess my main question is what to do when one service needs to offer both synchronous and asynchronous communication. I'm also using Ruby, which doesn't lend itself to having the multiple threads it would require to listen on two interfaces. A few things I've considered:</p>&#xA;&#xA;<ul>&#xA;<li>Just using AMQP, sending a message with a <code>reply_to</code> field, and blocking until response is received.</li>&#xA;<li>Extract the data access part of the core backend service and giving it a REST API. Then both the web service and the part that ""subscribes"" would query this other service. Seems unnecessary to have a service just for access database.</li>&#xA;<li>Having multiple threads and using some kind of event loop to listen on two interfaces. Seems overly complex.</li>&#xA;</ul>&#xA;"
49612709,Should each microservice manage its own user-permissions and user-roles?,2018-04-02 13:58:40,<jwt><microservices>,2,215,3,0.0,3,"<p>I have a design issue I am not sure of how to solve.</p>&#xA;&#xA;<p>Let's say my main application consists of 6 modules:</p>&#xA;&#xA;<ul>&#xA;<li>client</li>&#xA;<li>gateway</li>&#xA;<li>auth-service</li>&#xA;<li>forum</li>&#xA;<li>gallery</li>&#xA;<li>messages</li>&#xA;</ul>&#xA;&#xA;<p>The client is supposed to communicate with the gateway-service only.</p>&#xA;&#xA;<p>Should I have my gateway do the user-authentication (which ideally results in a JWT) and the other 3 productive-services (forum, gallery, messages) just verify that token and retrieve permissions and roles <strong>they manage themselves</strong> for that given user?</p>&#xA;&#xA;<p>To perhaps illustrate my few troubles, I create a sequence diagram:&#xA;<a href=""https://i.stack.imgur.com/j82Fv.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j82Fv.jpg"" alt=""this image shows the sequence diagram, which I am having trouble with""></a></p>&#xA;&#xA;<p><a href=""https://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharinghttps://drive.google.com/file/d/1xYbYJryk41G2c87qPqva5sARm1p68_ib/view?usp=sharing"" rel=""nofollow noreferrer"" title=""link to Google Drive file"">Click here</a> for the original draw.io graphics if you prefer that.</p>&#xA;&#xA;<p>I do not want to use any 3rd-party auth-services; I just want my auth-service (which is pretty much done) to register users and let them login. Or should I be managing permissions and roles in that service as well?</p>&#xA;&#xA;<p>I tried to wrap my brain around this issue for months, but I simply cannot find a suitable structure so I can let the user register, login/logout and communicate with various productive services. I am currently using Java for the backend stuff, but the good thing about microservices is, that I do not have to use one programming language for them all.</p>&#xA;&#xA;<p>Any help here is welcome!</p>&#xA;&#xA;<p>P.s.: I read <a href=""https://stackoverflow.com/questions/29644916/microservice-authentication-strategy"">Microservice Authentication strategy</a> and <a href=""https://stackoverflow.com/questions/33921375/zuul-api-gateway-authentication"">Zuul - Api Gateway Authentication</a>, but both did not seem to apply in my case.</p>&#xA;"
38714097,Deploy Service Fabric Application through VSTS release pipeline using Hosted Agent,2016-08-02 07:19:59,<azure><vsts><microservices><azure-service-fabric><vsts-release>,1,888,8,0.0,3,"<p>I have set up continuous integration using Hosted Agent for service fabric by following this document <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/"" rel=""nofollow noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-set-up-continuous-integration/</a></p>&#xA;&#xA;<p>In Release pipeline after importing certificate I am getting the following error and deployment failing. I am not able to identify where the issue is&#xA;<a href=""https://i.stack.imgur.com/Afc7G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Afc7G.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;  &#xA;  <p>Finishing task: ServiceFabricDeploy </p>&#xA;  &#xA;  <h2>[error]System.Exception: Task ServiceFabricDeploy failed.</h2>&#xA;  &#xA;  <p>This caused the job to fail. Look at the logs for the task for more details. </p>&#xA;  &#xA;  <p>[error]   at Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.Run(IJobContext jobContext, IJobRequest job, IJobExtension jobExtension, CancellationTokenSource tokenSource)</p>&#xA;</blockquote>&#xA;&#xA;<p>Under Deploy service fabric task it is showing the below error&#xA;<a href=""https://i.stack.imgur.com/bSCBZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bSCBZ.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>Imported cluster client certificate with thumbprint 'A6B32E70CFE715F608A247C1ED94AB3D0164A58E'.</p>&#xA;  &#xA;  <p>Thumbprint Subject                                            </p>&#xA;  &#xA;  <p>A6B32E70CFE715F608A247C1ED94AB3D0164A58E  >CN=clusternamedns.eastus.cloudapp.azure.com                                     </p>&#xA;  &#xA;  <h2>[error]An error occurred during this operation.  Please check the trace logs for more details.</h2>&#xA;</blockquote>&#xA;&#xA;<h2><strong>Update</strong></h2>&#xA;&#xA;<p>After setting system.debug to true in variables, I got the following log</p>&#xA;&#xA;<pre><code>    2016-08-03T05:44:31.6556865Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.6566887Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.6577063Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.6587072Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.6597111Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.6606871Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.6647953Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.6656886Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.6666879Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.6676869Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.6770225Z ##[debug]Leaving C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1.&#xA;&#xA;2016-08-03T05:44:31.6850322Z ##[debug]Caught exception from task script.&#xA;&#xA;2016-08-03T05:44:31.6890370Z ##[debug]Error record:&#xA;&#xA;2016-08-03T05:44:31.7380329Z ##[debug]Connect-ServiceFabricCluster : An error occurred during this operation.  Please check the trace logs for more details.&#xA;&#xA;2016-08-03T05:44:31.7390333Z ##[debug]At C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1:73 char:12&#xA;&#xA;2016-08-03T05:44:31.7410325Z ##[debug]+     [void](Connect-ServiceFabricCluster @clusterConnectionParameters)&#xA;&#xA;2016-08-03T05:44:31.7420325Z ##[debug]+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;2016-08-03T05:44:31.7430323Z ##[debug]    + CategoryInfo          : InvalidOperation: (:) [Connect-ServiceFabricCluster], FabricException&#xA;&#xA;2016-08-03T05:44:31.7440363Z ##[debug]    + FullyQualifiedErrorId : CreateClusterConnectionErrorId,Microsoft.ServiceFabric.Powershell.ConnectCluster&#xA;&#xA;2016-08-03T05:44:31.7450426Z ##[debug] &#xA;&#xA;2016-08-03T05:44:31.7470318Z ##[debug]Script stack trace:&#xA;&#xA;2016-08-03T05:44:31.7500512Z ##[debug]at &lt;ScriptBlock&gt;, C:\LR\MMS\Services\Mms\TaskAgentProvisioner\Tools\agents\1.103.1\tasks\ServiceFabricDeploy\1.0.1\deploy.ps1: line 73&#xA;&#xA;2016-08-03T05:44:31.7910331Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7920318Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 22&#xA;&#xA;2016-08-03T05:44:31.7930364Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 18&#xA;&#xA;2016-08-03T05:44:31.7940315Z ##[debug]at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1&#xA;&#xA;2016-08-03T05:44:31.7960349Z ##[debug]Exception:&#xA;&#xA;2016-08-03T05:44:31.8000522Z ##[debug]System.Fabric.FabricException: An error occurred during this operation.  Please check the trace logs for more details. ---&gt; System.Runtime.InteropServices.COMException: No credentials are available in the security package (Exception from HRESULT: 0x8009030E)&#xA;&#xA;2016-08-03T05:44:31.8010571Z ##[debug]   at System.Fabric.Interop.NativeClient.IFabricClientSettings2.SetSecurityCredentials(FABRIC_SECURITY_CREDENTIALS credentials)&#xA;&#xA;2016-08-03T05:44:31.8020684Z ##[debug]   at System.Fabric.FabricClient.SetSecurityCredentialsInternal(SecurityCredentials credentials)&#xA;&#xA;2016-08-03T05:44:31.8030335Z ##[debug]   at System.Fabric.Interop.Utility.WrapNativeSyncInvoke[TResult](Func`1 func, String functionTag, String functionArgs)&#xA;&#xA;2016-08-03T05:44:31.8040334Z ##[debug]   --- End of inner exception stack trace ---&#xA;&#xA;2016-08-03T05:44:31.8060326Z ##[debug]   at System.Fabric.Interop.Utility.RunInMTA[TResult](Func`1 func)&#xA;&#xA;2016-08-03T05:44:31.8070343Z ##[debug]   at System.Fabric.FabricClient.InitializeFabricClient(SecurityCredentials credentialArg, FabricClientSettings newSettings, String[] hostEndpointsArg)&#xA;&#xA;2016-08-03T05:44:31.8080330Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection.FabricClientBuilder.Build()&#xA;&#xA;2016-08-03T05:44:31.8090325Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ClusterConnection..ctor(FabricClientBuilder fabricClientBuilder, Boolean getMetadata)&#xA;&#xA;2016-08-03T05:44:31.8100358Z ##[debug]   at Microsoft.ServiceFabric.Powershell.ConnectCluster.ProcessRecord()&#xA;&#xA;2016-08-03T05:44:31.8340330Z ##[error]An error occurred during this operation.  Please check the trace logs for more details.&#xA;</code></pre>&#xA;"
38507565,"Connect ""MicroService Gateway"" with ""UAA Server"" Jhipster 3.5.0",2016-07-21 14:53:24,<jhipster><microservices>,4,1731,4,0.0,3,"<p>I created a UAA Server:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? [BETA] JHipster UAA server (for microservice OAuth2 authentication)&#xA;</code></pre>&#xA;&#xA;<p>And I created a Microservicio Gateway:</p>&#xA;&#xA;<pre><code>? (1/16) Which *type* of application would you like to create? Microservice gateway&#xA;...&#xA;? (6/16) What is the folder path of your UAA application?. ../elseruaa&#xA;</code></pre>&#xA;&#xA;<ul>&#xA;<li>I created the docker containers, in ""docker-compose"", and creates well.</li>&#xA;<li>I have to add some extra configuration on the gateway to work with the server UAA?</li>&#xA;<li><p>I get the following error trace in the container gateway:</p>&#xA;&#xA;<p><code>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration.setFilterChainProxySecurityConfigurer(org.springframework.security.config.annotation.ObjectPostProcessor,java.util.List) throws java.lang.Exception; nested exception is org.springframework.beans.factory.BeanExpressionException: Expression parsing failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.springframework.security.oauth2.provider.token.TokenStore org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfiguration.tokenStore; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tokenStore' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.TokenStore]: Factory method 'tokenStore' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jwtAccessTokenConverter' defined in class path resource [com/abalia/elser/config/MicroserviceSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter]: Factory method 'jwtAccessTokenConverter' threw exception; nested exception is java.lang.IllegalStateException: No instances available for elseruaa...</code></p></li>&#xA;</ul>&#xA;&#xA;<p>Thank you very much for your help.</p>&#xA;"
44946517,Unable to get jhipster gateway home page,2017-07-06 10:34:22,<angular><jhipster><microservices>,2,390,1,0.0,3,<p>I am unable to open My JHipster + Angular 2 (Gateway) Application home page with port 8080 (which is given at server port in application-dev.yml)&#xA;There is no errors in console.</p>&#xA;&#xA;<p><code>index.html</code> completely loading may be routing is not working fine.</p>&#xA;&#xA;<p>The Same application is running fine on port 9000 (which is provided by yarn) </p>&#xA;&#xA;<p>My problem is if I use 9000 port (Given by yarn) unable to communicate with other micro services applications.</p>&#xA;
48873507,Caching in a Microservices architecture,2018-02-19 20:14:02,<microservices>,1,589,0,0.0,3,"<p>In the <strong>API Gateway</strong> a caching feature can be implemented to reduce access time and bandwidth usage.<br>&#xA;What kind of data are cached in the gateway? <br>&#xA;In a <em>micro-services architecture</em>, does a gateway cache the discovered services descriptions ? if so, how he maintains the consistency of his cache?</p>&#xA;"
48963386,"Microservices, REST, event sourcing and data consistency",2018-02-24 13:29:08,<rest><apache-kafka><domain-driven-design><microservices><event-sourcing>,1,246,1,0.0,3,"<p>I'm planning a model for microservices using event sourcing. To achieve a high scalability and high throughput handling capacity, I'll use Kafka as a message broker for the microservices.</p>&#xA;&#xA;<p>At this point, I have questions about the implementation of the model to be able to have the benefits of Kafka topic and partition. There are some requirements that my model needs to fit:</p>&#xA;&#xA;<ol>&#xA;<li>Microservices must ingest data from the message broker (POST/PATCH/PUT/DELETE)</li>&#xA;<li>Data consistency is mandatory, if entity A needs previous existence of entity B, then must exists only records of entity A that points to valid records of entity B</li>&#xA;<li>The microservices can't couple their domains (refering to DDD)</li>&#xA;<li>The system must handle high thrgoughput of read and writes operations</li>&#xA;</ol>&#xA;&#xA;<p>Well, with this requirements in mind, I've endend up with a model that:</p>&#xA;&#xA;<ol>&#xA;<li>Use an Elasticsearch database that have the current valid state</li>&#xA;<li>All write requests are received by a ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Validate the request and the new state that is requested</li>&#xA;<li>Produce a write operation in the message broker</li>&#xA;<li>Receives state change events from the message broker</li>&#xA;<li>Responds to requester with the new state changed</li>&#xA;</ol></li>&#xA;<li>All write operations are consumed by a ""Microservice Processor"" that:&#xA;&#xA;<ol>&#xA;<li>Handles all the business logic and data denormalization</li>&#xA;<li>Updates the state in the Elasticsearch database</li>&#xA;<li>Produce a state change event in the message broker</li>&#xA;</ol></li>&#xA;<li>All read requests are handled by the ""Microservice Gateway"" that:&#xA;&#xA;<ol>&#xA;<li>Searchs at the Elasticsearch database for the requested resource's records</li>&#xA;<li>Responds to the requester with the results</li>&#xA;</ol></li>&#xA;</ol>&#xA;&#xA;<p>My questions:</p>&#xA;&#xA;<ol>&#xA;<li>This model does some coupling of the domains? The Gateway is validating subresources ID's to ensure data consistency in one Elasticsearch database (the case of A pointing to B).</li>&#xA;<li>I don't know if this model fits reports requests, there are some complex reports that process a lot of data with input parameters from the user and from his point of view, the operation must be ""synchronous"" (request/response REST)</li>&#xA;<li>Is the validation of requests/new state a part of the business logic (related to DDD)? If so, my model is incorret to separate them into two microservices?</li>&#xA;</ol>&#xA;&#xA;<p><strong>EDIT</strong></p>&#xA;&#xA;<p>My new proposal for my client:</p>&#xA;&#xA;<ol>&#xA;<li>Instead of having a gateway acting as a part of the microservice, let gateway only for: routing (microservice registry), balancing and auth stuffs (calling a dedicated microservice for authentication/authorization)</li>&#xA;<li>The microservices hold their own data/database, consistency is ensured by event sourcing architeture</li>&#xA;<li>Reports: if it's about one domain, can be a resource at the microservice that holds the data, if more than one domain is required, another microservice will provide the report</li>&#xA;</ol>&#xA;"
36705199,Lock a Service-Bus Queue and prevent others from accessing it,2016-04-18 22:12:03,<c#><azureservicebus><microservices>,4,541,5,1.0,3,"<p>I have multiple queues that multiple clients insert messages into them.</p>&#xA;&#xA;<p>On the server side, I have multiple micro-services that access the queues and handle those messages. I want to lock a queue whenever a service is working on it, so that other services won't be able to work on that queue.</p>&#xA;&#xA;<p>Meaning that if service A is processing a message from queue X, no other service can process a message from that queue, until service A has finished processing the message. Other services can process messages from any queue other than X.</p>&#xA;&#xA;<p>Does anyone has an idea on how to lock a queue and prevent others from accessing it? preferably the other services will receive an exception or something so that they'll try again on a different queue.</p>&#xA;&#xA;<p><strong>UPDATE</strong></p>&#xA;&#xA;<p>Another way can be to assign the queues to the services, and whenever a service is working on a queue no other service should be assigned to the queue, until the work item was processed. This is also something that isn't easy to achieve.</p>&#xA;"
44495957,docker microservice apps restart over and over again in kubernetes,2017-06-12 09:29:14,<docker><kubernetes><microservices>,1,422,9,0.0,3,"<p>I am trying to run microservice applications with kubernetes. I have rabbitmq, elasticsearch and eureka discovery service running on kubernetes. Other than that, I have three microservice applications. When I run two of them, it is fine; however when I run the third one they all began restarting over and over again without any reason.</p>&#xA;&#xA;<p>One of my config files:</p>&#xA;&#xA;<pre><code>apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: hrm&#xA;  labels:&#xA;    app: suite&#xA;spec:&#xA;  type: NodePort&#xA;  ports:&#xA;    - port: 8086&#xA;      nodePort: 30001&#xA;  selector:&#xA;    app: suite&#xA;    tier: hrm-core&#xA;---&#xA;apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: hrm&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: suite&#xA;        tier: hrm-core&#xA;    spec:&#xA;      containers:&#xA;      - image: privaterepo/hrm-core&#xA;        name: hrm&#xA;        ports:&#xA;        - containerPort: 8086&#xA;      imagePullSecrets:&#xA;      - name: regsecret&#xA;</code></pre>&#xA;&#xA;<p>Result from kubectl describe pod hrm:</p>&#xA;&#xA;<pre><code> State:     Running&#xA;      Started:      Mon, 12 Jun 2017 12:08:28 +0300&#xA;    Last State:     Terminated&#xA;      Reason:       Error&#xA;      Exit Code:    137&#xA;      Started:      Mon, 01 Jan 0001 00:00:00 +0000&#xA;      Finished:     Mon, 12 Jun 2017 12:07:05 +0300&#xA;    Ready:      True&#xA;    Restart Count:  5&#xA;  18m       18m     1   kubelet, minikube               Warning     FailedSync  Error syncing pod, skipping: failed to ""StartContainer"" for ""hrm"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=hrm pod=hrm-3288407936-cwvgz_default(915fb55c-4f4a-11e7-9240-080027ccf1c3)""&#xA;</code></pre>&#xA;&#xA;<p>kubectl get pods:</p>&#xA;&#xA;<pre><code>NAME                        READY     STATUS    RESTARTS   AGE&#xA;discserv-189146465-s599x    1/1       Running   0          2d&#xA;esearch-3913228203-9sm72    1/1       Running   0          2d&#xA;hrm-3288407936-cwvgz        1/1       Running   6          46m&#xA;parabot-1262887100-6098j    1/1       Running   9          2d&#xA;rabbitmq-279796448-9qls3    1/1       Running   0          2d&#xA;suite-ui-1725964700-clvbd   1/1       Running   3          2d&#xA;</code></pre>&#xA;&#xA;<p>kubectl version:</p>&#xA;&#xA;<pre><code>Client Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.4"", GitCommit:""d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae"", GitTreeState:""clean"", BuildDate:""2017-05-19T18:44:27Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.0"", GitCommit:""fff5156092b56e6bd60fff75aad4dc9de6b6ef37"", GitTreeState:""dirty"", BuildDate:""2017-04-07T20:43:50Z"", GoVersion:""go1.7.1"", Compiler:""gc"", Platform:""linux/amd64""}&#xA;</code></pre>&#xA;&#xA;<p>minikube version:</p>&#xA;&#xA;<pre><code>minikube version: v0.18.0&#xA;</code></pre>&#xA;&#xA;<p>When I look at pod logs, there is no error. It seems like it starts without any problem. what could be the problem here?</p>&#xA;&#xA;<p>edit: output of kubectl get events:</p>&#xA;&#xA;<pre><code>19m        19m         1         discserv-189146465-lk3sm    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Created                   kubelet, minikube       Created container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         discserv-189146465-lk3sm    Pod          spec.containers{discserv}   Normal    Started                   kubelet, minikube       Started container with id 1607af1a7d217a6c9c91c1061f6b2148dd830a525b4fb02e9c6d71e8932c9f67&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Pulled                    kubelet, minikube       Container image ""elasticsearch:2.4"" already present on machine&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Created                   kubelet, minikube       Created container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;19m        19m         1         esearch-3913228203-6l3t7    Pod          spec.containers{esearch}    Normal    Started                   kubelet, minikube       Started container with id db30f7190fec4643b0ee7f9e211fa92572ff24a7d934e312a97e0a08bb1ccd60&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned hrm-3288407936-d2vhh to minikube&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Created                   kubelet, minikube       Created container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936-d2vhh        Pod          spec.containers{hrm}        Normal    Started                   kubelet, minikube       Started container with id 34d1f35fc68ed64e5415e9339405847d496e48ad60eb7b08e864ee0f5b87516e&#xA;18m        18m         1         hrm-3288407936              ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: hrm-3288407936-d2vhh&#xA;18m        18m         1         hrm                         Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set hrm-3288407936 to 1&#xA;19m        19m         1         minikube                    Node                                     Normal    RegisteredNode            controllermanager       Node minikube event: Registered Node minikube in NodeController&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kubelet, minikube       Starting kubelet.&#xA;19m        19m         1         minikube                    Node                                     Warning   ImageGCFailed             kubelet, minikube       unable to find data for container /&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeAllocatableEnforced   kubelet, minikube       Updated Node Allocatable limit across pods&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientDisk     kubelet, minikube       Node minikube status is now: NodeHasSufficientDisk&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasSufficientMemory   kubelet, minikube       Node minikube status is now: NodeHasSufficientMemory&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeHasNoDiskPressure     kubelet, minikube       Node minikube status is now: NodeHasNoDiskPressure&#xA;19m        19m         1         minikube                    Node                                     Warning   Rebooted                  kubelet, minikube       Node minikube has been rebooted, boot id: f66e28f9-62b3-4066-9e18-33b152fa1300&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeNotReady              kubelet, minikube       Node minikube status is now: NodeNotReady&#xA;19m        19m         1         minikube                    Node                                     Normal    Starting                  kube-proxy, minikube    Starting kube-proxy.&#xA;19m        19m         1         minikube                    Node                                     Normal    NodeReady                 kubelet, minikube       Node minikube status is now: NodeReady&#xA;8m         8m          1         minikube                    Node                                     Warning   SystemOOM                 kubelet, minikube       System OOM encountered&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod                                      Normal    Scheduled                 default-scheduler       Successfully assigned parabot-1262887100-r84kf to minikube&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;8m         18m         2         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;18m        18m         1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id ed8b5c19a2ad3729015f20707b6b4d4132f86bd8a3f8db1d8d79381200c63045&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Created                   kubelet, minikube       Created container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;8m         8m          1         parabot-1262887100-r84kf    Pod          spec.containers{parabot}    Normal    Started                   kubelet, minikube       Started container with id 664931f24e482310e1f66dcb230c9a2a4d11aae8d4b3866bcbd084b19d3d7b2b&#xA;18m        18m         1         parabot-1262887100          ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller   Created pod: parabot-1262887100-r84kf&#xA;18m        18m         1         parabot                     Deployment                               Normal    ScalingReplicaSet         deployment-controller   Scaled up replica set parabot-1262887100 to 1&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulling                   kubelet, minikube       pulling image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""rabbitmq""&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Created                   kubelet, minikube       Created container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         rabbitmq-279796448-pcqqh    Pod          spec.containers{rabbitmq}   Normal    Started                   kubelet, minikube       Started container with id 155e900afaa00952e4bb9a7a8b282d2c26004d187aa727201bab596465f0ea50&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod                                      Normal    SandboxChanged            kubelet, minikube       Pod sandbox changed, it will be killed and re-created.&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulling                   kubelet, minikube       pulling image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Pulled                    kubelet, minikube       Successfully pulled image ""private repo""&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Created                   kubelet, minikube       Created container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;19m        19m         1         suite-ui-1725964700-ssshn   Pod          spec.containers{suite-ui}   Normal    Started                   kubelet, minikube       Started container with id bcaa7d96e3b0e574cd48641a633eb36c5d938f5fad41d44db425dd02da63ba3a&#xA;</code></pre>&#xA;"
44124914,How to deploy multiple version of an application in production for microservice based application,2017-05-23 02:40:41,<api><amazon-web-services><elastic-beanstalk><microservices><production-environment>,4,920,0,3.0,3,"<p><br/>&#xA;Is it possible to have multiple versions of service(s) deployed in production at the same time. From my assumption, this should be pretty common pattern for microservice/api based projects or mobile projects. I want to know how do you do it and what are common pattern in industry for this kind of problems. It would be helpful if your answers around AWS environment or Kubernetes environment.&#xA;<br/>Thanks in Advance.</p>&#xA;"
44183595,Java - Kubernetes find services by label,2017-05-25 14:54:26,<java><spring-boot><kubernetes><spring-cloud><microservices>,2,436,0,3.0,3,"<p>I'm trying to develop a sample application using spring cloud and minikube which consist of 3 spring boot applications.</p>&#xA;&#xA;<p>The first two are two different application (servers) which have the same endpoint but different functionality, and the third one is a client used to integrates the two other applications into one single exposed api.</p>&#xA;&#xA;<p>I managed to deploy all three applications in minikube and managed to develop the full stack and make them communicate between each other, but now I want to go a step further and make the discovery of the two servers automatically, without hard coding the service names.</p>&#xA;&#xA;<p>I deployed the two servers in minikube using the same label and would like to find something so that the client is able to find the services related to the two server apps automatically. This will allow expanding the application easily, so that when I add a new server to the stack the client will find it and expose it without need of any change.</p>&#xA;&#xA;<p>Using Netflix Eureka this can be easily achieved by using something like </p>&#xA;&#xA;<pre><code>discoveryClient.getInstances(""service-name"").forEach((ServiceInstance s)&#xA;</code></pre>&#xA;&#xA;<p>But I do no want to add an extra eureka server to the list of microservices since we are going to use kubernetes.</p>&#xA;&#xA;<p>Is there any library which gives this functionality for kubernetes?</p>&#xA;"
46386326,Backing Services as attached resources,2017-09-24 03:32:03,<spring-boot><cloud><microservices><cloudfoundry><12factor>,1,126,0,0.0,3,"<p>I was looking at 12 factor app principle and saw this statement. I believe this statement states that the application must respond to any backing service such database or message broker and connect to them irrespective of what they are. How does it differ from traditional way of connecting? For eg: in my microservice , I was defined database and kafka broker as user provided service in cloud foundry. It just provides the connection parameters as vcap service variables. I still have code to connect to a database and kafka broker which are entirely different. What does this statement signify and how does it differ from what we do in non-cloud environment?</p>&#xA;"
41008507,Is there an established pattern for paging in Service Fabric ReliableCollections,2016-12-07 02:36:18,<azure><microservices><azure-service-fabric><service-fabric-stateful>,2,403,0,2.0,3,"<p>In reliable collections (specifically IReliableDictionary), an approach for implementing 'common' queries is to update a secondary dictionary which structures the keys to be ordered a specific way in an enumeration.  For large data sets, <strong>I would like to avoid shuttling a large amount of data around</strong>.  </p>&#xA;&#xA;<p>To achieve this I would like to <strong>implement some sort of continuation token</strong> which the caller can supply to me when requesting the data.  I am currently implementing this by first generating an ordered enumeration and returning the first n items where n = the MAX_PAGE size.   <strong>The continuation is essentially the last key in that list of n items</strong>. The next time the caller passes in the continuation token, <strong>I generate the ordered enumerable with the filter function specifying that the key should be greater than the continuation</strong>.  </p>&#xA;&#xA;<p>This has 2 problems (that I can see):</p>&#xA;&#xA;<ol>&#xA;<li>The <strong>collection could change between when the caller first requests a page and a subsequent request</strong>.  This, I'm not certain I can avoid since updates to the collection need to be able to occur at any time regardless of who is attempting to page through the data.</li>&#xA;<li>I'm not certain how the filter function is used. I would assume that since a developer could filter on anything, the <strong>GetEnumerableAsync() method must supply all keys in the dictionary before returning the enumerable</strong>.  For a sufficiently large data set, this seems slow.</li>&#xA;</ol>&#xA;&#xA;<p><strong>Are there any prescribed approaches for paging data like this?</strong>  I am beginning to feel like I might be barking up the wrong tree with Reliable Collections for some of my use cases.  </p>&#xA;"
40890804,Register MicroServices in Azure Active Directory (AAD) for Security,2016-11-30 14:24:14,<azure><asp.net-web-api><owin><azure-active-directory><microservices>,1,654,4,0.0,3,"<p>I have a service fabric application (Stateless and Statefull) deployed in Service fabric cluster. I am trying to implement security in the applications. The application uses the Active Directory Authentication Library (ADAL) to get a token from Azure AD using the OAuth 2.0 client credential flow, where the client credential is a password. I am able to implement the same scenario in ordinary web api applications by registering them in Azure portal. Can anyone tell me how to register a service fabric microservice application with WebApi exposed using Owin. i have difficulties registering the reply url and sign on url as the urls are dynamic(for statefull partitionid and replica id). I receive unauthorized access while calling the corresponding service. I am not sure of what url has to be registered for a statefull or stateless application when adding the application in in azure active directory. Could you please suggest me where I'm wrong and what to do to implement.</p>&#xA;"
50328886,How to setup nginx as reverse proxy for rest microservice in kubernetes?,2018-05-14 11:11:19,<docker><nginx><kubernetes><microservices>,3,125,2,2.0,3,<p>I have a rest microservice and would like to setup nginx as a reverse proxy for it. I am little confused about which approach to follow:</p>&#xA;&#xA;<ol>&#xA;<li>Run nginx in each pod where application code is running.</li>&#xA;<li>Run nginx in separate pods and redirect http requests to application code running in separate pods.</li>&#xA;</ol>&#xA;&#xA;<p>Can someone explain which one is better </p>&#xA;
34301614,"Zuul url mapping with spring boot,Eureka",2015-12-15 23:47:42,<spring-boot><spring-cloud><microservices><netflix-eureka><netflix-zuul>,1,3960,3,1.0,3,<p>I am building Rest api using microservice architecture. I have multiple apis for user that we have made into multiple projects. I have everything else ready except I am not able to map the user facing url to the application url in zuul.</p>&#xA;&#xA;<p>The user facing url is : user/v1/accountholders/{id}/cards and the actual url for my application is /user-cards/v1/accountholders/{id}/cards. </p>&#xA;&#xA;<p>Here id is the path variable. Below are other similar api url so if there is a way to configure them generically in zuul. Also the context root of the application url is also the project name in Eureka.</p>&#xA;&#xA;<pre><code>Other similar urls are:&#xA;&#xA;client side:- /user/v1/accountholders/{id}/cards/{cardid}&#xA;application:- /user-cards/v1/accountholders/{id}/cards/{cardid}&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders&#xA;application:- /user-cardholder/v1/accountholder&#xA;&#xA;client side:- /user/v1/accountholders/{id}&#xA;application:- /user-cardholder/v1/accountholders/{id}&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts&#xA;&#xA;client side:- /user/v1/accountholders/{id}/accounts/{accid}&#xA;application:- /user-accounts/v1/accountholders/{id}/accounts/{accid}&#xA;</code></pre>&#xA;&#xA;<p>Need some help to set this up in the properties or yml file for zuul. I havent been able to make any progress with the mapping stuff yet. Any inputs will be helpful.</p>&#xA;&#xA;<p><strong>SOLVED:-</strong>&#xA;After getting the input from @Daniel (which is the accepted answer)This is what i used in zuul config:-</p>&#xA;&#xA;<pre><code>zuul:&#xA; routes:&#xA;   User-Cards: &#xA;        path: /user/v1/accountholders/*/cards/**&#xA;        url: http://desktop-uvkv1ed:9999/user-cards/v1/accountholders&#xA;   User-Transactions1: &#xA;        path: /user/v1/accountholders/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Transactions2:  &#xA;        path: /user/v1/accountholders/*/accounts/*/transactions&#xA;        url: http://desktop-uvkv1ed:5555/user-transactions/v1/accountholders&#xA;        service-id: User-Transactions&#xA;   User-Accounts: &#xA;        path: /user/v1/accountholders/*/accounts/**&#xA;        url: http://desktop-uvkv1ed:7777/user-accounts/v1/accountholders&#xA;   User-Cardholders: &#xA;        path: /user/v1/accountholders/**&#xA;        url: http://desktop-uvkv1ed:8888/user-cardholders/v1/accountholders&#xA;</code></pre>&#xA;
37243939,How to initialize a postgres database tables in microservice architecture with node running in docker,2016-05-15 21:39:56,<node.js><postgresql><docker><containers><microservices>,1,460,1,1.0,3,"<p>What is the best practice for initializing a node microservice's tables in a postgres database ? Should it be on service start ?</p>&#xA;&#xA;<p>I'm thinking of copying all the .sql files to the container (during docker build) + install psql into that container, and only run the .sql files during docker run before npm start. Does this make sense ?</p>&#xA;&#xA;<p>I need to consider the fact that soon I will need to manage upgrading the database's tables for the microservice as well.</p>&#xA;"
43529266,How to use Haskell Stack with Docker Compose?,2017-04-20 20:25:35,<haskell><docker><docker-compose><microservices><haskell-stack>,1,398,2,0.0,3,"<p>I am trying to use docker compose to tie together some haskell services for local development. Most of the time I'm messing around in <code>stack ghci</code>, running unit tests, etc, but I also need to be able to run code that hits a dependency. Docker compose is great for this: I can run the dependencies (databases, other services, etc), and link everything together. </p>&#xA;&#xA;<p>Stack has docker support. It can build in a docker container with <code>docker: enable: true</code>, and also can create an executable image with <code>stack image container</code>.</p>&#xA;&#xA;<p>How do I leverage stack's docker functionality from within <code>docker-compose.yml</code>? </p>&#xA;&#xA;<pre><code>version: ""3""&#xA;&#xA;services:&#xA;&#xA;  my-service:&#xA;&#xA;    # how can I use `stack image container` here? Is it possible?&#xA;    build: '.'&#xA;&#xA;    links:&#xA;    - other-service&#xA;&#xA;    env_file:&#xA;    - test.env&#xA;&#xA;  other-service:&#xA;    image: other-service-image&#xA;</code></pre>&#xA;&#xA;<p>Do I have to make my own Dockerfile, or is there some way to use the <code>stack image container</code> functionality?</p>&#xA;&#xA;<p>Follow-up questions: Is there some way to run <code>stack ghci</code> with all the settings (env, links, etc) from the docker compose file? </p>&#xA;"
48134800,Deploying Go apps with micro-service architecture in containers or not in containers?,2018-01-07 06:15:06,<go><kubernetes><microservices><devops><docker-container>,2,331,3,1.0,3,"<p>I'm new to DevOps specifically using golang and microservice architecture.</p>&#xA;&#xA;<p>I'm wondering if go applications should or should not be deployed in containers (Docker). In this case, I have a system built with micro-service architecture. For example here, I have 2 web services, A and B. Also I have another web server acts as a gateway in front of those two.</p>&#xA;&#xA;<p>Both A and B need access for a database, MySQL for example. A handles table A, and B handles table B.</p>&#xA;&#xA;<p>I know that in Go, source codes are compiled into a single executable binary file. And because I have 3 services here, I have 3 binaries. All three run as web server exposing JSON REST API.</p>&#xA;&#xA;<p>My questions are these:</p>&#xA;&#xA;<ul>&#xA;<li><p><strong>Can I deploy these servers together in one host running on different ports?</strong>&#xA;If my host get an IP x.x.x.x for example, my gateway can run in x.x.x.x:80, A in port 81, and B in port 82 for example. A and B will talk to a MySQL server somewhere outside or maybe inside the same host. Is this a good practice? Can Continuous Deployment works with this practice?</p></li>&#xA;<li><p><strong>Why should I deploy and run those binaries inside containers like Docker?</strong>&#xA;I know that since its release few years ago, Docker had found its way to be integrated inside a development workflow easily. But of course using Docker is not as simple as just compiling the code into a binary and then moving it to a deployment server. Using Docker we have to put the executable inside the container and then move the container as well to the deployment server.</p></li>&#xA;<li><p><strong>What about scalibility and high availability without using Docker?</strong>&#xA;Can I just replicate my services and run them all at once in different hosts using a load balancer? This way I should deploy A, B, and gateway in one host, and another A, B, and gateway in another host, then setup load balancer in front of them. A, B, and the gateway runs in port 80, 81, and 82 respectively. This way I could have  thousands of nodes in a form of VMs or LXD containers maybe, spread accross hundreds of bare metals, deployed with a simple bash script and ssh, or Ansible if things get complex. Yes or no?</p></li>&#xA;<li><p><strong>And what about the scalability and availability of using Docker?</strong>&#xA;Should I just put all my services inside containers and manage them with something like Kubernetes to achieve high availability? Doing this does add overhead, right? Because the team will have to learn new technology like Kubernetes if they haven't known it yet.</p></li>&#xA;<li><p>Can you give me an example of some best practices of deploying golang services?</p></li>&#xA;</ul>&#xA;"
42199241,What is an efficient way to communicate in microservices architecture,2017-02-13 08:03:56,<node.js><web-services><amazon-ec2><microservices>,3,319,0,0.0,3,<p>I am using Node.js and a REST based light weight web service to communicate between servers. i want to know if there is another more efficient way to communicate between servers?&#xA;I am using ec2 instances in a vpn.</p>&#xA;
48791411,Horizontal scaling of consumers when the publisher provides sequenced messages,2018-02-14 16:02:53,<asynchronous><rabbitmq><microservices>,4,167,0,1.0,3,"<p>In a distributed service oriented architecture, lets say I have a producer that send messages to a consumer using RMQ. </p>&#xA;&#xA;<p>We decided then to horizontally scale the consuming part of our architecture by adding more consumers and we faced some limitations.</p>&#xA;&#xA;<p>The publisher provide a sequence number in every message it sent. And it’s very important that the consumers process the messages based on the sequence number it has.</p>&#xA;&#xA;<p>Every time that deal with a given resource, lets say A, the publisher will send RMQ messages that says ""Hey lets do sequence 1 for A"" and then ""Hey lets do sequence 2 for A"" and so on.</p>&#xA;&#xA;<p>If for example the publisher provides 3 messages for A with sequences 1, 2 and 3 and the 3 messages are distributed to 3 different instances of our consumer. The message of sequence 2 is requeued until sequence 1 is well processed, same for sequence 3.</p>&#xA;&#xA;<p>At the end the messages are all well processed, but after many retries! This causes some latency in our system as we retries many times if we’ve 100 sequences to consume.</p>&#xA;&#xA;<p>A possible solution would be to make sure each set of sequences for a given resource has to be processed by the same consumer. But how can we achieve that?</p>&#xA;&#xA;<p>How can I avoid the requeuing in order to make sure every instance of our consumer always get the messages for a given resource well ordered?</p>&#xA;"
48624757,Asynchronous Message-Passing and Microservices,2018-02-05 14:27:51,<java><spring-boot><apache-kafka><microservices>,3,434,2,2.0,3,"<p>I am planning the develop of a microservice based architecture application and I decided to use kafka for the internal communicaton while I was reading the book <em>Microservice Architecture by Ronnie Mitra; Matt McLarty; Mike Amundsen; Irakli Nadareishvili</em> where they said: </p>&#xA;&#xA;<blockquote>&#xA;  <p>letting microservices directly interact with message brokers (such as&#xA;  RabbitMQ, etc.) is rarely a good idea. If two microservices are&#xA;  directly communicating via a message-queue channel, they are sharing a&#xA;  data space (the channel) and we have already talked, at length, about&#xA;  the evils of two microservices sharing a data space. Instead, what we&#xA;  can do is encapsulate message-passing behind an independent&#xA;  microservice that can provide message-passing capability, in a loosely&#xA;  coupled way, to all interested microservices.</p>&#xA;</blockquote>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/XK10H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XK10H.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I am using Netflix Eureka for Service registration and discovery, Zuul as edge server and Hystrix. &#xA;Said so, in practice, how can I implement that kind of microservice? How can I make my microservices indipendent from the communcation channel ( in this case Kafka)? &#xA;Actually I'm directly interacting with the channel, so I don't have an extra layer between my publishers/subscribers and kafka.</p>&#xA;&#xA;<p><strong>UPDATE 06/02/2018</strong></p>&#xA;&#xA;<p>to be more precise, we have a couple of microservices: one is publishing news on a topic (activemq, kafka...) and the other microservice is subscribed on that topic and doing some operations on the messages that are coming through. So we have these services that are coupled to the message broker (to the channel)... we have the the message broker's apis ""embedeed"" on our code and for example, if we want to change the message broker we have to change all the microservices that made use of the message broker's api. So, they are suggesting to use a microservice(in the picture I assume is the Events Hub) that is the ""dispatcher"" of the various messages. In this way it is the only component that interacts with the channel.</p>&#xA;"
41164987,User's locale in microservice - JHipster,2016-12-15 13:09:07,<java><spring-security><jwt><jhipster><microservices>,1,264,0,0.0,3,"<p>In one of the microservices, in a JHipster microservice architecture, I want to generate a document, in the users' language.</p>&#xA;&#xA;<p>In the gateway, the users' language is retrieved by a cookie (AngularCookieLocaleResolver). But when a request, routed through the gateway, arrives at the microservice, no cookies are found on the request.</p>&#xA;&#xA;<p>I see a few options here:</p>&#xA;&#xA;<ol>&#xA;<li>Add a locale claim to the JWT-token</li>&#xA;<li>Contact the gateway with the username, to retrieve the locale</li>&#xA;<li>Do not generate locale specific content at a microservice</li>&#xA;</ol>&#xA;&#xA;<p>I would prefer the first option, but maybe there are some better options...</p>&#xA;&#xA;<p>Can anyone help me choose or list up alternatives?</p>&#xA;"
40422613,Sharing data between isolated microservices,2016-11-04 12:24:29,<web-services><heroku><database-design><web-applications><microservices>,1,804,1,3.0,3,"<p>I'd like to use the microservices architectural pattern for a new system, but I'm having trouble figuring out how to share and merge data between the services when the services are isolated from each other. In particular, I'm thinking of returning consolidated data to populate a web app UI over HTTP.</p>&#xA;&#xA;<p>For context, I'm intending to deploy each service to its own isolated environment (Heroku) where I won't be able to communicate internally between services (e.g. via <code>//localhost:PORT</code>. I plan to use RabbitMQ for inter-service communication, and Postgres for the database.</p>&#xA;&#xA;<p>The decoupling of services makes sense for CREATE operations:</p>&#xA;&#xA;<ul>&#xA;<li>Authenticated user with <code>UserId</code> submits 'Join group' webform on the frontend</li>&#xA;<li>A new <code>GroupJoinRequest</code> including the <code>UserId</code> is added to the RabbitMQ queue</li>&#xA;<li>The <code>Groups</code> service picks up the event and processes it, referencing the user's <code>UserId</code></li>&#xA;</ul>&#xA;&#xA;<p>However, READ operations are much harder if I want to merge data across tables/schemas. Let's say I want to get details for all the users in a certain group. In a monolithic design, I'd just do a SQL <code>JOIN</code> across the Users and the Groups tables, but that loses the isolation benefits of microservices.</p>&#xA;&#xA;<p>My options seem to be as follows:</p>&#xA;&#xA;<h3>Database per service, public API per service</h3>&#xA;&#xA;<p>To view all the <code>Users</code> in a <code>Group</code>, a site visitor gets a list of <code>UserID</code>s associated with a group from the Groups service, then queries the <code>Users</code> service separately to get their names.</p>&#xA;&#xA;<p><strong>Pros:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>very clear separation of concerns</li>&#xA;<li>each service is entirely responsible for its own data</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>requires multiple HTTP requests</li>&#xA;<li>a lot of postprocessing has to be done client-side</li>&#xA;<li>multiple SQL queries can't be optimized</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data over HTTP, single public API</h3>&#xA;&#xA;<p>A public API server handles request endpoints. Application logic in the API server makes requests to each service over a HTTP channel that is only accessible to other services in the system.</p>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>good separation of concerns</li>&#xA;<li>each service is responsible for an API contract but can do whatever it wants with schema and data store, so long as API responses don't change</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>non-performant</li>&#xA;<li>HTTP seems a weird transport mechanism to be using for internal comms</li>&#xA;<li>ends up exposing multiple services to the public internet (even if they're notionally locked down), so security threats grow from greater attack surface</li>&#xA;</ul>&#xA;&#xA;<h3>Database-per-service, services share data through message broker</h3>&#xA;&#xA;<p>Given I've already got RabbitMQ running, I could just use it to queue requests for data and then to send the data itself. So for example:</p>&#xA;&#xA;<ul>&#xA;<li>client requests all Users in a Group</li>&#xA;<li>the public API service sends a <code>GetUsersInGroup</code> event with a <code>RequestID</code></li>&#xA;<li>the <code>Groups</code> service picks this up, and adds the <code>UserID</code>s to the queue</li>&#xA;<li>The `Users service picks this up, and adds the User data onto the queue</li>&#xA;<li>the API service listens for events with the <code>RequestID</code>, waits for the responses, merges the data into the correct format, and sends back to the client</li>&#xA;</ul>&#xA;&#xA;<p><strong>Pros:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Using existing infrastructure</li>&#xA;<li>good decoupling</li>&#xA;<li>inter-service requests remain internal (no public APIs)</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Multiple SQL queries</li>&#xA;<li>Lots of data processing at the application layer</li>&#xA;<li>harder to reason about</li>&#xA;<li>Seems strange to pass large quantities around data via event system</li>&#xA;<li>Latency?</li>&#xA;</ul>&#xA;&#xA;<h3>Services share a database, separated by schema, other services read from <code>VIEW</code>s</h3>&#xA;&#xA;<p>Services are isolated into database schemas. Schemas can only be written to by their respective services. Services expose a SQL <code>VIEW</code> layer on their schemas that can be queried by other services. </p>&#xA;&#xA;<p>The <code>VIEW</code> functions as an API contract; even if the underlying schema or service application logic changes, the <code>VIEW</code> exposes the same data, so that </p>&#xA;&#xA;<p><strong>Pros</strong>: </p>&#xA;&#xA;<ul>&#xA;<li>Presumably much more performant (single SQL query can get all relevant data)</li>&#xA;<li>Foreign key management much easier</li>&#xA;<li>Less infrastructure to maintain</li>&#xA;<li>Easier to run reports that span multiple services</li>&#xA;</ul>&#xA;&#xA;<p><strong>Cons:</strong> </p>&#xA;&#xA;<ul>&#xA;<li>tighter coupling between services</li>&#xA;<li>breaks the idea of fundamentally atomic services that don't know about each other</li>&#xA;<li>adds a monolithic component (database) that may be hard to scale (in contrast to atomic services which can scale databases independently as required)</li>&#xA;<li>Locks all services into using the same system of record (Postgres might not be the best database for all services)</li>&#xA;</ul>&#xA;&#xA;<hr>&#xA;&#xA;<p>I'm leaning towards the last option, but would appreciate any thoughts on other approaches.</p>&#xA;"
40539447,Run two processes in a single docker container or two containers connecting to the same DB?,2016-11-11 00:37:10,<python><docker><containers><apache-kafka><microservices>,1,224,1,1.0,3,"<p>I need to develop an application that listens to a kafka topic and saves the data to a DB (cassandra). It will be a high density stream of data so saving the data will be resource expensive. Once the data is saved it will be queried and exposed through a REST API.</p>&#xA;&#xA;<p>I see two options, but both of them have downsides:</p>&#xA;&#xA;<p><strong>Option 1</strong><br>&#xA;Create two services, each one in a separate docker container. One would run only the kafka listener process in python and the other one a flask web server.<br>&#xA;<em>Advantages</em>: Every container runs only one process<br>&#xA;<em>Downsides</em>: Both services connect to the same DB, which is not ideal according to the microservices pattern architecture, for the services are not completely decoupled.</p>&#xA;&#xA;<p><strong>Option 2</strong><br>&#xA;Run both, kafka listener and web service in one container.<br>&#xA;<em>Advantages</em>: Just one service to connect to the DB.<br>&#xA;<em>Downsides</em>: More than one process running in a single docker container, and one of them (saving and updating) would be a lot more resource expensive than the other, so it would not scale uniformly.   </p>&#xA;&#xA;<p>Is there another way to go that doesn't involve moving to a monolithic architecture? Or which one of them is the best practice?</p>&#xA;"
29689630,Moving over to microservices for .NET apps - some questions,2015-04-17 03:18:48,<.net><rest><architecture><restsharp><microservices>,2,1406,0,2.0,3,"<p>I'd like to start getting into splitting my apps into microservices. My first task is to remove functionality that is repeated in each of our apps. Things like email sending, exporting, searching indexes etc - stuff where the same or similar code is repeated in every app.</p>&#xA;&#xA;<p>I just feel a little overwhelmed and struggling to get a start. I understand that the purpose of microservices is that you can pick the right language for the job, but for our current purposes i'm going with the assumption that .NET would be the primary framework i'll be building everything in.</p>&#xA;&#xA;<p>Basically, to start with, I want to create a microservice that simply sends emails that all our apps can talk to and tell to send the emails they need. The way I was thinking was the email sender has the logic to send the email, but each app needs to tell it the recipients, body etc.</p>&#xA;&#xA;<p>I'm struggling with things like:</p>&#xA;&#xA;<ul>&#xA;<li><p>What protocol should the apps use to talk to this service? REST over HTTP? If this is the case, would the email sending microservice effectively just be a Web API 2 app (this is what I'd personally go with if i were to build a REST api).</p></li>&#xA;<li><p>If I'm going REST, whats the best way to make restful calls from the backend? Most emails in our system are sent via the backend code right now. I've seen the RestSharp name thrown around, is this generally considered the best way?</p></li>&#xA;<li><p>Future planning, I think having some sort of gateway which knows about all the services would be beneficial so that each app only needs to know about this gateway and then the gateway talks to whatever services it needs. Would this just be yet another REST API in between the apps and the micro services?</p></li>&#xA;</ul>&#xA;&#xA;<p>Sorry for all the questions, just getting a start in all this sort of stuff (and architecture in general) in order to step up in my workplace and it's a bit to get my head around currently.</p>&#xA;"
41853686,Using RabbitMQ in for communication between different Docker container,2017-01-25 14:06:41,<docker><rabbitmq><message-queue><microservices>,2,332,0,0.0,3,"<p>I want to communicate between 2 apps stored in different docker containers, both part of the same docker network. I'll be using a message queue for this ( RabbitMQ )</p>&#xA;&#xA;<p>Should I make a 3rd Docker container that will run as my RabbitMQ server, and then just make a channel on it for those 2 specific containers ? So that later on I can make more channels if I need for example a 3rd app that needs to communicate with the other 2?</p>&#xA;&#xA;<p>Regards!</p>&#xA;"
41757509,How to setup Docker for a polyglot microservice-based application?,2017-01-20 06:38:13,<docker><docker-compose><dockerfile><microservices><docker-machine>,1,183,0,0.0,3,"<p>Working on a larger-than-usual project of mine, I am building an web application that will talk to several APIs of mine, each written in its own language. I use two databases, one being MariaDB and the second being Dgraph (graph database.)</p>&#xA;&#xA;<p>Here is my local director architecture:</p>&#xA;&#xA;<ul>&#xA;<li><strong>services</strong> - all my services&#xA;&#xA;<ul>&#xA;<li><strong>api</strong> - contains all my APIs&#xA;&#xA;<ul>&#xA;<li><strong>auth</strong> - contains my user auth/signup API&#xA;&#xA;<ul>&#xA;<li><strong>v1</strong> - contains my current (only) API version</li>&#xA;</ul></li>&#xA;<li><strong>trial</strong> - contains my an API of mine called <em>trial</em></li>&#xA;<li>etc...</li>&#xA;</ul></li>&#xA;<li><strong>application</strong> - contains the app users will interact with</li>&#xA;<li><strong>daemon</strong> - contains my programs that will run as daemons</li>&#xA;<li><strong>tools</strong> - contains tools (import data, scrapers, etc)</li>&#xA;</ul></li>&#xA;<li><strong>databases</strong> - to contain my two configs (MariaDB and Dgraph)</li>&#xA;</ul>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/PewMe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PewMe.png"" alt=""Local File Structure""></a></p>&#xA;&#xA;<p>Because some components are written in PHP7-NGINX while others are in PYTHON-FLASK-NGINX, how can I do a proper Docker setup with that in mind? Each service, api, daemon and tool is independant and they all talk through their own REST-endpoints.</p>&#xA;&#xA;<p>Each has its own private github repository, and I want to be able to take each one and deploy it to its own server when needed.</p>&#xA;&#xA;<p>I am new to Docker and all the reading I do confuses me: should I create a docker-compose.yml for each service or one for the entire project? But each service is deployed separately so how does docker-compose.yml know that?</p>&#xA;&#xA;<p>Any pointers to a clean solution? Should I create a container for each service and in that container put NGINX, PHP or PYTHON, etc?</p>&#xA;"
41893494,Docker Swarm Mode routing mesh vs linkerd,2017-01-27 11:59:09,<docker><microservices><docker-swarm-mode><linkerd>,1,713,0,1.0,3,"<p>Is Docker Swarm Mode routing mesh a built-in substitute for linkerd routing mesh? In other words, is there still any reason to look into linkerd if there is an out-of-the-box solution?</p>&#xA;"
41881610,Spring-Cloud Zuul breaks UTF-8 symbols in forwarded multipart request filename,2017-01-26 19:40:58,<spring-boot><utf-8><microservices><netflix-zuul><netflix-eureka>,1,770,1,1.0,3,"<p>this is first time for me on SO, so please be patient for my first question.</p>&#xA;&#xA;<p>I think i have some kind of configuration problem, but after a day of experiments i'm stuck. Our application is based on Spring-Cloud [Brixton release]. We have configuration like this: Portal (web application serving angular-based web-ui), which has zuul proxy with single route configured to our gateway service, like so:</p>&#xA;&#xA;<pre><code>zuul:&#xA;   ignoredServices: '*'&#xA;   prefix: /api&#xA;   routes:&#xA;       api-proxy:&#xA;          path: /**&#xA;          serviceId: api-gateway&#xA;</code></pre>&#xA;&#xA;<p>which has another Zuul configured and relays requests to inner bussiness logic services:</p>&#xA;&#xA;<pre><code>zuul:&#xA;  ignoredServices: '*'&#xA;  routes:&#xA;     service1:&#xA;       path: /service1/**&#xA;       serviceId: service1&#xA;     service2:&#xA;       path: /service2/**&#xA;       serviceId: service2&#xA;</code></pre>&#xA;&#xA;<p>All this configuration is working with no problem.&#xA;The problem now that i am facing is with file upload multipart requests. To be more precise - those multipart requests, when file to be uploaded has non latin symbols (e.g. ąčęėįš) from <code>UTF-8</code>. When request reaches service which has to deal with <code>@RequestPart MultipartFile file</code>, then <code>file.getOriginalFilename()</code> returns questionmarks in the places of aforementioned symbols. Now, i have tried to directly upload such file to such controller, and filename comes without questionmarks, that is, not broken, which suggests, that some bad interpretation/parsing of multipart request occurs somewhere in Zuul filters, when proxy relays incomming request.</p>&#xA;&#xA;<p>Maybe someone had similar experience with Zuul and can direct me some way to resolve this problem?</p>&#xA;"
42582463,Monitoring a microservice architecture,2017-03-03 15:14:05,<amazon-web-services><aws-lambda><microservices><prometheus>,2,253,0,1.0,3,"<p>I'm designing an architecture that similar to what's described <a href=""https://aws.amazon.com/blogs/compute/better-together-amazon-ecs-and-aws-lambda/"" rel=""nofollow noreferrer"">here</a>.  The diagram is: &#xA;<a href=""https://i.stack.imgur.com/y72pp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/y72pp.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>My question is how do you monitor such an architecture where independent pieces compose into a logical unit?  It's almost as if we need a monitoring system that checks S3 for .zip files and then polls S3 for the corresponding png files.  If <em>after</em> X hours no png files are found then alert.  </p>&#xA;&#xA;<p>Is there a tool that does timeseries analysis?  Does Prometheus do this?</p>&#xA;"
42527724,Accessing microservices deployed on apache mesos agents,2017-03-01 09:18:27,<dns><load-balancing><microservices><mesos><marathon>,2,100,1,0.0,3,"<p>How client can access a deployed microservice <strong>without</strong> specifing the host agent ip-address and the related mapping port.</p>&#xA;&#xA;<p>If we add Mesos-DNS as the client resolver, we can only obtain agent ip-addresses but it doesn't return the list of  microservices instances and their related ports.</p>&#xA;&#xA;<p>Supposed we have three instannces of webapp1 as follow:</p>&#xA;&#xA;<pre><code>+---------+---------+&#xA;| agent1  | agent2  |&#xA;+---------+---------+&#xA;|         |         |&#xA;| ins1:11 | ins3:13 |&#xA;|         |         |&#xA;| ins2:12 |         |&#xA;|         |         |&#xA;+---------+---------+&#xA;</code></pre>&#xA;&#xA;<p>client should be enabled to access one of instances directly (without referring agent1 and agent2 ip-addresses or those 11, 12 and 13 port numbers). For example:</p>&#xA;&#xA;<pre><code>$ lynx webapp1.marathon.mesos&#xA;</code></pre>&#xA;"
39601492,how monolith spring 3 application will communicate with microservice?,2016-09-20 18:41:04,<spring><spring-boot><microservices><netflix-ribbon>,1,238,2,0.0,3,<p>I have one monolith spring web application developed using spring 3.1 and spring-security 3.1 with Java 7 and it is deployed on tomcat 7. </p>&#xA;&#xA;<p>Now I have a new requirement where I have to create a micro-service for a new module using spring boot with java 8. This micro-service will be deployed separately on different EC2 instance. </p>&#xA;&#xA;<p>I am looking for suggestion/idea to access new microservice from my existing spring web application. </p>&#xA;&#xA;<p>How to perform <em>inter process communication</em> within these two spring application?</p>&#xA;&#xA;<p>Can someone provide me any help/pointer?</p>&#xA;
47757342,Programmatically add a service to docker compose project,2017-12-11 16:34:58,<docker><docker-compose><microservices>,1,231,0,0.0,3,"<p>I have a project with components base on Docker and orchestrated with <code>docker-compose</code>. Some of them are optional, and can be added at runtime.</p>&#xA;&#xA;<p>I can think about two ways to achieve that:</p>&#xA;&#xA;<ul>&#xA;<li>Create a new <code>serviceA.yml</code> compose file and run it as a separate project</li>&#xA;<li>Add <code>serviceA</code> to my base <code>compose.yml</code> and run it again</li>&#xA;</ul>&#xA;&#xA;<p>What is the preferred option to do that?</p>&#xA;&#xA;<p>I've also seen that you can combine <code>docker-compose</code> files with the <code>extend</code> keyword, but I don't think this can fit, since I have a variable number of services that I can add at runtime.</p>&#xA;"
51783877,How Ribbon get the list of Available instances of a service,2018-08-10 09:56:30,<spring><microservices><ribbon><eureka>,1,27,0,0.0,3,<p>I am using ribbon as load balancer on API gateway and eureka server. When client request comes to my API gateway does it query service registry every time to get the avaliable instance of a service or ribbon stores the available instances into it's cache.</p>&#xA;
51821786,@EnableZuulProxy doesnot work due to `HttpServletRequest` class not found,2018-08-13 11:55:10,<java><spring-boot><microservices><netflix-zuul>,1,130,6,0.0,3,"<p>I am writing a <code>Zuul</code> enabled API gateway for my microservices,&#xA;However while starting the the microservice containing <code>zuul</code>, I am getting the below mentioned error</p>&#xA;&#xA;<blockquote>&#xA;  <p>Error: <strong>Caused by: java.lang.ClassNotFoundException:</strong>&#xA;  <strong>javax.servlet.http.HttpServletRequest</strong></p>&#xA;</blockquote>&#xA;&#xA;<p>After numerous search, I have found below two solutions which does not help me. Hence I am here</p>&#xA;&#xA;<ol>&#xA;<li>Enable the <code>Apache tomcat facet</code>. This for some reason disabled in <code>Dynamic web module 3.0</code>.</li>&#xA;<li>Creating custom <code>dispatcher servlet</code>. But this solution should be feasible when we use servlet 2.5.</li>&#xA;</ol>&#xA;&#xA;<p>Since I am using a spring-boot app imported from <code>https://spring.io</code>, so it cements that I am using <code>servlet 3.0</code>.</p>&#xA;&#xA;<p>My API gateway <code>pom.xml</code>:</p>&#xA;&#xA;<pre><code>&lt;properties&gt;&#xA;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&#xA;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&#xA;        &lt;java.version&gt;1.8&lt;/java.version&gt;&#xA;        &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&#xA;    &lt;/properties&gt;&#xA;&#xA;    &lt;dependencies&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&#xA;        &lt;/dependency&gt;&#xA;&#xA;        &lt;dependency&gt;&#xA;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&#xA;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&#xA;            &lt;scope&gt;test&lt;/scope&gt;&#xA;        &lt;/dependency&gt;&#xA;    &lt;/dependencies&gt;&#xA;</code></pre>&#xA;&#xA;<p>I have annotated my API gateway class with <code>@EnableZuulProxy</code>.</p>&#xA;&#xA;<p>Having said these could you please help me with my error highlighted above.</p>&#xA;&#xA;<blockquote>&#xA;  <p>Edit:  When I change the &#xA;  1. <code>spring-starter-parent</code> to <strong>1.5.3RELEASE</strong> instead of the latest.&#xA;  2. <code>spring-cloud.version</code> to <strong>Edgware.SR2</strong> from <strong>Finchley.SR1</strong>. I face no issue at all.</p>&#xA;</blockquote>&#xA;&#xA;<p>I guess it is latest spring thing ? Any thoughts!</p>&#xA;"
51542197,Async Flows Design in Lagom or Microservices,2018-07-26 15:12:22,<domain-driven-design><microservices><lagom>,1,67,7,5.0,3,"<p>How to design asyn flows in Lagom ? </p>&#xA;&#xA;<p>Problem faced: In our product we have a Lead Aggregate which has a User Id (represents the owner of the lead), Now User has a limitation which says one user can have max of 10 Lead associated with this. We designed this by creating a separate Service ResourceManagement and when a User asks for Picking a Lead, we send a Command to LeadAggregate which generates a Event LeadPickRequested. On ProcessManager Listen to the event and asks for the Resource From ResourceManagement, on Success send Command to LeadAggregate - MarkAsPicked and on this send Push notification to the User that Lead is Picked but from building the UI perspective its very difficult and same cannot be done for exposing our API to third party. </p>&#xA;&#xA;<p>One Sol. we have done is when request is received on Service save a RequestID Vs Request Future . in Command Add the request Id and when the LeadAggregate finally change into Picked State or Picked Failure a PM listen to the event , checks if a RequestFuture is there for the request Id , then complete the future with correct response. This way it works as Sync API for the end User. </p>&#xA;&#xA;<p>Any Better Sol. for this</p>&#xA;"
40702179,micro service web app with AWS,2016-11-20 08:43:36,<amazon-web-services><amazon-s3><amazon-ec2><microservices>,1,601,0,2.0,3,"<p>I am developing a web application for image upload and retrieval with AWS cloud services using a micro service architecture.&#xA;I am new to AWS and micro service architecture, please help me map the components of the architecture to AWS components.</p>&#xA;&#xA;<p>Do i consider each micro service to run on one EC2 instance with auto scaling and load balancing?&#xA;Or do I run each micro service on one EC2 cluster?</p>&#xA;&#xA;<p>If i put my static html files in an S3, how can i call database methods to load the html pages with content? &#xA;Is it by calling am API gateway from the client?</p>&#xA;&#xA;<p>I have searched the web, but was unable to find a tutorial which implements multiple services as micro services using AWS EC2 / ECS.</p>&#xA;&#xA;<p>Please help me figure out how to map my requirements and if there are any tutorials on implementing a similar app, will be very helpful.</p>&#xA;&#xA;<p>Thank you in advance! :)</p>&#xA;"
45648115,Dockering a nodejs application with external dependencies,2017-08-12 08:20:12,<node.js><docker><containers><microservices>,2,178,0,1.0,3,"<p>We are building Node.js microservices. For some reusable components we have created a utils folder. This folder is outside the actual microservices package. When we run the microservices, we can refer to that code using <code>require(../../utils/logger)</code> and it works like a charm.&#xA;However when trying to create the docker image for my microservices </p>&#xA;&#xA;<pre><code>project the container gives me an error saying:&#xA;Error: Cannot find module '../../Utils/logger&#xA;</code></pre>&#xA;&#xA;<p>which makes a lot of sense as we are building the docker image inside the microservice project.&#xA;There are few architectural decisions which needs to be taken here:</p>&#xA;&#xA;<ol>&#xA;<li><p>We move the utils code into each microservice as required.</p>&#xA;&#xA;<ul>&#xA;<li>Pro: Microservice remains self sustained completely and no code level dependency on any other package.</li>&#xA;<li>Cons: Maintenance of cross cutting concerns and the changes would be cumbersome.</li>&#xA;</ul></li>&#xA;</ol>&#xA;&#xA;<p>2.Create a private npm module and inject dependency into the microservice package.json file. Not sure if that would work.</p>&#xA;&#xA;<p>Any suggestions on this are highly appreciated.</p>&#xA;&#xA;<p>Best,&#xA;- Vaibhav</p>&#xA;"
28339882,"service discovery, load balancing and connection pooling approach",2015-02-05 09:03:45,<load-balancing><connection-pooling><soa><microservices>,1,642,0,1.0,4,<p>There are two approaches that can be used for service interaction when having SOA for large systems deployed on cloud like AWS.</p>&#xA;&#xA;<ol>&#xA;<li><p>Have each service cluster behind internal elb. client makes a connection pool with corresponding elb and elb does round-robin balancing.</p></li>&#xA;<li><p>going with service discovery approach like netflix eureka.</p></li>&#xA;</ol>&#xA;&#xA;<p>Currently we are using 1st approach where each service cluster is behind internal elb and clients communicate via elbs so each client instance has to maintain only 1 pool i.e. with the elb endpoint.</p>&#xA;&#xA;<p>I have following doubts regarding 2nd apporach.</p>&#xA;&#xA;<ol>&#xA;<li>Is there a benefit in moving to service discovery and smart client architecture where service client knows all service instances (via eureka service or equivalent) and does internal load balancing?</li>&#xA;<li>In above case how does connection pooling work? Currently each client instance has to maintain exactly 1 connection pool i.e. with the corresponding service's elb. But with rich client each client will have all the service instance endpoints to directly communicate to. Making connection on each request will not be efficient and having so many connection pools (1 for each service instance) for each client is a overkill I guess.</li>&#xA;</ol>&#xA;&#xA;<p>Need inputs/suggestions on above two questions.</p>&#xA;
30995669,Microservices service registry registration and discovery,2015-06-23 06:46:40,<web-services><rest><service><amqp><microservices>,1,1494,0,3.0,4,"<p><strong>Little domain presentation</strong></p>&#xA;&#xA;<p>I m actually having two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User - managing CRUD on users</li>&#xA;<li>Billings - managing CRUD on billings, with a ""reference"" on a user concerned by the billing</li>&#xA;</ul>&#xA;&#xA;<p><strong>Explanation</strong></p>&#xA;&#xA;<p>I need, when a billing is called in a HTTP request, to send the fully billing object with the user loaded. In that case, and in this specifical case, I really need this.</p>&#xA;&#xA;<p>In a first time, I looked around, and it seems that it was a good idea to use message queuing, for asynchronicity, and so the billing service can send on a queue :</p>&#xA;&#xA;<blockquote>&#xA;  <p>""who's the user with the id 123456 ? I need to load it""</p>&#xA;</blockquote>&#xA;&#xA;<p>So my two services could exchange, without really knowing each other, or without knowing the ""location"" of each other.</p>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ul>&#xA;<li><p>My first question is, what is the aim of using a service registry in that case ? The message queuing is able to give us the information without knowing anything at all concerning the user service location no ?</p></li>&#xA;<li><p>When do we need to use a service registration :&#xA;In the case of Aggregator Pattern, with RESTFul API, we can navigate through hateoas links. In the case of Proxy pattern maybe ? When the microservices are interfaced by another service ?</p></li>&#xA;<li><p>Admitting now, that we use proxy pattern, with a ""frontal service"". In this case, it's okay for me to use a service registration. But it means that the front send service know the name of the userService and the billing service in the service registration ? Example :</p></li>&#xA;</ul>&#xA;&#xA;<blockquote>&#xA;  <p>Service User registers as ""UserServiceOfHell:<a href=""http://80.80.80.80/v1/"" rel=""nofollow"">http://80.80.80.80/v1/</a>""&#xA;  on ZooKeeper</p>&#xA;  &#xA;  <p>Service Billing registers as ""BillingService:<a href=""http://90.90.90.90/v4.3/"" rel=""nofollow"">http://90.90.90.90/v4.3/</a>""</p>&#xA;</blockquote>&#xA;&#xA;<p>The front end service  needs to send some requests to the user and billing service, it implies that it needs to know that the user service is ""UserServiceOfHell"". Is this defined at the beginning of the project ?</p>&#xA;&#xA;<ul>&#xA;<li>Last question, can we use multiple microservices patterns in one microservices architecture or is this a bad practice ?</li>&#xA;</ul>&#xA;&#xA;<p><em>NB : Everything I ask is based on <a href=""http://blog.arungupta.me/microservice-design-patterns/"" rel=""nofollow"">http://blog.arungupta.me/microservice-design-patterns/</a></em></p>&#xA;"
33926707,Passing objects between microservices,2015-11-25 21:28:36,<php><oop><soa><microservices>,1,527,0,1.0,4,"<p>I am experimenting with moving some parts of a monolith to external services. I like the idea so far and it seems a lot cleaner to encapsulate all related functionality inside one application. The different applications use RabbitMQ to communicate. </p>&#xA;&#xA;<p>I have a user object in one service. If I want to use this exact same class in the service I can easily serialize it and send the serialized object in the message body. But since both the sender and receiver need to contain the user class I would have to share a library containing some representation of the user object (although to me it seems strange to put the real user object in the library since it's core to the main application). I guess I could also just pass an array with a <code>user</code> key and defined key-values.</p>&#xA;&#xA;<p>I'm also thinking that if I someday create a service in something other than PHP then it won't be able to unserialize the user object and thus will have no access to the data in the message.</p>&#xA;&#xA;<p>So basically I like the idea of passing entities between services and being able to user them as objects in the receiving end, but I'm not sure if this is the right approach.</p>&#xA;&#xA;<p>My question is what would the best way to pass objects between these services be?</p>&#xA;"
36080524,Rails: How to listen to / pull from service or queue?,2016-03-18 09:21:32,<ruby-on-rails><rabbitmq><apache-kafka><microservices>,4,2107,3,0.0,4,"<p>Most Rails applications work in a way that they are waiting for requests comming from a client and then do their magic.&#xA;But if I want to use a Rails application as part of a microservice architecture (for example) with some asychonious communication (Serivce A sends an event into a Kafka or RabbitMQ queue and Service B - my Rails app - is supposed to listen to this queue), how can I tune/start the Rails app to immediately listen to a queue and being triggered by event from there? (Meaning the initial trigger is not comming from a client, but from the App itself.)</p>&#xA;&#xA;<p>Thanks for your advice!</p>&#xA;"
35613841,Most efficient way to communicate between multiple .NET apps,2016-02-24 21:48:15,<.net><rest><azure><architecture><microservices>,4,1116,0,2.0,4,"<p>Currently i have a setup where my clients (web apps, iOS app etc) talks to my backend API .NET web app (Nancy) via REST calls. Nothing special.</p>&#xA;&#xA;<p>I now have a requirement to split this API up into microservices, where each service can be individually upgraded/deployed. </p>&#xA;&#xA;<p>My main API (public) will just perform authentication, then call into one of my microservices, which will be in my private network.</p>&#xA;&#xA;<p><strong>What's the different ways i could communicate between my main API and other microservice API's? Pros/cons of each approach?</strong></p>&#xA;&#xA;<p>The communication needs to be realtime - e.g request comes in from a browser/device, main API performs auth, then calls into microservice API then returns response. So i can't use things like queues or pub/sub. It doesn't necessarily need to use HTTP, but it needs to be realtime communication (request/response). I also have other services (WebJobs, cloud services, etc) that need to talk to these microservices (they are also in the private network).</p>&#xA;&#xA;<p>The only approach that comes to mind is simple REST-based calls. Totally fine, but latency is the main issue here.</p>&#xA;&#xA;<p>Can anyone recommend any other solutions to this problem? Is there anything in Azure suited to this?</p>&#xA;&#xA;<p>Many thanks</p>&#xA;"
39763013,many log files on azure service fabric,2016-09-29 06:33:42,<azure><microservices><azure-service-fabric>,2,628,0,0.0,4,"<p>I have a azure service fabric development cluster running locally with two applications.</p>&#xA;&#xA;<p>After a two week holiday I come back and see that my hard drive is completely full, consequently nothing really works anymore.</p>&#xA;&#xA;<p>the sfdevcluster\log\traces folder has many *.etl files all larger than 100MB.&#xA;And all kinds of other log files > 250 MB are present</p>&#xA;&#xA;<p>So my questions: how to disable tracing/logging on azure service fabric and are there tools to administer log files?</p>&#xA;"
39852947,"Spring microservices, stateless session, angular and static file serving",2016-10-04 12:56:13,<angularjs><spring-security><spring-boot><spring-cloud><microservices>,1,577,1,0.0,4,"<p>I am designing the backend of large application which is divided into microservices. I am using <strong>Spring Cloud</strong> with its tools: <strong>Eureka</strong>, <strong>Zuul</strong> and etc. I have implemented <strong>OAuth2</strong> authorization server which supports four grant types. It is working without problems.</p>&#xA;&#xA;<p>Then I was asked to serve <strong>html files</strong> and <strong>in such manner that if not authorized, backend must redirect to login page and strongly recommended that I don't use sessions</strong>. I thought that without session spring cant really know what's going with, in the end <strong>it must have token to decide to build security context</strong>.</p>&#xA;&#xA;<p>I started researching about this issue. I found that examples from <a href=""https://spring.io/guides/tutorials/spring-security-and-angular-js/"" rel=""nofollow"">Spring Security and Angular JS tutorial</a> show that routings and redirections are accomplished inside <strong>angular</strong> with the help of <strong>ui-route</strong>. I skimmed several projects in github and they also were using angular for redirections.</p>&#xA;&#xA;<p>Is it possible to redirect using backend in totally stateless session?(This sounds so dumb, but it couldn't be expressed otherwise. I want to give this answer to my coworkers that are stating that is possible). If possible, are there any examples?</p>&#xA;"
35361819,how to scale microservice (service fabric) instance when queue length increass,2016-02-12 11:45:43,<azure><scale><microservices><azure-service-fabric>,2,1690,0,0.0,4,"<p><a href=""https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/"" rel=""nofollow"">https://azure.microsoft.com/en-us/documentation/articles/cloud-services-how-to-scale/</a></p>&#xA;&#xA;<p>But how can I scale up my microservice when queue length increases. have any inbuild way in azure service fabric ?</p>&#xA;"
41636566,Inter-communication microservices - How?,2017-01-13 14:14:59,<node.js><web-services><rest><rabbitmq><microservices>,2,2165,1,1.0,4,"<p>I'm working on a personnal project which is to transform a monolithic web application into microservices (each service has its own database).</p>&#xA;&#xA;<p>At this moment the monolithic backend is made with  NodeJS and is able to reply REST request. &#xA;When I began to split the application into multiple services I faced the next problem : How to make the communication between them nicely ?</p>&#xA;&#xA;<p>First I tried to use <strong>REST call</strong> with the next example : &#xA;""Register Service"" inserts interesting things into its database, then forward (HTTP POST) the user information to the ""User Service"" in order to persist it into the ""user"" database.&#xA;From this example we have 2 services thus 2 databases.</p>&#xA;&#xA;<p>I realized at this moment <strong>it wasn't a good choice</strong>. Because my ""Register Service"" depends on ""User service"". They are kind of coupled and this is an anti-pattern of the microservices conception ( from what I read about ).</p>&#xA;&#xA;<p>The second idea was to use a <strong>message broker</strong> like RabbitMQ. ""Register Service"" still insert interesting things into its own database and publish a message in a queue with the user information as data. ""User Service"" consumes this message and persists data into its ""user"" database. By using this conception, both of the services are fully isolated and could be a great idea.</p>&#xA;&#xA;<p>BUT, <strong>how about the response to send to the client</strong> ( who made the request  to ""Register Service""). With the first idea we could send ""200, everything's ok !"" or 400. It is not a problem. With the second idea, we don't know if the consumer (""User Service"")  persisted the user data, so what do I need to reply to the client ?</p>&#xA;&#xA;<p>I have the same problem with the shop side of the web application. The client post the product he wants to buy to ""Order Service"". This one needs to check the virtual money he has into ""User Service"" then forward the product detail to ""Deliver Service"" if the user has enough money. How to do that with fully isolated services ? </p>&#xA;&#xA;<p>I don't want to use the http request time from the client to make async request/reply on the message broker. </p>&#xA;&#xA;<p>I hope some of you will enlighten me.</p>&#xA;"
43034203,node.js api gateway implementation and passport authentication,2017-03-26 20:33:25,<node.js><passport.js><microservices>,1,837,1,0.0,4,"<p>I am working on implementing a microservices-based application using node.js.  While searching for examples on how to implement the api gateway, I came across the following article that seems to provide an example on implementing the api gateway: <a href=""https://memz.co/api-gateway-microservices-docker-node-js/"" rel=""nofollow noreferrer"">https://memz.co/api-gateway-microservices-docker-node-js/</a>.  Though, finding example for implementing the api gateway pattern in node.js seems to be a little hard to come by so far, this article seemed to be a really good example.  </p>&#xA;&#xA;<p>There are a few items that are still unclear and I am still have issues finding doc. on.  </p>&#xA;&#xA;<p>1) Security is a major item for the app. I am developing, I am having trouble seeing where the authentication should take place (i.e. using passport, should I add the authentication items in the api gateway and pass the jwt token along with the request to the corresponding microservice as the user's logged in information is needed for certain activities?  The only issue here seems to be that all of the microservices would need passport in order to decrypt the jwt token to get the user's profile information.  Would the microservice be technically, inaccessible to the outside world except through the api gateway as this seems to be the aim?</p>&#xA;&#xA;<p>2) How does this scenario change if I need to scale to multiple servers with docker images on each one?  How would this affect load balancing, as it seems like something would have to sit at a higher level to deal with load balancing?</p>&#xA;"
42651456,Spring cloud Zuul retry when instance is down and forward to other available instance,2017-03-07 14:56:39,<spring-cloud><microservices><netflix-zuul><spring-cloud-netflix><spring-cloud-feign>,2,2435,0,1.0,4,"<p>using 'Camden.SR5' for spring-cloud-dependencies, with spring boot '1.5.2.RELEASE'.</p>&#xA;&#xA;<p>In my current setup, I have </p>&#xA;&#xA;<ul>&#xA;<li>eureka server </li>&#xA;<li>config server  (running on random ports)</li>&#xA;<li>zuul gateway server  </li>&#xA;<li>and 2 instances of a service (running on random ports)</li>&#xA;</ul>&#xA;&#xA;<p>All these instances are successfully register with Eureka.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/BYNWR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BYNWR.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>When all the services are running, The load balancing is done properly through zuul without any issues.</p>&#xA;&#xA;<p>when an instance is killed, Zuul is still trying to fulfil the request using the same service which is down. However if waited till the eureka registry is fetched after shutting down the instance, requests are fulfilled with the other instances which are 'UP'.</p>&#xA;&#xA;<pre><code>    2017-03-07 19:57:41.409 DEBUG 26658 --- [nio-5555-exec-3] c.n.l.reactive.LoadBalancerCommand       : Got error org.apache.http.conn.HttpHostConnectException: Connect to 10.99.4.151:64381 [/10.99.4.151] failed: Connection refused when executed on server 10.99.4.151:64381&#xA;2017-03-07 19:57:41.420 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : Error executing HystrixCommand.run(). Proceeding to fallback logic ...&#xA;&#xA;com.netflix.client.ClientException: null&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:123) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:81) ~[ribbon-loadbalancer-2.2.0.jar:2.2.0]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:96) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>    at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.3.jar:4.5.3]&#xA;    ... 162 common frames omitted&#xA;&#xA;2017-03-07 19:57:41.425 DEBUG 26658 --- [nio-5555-exec-3] com.netflix.hystrix.AbstractCommand      : No fallback for HystrixCommand. &#xA;&#xA;java.lang.UnsupportedOperationException: No fallback available.&#xA;    at com.netflix.hystrix.HystrixCommand.getFallback(HystrixCommand.java:292) [hystrix-core-1.5.6.jar:1.5.6]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:117) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.getFallback(AbstractRibbonCommand.java:42) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]&#xA;    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.11.jar:8.5.11]&#xA;    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_66]&#xA;&#xA;2017-03-07 19:57:41.428  WARN 26658 --- [nio-5555-exec-3] o.s.c.n.z.filters.post.SendErrorFilter   : Error during filtering&#xA;&#xA;com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:170) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:145) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:88) ~[spring-cloud-netflix-core-1.2.5.RELEASE.jar:1.2.5.RELEASE]&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Following are the zuul configuration used with @EnableZuulProxy and @EnableEurekaClient</p>&#xA;&#xA;<pre><code>    server:&#xA;  port: 5555&#xA;&#xA;spring:&#xA;  application:&#xA;    name: gateway-server&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        service-id: CONFIGSERVER&#xA;      fail-fast: true&#xA;      retry:&#xA;        multiplier:  1.1&#xA;        initial-interval: 1000&#xA;        max-attempts: 6&#xA;        max-interval: 2000&#xA;&#xA;hystrix:&#xA;  command:&#xA;    default:&#xA;      execution:&#xA;        isolation:&#xA;          thread:&#xA;            timeoutInMilliseconds: 100000&#xA;        timeout:&#xA;          enabled: false&#xA;&#xA;ribbon:&#xA;  ReadTimeout: 5000&#xA;  ConnectTimeout: 3000&#xA;  maxAutoRetries: 1&#xA;  MaxAutoRetriesNextServer: 2&#xA;  OkToRetryOnAllOperations: true&#xA;&#xA;&#xA;logging:&#xA;  level:&#xA;    ROOT: DEBUG&#xA;&#xA;zuul:&#xA;  routes:&#xA;    security-service:&#xA;      retryable: true&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The 2 instances of service with are running with unique instance-ids </p>&#xA;&#xA;<pre><code>@EnableEurekaClient&#xA;@EnableHystrix&#xA;@SpringBootApplication&#xA;public class SecurityServer implements HealthIndicator{&#xA;&#xA;    public static void main(String args[])&#xA;    {&#xA;        SpringApplication.run(SecurityServer.class,args);&#xA;    }&#xA;&#xA;    @Override&#xA;    public Health health() {&#xA;        return Health.up().withDetail(""STATUS"", ""SUCCESS"").build();&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>instanceId: ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${random.uuid}}&#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>Can you help me with the zuul &amp; instances configuration, so that request is automatically forwarded to the other available instances when an instance goes down. </p>&#xA;"
49612911,Understanding microservices using Express.js and docker,2018-04-02 14:13:05,<node.js><express><microservices>,2,332,0,1.0,4,"<p>I am new to node.js and docker as well as the microservices architecture.&#xA;I am trying to understand what microservices architecture actually is and theoretically I do understand what microservices arch is.Please see the following implementation&#xA;This is the <strong>index.js</strong> file:</p>&#xA;&#xA;<pre><code>var express = require(""express""); &#xA;var app = express();&#xA;var service1 = require(""./service1"");&#xA;var service2 = require(""./service2"");&#xA;app.use(""/serviceonerequest"",service1);&#xA;app.use(""/servicetwo"",service2);&#xA;app.listen(3000,function(){&#xA;    console.log(""listening on port 3000"");&#xA;});&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service1</strong>:</p>&#xA;&#xA;<pre><code>    var express = require(""express"");&#xA;    var router = express.Router();&#xA;    router.use(express.json());&#xA;    router.get(""/"",(req,res)=&gt;{&#xA;        //perform some service here&#xA;        res.send(""in the get method of service 1"");&#xA;        res.end();&#xA;        });&#xA;&#xA;        router.post(""/letsPost"",(req,res)=&gt;{&#xA;            res.send(req.body);&#xA;            res.end(""in post method here"");&#xA;        })&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<p>The file <strong>service2:</strong></p>&#xA;&#xA;<pre><code>var express = require(""express"");&#xA;var router = express.Router();&#xA;&#xA;router.use(express.json());&#xA;router.get(""/"",(req,res)=&gt;{&#xA;    //perform some service here&#xA;    res.end(""in the GET method for service 2"");&#xA;});&#xA;&#xA;router.post(""/postservice2"",(req,res)=&gt;{&#xA;    res.send(req.body);&#xA;});&#xA;&#xA;module.exports = router;&#xA;</code></pre>&#xA;&#xA;<ol>&#xA;<li>Does the above qualifies as 'micro service architecture'?Since there are two services and they can be accessed through the 'api-gateway' index.js?</li>&#xA;<li>I have read the basic tutorial of Docker.Is it possible to have the above three ""modules"" in separate containers?</li>&#xA;<li>If the above does not qualify as a microservice what should be done to convert the above sample into microservices?</li>&#xA;</ol>&#xA;"
38820356,Does Kong support API Aggregation,2016-08-08 02:04:58,<microservices><kong>,1,1695,1,2.0,4,"<p>We are just researching a couple of API gateways, in particular <a href=""https://getkong.org"" rel=""noreferrer"">Kong</a>.&#xA;Looking through their documentation it seems they support request/response transformation. </p>&#xA;&#xA;<p>However, if I understand this correctly, this seems limited to headers.</p>&#xA;&#xA;<p>Does Kong support API Aggregation like <a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""noreferrer"">Netflix</a> does it?</p>&#xA;"
38687434,Best Practices for Microservices discovery without Hard Coding?,2016-07-31 19:01:30,<architecture><microservices>,2,397,0,0.0,4,"<p>This is a question that's been annoying me for a while, how does one write a series of microservices that run on on various machines at different locations without the need to hard code each services individual location?</p>&#xA;&#xA;<p>Like say for instance I had service A which does some form of validation of a json message. Service A runs on box 1,3,5 and more instances can be brought up as demand grows.</p>&#xA;&#xA;<p>Now say I have service B which looks to call upon service A, how would I communicate to service B where my service A resides? </p>&#xA;&#xA;<p>Possible Solutions I've considered:</p>&#xA;&#xA;<ul>&#xA;<li><p>Hard coding service B with the location of a 'master' node for Service A which then delegates tasks out to all instances of service A.</p></li>&#xA;<li><p>Utilization of message queues? - Service B writes to a series of message queues, Service A instances read from set message queues and sends back results to service B. </p></li>&#xA;<li><p>SSDP - utilizing some form of simple service discovery protocol to broadcast which services are running where on a set network and keeping track of these services. </p></li>&#xA;</ul>&#xA;&#xA;<p>I'm quite new to this architectural style so I'm hoping I've not missed something very simple?</p>&#xA;"
45002471,Are docker containers safe enough to run third-party untrusted containers side-by-side with production system?,2017-07-10 01:02:04,<docker><microservices>,2,147,0,1.0,4,"<p>We plan to allow execution of third-party micro-services code on our infrastructure interacting with our api. &#xA;Is dockerizing safe enough? Are there solutions for tracking resources(network, ram,cpu)container consumes? </p>&#xA;"
40786831,How do I version control a kubernetes application?,2016-11-24 12:48:39,<kubernetes><microservices><kubernetes-helm>,2,771,0,1.0,4,"<p>I've checked out helm.sh of course, but at first glance the entire setup seems a little complicated (helm-client &amp; tiller-server). It seems to me like I can get away by just having a helm-client in most cases.</p>&#xA;&#xA;<p><strong>This is what I currently do</strong></p>&#xA;&#xA;<p>Let's say I have a project composed of 3 services viz. <code>postgres</code>, <code>express</code>, <code>nginx</code>.</p>&#xA;&#xA;<p>I create a directory called <code>product-release</code> that is as follows:</p>&#xA;&#xA;<pre><code>product-release/&#xA;    .git/&#xA;    k8s/&#xA;        postgres/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;            Secret.mustache.yaml   # Needs to be rendered by the dev before use&#xA;        express/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;        nginx/&#xA;            Deployment.yaml&#xA;            Service.yaml&#xA;    updates/&#xA;        0.1__0.2/&#xA;            Job.yaml    # postgres schema migration&#xA;            update.sh   # k8s API server scritps to patch/replace existing k8s objects, and runs the state change job&#xA;</code></pre>&#xA;&#xA;<p>The usual git stuff can apply now. Everytime I make a change, I make changes to the spec files, test them, write the update scripts to help move from the last version to this current version and then commit it and tag it.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<ol>&#xA;<li>This works for me so far, but is this ""the right way""?</li>&#xA;<li>Why does <code>helm</code> have the tiller server? Isn't it simpler to do the templating on the client-side? Of course, if you want to separate the activity of the deployment from the knowledge of the application (like secrets) the templating would have to happen on the server, but otherwise why?</li>&#xA;</ol>&#xA;"
40936597,Spring Eureka App doesn't show dashboard,2016-12-02 16:16:44,<java><spring><microservices><netflix-eureka>,3,1019,1,0.0,4,"<p>There is a Eureka Server application:</p>&#xA;&#xA;<pre><code>@EnableEurekaServer&#xA;@SpringBootApplication&#xA;public class RegistrationModulesServiceApplication {&#xA;&#xA;    public static void main(String[] args) {&#xA;        SpringApplication.run(RegistrationModulesServiceApplication.class, args);&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>With applicaton.yml config (be default):</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    hostname: localhost&#xA;  client: &#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;&#xA;server:&#xA;  port: 1111  &#xA;</code></pre>&#xA;&#xA;<p>On the first run - I saw dashboard with statuses.&#xA;Like in documentation:&#xA;<a href=""https://i.stack.imgur.com/Sa2cD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Sa2cD.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Then - after restart I can see only xml response:&#xA;<a href=""https://i.stack.imgur.com/1lC5l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1lC5l.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Why?</p>&#xA;&#xA;<p>No error in log.</p>&#xA;"
50454109,Communication between microservices - request data,2018-05-21 17:46:22,<rest><rabbitmq><microservices><rpc>,3,363,3,1.0,4,"<p>I am dealing with communication between microservices.</p>&#xA;&#xA;<p>For example (<em>fictive example, just for the illustration</em>):</p>&#xA;&#xA;<ul>&#xA;<li><strong>Microservice A - Store Users (getUser, etc.)</strong></li>&#xA;<li><strong>Microservice B - Store Orders (createOrder, etc.)</strong></li>&#xA;</ul>&#xA;&#xA;<p>Now if I want to add new Order from the Client app, I need to know user address. So the request would be like this:</p>&#xA;&#xA;<p><strong>Client -> Microservice B (createOrder for userId 5) -> Microservice A (getUser with id 5)</strong></p>&#xA;&#xA;<p>The microservice B will create order with details (address) from the User Microservice.</p>&#xA;&#xA;<p><strong>PROBLEM TO SOLVE:</strong> How effectively deal with communication between microservice A and microservice B, as we have to wait until the response come back?</p>&#xA;&#xA;<p><strong>OPTIONS:</strong></p>&#xA;&#xA;<ul>&#xA;<li>Use RestAPI,</li>&#xA;<li>Use AMQP, like RabbitMQ and deal with this issue via RPC. (<a href=""https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html"" rel=""nofollow noreferrer"">https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html</a>)</li>&#xA;</ul>&#xA;&#xA;<p>I don't know <strong>what will be better for the performance</strong>. Is call faster via RabbitMQ, or RestAPI? <strong>What is the best solution for microservice architecture</strong>?</p>&#xA;"
43763418,How to update Update X509 certificates for On-Premise Service Fabric cluster,2017-05-03 14:49:28,<microservices><azure-service-fabric>,1,288,2,0.0,4,"<p>The documentation for updating x509 certificates in Service Fabric is unclear to me with regards to non-Azure (On-Prem) installations: <a href=""https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade-windows-server</a></p>&#xA;&#xA;<p>I have followed these steps, but they have not worked.</p>&#xA;&#xA;<ol>&#xA;<li>Updated the cluster setup json template so that the thumbprint of the original certificate is now ""ThumbprintSecondary"".</li>&#xA;<li><p>Added the new certificate thumbprint under ""Thumbprint"". e.g.</p>&#xA;&#xA;<p>""security"": {&#xA;     ""metadata"": ""The Credential type X509 indicates this is cluster is &#xA;      secured using X509 Certificates. The thumbprint format is - d5 ec 42 3b 79 cb e5 07 fd 83 59 3c 56 b9 d5 31 24 25 42 64."",&#xA;        ""ClusterCredentialType"": ""X509"",&#xA;        ""ServerCredentialType"": ""X509"",&#xA;        ""CertificateInformation"": {&#xA;            ""ClusterCertificate"": {&#xA;                ""Thumbprint"": ""New Thumbprint"",&#xA;                ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;                ""X509StoreName"": ""My""&#xA;        },&#xA;        ""ServerCertificate"": {&#xA;        ""Thumbprint"": ""New Thumbprint"",&#xA;        ""ThumbprintSecondary"": ""Old Thumbprint"",&#xA;        ""X509StoreName"": ""My""&#xA;    },</p></li>&#xA;<li><p>Install the new certificate pfx and update the ACL for ""NETWORK SERVICE""</p></li>&#xA;<li>Run Start-ServiceFabricClusterConfigurationUpgrade -ClusterConfigPath ""Path to json Configuration File""</li>&#xA;</ol>&#xA;"
43785728,Where is the best place to do data aggregation for UI in microservices architecture,2017-05-04 14:30:33,<rest><api><web><single-page-application><microservices>,1,716,3,0.0,4,"<p>I am building an application using microservice architecture. It has five Rest API and one UI(single page application) microservices. </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/DbuHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DbuHq.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>Could anyone advise me which is the best option to do the data aggregation? </p>&#xA;&#xA;<ol>&#xA;<li>Make UI application as a static web application and do all API requests from the front end (from the browser using javascript framework) and all data aggregation do in front end itself and render? </li>&#xA;<li>Make UI application as a dynamic web application and do all API request and data aggregation in web application backend?</li>&#xA;</ol>&#xA;"
47364834,Microservices sharing code,2017-11-18 10:09:25,<javascript><node.js><microservices>,1,94,7,1.0,4,"<p>There are so many answers and blogposts saying ""never share code between microservices"" and I wonder right now how I am supposed to follow that advice. I've got the following microservices and each of them is communicating via RabbitMQ:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/0Agof.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Agof.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>The express server and the two different background services have completely different code, while the request workers are just multiple instances. Each request worker is supposed to process a request and return a direct reply to it once it is done with it (RPC).</p>&#xA;&#xA;<p><strong>My question:</strong></p>&#xA;&#xA;<p>I have written a class (<code>RequestScheduler</code>) which offers methods to schedule a request (e. g. <code>getProfile: Promise&lt;IProfile&gt;</code>). Since I am apparently not allowed to share code between microservices what about the code for the communication between the microservices?</p>&#xA;&#xA;<p>I don't see a way how I could avoid sharing that code along my microservices on the left side.</p>&#xA;"
37074642,Settings in application.yml for spring.cloud.config aren't used when app is executing,2016-05-06 14:13:00,<java><spring><spring-boot><spring-cloud><microservices>,1,4981,0,0.0,4,"<p>I have a problem with spring cloud: my settings in application.yml for spring.cloud.config aren't used when app is executing. let me put more detail here.&#xA;I'd like to my services could get settings from a remote ConfigServer. I've created the ConfigServer as a spring boot app with annotation @EnableConfigServer. &#xA;After that i've created client app with next config file:</p>&#xA;&#xA;<pre><code>    application:&#xA;      name: mw&#xA;    cloud:&#xA;      config:&#xA;        enabled: true&#xA;        uri: http://172.17.42.1:8888&#xA;        fail-fast: true&#xA;</code></pre>&#xA;&#xA;<p>main class:</p>&#xA;&#xA;<pre><code>    @EnableEurekaClient&#xA;    @SpringBootApplication&#xA;    public class MwApplication&#xA;</code></pre>&#xA;&#xA;<p>and extra configuration into app:</p>&#xA;&#xA;<pre><code>    @Configuration&#xA;    @EnableJpaRepositories(basePackages = {""com.sample.repository""})&#xA;    @EnableTransactionManagement&#xA;    @EnableScheduling&#xA;    public class AppConfiguration&#xA;</code></pre>&#xA;&#xA;<p>also i have next dependencies:</p>&#xA;&#xA;<pre><code>    spring-cloud-starter-eureka&#xA;    spring-cloud-config-client&#xA;    spring-boot-configuration-processor&#xA;    spring-boot-starter-data-jpa&#xA;</code></pre>&#xA;&#xA;<p>When i execute my client app, i've got this message: ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""<a href=""http://localhost:8888/mw/default"" rel=""nofollow"">http://localhost:8888/mw/default</a>""</p>&#xA;&#xA;<p>The app try to get data from default uri(localhost) instead of to use uri from my setting. I've looked at app in debug mode and saw org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration was creating ConfigClientProperties with default property and my settings from application.yml weren't used. </p>&#xA;&#xA;<p>What am i doing wrong?&#xA;thanks.</p>&#xA;"
43350853,Authentication with Kong,2017-04-11 15:56:31,<django><authentication><microservices><restful-authentication><kong>,1,741,0,4.0,4,"<p>I'm looking at <a href=""https://getkong.org/"" rel=""nofollow noreferrer"">Kong</a> to replace my current hand-rolled NodeJS API gateway. Currently I have a user service that handles authentication (written in Django) by providing a JWT back upon login, which the client then passes in through a header. My current API gateway then intercepts any calls, does a validation call back to the user service, and replaces the JWT Header with <code>X-User-Id</code> and <code>X-User-Email</code>. </p>&#xA;&#xA;<p>As far as I can tell, Kong can do roughly the same thing. I'm trying to figure out the flow of how this should work <em>in a perfect world</em>. I still have the opportunity to replace much of the infrastructure, so rewriting some services is not completely out of the question. </p>&#xA;&#xA;<p>So, in my mind, what would happen is the following:</p>&#xA;&#xA;<ol>&#xA;<li>User registers on my site. I then create a new consumer with their username/id on Kong</li>&#xA;<li>User logs in. This is where I get stuck. Do I log in (or in this case, simply authenticate the user as being said user), ask Kong for the JWT for this consumer, and return that? What if I wanted some more data in the payload of the JWT? What happens on Kong's side when the JWT expires?</li>&#xA;<li>When the user requests a service, Kong will the sniff out the JWT from the headers, replace it with <code>X-Consumer-*</code> - is that correct? </li>&#xA;</ol>&#xA;&#xA;<p>Please do correct me if my thinking is wrong, or if there is a better way to achieve this. I'm fairly new to the whole microservices thing. </p>&#xA;"
48515460,Is it recommended to use Database as a container in Production environment?,2018-01-30 06:46:30,<database><docker><containers><microservices><production-environment>,3,1693,0,0.0,4,"<p>Assuming we are using a micro service architecture for a product and we decide to use 'Database per service' model, and deploy in cloud servers by provider like AWS. &#xA;It is convenient to have databases running as a container for development and test environments. </p>&#xA;&#xA;<p>But can same be implemented for Production environment! If so, how safe it would be?&#xA;Or is it proper to go with cloud solution as AWS RDS-DB instead!!</p>&#xA;"
46131196,com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server,2017-09-09 13:26:18,<java><spring-boot><microservices>,4,9807,0,2.0,4,"<p>I am very new to the microservices and trying to run the code from link: <a href=""https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa"" rel=""nofollow noreferrer"">https://dzone.com/articles/advanced-microservices-security-with-spring-and-oa</a> . When I simply run the code I see the following error comes. </p>&#xA;&#xA;<p>What is the issue ?</p>&#xA;&#xA;<pre><code>com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server&#xA;    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1030) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:944) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1468) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1435) [eureka-client-1.4.12.jar:1.4.12]&#xA;    at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_144]&#xA;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_144]&#xA;    at java.lang.Thread.run(Unknown Source) [na:1.8.0_144]&#xA;&#xA;2017-09-09 18:53:11.909 ERROR 16268 --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error&#xA;</code></pre>&#xA;&#xA;<p>I have not installed anything special on to the system. Please let me know what do I need to install? </p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/8oWl2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8oWl2.png"" alt=""enter image description here""></a></p>&#xA;"
41018981,Microservices and database,2016-12-07 13:38:59,<database><docker><cloud><microservices><docker-swarm>,1,656,0,1.0,4,"<p>What is the best practice to deploy database in microservices architecture, more precisely in distributed environment, such as docker swarm? Microservices principles states each service should be stateless to enable scaling. As database obviously has a state, should it live at fixed position outside of cluster, deployed and configured before the cluster is initialized?</p>&#xA;&#xA;<p>I'm confused, because all docker compose examples includes database container in the service definition. But things aren't that simple. Often the database needs a lot of configuration before it's ready to use. Also, docker sucks at coordinating the service starting order.</p>&#xA;&#xA;<p>If it's really a good practice to deploy the database alongside with services to docker swarm, how to ensure consistency and persistence of cricial data?</p>&#xA;"
45847796,What is a sidecar in the context of microservices?,2017-08-23 19:19:33,<kubernetes><microservices><istio>,2,1026,0,1.0,4,<p>I'm currently looking through an Istio and Kubernetes talk and mention the management of services along with the use of sidecars. I'm not sure what that is.</p>&#xA;
40457443,azure service fabric reliable dictionary linq query very slow,2016-11-07 03:36:20,<c#><performance><linq-to-entities><microservices><azure-service-fabric>,1,1465,7,1.0,4,"<p>I have a reliable dictionary in service fabric stateful service. I have a simple linq expression.<br>&#xA;I am using Ix-Async package for building an asyncenumerable.  </p>&#xA;&#xA;<hr>&#xA;&#xA;<pre><code>using (ITransaction tx = this.StateManager.CreateTransaction())  &#xA;        {  &#xA;&#xA;          var result = (await customers.CreateLinqAsyncEnumerable(tx))&#xA;                .Where(x =&gt; x.Value.NameFirst != null &amp;&amp; x.Value.NameFirst.EndsWith(n, StringComparison.InvariantCultureIgnoreCase))&#xA;                    .Select(y =&gt; y.Value);&#xA;&#xA;           return await result.ToList();&#xA;&#xA;&#xA;        }  &#xA;</code></pre>&#xA;&#xA;<hr>&#xA;&#xA;<p>The data is organized into 2 partitions with around 75,000 records in each partition. I am using Int64 range as the partition key. In the above code, the ""Result.ToList()"" takes around 1 minute to execute for each partition. Another weired thing is, the actual result is empty!. The same sql run in sql server returns rows with customer first names ending with ""c"". But, this is besides the point. My biggest concern is performance of ""ReliableDictionary"" linq query.<br>&#xA;Regards</p>&#xA;"
39615381,Advantages of Service Fabric Microservices vs Collection of Azure Cloud services/web apps,2016-09-21 11:31:17,<azure><microservices><azure-service-fabric><azure-cloud-services><azure-appfabric>,2,4502,0,2.0,4,"<p>I have a application that can be broken down into multiple communicating services. My current implementation is monolithic and I want to reorganize the same so that individual components can be deployed,iterated upon, scaled independently. I see two ways to do this with Azure:</p>&#xA;&#xA;<ol>&#xA;<li>Service Fabric service composed of set of communicating micro-services(stateless, web-api etc.)</li>&#xA;<li>A collection of individual Azure Web Apps/ Cloud Services that call each other at the http end points.</li>&#xA;</ol>&#xA;&#xA;<p>Are there any obvious advantages of 1 over 2? Any rule of thumb to chose one over the other would also be very helpful.</p>&#xA;"
39467200,How to self register a service with Consul,2016-09-13 09:58:28,<c#><asp.net-core><microservices><consul>,1,2286,0,6.0,4,"<p>I'm trying to <a href=""http://microservices.io/patterns/self-registration.html"" rel=""nofollow noreferrer"">self</a> register my ASP.NET Core application to Consul registry on startup and deregister it on shutdown.</p>&#xA;&#xA;<p>From <a href=""https://www.consul.io/docs/agent/http/agent.html#agent_service_register"" rel=""nofollow noreferrer"">here</a> I can gather that calling the http api [<code>put /v1/agent/service/register</code>] might be the way to go (or maybe not!).</p>&#xA;&#xA;<p>From my app, I thought I'll target the <code>Startup</code> class, starting with adding the my <code>.json</code> file</p>&#xA;&#xA;<pre><code>public Startup(IHostingEnvironment env)&#xA;{&#xA;   var builder = new Configuration().AddJsonFile(""consulconfig.json"");&#xA;   Configuration = builder.Build();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But now, I'm stuck as <code>ConfigureServices</code> method tells me thats where I add services to the container, and <code>Configure</code> method is where I configure the Http request pipeline.</p>&#xA;&#xA;<p>Anybody to point me in the right directions, online readings, examples, etc.                                        </p>&#xA;"
47311911,Event sourcing / CQRS read model - projections,2017-11-15 15:57:11,<domain-driven-design><microservices><cqrs><event-sourcing>,2,407,0,0.0,4,"<p>I have a microservice-based application running on AWS Lambda. Two of the microservices, the most crucial ones, use event-sourcing/cqrs. </p>&#xA;&#xA;<p><strong>Background: (this is also for me to organize my thoughts)</strong></p>&#xA;&#xA;<p>I'm using <a href=""https://github.com/bakerface/easy-source"" rel=""nofollow noreferrer"">this library</a>  and storing events in DynamoDB and projections in AWS S3.</p>&#xA;&#xA;<p>The write part works like a charm: Each command invocation loads the current state of the aggregate from DynamoDB (by running events through a handler and/or loading an cached aggregate), it decides to accept or reject the command based on some business logic, then writes to DynamoDB with <code>KeyConditionExpression: 'aggregateId = :a AND version &gt;= :v'</code> where the version is a count of events processed for that aggregate. If there's a conflict, the write fails. Seems like a good system to me!</p>&#xA;&#xA;<p>Each event is then broadcast to SNS (topic name is the service name) so other services can react to the event, if they want.</p>&#xA;&#xA;<p>The part that I really struggle with is the read. Projections are stored in S3 and tagged with the last commitId processed for each event source. When a read query comes in, it loads the entire projected state from S3 <em>(for all aggregates)</em>, queries the event sources for all newer events, computes the latest state (again, for all aggregates - and writing an updated object to S3 if it's newer), and returns relevant parts of the state based on the query params.</p>&#xA;&#xA;<p><strong>My problem: (or one of them)</strong></p>&#xA;&#xA;<p>I think I'm doing projections wrong. </p>&#xA;&#xA;<p>Most of my projections only group ids by important attribute, so the files stay relatively small. But I also need a way to retrieve an individual aggregate. Using projections for that seems crazy, because I need to load the entire state each time (i.e. every projected aggregate) apply new events to that, then retrieve the record I want (it may not have even changed).</p>&#xA;&#xA;<p>This is what I'm doing now, it's performing fine (&lt;100k records) but I can't imagine it will continue much longer. </p>&#xA;&#xA;<p>The other problem is queries. I need to build a projection mapping value to matching aggregateIds for every attribute I need to query on!! There's got to be a better way!</p>&#xA;&#xA;<p>No matter what way I think about this problem, projections always need the entire current state + any new events before it can return even a single record that hasn't changed.</p>&#xA;"
47680711,Which HTTP errors should never trigger an automatic retry?,2017-12-06 18:02:51,<http><microservices><hystrix><spring-retry>,1,461,3,2.0,4,"<p>I'm trying to make a few microservices more resilient and retrying certain types of HTTP requests would help with that.</p>&#xA;&#xA;<p>Retrying timeouts will give clients a terribly slow experience, so I don't intend to retry in this case. Retrying 400s doesn't help because a bad request will remain a bad request a few milliseconds later. </p>&#xA;&#xA;<p>I imagine there are other reasons to not retry a few other types of errors, but which errors and why?</p>&#xA;"
45538292,"In a publish/subscribe model in microservices, how to receive/consume a message only once per service type",2017-08-07 01:38:32,<rabbitmq><apache-kafka><messaging><publish-subscribe><microservices>,4,360,0,1.0,4,"<p>We are designing for a microservices architecture model where service A publishes a message and services B, and C would like to receive/consume the message. However, for high availability multiple instances of services B and C are running at the same time. Now the question is how do we design such that only one service instance of B and one service instance of C receive the message and not all the other service instances. </p>&#xA;&#xA;<p>As far as I know about RabbitMQ, it is not easy to achieve this behavior. I wonder if Kafka or any other messaging framework has a built-in support for this scenario, which I believe should be very common in a microservices architecture.</p>&#xA;"
51416552,How to call one microservice from another microservice using docker images,2018-07-19 07:16:12,<java><rest><docker><spring-boot><microservices>,2,103,8,2.0,4,"<p>I have two <code>SpringBoot</code> microservices <code>M1</code>(port 2002) and <code>M2</code>(port 2004)</p>&#xA;&#xA;<p><code>M1</code> and <code>M2</code> are communicating successfully if I run them using <code>eclipse</code> (run as Java Project or SpringBoot Project). </p>&#xA;&#xA;<p>However, I want to communicate them using <code>Docker container</code>.</p>&#xA;&#xA;<p>So I build images for both <code>Microservices</code> (<code>M1</code> and <code>M2</code>) using the command:</p>&#xA;&#xA;<pre><code>docker build -f Dockerfile -t image_name .&#xA;</code></pre>&#xA;&#xA;<p>And run the images using:</p>&#xA;&#xA;<pre><code>docker run -p 2004:2004 image_name&#xA;</code></pre>&#xA;&#xA;<p><strong>Note: I am exposing same port from docker as defined above</strong></p>&#xA;&#xA;<p>But the M1 and M2 are not able to communicate.&#xA;I am using <code>RestTemplate</code> </p>&#xA;&#xA;<pre><code>RestTemplate restTemplate = new RestTemplate();&#xA;ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://localhost:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p>I am getting below exception : </p>&#xA;&#xA;<pre><code>I/O error on GET request for \""http://localhost:2002/apis/test\"": Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)&#xA;</code></pre>&#xA;&#xA;<p>However, If I call the other microservice using my <strong>machine's IP</strong>, It's communicating successfully </p>&#xA;&#xA;<pre><code>ResponseEntity&lt;Boolean&gt; isUp = restTemplate.getForEntity(""http://XX.XX.XX.XXX:2002/apis/test"",Boolean.class);&#xA;</code></pre>&#xA;&#xA;<p><strong>Can someone please tell if I am  doing it write(using IP address) or there is another good approach to call one microservice from another using Docker?</strong> </p>&#xA;"
40669943,why hystrix or any other circuit breaker for a microservice?,2016-11-18 05:28:16,<java><spring><spring-boot><microservices><hystrix>,2,799,0,1.0,4,"<p>I am developing microservice with spring boot and spring cloud. I came to know about hystrix and circuit breaker pattern. I know that circuit breakers are for responding with alternate response in case of errors from downstream microservices on which I depend on to get the data. My question is, if I don't have any meaningful alternative response to provide, why would I need a circuit breaker at all?</p>&#xA;"
34094882,"Storing submodules for micro services, but still using forks",2015-12-04 18:18:43,<git><docker><git-submodules><docker-compose><microservices>,3,869,0,2.0,5,"<p>I am stumped here.  A lot of this is already in place, its just the wrapping that I cannot figure out.</p>&#xA;&#xA;<p>We have a micro-service architecture, with many separate repositories.  We are using Docker, and Docker Compose for building and running the development environment, which works beautifully.</p>&#xA;&#xA;<p>The question I have, is how to package up the main collection of repositories.  So if I have a folder structure like:</p>&#xA;&#xA;<pre><code>\&#xA;    service1&#xA;        .git&#xA;        Dockerfile&#xA;    service2 &#xA;        .git&#xA;        Dockerfile&#xA;    service3&#xA;        .git&#xA;        Dockerfile&#xA;    docker-compose.yml&#xA;    README.md&#xA;</code></pre>&#xA;&#xA;<p>...Where service1, service2, service3 are each their own git repository.</p>&#xA;&#xA;<p>My first thought was to use git submodules, which <em>would</em> work, however we enforce policies to require developers to fork repositories instead of working off the main repository due to continuous integration constraints and code reviews.  I was not overly excited about using git submodules at all, even before I thought of this caveat, so an alternative solution would be much preferred.</p>&#xA;&#xA;<p>At the moment i can only think to write scripts to store a list of repositories; run a query for each to see if the logged-in developer has a fork of each, creating one if not, then pulling into the master folder; and then booting docker-compose.  This seems like a horrible solution though, enough so that I may just have to write docs to just tell devs how to manually do this process...</p>&#xA;&#xA;<p>Thoughts??</p>&#xA;&#xA;<p>Thanks for your time :)</p>&#xA;"
32093067,Microservices styles and tradeoffs - Akka cluster vs Kubernetes vs,2015-08-19 10:35:06,<akka><microservices><fault-tolerance><akka-cluster><tradeoff>,1,1425,0,1.0,5,"<p>So, here's the thing. I really like the idea of microservices and want to set it up and test it before deciding if I want to use it in production. And then if I do want to use it I want to slowly chip away pieces of my old rails app and move logic to microservices. This I think I can do using HAProxy and set up different routing based on URLs. So this should be covered.</p>&#xA;&#xA;<p>Then my next biggest concern is that I don't want too much overhead to ensure everything is running smoothly on the infrastructure side. I want preferrably low configuration and the ease of development, testing and deployment.</p>&#xA;&#xA;<p>Now, I want to know what are the benefits and downsides of each styles. Akka (cluster) vs something like Kubernetes (maybe even fabric8 on top of it).</p>&#xA;&#xA;<p>What I also worry about is fault tolerance. I don't know how do you do that with Kubernetes. Do you then have to include some message queue to ensure your messages don't get lost? And then also have multiple queue if one of the queues goes down? Or just retry until queue comes up again? Akka actors already have that right? Retrying and mail boxes? What are the strategies for fault tolerance for microservices? Do they differ for each approach?</p>&#xA;&#xA;<p>Someone please enlighten me! ;)</p>&#xA;"
29303048,HATEOAS and Microservices,2015-03-27 14:26:23,<rest><hateoas><microservices><hypermedia>,2,2172,6,0.0,5,"<p>I'm having some serious trouble seeing how HATEOAS and Microservices can co-exist.</p>&#xA;&#xA;<p>Let's take an example:</p>&#xA;&#xA;<p>Let's say we have a shopping cart resource.&#xA;And we need to put snapshots of products into it, e.g. product Id, product price; snapshot of current price when item was added to cart, and possibly some other values.&#xA;The actual use-case is not relevant, but just to get some idea on the problem at hand.</p>&#xA;&#xA;<p>When I have been doing HATEOAS earlier, I would have put a link in the shopping cart resource that links to products or a template url that links to a specific product.</p>&#xA;&#xA;<p>This way, the client can still be ignorant of resource URL's.</p>&#xA;&#xA;<p>But in the microservice world, a service should have no knowledge of other services. AFAIK.</p>&#xA;&#xA;<p>So how could they both work together?</p>&#xA;&#xA;<p>My interpretation of microservices is that they can never link to anything else than themselves, which would pretty much be a <code>Self</code> link.</p>&#xA;&#xA;<p>I've found the same question asked on ther places, e.g.&#xA;<a href=""https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc"" rel=""noreferrer"">https://groups.google.com/forum/#!topic/api-craft/YRkLFVY_zFc</a></p>&#xA;&#xA;<p>Where solutions like ""macro services"" that weave all this together is used.&#xA;Which doesn't seem like a clean way to solve things.</p>&#xA;&#xA;<p>[Edit]</p>&#xA;&#xA;<p>I've found some more nice info on the topic:&#xA;<a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">https://github.com/Netflix/eureka</a>&#xA;<a href=""https://github.com/RestExpress/HyperExpress"" rel=""noreferrer"">https://github.com/RestExpress/HyperExpress</a></p>&#xA;&#xA;<p>This seems nice to have some tool augument the resources with links, but this makes me think, where does the logic to decide what links a resource should have belongs?&#xA;In the service that exposes the resource?&#xA;In the central service registry?</p>&#xA;"
32529742,how to roll back a transaction happening between microservices?,2015-09-11 18:15:08,<java><spring><spring-mvc><spring-data><microservices>,4,2904,0,1.0,5,"<p>we have <code>microservice</code> architecture where for most part each <code>microservice</code> is independent. But for some legacy reasons, there is a situation where we have to call another <code>microservice</code> from within another.</p>&#xA;&#xA;<p>eg: the following method is part of <code>Legal Service</code></p>&#xA;&#xA;<pre><code>@Autowired&#xA;public ServiceManager UserServiceManager;&#xA;&#xA;public void updateUserLegalData(){&#xA;&#xA;    //do db update of Legal info for the user&#xA;&#xA;   userServiveManager.setAcceptedLegal(true);&#xA;&#xA;&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>There are two <code>db transactions</code> going on above. one is updating legalService db and other is updating UserService db. please NOTE userService is a <code>microservice</code>running on a separate VM.</p>&#xA;&#xA;<p>we are seeing situations where legal Service db is updated but call to userService is failing (<code>Internal server error</code>). so this leaves the application in an inconsistent state. How can we fix this in a recommended way?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
39154613,Netflix Ribbon and Hystrix Timeout,2016-08-25 20:57:31,<spring-boot><spring-cloud><microservices><hystrix><netflix-ribbon>,1,3615,2,1.0,5,"<p>We are using Spring cloud in our project. We have several micro services and each has its own .yml file.</p>&#xA;&#xA;<p>Below properies are only in zuul server</p>&#xA;&#xA;<pre><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000&#xA;&#xA;    ribbon: &#xA;     ConnectTimeout: 3000&#xA;     ReadTimeout: 60000&#xA;</code></pre>&#xA;&#xA;<p><strong>Test 1:</strong></p>&#xA;&#xA;<p><strong>Accounts Service:</strong></p>&#xA;&#xA;<p>This service is what I'm calling to test the timeout and I'm calling the request through zuul i.e., using the port 8006.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>The above service internally calls the below one using Spring RestTemplate.&#xA;I started testing by adding a sleep time of 5000ms like below in <strong>Association Service</strong> and made a request to <strong>Accounts Service</strong> (getAccounts call).</p>&#xA;&#xA;<p><strong>Association Service:</strong></p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/internal/userassociationstatus"", produces = ""application/json; charset=utf-8"", consumes = ""application/json"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public UserAssociationStatusVO getUserAssociationStatus(@RequestParam final Map&lt;String, String&gt; allRequestParams) {&#xA;        try {&#xA;            Thread.sleep(5000);&#xA;        } catch (InterruptedException e) {&#xA;            // TODO Auto-generated catch block&#xA;            e.printStackTrace();&#xA;        }&#xA;        return iUserAssociationsService.getUserAssociationStatus(allRequestParams);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Association Service</strong></p>&#xA;&#xA;<pre><code>org.apache.catalina.connector.ClientAbortException: java.io.IOException: An established connection was aborted by the software in your host machine&#xA;at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:393) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.tomcat.util.buf.ByteChunk.flushBuffer(ByteChunk.java:426) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:342) ~[tomcat-embed-core-8.0.30.jar:8.0.30]&#xA;</code></pre>&#xA;&#xA;<p>Below is the error I got in <strong>Accounts Service</strong></p>&#xA;&#xA;<pre><code>org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://USERASSOCIATIONS-V1/user/v1/internal/userassociationstatus?cardholderid=123&amp;usercontextid=222&amp;role=ACCOUNT"": com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out; nested exception is java.io.IOException: com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out&#xA;    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:607) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:557) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;    at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:475) ~[spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]&#xA;</code></pre>&#xA;&#xA;<p>If I keep the sleep time as 4500 it gives me response, but if is >=4800 it throws the above exception. I'm thinking this is not related to Ribbon Timeouts but something else. Any specific reason for the above exception after certain point. </p>&#xA;&#xA;<p><strong>Test 2</strong></p>&#xA;&#xA;<p>Then I tried keeping a sleep time of 75000 ms in <strong>Accounts Service</strong> directly and removed sleep time <strong>Association Service</strong>.</p>&#xA;&#xA;<pre><code>@RequestMapping(value = ""/accountholders/{cardHolderId}/accounts"", produces = ""application/json; charset=utf-8"", method = RequestMethod.GET)&#xA;    @ResponseBody&#xA;    public AllAccountsVO getAccounts(@PathVariable(""cardHolderId"") final String cardHolderId,&#xA;            @RequestHeader(""userContextId"") final String userContextId,&#xA;            @RequestParam final MultiValueMap&lt;String, String&gt; allRequestParams, final HttpServletRequest request) {&#xA;&#xA;        try {&#xA;            Thread.sleep(75000);&#xA;        } catch (InterruptedException ex) {&#xA;            // TODO Auto-generated catch block&#xA;            ex.printStackTrace();&#xA;        }&#xA;        return iAccountService.getCardHolderAccountsInfo(cardHolderId, userContextId, request, allRequestParams,&#xA;                ApplicationConstants.ACCOUNTHOLDER);&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>In this case I got   ""exception"": ""com.netflix.zuul.exception.ZuulException"",</p>&#xA;&#xA;<p>And in my APIGateway(Zuul application) log I see the below error.</p>&#xA;&#xA;<pre><code>com.netflix.zuul.exception.ZuulException: Forwarding error&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:134) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:76) ~[spring-cloud-netflix-core-1.1.0.M5.jar:1.1.0.M5]&#xA;    at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:112) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;    at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:197) ~[zuul-core-1.1.0.jar:1.1.0]&#xA;&#xA;&#xA;Caused by: com.netflix.hystrix.exception.HystrixRuntimeException: useraccounts-v1RibbonCommand timed-out and no fallback available.&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:806) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at com.netflix.hystrix.AbstractCommand$16.call(AbstractCommand.java:790) ~[hystrix-core-1.4.23.jar:1.4.23]&#xA;    at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$1.onError(OperatorOnErrorResumeNextViaFunction.java:99) ~[rxjava-1.0.14.jar:1.0.14]&#xA;    at rx.internal.operators.OperatorDoOnEach$1.onError(OperatorDoOnEach.java:70) ~[rxjava-1.0.14.jar:1.0.14]&#xA;</code></pre>&#xA;&#xA;<p>I think this has nothing to do with Ribbon ConnectTimeout or ReadTimeout. This error is because of the property <strong>""execution.isolation.thread.timeoutInMilliseconds: 60000""</strong>. I have also reduced this property to 10000 ms to test the behavior and got the same exception if the sleep time is more(ex: 12000).</p>&#xA;&#xA;<p><strong>I want to understand Ribbon ConnectTimeout and Read-timeout vs Hystrix timeout and how to test ribbon timeouts in my application. Also if I want different timeouts for different microservices, Do I keep these properties in respective .yml files?.</strong> Any thoughts?</p>&#xA;&#xA;<p>I'm trying to create a document to be used by my team so that it is easy for a developer to know how these timeout options work in Spring cloud.</p>&#xA;&#xA;<p>(It's a lengthy description but to make it clearer I had to write in detail)</p>&#xA;"
31097306,Spring Boot + Tomcat - Microservices solution,2015-06-28 07:44:28,<spring-boot><microservices>,2,4706,4,1.0,5,<p>I'm planning to expose few microservices (~20 at this stage) using Spring Boot. I will be creating executable fat jars using the embededed Tomcat. The executable jar will be wrapped in Docker container and deployed to AWS. </p>&#xA;&#xA;<p>In my case 20 jars will have 20 tomcat instances running at the same time. I'm concerned about the overhead of running so many tomcat instances in the production server. Is this a valid concern?</p>&#xA;&#xA;<p>I was wondering if someone has used something similar configuration in production and can share their experience.</p>&#xA;&#xA;<p>Any suggestions will be appreciated.</p>&#xA;&#xA;<p>Thanks&#xA;JP</p>&#xA;
36197572,How to improve communication between microservices,2016-03-24 10:07:12,<java><rest><spring-boot><microservices>,3,2704,0,0.0,5,"<p>In our company we use spring boot, microservices, spring cloud and so on... We are happy with this infrastructure, but I still have some concerns:&#xA;we use rest as comunication protocoll and even if a I find it great, I still think that we could find something better. With rest:</p>&#xA;&#xA;<ul>&#xA;<li>you need to use a client and a server (restcontroller)</li>&#xA;<li>you need to know the server <code>URI</code>, the http method (<code>POST, GET, PUT,...</code>)</li>&#xA;<li>you need know where params go (body, querystring)</li>&#xA;<li>....</li>&#xA;</ul>&#xA;&#xA;<p>Don't you think It would be much easier if we had something like RMI? I know it's a quite old technology(and it's not language independent), but it made life easier (you just need an interface and its implementation).</p>&#xA;&#xA;<p>Searching around, I found some interesting projects like feign clients or spring cloud stream, but none of them seem to be the silver bullet. </p>&#xA;&#xA;<p>What do you think about this topic? Is that a problem that you feel? If so, how do you approach it? </p>&#xA;&#xA;<p>Thanks in advance.</p>&#xA;"
36144330,Scaling microservices using Docker,2016-03-22 00:49:13,<node.js><meteor><amazon-ec2><docker><microservices>,2,389,2,1.0,5,"<p>I've created a Node.js (Meteor) application and I'm looking at strategies to handle scaling in the future. I've designed my application as a set of microservices, and I'm now considering implementing this in production.</p>&#xA;&#xA;<p>What I'd like to do however is have many microservices running on one server instance to maximise resource usage whilst they are using a small number of resources. I know containers are useful for this, but I'm curious if there's a way to create a dynamically scaling set of containers where I can:</p>&#xA;&#xA;<ul>&#xA;<li>Write commands such as ""provision another app container on this server if the containers running this app reach > 80% CPU/other limiting metrics"",</li>&#xA;<li>Provision and prepare other servers if needed for extra containers,</li>&#xA;<li>Load balance connections between these containers (and does this affect server load balancing, e.g., send less connections to servers with fewer containers?)</li>&#xA;</ul>&#xA;&#xA;<p>I've looked into AWS EC2, Docker Compose and nginx, but I'm uncertain if I'm going in the right direction.</p>&#xA;"
47050984,Enabling session in lumen framework,2017-11-01 08:39:14,<laravel><microservices><lumen>,3,2894,12,1.0,5,"<p>I have two (but let's image more) micro-services (API) which need to be aware of authenticated user. Ideally I would simple like to resume their sessions.</p>&#xA;&#xA;<p>All micro-services are using same storage for sessions: redis.</p>&#xA;&#xA;<p>All API calls will have Cookie header, so all services will be able to resume sessions based on that cookie. I have successfully implemented this via PHP $_SESSIONs.</p>&#xA;&#xA;<p>Now the question: how would you go about implementing this with Laravel/Lumen?</p>&#xA;"
38186942,Correlation Token for Service Fabric Actors and Services,2016-07-04 14:20:13,<logging><token><actor><microservices><azure-service-fabric>,1,292,0,1.0,5,"<p>We started playing with Service Fabric as a microservice platform and after having succesfully implemented our firsts ""hello world"" samples about actor pattern, stateless/stateful services, web api (and so on) we are moving to looking solutions for other core aspects like auth/autz and application logging.</p>&#xA;&#xA;<p>I have a doubt about the Logging; in all the SOA we have designed till now we always added a ""correlation token"" to all the services involved (often at architectural level, automatically added as header onto WCF, hidden to the developers) so, now we are trying to do the same with Service Fabric.</p>&#xA;&#xA;<p>Looking for the best solution to let flow a ""Correlation Token"" through all the actor/service calls, since we haven't found out anything ready out-of-the-box, we are wondering if we are looking for something theoretically wrong.</p>&#xA;&#xA;<p>Any suggestion out there?</p>&#xA;"
39913816,Zero Downtime Deployment for Micro Service architecture,2016-10-07 09:22:58,<java><database><docker><spring-boot><microservices>,1,911,4,0.0,5,"<p>At the moment I'm working on an application which will be based on the <strong>Micro Service architecture</strong>. As main technologies we planned to use <strong>Spring Boot and Docker</strong> for each Micro Service development. One of the goals is to provide Zero Downtime Deployment feature for the users. </p>&#xA;&#xA;<p>I spent some time trying to found some solution and know about <code>Blue Green Deployment (BGD)</code> but some aspects is still not clear for me. The main problem is DataBase state and version compatibility. </p>&#xA;&#xA;<blockquote>&#xA;  <p>For example if <code>BGD</code> is used how to migrate all the data changes from&#xA;  Green to Blue contour after successful deployment?</p>&#xA;</blockquote>&#xA;&#xA;<p>I found interesting approach in Spring's <a href=""https://spring.io/blog/2016/05/31/zero-downtime-deployment-with-a-database"" rel=""nofollow"">Zero Downtime Deployment with a Database</a> article, but I think that such approach has too complicated Application Versions and Releases Planing process and backward compatibility requirements.</p>&#xA;&#xA;<p>So my I want to ask following questions:</p>&#xA;&#xA;<ol>&#xA;<li>Any suggestions on the Zero Downtime Deployment process concept, backed by real  experience using  it?</li>&#xA;<li>Is there any Out Of The box solutions (Paid or Free)  that provide Zero Downtime Deployment feature for applications with Relational Data Base?</li>&#xA;</ol>&#xA;&#xA;<p><strong>PS</strong></p>&#xA;&#xA;<p><em>It is interesting how Zero Downtime Deployment works in StackOverflow.com if it is?</em></p>&#xA;"
46742274,About the Mediator in Event-Driven Topology,2017-10-14 08:00:14,<events><microservices><event-driven><orchestration><event-driven-design>,2,278,0,2.0,5,"<p>I was reading this article called <a href=""http://radar.oreilly.com/2015/02/variations-in-event-driven-architecture.html"" rel=""nofollow noreferrer"">Variations in event-driven architecture</a> in which they demonstrate both the mediator and broker topologies.</p>&#xA;&#xA;<p>According to the article the mediator topology looks somewhat like this:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QTwOw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QTwOw.jpg"" alt=""Mediator Topology""></a></p>&#xA;&#xA;<blockquote>&#xA;  <p>The event flow starts with the client sending an event to an <em>event queue</em>, which is used to transport the event to the mediator. The <em>event mediator</em> receives the initial event and orchestrates that event by sending additional asynchronous events to <em>event channels</em> to execute each step of the process. <em>Event processors</em>, which listen on the event channels, receive the event from the even mediator and execute specific business logic to process the event [...] It is important to note that the event mediator doesn't actually perform the business logic necessary to process the initial event, rather, it knows of the steps required to process the event [...] The event channels can be either message queues o message topics.</p>&#xA;</blockquote>&#xA;&#xA;<p>So, I was studying this diagram, trying to understand how the mediator could determine when a given processor has finished processing a given event, such that it could orchestrate the next step of the process.</p>&#xA;&#xA;<p>The article is not clear enough when it says</p>&#xA;&#xA;<blockquote>&#xA;  <p>For each initial event step, the event mediator creates a processing event, sends that processing event and <em>waits</em> for the processing event to be processed by the corresponding event processor. This process continues until all of the steps in the initial event have been processed.</p>&#xA;</blockquote>&#xA;&#xA;<p>Now, the article is clear in that the communication is asynchronous, and event messages will travel through message queues, but the diagram does not show <em>any events coming out of the event processor and back to the mediator</em>.</p>&#xA;&#xA;<p>The article says the mediator waits for the event processor to finish, but it is not clear how this is supposed to happen in architectural terms.</p>&#xA;&#xA;<p>Is it asynchronous, queue-based RPC (e.g. <a href=""https://www.rabbitmq.com/tutorials/tutorial-six-python.html"" rel=""nofollow noreferrer"">Rabbit RPC</a>), or is there another listener waiting for an asynchronous response somewhere?</p>&#xA;&#xA;<p>Any thoughts on how this can be implemented from an architectural standpoint?</p>&#xA;"
37662379,Jhipster import-jdl not generating entities,2016-06-06 16:23:46,<jhipster><microservices>,4,2344,1,4.0,5,"<p>I am running into a problem with import-jdl and I am not sure why it is not working. I am trying to generate entities for microservices application. </p>&#xA;&#xA;<p>All I get is </p>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;&#xA;<p>but nothing else.</p>&#xA;&#xA;<p>I used the sample <a href=""https://jhipster.github.io/jdl-studio/"" rel=""nofollow"">https://jhipster.github.io/jdl-studio/</a> entity provided by JDL without any modification. </p>&#xA;&#xA;<p>I have tried this in my Mac, Linux (Ubuntu), and Docker container but I get the same error. </p>&#xA;&#xA;<p>Here are the versions of the software: </p>&#xA;&#xA;<pre><code>JHipster Generator: v3.3.0&#xA;npm : 3.9.2&#xA;yo : 1.8.3&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>Microservices Application </p>&#xA;  &#xA;  <p>------- Application files will be generated in folder: /Users/anand/Desktop/jhexample </p>&#xA;  &#xA;  <hr>&#xA;  &#xA;  <p>JHipster update available: 3.4.0 (current: 3.3.0)   Run npm install&#xA;  -g generator-jhipster to update.  ______________________________________________________________________________</p>&#xA;  &#xA;  <p>? (1/16) Which <em>type</em> of application would you like to create?&#xA;  Microservice application</p>&#xA;  &#xA;  <p>? (2/16) What is the base name of your application? jhexample</p>&#xA;  &#xA;  <p>? (3/16) As you are running in a microservice architecture, on which&#xA;  port would like your server to run? It should be unique to avoid port&#xA;  conflicts. 8081</p>&#xA;  &#xA;  <p>? (4/16) What is your default Java package name? com.anand</p>&#xA;  &#xA;  <p>? (5/16) Which <em>type</em> of authentication would you like to use? JWT&#xA;  authentication (stateless, with a token)</p>&#xA;  &#xA;  <p>? (6/16) Which <em>type</em> of database would you like to use? MongoDB</p>&#xA;  &#xA;  <p>? (7/16) Would you like to use Maven or Gradle for building the&#xA;  backend? Maven</p>&#xA;  &#xA;  <p>? (8/16) Would you like to enable internationalization support? No</p>&#xA;  &#xA;  <p>? (9/16) Which testing frameworks would you like to use? (Press&#xA;   to select)Gatling</p>&#xA;</blockquote>&#xA;&#xA;<p>...snip...</p>&#xA;&#xA;<blockquote>&#xA;  <p>Server app generated successfully.</p>&#xA;</blockquote>&#xA;&#xA;<pre><code>anand$ yo jhipster:import-jdl ./jhipster-jdl.jh&#xA;</code></pre>&#xA;&#xA;<blockquote>&#xA;  <p>The jdl is being imported.</p>&#xA;</blockquote>&#xA;"
44704629,identity aspnet core microservices,2017-06-22 16:15:48,<asp.net-core><microservices><identityserver4>,1,373,0,1.0,5,"<p>I want to develop an application using microservices architecture. I'm really new at microservices and until now I've only worked with monolithich approach.</p>&#xA;&#xA;<p>What I would like to do is to have a microservice which takes care of user authentication and have Proxy APIS to authorize the requests. </p>&#xA;&#xA;<p>Authorizing the request in the Proxy API is pretty well documented on the IdentityServer4 docs, but, when the proxy api passes the request to the end microservice how do I authorize this request?</p>&#xA;&#xA;<p>I know that if I setup the end microservice correctly, the same token used in the proxy api can be used to authorize the request at the end microservice. But how do I pass it? Do I grab the token from the request in the Proxy API and pass it down to the end microservice just like that? is it a good practice to do this?</p>&#xA;&#xA;<p>Or is it a better option to block the end microservice to receive only requests from my proxy apis and have no authorization logic there?</p>&#xA;&#xA;<p>PD: I would like to use asp.net-core</p>&#xA;"
37523631,HTTP vs Thrift in microservices architecture,2016-05-30 10:39:41,<java><microservices>,1,2185,0,1.0,5,"<p>I'm have just start learning about micro-services and I have a question that I cannot answer myself. (and I'm also a Java based developer)</p>&#xA;&#xA;<p>I have a situation like this:</p>&#xA;&#xA;<ol>&#xA;<li><p>I have service A (an API service) that call Thrift services (Named T1) for get data.</p></li>&#xA;<li><p>Then I have a service B that can use data response from A, parse these data and then generate some new data, finally, return it to client.</p></li>&#xA;</ol>&#xA;&#xA;<p>The question is: Which I should use?&#xA;B call API from A and parse (for example JSON data) with HttpClient/ AsyncHttpClient with connection pool or B direct call T1 and repeat what A do?</p>&#xA;&#xA;<p>IMHO, I think Thrift (with connection pooling too) is faster than HTTP call? Am I right?</p>&#xA;&#xA;<p>I see a lot of services that use HTTP for internal like Elastic search, Neo4j, Eureka Netflix, etc ...</p>&#xA;&#xA;<p>So, which one should I use? And why HTTP is so popular for internal use instead of RPC like Thrift, ProtoBuf, ...?</p>&#xA;&#xA;<p>Sorry for my bad english.&#xA;Thank you in advance.</p>&#xA;"
44065186,How to implement distributed transaction with hystrix fallback based on Spring Cloud architect,2017-05-19 08:35:52,<spring-cloud><microservices><distributed-transactions><hystrix><spring-cloud-netflix>,1,1134,1,4.0,5,"<p>I am using spring cloud to implement my micro services system, a ticket sale platform. The scenario is, there is a zuul proxy, a eureka registry, and 3 service: user service, order service and ticket service. Services use feign declarative REST Client to communicate with each other.</p>&#xA;&#xA;<p>Now there is a function to buy tickets, the main process is as below:<br>&#xA;  1. order service accept request to create order<br>&#xA;  2. order service create Order entity with Pending status.<br>&#xA;  3. order service call user service to process user pay.<br>&#xA;  4. order service call ticket service to update user tickets.<br>&#xA;  5. order service update the order entity as FINISHED.</p>&#xA;&#xA;<p>And I want to use <code>Hystrix Fallback</code> to implement transaction. For example, if the payment process is finished, but some error happened during ticket movement. How to revet user payment, and order status. Because user payment is in other service.</p>&#xA;&#xA;<p>The following is my current solution, I am not sure whether it is proper. Or is there any other better way to do that.</p>&#xA;&#xA;<p>At first, the OrderResource:</p>&#xA;&#xA;<pre><code>@RestController&#xA;@RequestMapping(""/api/order"")&#xA;public class OrderResource {&#xA;&#xA;  @HystrixCommand(fallbackMethod = ""createFallback"")&#xA;  @PostMapping(value = ""/"")&#xA;  public Order create(@RequestBody Order order) {&#xA;    return orderService.create(order);&#xA;  }&#xA;&#xA;  private Order createFallback(Order order) {&#xA;    return orderService.createFallback(order);&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then the OrderService:</p>&#xA;&#xA;<pre><code>@Service&#xA;public class OrderService {&#xA;&#xA;    @Transactional&#xA;    public Order create(Order order) {&#xA;        order.setStatus(""PENDING"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        userCompositeService.payForOrder(payDTO);&#xA;&#xA;        order.setStatus(""PAID"");&#xA;        order = orderRepository.save(order);&#xA;&#xA;        ticketCompositeService.moveTickets(ticketIds, currentUserId);&#xA;&#xA;        order.setStatus(""FINISHED"");&#xA;        order = orderRepository.save(order);&#xA;        return order;&#xA;    }&#xA;&#xA;    @Transactional&#xA;    public Order createFallback(Order order) {&#xA;        // order is the object processed in create(), there is Transaction in create(), so saving order will be rollback,&#xA;        // but the order instance still exist.&#xA;        if (order.getId() == null) { // order not saved even.&#xA;            return null;&#xA;        }&#xA;        UserPayDTO payDTO = new UserPayDTO();&#xA;        try {&#xA;            if (order.getStatus() == ""FINISHED"") { // order finished, must be paid and ticket moved&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PAID"") { // is paid, but not sure whether has error during ticket movement.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;                ticketCompositeService.moveTicketsFallback(getTicketIdList(order.getTicketIds()), currentUserId);&#xA;            } else if (order.getStatus() == ""PENDING"") { // maybe have error during payment.&#xA;                userCompositeService.payForOrderFallback(payDTO);&#xA;            }&#xA;        } catch (Exception e) {&#xA;            LOG.error(e.getMessage(), e);&#xA;        }&#xA;&#xA;        order.setStatus(""FAILED"");&#xA;        orderRepository.save(order); // order saving is rollbacked during create(), I save it here to trace the failed orders.&#xA;        return order;&#xA;    }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Some key points here are:</p>&#xA;&#xA;<ol>&#xA;<li>Using <code>@HystrixCommand</code> in <code>OrderResource.create(order)</code> method, with <code>fallback</code> function.   </li>&#xA;<li>If there is some error in creation, the <code>order</code> instance used in  <code>OrderResource.create(order)</code> will be used again in fallback function. Although the persistence of this <code>order</code> will be roll-backed. But the data in this instance still can be used to check the running.   </li>&#xA;<li>So I use a status: 'PENDING', 'PAID', 'FINISHED' to check whether some service call is made.   </li>&#xA;<li><code>ticketCompositeService</code> and <code>userCompositeService</code> is a feign client. For feign client method <code>payForOrder()</code>, there is another method <code>payForOrderFallback()</code> for fallback.   </li>&#xA;<li>I need to make sure the fallback methods can be called multiple times.   </li>&#xA;<li>I add <code>try/catch</code> for <code>ticketCompositeService</code> and <code>userCompositeService</code> call, to make sure the order will be save anyway with 'FAILED' status.</li>&#xA;</ol>&#xA;&#xA;<p>It seems that this solution can work at the most of the time. Except that, in fallback function, if there is some error in <code>userCompositeService.payForOrderFallback(payDTO);</code>, then the following composite service call will not be called.</p>&#xA;&#xA;<p>And, another problem is, I think it is too complicated.</p>&#xA;&#xA;<p>So, for this scenario, how should I implement dist transaction properly and effectively. Any suggestion or advice will help. Thanks.</p>&#xA;"
40972026,Netflix-Zuul vs Mashape-Kong,2016-12-05 10:26:37,<microservices><netflix-zuul><kong><mashape>,1,4235,4,3.0,5,<p>Both Zuul and kong serve as a good API gateway layer in a microservices architecture. What are some important differences between these two?</p>&#xA;
49944806,"How we configure API gateway, service discovery for micro services in pcf?",2018-04-20 15:13:55,<spring-boot><microservices><spring-cloud-netflix><pcf>,2,254,0,2.0,5,"<p>I am learning building  microservices using spring boot, Spring Cloud(netflix OSS Components). I have used netflix Eureka for service discovery, zuul for api gateway, ribbon, feign while running in my local machine.</p>&#xA;&#xA;<p>Netflix eureka, zuul, ribbon, feign spring cloud config are not useful when we deploy to PCF?(if yes what are the alternatives available in pcf and how to configure them?)</p>&#xA;&#xA;<p>As who are building microservices follows CI/CD approach, how developer verify working of  their micro services before pushing code as we don't use eureka, zuul,ribbon,feign in production pcf. (how to simulate pcf environment in developer machine?). </p>&#xA;"
47516458,CQRS: project out-of-order notifications in an ElasticSearch read model,2017-11-27 17:17:35,<elasticsearch><apache-kafka><domain-driven-design><microservices><cqrs>,1,162,8,4.0,5,"<p>We have a microservice architecture and apply the CQRS pattern. A command sent to a microservice triggers an application state change and the emission of the corresponding event on our Kafka bus. We project these events in a read model built with ElasticSearch.</p>&#xA;&#xA;<p>So far, so good.</p>&#xA;&#xA;<p>Our microservices are eventually consistent with each other. But at any given time, they aren't (necessarily). Consequently, the events they send are not always consistent with each other either.</p>&#xA;&#xA;<p>Moreover, to guarantee the coherence between an application state change and the emission of the corresponding event, we persist in DB the new state and the corresponding event in the same transaction (I am aware that we could use event sourcing and avoid persisting the state altogether). An asynchronous worker is then responsible to send these events on the Kafka bus. This pattern guarantees that at least one event will be sent for each state change (which is not an issue since our events are idempotent). However, since each microservice has its own event table and asynchronous worker, we cannot guarantee that events will be sent in the sequence in which the corresponding state changes occurred in their respective microservices.</p>&#xA;&#xA;<p>EDIT: to clarify, each microservice has its own database, its own event table and its own worker. A specific worker processes the events in the order in which they were persisted in its corresponding event table, but different workers on different event tables, i.e. for distinct microservices, do not give such guarantee.</p>&#xA;&#xA;<p>The problem arises when projecting these incoherent or out-of-sequence events from different microservices in the same ElasticSearch document.</p>&#xA;&#xA;<p>A concrete example: let's imagine three different aggregates A, B and C (aggregate in the Domain Driven Design sense) managed by different microservices:</p>&#xA;&#xA;<ul>&#xA;<li>There is a many-to-many relation between A and B. Aggregate A references the aggregate roots B he is bound to, but B is unaware of its relationships with A. When B is deleted, the microservice managing A listens for the corresponding event and undoes the binding of A with B.</li>&#xA;<li>Similarily, there is a many-to-many relation between B and C. B knows of all related C aggregates, but the inverse is not true. When C is deleted, the microservice managing B listens for the corresponding event and undoes the binding of B with C.</li>&#xA;<li>C has a property ""name"".</li>&#xA;</ul>&#xA;&#xA;<p>One of the use cases is to find, through ElasticSearch, all aggregates A that are bound to an aggregate B that is in turn bound to an aggregate C with a specific name.</p>&#xA;&#xA;<p>As explained above, the separate event tables and workers could introduce variable delays between the emission of events from different microservices. Creating A, B and C and binding them together could for example result in the following sequence of events:</p>&#xA;&#xA;<ol>&#xA;<li>B created</li>&#xA;<li>B bound to C</li>&#xA;<li>C created with name XYZ</li>&#xA;<li>A created</li>&#xA;<li>A bound to B</li>&#xA;</ol>&#xA;&#xA;<p>Another example of batch of events: let's suppose we initially have aggregates B and C and two commands are issued simultaneously:</p>&#xA;&#xA;<ul>&#xA;<li>delete C</li>&#xA;<li>bind B to C</li>&#xA;</ul>&#xA;&#xA;<p>this could result in the events:</p>&#xA;&#xA;<ol>&#xA;<li>C deleted</li>&#xA;<li>B bound to C</li>&#xA;<li>B unbound from C (in response to event 1)</li>&#xA;</ol>&#xA;&#xA;<p>Concretely, we have trouble projecting these events in ElasticSearch document(s) because the events sometimes reference aggregates that do not exist anymore or do not exist yet. Any help would be appreciated.</p>&#xA;"
37148836,"What is service discovery, and why do you need it?",2016-05-10 20:56:48,<web-services><configuration><architecture><microservices>,1,1765,2,4.0,5,"<p>As far as I can tell, ""service discovery"" means a way for a client to find out about a server (or cluster of servers) that it wants to connect to.</p>&#xA;&#xA;<p>I've built web applications that communicate with other back-end processes using protocols like HTTP and AMQP. In those, each client has a config file that contains a host name or whatever information it needs to connect to the server, which gets set at deployment time using a configuration tool like Ansible. That's simple and seems to work pretty well.</p>&#xA;&#xA;<p>Is service discovery an alternative to just putting server information in a client's config file? If so, why is it better? If not, what problem does it solve?</p>&#xA;"
29636094,Microservices communication,2015-04-14 19:45:33,<java><node.js><apache-zookeeper><microservices>,2,2362,1,3.0,5,"<p>I'm actually studying microservices and I'm facing a problem.</p>&#xA;&#xA;<p><strong>Context</strong></p>&#xA;&#xA;<p>I m developing two microservices :</p>&#xA;&#xA;<ul>&#xA;<li>User management, Spring Based, with MySQL database</li>&#xA;<li>Planning management, ASP.NET based with SQL Server database. The only access point of this service is an API listing some RESTFUL endpoints like <code>/planning/{day}/{userId} or /planning/{startDate}/{endDate}/{idUser}</code></li>&#xA;<li>Billing management, Node.Js based with MongoDB.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Problems</strong></p>&#xA;&#xA;<ol>&#xA;<li><p>What can I do to only permit accessing the planning information through the user service without couple the two services ? Knowing that the planning service could be accessed later from somewhere else, but not now.</p></li>&#xA;<li><p>How can I do to access billing information from billing service corresponding to a user from the MySQL database? I know that microservices are not coupled, and this point is killing me, cause it has to be coupled in a way no? Like referencing <code>idUser</code> in a billing? Else, how can I know which billing from my API should I expose? More precisely, how do microservices communicate between them, without to be coupled?</p></li>&#xA;<li><p>How to create authentication without duplicating authentication requests to the authentication service, from other services?</p></li>&#xA;</ol>&#xA;"
41814001,Heroku load balancer vs Netflix zuul,2017-01-23 19:20:54,<heroku><docker><microservices><netflix-zuul><netflix-eureka>,1,514,0,1.0,5,"<p>According to this answer <a href=""https://stackoverflow.com/a/41811770/2849613"">https://stackoverflow.com/a/41811770/2849613</a> I would like to get a little bit more information about best practices with microservices on Heroku. </p>&#xA;&#xA;<p>The question is which approach is better?</p>&#xA;&#xA;<ol>&#xA;<li>Install every services as independent app, and use one of them as REST ""proxy"" (for example Netflix Eureka)?</li>&#xA;</ol>&#xA;&#xA;<p>Or</p>&#xA;&#xA;<ol start=""2"">&#xA;<li>Create docker based approach with, for example Netflix Zuul as a load balancer?</li>&#xA;</ol>&#xA;&#xA;<p>On my own I see already some pros and cons of both approaches:</p>&#xA;&#xA;<ol>&#xA;<li><p><strong>Pros</strong>: better scalability (easy to create new machines for bigger load). <strong>Cons</strong>: communication between services goes ""outside of heroku"" in other words: because heroku app have public address everyone can connect directly to service (without going threw Eureka), because of that every services need to provide some authentication method and share it between each other - I think that this is risk prone. </p></li>&#xA;<li><p><strong>Pros</strong>: easy to reproduce production environment for tests and develop (docker image), communication between services is done ""internally"" (image to image instead app to app). <strong>Cons</strong>: hard to scale (I think that load balancing between Heroku apps and then docker images is a little bit overhead). </p></li>&#xA;</ol>&#xA;&#xA;<p>Which approach is better? Maybe I can mix them together? Or maybe there is some different, better solution?</p>&#xA;&#xA;<p>Do be honest the only thing which I am sure, is that I want to use rabbitMQ as a message queue...</p>&#xA;"
39450504,Serverless Framework - Two services under one APIGW endpoint,2016-09-12 12:37:05,<microservices><amazon-cloudformation><aws-api-gateway><serverless-framework>,5,628,0,1.0,5,"<p>If I have two services, 'Users' and 'Products', each with several functions with endpoints defined for each one (as any traditional API would), is it possible for them to be organised separately in a code base (for clarity) but once deployed share the same API base URL? For example, consider I have the following structure:</p>&#xA;&#xA;<pre><code>/src&#xA;-- /users&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;-- /products&#xA;---- event.json&#xA;---- handler.js&#xA;---- serverless.yml&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/users/serverless.yml</code> has the following defined:</p>&#xA;&#xA;<pre><code>functions:&#xA;  create:&#xA;    handler: handler.create&#xA;    events:&#xA;      - http: POST user&#xA;&#xA;  read:&#xA;    handler: handler.read&#xA;    events:&#xA;      - http: GET user&#xA;</code></pre>&#xA;&#xA;<p>and my <code>src/products/serverless.yml</code> has basically the same thing, just swap 'user' for 'products'.</p>&#xA;&#xA;<p>Currently, both of those services will be deployed to distinctly different API endpoints, one with a URL <code>https://fghijklmnop.execute-api...</code> and another with a URL <code>https://abcdevwxyz.execute-api....</code> </p>&#xA;&#xA;<p>My question is, would it be possible to have these services be deployed but remain under a single API with a single URL (so both would be served under URL <code>https://abcdevwxyz.execute-api....</code>)?</p>&#xA;&#xA;<p>I'm assuming the answer to be, 'No, because Cloud Formation...', but I thought I would post the question here simply for the sake of discussion and to aid my own understanding of building serverless applications.</p>&#xA;&#xA;<p>I'm aware of using Custom Domains, as per <a href=""https://stackoverflow.com/questions/38408493/serverless-framework-v1-multiple-resources-in-one-service"">the answer here</a>, but for a quicker development cycle this is not really an ideal solution.</p>&#xA;&#xA;<p>My only solution so far would be to simply create a service called 'api' which would contain all the endpoints my API would need which would simply invoke my other services' Lambda functions directly rather than via previously-configured endpoints. It would be an abstraction layer, really, but add potentially unnecessary layers to my application. Again, curious to see what the community feels on this.</p>&#xA;"
20693516,"In a micro-service architecture, how the micro-services will be served?",2013-12-19 23:12:37,<service><deployment><architecture><port><microservices>,1,3018,0,1.0,6,"<p>I have read some articles and watched some videos, but did not find a concrete suggestion when it comes to serving those micro-services. My understanding is that they should be served with their own application server. </p>&#xA;&#xA;<p>My question is should they be deployed on different servers or it does not matter.</p>&#xA;&#xA;<p>When they are served on the same server(computer) won't there be port conflicts?</p>&#xA;"
28319278,How to connect separate microservice applications?,2015-02-04 10:40:39,<api><security><rest><http><microservices>,5,3209,2,1.0,6,"<p>I am building huge application using microservices architecture. The application will consist of multiple backend microservices (deployed on multiple cloud instances), some of which I would like to connect using rest apis in order to pass data between them.</p>&#xA;&#xA;<p>The application will also expose public api for third parties, but the above mentioned endpoints should be restricted ONLY to other microservices within the same application creating some kind of a private network.</p>&#xA;&#xA;<p>So, my question is: </p>&#xA;&#xA;<p><strong>How to achieve that restricted api access to other microservices within the same application?</strong></p>&#xA;&#xA;<p>If there are better ways to connect microservices than using http transport layer, please mention them.</p>&#xA;&#xA;<p>Please keep the answers server/language agnostic if possible.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
35172625,Spring Cloud Config Eureka-first approach not working,2016-02-03 09:08:19,<spring><spring-boot><spring-cloud><microservices><netflix-eureka>,1,11088,3,2.0,6,"<p>I'm developing a Spring Cloud Eureka microservices application. I want my services to connect to the config service via an Eureka-first approach. Microservices are packaged as docker containers and deployed via docker-compose. The application is composed by:</p>&#xA;&#xA;<ol>&#xA;<li><code>myapp-service-registry</code>: a service registry service implemented with Spring Cloud Eureka</li>&#xA;<li><code>myapp-config-service</code>: a Spring Cloud config service server</li>&#xA;<li><code>myapp-service-test</code>: An example microservice which should try to take its config data from the config service by connecting to this via an Eureka-first approach. </li>&#xA;</ol>&#xA;&#xA;<p>The connection to the config service fail as described below. First of all some configuration data:</p>&#xA;&#xA;<p>Here is <code>myapp-service-registry</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${PORT:8761}&#xA;&#xA;eureka:&#xA;  client:&#xA;    registerWithEureka: false&#xA;    fetchRegistry: false&#xA;  server:&#xA;    waitTimeInMsWhenSyncEmpty: 0&#xA;</code></pre>&#xA;&#xA;<p>Here the <code>myapp-config-service</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>server:&#xA;  port: ${MYAPP_CONFIG_SERVICE_PORT:8888}&#xA;&#xA;spring: &#xA;  cloud:&#xA;    config:&#xA;      server:&#xA;        git:&#xA;          uri: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;  config:&#xA;    name: myapp-config-service&#xA;&#xA;# eureka service registry client&#xA;&#xA;eureka: &#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>Config server and client are initialized as in <code>configserver-eureka</code> and <code>eureka-first</code> samples in <a href=""https://github.com/spring-cloud-samples/tests"" rel=""nofollow"">https://github.com/spring-cloud-samples/tests</a> :</p>&#xA;&#xA;<p><code>myapp-config-service</code>'s <code>bootstrap.yml</code> is:</p>&#xA;&#xA;<pre><code>spring:&#xA;    application:&#xA;        name: myapp-config-service&#xA;    cloud:&#xA;        config:&#xA;            discovery:&#xA;                enabled: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>application.yml</code>:</p>&#xA;&#xA;<pre><code>eureka:&#xA;    client:&#xA;        serviceUrl:&#xA;            defaultZone: http://${SERVICE_REGISTRY_HOST}:${SERVICE_REGISTRY_PORT}/eureka/&#xA;    instance:&#xA;        preferIpAddress: true&#xA;</code></pre>&#xA;&#xA;<p>And <code>myapp-service-test</code>'s <code>bootstrap.yml</code>:</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: myapp-service-test&#xA;  cloud:&#xA;    config:&#xA;      discovery:&#xA;        enabled: true&#xA;        serviceId: myapp-config-service&#xA;</code></pre>&#xA;&#xA;<p>Following is the <code>docker-compose.yml</code> (env variable are replaced with actual values at launch):</p>&#xA;&#xA;<pre><code>myapp-service-registry:&#xA;image: myapp/myapp-service-registry:0.0.1&#xA;ports:&#xA;    - ${EUREKA_PORT}:${EUREKA_PORT}&#xA;&#xA;# myapp-config-service&#xA;&#xA;myapp-config-service:&#xA;    image: myapp/myapp-config-service:0.0.1&#xA;    volumes:&#xA;    - ${MYAPP_DATA_FOLDER}/config:/var/opt/myapp/config&#xA;    environment:&#xA;      MYAPP_CONFIG_SERVICE_PORT: ${MYAPP_CONFIG_SERVICE_PORT}&#xA;      SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;      SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;      MYAPP_CONFIG_SERVICE_GIT_URI: ${MYAPP_CONFIG_SERVICE_GIT_URI}&#xA;    ports:&#xA;        - ${MYAPP_CONFIG_SERVICE_PORT}:${MYAPP_CONFIG_SERVICE_PORT}&#xA;&#xA; # myapp-service-test&#xA;&#xA;myapp-service-test:&#xA;  image: myapp/myapp-service-test:0.0.1&#xA;  environment:&#xA;    SERVICE_REGISTRY_HOST: ${MYAPP_STAGING_IP}&#xA;    SERVICE_REGISTRY_PORT: ${EUREKA_PORT}&#xA;  ports:&#xA;    - ${MYAPP_SERVICE_TEST_TWO_PORT}:8080&#xA;</code></pre>&#xA;&#xA;<p>I can check that Eureka is working by connecting the browser to <a href=""http://[...MACHINE-IP...]:8761/"" rel=""nofollow"">http://[...MACHINE-IP...]:8761/</a> and seeing the Eureka dashboard. Similarly, I test that the config service is working and responds to <a href=""http:///[...MACHINE-IP...]:8888/myapp-config-service"" rel=""nofollow"">http:///[...MACHINE-IP...]:8888/myapp-config-service</a>; With the above configuration, on the other hand, myapp-service-test crashes at startup with the following log:</p>&#xA;&#xA;<pre><code>-02-03 08:26:45.191  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Starting TestServiceApplication v0.0.1 on b1bc37422027 with PID 1 (/app.jar started by root in /)&#xA;2016-02-03 08:26:45.223  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : No active profile set, falling back to default profiles: default&#xA;2016-02-03 08:26:45.448  INFO 1 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@4d97e82d: startup date [Wed Feb 03 08:26:45 UTC 2016]; root of context hierarchy&#xA;2016-02-03 08:26:46.382  INFO 1 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring&#xA;2016-02-03 08:26:46.442  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'configurationPropertiesRebinderAutoConfiguration' of type [class org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6b65138e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&#xA;2016-02-03 08:26:47.089  INFO 1 --- [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING&#xA;2016-02-03 08:26:48.231  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:48.237  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.171  INFO 1 --- [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson&#xA;2016-02-03 08:26:49.496  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null&#xA;2016-02-03 08:26:49.497  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false&#xA;2016-02-03 08:26:49.498  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false&#xA;2016-02-03 08:26:49.502  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true&#xA;2016-02-03 08:26:49.503  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server&#xA;2016-02-03 08:26:49.720  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't get a response from http://localhost:8761/eureka/apps/&#xA;&lt;...&gt;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.jar!/:1.19]&#xA;    at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.jar!/:1.19]&#xA;    at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    &lt;...&gt;&#xA;Caused by: java.net.ConnectException: Connection refused&#xA;    at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_66-internal]&#xA;    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_66-internal]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.747 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.770 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_MYAPP-SERVICE-TEST/b1bc37422027:myapp-service-test - was unable to refresh its cache! status = java.net.ConnectException: Connection refused&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:49.785  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.&#xA;2016-02-03 08:26:49.810  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 10&#xA;2016-02-03 08:26:49.818  INFO 1 --- [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4&#xA;2016-02-03 08:26:50.443  WARN 1 --- [           main] lientConfigServiceBootstrapConfiguration : Could not locate configserver via discovery&#xA;&#xA;java.lang.RuntimeException: No matches for the virtual host name :myapp-config-service&#xA;    at com.netflix.discovery.DiscoveryClient.getNextServerFromEureka(DiscoveryClient.java:782) ~[eureka-client-1.3.4.jar!/:1.3.4]&#xA;    at org.springframework.cloud.netflix.config.DiscoveryClientConfigServiceBootstrapConfiguration.refresh(DiscoveryClientConfigServiceBootstrapConfiguration.java:71) [spring-cloud-netflix-core-1.1.0.M3.jar!/:1.1.0.M3]&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:50.470  INFO 1 --- [           main] e.f.s.two.TestServiceApplication      : Started TestServiceApplication in 7.101 seconds (JVM running for 9.329)&#xA;&#xA;  .   ____          _            __ _ _&#xA; /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \&#xA;( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \&#xA; \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xA;  '  |____| .__|_| |_|_| |_\__, | / / / /&#xA; =========|_|==============|___/=/_/_/_/&#xA; :: Spring Boot ::        (v1.3.1.RELEASE)&#xA;&#xA;2016-02-03 08:26:50.773  INFO 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://localhost:8888&#xA;2016-02-03 08:26:51.015  WARN 1 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for ""http://localhost:8888/myapp-service-test/default"":Connection refused; nested exception is java.net.ConnectException: Connection refused&#xA;&#xA;&lt;...&gt;&#xA;&#xA;2016-02-03 08:26:54.856 ERROR 1 --- [pool-5-thread-1] com.netflix.discovery.DiscoveryClient    : Can't contact any eureka nodes - possibly a security group issue?&#xA;&#xA;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&#xA;    &lt;...&gt;&#xA;&#xA;2016-02-03 08:26:57.272  WARN 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'testTwoServiceController': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: java.lang.String myapp.services.two.TestServiceController.message; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'message' in string value ""${message}""&#xA;2016-02-03 08:26:57.281  INFO 1 --- [           main] o.apache.catalina.core.StandardService   : Stopping service Tomcat&#xA;2016-02-03 08:26:57.299 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed&#xA;</code></pre>&#xA;&#xA;<p>Note that if I don't implement an Eureka-first approach (and set spring.cloud.config.uri directly in the service's <code>bootstrap.yml</code>), the service registers to Eureka, finds the config server and works correctly (I can see the registered service in Eureka's dashboard and can check that config properties are correctly read).</p>&#xA;"
41358754,Looking for API Gateway Technology that call multiple microservices,2016-12-28 09:10:08,<amazon-web-services><microservices><aws-api-gateway><gateway><service-discovery>,1,422,1,4.0,6,"<p>In my company, we plan to migrate our back-end solution, which is a huge monolith, to a sexier microservices architecture.</p>&#xA;&#xA;<p>So far, we have benchmarked many technologies, and we will probably use the AWS infrastructure with AWS EC2 Container Services (ECS). Our microservices will be wrapped in Docker containers.</p>&#xA;&#xA;<p>We have already deployed containers and configured the auto-scaling and the load balancing. Everything works great.</p>&#xA;&#xA;<p>However, we are looking for an API Gateway technology that could allow us to call multiple microservices with only one request for the client.</p>&#xA;&#xA;<p>The idea is to develop an architecture that looks like Netflix one: &#xA;<a href=""http://techblog.netflix.com/2013/01/optimizing-netflix-api.html"" rel=""nofollow noreferrer"">http://techblog.netflix.com/2013/01/optimizing-netflix-api.html</a></p>&#xA;&#xA;<p>For example:</p>&#xA;&#xA;<p>If the client (a web site) wants to fetch the cart of a client. It will send a Get request to the API.</p>&#xA;&#xA;<p>First, I would like that our gateway call the ""user"" microservice that will return the user's information and the list of the id product that his cart contains:</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [1,2,3]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Then, without directly responding to the client, the gateway will call the ""product"" microservice to hydrate the Json with the information about each product.</p>&#xA;&#xA;<pre><code>{&#xA;    ""name"": ""john"",&#xA;    ....,&#xA;    ""cart"": [&#xA;         {""id"": 1, ""name"": ""Iphone"", ...},&#xA;         {""id"": 2, ""name"": ""Ipad"", ...},&#xA;         {""id"": 3, ""name"": ""Ipod"", ...}&#xA;    ]&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>So, my question is do you know a nice technology that could do the job ?</p>&#xA;"
31573823,Microservice Composition Approaches,2015-07-22 20:55:23,<web-services><architecture><microservices>,4,2048,0,3.0,6,"<p>I have a question for the microservices community. I'll give an example from the educational field but it applies to every microservices architecture.</p>&#xA;&#xA;<p>Let's say I have <strong>student-service</strong> and <strong>licensing-service</strong> with a business requirement that the number of students is limited by a license. So every time a student is created a licensing check has to be made. There are multiple types of licenses so the type of the license would have to be included in the operation.</p>&#xA;&#xA;<p>My question is which approach have you found is better in practice:</p>&#xA;&#xA;<ol>&#xA;<li>Build a composite service that calls the 2 services</li>&#xA;<li>Coupling student-service to licensing-service so that when createStudent is called the student-service makes a call to licensing-service and only when that completes will the student be created</li>&#xA;<li>Use an event-based architecture</li>&#xA;</ol>&#xA;&#xA;<p>People talk about microservice architectures being more like a graph than a hierarchy and <strong>option 1</strong> kinda turns this into a hierarchy where you get increasingly coarse composites. Other downsides is it creates confusion as to what service clients should actually use and there's some duplication going on because the composites API would have to include all of the parameters that are needed to call the downstream services.&#xA;It does have a big benefit because it gives you a natural place to do failure handling, choreography and handle consistency.</p>&#xA;&#xA;<p><strong>Option 2</strong> seems like it has disadvantages too:</p>&#xA;&#xA;<ul>&#xA;<li><p>the API of licensing would have to leak into the student API so that you can specify licensing restrictions. </p></li>&#xA;<li><p>it puts a lot of burden on the student-service because it has to handle consistency across all of the dependent services</p></li>&#xA;<li>as more services need to react when a student is created I could see the dependency graph quickly getting out of control and the service would have to handle that complexity in addition to the one from its own logic for managing students.</li>&#xA;</ul>&#xA;&#xA;<p><strong>Option 3</strong> While being decoupling heaven, I don't really think would work because this is all triggered from an UI and people aren't really used to ""go do something else until this new student shows up"" approach.</p>&#xA;&#xA;<p>Thank you </p>&#xA;"
47918407,Microservice architecture - carry message through services when order doesn't matter,2017-12-21 05:21:21,<design-patterns><architecture><rabbitmq><message-queue><microservices>,2,521,0,3.0,6,"<p><strong>Tl;dr</strong>: ""How can I push a message through a bunch of asynchronous, unordered microservices and know when that message has made it through each of them?""</p>&#xA;&#xA;<p>I'm struggling to find the right messaging system/protocol for a specific microservices architecture. This isn't a ""which is best"" question, but a question about what my options are for a design pattern/protocol.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/MbHRf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/MbHRf.png"" alt=""Diagram""></a></p>&#xA;&#xA;<ul>&#xA;<li>I have a <em>message</em> on the beginning queue. Let's say a RabbitMQ message with serialized JSON</li>&#xA;<li>I need that message to go through an arbitrary number of microservices</li>&#xA;<li>Each of those microservices are long running, must be independent, and may be implemented in a variety of languages</li>&#xA;<li>The order of services the message goes through does not matter. In fact, it should not be synchronous.</li>&#xA;<li>Each service can <em>append</em> data to the original message, but that data is ignored by the other services. There should be <em>no</em> merge conflicts (each service writes a unique key). No service will change or destroy data.</li>&#xA;<li>Once <em>all the services have had their turn</em>, the message should be published to a second RabbitMQ queue with the original data and the new data.</li>&#xA;<li>The microservices will have no other side-effects. If this were all in one monolithic application (and in the same language), functional programming would be perfect.</li>&#xA;</ul>&#xA;&#xA;<p>So, the question is, what is an appropriate way to manage that message through the various services? I <strong>don't</strong> want to have to do one at a time, and the order isn't important. But, if that's the case, how can the system know when all the services have had their whack and the final message can be written onto the ending queue (to have the next batch of services have their go).</p>&#xA;&#xA;<p>The only, semi-elegant solution I could come up with was </p>&#xA;&#xA;<ol>&#xA;<li>to have the first service that encounters a message write that message to common storage (say mongodb)</li>&#xA;<li>Have each service do its thing, mark that it has completed for that message, and then check to see if all the services have had their turn</li>&#xA;<li>If so, that last service would publish the message</li>&#xA;</ol>&#xA;&#xA;<p>But that still requires each service to be aware of all the other services <em>and</em> requires each service to leave its mark. Neither of those is desired.</p>&#xA;&#xA;<p>I am open to a ""Shepherd"" service of some kind.</p>&#xA;&#xA;<p>I would appreciate any options that I have missed, and am willing to concede that their may be a better, fundamental design.</p>&#xA;&#xA;<p>Thank you.</p>&#xA;"
31047564,How to get a visualization of cross-app Spring Integration flow?,2015-06-25 10:19:06,<java><spring-integration><esb><microservices>,2,892,2,2.0,6,"<p>We have a microservices architecture, i.e. each of the main components of our system is designed to be run as a separate Java app (jar or war).</p>&#xA;&#xA;<p>We use Spring Integration to facilitate communication between the components (over a MQ service).</p>&#xA;&#xA;<p><strong>How can we get a graphical diagram of the whole integration layer of the system, given that each component has its own Spring Integration XML config?</strong></p>&#xA;&#xA;<p>Note that we know how to do it within a single application. The question is how to do it cross-app.</p>&#xA;&#xA;<p>Example: &#xA;Component 1 generates stream of POJOs -> MQ -> Component 2 serializes POJO object graph to JSON -> MQ -> Component 3 saves JSON to DB</p>&#xA;&#xA;<p>Also, if a viable solution would be to create a single Spring Integration config, then how to make sure all components use it?</p>&#xA;"
35379246,Django models across multiple projects/microservices. How to?,2016-02-13 11:24:40,<django><microservices>,4,2688,0,1.0,6,"<p>I'm wondering how to solve sharing of the model structure between multiple (separated) django projects/microservices. Eg:</p>&#xA;&#xA;<ol>&#xA;<li>Project: API</li>&#xA;<li>Project: Users dashboard</li>&#xA;<li>Project: Admin dashboard</li>&#xA;<li>Project: Statistics</li>&#xA;</ol>&#xA;&#xA;<p>Each of that projects uses the same django models. Is there a one, proper way to solve that?</p>&#xA;"
39920488,What is the role of falcor in a microservice architecture?,2016-10-07 15:09:11,<microservices><falcor>,2,1336,0,4.0,6,"<p>Say we have following taxi-hailing application that is composed of loosely coupled microservices:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/QgctP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QgctP.png"" alt=""https://www.nginx.com/blog/introduction-to-microservices/""></a></p>&#xA;&#xA;<p><em>The example is taken from <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">https://www.nginx.com/blog/introduction-to-microservices/</a></em></p>&#xA;&#xA;<p>Each services has its own rest api and all services are combined in a single api gateway. The client does not talk to a single service but to the gateway. The gateway requests information from several services and combines them to a single response. For the client it looks like it is talking to a monolithic application.</p>&#xA;&#xA;<p><strong>I am trying to understand: where could we incorporate falcor into this application?</strong></p>&#xA;&#xA;<p><strong>One Model Everywhere</strong> from <a href=""http://netflix.github.io/falcor/"" rel=""nofollow noreferrer"">http://netflix.github.io/falcor/</a> </p>&#xA;&#xA;<blockquote>&#xA;  <p>Falcor lets you represent all your remote data sources as a single&#xA;  domain model via a virtual JSON graph. You code the same way no matter&#xA;  where the data is, whether in memory on the client or over the network&#xA;  on the server.</p>&#xA;</blockquote>&#xA;&#xA;<p>In this taxi-hailing application each microservice represents a single domain model already. Can you think of any benefit we could thrive by wrapping each microservice with falcor? I cannot.</p>&#xA;&#xA;<p>However I think it is very convenient to incorporate falcor into the api gateway because we can abstract away the different domain models created by the microservices into one single or at least a few models.</p>&#xA;&#xA;<p>What is your opinion?</p>&#xA;"
38565470,Can Service Fabric Cluster Maintains the old versions of a service?,2016-07-25 10:35:16,<azure><microservices><azure-service-fabric>,1,327,1,0.0,6,"<p>I have a Micro Service in service fabric cluster which is a V1 for example. Now I upgraded it to the new version lets say v2. After a successful upgrade, Service Fabric replaced the old version with the new version of micro service. But I want to have and communicate with both versions of services. Can I achieve this in Service Fabric? If yes can anyone help me out on this?</p>&#xA;&#xA;<p>-Kishore.</p>&#xA;"
44043159,How do I include end-to-end tests across microservices into multiple continuous delivery pipelines?,2017-05-18 08:59:34,<automated-tests><microservices><end-to-end><continuous-delivery><ase>,1,259,1,1.0,6,"<p>My team develops three microservices. The three work together to provide a business scenario. They communicate with REST and RabbitMQ. Looks like in <a href=""https://martinfowler.com/articles/microservice-testing/#testing-end-to-end-diagram"" rel=""noreferrer"">Toby Clemson's presentation on Microservice Testing</a>.</p>&#xA;&#xA;<p>Each microservice has its own continuous delivery pipeline. They are <em>delivery</em>, not <em>deployment</em> pipelines, meaning there is a manual release decision at the end.</p>&#xA;&#xA;<p><strong>How do I include an end-to-end test for the <em>business scenario</em>, i.e. across all microservices, into the delivery pipelines?</strong></p>&#xA;&#xA;<p>My team suggested this:</p>&#xA;&#xA;<p>We add one <em>shared</em> end-to-end stage that deploys all three microservices and runs the end-to-end test on them. Each time one of the pipelines reaches this stage, it deploys and tests. A semaphore ensures the pipelines pass the stage one after the other. Failure stops all three pipelines.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ODu29.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ODu29.png"" alt=""Shared end-to-end stage""></a></p>&#xA;&#xA;<p>To me, this seems to sacrifice all the independence the microservice architecture wins in the first place:</p>&#xA;&#xA;<ul>&#xA;<li><p>The end-to-end stage is a bottleneck. A fast pipeline could thwart slow pipelines because it reserves the end-to-end stage more often, making the others wait before they may run their tests.</p></li>&#xA;<li><p>Failure in one pipeline would stop the other pipelines from delivering, also disabling them from shipping urgent bug fixes.</p></li>&#xA;<li><p>The solution doesn't adapt to new business scenarios that need different combinations of microservices. We would either end up with a super-stage that wires all microservices, or each business scenario would require its own, new end-to-end stage.</p></li>&#xA;<li><p>The end-to-end stage shows only a narrow result because it confirms only that one exact combination of microservice versions work together. If production contains different versions, it does not guarantee this will work as well.</p></li>&#xA;<li><p>The stage is also in conflict with the manual release decision at the end: What if a build passed end-to-end but we decide to not release it to production? Production would then contain a different version of that microservice than end-to-end, causing warped results.</p></li>&#xA;</ul>&#xA;&#xA;<p><strong>So what's a better way to do this?</strong></p>&#xA;"
40938088,Microservices in practice,2016-12-02 17:44:43,<spring><docker><cloud><microservices><docker-swarm>,1,387,1,1.0,6,"<p>I have studied concept of microservices for a good while now, and understand what they are are and why they are necessary.</p>&#xA;&#xA;<p><strong>Quick refresher</strong></p>&#xA;&#xA;<p>In a nutshell, monolith application is decomposed into independent deployable units, each of which typically exposes it's own web API and has it's own database. Each service fulfills a single responsibility and does it well. These services communicates over synchronous web services such as REST or SOAP, or using asynchronous messaging such as JMS to fulfill some request in synergy. Our monolith application has became a distributed system. Typically all these fine grained APIs are made available through an API gateway or proxy, which acts as an single-point-of-entry facade, performing security and monitoring related tasks.</p>&#xA;&#xA;<p>Main reasons to adapt microservices is high availability, zero downtime update and high performance achieved via horizontal scaling of a particular service, and looser coupling in the system, meaning easier maintenance. Also, IDE functionality, build and deployment process will be significantly faster, and it's easier to change framework or even the language.</p>&#xA;&#xA;<p>Microservices goes hand in hand with clustering and containerization technologies, such as Docker. Each microservice could be packed as a docker container to run it in any platform. Principal concepts of clustering are <em>service discovery</em>, <em>replication</em>, <em>load balancing</em> and <em>fault tolerance</em>. Docker Swarm is a clustering tool which orchestrates these containerized services, glues them together, and handles all those tasks under the hood in a declarative manner, maintaining the desired state of the cluster.</p>&#xA;&#xA;<p>Sounds easy and simple in theory, but I still don't understand how to implement this in practice, even I know Docker Swarm pretty well. Let's view an concrete example.</p>&#xA;&#xA;<p><strong>Here is the question</strong></p>&#xA;&#xA;<p>I'm building a simplistic java application with <em>Spring Boot</em>, backed by <em>MySQL</em> database. I want to build a system, where user gets a webpage from <em>Service A</em> and submits a form. <em>Service A</em> will do some manipulation to data and sends it to <em>Service B</em>, which will further manipulate data, write to database, return something and in the end some response is sent back to user.</p>&#xA;&#xA;<p>Now the problem is, <em>Service A</em> doesn't know where to find <em>Service B</em>, nor <em>Service B</em> know where to find <em>database</em> (because they could be deployed at any node in the cluster), so I don't know how I should configure the Spring boot application. First thing to come in my mind is to use DNS, but I can't find tutorials how to setup such a system in docker swarm. What is the correct way to configure connection parameters in Spring for distributed cloud deployment? I have researched about Spring Cloud project, but don't understand if it's the key for this dilemma.</p>&#xA;&#xA;<p>I'm also confused how databases should be deployed. Should they live in the cluster, deployed alongside with the service (possibly with aid of docker compose), or is it better to manage them in more traditional way with fixed IP's?</p>&#xA;&#xA;<p>Last question is about load balancing. I'm confused if there should be multiple load balancers for each service, or just a single master load balancer. Should the load balancer has a static IP mapped to a domain name, and all user requests target this load balancer? What if load balancer fails, doesn't it make all the effort to scale the services pointless? Is it even necessary to setup a load balancer with Docker Swarm, as it has it's own routing mesh? Which node end user should target then?</p>&#xA;"
40856925,Microservices: database and microservice instances,2016-11-29 02:42:17,<microservices><instances><horizontal-scaling>,3,873,3,1.0,6,"<p>Lets say we have a microservice A and a B. B has its own database. However B has to be horizontally scaled, thus we end up having 3 instances of B. What happens to the database? Does it scale accordingly, does it stays the same (centralized) database for the 3 B instances, does it become a distributed database, what happens?</p>&#xA;"
43179951,Business data querying/reporting in service oriented architecture,2017-04-03 08:33:41,<database><reporting><soa><microservices><database-replication>,2,254,7,1.0,6,"<p>For the better part of the last year my company has been slicing up a monolith and building new products upon principles of (micro) service architecture. This is all fine and gives us great flexibility in keeping UI and backend logic separate and lowering the amount of dependencies.</p>&#xA;&#xA;<p>BUT!</p>&#xA;&#xA;<p>There is an important part of our business that has a growing headache as a result of this, namely reporting.</p>&#xA;&#xA;<p>Since we make sure that there is no data replication (and business logic sharing) between services, then each service knows its own data and if another service really needs to keep a reference for that data, they do it through ID's (entity linking, essentially). And while otherwise its great, it's not great for reporting.</p>&#xA;&#xA;<p>Our business often needs to create ad-hoc reports about specific instances happening with our customers. In the 'old days' you made a simple SQL query that joined a couple of database tables and queried whatever you needed, but it is not possible with decoupled services. And this is a problem as business sees it.</p>&#xA;&#xA;<p>I am personally not a fan of data replication for reporting purposes in the back end, as that may have another tendency to grow into a nightmare (which it already is even in our legacy monoliths). So this problem is really not about legacy monoliths versus modern microservices, but about data dependencies in general.</p>&#xA;&#xA;<p>Have you faced issues like this and if yes, then how did you solve it?</p>&#xA;&#xA;<p><strong>EDIT:</strong></p>&#xA;&#xA;<p>We have been discussing in-house the few potential solutions how to solve this, but none of them are actually good and I've not gotten the answer I am looking for yet that solves the issues in large scale.</p>&#xA;&#xA;<ol>&#xA;<li><p>Good old replicate-everything-and-let-BI-people-figure-it-out is what is still used to this day. From the old monolith times the BI/data-warehouse team made duplicates of all databases, but same practice is more inconvenient, but still done to this day for all microservices that use a database. This is not good for various reasons and comes with the shared sandbox cancer you can expect.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that are meant for fetching out specific reports. Each of them connect to set microservices that carries the relevant data and builds the report as expected. This introduces tighter coupling however and can be incredibly complicated and slow with large datasets.</p></li>&#xA;<li><p>Build a separate microservice or a set of microservices that each have databases replicated from other databases in background. This is problematic as team databases are being coupled and data is directly replicated and there is a strong dependency on technology of databases that is being used.</p></li>&#xA;<li><p>Have each service send out an event to RabbitMQ that BI services would pick up on and then fetch additional data, if needed. It sounds by far the best for me, but by far the most complex to implement as all services need to start publishing relevant data. It is what I would personally choose at present time, from a very abstract level, that is.</p></li>&#xA;</ol>&#xA;"
42484087,Microservice: Service discovery and Service Registry with Akka,2017-02-27 11:01:10,<akka><microservices>,1,535,2,2.0,6,<p>I'm going to apply Microservices architecture for my application. The internal communication between microservices will be achieved by using Akka. But I don't know how to make all microservices aware and register each other. I have some options to design Service Registry and Discovery:</p>&#xA;&#xA;<p>1) Use Zookeeper as a centrailized service to hold all metadata of all microservices (nodes) and let them access these metadata to communicate. The metadata of each node contains Akka path (address) information to let the other nodes communicate to.</p>&#xA;&#xA;<p>2) Join all microservices (Akka Nodes) to an Akka Cluster and each node will keep reference of each other to communicate. Akka Cluster supports gossip protocol and it will let all nodes in cluster aware together.</p>&#xA;&#xA;<p>Can anybody give me some advices about this? How to design Service Discovery and Service Registry efficiently on top of Akka? Are there any options for this?</p>&#xA;
45510905,Authentication to access Spring boot Zuul Service routes,2017-08-04 15:47:31,<spring-mvc><spring-boot><microservices><netflix-eureka><netflix-zuul>,1,938,3,2.0,6,"<p>I have configured my micro services using Spring boot zuul and eureka services. &#xA;Now I need to authenticate all routes/REST API calls.&#xA;I mean, for all APIs client send one accessToken. &#xA;On zuul service, before routing to the particular service, I have to call a micro service (auth-service) with accessToken and that auth-service will check the user exists or not for the accessToken sent.&#xA;If the accessToken is valid then only routing should happen.</p>&#xA;&#xA;<p>Please help me to implement this using spring boot service.</p>&#xA;&#xA;<p>Thanks.</p>&#xA;"
40660618,AWS API Gateway + Elastic Beanstalk and Microservices,2016-11-17 16:49:51,<amazon-web-services><elastic-beanstalk><microservices><aws-api-gateway>,1,4604,1,3.0,6,"<p>I'm going to build microservices' architecture on AWS and I want to ask you to clarify my doubts.</p>&#xA;&#xA;<p><strong>My current general concept</strong></p>&#xA;&#xA;<p>I would like to use API Gateway, which exposes microsevices' APIs running in Elastic Beanstalk. I would like to place the Elastic Beanstalk in VPC without direct access from Internet to its instances.</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/6BQi4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6BQi4.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p><strong>Questions &amp; Doubts:</strong></p>&#xA;&#xA;<ol>&#xA;<li>Elastic Beanstalk gets subdomain on application creation. This subdomain should be used by API Gateway with integration type: AWS service, in action configuration - Am I right?</li>&#xA;<li>What would represent a single microservice? An Elastic Beanstalk's application is a specific scalable microservice?</li>&#xA;<li>How the microservices should communicate with each other? There would be some task where Im going to use SQS (Simple Queue Service). But in other cases, is it better when two microservices communicates with each other through API Gateway rather than directly - am I right?</li>&#xA;<li>Test environment: What structure should I use in test environment (or staging env.)? I think about creating separate VPC with another Elastic Beanstalk and other Amazon services.</li>&#xA;<li>Test environment and API Gateway: How should I set up an API Gateway? It should allow clients to access the microservices in test environment if request has specific subdomain, like: test.mydomain.com/hello_world/say_hello. I'm not sure how to use API Gateway in CI/CD to make it fast and simple, without manual copying some configuration from test stage to the production stage. (I'm not expecting any complex solution, only some hints about what components, parts, concepts could I use for it. More details I'll find on my own).</li>&#xA;<li>Have you any experience in deploying apps to Elastic Beanstalk using Codep Deploy and/or Jenkins? I'm interesting in which way could be better: Jenkins, AWS Code Deploy or Jenkins+CodeDeploy.</li>&#xA;</ol>&#xA;"
33165216,Micro Service with API Gateway,2015-10-16 07:51:50,<c#><api><gateway><microservices>,2,8252,1,5.0,7,"<p>For my new project, I have to use <strong>Micro Services with Api Gateway</strong>. So I gathered detailed informations about Micro Service but the Api Gateway part is not clear.</p>&#xA;&#xA;<p>My question is,</p>&#xA;&#xA;<ol>&#xA;<li>Is anyone know about how the request routing part is done in Api&#xA;Gateway?</li>&#xA;<li>Is that can be done by simple if condition[<strong><em>pseudo code:</em></strong>&#xA;if(keyword==""product"") then route(""product service"")]?</li>&#xA;<li>Or Is that any better way to do it?</li>&#xA;</ol>&#xA;&#xA;<p>I am using C#.Net to develop Api.<br>&#xA;I got some info about Api Gateway from <a href=""https://www.nginx.com/blog/building-microservices-using-an-api-gateway/"" rel=""noreferrer"">https://www.nginx.com/blog/building-microservices-using-an-api-gateway/</a></p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/jVOVq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/jVOVq.png"" alt=""Api Gateway""></a></p>&#xA;"
32715464,How to forward all requests to specific version (of same service) during deployment using netflix?,2015-09-22 11:17:13,<spring-cloud><microservices><netflix><netflix-eureka><netflix-zuul>,1,918,1,1.0,7,"<p>I have 4 instance of the same service running on different hosts. I am deploying new version for that service node by node. While deployment, incoming requests get forwarded according to the load balancer to any version (host). Is there any way in netflix where I can forward all incoming requests to a specific version?</p>&#xA;&#xA;<p>Is there any generic way where we can define version (for same serviceId). And if incoming requests has version defined in header, we can use that to forward the requests to specific version.</p>&#xA;&#xA;<p>Could be something like:</p>&#xA;&#xA;<p>In Zuul Proxy,</p>&#xA;&#xA;<pre><code>zuul:&#xA;  routes:&#xA;    sample:&#xA;      path: /sample/{version}/**&#xA;      serviceId: sample-service&#xA;</code></pre>&#xA;&#xA;<p>In sample-service,</p>&#xA;&#xA;<pre><code>eureka:&#xA;  instance:&#xA;    appname: sample-service&#xA;    metadataMap:&#xA;      version: v1&#xA;</code></pre>&#xA;&#xA;<p>or any other mechanism to achieve versioning of same service?</p>&#xA;"
27790905,How to establish relationships between Spring Data REST / Spring HATEOAS based (micro) services?,2015-01-06 01:50:17,<spring-data-rest><hateoas><spring-cloud><microservices>,2,2702,2,3.0,7,"<p>Trying to figure out a pattern for how to handle relationships when using a hypermedia based microservices based on Spring Data Rest or HATEOAS.</p>&#xA;&#xA;<p>If you have service A (Instructor) and Service B (Course) each exist as an a stand alone app.</p>&#xA;&#xA;<p>What is the preferred method for establishing a relationship between the two services.  In a manner that does not require columns for IDs of the foreign service.  It would be possible for each service to have many other services that need to communicate in the same manor.</p>&#xA;&#xA;<p>Possible solution (Not sure a correct path)</p>&#xA;&#xA;<p>Each service has a second table with a OneToMany with the primary entity within the service.  The table would have the following fields:</p>&#xA;&#xA;<p>ID, entityID, rel, relatedID</p>&#xA;&#xA;<p>Then in the opposite service using Spring Data Rest setup a find that queries the join table to find records that match.</p>&#xA;&#xA;<p>The primary goal I want to accomplish would be any service can have relationships with any number of other services without having to have knowledge of the other service.</p>&#xA;"
36541906,centralized settings with microservices,2016-04-11 07:01:48,<microservices>,1,2419,0,2.0,7,"<p>Microservices are all about decomposing your system into separate components.&#xA;However, some things in a system seem like centralized in nature.&#xA;My concern is about the system settings.&#xA;In a monolith you have one big file / db with all the parameters, settings and preferences.&#xA;This can be updated, backup, restore, export, import etc (think about Windows registry). More than this, your customers are used to go to this one ""place"" and set the system.&#xA;With microservices architecture this ""centralism"" seems like an anti pattern.</p>&#xA;&#xA;<p>What are the mechanisms/ frameworks to deal with such contradiction?</p>&#xA;"
51726683,How should microservices developed using AWS API Gateway + Lambda/ECS talk?,2018-08-07 12:20:51,<amazon-web-services><aws-lambda><microservices><aws-api-gateway><amazon-ecs>,5,197,0,5.0,7,"<p>I am developing a ""micro-services"" application using AWS API Gateway with either Lambda or ECS for compute. The issue now is communication between services are via API calls through the API gateway. This feels inefficient and less secure than it can be. Is there a way to make my microservices talk to each other in a more performant and secure manner? Like somehow talk directly within the private network? </p>&#xA;&#xA;<p>One way I thought of is multiple levels of API gateway. </p>&#xA;&#xA;<ul>&#xA;<li>1 public API gateway</li>&#xA;<li>1 private API gateway per microservice. And each microservice can call another microservice ""directly"" inside the private network</li>&#xA;</ul>&#xA;&#xA;<p>But in this way, I need to ""duplicate"" my routes in 2 levels of API ... this does not seem ideal. I was thinking maybe use <code>{proxy+}</code>. So anything <code>/payment/{proxy+}</code> goes to payment API gateway and so on - theres still 2 levels of API gateway ... but this seem to be the best I can go? </p>&#xA;&#xA;<p>Maybe there is a better way? </p>&#xA;"
36137802,An event store could become a single point of failure?,2016-03-21 17:25:54,<cqrs><microservices><event-sourcing><get-event-store>,4,2355,4,3.0,7,"<p>Since a couple of days I've been trying to figure it out how to inform to the rest of the microservices that a new entity was created in a microservice A that store that entity in a MongoDB.</p>&#xA;&#xA;<p>I want to:</p>&#xA;&#xA;<ul>&#xA;<li><p>Have low coupling between the microservices</p></li>&#xA;<li><p>Avoid distributed transactions between microservices like Two Phase Commit (2PC)</p></li>&#xA;</ul>&#xA;&#xA;<p>At first a message broker like RabbitMQ seems to be a good tool for the job but then I see the problem of <strong>commit</strong> the new document in MongoDB and <strong>publish</strong> the message in the broker not being atomic.</p>&#xA;&#xA;<p><a href=""http://eventuate.io/whyeventsourcing.html"" rel=""nofollow noreferrer"">Why event sourcing?</a> by eventuate.io:&#xA;<a href=""https://i.stack.imgur.com/xovbk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xovbk.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>One way of solving this issue implies make the schema of the documents a bit dirtier by adding a mark that says if the document have been published in the broker and having a scheduled background process that search unpublished documents in MongoDB and publishes those to the broker using <a href=""https://www.rabbitmq.com/confirms.html"" rel=""nofollow noreferrer"">confirmations</a>, when the confirmation arrives the document will be marked as published (using at-least-once and idempotency semantics). This solutions is proposed in <a href=""https://stackoverflow.com/a/13490358/3517383"">this</a> and <a href=""https://stackoverflow.com/a/17812090/3517383"">this</a> answers.</p>&#xA;&#xA;<p>Reading an <a href=""https://www.nginx.com/blog/introduction-to-microservices/"" rel=""nofollow noreferrer"">Introduction to Microservices</a> by Chris Richardson I ended up in this great presentation of <a href=""http://www.slideshare.net/chris.e.richardson/developing-functional-domain-models-with-event-sourcing-sbtb-sbtb2015"" rel=""nofollow noreferrer"">Developing functional domain models with event sourcing</a> where one of the slides asked:</p>&#xA;&#xA;<blockquote>&#xA;  <p>How to <strong>atomically</strong> update the database <strong>and</strong> publish events and publish events without 2PC? (dual write problem).</p>&#xA;</blockquote>&#xA;&#xA;<p>The answer is simple (on the next slide)</p>&#xA;&#xA;<blockquote>&#xA;  <p><strike>Update the database <strong>and</strong></strike> publish events</p>&#xA;</blockquote>&#xA;&#xA;<p>This is a different approach to <a href=""https://stackoverflow.com/q/13488982/3517383"">this one</a> that is based on <a href=""https://github.com/MarkNijhof/Cre8iveThought/blob/master/blog/articles/2009-11-12-cqrs--la-greg-young.txt"" rel=""nofollow noreferrer"">CQRS a la Greg Young</a>.</p>&#xA;&#xA;<blockquote>&#xA;  <p>The domain repository is responsible for publishing the events, this&#xA;  would normally be inside a single transaction together with storing&#xA;  the events in the event store.</p>&#xA;</blockquote>&#xA;&#xA;<p>I think that delegate the responsabilities of storing and publishing the events to the event store is a good thing because avoids the need of 2PC or a background process.</p>&#xA;&#xA;<p>However, in a certain way it's true <a href=""https://stackoverflow.com/a/12678477/3517383"">that</a>:</p>&#xA;&#xA;<blockquote>&#xA;  <p>If you rely on the event store to publish the events you'd have a&#xA;  tight coupling to the storage mechanism.</p>&#xA;</blockquote>&#xA;&#xA;<p>But we could say the same if we adopt a message broker for intecommunicate the microservices.</p>&#xA;&#xA;<p>The thing that worries me more is that the Event Store seems to become a Single Point of Failure.</p>&#xA;&#xA;<p>If we look this <a href=""https://github.com/cer/event-sourcing-examples"" rel=""nofollow noreferrer"">example</a> from <a href=""http://eventuate.io"" rel=""nofollow noreferrer"">eventuate.io</a>&#xA;<a href=""https://i.stack.imgur.com/52rMK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/52rMK.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>we can see that if the event store is down, we can't create accounts or money transfers, losing one of the advantages of microservices. (although the system will continue responding querys).</p>&#xA;&#xA;<p>So, it's correct to affirmate that the Event Store as used in the eventuate example is a Single Point of Failure?</p>&#xA;"
47071729,AWS Load Balancer 502,2017-11-02 09:27:21,<amazon-web-services><amazon-ec2><microservices><elastic-load-balancer><internal-load-balancer>,1,873,4,3.0,7,"<p>I have microservices(in different programming languages) running on an EC2 instance.&#xA;On production I notice a few 502 Bad Gateway Errors when these services try to interact with each other.&#xA;Also in the logs of the requested service it doesn't show any api call is being hit</p>&#xA;&#xA;<p>example service A calls service B, but in service B logs there is nothing to indicate that a call came from service A.</p>&#xA;&#xA;<p>Can it be AWS load balancer issue? Any help would be appreciated. Thanks in advance.</p>&#xA;&#xA;<p>Solution tried:&#xA;We tried making http/https connection agents in each service but still we get this issue.</p>&#xA;&#xA;<p>Update:&#xA;In lb logs, the api is logged, but the target response code shows ""-"" whereas lb response code shows 502 or 504. Does it mean that lb is not able to handle the traffic or my application?</p>&#xA;&#xA;<p>Also what can be the possible solution?</p>&#xA;"
48635782,Zookeeper vs Eureka for microservices?,2018-02-06 05:00:32,<apache-zookeeper><microservices><netflix-eureka><orchestration>,2,4240,0,4.0,7,"<p>I am going to implement the orchestration of a set of microservices in my application. Two widely using tools I found vs Apache <a href=""https://zookeeper.apache.org/"" rel=""noreferrer"">Zookeeper</a> and Netflix <a href=""https://github.com/Netflix/eureka"" rel=""noreferrer"">Eureka</a>.</p>&#xA;&#xA;<p>Can anyone please give me a comparison based on fundamental differences, those two services have?</p>&#xA;&#xA;<p>Is there any other powerful tool?</p>&#xA;"
41903352,How do I register a microservice (or its methods) to Task in Netflix Conductor?,2017-01-27 21:33:02,<microservices><netflix><amazon-swf><axon><netflix-conductor>,2,1341,1,0.0,7,"<p>I was looking for a more sophisticated workflow than Saga from AxonFramework  -- which we are currently using -- and I found one in Netflix Conductor. &#xA;Sadly, I have searched the Internet for a decent example but to no avail.</p>&#xA;&#xA;<p>My question is, in Netflix Conductor, how might one define and create Task or WorkflowTask and most importantly, link a microservice to it? Here is a Netflix Conductor code from github:</p>&#xA;&#xA;<pre><code>    WorkflowDef def = new WorkflowDef();&#xA;    def.setName(""test"");&#xA;    WorkflowTask t0 = new WorkflowTask();&#xA;    t0.setName(""t0"");&#xA;    t0.setType(Type.SIMPLE);&#xA;    t0.setTaskReferenceName(""t0"");&#xA;&#xA;    WorkflowTask t1 = new WorkflowTask();&#xA;    t1.setName(""t1"");&#xA;    t1.setType(Type.SIMPLE);&#xA;    t1.setTaskReferenceName(""t1"");&#xA;&#xA;    def.getTasks().add(t0);&#xA;    def.getTasks().add(t1);&#xA;</code></pre>&#xA;&#xA;<p>Pardon my confusion as I am new to Netflix Conductor.</p>&#xA;"
50176793,Automate RabbitMQ consumer testing,2018-05-04 14:02:25,<rabbitmq><integration-testing><microservices>,2,245,0,0.0,7,"<p>I have a .net micro-service receiving messages using RabbitMQ client, I need to test the following:</p>&#xA;&#xA;<p>1- consumer is successfully connected to rabbitMq host.</p>&#xA;&#xA;<p>2- consumer is listening to queue.</p>&#xA;&#xA;<p>3- consumer is receiving messages successfully.</p>&#xA;&#xA;<p>To achieve the above, I have created a sample application that sends messages and I am debugging consumer to be sure that it is receiving messages.</p>&#xA;&#xA;<p>How can I automate this test? hence include it in my micro-service CI.</p>&#xA;&#xA;<p>I am thinking to include my sample app in my CI so I can fire a message then run a consumer unit test that waits a specific time then passes if the message received, but this seems like a wrong practice to me because the test will not start until a few seconds the message is fired.</p>&#xA;&#xA;<p>Another way I am thinking of is firing the sample application from the unit test itself, but if the sample app fails to work that would make it the service fault.</p>&#xA;&#xA;<p>Is there any best practices for integration testing of micro-services connecting through RabbitMQ?</p>&#xA;"
26854986,Cross-service linking for HATEOAS micro-services,2014-11-10 23:33:32,<spring><spring-boot><hateoas><spring-hateoas><microservices>,1,1372,3,4.0,8,"<p>I have a number of micro-services built with Spring Boot, so for a bit of fun, I thought I'd have a go at adding HATEOAS to them to help set up cross-resource linking. It seems to work quite nicely within a particular project, but I was wondering whether there's a good way to link across APIs. As an example, imagine I have 3 services:</p>&#xA;&#xA;<p>A user details service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}&#xA;</code></pre>&#xA;&#xA;<p>A user calendar service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/appointments&#xA;/users/{userid}/appointments/{appointmentid}&#xA;</code></pre>&#xA;&#xA;<p>A user messaging service:&#xA;Code:</p>&#xA;&#xA;<pre><code>/users/{userid}/messages&#xA;/users/{userid}/messages/{messageid}&#xA;</code></pre>&#xA;&#xA;<p>To make this browsable via the API, it would be good to have links from a user resource to its appointments and messages. Similarly, it would be nice to have links back from those resources. This is all very achievable when I have a single API with everything on the classpath, where I can write code such as:</p>&#xA;&#xA;<p>Code:</p>&#xA;&#xA;<pre><code>user.add(linkTo(methodOn(CalendarController.class).appointments(user.getKey())).withRel(""appointments""))&#xA;</code></pre>&#xA;&#xA;<p>However I'm not able to do this if CalendarController is not on the classpath of the service I'm currently hitting.</p>&#xA;&#xA;<p>Is there a good/recommended method for creating links to controllers which are not in the current project?</p>&#xA;&#xA;<p>Referenced from <a href=""http://forum.spring.io/forum/spring-projects/web/749306-cross-service-linking-for-hateoas-micro-services"">spring forums</a></p>&#xA;"
41262716,Don't allow direct calls to Microservices. Only allow through API Gateway,2016-12-21 12:20:58,<java><spring><rest><microservices><gateway>,4,1584,6,1.0,8,"<p>Maybe this is a strange question (I'm new with Microservices). But I'm looking for some info on how proceed with this. Does not need to be Spring specific, but that's the framework I'm using at the moment.</p>&#xA;&#xA;<p>Example:&#xA;Lets say we have two Microservices</p>&#xA;&#xA;<p>a) <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>b) <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>and we have setup Spring Zuul (acting as the API Gateway) with the following rules that forward the incoming calls:</p>&#xA;&#xA;<p>/rest/one -> <a href=""http://myurlfortesting.com:8085/api/rest/serviceone"" rel=""noreferrer"">http://myurlfortesting.com:8085/api/rest/serviceone</a></p>&#xA;&#xA;<p>/rest/two -> <a href=""http://myurlfortesting.com:8090/api/rest/servicetwo"" rel=""noreferrer"">http://myurlfortesting.com:8090/api/rest/servicetwo</a></p>&#xA;&#xA;<p>The question...&#xA;Is there a way to stop users from directly accessing the services mentioned in A and B (only allow the ones that come through the API Gateway)?</p>&#xA;&#xA;<p>Can this be done with Springs Zuul (Acting as a API Gateway) by setting up some extra filters or do we set it up in Microservices endpoints?</p>&#xA;&#xA;<p>Would even like to know if there is a way to not even processing the direct calls on the Microservices endpoints that don't come via the API Gateway.</p>&#xA;&#xA;<p>Maybe this is solved with server specific rules and has nothing to do with Spring? </p>&#xA;&#xA;<p>Many thanks,</p>&#xA;&#xA;<p>/D</p>&#xA;"
32334161,What is the conceptual difference between Service Discovery tools and Load Balancers that check node health?,2015-09-01 14:24:24,<load-balancing><distributed-computing><microservices><service-discovery><consul>,3,414,3,6.0,8,"<p>Recently several service discovery tools have become popular/""mainstream"", and I’m wondering under what primary use cases one should employ them instead of traditional load balancers.</p>&#xA;&#xA;<p>With LBs, you cluster a bunch of nodes behind the balancer, and then clients make requests to the balancer, who then (typically) round robins those requests to all the nodes in the cluster.</p>&#xA;&#xA;<p>With service discovery (<a href=""https://www.consul.io"" rel=""noreferrer"">Consul</a>, <a href=""https://zookeeper.apache.org"" rel=""noreferrer"">ZK</a>, etc.), you let a centralized “consensus” service determine what nodes for particular service are healthy, and your app connects to the nodes that the service deems as being healthy. <strong>So while service discovery and load balancing are two separate concepts, service discovery gives you load balancing as a convenient side effect.</strong></p>&#xA;&#xA;<p>But, if the load balancer (say <a href=""http://www.haproxy.org"" rel=""noreferrer"">HAProxy</a> or <a href=""http://wiki.nginx.org/Main"" rel=""noreferrer"">nginx</a>) has monitoring and health checks built into it, then you pretty much get service discovery as a side effect of load balancing! Meaning, if my LB knows not to forward a request to an unhealthy node in its cluster, then that’s functionally equivalent to a consensus server telling my app not to connect to an unhealty node.</p>&#xA;&#xA;<p>So to me, service discovery tools feel like the “6-in-one,half-dozen-in-the-other” equivalent to load balancers. Am I missing something here? If someone had an application architecture entirely predicated on load balanced microservices, what is the benefit (or not) to switching over to a service discovery-based model?</p>&#xA;"
31546631,What are the option to API gateway with docker?,2015-07-21 18:13:46,<api><docker><microservices><gateway><tyk>,2,6049,0,6.0,8,"<p>I've created several RESTful microservices and dockerized them. Now I want to have a web-based UI for them and the ability to create users and grant permissions to them to use some of the APIs.</p>&#xA;&#xA;<p>I know that I need some kind of API gateway. My first thought was that I always could do that bruteforce way: create some django app that would serve UI and proxy all request to APIs by hand, but this seems very dull. Maybe there are some alternatives? I've ready about Tyk, but can't find any information about the ability to add users and grant permissions to them.</p>&#xA;&#xA;<p>I probably could create an application that would serve as API gateway and automate proxying of requests by writing some code that would model that. So for example I basically need a mapping between external urls to actual api urls and some authorization logic. Maybe there are already something like that?</p>&#xA;"
34593341,Trade offs and best practices building microservices with Azure Service Fabric,2016-01-04 14:26:47,<c#><azure><asp.net-web-api2><microservices><azure-service-fabric>,2,2284,2,3.0,8,"<p>I want to build a microservice application based on Azure Service Fabric. For some stateful services or actors I want to access the state from outside via web api.</p>&#xA;&#xA;<p>What are the general trade-offs and best practices for such a Service Fabric project regarding to:</p>&#xA;&#xA;<ol>&#xA;<li><p>using one vs. multiple services in a single application? Therefore if I use one service per application, I will have multiple applications for my project. When is it useful to use one service per application?</p></li>&#xA;<li><p>using one vs. multiple actors in a single service? When is it useful to have more than one actor per service?</p></li>&#xA;<li><p>using one stateless web api service for the whole project vs. multiple stateless web services for each stateful service or for each application?</p></li>&#xA;</ol>&#xA;&#xA;<p>I know these decisions are based on the specific project. But maybe there are general advantages and disadvantages for the three points above.</p>&#xA;"
35409492,Eureka service discovery without Spring-boot,2016-02-15 12:32:50,<java><spring><spring-boot><microservices><netflix-eureka>,3,8751,1,5.0,8,"<p>I have written a spring boot micro-service and a REST client. The client is a part of another module and make RESTful calls to the micro-service. The micro-service registers with the Eureka registry and I want my client (Which is not a spring boot project) to use the Eureka to query and get the service endpoints. </p>&#xA;&#xA;<p>My problem is since the client is not a Spring-Boot applications I can not use the annotations like <code>@SpringBootApplication</code>, <code>@EnableDiscoveryClient</code> and the <code>DiscoveryClient</code> is not get auto wired to the application. Is there anyway to manually auto-wire the <code>DiscoveryClient</code> bean to the client without using the annotations ?</p>&#xA;"
41618538,Securing REST microservices with Spring Security,2017-01-12 16:41:21,<spring><spring-security><microservices>,1,4585,2,7.0,8,"<p>I'm looking for a best-practice and efficient solution to secure multiple microservices communicating via REST to a Web Client application.</p>&#xA;&#xA;<p><strong>Current setup</strong>:</p>&#xA;&#xA;<p>These microservices are made in Java, with Spring Framework and run into Docker containers.</p>&#xA;&#xA;<p>The client is an Angular 2 application.</p>&#xA;&#xA;<p>I made a new µService that will act as a ""<em>gateway</em>"" and be the only communication point between my web client and my other services.</p>&#xA;&#xA;<p>I retrieve a JWT encrypted token from a remote authentication API (let's call it LOCK)</p>&#xA;&#xA;<p><strong>Solution I was thinking about</strong>:</p>&#xA;&#xA;<p><a href=""https://i.stack.imgur.com/ajEpM.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ajEpM.png"" alt=""enter image description here""></a></p>&#xA;&#xA;<p>I could store the login JWT into a cookie, and send it to the gateway.</p>&#xA;&#xA;<p>The gateway embed in the final payload sent to the concerned µService the token and store the user if it's new into a database.</p>&#xA;&#xA;<p>The microservice then get the query, checks in the remote authentication service the user role, and if it's sufficient, it returns a 200 status with result.</p>&#xA;&#xA;<p><strong>Edit</strong></p>&#xA;&#xA;<p>We will need to have a RabbitMQ Broker into our µServices hive, and thus, to use the WebSockets. In order to secure WebSockets in the same way as securing REST APIs, I'm not sure if we still should manage security in a gateway, and maybe manage it at the microservice level by itself. Because lots of messages will transit, and we should maybe get rid a middleware that will slow down the thing.</p>&#xA;&#xA;<p><strong>Questions</strong>:</p>&#xA;&#xA;<p>Is it a good practice ? What could possibly be done better ? Do you have any example of things done that fills the same needs ? Thanks a lot for your shares &amp; thoughts.</p>&#xA;"
36157778,Accessing stateless service via ServiceProxy fails + ASP.NET 5 Web API project throws Health State error,2016-03-22 14:55:29,<c#><asp.net><.net><microservices><azure-service-fabric>,6,5965,4,3.0,8,"<p>I'm new to microsoft azure service fabric. For my master's degree I have to develop a microservice-approach prototype in service fabric. After hours of researching I am still not getting my issue(s) solved.</p>&#xA;&#xA;<p>I want to access my (in a local fabric cluster deployed) stateless service in a web front-end like in <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/"" rel=""noreferrer"">https://azure.microsoft.com/en-us/documentation/articles/service-fabric-add-a-web-frontend/</a>. The simplest way for doing that is by adding an ASP .NET 5 Web Api project to the Service Fabric application and make a <code>ServiceProxy</code> method call in the <code>ValuesController</code>. So I added this code to my solution:</p>&#xA;&#xA;<p><strong>ValuesController.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>[Route(""api/[controller]"")]&#xA;public class ValuesController : Controller&#xA;{&#xA;  // GET api/values/IObject&#xA;  [HttpGet(""{interfaceName}"")]&#xA;  public async Task&lt;string&gt; Get(string interfaceName)&#xA;  {&#xA;    var serviceName = ""fabric:/DataServiceFabric/MasterDataMService"";&#xA;    var masterDataService = ServiceProxy.Create&lt;IMasterDataMService&gt;(new Uri(serviceName));&#xA;    var result = await masterDataService.GetMasterDataByName(interfaceName);&#xA;    return result.Content;&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>After a F5-deploy my browser doesn't automatically navigate to my web front-end. By looking into the Service Fabric Explorer my ASP .NET 5 application throws a Health State error:</p>&#xA;&#xA;<pre><code>Kind        Health State  Description&#xA;=============================================================================&#xA;Partitions  Error         Unhealthy partitions: 100% (1/1), MaxPercentUnhealthyPartitionsPerService=0%.&#xA;Partition   Error         Unhealthy partition: PartitionId='413...', AggregatedHealthState='Error'.&#xA;Event       Error         Error event: SourceId='System.FM', Property='State'. Partition is below target replica or instance count.&#xA;</code></pre>&#xA;&#xA;<p>After this <a href=""https://stackoverflow.com/questions/34892366/partition-is-below-target-replica-or-instance-count-error-after-deploying-serv"">this</a> question the <em>""Partition is below target replica or instance count""</em> indicates that a unhandled exception in my service is preventing it from starting. But I'm not able to find a stack strace in my Service Fabric Explorer to debug this failure. This is my <code>ServiceManifest.xml</code> of my ASP .NET web service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (Web1):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Name=""Web1"" Version=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;ServiceTypes&gt;&#xA;      &lt;StatelessServiceType ServiceTypeName=""Web1Type""&gt;&#xA;         &lt;Extensions&gt;&#xA;            &lt;Extension Name=""__GeneratedServiceType__""&gt;&#xA;               &lt;GeneratedNames xmlns=""http://schemas.microsoft.com/2015/03/fabact-no-schema""&gt;&#xA;                  &lt;DefaultService Name=""Web1Service"" /&gt;&#xA;                  &lt;ServiceEndpoint Name=""Web1TypeEndpoint"" /&gt;&#xA;               &lt;/GeneratedNames&gt;&#xA;            &lt;/Extension&gt;&#xA;         &lt;/Extensions&gt;&#xA;      &lt;/StatelessServiceType&gt;&#xA;   &lt;/ServiceTypes&gt;&#xA;   &lt;CodePackage Name=""C"" Version=""1.0.0""&gt;&#xA;      &lt;EntryPoint&gt;&#xA;         &lt;ExeHost&gt;&#xA;            &lt;Program&gt;approot\runtimes\dnx-clr-win-x64.1.0.0-rc1-update1\bin\dnx.exe&lt;/Program&gt;&#xA;            &lt;Arguments&gt;--appbase approot\src\Web1 Microsoft.Dnx.ApplicationHost Microsoft.ServiceFabric.AspNet.Hosting --server Microsoft.AspNet.Server.WebListener&lt;/Arguments&gt;&#xA;            &lt;WorkingFolder&gt;CodePackage&lt;/WorkingFolder&gt;&#xA;            &lt;ConsoleRedirection FileRetentionCount=""5"" FileMaxSizeInKb=""2048"" /&gt;&#xA;         &lt;/ExeHost&gt;&#xA;      &lt;/EntryPoint&gt;&#xA;   &lt;/CodePackage&gt;&#xA;   &lt;Resources&gt;&#xA;      &lt;Endpoints&gt;&#xA;         &lt;Endpoint Name=""Web1TypeEndpoint"" Protocol=""http"" Type=""Input"" Port=""80"" /&gt;&#xA;      &lt;/Endpoints&gt;&#xA;   &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>And here my <code>ApplicationManifest.xml</code> of my service fabric solution:</p>&#xA;&#xA;<p><strong>ApplicationManifest.xml:</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ApplicationManifest xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" ApplicationTypeName=""DataServiceFabricType"" ApplicationTypeVersion=""1.0.0"" xmlns=""http://schemas.microsoft.com/2011/01/fabric""&gt;&#xA;   &lt;Parameters&gt;&#xA;      &lt;Parameter Name=""ActorTestServiceActorService_PartitionCount"" DefaultValue=""10"" /&gt;&#xA;      &lt;Parameter Name=""MasterDataMService_InstanceCount"" DefaultValue=""-1"" /&gt;&#xA;   &lt;/Parameters&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;     &lt;ServiceManifestRef ServiceManifestName=""Web2Pkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;     &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""Web1"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""ActorTestServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;ServiceManifestImport&gt;&#xA;      &lt;ServiceManifestRef ServiceManifestName=""MasterDataMServicePkg"" ServiceManifestVersion=""1.0.0"" /&gt;&#xA;      &lt;ConfigOverrides /&gt;&#xA;   &lt;/ServiceManifestImport&gt;&#xA;   &lt;DefaultServices&gt;&#xA;      &lt;Service Name=""Web1Service""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""Web1Type""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""ActorTestServiceActorService"" GeneratedIdRef=""761ee3cf-5a3a-49d8-9c57-aa3480d1acf1""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""ActorTestServiceActorServiceType""&gt;&#xA;            &lt;UniformInt64Partition PartitionCount=""[ActorTestServiceActorService_PartitionCount]"" LowKey=""-9223372036854775808"" HighKey=""9223372036854775807"" /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;      &lt;Service Name=""MasterDataMService""&gt;&#xA;         &lt;StatelessService ServiceTypeName=""MasterDataMServiceType"" InstanceCount=""[MasterDataMService_InstanceCount]""&gt;&#xA;            &lt;SingletonPartition /&gt;&#xA;         &lt;/StatelessService&gt;&#xA;      &lt;/Service&gt;&#xA;   &lt;/DefaultServices&gt;&#xA;&lt;/ApplicationManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>So I created a new solution with an ASP.NET 5 web application and the same <code>ValuesController.cs</code>. I ensured my stateless service is running on my local cluster and than I started my new web application. After calling the GET-Method in my Controller I got the following exception:</p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 0,2593ms 500&#xA;Microsoft.AspNet.Server.Kestrel: Error: An unhandled exception was thrown by the application.&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1}&#xA;</code></pre>&#xA;&#xA;<p>My stateless service is a SingletonPartition, so do I need a partition key here? And if yes, how do I get the key? The Service Fabric Explorer doesn't provide me with this information for my stateless service. Here is the <code>ServiceManifest.xml</code> of my stateless service:</p>&#xA;&#xA;<p><strong>ServiceManifest.xml (MasterDataMService):</strong></p>&#xA;&#xA;<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;&#xA;&lt;ServiceManifest Name=""MasterDataMServicePkg""&#xA;                 Version=""1.0.0""&#xA;                 xmlns=""http://schemas.microsoft.com/2011/01/fabric""&#xA;                 xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&#xA;                 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;&#xA;  &lt;ServiceTypes&gt;&#xA;    &lt;!-- This is the name of your ServiceType. &#xA;         This name must match the string used in RegisterServiceType call in Program.cs. --&gt;&#xA;    &lt;StatelessServiceType ServiceTypeName=""MasterDataMServiceType"" /&gt;&#xA;  &lt;/ServiceTypes&gt;&#xA;&#xA;  &lt;!-- Code package is your service executable. --&gt;&#xA;  &lt;CodePackage Name=""Code"" Version=""1.0.0""&gt;&#xA;    &lt;EntryPoint&gt;&#xA;      &lt;ExeHost&gt;&#xA;        &lt;Program&gt;MasterDataMService.exe&lt;/Program&gt;&#xA;      &lt;/ExeHost&gt;&#xA;    &lt;/EntryPoint&gt;&#xA;  &lt;/CodePackage&gt;&#xA;&#xA;  &lt;!-- Config package is the contents of the Config directoy under PackageRoot that contains an &#xA;       independently-updateable and versioned set of custom configuration settings for your service. --&gt;&#xA;  &lt;ConfigPackage Name=""Config"" Version=""1.0.0"" /&gt;&#xA;&#xA;  &lt;Resources&gt;&#xA;    &lt;Endpoints&gt;&#xA;      &lt;!-- This endpoint is used by the communication listener to obtain the port on which to &#xA;           listen. Please note that if your service is partitioned, this port is shared with &#xA;           replicas of different partitions that are placed in your code. --&gt;&#xA;      &lt;Endpoint Name=""ServiceEndpoint"" Type=""Input"" Protocol=""http"" Port=""80""/&gt;&#xA;    &lt;/Endpoints&gt;&#xA;  &lt;/Resources&gt;&#xA;&lt;/ServiceManifest&gt;&#xA;</code></pre>&#xA;&#xA;<p>After that I decided to set up a service communication with OWIN:</p>&#xA;&#xA;<p><strong>MasterDataMService.cs:</strong></p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>internal sealed class MasterDataMService : StatelessService, IMasterDataMService&#xA;{&#xA;  [...]      &#xA;&#xA;  protected override IEnumerable&lt;ServiceInstanceListener&gt; CreateServiceInstanceListeners()&#xA;  {&#xA;    return new[]&#xA;    {&#xA;      new ServiceInstanceListener(initParams =&gt; new OwinCommunicationListener(""MasterDataMService"", new StartUp(), initParams))&#xA;    };&#xA;  }&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>Now I can acess my microservice by using a <code>HttpClient</code> in my <code>DefaultController</code>:</p>&#xA;&#xA;<pre class=""lang-cs prettyprint-override""><code>var client = new HttpClient();&#xA;var request = ""http://localhost:80/MasterDataMService/api/values/query"";&#xA;var result = string.Empty;&#xA;HttpResponseMessage response = await client.GetAsync(request);&#xA;if (response.IsSuccessStatusCode)&#xA;{&#xA;  result = await response.Content.ReadAsStringAsync();&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>But thats not what I originally wanted. I don't want to specifiy the service endpoint in my request. Instead I would like to communicate with my stateless service over a <code>ServiceProxy</code>. How do I achieve that here? What did I wrong? And how can I solve this Health State error with my ASP .NET 5 application which is deployed into my service fabric cluster?</p>&#xA;&#xA;<p>Thanks for your time.</p>&#xA;&#xA;<p><strong>Edit:</strong></p>&#xA;&#xA;<p><em>Extended stacktrace of invalid partition key exception:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.Fabric.FabricException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,35ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.Fabric.FabricException: Invalid partition key/ID '{0}'  for selector {1} ---&gt; System.Runtime.InteropServices.COMException: exception of HRESULT: 0x80071BBF&#xA;   at System.Fabric.Interop.NativeClient.IFabricServiceManagementClient4.EndResolveServicePartition(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.FabricClient.ServiceManagementClient.ResolveServicePartitionEndWrapper(IFabricAsyncOperationContext context)&#xA;   at System.Fabric.Interop.AsyncCallOutAdapter2`1.Finish(IFabricAsyncOperationContext context, Boolean expectedCompletedSynchronously)&#xA;   --- End of inner exception stack trace ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Client.ServicePartitionResolver.&lt;ResolveAsyncHelper&gt;d__2a.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;GetClientAsync&gt;d__a.MoveNext()&#xA;</code></pre>&#xA;&#xA;<p>Please give me feedback if you need more. (full stack trace is 82 lines long)</p>&#xA;&#xA;<p><em>Invalid scheme exception stack trace:</em></p>&#xA;&#xA;<pre><code>Exception thrown: 'System.ArgumentException' in mscorlib.dll&#xA;Microsoft.AspNet.Hosting.Internal.HostingEngine: Information: Request finished in 1,45ms 500&#xA;Microsoft.AspNet.Server.WebListener.MessagePump: Error: ProcessRequestAsync&#xA;System.ArgumentException: the provided uri scheme 'http' is invalid; expected 'net.tcp'.&#xA;Parametername: via&#xA;   at System.ServiceModel.Channels.TransportChannelFactory`1.ValidateScheme(Uri via)&#xA;   at System.ServiceModel.Channels.ConnectionOrientedTransportChannelFactory`1.OnCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ChannelFactoryBase`1.InternalCreateChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.ServiceChannelFactoryOverDuplexSession.CreateInnerChannelBinder(EndpointAddress to, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateServiceChannel(EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.Channels.ServiceChannelFactory.CreateChannel(Type channelType, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, EndpointAddress address, Uri via)&#xA;   at System.ServiceModel.DuplexChannelFactory`1.CreateChannel(InstanceContext callbackInstance, Binding binding, EndpointAddress endpointAddress)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Wcf.Client.WcfCommunicationClientFactory`1.&lt;CreateClientAsync&gt;d__2.MoveNext()&#xA;--- End of stack trace from the previous location where the exception was thrown ---&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)&#xA;   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;   at Microsoft.ServiceFabric.Services.Communication.Client.CommunicationClientFactoryBase`1.&lt;CreateClientWithRetriesAsync&gt;d__1e.MoveNext()&#xA;</code></pre>&#xA;"
43313424,Consul and Spring Boot services in Docker - not deregistering,2017-04-10 00:36:46,<java><docker><spring-boot><microservices><consul>,2,585,1,2.0,8,"<p>So we have Java microservices written with Spring-Boot, using Consul for service discovery and config management and running in Docker containers.  All of it is working, but when a container dies or a service restarts the old service-id never goes away in Consul and the service forever after shows as ""Failing"" in the Consul UI, even though the new container has registered and shows all Green.</p>&#xA;&#xA;<p>We are not using heartbeat - but I cannot find much documentation on what the difference between heartbeat and healthcheck are for Consul.</p>&#xA;&#xA;<p>Here's my bootstrp.yml</p>&#xA;&#xA;<pre><code>spring:&#xA;  application:&#xA;    name: my-service&#xA;  cloud:&#xA;    config:&#xA;      enabled: false&#xA;    consul:&#xA;      host: ${discovery.host:localhost}&#xA;      port: ${discovery.port:8500}&#xA;      config:&#xA;        watch:&#xA;          wait-time: 30&#xA;          delay: 10000 &#xA;        profile-separator: ""-""&#xA;        format: FILES&#xA;      discovery:&#xA;        prefer-ip-address: true&#xA;        instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}&#xA;</code></pre>&#xA;&#xA;<p>There are other settings to enable heartbeat, but the docs say something about this putting more stress on the Consul cluster.</p>&#xA;&#xA;<p>Has anyone managed to get Consul and Spring Boot/Docker services to actually de-register automatically?  It actually doesn't cause any real problems, but it makes the Consul UI pretty useless to actually monitor for up/down services.</p>&#xA;"
43489589,.NET Core Microservice using RabbitMQ,2017-04-19 07:47:42,<c#><asp.net-web-api><.net-core><microservices><rawrabbit>,1,5075,2,1.0,8,"<p>I am planing to use Microservice architecture for a project. The selected technology stack is <code>.NET Core</code> with <code>Docker</code> and <code>RabbitMQ</code> as a simple service bus and this should be able to deploy on <code>Linux</code>.</p>&#xA;&#xA;<p>Lets say I have a <code>Payment</code> service and an <code>Order</code> Service, I want each of these services to expose <code>REST</code> endpoints. Because of that, I thought of making these two services as <code>.NET Core Web APIs</code>. </p>&#xA;&#xA;<p>But the problem is the inter-service communication using <code>RabbitMQ</code>. Whenever I get a new <code>order</code>, I want to publish an event using <code>RabbitMQ</code> and then listen to that event in <code>Payment</code> service to perform certain operations (database updates). But since these are <code>Web APIs</code>, I don't think it's possible to listen to events as I described. (I feel like I might have to use something like a console application to subscribe to events.)</p>&#xA;&#xA;<p>I would like to find the most viable method to achieve this using the best practices considering the scalability and extendability of the system.</p>&#xA;"
40458770,"Microservice to Microservice calls, authorization from a queue message",2016-11-07 06:05:22,<spring-security><jwt><microservices><netflix-zuul><keycloak>,2,1044,0,3.0,8,"<p><strong>Context:</strong> I'm creating a cloud platform to support multiple applications with SSO. I'm using <strong>Keycloak for authentication</strong> and <strong>Netflix Zuul for authorization</strong> (API Gateway) thru <strong>Keycloak Spring Security Adapter</strong>.</p>&#xA;&#xA;<p>Each microservice expect an Authorization header, which contains a valid JWT, from which it will take the username (sub) to process the request. Each microservice-to-microservice call should go thru Netflix Zuul first, passing the Authorization header to maintain a stateless validation. That strategy allow to every microservice to know who is the user (sub) who is invoking the microservice indirectly.</p>&#xA;&#xA;<p><strong>Problem/Question 1:</strong> What happens if a microservice is invoked from a queue message? One idea that I had is to storage in the queue the information related to the message + userInfo, and, create a dedicated microservice to process that kind of messages, with that approach this special microservice should read the userInfo from the queue and process the message.</p>&#xA;&#xA;<blockquote>&#xA;  <p>UPDATE 1: Per an email reply from another forum, storing the JWT in a queue isn't a good idea, since it could be mined easily.</p>&#xA;</blockquote>&#xA;&#xA;<p><strong>Problem/Question 2:</strong> But, what happens if the previous special microservice wants to call another normal microservice which expect to receive a JWT in a header? Should this special microservice create by himself a JWT to impersonate the user and be able to call the regular microservices?</p>&#xA;&#xA;<p>Another solution that I thought was to storage the original JWT in the queue, but, what happens if the queue calls to the special microservice later? Just after the JWT is not valid anymore (it expired) and the microservice called will reject the request?</p>&#xA;&#xA;<p><strong>Possible solutions:</strong> (Updated per João Angelo discussion, see below)</p>&#xA;&#xA;<blockquote>&#xA;  <p>I should authenticate the requests from my users (<strong>Authorization code flow</strong>) and my services (<strong>Client credentials grant</strong>), both requests should contain user information in the payload. When the request it comes from the user, I need to validate that the payload user info match with the JWT claims. When the request comes from a service, I just need to trust in that service (as long as it is under my control).</p>&#xA;</blockquote>&#xA;&#xA;<p>I will appreciate very much your help. Thanks.</p>&#xA;"
40377377,Micro Services communication,2016-11-02 10:16:49,<java><spring><rest><spring-integration><microservices>,5,1062,0,4.0,8,"<p>I'm new to micro-services, and I'm trying to take my project and turn it into  A micro services based project. My problem is figuring out how each service communicates with each other.</p>&#xA;&#xA;<p>First, I explored the REST style service, but if each service is based HTTP REST how do they ""talk"" to each other after all?</p>&#xA;&#xA;<p>Then I tried to learn Spring Integration, but then it became even unclearer how should they communicate because now it came to my mind that maybe I need to use RabbitMQ to be the middleware between the front end and the micro services back end.</p>&#xA;&#xA;<p>I also run into cloud and Docker technologies, so I guess each service should be on the cloud but still it doesn't make it clear how services communicate.</p>&#xA;&#xA;<p>I'm using Java, Spring technologies.</p>&#xA;&#xA;<p>I'll be happy if someone would give me a better picture how things should be.</p>&#xA;"
45551966,Can (or should) 2 docker containers interact with each other via localhost?,2017-08-07 16:50:30,<docker><docker-compose><microservices><consul><docker-networking>,3,938,1,2.0,8,"<p>We're dockerizing our micro services app, and I ran into some discovery issues.</p>&#xA;&#xA;<p>The app is configured as follows:</p>&#xA;&#xA;<p>When the a service is started in 'non-local' mode, it uses Consul as its Discovery registry.&#xA;When a service is started in 'local' mode, it automatically binds an address per service (For example, tcp://localhost:61001, tcp://localhost:61002 and so on. Hard coded addresses)</p>&#xA;&#xA;<p>After dockerizing the app (for local mode only, for now) each service is a container (Docker images orchestrated with docker-compose. And with docker-machine, if that matters)&#xA;But one service can not interact with another service since they are not on the same machine and tcp://localhost:61001 will obviously not work.</p>&#xA;&#xA;<p>Using docker-compose with <a href=""https://docs.docker.com/compose/compose-file/#links"" rel=""noreferrer"">links</a> and specifying localhost as an alias (service:localhost) didn't work. Is there a way for 2 containers to ""share"" the same localhost? </p>&#xA;&#xA;<p>If not, what is the best way to approach this?&#xA;I thought about using specific hostname per service, and then specify the hostname in the links section of the docker-compose. (But I doubt that this is the elegant solution)&#xA;Or maybe use a dockerized version of Consul and integrate with it?</p>&#xA;&#xA;<p>This post: <a href=""https://stackoverflow.com/questions/43547795/how-to-share-localhost-between-two-different-docker-containers"">How to share localhost between two different Docker containers?</a> provided some insights about why localhost shouldn't be messed with - but I'm still quite puzzled on what's the correct approach here.</p>&#xA;&#xA;<p>Thanks!</p>&#xA;"
36461493,Customizing Zuul Exception,2016-04-06 20:17:50,<java><spring-boot><spring-cloud><microservices><netflix-zuul>,4,9134,5,6.0,10,"<p>I have a scenario in Zuul where the service that the URL is routed too might be down . So the reponse body gets thrown with 500 HTTP Status and ZuulException in the JSON body response.</p>&#xA;&#xA;<pre><code>{&#xA;  ""timestamp"": 1459973637928,&#xA;  ""status"": 500,&#xA;  ""error"": ""Internal Server Error"",&#xA;  ""exception"": ""com.netflix.zuul.exception.ZuulException"",&#xA;  ""message"": ""Forwarding error""&#xA;}&#xA;</code></pre>&#xA;&#xA;<p>All I want to do is to customise or remove the JSON response and maybe change the HTTP status Code.</p>&#xA;&#xA;<p>I tried to create a exception Handler with @ControllerAdvice but the exception is not grabbed by the handler.</p>&#xA;&#xA;<p><strong>UPDATES:</strong></p>&#xA;&#xA;<p>So I extended the Zuul Filter I can see it getting into the run method after the error has been executed how do i change the response then. Below is what i got so far. I read somewhere about SendErrorFilter but how do i implement that and what does it do?</p>&#xA;&#xA;<pre><code>public class CustomFilter extends ZuulFilter {&#xA;&#xA;    @Override&#xA;    public String filterType() {&#xA;        return ""post"";&#xA;    }&#xA;&#xA;    @Override&#xA;    public int filterOrder() {&#xA;&#xA;        return 1;&#xA;    }&#xA;&#xA;    @Override&#xA;    public boolean shouldFilter() {&#xA;        return true;&#xA;    }&#xA;&#xA;    @Override&#xA;    public Object run() {&#xA;        final RequestContext ctx = RequestContext.getCurrentContext();&#xA;        final HttpServletResponse response = ctx.getResponse();&#xA;        if (HttpStatus.INTERNAL_SERVER_ERROR.value() == ctx.getResponse().getStatus()) {&#xA;            try {&#xA;                response.sendError(404, ""Error Error""); //trying to change the response will need to throw a JSON body.&#xA;            } catch (final IOException e) {&#xA;                e.printStackTrace();&#xA;            } ;&#xA;        }&#xA;&#xA;        return null;&#xA;    }&#xA;</code></pre>&#xA;&#xA;<p>Added this to the class that has @EnableZuulProxy</p>&#xA;&#xA;<pre><code>@Bean&#xA;public CustomFilter customFilter() {&#xA;    return new CustomFilter();&#xA;}&#xA;</code></pre>&#xA;"
44884316,How to implement contract testing when kafka is involved in microservice architecture?,2017-07-03 11:23:29,<java><jvm><apache-kafka><microservices><pact>,1,1471,0,2.0,10,<p>I am currently working on a project where we have kafka implementation in micro service architecture. Were you successful in creating contract test cases for mS to kafka topic interaction please using pact-jvm ?</p>&#xA;&#xA;<p>My implementation is microservice1 publishes a message to a REST Client which in turn posts the message to Kafka Topic. microservice2 uses GET method to retrieve messages from the Kafka Topic.</p>&#xA;
41010290,Microservices: REST vs Messaging,2016-12-07 05:49:29,<rest><architecture><messaging><microservices>,2,5671,2,2.0,10,"<p>I heard Amazon uses HTTP for its microservice based architecture. An alternative is to use a messaging system like RabbitMQ or Solace systems. I personally have experience with Solace based microservice architecture, but never with REST. <br>&#xA;Any idea what do various big league implementations like Amazon, Netflix, UK Gov etc use?<br>&#xA;Other aspect is, in microservices, following things are required (besides others):<br>&#xA;* Pattern matching<br>&#xA;* Async messaging.. receiving system may be down<br>&#xA;* Publish subscribe<br>&#xA;* Cache load event.. i.e. on start up, a service may need to load all data from a couple of other services, and should be notified when data is completely loaded, so that it can 'know' that it is now ready to service requests&#xA;<br>&#xA;These aspects are naturally done with messaging rather than REST. Why should anyone use REST (except for public API). Thanks.</p>&#xA;"
43983286,GraphQL and Microservices,2017-05-15 15:26:09,<rest><architecture><microservices><graphql>,2,1942,0,7.0,10,"<p>At my company we've decided on a microservice architecture for a new project.&#xA;We've taken a look at GraphQL and realised its potential and advantages for using as our single API endpoint.</p>&#xA;&#xA;<p>What we disagree on is how the communication should be done between GraphQL and each micro service. Some argue for REST, others say we should also have a graphQL endpoint for each service. </p>&#xA;&#xA;<p>I was wondering what are some of the pros and cons of each.&#xA;For example, having everything in graphQL seems a bit redundant, as we'd be replicating parts of the schema in each service.&#xA;On the other hand, we're using GraphQL to avoid some REST pitfalls. We're afraid having REST endpoints will nullify the advantages gained from gQL.</p>&#xA;&#xA;<p>Has anyone come across a similar dilemma?&#xA;None of us are experienced with GraphQL, so is there some obvious pro and con here that we might be missing?</p>&#xA;&#xA;<p>Thanks in advance!</p>&#xA;"
40495213,Service fabric projects in separate git repos,2016-11-08 19:46:45,<c#><azure><microservices><azure-service-fabric>,4,514,1,3.0,10,<p>Following a normal microservices framework we would like to place each microservice in it's own git repo and then have one repository for the Service Fabric project.  When we update one of the microservice the though would be that the Service Fabric project would redeploy just that service.</p>&#xA;&#xA;<p>Is there any examples of splitting the Service Fabric project up like this?  I've noticed in all of their examples everything is in one solution/repository.</p>&#xA;
25965275,what suitable Scala framework can I choose to use for microservice,2014-09-22 00:36:00,<scala><microservices>,1,1197,1,0.0,-2,"<p>Currently, I am using finagle Scala web framework as microservice for our project, They are very easy to use and also convenient to be deployable. At the same time, my colleague are trying to use Play framework for micro service, but I think it is too huge. It is not micro anymore. </p>&#xA;&#xA;<p>May I know what is your opinion about this and is there any other good microservice framework in scala should be taken into consideration ?</p>&#xA;&#xA;<p>Many thanks in advance</p>&#xA;"
28635179,Microservices with Flask,2015-02-20 17:50:37,<python><flask><docker><soa><microservices>,1,3560,0,0.0,-1,"<p>We are building a pretty large system that will expose several different REST API's, contain a Mongodb database, a Redis cache layer, and a backend computational library. Currently we are using Flask-Restful for building our API's, but for various reasons we also need to run another instance of Flask that provides database resources, and another layer on top of a front facing site. Blueprints are not really a solution since we might want to decouple these various services on different machines in ec2.</p>&#xA;&#xA;<p>We were planning to use Apache+WSGI as a production server, however each flask server would require a unique port, and it is a nightmare to manage all these microservices. I've heard of the concept of a gateway API, but I couldn't really find an documentation on how to implement one or how that looks in practice. </p>&#xA;&#xA;<p>Microservices/SOA seems like a really huge deal these days and in some sense our architecture is designed around that. But I am having trouble finding any info on how to do that in practice, especially in our specific setup. Management of all these servers seems like a potential nightmare. It feels like using Docker could solve most of our headaches, but I'm really curious to know what people did before containers.</p>&#xA;&#xA;<p>TLDR: Have lots of flask servers that are making up our microservice architecture. Have no idea how to manage that.</p>&#xA;"
51206924,how many hours each container is started,2018-07-06 09:14:01,<docker><microservices><swarm>,3,52,1,1.0,-1,"<p>how many hours each container is started</p>&#xA;&#xA;<p>Hi, I need know if have any tool or idea for take metrics, I want know how many hours, each container is up .</p>&#xA;&#xA;<p>This is possible actuality?</p>&#xA;&#xA;<p>Thanks</p>&#xA;"
51277418,mvn clean install -PbuildDocker don't work,2018-07-11 04:44:46,<java><spring><microservices>,2,64,3,0.0,-1,"<p>It is my error info:</p>&#xA;&#xA;<pre><code>Step 9/10 : EXPOSE ${EXPOSED_PORT}&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] Reactor Summary:&#xA;│[INFO]&#xA;│[INFO] spring-petclinic-microservices ..................... SUCCESS [ 0.246 s]&#xA;│[INFO] spring-petclinic-admin-server ...................... FAILURE [ 10.753 s]&#xA;│[INFO] spring-petclinic-monitoring ........................ SKIPPED&#xA;│[INFO] spring-petclinic-customers-service ................. SKIPPED&#xA;│[INFO] spring-petclinic-vets-service ...................... SKIPPED&#xA;│[INFO] spring-petclinic-visits-service .................... SKIPPED&#xA;│[INFO] spring-petclinic-config-server ..................... SKIPPED&#xA;│[INFO] spring-petclinic-discovery-server .................. SKIPPED&#xA;│[INFO] spring-petclinic-api-gateway ....................... SKIPPED&#xA;│[INFO] spring-petclinic-tracing-server .................... SKIPPED&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] BUILD FAILURE&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[INFO] Total time: 11.951 s&#xA;│[INFO] Finished at: 2018-07-11T10:30:27+08:00&#xA;│[INFO] Final Memory: 75M/651M&#xA;│[INFO] ------------------------------------------------------------------------&#xA;│[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;│ng-petclinic-admin-server: Exception caught: EXPOSE requires at least one argument -&gt; [Help 1]&#xA;│[ERROR]&#xA;│[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#xA;│[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#xA;│[ERROR]&#xA;│[ERROR] For more information about the errors and possible solutions, please read the following artic&#xA;│les:&#xA;│[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException&#xA;│[ERROR]&#xA;│[ERROR] After correcting the problems, you can resume the build with the command&#xA;│[ERROR] mvn -rf :spring-petclinic-admin-server&#xA;</code></pre>&#xA;&#xA;<p>It seems like the expose require an argument. What it should be?</p>&#xA;&#xA;<p>This is the dockerfile.</p>&#xA;&#xA;<p>I have tried to set <code>EXPOSE_PORT</code> to <code>22</code> and <code>8899</code> which doesn't work.&#xA;This error info:</p>&#xA;&#xA;<pre><code>[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project spri&#xA;│ng-petclinic-admin-server: Exception caught: Request error: POST unix://localhost:80/build?buildargs=&#xA;│%7B%22ARTIFACT_NAME%22%3A%22spring-petclinic-admin-server-1.5.9%22%2C%22EXPOSED_PORT%22%3A%229090%22%&#xA;│7D&amp;t=mszarlinski/spring-petclinic-admin-server: 500: HTTP 500 Internal Server Error -&gt; [Help 1]&#xA;│[ERROR]&#xA;</code></pre>&#xA;&#xA;<h2>Thanks!</h2>&#xA;&#xA;<p>This is the plugin apart of pom.xml about admin-server:</p>&#xA;&#xA;<pre><code>&lt;profiles&gt;&#xA;    &lt;profile&gt;&#xA;        &lt;id&gt;buildDocker&lt;/id&gt;&#xA;        &lt;build&gt;&#xA;            &lt;plugins&gt;&#xA;                &lt;plugin&gt;&#xA;                    &lt;groupId&gt;com.spotify&lt;/groupId&gt;&#xA;                    &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;&#xA;                    &lt;version&gt;${docker.plugin.version}&lt;/version&gt;&#xA;                &lt;/plugin&gt;&#xA;            &lt;/plugins&gt;&#xA;        &lt;/build&gt;&#xA;    &lt;/profile&gt;&#xA;&lt;/profiles&gt;&#xA;</code></pre>&#xA;"
45115860,how to use golang microservices?,2017-07-15 07:49:07,<go><microservices>,3,381,1,3.0,-1,"<p>My company use Go to build some HTTP API services. We want these services share one HTTP port. </p>&#xA;&#xA;<p>So the solution right now is we create a project named router, and router import some modules, every request pass through router to their own modules.<br>&#xA;But the question is that if one of these modules process crashed, the router just crash.</p>&#xA;&#xA;<p>Is there any solutions?</p>&#xA;&#xA;<p>Require:</p>&#xA;&#xA;<ol>&#xA;<li>One http port.</li>&#xA;<li>Every service is independent.</li>&#xA;</ol>&#xA;&#xA;<p>I know go-kit and go micro, also I have tried, but still not too understand.</p>&#xA;"
46390552,which is the best API gateway for micro services using spring?,2017-09-24 13:27:44,<spring-boot><microservices>,1,1655,0,0.0,-1,"<p>I am trying to build a simple application with microservices architecture.&#xA;Below are the details about 3 microservices I have created.</p>&#xA;&#xA;<pre><code>1] Customer.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8081&#xA;2] vendor.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8082&#xA;3] product.&#xA;       database: mongodb&#xA;       server  : embeded tomcat server.&#xA;       port    : 8083&#xA;</code></pre>&#xA;&#xA;<p>All the 3 micros runs on an embeded tomcat server.&#xA;Now I want to create a common gateway for all these micros [API gateway].&#xA;which help me to route my request based on the request I get for example:-&#xA;for example if I get a request of <a href=""http://hostname:port_of_gateway/customer"" rel=""nofollow noreferrer"">http://hostname:port_of_gateway/customer</a>.&#xA;on reading this I need to route the request tom my customer micro and fetch its response and send it back to client.&#xA;Which of the spring tool I can use to achieve this?</p>&#xA;"
50448620,Issue while using the kubernetes annotations,2018-05-21 12:10:46,<kubernetes><microservices>,3,151,0,0.0,-1,"<p>I've read documentation of kubernetes annotations. </p>&#xA;&#xA;<p>But I couldn't find basic example about using this annotations. For Example;</p>&#xA;&#xA;<p>I have a deployment yaml like below:</p>&#xA;&#xA;<pre><code>apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  annotations:&#xA;    test_value: ""test""&#xA;  name: nginx-deployment&#xA;  labels:&#xA;    app: nginx&#xA;spec:&#xA;  replicas: 1&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: nginx&#xA;    spec:&#xA;      containers:&#xA;      - name: nginx&#xA;        image: nginx:1.13&#xA;        ports:&#xA;        - containerPort: 80&#xA;</code></pre>&#xA;&#xA;<p>How can I use this annotation named test_value and where.</p>&#xA;&#xA;<p>Best Regards...</p>&#xA;"
43492974,Multiple docker services to listen on same host and port,2017-04-19 10:23:58,<nginx><docker><docker-compose><microservices><jwilder-nginx-proxy>,1,578,0,0.0,-1,"<p>i am new to nginx and I am not sure is this normal behavior...</p>&#xA;&#xA;<p>Here is the lib I am using: <a href=""https://github.com/jwilder/nginx-proxy"" rel=""nofollow noreferrer"">https://github.com/jwilder/nginx-proxy</a></p>&#xA;&#xA;<p>I will explain here what I trying to accomplish... </p>&#xA;&#xA;<p>I have 2 additional services <code>service1</code> and <code>service2</code> those services are simple node.js images with API endpoints</p>&#xA;&#xA;<pre><code>service1 have routes:&#xA;- service1/api/first&#xA;- service1/api/second&#xA;`&#xA;&#xA;`&#xA;service2 have routes:&#xA;- service2/api/third&#xA;- service2/api/fourth&#xA;`&#xA;&#xA;So is possible to be able to access this services from same host, like this:&#xA;localhost/service1/api/first&#xA;localhost/service2/api/third&#xA;?&#xA;&#xA;I tried like this:&#xA;&#xA;My `docker-compose.yml` file:&#xA;&#xA;&#xA;version: '2'&#xA;services:&#xA;  nginx-proxy:&#xA;    image: jwilder/nginx-proxy&#xA;    container_name: nginx-proxy&#xA;    ports:&#xA;      - ""80:80""&#xA;    volumes:&#xA;      - /var/run/docker.sock:/tmp/docker.sock:ro&#xA;&#xA;  whoami:&#xA;    image: jwilder/whoami&#xA;    environment:&#xA;      - VIRTUAL_HOST=whoami.local&#xA;  service1:&#xA;    image: mynode:1.1&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service1.local&#xA;      - VIRTUAL_PORT=8080&#xA;  service2:&#xA;    image: mynodeother:1.2&#xA;    volumes:&#xA;        - .:/app&#xA;    restart: always&#xA;    environment:&#xA;      - VIRTUAL_HOST=service2.local&#xA;      - VIRTUAL_PORT=8081&#xA;</code></pre>&#xA;&#xA;<p>Here is generated config file from command <code>docker exec nginx-proxy cat /etc/nginx/conf.d/default.conf</code>:&#xA;<a href=""http://pushsc.com/show/code/58f739790a58d602a0b99d22"" rel=""nofollow noreferrer"">http://pushsc.com/show/code/58f739790a58d602a0b99d22</a></p>&#xA;&#xA;<p>Also when I visit localhost in browser I get: </p>&#xA;&#xA;<blockquote>&#xA;  <p>Welcome to nginx!</p>&#xA;  &#xA;  <p>If you see this page, the nginx web server is successfully installed&#xA;  and working. Further configuration is required.</p>&#xA;  &#xA;  <p>For online documentation and support please refer to nginx.org.&#xA;  Commercial support is available at nginx.com.</p>&#xA;  &#xA;  <p>Thank you for using nginx.</p>&#xA;</blockquote>&#xA;"
51842460,Miscroservice Intercommunication with RabbitMQ,2018-08-14 13:18:11,<java><rabbitmq><microservices><messaging>,1,43,4,0.0,-1,"<p>I'm new in the worls of Microservices and I'm buildung a pretty basic Architecture the combine the basic components I might need for a later project.&#xA;My enviroment is eclipse using spring.&#xA;So I thought about having 3 different Microservices.&#xA;Service A does a simple calculation after a rest call and writes the parameters, the operand and the result in a database.&#xA;Service B should read the the last result from the database.&#xA;Service C should take the last 10 results from the Database.</p>&#xA;&#xA;<p>So after reading about best practice handling this task I thought about realizing it asynchronous. So A should message B and C when the result is written into the database so that they can read their needed values in parallel from the database instead of on waiting for another.&#xA;I found a pretty good tutorial where I think I got the code I need <a href=""https://www.youtube.com/watch?v=c7cWKZlgnNc"" rel=""nofollow noreferrer"">here</a> &#xA;I thought about running an instance of RabbitMQ on my localhost:9999 for example.&#xA;Then I would set Service A my message producer and B and C as my consumers with registering the connection to this adress. To communicate I would do one queue for each service where I send the signal when A is finished.&#xA;Is this a proper solution for this task and is my plan of realizing it reliable? Or do you have any better solution?&#xA;I hope this is not a dump question.&#xA;Thank you guys</p>&#xA;"
